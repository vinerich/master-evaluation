[32m[0906 13-40-12 @logger.py:99][0m Log file set to /app/logs/dats-delay-20/zinc-coating-v0_2/Tuesday_06_September_2022_01-40PM.log
[32m[0906 13-40-12 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00002, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -60.17445, mean: -1.00291
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -120.90565, mean: -1.09914
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -162.56158, mean: -1.01601
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -217.70398, mean: -1.03669
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -272.25336, mean: -1.04713
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -319.53992, mean: -1.03077
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -370.20780, mean: -1.02835
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -429.78961, mean: -1.04827
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -483.50653, mean: -1.05110
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -547.24990, mean: -1.07304
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -600.04280, mean: -1.07150
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -656.11028, mean: -1.07559
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -722.89082, mean: -1.09529
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -780.56920, mean: -1.09939
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -832.88764, mean: -1.09590
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -878.79064, mean: -1.08493
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -930.48180, mean: -1.08196
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -982.03169, mean: -1.07916
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -1058.80462, mean: -1.10292
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1121.23047, mean: -1.11013
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1185.50646, mean: -1.11840
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1245.07547, mean: -1.12169
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1303.02634, mean: -1.12330
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1359.01310, mean: -1.12315
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1417.56814, mean: -1.12505
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1477.15067, mean: -1.12760
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1538.07000, mean: -1.13093
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1603.40909, mean: -1.13717
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1661.27533, mean: -1.13786
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1718.26434, mean: -1.13792
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -1766.97816, mean: -1.13268
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -1825.15385, mean: -1.13364
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -1887.03623, mean: -1.13677
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -1956.82377, mean: -1.14434
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -2022.81171, mean: -1.14932
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -2112.06723, mean: -1.16689
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2192.24180, mean: -1.17862
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2270.81894, mean: -1.18891
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2342.67772, mean: -1.19524
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2416.52374, mean: -1.20225
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2488.26234, mean: -1.20789
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2568.66194, mean: -1.21738
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2655.09004, mean: -1.22921
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2706.56552, mean: -1.22469
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2763.72007, mean: -1.22288
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2831.39552, mean: -1.22571
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2882.01643, mean: -1.22119
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2935.90190, mean: -1.21822
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2993.31911, mean: -1.21680
[32m[0906 13-40-12 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-40-12 @Agent.py:118][0m Rollout length: 2520
[32m[0906 13-40-14 @MBExp.py:144][0m ####################################################################
[32m[0906 13-40-14 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-40-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30240, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29112, current rewards: -60.00000, mean: -1.00000
[32m[0906 13-40-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30506, current rewards: -110.00000, mean: -1.00000
[32m[0906 13-41-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31353, current rewards: -160.00000, mean: -1.00000
[32m[0906 13-41-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31789, current rewards: -210.00000, mean: -1.00000
[32m[0906 13-41-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32613, current rewards: -260.00000, mean: -1.00000
[32m[0906 13-41-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33362, current rewards: -310.00000, mean: -1.00000
[32m[0906 13-42-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33839, current rewards: -360.00000, mean: -1.00000
[32m[0906 13-42-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34207, current rewards: -410.00000, mean: -1.00000
[32m[0906 13-42-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34486, current rewards: -460.00000, mean: -1.00000
[32m[0906 13-43-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34693, current rewards: -510.00000, mean: -1.00000
[32m[0906 13-43-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34831, current rewards: -560.00000, mean: -1.00000
[32m[0906 13-43-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34959, current rewards: -610.00000, mean: -1.00000
[32m[0906 13-44-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35065, current rewards: -660.00000, mean: -1.00000
[32m[0906 13-44-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35172, current rewards: -710.00000, mean: -1.00000
[32m[0906 13-44-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35266, current rewards: -760.00000, mean: -1.00000
[32m[0906 13-45-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35348, current rewards: -810.00000, mean: -1.00000
[32m[0906 13-45-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35424, current rewards: -860.00000, mean: -1.00000
[32m[0906 13-45-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35477, current rewards: -910.00000, mean: -1.00000
[32m[0906 13-45-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35537, current rewards: -960.00000, mean: -1.00000
[32m[0906 13-46-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35585, current rewards: -1010.00000, mean: -1.00000
[32m[0906 13-46-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35617, current rewards: -1060.00000, mean: -1.00000
[32m[0906 13-46-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35645, current rewards: -1110.00000, mean: -1.00000
[32m[0906 13-47-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35658, current rewards: -1160.00000, mean: -1.00000
[32m[0906 13-47-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35667, current rewards: -1210.00000, mean: -1.00000
[32m[0906 13-47-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35684, current rewards: -1260.00000, mean: -1.00000
[32m[0906 13-48-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35697, current rewards: -1310.00000, mean: -1.00000
[32m[0906 13-48-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35702, current rewards: -1360.00000, mean: -1.00000
[32m[0906 13-48-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35717, current rewards: -1410.00000, mean: -1.00000
[32m[0906 13-48-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35736, current rewards: -1460.00000, mean: -1.00000
[32m[0906 13-49-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35744, current rewards: -1510.00000, mean: -1.00000
[32m[0906 13-49-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35757, current rewards: -1544.77244, mean: -0.99024
[32m[0906 13-49-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35775, current rewards: -1540.38830, mean: -0.95676
[32m[0906 13-50-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35796, current rewards: -1563.56547, mean: -0.94191
[32m[0906 13-50-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35810, current rewards: -1613.56547, mean: -0.94361
[32m[0906 13-50-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35825, current rewards: -1663.56547, mean: -0.94521
[32m[0906 13-51-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35838, current rewards: -1713.56547, mean: -0.94672
[32m[0906 13-51-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35851, current rewards: -1763.56547, mean: -0.94815
[32m[0906 13-51-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35863, current rewards: -1813.56547, mean: -0.94951
[32m[0906 13-51-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35872, current rewards: -1863.56547, mean: -0.95080
[32m[0906 13-52-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35879, current rewards: -1913.56547, mean: -0.95202
[32m[0906 13-52-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35890, current rewards: -1959.36419, mean: -0.95115
[32m[0906 13-52-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35891, current rewards: -2009.36419, mean: -0.95231
[32m[0906 13-53-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35891, current rewards: -2059.36419, mean: -0.95341
[32m[0906 13-53-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35889, current rewards: -2109.36419, mean: -0.95446
[32m[0906 13-53-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35888, current rewards: -2159.36419, mean: -0.95547
[32m[0906 13-54-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35891, current rewards: -2209.36419, mean: -0.95643
[32m[0906 13-54-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35892, current rewards: -2259.36419, mean: -0.95736
[32m[0906 13-54-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35903, current rewards: -2309.36419, mean: -0.95824
[32m[0906 13-54-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35910, current rewards: -2359.36419, mean: -0.95909
[32m[0906 13-55-13 @Agent.py:117][0m Average action selection time: 0.3592
[32m[0906 13-55-13 @Agent.py:118][0m Rollout length: 2520
[32m[0906 13-55-13 @MBExp.py:227][0m Rewards obtained: [-2399.364189314811], Lows: [0], Highs: [2407], Total time: 898.68028
[32m[0906 13-55-17 @MBExp.py:144][0m ####################################################################
[32m[0906 13-55-17 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-55-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36478, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-55-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36320, current rewards: -52.04185, mean: -0.86736
[32m[0906 13-55-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36235, current rewards: -152.04185, mean: -1.38220
[32m[0906 13-56-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36201, current rewards: -252.04185, mean: -1.57526
[32m[0906 13-56-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36138, current rewards: -352.04185, mean: -1.67639
[32m[0906 13-56-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36008, current rewards: -452.04185, mean: -1.73862
[32m[0906 13-57-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35975, current rewards: -552.04185, mean: -1.78078
[32m[0906 13-57-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35933, current rewards: -652.04185, mean: -1.81123
[32m[0906 13-57-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35894, current rewards: -719.26721, mean: -1.75431
[32m[0906 13-58-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35869, current rewards: -734.55978, mean: -1.59687
[32m[0906 13-58-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35879, current rewards: -746.42290, mean: -1.46357
[32m[0906 13-58-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35899, current rewards: -738.55648, mean: -1.31885
[32m[0906 13-58-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35914, current rewards: -730.67947, mean: -1.19784
[32m[0906 13-59-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35925, current rewards: -722.80207, mean: -1.09515
[32m[0906 13-59-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35931, current rewards: -714.93037, mean: -1.00694
[32m[0906 13-59-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35932, current rewards: -726.72446, mean: -0.95622
[32m[0906 14-00-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35945, current rewards: -726.83068, mean: -0.89732
[32m[0906 14-00-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35937, current rewards: -719.52879, mean: -0.83666
[32m[0906 14-00-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35942, current rewards: -712.75055, mean: -0.78324
[32m[0906 14-01-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35948, current rewards: -748.31062, mean: -0.77949
[32m[0906 14-01-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35961, current rewards: -738.86178, mean: -0.73155
[32m[0906 14-01-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35943, current rewards: -729.49012, mean: -0.68820
[32m[0906 14-01-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35929, current rewards: -720.12291, mean: -0.64876
[32m[0906 14-02-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35920, current rewards: -710.75151, mean: -0.61272
[32m[0906 14-02-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35913, current rewards: -725.43677, mean: -0.59953
[32m[0906 14-02-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35900, current rewards: -717.02938, mean: -0.56907
[32m[0906 14-03-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35891, current rewards: -710.94885, mean: -0.54271
[32m[0906 14-03-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35895, current rewards: -705.00595, mean: -0.51839
[32m[0906 14-03-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35908, current rewards: -699.06327, mean: -0.49579
[32m[0906 14-04-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35928, current rewards: -693.11594, mean: -0.47474
[32m[0906 14-04-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35955, current rewards: -687.15308, mean: -0.45507
[32m[0906 14-04-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35976, current rewards: -681.20848, mean: -0.43667
[32m[0906 14-04-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35984, current rewards: -675.24721, mean: -0.41941
[32m[0906 14-05-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35988, current rewards: -670.02026, mean: -0.40363
[32m[0906 14-05-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35984, current rewards: -665.41358, mean: -0.38913
[32m[0906 14-05-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35973, current rewards: -661.00590, mean: -0.37557
[32m[0906 14-06-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35963, current rewards: -723.76416, mean: -0.39987
[32m[0906 14-06-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35953, current rewards: -819.29894, mean: -0.44048
[32m[0906 14-06-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35949, current rewards: -912.59108, mean: -0.47780
[32m[0906 14-07-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35941, current rewards: -1008.10301, mean: -0.51434
[32m[0906 14-07-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35953, current rewards: -1101.38815, mean: -0.54795
[32m[0906 14-07-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35964, current rewards: -1196.86954, mean: -0.58100
[32m[0906 14-07-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35978, current rewards: -1292.31481, mean: -0.61247
[32m[0906 14-08-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35975, current rewards: -1385.48646, mean: -0.64143
[32m[0906 14-08-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35967, current rewards: -1480.94220, mean: -0.67011
[32m[0906 14-08-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35956, current rewards: -1574.10767, mean: -0.69651
[32m[0906 14-09-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35954, current rewards: -1669.54232, mean: -0.72275
[32m[0906 14-09-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35951, current rewards: -1764.98493, mean: -0.74787
[32m[0906 14-09-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35946, current rewards: -1858.16097, mean: -0.77102
[32m[0906 14-10-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35944, current rewards: -1953.60720, mean: -0.79415
[32m[0906 14-10-17 @Agent.py:117][0m Average action selection time: 0.3595
[32m[0906 14-10-17 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-10-17 @MBExp.py:227][0m Rewards obtained: [-1983.124898444077], Lows: [1062], Highs: [61], Total time: 1798.049714
[32m[0906 14-10-24 @MBExp.py:144][0m ####################################################################
[32m[0906 14-10-24 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 14-10-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35907, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-10-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36219, current rewards: -14.34658, mean: -0.23911
[32m[0906 14-11-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36256, current rewards: -6.50326, mean: -0.05912
[32m[0906 14-11-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36372, current rewards: 1.36351, mean: 0.00852
[32m[0906 14-11-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36434, current rewards: 9.23536, mean: 0.04398
[32m[0906 14-11-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36344, current rewards: 17.08507, mean: 0.06571
[32m[0906 14-12-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36309, current rewards: 24.95135, mean: 0.08049
[32m[0906 14-12-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36263, current rewards: 32.83581, mean: 0.09121
[32m[0906 14-12-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36171, current rewards: 41.11928, mean: 0.10029
[32m[0906 14-13-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36141, current rewards: 49.38825, mean: 0.10737
[32m[0906 14-13-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36097, current rewards: 57.64284, mean: 0.11303
[32m[0906 14-13-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36066, current rewards: 22.41776, mean: 0.04003
[32m[0906 14-14-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36031, current rewards: 30.54979, mean: 0.05008
[32m[0906 14-14-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36013, current rewards: 38.53638, mean: 0.05839
[32m[0906 14-14-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35987, current rewards: 46.49853, mean: 0.06549
[32m[0906 14-14-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35961, current rewards: 54.50658, mean: 0.07172
[32m[0906 14-15-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35934, current rewards: 66.46026, mean: 0.08205
[32m[0906 14-15-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35915, current rewards: 77.37954, mean: 0.08998
[32m[0906 14-15-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35901, current rewards: 88.35258, mean: 0.09709
[32m[0906 14-16-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35888, current rewards: 99.28287, mean: 0.10342
[32m[0906 14-16-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35901, current rewards: 110.24444, mean: 0.10915
[32m[0906 14-16-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35911, current rewards: 121.18833, mean: 0.11433
[32m[0906 14-17-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35925, current rewards: 87.52397, mean: 0.07885
[32m[0906 14-17-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35934, current rewards: 98.67679, mean: 0.08507
[32m[0906 14-17-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35941, current rewards: 108.41491, mean: 0.08960
[32m[0906 14-17-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35950, current rewards: 120.80403, mean: 0.09588
[32m[0906 14-18-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35956, current rewards: 133.20666, mean: 0.10168
[32m[0906 14-18-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35957, current rewards: 145.58888, mean: 0.10705
[32m[0906 14-18-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35964, current rewards: 157.99514, mean: 0.11205
[32m[0906 14-19-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35950, current rewards: 170.41415, mean: 0.11672
[32m[0906 14-19-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35936, current rewards: 182.82271, mean: 0.12107
[32m[0906 14-19-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35920, current rewards: 195.23166, mean: 0.12515
[32m[0906 14-20-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35906, current rewards: 202.31119, mean: 0.12566
[32m[0906 14-20-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35896, current rewards: 186.77509, mean: 0.11252
[32m[0906 14-20-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35885, current rewards: 190.80887, mean: 0.11158
[32m[0906 14-20-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35877, current rewards: 194.91003, mean: 0.11074
[32m[0906 14-21-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35866, current rewards: 199.01168, mean: 0.10995
[32m[0906 14-21-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35857, current rewards: 203.11898, mean: 0.10920
[32m[0906 14-21-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35847, current rewards: 207.22285, mean: 0.10849
[32m[0906 14-22-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35839, current rewards: 211.32754, mean: 0.10782
[32m[0906 14-22-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35829, current rewards: 216.81599, mean: 0.10787
[32m[0906 14-22-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35825, current rewards: 181.36337, mean: 0.08804
[32m[0906 14-23-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35816, current rewards: 189.95578, mean: 0.09003
[32m[0906 14-23-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35806, current rewards: 198.55063, mean: 0.09192
[32m[0906 14-23-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35805, current rewards: 207.15078, mean: 0.09373
[32m[0906 14-23-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35800, current rewards: 215.75071, mean: 0.09546
[32m[0906 14-24-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35802, current rewards: 224.33631, mean: 0.09712
[32m[0906 14-24-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35807, current rewards: 232.93270, mean: 0.09870
[32m[0906 14-24-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35810, current rewards: 238.04503, mean: 0.09877
[32m[0906 14-25-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35805, current rewards: 244.67897, mean: 0.09946
[32m[0906 14-25-19 @Agent.py:117][0m Average action selection time: 0.3581
[32m[0906 14-25-19 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-25-19 @MBExp.py:227][0m Rewards obtained: [249.98528644285662], Lows: [70], Highs: [40], Total time: 2693.90067
[32m[0906 14-25-28 @MBExp.py:144][0m ####################################################################
[32m[0906 14-25-28 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 14-25-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35734, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-25-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35511, current rewards: -19.81638, mean: -0.33027
[32m[0906 14-26-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35363, current rewards: -16.74579, mean: -0.15223
[32m[0906 14-26-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35370, current rewards: -13.68024, mean: -0.08550
[32m[0906 14-26-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35375, current rewards: -10.61361, mean: -0.05054
[32m[0906 14-27-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35325, current rewards: -18.16013, mean: -0.06985
[32m[0906 14-27-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35350, current rewards: -25.87720, mean: -0.08347
[32m[0906 14-27-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35367, current rewards: -22.28186, mean: -0.06189
[32m[0906 14-27-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35381, current rewards: -18.53671, mean: -0.04521
[32m[0906 14-28-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35386, current rewards: -14.77990, mean: -0.03213
[32m[0906 14-28-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35387, current rewards: -11.02670, mean: -0.02162
[32m[0906 14-28-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35399, current rewards: -7.27617, mean: -0.01299
[32m[0906 14-29-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35405, current rewards: -3.52184, mean: -0.00577
[32m[0906 14-29-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35409, current rewards: 0.22974, mean: 0.00035
[32m[0906 14-29-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35416, current rewards: 3.98008, mean: 0.00561
[32m[0906 14-29-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35441, current rewards: 8.10362, mean: 0.01066
[32m[0906 14-30-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35499, current rewards: 12.09348, mean: 0.01493
[32m[0906 14-30-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35498, current rewards: 16.08586, mean: 0.01870
[32m[0906 14-30-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35495, current rewards: 21.53793, mean: 0.02367
[32m[0906 14-31-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35488, current rewards: 27.42863, mean: 0.02857
[32m[0906 14-31-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35485, current rewards: 30.44303, mean: 0.03014
[32m[0906 14-31-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35479, current rewards: 33.45628, mean: 0.03156
[32m[0906 14-32-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35473, current rewards: 36.47092, mean: 0.03286
[32m[0906 14-32-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35471, current rewards: 39.36797, mean: 0.03394
[32m[0906 14-32-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35465, current rewards: 42.28665, mean: 0.03495
[32m[0906 14-32-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35458, current rewards: 39.91253, mean: 0.03168
[32m[0906 14-33-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35450, current rewards: 27.78909, mean: 0.02121
[32m[0906 14-33-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35446, current rewards: 31.77195, mean: 0.02336
[32m[0906 14-33-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35443, current rewards: 35.75017, mean: 0.02535
[32m[0906 14-34-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35438, current rewards: 39.72923, mean: 0.02721
[32m[0906 14-34-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35434, current rewards: 43.71108, mean: 0.02895
[32m[0906 14-34-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35432, current rewards: 51.41901, mean: 0.03296
[32m[0906 14-34-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35430, current rewards: 14.68475, mean: 0.00912
[32m[0906 14-35-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35432, current rewards: 23.73819, mean: 0.01430
[32m[0906 14-35-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35431, current rewards: 32.79162, mean: 0.01918
[32m[0906 14-35-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35430, current rewards: -5.39770, mean: -0.00307
[32m[0906 14-36-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35430, current rewards: -55.39770, mean: -0.03061
[32m[0906 14-36-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35433, current rewards: -105.39770, mean: -0.05667
[32m[0906 14-36-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35435, current rewards: -155.39770, mean: -0.08136
[32m[0906 14-37-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35435, current rewards: -205.39770, mean: -0.10479
[32m[0906 14-37-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35437, current rewards: -255.39770, mean: -0.12706
[32m[0906 14-37-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35434, current rewards: -305.39770, mean: -0.14825
[32m[0906 14-37-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35436, current rewards: -355.39770, mean: -0.16843
[32m[0906 14-38-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35437, current rewards: -405.39770, mean: -0.18768
[32m[0906 14-38-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35435, current rewards: -455.39770, mean: -0.20606
[32m[0906 14-38-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35432, current rewards: -505.39770, mean: -0.22363
[32m[0906 14-39-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35430, current rewards: -555.39770, mean: -0.24043
[32m[0906 14-39-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35434, current rewards: -605.39770, mean: -0.25652
[32m[0906 14-39-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35445, current rewards: -655.39770, mean: -0.27195
[32m[0906 14-40-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35450, current rewards: -705.39770, mean: -0.28675
[32m[0906 14-40-15 @Agent.py:117][0m Average action selection time: 0.3545
[32m[0906 14-40-15 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-40-15 @MBExp.py:227][0m Rewards obtained: [-745.3976954611098], Lows: [21], Highs: [843], Total time: 3580.9036
[32m[0906 14-40-27 @MBExp.py:144][0m ####################################################################
[32m[0906 14-40-27 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 14-40-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36103, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-40-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35967, current rewards: -96.83937, mean: -1.61399
[32m[0906 14-41-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35515, current rewards: -190.28450, mean: -1.72986
[32m[0906 14-41-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35487, current rewards: -285.91799, mean: -1.78699
[32m[0906 14-41-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35478, current rewards: -379.36450, mean: -1.80650
[32m[0906 14-41-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35427, current rewards: -474.99795, mean: -1.82692
[32m[0906 14-42-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35417, current rewards: -570.62556, mean: -1.84073
[32m[0906 14-42-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35397, current rewards: -664.18339, mean: -1.84495
[32m[0906 14-42-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35385, current rewards: -759.87928, mean: -1.85336
[32m[0906 14-43-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35371, current rewards: -855.56975, mean: -1.85993
[32m[0906 14-43-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35349, current rewards: -949.10963, mean: -1.86100
[32m[0906 14-43-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35343, current rewards: -1044.80517, mean: -1.86572
[32m[0906 14-44-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35335, current rewards: -1139.60323, mean: -1.86820
[32m[0906 14-44-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35326, current rewards: -1164.10754, mean: -1.76380
[32m[0906 14-44-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35325, current rewards: -1200.34083, mean: -1.69062
[32m[0906 14-44-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35333, current rewards: -1232.47206, mean: -1.62167
[32m[0906 14-45-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35344, current rewards: -1257.66467, mean: -1.55267
[32m[0906 14-45-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35356, current rewards: -1300.59667, mean: -1.51232
[32m[0906 14-45-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35366, current rewards: -1326.11224, mean: -1.45727
[32m[0906 14-46-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35382, current rewards: -1357.91680, mean: -1.41450
[32m[0906 14-46-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35410, current rewards: -1394.42303, mean: -1.38062
[32m[0906 14-46-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35429, current rewards: -1419.71035, mean: -1.33935
[32m[0906 14-47-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35468, current rewards: -1458.18187, mean: -1.31368
[32m[0906 14-47-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35499, current rewards: -1488.11240, mean: -1.28286
[32m[0906 14-47-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35511, current rewards: -1515.51399, mean: -1.25249
[32m[0906 14-47-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35527, current rewards: -1540.81779, mean: -1.22287
[32m[0906 14-48-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35543, current rewards: -1540.35491, mean: -1.17584
[32m[0906 14-48-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35550, current rewards: -1542.24617, mean: -1.13400
[32m[0906 14-48-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35561, current rewards: -1542.04158, mean: -1.09365
[32m[0906 14-49-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35573, current rewards: -1541.82187, mean: -1.05604
[32m[0906 14-49-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35588, current rewards: -1543.77139, mean: -1.02237
[32m[0906 14-49-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35612, current rewards: -1544.34503, mean: -0.98996
[32m[0906 14-50-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35635, current rewards: -1544.79744, mean: -0.95950
[32m[0906 14-50-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35661, current rewards: -1547.35762, mean: -0.93214
[32m[0906 14-50-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35686, current rewards: -1547.82125, mean: -0.90516
[32m[0906 14-50-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35713, current rewards: -1550.37524, mean: -0.88090
[32m[0906 14-51-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35738, current rewards: -1550.84294, mean: -0.85682
[32m[0906 14-51-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35747, current rewards: -1551.30455, mean: -0.83403
[32m[0906 14-51-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35752, current rewards: -1553.86449, mean: -0.81354
[32m[0906 14-52-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35755, current rewards: -1553.68716, mean: -0.79270
[32m[0906 14-52-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35750, current rewards: -1555.70956, mean: -0.77398
[32m[0906 14-52-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35740, current rewards: -1614.25975, mean: -0.78362
[32m[0906 14-53-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35730, current rewards: -1609.38070, mean: -0.76274
[32m[0906 14-53-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35722, current rewards: -1601.89872, mean: -0.74162
[32m[0906 14-53-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35712, current rewards: -1594.42223, mean: -0.72146
[32m[0906 14-53-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35708, current rewards: -1586.94125, mean: -0.70219
[32m[0906 14-54-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35703, current rewards: -1579.46150, mean: -0.68375
[32m[0906 14-54-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35705, current rewards: -1570.27823, mean: -0.66537
[32m[0906 14-54-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35706, current rewards: -1562.17320, mean: -0.64820
[32m[0906 14-55-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35699, current rewards: -1554.07573, mean: -0.63174
[32m[0906 14-55-19 @Agent.py:117][0m Average action selection time: 0.3568
[32m[0906 14-55-19 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-55-19 @MBExp.py:227][0m Rewards obtained: [-1547.6073500521334], Lows: [846], Highs: [63], Total time: 4473.685212
[32m[0906 14-55-32 @MBExp.py:144][0m ####################################################################
[32m[0906 14-55-32 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 14-55-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35488, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-55-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35587, current rewards: -98.00000, mean: -1.63333
[32m[0906 14-56-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35406, current rewards: -198.00000, mean: -1.80000
[32m[0906 14-56-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35523, current rewards: -298.00000, mean: -1.86250
[32m[0906 14-56-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35572, current rewards: -398.00000, mean: -1.89524
[32m[0906 14-57-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35571, current rewards: -498.00000, mean: -1.91538
[32m[0906 14-57-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35542, current rewards: -598.00000, mean: -1.92903
[32m[0906 14-57-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35699, current rewards: -698.00000, mean: -1.93889
[32m[0906 14-57-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35772, current rewards: -798.00000, mean: -1.94634
[32m[0906 14-58-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35745, current rewards: -898.00000, mean: -1.95217
[32m[0906 14-58-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35717, current rewards: -998.00000, mean: -1.95686
[32m[0906 14-58-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35694, current rewards: -1098.00000, mean: -1.96071
[32m[0906 14-59-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35678, current rewards: -1198.00000, mean: -1.96393
[32m[0906 14-59-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35678, current rewards: -1298.00000, mean: -1.96667
[32m[0906 14-59-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35689, current rewards: -1398.00000, mean: -1.96901
[32m[0906 15-00-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35690, current rewards: -1498.00000, mean: -1.97105
[32m[0906 15-00-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35711, current rewards: -1598.00000, mean: -1.97284
[32m[0906 15-00-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35736, current rewards: -1698.00000, mean: -1.97442
[32m[0906 15-00-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35754, current rewards: -1798.00000, mean: -1.97582
[32m[0906 15-01-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35783, current rewards: -1898.00000, mean: -1.97708
[32m[0906 15-01-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35792, current rewards: -1998.00000, mean: -1.97822
[32m[0906 15-01-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35784, current rewards: -2098.00000, mean: -1.97925
[32m[0906 15-02-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35772, current rewards: -2198.00000, mean: -1.98018
[32m[0906 15-02-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35761, current rewards: -2298.00000, mean: -1.98103
[32m[0906 15-02-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35754, current rewards: -2398.00000, mean: -1.98182
[32m[0906 15-03-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35742, current rewards: -2498.00000, mean: -1.98254
[32m[0906 15-03-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35732, current rewards: -2598.00000, mean: -1.98321
[32m[0906 15-03-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35720, current rewards: -2698.00000, mean: -1.98382
[32m[0906 15-03-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35728, current rewards: -2798.00000, mean: -1.98440
[32m[0906 15-04-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35761, current rewards: -2898.00000, mean: -1.98493
[32m[0906 15-04-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35786, current rewards: -2998.00000, mean: -1.98543
[32m[0906 15-04-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35814, current rewards: -3098.00000, mean: -1.98590
[32m[0906 15-05-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35838, current rewards: -3198.00000, mean: -1.98634
[32m[0906 15-05-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35850, current rewards: -3298.00000, mean: -1.98675
[32m[0906 15-05-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35841, current rewards: -3398.00000, mean: -1.98713
[32m[0906 15-06-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35839, current rewards: -3498.00000, mean: -1.98750
[32m[0906 15-06-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35843, current rewards: -3598.00000, mean: -1.98785
[32m[0906 15-06-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35833, current rewards: -3698.00000, mean: -1.98817
[32m[0906 15-06-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35824, current rewards: -3798.00000, mean: -1.98848
[32m[0906 15-07-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35819, current rewards: -3898.00000, mean: -1.98878
[32m[0906 15-07-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35815, current rewards: -3998.00000, mean: -1.98905
[32m[0906 15-07-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35815, current rewards: -4098.00000, mean: -1.98932
[32m[0906 15-08-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35810, current rewards: -4198.00000, mean: -1.98957
[32m[0906 15-08-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35809, current rewards: -4298.00000, mean: -1.98981
[32m[0906 15-08-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35815, current rewards: -4398.00000, mean: -1.99005
[32m[0906 15-09-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35821, current rewards: -4498.00000, mean: -1.99027
[32m[0906 15-09-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35809, current rewards: -4598.00000, mean: -1.99048
[32m[0906 15-09-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35813, current rewards: -4698.00000, mean: -1.99068
[32m[0906 15-09-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35811, current rewards: -4798.00000, mean: -1.99087
[32m[0906 15-10-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35809, current rewards: -4898.00000, mean: -1.99106
[32m[0906 15-10-28 @Agent.py:117][0m Average action selection time: 0.3580
[32m[0906 15-10-28 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-10-28 @MBExp.py:227][0m Rewards obtained: [-4978], Lows: [2478], Highs: [22], Total time: 5369.318394
[32m[0906 15-10-44 @MBExp.py:144][0m ####################################################################
[32m[0906 15-10-44 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 15-10-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36171, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-11-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35957, current rewards: -91.67552, mean: -1.52793
[32m[0906 15-11-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35539, current rewards: -191.67552, mean: -1.74250
[32m[0906 15-11-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35617, current rewards: -281.69198, mean: -1.76057
[32m[0906 15-11-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35673, current rewards: -342.46695, mean: -1.63079
[32m[0906 15-12-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35714, current rewards: -442.46695, mean: -1.70180
[32m[0906 15-12-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35670, current rewards: -542.46695, mean: -1.74989
[32m[0906 15-12-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35708, current rewards: -591.43004, mean: -1.64286
[32m[0906 15-13-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35746, current rewards: -585.05345, mean: -1.42696
[32m[0906 15-13-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35790, current rewards: -578.67145, mean: -1.25798
[32m[0906 15-13-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35808, current rewards: -572.28237, mean: -1.12212
[32m[0906 15-14-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35793, current rewards: -565.89432, mean: -1.01053
[32m[0906 15-14-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35784, current rewards: -561.18062, mean: -0.91997
[32m[0906 15-14-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35773, current rewards: -555.58630, mean: -0.84180
[32m[0906 15-14-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35756, current rewards: -549.97965, mean: -0.77462
[32m[0906 15-15-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35744, current rewards: -544.37002, mean: -0.71628
[32m[0906 15-15-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35752, current rewards: -570.44048, mean: -0.70425
[32m[0906 15-15-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35757, current rewards: -573.21530, mean: -0.66653
[32m[0906 15-16-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35790, current rewards: -530.95137, mean: -0.58346
[32m[0906 15-16-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35811, current rewards: -485.74020, mean: -0.50598
[32m[0906 15-16-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35830, current rewards: -510.64303, mean: -0.50559
[32m[0906 15-17-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35866, current rewards: -497.50162, mean: -0.46934
[32m[0906 15-17-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35889, current rewards: -479.34281, mean: -0.43184
[32m[0906 15-17-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35890, current rewards: -461.08214, mean: -0.39748
[32m[0906 15-17-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35889, current rewards: -442.82600, mean: -0.36597
[32m[0906 15-18-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35897, current rewards: -424.55537, mean: -0.33695
[32m[0906 15-18-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35904, current rewards: -406.33787, mean: -0.31018
[32m[0906 15-18-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35897, current rewards: -388.07043, mean: -0.28535
[32m[0906 15-19-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35886, current rewards: -373.22134, mean: -0.26470
[32m[0906 15-19-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35875, current rewards: -351.32314, mean: -0.24063
[32m[0906 15-19-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35867, current rewards: -327.18709, mean: -0.21668
[32m[0906 15-20-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35859, current rewards: -335.51555, mean: -0.21507
[32m[0906 15-20-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35852, current rewards: -328.29203, mean: -0.20391
[32m[0906 15-20-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35853, current rewards: -322.03685, mean: -0.19400
[32m[0906 15-20-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35847, current rewards: -315.75148, mean: -0.18465
[32m[0906 15-21-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35841, current rewards: -309.47518, mean: -0.17584
[32m[0906 15-21-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35834, current rewards: -298.54080, mean: -0.16494
[32m[0906 15-21-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35828, current rewards: -287.89660, mean: -0.15478
[32m[0906 15-22-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35825, current rewards: -278.51547, mean: -0.14582
[32m[0906 15-22-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35821, current rewards: -269.15169, mean: -0.13732
[32m[0906 15-22-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35814, current rewards: -259.78183, mean: -0.12924
[32m[0906 15-23-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35808, current rewards: -250.40109, mean: -0.12155
[32m[0906 15-23-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35805, current rewards: -245.78620, mean: -0.11649
[32m[0906 15-23-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35807, current rewards: -280.24117, mean: -0.12974
[32m[0906 15-23-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35803, current rewards: -265.75825, mean: -0.12025
[32m[0906 15-24-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35798, current rewards: -251.83098, mean: -0.11143
[32m[0906 15-24-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35776, current rewards: -237.92536, mean: -0.10300
[32m[0906 15-24-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35773, current rewards: -224.01135, mean: -0.09492
[32m[0906 15-25-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35773, current rewards: -210.11372, mean: -0.08718
[32m[0906 15-25-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35772, current rewards: -196.22273, mean: -0.07977
[32m[0906 15-25-38 @Agent.py:117][0m Average action selection time: 0.3576
[32m[0906 15-25-38 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-25-38 @MBExp.py:227][0m Rewards obtained: [-185.06962275898323], Lows: [343], Highs: [62], Total time: 6263.930339
[32m[0906 15-25-56 @MBExp.py:144][0m ####################################################################
[32m[0906 15-25-56 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 15-25-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35859, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-26-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35929, current rewards: -95.86459, mean: -1.59774
[32m[0906 15-26-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35594, current rewards: -190.32332, mean: -1.73021
[32m[0906 15-26-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35665, current rewards: -245.15628, mean: -1.53223
[32m[0906 15-27-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35702, current rewards: -345.15628, mean: -1.64360
[32m[0906 15-27-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35697, current rewards: -445.15628, mean: -1.71214
[32m[0906 15-27-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35583, current rewards: -545.15628, mean: -1.75857
[32m[0906 15-28-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35646, current rewards: -645.15628, mean: -1.79210
[32m[0906 15-28-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35671, current rewards: -745.15628, mean: -1.81745
[32m[0906 15-28-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35704, current rewards: -845.15628, mean: -1.83730
[32m[0906 15-28-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35702, current rewards: -945.15628, mean: -1.85325
[32m[0906 15-29-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35705, current rewards: -1023.95081, mean: -1.82848
[32m[0906 15-29-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35707, current rewards: -1102.87608, mean: -1.80799
[32m[0906 15-29-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35710, current rewards: -1202.87608, mean: -1.82254
[32m[0906 15-30-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35720, current rewards: -1302.87608, mean: -1.83504
[32m[0906 15-30-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35718, current rewards: -1402.87608, mean: -1.84589
[32m[0906 15-30-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35713, current rewards: -1502.87608, mean: -1.85540
[32m[0906 15-31-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35718, current rewards: -1602.87608, mean: -1.86381
[32m[0906 15-31-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35730, current rewards: -1702.87608, mean: -1.87129
[32m[0906 15-31-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35747, current rewards: -1802.87608, mean: -1.87800
[32m[0906 15-31-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35754, current rewards: -1902.87608, mean: -1.88404
[32m[0906 15-32-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35769, current rewards: -2002.87608, mean: -1.88951
[32m[0906 15-32-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35789, current rewards: -2102.87608, mean: -1.89448
[32m[0906 15-32-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35820, current rewards: -2202.87608, mean: -1.89903
[32m[0906 15-33-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35837, current rewards: -2302.87608, mean: -1.90320
[32m[0906 15-33-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35851, current rewards: -2402.87608, mean: -1.90704
[32m[0906 15-33-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35860, current rewards: -2502.87608, mean: -1.91059
[32m[0906 15-34-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35861, current rewards: -2571.60061, mean: -1.89088
[32m[0906 15-34-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35856, current rewards: -2656.73610, mean: -1.88421
[32m[0906 15-34-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35858, current rewards: -2753.78175, mean: -1.88615
[32m[0906 15-34-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35861, current rewards: -2822.75705, mean: -1.86938
[32m[0906 15-35-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35843, current rewards: -2894.89977, mean: -1.85570
[32m[0906 15-35-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35834, current rewards: -2973.33600, mean: -1.84679
[32m[0906 15-35-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35829, current rewards: -3057.47177, mean: -1.84185
[32m[0906 15-36-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35822, current rewards: -3141.84058, mean: -1.83733
[32m[0906 15-36-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35814, current rewards: -3218.15474, mean: -1.82850
[32m[0906 15-36-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35809, current rewards: -3318.15474, mean: -1.83323
[32m[0906 15-37-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35802, current rewards: -3356.62237, mean: -1.80464
[32m[0906 15-37-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35799, current rewards: -3456.62237, mean: -1.80975
[32m[0906 15-37-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35795, current rewards: -3556.62237, mean: -1.81460
[32m[0906 15-37-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35793, current rewards: -3656.62237, mean: -1.81922
[32m[0906 15-38-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35777, current rewards: -3756.62237, mean: -1.82360
[32m[0906 15-38-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35761, current rewards: -3856.62237, mean: -1.82778
[32m[0906 15-38-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35746, current rewards: -3956.62237, mean: -1.83177
[32m[0906 15-39-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35648, current rewards: -4056.62237, mean: -1.83558
[32m[0906 15-39-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35557, current rewards: -4136.62237, mean: -1.83036
[32m[0906 15-39-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35456, current rewards: -4236.62237, mean: -1.83404
[32m[0906 15-39-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35372, current rewards: -4336.62237, mean: -1.83755
[32m[0906 15-40-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35290, current rewards: -4436.62237, mean: -1.84092
[32m[0906 15-40-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35213, current rewards: -4536.62237, mean: -1.84416
[32m[0906 15-40-35 @Agent.py:117][0m Average action selection time: 0.3514
[32m[0906 15-40-35 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-40-35 @MBExp.py:227][0m Rewards obtained: [-4616.622374979008], Lows: [2325], Highs: [42], Total time: 7143.126477
[32m[0906 15-40-52 @MBExp.py:144][0m ####################################################################
[32m[0906 15-40-52 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 15-40-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31714, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-41-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31413, current rewards: -34.51731, mean: -0.57529
[32m[0906 15-41-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31278, current rewards: -52.78954, mean: -0.47990
[32m[0906 15-41-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31365, current rewards: -79.44070, mean: -0.49650
[32m[0906 15-41-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31398, current rewards: -106.01088, mean: -0.50481
[32m[0906 15-42-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31432, current rewards: -126.18550, mean: -0.48533
[32m[0906 15-42-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31339, current rewards: -146.35797, mean: -0.47212
[32m[0906 15-42-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31384, current rewards: -168.67658, mean: -0.46855
[32m[0906 15-43-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31402, current rewards: -195.24324, mean: -0.47620
[32m[0906 15-43-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31421, current rewards: -222.87662, mean: -0.48451
[32m[0906 15-43-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31435, current rewards: -244.11811, mean: -0.47866
[32m[0906 15-43-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31451, current rewards: -264.37370, mean: -0.47210
[32m[0906 15-44-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31477, current rewards: -306.22123, mean: -0.50200
[32m[0906 15-44-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31482, current rewards: -321.20739, mean: -0.48668
[32m[0906 15-44-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31483, current rewards: -317.38037, mean: -0.44701
[32m[0906 15-44-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31491, current rewards: -313.55739, mean: -0.41258
[32m[0906 15-45-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31490, current rewards: -309.73425, mean: -0.38239
[32m[0906 15-45-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31489, current rewards: -305.90968, mean: -0.35571
[32m[0906 15-45-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31489, current rewards: -302.08784, mean: -0.33196
[32m[0906 15-45-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31486, current rewards: -353.77051, mean: -0.36851
[32m[0906 15-46-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31492, current rewards: -415.90850, mean: -0.41179
[32m[0906 15-46-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31497, current rewards: -424.84420, mean: -0.40080
[32m[0906 15-46-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31496, current rewards: -420.85327, mean: -0.37915
[32m[0906 15-46-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31496, current rewards: -417.00760, mean: -0.35949
[32m[0906 15-47-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31499, current rewards: -413.17723, mean: -0.34147
[32m[0906 15-47-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31505, current rewards: -409.34715, mean: -0.32488
[32m[0906 15-47-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31513, current rewards: -405.51279, mean: -0.30955
[32m[0906 15-48-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31514, current rewards: -401.10320, mean: -0.29493
[32m[0906 15-48-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31513, current rewards: -396.86193, mean: -0.28146
[32m[0906 15-48-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31510, current rewards: -400.21443, mean: -0.27412
[32m[0906 15-48-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31513, current rewards: -450.21443, mean: -0.29816
[32m[0906 15-49-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31511, current rewards: -476.07985, mean: -0.30518
[32m[0906 15-49-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31511, current rewards: -501.95169, mean: -0.31177
[32m[0906 15-49-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31512, current rewards: -529.91827, mean: -0.31923
[32m[0906 15-49-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31510, current rewards: -556.83595, mean: -0.32564
[32m[0906 15-50-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31509, current rewards: -567.73811, mean: -0.32258
[32m[0906 15-50-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31520, current rewards: -564.13562, mean: -0.31168
[32m[0906 15-50-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31519, current rewards: -560.58487, mean: -0.30139
[32m[0906 15-50-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31519, current rewards: -557.03486, mean: -0.29164
[32m[0906 15-51-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31518, current rewards: -553.48493, mean: -0.28239
[32m[0906 15-51-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31517, current rewards: -549.93516, mean: -0.27360
[32m[0906 15-51-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31516, current rewards: -546.38572, mean: -0.26524
[32m[0906 15-51-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31514, current rewards: -542.83519, mean: -0.25727
[32m[0906 15-52-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31514, current rewards: -539.10958, mean: -0.24959
[32m[0906 15-52-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31513, current rewards: -529.69060, mean: -0.23968
[32m[0906 15-52-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31514, current rewards: -524.44351, mean: -0.23205
[32m[0906 15-53-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31501, current rewards: -520.11161, mean: -0.22516
[32m[0906 15-53-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31493, current rewards: -516.93303, mean: -0.21904
[32m[0906 15-53-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31496, current rewards: -513.62441, mean: -0.21312
[32m[0906 15-53-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31499, current rewards: -510.31378, mean: -0.20744
[32m[0906 15-54-00 @Agent.py:117][0m Average action selection time: 0.3149
[32m[0906 15-54-00 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-54-00 @MBExp.py:227][0m Rewards obtained: [-507.6662124557277], Lows: [91], Highs: [480], Total time: 7930.9909099999995
[32m[0906 15-54-19 @MBExp.py:144][0m ####################################################################
[32m[0906 15-54-19 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 15-54-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31789, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-54-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31530, current rewards: -17.67737, mean: -0.29462
[32m[0906 15-54-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31192, current rewards: -25.13768, mean: -0.22852
[32m[0906 15-55-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31319, current rewards: -21.10936, mean: -0.13193
[32m[0906 15-55-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31335, current rewards: -17.24520, mean: -0.08212
[32m[0906 15-55-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31372, current rewards: -13.38539, mean: -0.05148
[32m[0906 15-55-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31308, current rewards: -9.52620, mean: -0.03073
[32m[0906 15-56-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31319, current rewards: -5.66555, mean: -0.01574
[32m[0906 15-56-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31359, current rewards: -1.80782, mean: -0.00441
[32m[0906 15-56-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31401, current rewards: 2.05420, mean: 0.00447
[32m[0906 15-57-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31427, current rewards: 6.45337, mean: 0.01265
[32m[0906 15-57-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31456, current rewards: 12.33660, mean: 0.02203
[32m[0906 15-57-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31464, current rewards: 15.63810, mean: 0.02564
[32m[0906 15-57-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31481, current rewards: 16.80619, mean: 0.02546
[32m[0906 15-58-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31492, current rewards: 1.91152, mean: 0.00269
[32m[0906 15-58-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31512, current rewards: 4.75545, mean: 0.00626
[32m[0906 15-58-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31510, current rewards: 7.54742, mean: 0.00932
[32m[0906 15-58-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31507, current rewards: 10.34085, mean: 0.01202
[32m[0906 15-59-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31507, current rewards: 13.13520, mean: 0.01443
[32m[0906 15-59-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31504, current rewards: -5.84384, mean: -0.00609
[32m[0906 15-59-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31501, current rewards: -1.86687, mean: -0.00185
[32m[0906 15-59-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31501, current rewards: 1.90330, mean: 0.00180
[32m[0906 16-00-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31498, current rewards: -34.41050, mean: -0.03100
[32m[0906 16-00-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31498, current rewards: -29.70662, mean: -0.02561
[32m[0906 16-00-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31494, current rewards: -24.99340, mean: -0.02066
[32m[0906 16-00-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31490, current rewards: -20.28077, mean: -0.01610
[32m[0906 16-01-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31488, current rewards: -15.56838, mean: -0.01188
[32m[0906 16-01-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31487, current rewards: -9.99924, mean: -0.00735
[32m[0906 16-01-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31483, current rewards: -7.78206, mean: -0.00552
[32m[0906 16-01-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31480, current rewards: -2.73185, mean: -0.00187
[32m[0906 16-02-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31487, current rewards: -14.19912, mean: -0.00940
[32m[0906 16-02-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31486, current rewards: -13.50974, mean: -0.00866
[32m[0906 16-02-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31484, current rewards: -7.80758, mean: -0.00485
[32m[0906 16-03-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31481, current rewards: -2.08758, mean: -0.00126
[32m[0906 16-03-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31481, current rewards: 3.61426, mean: 0.00211
[32m[0906 16-03-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31477, current rewards: 9.31999, mean: 0.00530
[32m[0906 16-03-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31475, current rewards: 17.27936, mean: 0.00955
[32m[0906 16-04-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31473, current rewards: 24.01490, mean: 0.01291
[32m[0906 16-04-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31469, current rewards: 13.60370, mean: 0.00712
[32m[0906 16-04-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31466, current rewards: -4.69357, mean: -0.00239
[32m[0906 16-04-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31465, current rewards: -0.02148, mean: -0.00001
[32m[0906 16-05-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31463, current rewards: 4.64981, mean: 0.00226
[32m[0906 16-05-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31462, current rewards: 9.32202, mean: 0.00442
[32m[0906 16-05-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31465, current rewards: 13.99467, mean: 0.00648
[32m[0906 16-05-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31463, current rewards: 18.66655, mean: 0.00845
[32m[0906 16-06-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31460, current rewards: -14.34210, mean: -0.00635
[32m[0906 16-06-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31450, current rewards: -59.57658, mean: -0.02579
[32m[0906 16-06-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31438, current rewards: -60.47642, mean: -0.02563
[32m[0906 16-06-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31439, current rewards: -52.82133, mean: -0.02192
[32m[0906 16-07-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31440, current rewards: -45.16624, mean: -0.01836
[32m[0906 16-07-26 @Agent.py:117][0m Average action selection time: 0.3143
[32m[0906 16-07-26 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-07-26 @MBExp.py:227][0m Rewards obtained: [-39.04217418763361], Lows: [92], Highs: [92], Total time: 8717.396115
[32m[0906 16-07-47 @MBExp.py:144][0m ####################################################################
[32m[0906 16-07-47 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 16-07-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31729, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-08-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31327, current rewards: -54.06973, mean: -0.90116
[32m[0906 16-08-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31124, current rewards: -48.48958, mean: -0.44081
[32m[0906 16-08-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31283, current rewards: -43.25564, mean: -0.27035
[32m[0906 16-08-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31428, current rewards: -40.06415, mean: -0.19078
[32m[0906 16-09-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31460, current rewards: -37.50684, mean: -0.14426
[32m[0906 16-09-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31377, current rewards: -34.94737, mean: -0.11273
[32m[0906 16-09-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31352, current rewards: -37.64349, mean: -0.10457
[32m[0906 16-09-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31387, current rewards: -121.64349, mean: -0.29669
[32m[0906 16-10-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31408, current rewards: -221.64349, mean: -0.48183
[32m[0906 16-10-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31430, current rewards: -321.64349, mean: -0.63067
[32m[0906 16-10-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31443, current rewards: -421.64349, mean: -0.75293
[32m[0906 16-10-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31460, current rewards: -521.64349, mean: -0.85515
[32m[0906 16-11-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31469, current rewards: -621.64349, mean: -0.94188
[32m[0906 16-11-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31495, current rewards: -721.64349, mean: -1.01640
[32m[0906 16-11-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31496, current rewards: -821.64349, mean: -1.08111
[32m[0906 16-12-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31498, current rewards: -921.64349, mean: -1.13783
[32m[0906 16-12-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31502, current rewards: -1021.64349, mean: -1.18796
[32m[0906 16-12-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31503, current rewards: -1121.64349, mean: -1.23258
[32m[0906 16-12-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31506, current rewards: -1221.64349, mean: -1.27255
[32m[0906 16-13-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31506, current rewards: -1321.64349, mean: -1.30856
[32m[0906 16-13-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31504, current rewards: -1421.64349, mean: -1.34117
[32m[0906 16-13-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31501, current rewards: -1521.64349, mean: -1.37085
[32m[0906 16-13-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31504, current rewards: -1621.64349, mean: -1.39797
[32m[0906 16-14-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31504, current rewards: -1721.64349, mean: -1.42285
[32m[0906 16-14-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31502, current rewards: -1821.64349, mean: -1.44575
[32m[0906 16-14-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31500, current rewards: -1921.64349, mean: -1.46690
[32m[0906 16-14-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31497, current rewards: -2021.64349, mean: -1.48650
[32m[0906 16-15-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31495, current rewards: -2121.64349, mean: -1.50471
[32m[0906 16-15-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31489, current rewards: -2221.64349, mean: -1.52167
[32m[0906 16-15-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31491, current rewards: -2321.64349, mean: -1.53751
[32m[0906 16-15-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31496, current rewards: -2421.64349, mean: -1.55234
[32m[0906 16-16-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31493, current rewards: -2521.64349, mean: -1.56624
[32m[0906 16-16-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31489, current rewards: -2621.64349, mean: -1.57930
[32m[0906 16-16-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31487, current rewards: -2721.64349, mean: -1.59160
[32m[0906 16-17-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31486, current rewards: -2821.64349, mean: -1.60321
[32m[0906 16-17-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31485, current rewards: -2921.64349, mean: -1.61417
[32m[0906 16-17-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31482, current rewards: -3021.64349, mean: -1.62454
[32m[0906 16-17-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31482, current rewards: -3121.64349, mean: -1.63437
[32m[0906 16-18-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31479, current rewards: -3221.64349, mean: -1.64370
[32m[0906 16-18-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31478, current rewards: -3321.64349, mean: -1.65256
[32m[0906 16-18-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31481, current rewards: -3421.64349, mean: -1.66099
[32m[0906 16-18-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31481, current rewards: -3521.64349, mean: -1.66903
[32m[0906 16-19-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31482, current rewards: -3621.64349, mean: -1.67669
[32m[0906 16-19-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31481, current rewards: -3721.64349, mean: -1.68400
[32m[0906 16-19-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31483, current rewards: -3821.64349, mean: -1.69099
[32m[0906 16-19-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31474, current rewards: -3921.64349, mean: -1.69768
[32m[0906 16-20-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31461, current rewards: -4021.64349, mean: -1.70409
[32m[0906 16-20-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31461, current rewards: -4121.64349, mean: -1.71023
[32m[0906 16-20-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31464, current rewards: -4221.64349, mean: -1.71612
[32m[0906 16-20-53 @Agent.py:117][0m Average action selection time: 0.3146
[32m[0906 16-20-53 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-20-54 @MBExp.py:227][0m Rewards obtained: [-4301.643487636433], Lows: [2143], Highs: [41], Total time: 9504.400905999999
[32m[0906 16-21-16 @MBExp.py:144][0m ####################################################################
[32m[0906 16-21-16 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 16-21-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31692, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-21-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31391, current rewards: -13.36071, mean: -0.22268
[32m[0906 16-21-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31168, current rewards: -85.27546, mean: -0.77523
[32m[0906 16-22-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31289, current rewards: -144.08962, mean: -0.90056
[32m[0906 16-22-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31376, current rewards: -241.09474, mean: -1.14807
[32m[0906 16-22-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31411, current rewards: -302.70136, mean: -1.16424
[32m[0906 16-22-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31350, current rewards: -375.84789, mean: -1.21241
[32m[0906 16-23-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31329, current rewards: -449.34630, mean: -1.24818
[32m[0906 16-23-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31359, current rewards: -507.97868, mean: -1.23897
[32m[0906 16-23-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31378, current rewards: -605.09877, mean: -1.31543
[32m[0906 16-23-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31418, current rewards: -664.29342, mean: -1.30254
[32m[0906 16-24-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31435, current rewards: -649.60488, mean: -1.16001
[32m[0906 16-24-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31439, current rewards: -739.30703, mean: -1.21198
[32m[0906 16-24-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31443, current rewards: -839.30703, mean: -1.27168
[32m[0906 16-25-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31445, current rewards: -939.30703, mean: -1.32297
[32m[0906 16-25-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31454, current rewards: -1039.30703, mean: -1.36751
[32m[0906 16-25-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31463, current rewards: -1139.30703, mean: -1.40655
[32m[0906 16-25-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31459, current rewards: -1239.30703, mean: -1.44105
[32m[0906 16-26-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31452, current rewards: -1339.30703, mean: -1.47177
[32m[0906 16-26-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31452, current rewards: -1439.30703, mean: -1.49928
[32m[0906 16-26-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31448, current rewards: -1539.30703, mean: -1.52407
[32m[0906 16-26-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31457, current rewards: -1639.30703, mean: -1.54652
[32m[0906 16-27-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31459, current rewards: -1739.30703, mean: -1.56694
[32m[0906 16-27-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31453, current rewards: -1839.30703, mean: -1.58561
[32m[0906 16-27-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31448, current rewards: -1939.30703, mean: -1.60273
[32m[0906 16-27-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31444, current rewards: -2039.30703, mean: -1.61850
[32m[0906 16-28-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31443, current rewards: -2088.32669, mean: -1.59414
[32m[0906 16-28-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31441, current rewards: -2147.26206, mean: -1.57887
[32m[0906 16-28-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31439, current rewards: -2215.35824, mean: -1.57118
[32m[0906 16-28-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31440, current rewards: -2274.97482, mean: -1.55820
[32m[0906 16-29-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31438, current rewards: -2346.06802, mean: -1.55369
[32m[0906 16-29-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31435, current rewards: -2408.74150, mean: -1.54407
[32m[0906 16-29-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31431, current rewards: -2476.99090, mean: -1.53850
[32m[0906 16-29-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31429, current rewards: -2553.76098, mean: -1.53841
[32m[0906 16-30-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31425, current rewards: -2642.39290, mean: -1.54526
[32m[0906 16-30-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31420, current rewards: -2742.39290, mean: -1.55818
[32m[0906 16-30-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31416, current rewards: -2842.39290, mean: -1.57038
[32m[0906 16-31-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31412, current rewards: -2942.39290, mean: -1.58193
[32m[0906 16-31-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31409, current rewards: -3042.39290, mean: -1.59288
[32m[0906 16-31-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31408, current rewards: -3118.68212, mean: -1.59116
[32m[0906 16-31-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31411, current rewards: -3199.28918, mean: -1.59169
[32m[0906 16-32-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31408, current rewards: -3299.28918, mean: -1.60160
[32m[0906 16-32-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31410, current rewards: -3399.28918, mean: -1.61104
[32m[0906 16-32-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31410, current rewards: -3499.28918, mean: -1.62004
[32m[0906 16-32-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31409, current rewards: -3599.28918, mean: -1.62864
[32m[0906 16-33-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31408, current rewards: -3699.28918, mean: -1.63685
[32m[0906 16-33-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31399, current rewards: -3799.28918, mean: -1.64471
[32m[0906 16-33-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31386, current rewards: -3899.28918, mean: -1.65224
[32m[0906 16-33-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31389, current rewards: -3999.28918, mean: -1.65946
[32m[0906 16-34-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31391, current rewards: -4099.28918, mean: -1.66638
[32m[0906 16-34-21 @Agent.py:117][0m Average action selection time: 0.3139
[32m[0906 16-34-21 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-34-22 @MBExp.py:227][0m Rewards obtained: [-4179.289176472756], Lows: [2170], Highs: [41], Total time: 10289.723676999998
[32m[0906 16-34-46 @MBExp.py:144][0m ####################################################################
[32m[0906 16-34-46 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 16-34-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31766, current rewards: 0.86228, mean: 0.08623
[32m[0906 16-35-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31441, current rewards: 4.65250, mean: 0.07754
[32m[0906 16-35-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31197, current rewards: 9.34675, mean: 0.08497
[32m[0906 16-35-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31303, current rewards: 14.04363, mean: 0.08777
[32m[0906 16-35-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31387, current rewards: 18.73851, mean: 0.08923
[32m[0906 16-36-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31416, current rewards: 23.43584, mean: 0.09014
[32m[0906 16-36-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31357, current rewards: 28.13510, mean: 0.09076
[32m[0906 16-36-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31303, current rewards: 32.82894, mean: 0.09119
[32m[0906 16-36-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31339, current rewards: 37.52725, mean: 0.09153
[32m[0906 16-37-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31376, current rewards: 27.95893, mean: 0.06078
[32m[0906 16-37-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31397, current rewards: -22.04107, mean: -0.04322
[32m[0906 16-37-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31428, current rewards: -72.04107, mean: -0.12864
[32m[0906 16-37-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31448, current rewards: -122.04107, mean: -0.20007
[32m[0906 16-38-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31447, current rewards: -172.04107, mean: -0.26067
[32m[0906 16-38-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31455, current rewards: -222.04107, mean: -0.31273
[32m[0906 16-38-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31462, current rewards: -272.04107, mean: -0.35795
[32m[0906 16-39-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31462, current rewards: -322.04107, mean: -0.39758
[32m[0906 16-39-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31466, current rewards: -372.04107, mean: -0.43261
[32m[0906 16-39-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31465, current rewards: -422.04107, mean: -0.46378
[32m[0906 16-39-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31470, current rewards: -472.04107, mean: -0.49171
[32m[0906 16-40-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31472, current rewards: -522.04107, mean: -0.51687
[32m[0906 16-40-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31475, current rewards: -572.04107, mean: -0.53966
[32m[0906 16-40-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31478, current rewards: -622.04107, mean: -0.56040
[32m[0906 16-40-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31474, current rewards: -672.04107, mean: -0.57935
[32m[0906 16-41-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31480, current rewards: -722.04107, mean: -0.59673
[32m[0906 16-41-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31479, current rewards: -772.04107, mean: -0.61273
[32m[0906 16-41-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31480, current rewards: -822.04107, mean: -0.62751
[32m[0906 16-41-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31484, current rewards: -872.04107, mean: -0.64121
[32m[0906 16-42-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31487, current rewards: -922.04107, mean: -0.65393
[32m[0906 16-42-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31486, current rewards: -972.04107, mean: -0.66578
[32m[0906 16-42-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31482, current rewards: -1022.04107, mean: -0.67685
[32m[0906 16-42-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31478, current rewards: -1072.04107, mean: -0.68721
[32m[0906 16-43-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31475, current rewards: -1122.04107, mean: -0.69692
[32m[0906 16-43-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31475, current rewards: -1172.04107, mean: -0.70605
[32m[0906 16-43-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31474, current rewards: -1222.04107, mean: -0.71464
[32m[0906 16-44-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31473, current rewards: -1272.04107, mean: -0.72275
[32m[0906 16-44-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31469, current rewards: -1322.04107, mean: -0.73041
[32m[0906 16-44-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31465, current rewards: -1372.04107, mean: -0.73766
[32m[0906 16-44-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31463, current rewards: -1422.04107, mean: -0.74452
[32m[0906 16-45-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31461, current rewards: -1472.04107, mean: -0.75104
[32m[0906 16-45-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31462, current rewards: -1522.04107, mean: -0.75723
[32m[0906 16-45-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31459, current rewards: -1572.04107, mean: -0.76313
[32m[0906 16-45-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31458, current rewards: -1622.04107, mean: -0.76874
[32m[0906 16-46-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31457, current rewards: -1672.04107, mean: -0.77409
[32m[0906 16-46-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31457, current rewards: -1722.04107, mean: -0.77920
[32m[0906 16-46-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31457, current rewards: -1772.04107, mean: -0.78409
[32m[0906 16-46-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31452, current rewards: -1822.04107, mean: -0.78876
[32m[0906 16-47-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31438, current rewards: -1872.04107, mean: -0.79324
[32m[0906 16-47-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31435, current rewards: -1922.04107, mean: -0.79753
[32m[0906 16-47-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31436, current rewards: -1972.04107, mean: -0.80164
[32m[0906 16-47-52 @Agent.py:117][0m Average action selection time: 0.3143
[32m[0906 16-47-52 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-47-52 @MBExp.py:227][0m Rewards obtained: [-2012.0410692837445], Lows: [9], Highs: [2041], Total time: 11076.148338999998
[32m[0906 16-48-19 @MBExp.py:144][0m ####################################################################
[32m[0906 16-48-19 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 16-48-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31757, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-48-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31254, current rewards: -30.05165, mean: -0.50086
[32m[0906 16-48-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31082, current rewards: -29.66304, mean: -0.26966
[32m[0906 16-49-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31236, current rewards: -26.39025, mean: -0.16494
[32m[0906 16-49-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31357, current rewards: -23.07627, mean: -0.10989
[32m[0906 16-49-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31407, current rewards: -19.77524, mean: -0.07606
[32m[0906 16-49-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31363, current rewards: -16.47319, mean: -0.05314
[32m[0906 16-50-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31300, current rewards: -13.16979, mean: -0.03658
[32m[0906 16-50-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31342, current rewards: -9.86821, mean: -0.02407
[32m[0906 16-50-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31366, current rewards: -6.50683, mean: -0.01415
[32m[0906 16-50-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31384, current rewards: -2.91330, mean: -0.00571
[32m[0906 16-51-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31407, current rewards: 0.54799, mean: 0.00098
[32m[0906 16-51-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31427, current rewards: 4.02039, mean: 0.00659
[32m[0906 16-51-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31438, current rewards: 7.49184, mean: 0.01135
[32m[0906 16-52-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31449, current rewards: -23.06288, mean: -0.03248
[32m[0906 16-52-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31454, current rewards: -27.46978, mean: -0.03614
[32m[0906 16-52-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31461, current rewards: -34.50238, mean: -0.04260
[32m[0906 16-52-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31458, current rewards: -47.91628, mean: -0.05572
[32m[0906 16-53-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31456, current rewards: -58.98237, mean: -0.06482
[32m[0906 16-53-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31454, current rewards: -67.30425, mean: -0.07011
[32m[0906 16-53-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31453, current rewards: -74.10708, mean: -0.07337
[32m[0906 16-53-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31452, current rewards: -81.28749, mean: -0.07669
[32m[0906 16-54-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31453, current rewards: -88.25996, mean: -0.07951
[32m[0906 16-54-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31452, current rewards: -95.13319, mean: -0.08201
[32m[0906 16-54-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31452, current rewards: -102.09063, mean: -0.08437
[32m[0906 16-54-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31453, current rewards: -108.95749, mean: -0.08647
[32m[0906 16-55-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31447, current rewards: -115.82673, mean: -0.08842
[32m[0906 16-55-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31446, current rewards: -111.36904, mean: -0.08189
[32m[0906 16-55-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31442, current rewards: -131.75400, mean: -0.09344
[32m[0906 16-55-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31440, current rewards: -142.22833, mean: -0.09742
[32m[0906 16-56-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31439, current rewards: -149.49333, mean: -0.09900
[32m[0906 16-56-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31438, current rewards: -161.06881, mean: -0.10325
[32m[0906 16-56-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31437, current rewards: -169.44081, mean: -0.10524
[32m[0906 16-57-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31435, current rewards: -178.87560, mean: -0.10776
[32m[0906 16-57-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31432, current rewards: -179.12722, mean: -0.10475
[32m[0906 16-57-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31430, current rewards: -211.48575, mean: -0.12016
[32m[0906 16-57-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31426, current rewards: -311.48575, mean: -0.17209
[32m[0906 16-58-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31423, current rewards: -411.48575, mean: -0.22123
[32m[0906 16-58-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31420, current rewards: -511.48575, mean: -0.26779
[32m[0906 16-58-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31420, current rewards: -611.48575, mean: -0.31198
[32m[0906 16-58-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31421, current rewards: -711.48575, mean: -0.35397
[32m[0906 16-59-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31420, current rewards: -811.48575, mean: -0.39393
[32m[0906 16-59-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31418, current rewards: -911.48575, mean: -0.43198
[32m[0906 16-59-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31415, current rewards: -1011.48575, mean: -0.46828
[32m[0906 16-59-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31414, current rewards: -1111.48575, mean: -0.50293
[32m[0906 17-00-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31414, current rewards: -1211.48575, mean: -0.53606
[32m[0906 17-00-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31411, current rewards: -1311.48575, mean: -0.56774
[32m[0906 17-00-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31396, current rewards: -1411.48575, mean: -0.59809
[32m[0906 17-00-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31390, current rewards: -1511.48575, mean: -0.62717
[32m[0906 17-01-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31396, current rewards: -1611.48575, mean: -0.65508
[32m[0906 17-01-24 @Agent.py:117][0m Average action selection time: 0.3139
[32m[0906 17-01-24 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-01-24 @MBExp.py:227][0m Rewards obtained: [-1691.485745926206], Lows: [814], Highs: [188], Total time: 11861.570638999998
[32m[0906 17-01-52 @MBExp.py:144][0m ####################################################################
[32m[0906 17-01-52 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 17-01-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31699, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-02-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31243, current rewards: -18.10066, mean: -0.30168
[32m[0906 17-02-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31046, current rewards: -14.42774, mean: -0.13116
[32m[0906 17-02-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31205, current rewards: -10.75447, mean: -0.06722
[32m[0906 17-02-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31268, current rewards: -7.08313, mean: -0.03373
[32m[0906 17-03-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31330, current rewards: -3.40962, mean: -0.01311
[32m[0906 17-03-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31306, current rewards: 0.26152, mean: 0.00084
[32m[0906 17-03-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31239, current rewards: 3.93570, mean: 0.01093
[32m[0906 17-04-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31277, current rewards: 7.79626, mean: 0.01902
[32m[0906 17-04-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31316, current rewards: 12.70642, mean: 0.02762
[32m[0906 17-04-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31337, current rewards: -4.90249, mean: -0.00961
[32m[0906 17-04-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31364, current rewards: -1.30239, mean: -0.00233
[32m[0906 17-05-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31372, current rewards: 2.73525, mean: 0.00448
[32m[0906 17-05-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31383, current rewards: 6.76949, mean: 0.01026
[32m[0906 17-05-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31391, current rewards: 10.80676, mean: 0.01522
[32m[0906 17-05-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31390, current rewards: 14.84074, mean: 0.01953
[32m[0906 17-06-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31396, current rewards: 18.87275, mean: 0.02330
[32m[0906 17-06-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31404, current rewards: 21.94427, mean: 0.02552
[32m[0906 17-06-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31409, current rewards: -15.95792, mean: -0.01754
[32m[0906 17-06-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31413, current rewards: -9.86977, mean: -0.01028
[32m[0906 17-07-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31413, current rewards: -4.14896, mean: -0.00411
[32m[0906 17-07-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31417, current rewards: 1.55137, mean: 0.00146
[32m[0906 17-07-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31419, current rewards: 7.25159, mean: 0.00653
[32m[0906 17-07-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31419, current rewards: 12.95330, mean: 0.01117
[32m[0906 17-08-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31417, current rewards: 11.96910, mean: 0.00989
[32m[0906 17-08-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31417, current rewards: 1.65643, mean: 0.00131
[32m[0906 17-08-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31419, current rewards: 5.61118, mean: 0.00428
[32m[0906 17-09-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31420, current rewards: 9.52662, mean: 0.00700
[32m[0906 17-09-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31418, current rewards: 13.44305, mean: 0.00953
[32m[0906 17-09-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31417, current rewards: 17.35791, mean: 0.01189
[32m[0906 17-09-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31416, current rewards: 21.27353, mean: 0.01409
[32m[0906 17-10-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31418, current rewards: 25.82061, mean: 0.01655
[32m[0906 17-10-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31417, current rewards: 37.34069, mean: 0.02319
[32m[0906 17-10-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31418, current rewards: 41.97910, mean: 0.02529
[32m[0906 17-10-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31418, current rewards: 45.90123, mean: 0.02684
[32m[0906 17-11-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31415, current rewards: 50.63478, mean: 0.02877
[32m[0906 17-11-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31409, current rewards: 14.11684, mean: 0.00780
[32m[0906 17-11-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31404, current rewards: 19.99310, mean: 0.01075
[32m[0906 17-11-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31401, current rewards: 25.92613, mean: 0.01357
[32m[0906 17-12-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31403, current rewards: 31.85640, mean: 0.01625
[32m[0906 17-12-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31401, current rewards: 37.78658, mean: 0.01880
[32m[0906 17-12-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31400, current rewards: 24.70562, mean: 0.01199
[32m[0906 17-12-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31397, current rewards: 24.67326, mean: 0.01169
[32m[0906 17-13-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31395, current rewards: 28.50721, mean: 0.01320
[32m[0906 17-13-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31395, current rewards: 32.34186, mean: 0.01463
[32m[0906 17-13-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31394, current rewards: 36.17648, mean: 0.01601
[32m[0906 17-13-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31390, current rewards: -0.83655, mean: -0.00036
[32m[0906 17-14-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31376, current rewards: 3.05984, mean: 0.00130
[32m[0906 17-14-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31366, current rewards: 6.84404, mean: 0.00284
[32m[0906 17-14-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31369, current rewards: 10.62733, mean: 0.00432
[32m[0906 17-14-57 @Agent.py:117][0m Average action selection time: 0.3137
[32m[0906 17-14-57 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-14-57 @MBExp.py:227][0m Rewards obtained: [13.854381959996816], Lows: [61], Highs: [82], Total time: 12646.409846999997
[32m[0906 17-15-27 @MBExp.py:144][0m ####################################################################
[32m[0906 17-15-27 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 17-15-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31680, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-15-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31194, current rewards: -16.42828, mean: -0.27380
[32m[0906 17-16-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31004, current rewards: -10.43491, mean: -0.09486
[32m[0906 17-16-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31147, current rewards: -4.43621, mean: -0.02773
[32m[0906 17-16-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31251, current rewards: 1.55588, mean: 0.00741
[32m[0906 17-16-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31312, current rewards: 7.55779, mean: 0.02907
[32m[0906 17-17-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31283, current rewards: 13.55680, mean: 0.04373
[32m[0906 17-17-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31224, current rewards: 19.54585, mean: 0.05429
[32m[0906 17-17-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31254, current rewards: 2.27044, mean: 0.00554
[32m[0906 17-17-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31288, current rewards: 6.04400, mean: 0.01314
[32m[0906 17-18-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31318, current rewards: 9.93703, mean: 0.01948
[32m[0906 17-18-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31340, current rewards: 13.82425, mean: 0.02469
[32m[0906 17-18-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31358, current rewards: 17.71318, mean: 0.02904
[32m[0906 17-18-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31372, current rewards: 21.60179, mean: 0.03273
[32m[0906 17-19-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31390, current rewards: 25.49054, mean: 0.03590
[32m[0906 17-19-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31402, current rewards: 29.37985, mean: 0.03866
[32m[0906 17-19-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31412, current rewards: 33.27599, mean: 0.04108
[32m[0906 17-19-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31421, current rewards: 42.19340, mean: 0.04906
[32m[0906 17-20-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31427, current rewards: 47.58813, mean: 0.05229
[32m[0906 17-20-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31432, current rewards: 52.97136, mean: 0.05518
[32m[0906 17-20-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31432, current rewards: 57.08818, mean: 0.05652
[32m[0906 17-21-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31437, current rewards: 62.17200, mean: 0.05865
[32m[0906 17-21-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31435, current rewards: 67.22533, mean: 0.06056
[32m[0906 17-21-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31435, current rewards: 72.28396, mean: 0.06231
[32m[0906 17-21-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31435, current rewards: 77.33843, mean: 0.06392
[32m[0906 17-22-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31436, current rewards: 81.97656, mean: 0.06506
[32m[0906 17-22-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31437, current rewards: 86.74810, mean: 0.06622
[32m[0906 17-22-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31440, current rewards: 91.50216, mean: 0.06728
[32m[0906 17-22-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31441, current rewards: 96.25290, mean: 0.06826
[32m[0906 17-23-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31439, current rewards: 101.00767, mean: 0.06918
[32m[0906 17-23-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31440, current rewards: 105.75759, mean: 0.07004
[32m[0906 17-23-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31436, current rewards: 88.35130, mean: 0.05664
[32m[0906 17-23-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31435, current rewards: 92.43600, mean: 0.05741
[32m[0906 17-24-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31433, current rewards: 96.20386, mean: 0.05795
[32m[0906 17-24-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31433, current rewards: 99.90832, mean: 0.05843
[32m[0906 17-24-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31430, current rewards: 103.70825, mean: 0.05893
[32m[0906 17-24-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31430, current rewards: 107.50390, mean: 0.05939
[32m[0906 17-25-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31429, current rewards: 111.30154, mean: 0.05984
[32m[0906 17-25-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31426, current rewards: 115.09850, mean: 0.06026
[32m[0906 17-25-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31425, current rewards: 118.89230, mean: 0.06066
[32m[0906 17-25-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31425, current rewards: 122.68984, mean: 0.06104
[32m[0906 17-26-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31424, current rewards: 126.58479, mean: 0.06145
[32m[0906 17-26-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31421, current rewards: 136.95451, mean: 0.06491
[32m[0906 17-26-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31421, current rewards: 141.70478, mean: 0.06560
[32m[0906 17-27-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31422, current rewards: 146.56458, mean: 0.06632
[32m[0906 17-27-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31422, current rewards: 151.42578, mean: 0.06700
[32m[0906 17-27-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31421, current rewards: 156.28757, mean: 0.06766
[32m[0906 17-27-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31406, current rewards: 161.14860, mean: 0.06828
[32m[0906 17-28-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31392, current rewards: 166.01020, mean: 0.06888
[32m[0906 17-28-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31396, current rewards: 170.87206, mean: 0.06946
[32m[0906 17-28-32 @Agent.py:117][0m Average action selection time: 0.3139
[32m[0906 17-28-32 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-28-32 @MBExp.py:227][0m Rewards obtained: [166.37561738527552], Lows: [0], Highs: [67], Total time: 13431.890308999997
[32m[0906 17-29-04 @MBExp.py:144][0m ####################################################################
[32m[0906 17-29-04 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 17-29-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31567, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-29-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31076, current rewards: -19.59796, mean: -0.32663
[32m[0906 17-29-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30986, current rewards: -16.81477, mean: -0.15286
[32m[0906 17-29-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31133, current rewards: -14.06844, mean: -0.08793
[32m[0906 17-30-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31216, current rewards: -11.32649, mean: -0.05394
[32m[0906 17-30-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31269, current rewards: -8.58394, mean: -0.03302
[32m[0906 17-30-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31230, current rewards: -5.84211, mean: -0.01885
[32m[0906 17-30-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31178, current rewards: -3.10053, mean: -0.00861
[32m[0906 17-31-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31200, current rewards: -0.08490, mean: -0.00021
[32m[0906 17-31-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31242, current rewards: 3.71742, mean: 0.00808
[32m[0906 17-31-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31283, current rewards: 6.83550, mean: 0.01340
[32m[0906 17-32-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31309, current rewards: 9.95357, mean: 0.01777
[32m[0906 17-32-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31326, current rewards: 13.07164, mean: 0.02143
[32m[0906 17-32-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31345, current rewards: 16.18972, mean: 0.02453
[32m[0906 17-32-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31357, current rewards: 13.99598, mean: 0.01971
[32m[0906 17-33-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31365, current rewards: -36.00402, mean: -0.04737
[32m[0906 17-33-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31368, current rewards: -86.00402, mean: -0.10618
[32m[0906 17-33-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31379, current rewards: -136.00402, mean: -0.15814
[32m[0906 17-33-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31384, current rewards: -186.00402, mean: -0.20440
[32m[0906 17-34-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31385, current rewards: -236.00402, mean: -0.24584
[32m[0906 17-34-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31388, current rewards: -286.00402, mean: -0.28317
[32m[0906 17-34-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31392, current rewards: -336.00402, mean: -0.31698
[32m[0906 17-34-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31394, current rewards: -386.00402, mean: -0.34775
[32m[0906 17-35-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31397, current rewards: -436.00402, mean: -0.37587
[32m[0906 17-35-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31398, current rewards: -486.00402, mean: -0.40166
[32m[0906 17-35-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31397, current rewards: -536.00402, mean: -0.42540
[32m[0906 17-35-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31398, current rewards: -586.00402, mean: -0.44733
[32m[0906 17-36-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31398, current rewards: -636.00402, mean: -0.46765
[32m[0906 17-36-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31397, current rewards: -686.00402, mean: -0.48653
[32m[0906 17-36-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31395, current rewards: -736.00402, mean: -0.50411
[32m[0906 17-36-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31400, current rewards: -786.00402, mean: -0.52053
[32m[0906 17-37-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31402, current rewards: -836.00402, mean: -0.53590
[32m[0906 17-37-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31407, current rewards: -886.00402, mean: -0.55031
[32m[0906 17-37-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31409, current rewards: -936.00402, mean: -0.56386
[32m[0906 17-38-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31408, current rewards: -986.00402, mean: -0.57661
[32m[0906 17-38-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31409, current rewards: -1036.00402, mean: -0.58864
[32m[0906 17-38-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31410, current rewards: -1086.00402, mean: -0.60000
[32m[0906 17-38-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31411, current rewards: -1136.00402, mean: -0.61075
[32m[0906 17-39-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31412, current rewards: -1186.00402, mean: -0.62094
[32m[0906 17-39-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31412, current rewards: -1236.00402, mean: -0.63061
[32m[0906 17-39-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31412, current rewards: -1286.00402, mean: -0.63980
[32m[0906 17-39-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31411, current rewards: -1336.00402, mean: -0.64855
[32m[0906 17-40-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31411, current rewards: -1386.00402, mean: -0.65687
[32m[0906 17-40-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31412, current rewards: -1436.00402, mean: -0.66482
[32m[0906 17-40-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31412, current rewards: -1486.00402, mean: -0.67240
[32m[0906 17-40-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31411, current rewards: -1536.00402, mean: -0.67965
[32m[0906 17-41-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31409, current rewards: -1586.00402, mean: -0.68658
[32m[0906 17-41-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31395, current rewards: -1636.00402, mean: -0.69322
[32m[0906 17-41-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31380, current rewards: -1686.00402, mean: -0.69959
[32m[0906 17-41-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31382, current rewards: -1736.00402, mean: -0.70569
[32m[0906 17-42-09 @Agent.py:117][0m Average action selection time: 0.3138
[32m[0906 17-42-09 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-42-09 @MBExp.py:227][0m Rewards obtained: [-1776.0040169463416], Lows: [0], Highs: [1817], Total time: 14217.078711999997
[32m[0906 17-42-43 @MBExp.py:144][0m ####################################################################
[32m[0906 17-42-43 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 17-42-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31843, current rewards: 1.35535, mean: 0.13553
[32m[0906 17-43-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31113, current rewards: 4.97671, mean: 0.08295
[32m[0906 17-43-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31011, current rewards: 9.41120, mean: 0.08556
[32m[0906 17-43-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31160, current rewards: 13.86673, mean: 0.08667
[32m[0906 17-43-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31256, current rewards: 18.32278, mean: 0.08725
[32m[0906 17-44-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31290, current rewards: 22.77970, mean: 0.08761
[32m[0906 17-44-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31262, current rewards: 27.23641, mean: 0.08786
[32m[0906 17-44-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31199, current rewards: 31.69479, mean: 0.08804
[32m[0906 17-44-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31172, current rewards: 36.15296, mean: 0.08818
[32m[0906 17-45-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31211, current rewards: 42.11640, mean: 0.09156
[32m[0906 17-45-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31240, current rewards: 47.22032, mean: 0.09259
[32m[0906 17-45-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31265, current rewards: 52.33805, mean: 0.09346
[32m[0906 17-45-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31288, current rewards: 57.45078, mean: 0.09418
[32m[0906 17-46-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31308, current rewards: 62.55999, mean: 0.09479
[32m[0906 17-46-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31318, current rewards: 67.66892, mean: 0.09531
[32m[0906 17-46-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31328, current rewards: 72.77920, mean: 0.09576
[32m[0906 17-46-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31338, current rewards: 41.73599, mean: 0.05153
[32m[0906 17-47-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31345, current rewards: 32.04158, mean: 0.03726
[32m[0906 17-47-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31357, current rewards: 8.56662, mean: 0.00941
[32m[0906 17-47-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31366, current rewards: -15.87331, mean: -0.01653
[32m[0906 17-48-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31366, current rewards: -38.83202, mean: -0.03845
[32m[0906 17-48-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31370, current rewards: -50.89139, mean: -0.04801
[32m[0906 17-48-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31375, current rewards: -66.91974, mean: -0.06029
[32m[0906 17-48-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31379, current rewards: -89.30381, mean: -0.07699
[32m[0906 17-49-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31382, current rewards: -131.57295, mean: -0.10874
[32m[0906 17-49-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31385, current rewards: -138.80306, mean: -0.11016
[32m[0906 17-49-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31386, current rewards: -128.17645, mean: -0.09784
[32m[0906 17-49-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31386, current rewards: -115.41461, mean: -0.08486
[32m[0906 17-50-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31384, current rewards: -103.17872, mean: -0.07318
[32m[0906 17-50-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31386, current rewards: -91.29331, mean: -0.06253
[32m[0906 17-50-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31388, current rewards: -79.31079, mean: -0.05252
[32m[0906 17-50-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31388, current rewards: -67.38925, mean: -0.04320
[32m[0906 17-51-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31388, current rewards: -55.45644, mean: -0.03444
[32m[0906 17-51-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31392, current rewards: -68.15321, mean: -0.04106
[32m[0906 17-51-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31390, current rewards: -124.66497, mean: -0.07290
[32m[0906 17-51-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31388, current rewards: -176.03315, mean: -0.10002
[32m[0906 17-52-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31388, current rewards: -246.98521, mean: -0.13646
[32m[0906 17-52-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31389, current rewards: -320.73045, mean: -0.17244
[32m[0906 17-52-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31390, current rewards: -380.99501, mean: -0.19947
[32m[0906 17-52-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31390, current rewards: -454.38310, mean: -0.23183
[32m[0906 17-53-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31390, current rewards: -530.61934, mean: -0.26399
[32m[0906 17-53-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31387, current rewards: -573.23803, mean: -0.27827
[32m[0906 17-53-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31387, current rewards: -569.14483, mean: -0.26974
[32m[0906 17-54-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31388, current rewards: -563.97339, mean: -0.26110
[32m[0906 17-54-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31390, current rewards: -558.73622, mean: -0.25282
[32m[0906 17-54-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31394, current rewards: -553.50899, mean: -0.24492
[32m[0906 17-54-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31394, current rewards: -548.27729, mean: -0.23735
[32m[0906 17-55-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31382, current rewards: -543.04841, mean: -0.23011
[32m[0906 17-55-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31370, current rewards: -537.82145, mean: -0.22316
[32m[0906 17-55-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31372, current rewards: -539.21916, mean: -0.21919
[32m[0906 17-55-48 @Agent.py:117][0m Average action selection time: 0.3137
[32m[0906 17-55-48 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-55-48 @MBExp.py:227][0m Rewards obtained: [-587.1580147968383], Lows: [410], Highs: [64], Total time: 15001.996806999996
[32m[0906 17-56-23 @MBExp.py:144][0m ####################################################################
[32m[0906 17-56-23 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 17-56-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31701, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-56-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30990, current rewards: -46.31378, mean: -0.77190
[32m[0906 17-56-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30901, current rewards: -39.97054, mean: -0.36337
[32m[0906 17-57-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31054, current rewards: -33.96500, mean: -0.21228
[32m[0906 17-57-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31161, current rewards: -68.10703, mean: -0.32432
[32m[0906 17-57-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31212, current rewards: -57.58588, mean: -0.22148
[32m[0906 17-58-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31202, current rewards: -51.41816, mean: -0.16587
[32m[0906 17-58-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31146, current rewards: -45.25435, mean: -0.12571
[32m[0906 17-58-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31125, current rewards: -83.03802, mean: -0.20253
[32m[0906 17-58-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31180, current rewards: -76.28549, mean: -0.16584
[32m[0906 17-59-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31209, current rewards: -69.16499, mean: -0.13562
[32m[0906 17-59-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31241, current rewards: -61.80515, mean: -0.11037
[32m[0906 17-59-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31257, current rewards: -54.45341, mean: -0.08927
[32m[0906 17-59-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31270, current rewards: -47.09638, mean: -0.07136
[32m[0906 18-00-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31291, current rewards: -39.73921, mean: -0.05597
[32m[0906 18-00-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31304, current rewards: -32.38371, mean: -0.04261
[32m[0906 18-00-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31313, current rewards: -25.03222, mean: -0.03090
[32m[0906 18-00-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31314, current rewards: -18.17816, mean: -0.02114
[32m[0906 18-01-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31320, current rewards: -10.63382, mean: -0.01169
[32m[0906 18-01-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31327, current rewards: -12.15921, mean: -0.01267
[32m[0906 18-01-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31332, current rewards: -84.02440, mean: -0.08319
[32m[0906 18-01-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31334, current rewards: -142.12738, mean: -0.13408
[32m[0906 18-02-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31339, current rewards: -204.18113, mean: -0.18395
[32m[0906 18-02-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31341, current rewards: -253.59852, mean: -0.21862
[32m[0906 18-02-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31348, current rewards: -309.25794, mean: -0.25559
[32m[0906 18-02-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31351, current rewards: -366.92602, mean: -0.29121
[32m[0906 18-03-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31354, current rewards: -412.54388, mean: -0.31492
[32m[0906 18-03-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31355, current rewards: -462.38275, mean: -0.33999
[32m[0906 18-03-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31356, current rewards: -453.77937, mean: -0.32183
[32m[0906 18-04-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31354, current rewards: -445.58518, mean: -0.30520
[32m[0906 18-04-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31355, current rewards: -437.39029, mean: -0.28966
[32m[0906 18-04-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31354, current rewards: -441.99962, mean: -0.28333
[32m[0906 18-04-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31354, current rewards: -450.38146, mean: -0.27974
[32m[0906 18-05-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31355, current rewards: -441.68439, mean: -0.26607
[32m[0906 18-05-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31353, current rewards: -433.83305, mean: -0.25370
[32m[0906 18-05-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31354, current rewards: -425.37659, mean: -0.24169
[32m[0906 18-05-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31354, current rewards: -416.91507, mean: -0.23034
[32m[0906 18-06-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31352, current rewards: -408.45492, mean: -0.21960
[32m[0906 18-06-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31353, current rewards: -399.99899, mean: -0.20942
[32m[0906 18-06-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31352, current rewards: -391.54072, mean: -0.19977
[32m[0906 18-06-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31356, current rewards: -383.06230, mean: -0.19058
[32m[0906 18-07-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31353, current rewards: -441.60489, mean: -0.21437
[32m[0906 18-07-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31352, current rewards: -516.45145, mean: -0.24476
[32m[0906 18-07-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31350, current rewards: -573.54734, mean: -0.26553
[32m[0906 18-07-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31350, current rewards: -641.36103, mean: -0.29021
[32m[0906 18-08-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31348, current rewards: -709.20175, mean: -0.31381
[32m[0906 18-08-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31346, current rewards: -766.28844, mean: -0.33173
[32m[0906 18-08-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31333, current rewards: -836.25503, mean: -0.35435
[32m[0906 18-08-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31320, current rewards: -897.67608, mean: -0.37248
[32m[0906 18-09-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31319, current rewards: -961.18262, mean: -0.39072
[32m[0906 18-09-27 @Agent.py:117][0m Average action selection time: 0.3132
[32m[0906 18-09-27 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-09-27 @MBExp.py:227][0m Rewards obtained: [-1011.2728052448969], Lows: [612], Highs: [81], Total time: 15785.559289999996
[32m[0906 18-10-04 @MBExp.py:144][0m ####################################################################
[32m[0906 18-10-04 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 18-10-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31505, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-10-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30891, current rewards: -57.44950, mean: -0.95749
[32m[0906 18-10-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30847, current rewards: -49.80532, mean: -0.45278
[32m[0906 18-10-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31000, current rewards: -42.16356, mean: -0.26352
[32m[0906 18-11-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31152, current rewards: -34.52677, mean: -0.16441
[32m[0906 18-11-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31236, current rewards: -26.88614, mean: -0.10341
[32m[0906 18-11-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31223, current rewards: -19.24971, mean: -0.06210
[32m[0906 18-11-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31160, current rewards: -11.61917, mean: -0.03228
[32m[0906 18-12-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31117, current rewards: -47.30272, mean: -0.11537
[32m[0906 18-12-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31187, current rewards: -43.19828, mean: -0.09391
[32m[0906 18-12-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31526, current rewards: -38.74859, mean: -0.07598
[32m[0906 18-13-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31863, current rewards: -34.06235, mean: -0.06083
[32m[0906 18-13-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32151, current rewards: -29.38595, mean: -0.04817
[32m[0906 18-13-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32411, current rewards: -24.99102, mean: -0.03787
[32m[0906 18-13-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32640, current rewards: -20.74103, mean: -0.02921
[32m[0906 18-14-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32851, current rewards: -16.29971, mean: -0.02145
[32m[0906 18-14-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33028, current rewards: -9.42902, mean: -0.01164
[32m[0906 18-14-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33181, current rewards: -5.11093, mean: -0.00594
[32m[0906 18-15-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33320, current rewards: -0.77575, mean: -0.00085
[32m[0906 18-15-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33442, current rewards: 3.55721, mean: 0.00371
[32m[0906 18-15-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33552, current rewards: -8.09758, mean: -0.00802
[32m[0906 18-16-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33653, current rewards: -58.09758, mean: -0.05481
[32m[0906 18-16-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33745, current rewards: -108.09758, mean: -0.09739
[32m[0906 18-16-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33844, current rewards: -158.09758, mean: -0.13629
[32m[0906 18-16-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33948, current rewards: -208.09758, mean: -0.17198
[32m[0906 18-17-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34044, current rewards: -258.09758, mean: -0.20484
[32m[0906 18-17-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34117, current rewards: -308.09758, mean: -0.23519
[32m[0906 18-17-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34163, current rewards: -358.09758, mean: -0.26331
[32m[0906 18-18-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34206, current rewards: -408.09758, mean: -0.28943
[32m[0906 18-18-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34250, current rewards: -458.09758, mean: -0.31377
[32m[0906 18-18-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34289, current rewards: -508.09758, mean: -0.33649
[32m[0906 18-19-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34327, current rewards: -558.09758, mean: -0.35775
[32m[0906 18-19-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34361, current rewards: -608.09758, mean: -0.37770
[32m[0906 18-19-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34395, current rewards: -658.09758, mean: -0.39644
[32m[0906 18-19-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34424, current rewards: -708.09758, mean: -0.41409
[32m[0906 18-20-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34452, current rewards: -758.09758, mean: -0.43074
[32m[0906 18-20-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34476, current rewards: -808.09758, mean: -0.44646
[32m[0906 18-20-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34498, current rewards: -858.09758, mean: -0.46134
[32m[0906 18-21-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34522, current rewards: -908.09758, mean: -0.47544
[32m[0906 18-21-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34542, current rewards: -958.09758, mean: -0.48883
[32m[0906 18-21-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34569, current rewards: -1008.09758, mean: -0.50154
[32m[0906 18-21-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34594, current rewards: -1058.09758, mean: -0.51364
[32m[0906 18-22-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34621, current rewards: -1108.09758, mean: -0.52516
[32m[0906 18-22-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34645, current rewards: -1158.09758, mean: -0.53616
[32m[0906 18-22-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34666, current rewards: -1208.09758, mean: -0.54665
[32m[0906 18-23-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34691, current rewards: -1258.09758, mean: -0.55668
[32m[0906 18-23-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34713, current rewards: -1308.09758, mean: -0.56628
[32m[0906 18-23-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34716, current rewards: -1358.09758, mean: -0.57547
[32m[0906 18-24-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34715, current rewards: -1408.09758, mean: -0.58427
[32m[0906 18-24-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34720, current rewards: -1458.09758, mean: -0.59272
[32m[0906 18-24-33 @Agent.py:117][0m Average action selection time: 0.3474
[32m[0906 18-24-33 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-24-33 @MBExp.py:227][0m Rewards obtained: [-1498.0975778569227], Lows: [40], Highs: [1526], Total time: 16654.651764999995
[32m[0906 18-25-18 @MBExp.py:144][0m ####################################################################
[32m[0906 18-25-18 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 18-25-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35310, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-25-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34972, current rewards: -16.66939, mean: -0.27782
[32m[0906 18-25-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35247, current rewards: -12.07140, mean: -0.10974
[32m[0906 18-26-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35509, current rewards: -7.47922, mean: -0.04675
[32m[0906 18-26-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35478, current rewards: -2.88430, mean: -0.01373
[32m[0906 18-26-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35451, current rewards: 1.71126, mean: 0.00658
[32m[0906 18-27-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35370, current rewards: 6.30777, mean: 0.02035
[32m[0906 18-27-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35260, current rewards: 11.24474, mean: 0.03124
[32m[0906 18-27-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35166, current rewards: 3.17128, mean: 0.00773
[32m[0906 18-28-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35201, current rewards: -14.35098, mean: -0.03120
[32m[0906 18-28-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35224, current rewards: -9.84365, mean: -0.01930
[32m[0906 18-28-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35251, current rewards: -5.33899, mean: -0.00953
[32m[0906 18-28-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35289, current rewards: -0.83801, mean: -0.00137
[32m[0906 18-29-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35324, current rewards: 3.67245, mean: 0.00556
[32m[0906 18-29-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35357, current rewards: 8.17953, mean: 0.01152
[32m[0906 18-29-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35397, current rewards: 12.68873, mean: 0.01670
[32m[0906 18-30-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35408, current rewards: 16.86010, mean: 0.02081
[32m[0906 18-30-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35397, current rewards: 21.79372, mean: 0.02534
[32m[0906 18-30-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35390, current rewards: 26.74522, mean: 0.02939
[32m[0906 18-30-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35393, current rewards: -11.28448, mean: -0.01175
[32m[0906 18-31-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35384, current rewards: -85.85338, mean: -0.08500
[32m[0906 18-31-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35375, current rewards: -164.20084, mean: -0.15491
[32m[0906 18-31-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35368, current rewards: -249.66081, mean: -0.22492
[32m[0906 18-32-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35336, current rewards: -335.17257, mean: -0.28894
[32m[0906 18-32-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35176, current rewards: -398.28907, mean: -0.32916
[32m[0906 18-32-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35033, current rewards: -441.30411, mean: -0.35024
[32m[0906 18-32-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34901, current rewards: -494.35540, mean: -0.37737
[32m[0906 18-33-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34778, current rewards: -544.95340, mean: -0.40070
[32m[0906 18-33-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34659, current rewards: -592.79787, mean: -0.42042
[32m[0906 18-33-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34551, current rewards: -638.40181, mean: -0.43726
[32m[0906 18-33-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34450, current rewards: -631.08782, mean: -0.41794
[32m[0906 18-34-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34357, current rewards: -627.09528, mean: -0.40198
[32m[0906 18-34-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34268, current rewards: -623.08785, mean: -0.38701
[32m[0906 18-34-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34183, current rewards: -619.08093, mean: -0.37294
[32m[0906 18-35-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34102, current rewards: -615.07563, mean: -0.35969
[32m[0906 18-35-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34025, current rewards: -611.06960, mean: -0.34720
[32m[0906 18-35-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33953, current rewards: -607.06072, mean: -0.33539
[32m[0906 18-35-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33885, current rewards: -603.05255, mean: -0.32422
[32m[0906 18-36-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33819, current rewards: -619.92418, mean: -0.32457
[32m[0906 18-36-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33757, current rewards: -615.85763, mean: -0.31421
[32m[0906 18-36-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33700, current rewards: -612.55465, mean: -0.30475
[32m[0906 18-36-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33645, current rewards: -609.22412, mean: -0.29574
[32m[0906 18-37-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33592, current rewards: -605.83159, mean: -0.28712
[32m[0906 18-37-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33543, current rewards: -602.44054, mean: -0.27891
[32m[0906 18-37-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33494, current rewards: -599.05012, mean: -0.27106
[32m[0906 18-37-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33446, current rewards: -595.65004, mean: -0.26356
[32m[0906 18-38-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33407, current rewards: -592.25682, mean: -0.25639
[32m[0906 18-38-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33352, current rewards: -587.96526, mean: -0.24914
[32m[0906 18-38-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33298, current rewards: -583.07646, mean: -0.24194
[32m[0906 18-38-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33250, current rewards: -578.78234, mean: -0.23528
[32m[0906 18-39-09 @Agent.py:117][0m Average action selection time: 0.3322
[32m[0906 18-39-09 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-39-09 @MBExp.py:227][0m Rewards obtained: [-575.4560173418668], Lows: [362], Highs: [80], Total time: 17485.803311999996
[32m[0906 18-39-50 @MBExp.py:144][0m ####################################################################
[32m[0906 18-39-50 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 18-39-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30879, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-40-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30812, current rewards: -17.95174, mean: -0.29920
[32m[0906 18-40-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30812, current rewards: -13.77351, mean: -0.12521
[32m[0906 18-40-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30930, current rewards: -9.61566, mean: -0.06010
[32m[0906 18-40-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31076, current rewards: -5.45893, mean: -0.02599
[32m[0906 18-41-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31159, current rewards: -1.30294, mean: -0.00501
[32m[0906 18-41-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31164, current rewards: 2.85528, mean: 0.00921
[32m[0906 18-41-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31123, current rewards: 10.13260, mean: 0.02815
[32m[0906 18-41-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31087, current rewards: -6.96280, mean: -0.01698
[32m[0906 18-42-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31135, current rewards: -3.64857, mean: -0.00793
[32m[0906 18-42-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31175, current rewards: -0.39243, mean: -0.00077
[32m[0906 18-42-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31207, current rewards: 2.83685, mean: 0.00507
[32m[0906 18-43-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31227, current rewards: 6.05739, mean: 0.00993
[32m[0906 18-43-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31240, current rewards: 9.27494, mean: 0.01405
[32m[0906 18-43-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31254, current rewards: 12.49017, mean: 0.01759
[32m[0906 18-43-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31275, current rewards: 1.67667, mean: 0.00221
[32m[0906 18-44-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31282, current rewards: 4.80558, mean: 0.00593
[32m[0906 18-44-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31290, current rewards: -33.11823, mean: -0.03851
[32m[0906 18-44-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31307, current rewards: -28.77075, mean: -0.03162
[32m[0906 18-44-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31320, current rewards: -23.22335, mean: -0.02419
[32m[0906 18-45-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31327, current rewards: -17.57055, mean: -0.01740
[32m[0906 18-45-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31336, current rewards: -11.91726, mean: -0.01124
[32m[0906 18-45-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31340, current rewards: -6.26637, mean: -0.00565
[32m[0906 18-45-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31346, current rewards: -1.32474, mean: -0.00114
[32m[0906 18-46-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31351, current rewards: 2.90501, mean: 0.00240
[32m[0906 18-46-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31356, current rewards: 7.86588, mean: 0.00624
[32m[0906 18-46-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31358, current rewards: 12.82632, mean: 0.00979
[32m[0906 18-46-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31364, current rewards: -4.21535, mean: -0.00310
[32m[0906 18-47-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31366, current rewards: -0.76876, mean: -0.00055
[32m[0906 18-47-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31371, current rewards: 2.58948, mean: 0.00177
[32m[0906 18-47-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31372, current rewards: 5.94978, mean: 0.00394
[32m[0906 18-48-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31375, current rewards: 9.35339, mean: 0.00600
[32m[0906 18-48-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31377, current rewards: 15.10293, mean: 0.00938
[32m[0906 18-48-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31379, current rewards: -2.70700, mean: -0.00163
[32m[0906 18-48-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31377, current rewards: 2.64280, mean: 0.00155
[32m[0906 18-49-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31378, current rewards: 7.65371, mean: 0.00435
[32m[0906 18-49-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31382, current rewards: 12.65920, mean: 0.00699
[32m[0906 18-49-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31381, current rewards: 2.96367, mean: 0.00159
[32m[0906 18-49-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31382, current rewards: -18.93610, mean: -0.00991
[32m[0906 18-50-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31383, current rewards: -13.76108, mean: -0.00702
[32m[0906 18-50-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31382, current rewards: -8.58995, mean: -0.00427
[32m[0906 18-50-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31381, current rewards: -3.41739, mean: -0.00166
[32m[0906 18-50-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31380, current rewards: 1.74646, mean: 0.00083
[32m[0906 18-51-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31378, current rewards: 6.91316, mean: 0.00320
[32m[0906 18-51-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31378, current rewards: 12.07973, mean: 0.00547
[32m[0906 18-51-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31377, current rewards: -6.49824, mean: -0.00288
[32m[0906 18-51-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31376, current rewards: -1.37364, mean: -0.00059
[32m[0906 18-52-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31364, current rewards: 3.62878, mean: 0.00154
[32m[0906 18-52-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31350, current rewards: 8.11743, mean: 0.00337
[32m[0906 18-52-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31338, current rewards: 12.92745, mean: 0.00526
[32m[0906 18-52-54 @Agent.py:117][0m Average action selection time: 0.3134
[32m[0906 18-52-54 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-52-54 @MBExp.py:227][0m Rewards obtained: [16.709743164974434], Lows: [40], Highs: [115], Total time: 18269.904616999997
[32m[0906 18-53-37 @MBExp.py:144][0m ####################################################################
[32m[0906 18-53-37 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 18-53-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30398, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-53-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30745, current rewards: -49.88390, mean: -0.83140
[32m[0906 18-54-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30758, current rewards: -42.37196, mean: -0.38520
[32m[0906 18-54-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30871, current rewards: -36.03767, mean: -0.22524
[32m[0906 18-54-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31018, current rewards: -29.71191, mean: -0.14149
[32m[0906 18-54-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31110, current rewards: -23.39264, mean: -0.08997
[32m[0906 18-55-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31123, current rewards: -16.85559, mean: -0.05437
[32m[0906 18-55-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31079, current rewards: -40.42104, mean: -0.11228
[32m[0906 18-55-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31036, current rewards: -35.45106, mean: -0.08647
[32m[0906 18-56-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31072, current rewards: -30.49988, mean: -0.06630
[32m[0906 18-56-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31112, current rewards: -50.73821, mean: -0.09949
[32m[0906 18-56-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31150, current rewards: -57.76295, mean: -0.10315
[32m[0906 18-56-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31175, current rewards: -51.25550, mean: -0.08403
[32m[0906 18-57-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31203, current rewards: -44.77775, mean: -0.06785
[32m[0906 18-57-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31233, current rewards: -38.29987, mean: -0.05394
[32m[0906 18-57-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31253, current rewards: -31.82089, mean: -0.04187
[32m[0906 18-57-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31270, current rewards: -51.92192, mean: -0.06410
[32m[0906 18-58-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31282, current rewards: -57.76567, mean: -0.06717
[32m[0906 18-58-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31288, current rewards: -31.98171, mean: -0.03514
[32m[0906 18-58-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31298, current rewards: -7.85043, mean: -0.00818
[32m[0906 18-58-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31309, current rewards: 16.19784, mean: 0.01604
[32m[0906 18-59-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31318, current rewards: 40.23010, mean: 0.03795
[32m[0906 18-59-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31322, current rewards: 64.22295, mean: 0.05786
[32m[0906 18-59-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31327, current rewards: 80.67323, mean: 0.06955
[32m[0906 18-59-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31328, current rewards: 46.01766, mean: 0.03803
[32m[0906 19-00-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31332, current rewards: 3.84413, mean: 0.00305
[32m[0906 19-00-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31338, current rewards: -31.27565, mean: -0.02387
[32m[0906 19-00-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31337, current rewards: -59.42899, mean: -0.04370
[32m[0906 19-00-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31338, current rewards: -110.69535, mean: -0.07851
[32m[0906 19-01-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31342, current rewards: -146.53954, mean: -0.10037
[32m[0906 19-01-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31340, current rewards: -174.69574, mean: -0.11569
[32m[0906 19-01-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31338, current rewards: -226.06102, mean: -0.14491
[32m[0906 19-02-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31339, current rewards: -260.09546, mean: -0.16155
[32m[0906 19-02-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31341, current rewards: -284.93260, mean: -0.17165
[32m[0906 19-02-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31338, current rewards: -279.15525, mean: -0.16325
[32m[0906 19-02-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31339, current rewards: -273.63861, mean: -0.15548
[32m[0906 19-03-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31341, current rewards: -268.11502, mean: -0.14813
[32m[0906 19-03-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31339, current rewards: -262.60177, mean: -0.14118
[32m[0906 19-03-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31340, current rewards: -257.08475, mean: -0.13460
[32m[0906 19-03-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31339, current rewards: -251.56215, mean: -0.12835
[32m[0906 19-04-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31340, current rewards: -246.72709, mean: -0.12275
[32m[0906 19-04-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31338, current rewards: -281.18940, mean: -0.13650
[32m[0906 19-04-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31340, current rewards: -268.10922, mean: -0.12707
[32m[0906 19-04-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31341, current rewards: -255.79335, mean: -0.11842
[32m[0906 19-05-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31341, current rewards: -243.48609, mean: -0.11017
[32m[0906 19-05-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31341, current rewards: -231.19553, mean: -0.10230
[32m[0906 19-05-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31340, current rewards: -218.89661, mean: -0.09476
[32m[0906 19-05-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31329, current rewards: -233.51326, mean: -0.09895
[32m[0906 19-06-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31316, current rewards: -208.88716, mean: -0.08668
[32m[0906 19-06-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31303, current rewards: -189.70995, mean: -0.07712
[32m[0906 19-06-40 @Agent.py:117][0m Average action selection time: 0.3131
[32m[0906 19-06-40 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-06-40 @MBExp.py:227][0m Rewards obtained: [-174.19172379893033], Lows: [301], Highs: [62], Total time: 19053.159449999996
[32m[0906 19-07-25 @MBExp.py:144][0m ####################################################################
[32m[0906 19-07-25 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 19-07-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30136, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-07-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30780, current rewards: -15.98638, mean: -0.26644
[32m[0906 19-07-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30775, current rewards: -10.91100, mean: -0.09919
[32m[0906 19-08-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30891, current rewards: -5.83309, mean: -0.03646
[32m[0906 19-08-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31034, current rewards: -0.75581, mean: -0.00360
[32m[0906 19-08-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31114, current rewards: 4.32071, mean: 0.01662
[32m[0906 19-09-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31119, current rewards: 9.70231, mean: 0.03130
[32m[0906 19-09-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31076, current rewards: 11.81107, mean: 0.03281
[32m[0906 19-09-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31048, current rewards: -18.03121, mean: -0.04398
[32m[0906 19-09-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31070, current rewards: -48.09293, mean: -0.10455
[32m[0906 19-10-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31121, current rewards: -82.34823, mean: -0.16147
[32m[0906 19-10-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31156, current rewards: -110.31248, mean: -0.19699
[32m[0906 19-10-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31191, current rewards: -150.86872, mean: -0.24733
[32m[0906 19-10-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31228, current rewards: -181.99483, mean: -0.27575
[32m[0906 19-11-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31254, current rewards: -222.55186, mean: -0.31345
[32m[0906 19-11-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31270, current rewards: -260.97146, mean: -0.34338
[32m[0906 19-11-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31283, current rewards: -277.48172, mean: -0.34257
[32m[0906 19-11-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31295, current rewards: -273.04835, mean: -0.31750
[32m[0906 19-12-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31307, current rewards: -268.64085, mean: -0.29521
[32m[0906 19-12-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31317, current rewards: -264.23041, mean: -0.27524
[32m[0906 19-12-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31325, current rewards: -259.82204, mean: -0.25725
[32m[0906 19-12-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31335, current rewards: -255.40798, mean: -0.24095
[32m[0906 19-13-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31342, current rewards: -250.99572, mean: -0.22612
[32m[0906 19-13-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31345, current rewards: -244.97491, mean: -0.21119
[32m[0906 19-13-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31350, current rewards: -240.31429, mean: -0.19861
[32m[0906 19-14-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31357, current rewards: -235.66168, mean: -0.18703
[32m[0906 19-14-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31362, current rewards: -232.09854, mean: -0.17717
[32m[0906 19-14-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31366, current rewards: -248.18812, mean: -0.18249
[32m[0906 19-14-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31369, current rewards: -244.76300, mean: -0.17359
[32m[0906 19-15-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31373, current rewards: -241.32563, mean: -0.16529
[32m[0906 19-15-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31376, current rewards: -237.88605, mean: -0.15754
[32m[0906 19-15-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31380, current rewards: -233.49730, mean: -0.14968
[32m[0906 19-15-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31383, current rewards: -229.53616, mean: -0.14257
[32m[0906 19-16-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31384, current rewards: -225.63758, mean: -0.13593
[32m[0906 19-16-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31385, current rewards: -221.73886, mean: -0.12967
[32m[0906 19-16-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31386, current rewards: -217.84650, mean: -0.12378
[32m[0906 19-16-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31383, current rewards: -253.95795, mean: -0.14031
[32m[0906 19-17-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31384, current rewards: -247.70943, mean: -0.13318
[32m[0906 19-17-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31384, current rewards: -241.39181, mean: -0.12638
[32m[0906 19-17-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31385, current rewards: -235.26636, mean: -0.12003
[32m[0906 19-17-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31387, current rewards: -229.03058, mean: -0.11395
[32m[0906 19-18-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31385, current rewards: -261.00156, mean: -0.12670
[32m[0906 19-18-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31385, current rewards: -258.83104, mean: -0.12267
[32m[0906 19-18-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31386, current rewards: -251.86872, mean: -0.11661
[32m[0906 19-18-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31388, current rewards: -244.91402, mean: -0.11082
[32m[0906 19-19-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31387, current rewards: -237.95734, mean: -0.10529
[32m[0906 19-19-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31387, current rewards: -231.00271, mean: -0.10000
[32m[0906 19-19-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31376, current rewards: -224.52955, mean: -0.09514
[32m[0906 19-20-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31364, current rewards: -218.83018, mean: -0.09080
[32m[0906 19-20-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31350, current rewards: -212.65614, mean: -0.08645
[32m[0906 19-20-29 @Agent.py:117][0m Average action selection time: 0.3135
[32m[0906 19-20-29 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-20-29 @MBExp.py:227][0m Rewards obtained: [-207.72152888385727], Lows: [40], Highs: [341], Total time: 19837.504780999996
[32m[0906 19-21-16 @MBExp.py:144][0m ####################################################################
[32m[0906 19-21-16 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 19-21-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29886, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-21-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30685, current rewards: -20.62736, mean: -0.34379
[32m[0906 19-21-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30770, current rewards: -16.77754, mean: -0.15252
[32m[0906 19-22-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30910, current rewards: -12.92908, mean: -0.08081
[32m[0906 19-22-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31079, current rewards: -9.07666, mean: -0.04322
[32m[0906 19-22-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31192, current rewards: -5.22524, mean: -0.02010
[32m[0906 19-22-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31213, current rewards: 8.12965, mean: 0.02622
[32m[0906 19-23-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31168, current rewards: 13.27542, mean: 0.03688
[32m[0906 19-23-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31130, current rewards: 18.42107, mean: 0.04493
[32m[0906 19-23-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31141, current rewards: 23.56672, mean: 0.05123
[32m[0906 19-23-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31189, current rewards: 28.71237, mean: 0.05630
[32m[0906 19-24-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31217, current rewards: -0.33228, mean: -0.00059
[32m[0906 19-24-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31239, current rewards: -50.33228, mean: -0.08251
[32m[0906 19-24-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31264, current rewards: -100.33228, mean: -0.15202
[32m[0906 19-24-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31281, current rewards: -150.33228, mean: -0.21174
[32m[0906 19-25-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31299, current rewards: -200.33228, mean: -0.26360
[32m[0906 19-25-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31309, current rewards: -250.33228, mean: -0.30905
[32m[0906 19-25-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31315, current rewards: -300.33228, mean: -0.34922
[32m[0906 19-26-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31324, current rewards: -350.33228, mean: -0.38498
[32m[0906 19-26-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31340, current rewards: -400.33228, mean: -0.41701
[32m[0906 19-26-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31347, current rewards: -450.33228, mean: -0.44587
[32m[0906 19-26-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31353, current rewards: -500.33228, mean: -0.47201
[32m[0906 19-27-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31358, current rewards: -550.33228, mean: -0.49579
[32m[0906 19-27-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31358, current rewards: -600.33228, mean: -0.51753
[32m[0906 19-27-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31365, current rewards: -650.33228, mean: -0.53746
[32m[0906 19-27-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31369, current rewards: -700.33228, mean: -0.55582
[32m[0906 19-28-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31372, current rewards: -750.33228, mean: -0.57277
[32m[0906 19-28-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31373, current rewards: -800.33228, mean: -0.58848
[32m[0906 19-28-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31374, current rewards: -850.33228, mean: -0.60307
[32m[0906 19-28-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31379, current rewards: -900.33228, mean: -0.61667
[32m[0906 19-29-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31385, current rewards: -950.33228, mean: -0.62936
[32m[0906 19-29-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31391, current rewards: -1000.33228, mean: -0.64124
[32m[0906 19-29-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31393, current rewards: -1050.33228, mean: -0.65238
[32m[0906 19-29-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31485, current rewards: -1100.33228, mean: -0.66285
[32m[0906 19-30-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31593, current rewards: -1150.33228, mean: -0.67271
[32m[0906 19-30-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31693, current rewards: -1200.33228, mean: -0.68201
[32m[0906 19-30-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31790, current rewards: -1250.33228, mean: -0.69079
[32m[0906 19-31-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31878, current rewards: -1300.33228, mean: -0.69910
[32m[0906 19-31-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31966, current rewards: -1350.33228, mean: -0.70698
[32m[0906 19-31-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32043, current rewards: -1400.33228, mean: -0.71446
[32m[0906 19-32-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32120, current rewards: -1450.33228, mean: -0.72156
[32m[0906 19-32-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32191, current rewards: -1500.33228, mean: -0.72832
[32m[0906 19-32-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32262, current rewards: -1550.33228, mean: -0.73475
[32m[0906 19-32-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32329, current rewards: -1600.33228, mean: -0.74089
[32m[0906 19-33-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32393, current rewards: -1650.33228, mean: -0.74676
[32m[0906 19-33-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32455, current rewards: -1700.33228, mean: -0.75236
[32m[0906 19-33-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32515, current rewards: -1750.33228, mean: -0.75772
[32m[0906 19-34-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32556, current rewards: -1800.33228, mean: -0.76285
[32m[0906 19-34-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32595, current rewards: -1850.33228, mean: -0.76777
[32m[0906 19-34-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32629, current rewards: -1900.33228, mean: -0.77249
[32m[0906 19-34-53 @Agent.py:117][0m Average action selection time: 0.3266
[32m[0906 19-34-53 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-34-53 @MBExp.py:227][0m Rewards obtained: [-1940.3322816619402], Lows: [0], Highs: [1994], Total time: 20654.761735999997
[32m[0906 19-35-47 @MBExp.py:144][0m ####################################################################
[32m[0906 19-35-47 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 19-35-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33312, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-36-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34170, current rewards: -14.45982, mean: -0.24100
[32m[0906 19-36-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34274, current rewards: -12.41619, mean: -0.11287
[32m[0906 19-36-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34442, current rewards: -8.12783, mean: -0.05080
[32m[0906 19-36-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34659, current rewards: -6.05313, mean: -0.02882
[32m[0906 19-37-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34755, current rewards: -1.87266, mean: -0.00720
[32m[0906 19-37-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34769, current rewards: 2.71218, mean: 0.00875
[32m[0906 19-37-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34716, current rewards: -36.38748, mean: -0.10108
[32m[0906 19-38-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34672, current rewards: -28.49123, mean: -0.06949
[32m[0906 19-38-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34663, current rewards: -23.73631, mean: -0.05160
[32m[0906 19-38-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34718, current rewards: -19.06792, mean: -0.03739
[32m[0906 19-39-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34763, current rewards: -14.40016, mean: -0.02571
[32m[0906 19-39-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34797, current rewards: -9.73047, mean: -0.01595
[32m[0906 19-39-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34830, current rewards: -5.06063, mean: -0.00767
[32m[0906 19-39-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34853, current rewards: -0.38969, mean: -0.00055
[32m[0906 19-40-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34874, current rewards: 4.27940, mean: 0.00563
[32m[0906 19-40-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34894, current rewards: -14.95510, mean: -0.01846
[32m[0906 19-40-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34924, current rewards: -9.93126, mean: -0.01155
[32m[0906 19-41-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34937, current rewards: -5.11777, mean: -0.00562
[32m[0906 19-41-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34953, current rewards: -0.32190, mean: -0.00034
[32m[0906 19-41-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34961, current rewards: 4.47927, mean: 0.00443
[32m[0906 19-41-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34970, current rewards: 9.27318, mean: 0.00875
[32m[0906 19-42-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34977, current rewards: 21.52566, mean: 0.01939
[32m[0906 19-42-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34985, current rewards: 27.71490, mean: 0.02389
[32m[0906 19-42-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34995, current rewards: 33.14005, mean: 0.02739
[32m[0906 19-43-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35002, current rewards: 38.55026, mean: 0.03060
[32m[0906 19-43-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35010, current rewards: 43.95343, mean: 0.03355
[32m[0906 19-43-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35014, current rewards: 49.35518, mean: 0.03629
[32m[0906 19-44-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35015, current rewards: 54.74950, mean: 0.03883
[32m[0906 19-44-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35021, current rewards: 18.64472, mean: 0.01277
[32m[0906 19-44-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34945, current rewards: 22.86636, mean: 0.01514
[32m[0906 19-44-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34840, current rewards: 27.47136, mean: 0.01761
[32m[0906 19-45-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34733, current rewards: 32.10870, mean: 0.01994
[32m[0906 19-45-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34634, current rewards: 36.74560, mean: 0.02214
[32m[0906 19-45-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34539, current rewards: 41.38488, mean: 0.02420
[32m[0906 19-45-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34452, current rewards: 46.02626, mean: 0.02615
[32m[0906 19-46-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34365, current rewards: 50.66276, mean: 0.02799
[32m[0906 19-46-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34285, current rewards: 55.30276, mean: 0.02973
[32m[0906 19-46-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34212, current rewards: 56.99743, mean: 0.02984
[32m[0906 19-46-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34140, current rewards: 63.25083, mean: 0.03227
[32m[0906 19-47-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34071, current rewards: 30.84050, mean: 0.01534
[32m[0906 19-47-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34006, current rewards: 38.74014, mean: 0.01881
[32m[0906 19-47-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33942, current rewards: 46.20034, mean: 0.02190
[32m[0906 19-47-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33883, current rewards: 53.66053, mean: 0.02484
[32m[0906 19-48-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33825, current rewards: 61.12072, mean: 0.02766
[32m[0906 19-48-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33774, current rewards: 68.58091, mean: 0.03035
[32m[0906 19-48-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33723, current rewards: 76.04110, mean: 0.03292
[32m[0906 19-49-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33665, current rewards: 79.32882, mean: 0.03361
[32m[0906 19-49-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33605, current rewards: 81.94673, mean: 0.03400
[32m[0906 19-49-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33547, current rewards: 62.46511, mean: 0.02539
[32m[0906 19-49-45 @Agent.py:117][0m Average action selection time: 0.3351
[32m[0906 19-49-45 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-49-45 @MBExp.py:227][0m Rewards obtained: [22.465111221351577], Lows: [81], Highs: [101], Total time: 21493.040635999998
[32m[0906 19-50-35 @MBExp.py:144][0m ####################################################################
[32m[0906 19-50-35 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 19-50-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29765, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-50-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30532, current rewards: -15.53094, mean: -0.25885
[32m[0906 19-51-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30655, current rewards: -9.20424, mean: -0.08367
[32m[0906 19-51-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30803, current rewards: -2.48994, mean: -0.01556
[32m[0906 19-51-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30989, current rewards: 4.04342, mean: 0.01925
[32m[0906 19-51-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31083, current rewards: 10.69761, mean: 0.04114
[32m[0906 19-52-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31099, current rewards: 20.21313, mean: 0.06520
[32m[0906 19-52-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31062, current rewards: 26.79656, mean: 0.07443
[32m[0906 19-52-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31027, current rewards: 33.36392, mean: 0.08138
[32m[0906 19-52-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31012, current rewards: 39.93092, mean: 0.08681
[32m[0906 19-53-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31070, current rewards: 46.50141, mean: 0.09118
[32m[0906 19-53-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31115, current rewards: 53.06309, mean: 0.09476
[32m[0906 19-53-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31149, current rewards: 42.58138, mean: 0.06981
[32m[0906 19-54-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31180, current rewards: 22.88842, mean: 0.03468
[32m[0906 19-54-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31210, current rewards: 27.78490, mean: 0.03913
[32m[0906 19-54-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31229, current rewards: 33.32046, mean: 0.04384
[32m[0906 19-54-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31241, current rewards: 38.87991, mean: 0.04800
[32m[0906 19-55-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31254, current rewards: 44.43938, mean: 0.05167
[32m[0906 19-55-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31265, current rewards: 49.99616, mean: 0.05494
[32m[0906 19-55-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31274, current rewards: 55.55795, mean: 0.05787
[32m[0906 19-55-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31278, current rewards: 18.73383, mean: 0.01855
[32m[0906 19-56-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31283, current rewards: 23.92385, mean: 0.02257
[32m[0906 19-56-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31291, current rewards: 31.65073, mean: 0.02851
[32m[0906 19-56-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31295, current rewards: 36.84722, mean: 0.03176
[32m[0906 19-56-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31298, current rewards: 41.97697, mean: 0.03469
[32m[0906 19-57-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31301, current rewards: 47.10492, mean: 0.03738
[32m[0906 19-57-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31308, current rewards: 52.23254, mean: 0.03987
[32m[0906 19-57-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31310, current rewards: 57.36087, mean: 0.04218
[32m[0906 19-57-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31314, current rewards: 62.48831, mean: 0.04432
[32m[0906 19-58-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31314, current rewards: 67.61586, mean: 0.04631
[32m[0906 19-58-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31315, current rewards: 68.78599, mean: 0.04555
[32m[0906 19-58-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31319, current rewards: 39.64382, mean: 0.02541
[32m[0906 19-59-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31323, current rewards: 44.84302, mean: 0.02785
[32m[0906 19-59-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31326, current rewards: 49.98869, mean: 0.03011
[32m[0906 19-59-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31328, current rewards: 55.10248, mean: 0.03222
[32m[0906 19-59-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31331, current rewards: 60.21362, mean: 0.03421
[32m[0906 20-00-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31331, current rewards: 65.30822, mean: 0.03608
[32m[0906 20-00-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31332, current rewards: 70.41302, mean: 0.03786
[32m[0906 20-00-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31335, current rewards: 75.81405, mean: 0.03969
[32m[0906 20-00-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31335, current rewards: 83.24287, mean: 0.04247
[32m[0906 20-01-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31336, current rewards: 69.25832, mean: 0.03446
[32m[0906 20-01-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31337, current rewards: 51.39006, mean: 0.02495
[32m[0906 20-01-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31337, current rewards: 56.88903, mean: 0.02696
[32m[0906 20-01-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31339, current rewards: 62.39665, mean: 0.02889
[32m[0906 20-02-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31339, current rewards: 67.89986, mean: 0.03072
[32m[0906 20-02-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31338, current rewards: 73.40254, mean: 0.03248
[32m[0906 20-02-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31340, current rewards: 78.91396, mean: 0.03416
[32m[0906 20-02-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31331, current rewards: 82.87098, mean: 0.03511
[32m[0906 20-03-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31319, current rewards: 88.45191, mean: 0.03670
[32m[0906 20-03-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31308, current rewards: 93.86313, mean: 0.03816
[32m[0906 20-03-38 @Agent.py:117][0m Average action selection time: 0.3130
[32m[0906 20-03-38 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-03-38 @MBExp.py:227][0m Rewards obtained: [98.0865491348485], Lows: [68], Highs: [41], Total time: 22276.142698
[32m[0906 20-04-30 @MBExp.py:144][0m ####################################################################
[32m[0906 20-04-30 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 20-04-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29997, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-04-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30595, current rewards: -16.04591, mean: -0.26743
[32m[0906 20-05-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30742, current rewards: -12.63776, mean: -0.11489
[32m[0906 20-05-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30884, current rewards: -9.23607, mean: -0.05773
[32m[0906 20-05-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31071, current rewards: -5.83268, mean: -0.02777
[32m[0906 20-05-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31177, current rewards: -2.34850, mean: -0.00903
[32m[0906 20-06-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31209, current rewards: 2.76902, mean: 0.00893
[32m[0906 20-06-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31144, current rewards: -20.66930, mean: -0.05741
[32m[0906 20-06-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31112, current rewards: -43.44322, mean: -0.10596
[32m[0906 20-06-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31078, current rewards: -69.98162, mean: -0.15213
[32m[0906 20-07-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31136, current rewards: -87.93066, mean: -0.17241
[32m[0906 20-07-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31172, current rewards: -153.57724, mean: -0.27425
[32m[0906 20-07-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31207, current rewards: -215.06428, mean: -0.35256
[32m[0906 20-07-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31234, current rewards: -281.38826, mean: -0.42635
[32m[0906 20-08-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31255, current rewards: -295.48885, mean: -0.41618
[32m[0906 20-08-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31277, current rewards: -287.95572, mean: -0.37889
[32m[0906 20-08-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31292, current rewards: -280.86181, mean: -0.34674
[32m[0906 20-09-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31310, current rewards: -273.87145, mean: -0.31846
[32m[0906 20-09-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31322, current rewards: -276.02335, mean: -0.30332
[32m[0906 20-09-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31334, current rewards: -282.85538, mean: -0.29464
[32m[0906 20-09-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31341, current rewards: -277.51464, mean: -0.27477
[32m[0906 20-10-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31350, current rewards: -272.20813, mean: -0.25680
[32m[0906 20-10-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31356, current rewards: -267.02417, mean: -0.24056
[32m[0906 20-10-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31367, current rewards: -261.77581, mean: -0.22567
[32m[0906 20-10-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31371, current rewards: -279.28057, mean: -0.23081
[32m[0906 20-11-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31377, current rewards: -276.35939, mean: -0.21933
[32m[0906 20-11-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31377, current rewards: -273.51837, mean: -0.20879
[32m[0906 20-11-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31379, current rewards: -270.67666, mean: -0.19903
[32m[0906 20-11-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31384, current rewards: -267.83542, mean: -0.18995
[32m[0906 20-12-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31388, current rewards: -264.99328, mean: -0.18150
[32m[0906 20-12-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31394, current rewards: -296.97002, mean: -0.19667
[32m[0906 20-12-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31394, current rewards: -294.62020, mean: -0.18886
[32m[0906 20-12-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31391, current rewards: -291.65553, mean: -0.18115
[32m[0906 20-13-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31392, current rewards: -288.65681, mean: -0.17389
[32m[0906 20-13-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31401, current rewards: -285.69312, mean: -0.16707
[32m[0906 20-13-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31509, current rewards: -282.72577, mean: -0.16064
[32m[0906 20-14-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31607, current rewards: -279.76070, mean: -0.15456
[32m[0906 20-14-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31705, current rewards: -276.79413, mean: -0.14881
[32m[0906 20-14-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31796, current rewards: -283.40913, mean: -0.14838
[32m[0906 20-14-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31880, current rewards: -300.04946, mean: -0.15309
[32m[0906 20-15-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31959, current rewards: -314.33305, mean: -0.15638
[32m[0906 20-15-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32034, current rewards: -328.80204, mean: -0.15961
[32m[0906 20-15-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32104, current rewards: -343.15865, mean: -0.16263
[32m[0906 20-16-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32173, current rewards: -356.38558, mean: -0.16499
[32m[0906 20-16-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32237, current rewards: -369.83976, mean: -0.16735
[32m[0906 20-16-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32298, current rewards: -382.85376, mean: -0.16940
[32m[0906 20-16-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32355, current rewards: -436.40728, mean: -0.18892
[32m[0906 20-17-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32402, current rewards: -436.14599, mean: -0.18481
[32m[0906 20-17-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32441, current rewards: -431.11325, mean: -0.17889
[32m[0906 20-17-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32479, current rewards: -426.08336, mean: -0.17320
[32m[0906 20-18-04 @Agent.py:117][0m Average action selection time: 0.3251
[32m[0906 20-18-04 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-18-04 @MBExp.py:227][0m Rewards obtained: [-422.0588226424562], Lows: [165], Highs: [295], Total time: 23089.494313
[32m[0906 20-19-03 @MBExp.py:144][0m ####################################################################
[32m[0906 20-19-03 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 20-19-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33256, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-19-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34049, current rewards: -18.64281, mean: -0.31071
[32m[0906 20-19-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34231, current rewards: -12.83043, mean: -0.11664
[32m[0906 20-19-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34354, current rewards: -7.11729, mean: -0.04448
[32m[0906 20-20-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34573, current rewards: -1.41360, mean: -0.00673
[32m[0906 20-20-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34723, current rewards: 3.01727, mean: 0.01160
[32m[0906 20-20-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34772, current rewards: -33.82591, mean: -0.10912
[32m[0906 20-21-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34726, current rewards: -25.55004, mean: -0.07097
[32m[0906 20-21-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34684, current rewards: -16.81687, mean: -0.04102
[32m[0906 20-21-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34653, current rewards: -8.10662, mean: -0.01762
[32m[0906 20-22-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34704, current rewards: 0.58312, mean: 0.00114
[32m[0906 20-22-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34751, current rewards: 9.30388, mean: 0.01661
[32m[0906 20-22-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34801, current rewards: 18.03258, mean: 0.02956
[32m[0906 20-22-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34828, current rewards: 27.56196, mean: 0.04176
[32m[0906 20-23-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34848, current rewards: 44.39362, mean: 0.06253
[32m[0906 20-23-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34869, current rewards: 50.52647, mean: 0.06648
[32m[0906 20-23-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34880, current rewards: 56.48325, mean: 0.06973
[32m[0906 20-24-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34896, current rewards: 55.69616, mean: 0.06476
[32m[0906 20-24-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34908, current rewards: 42.26986, mean: 0.04645
[32m[0906 20-24-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34919, current rewards: 45.11917, mean: 0.04700
[32m[0906 20-24-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34936, current rewards: 47.97755, mean: 0.04750
[32m[0906 20-25-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34949, current rewards: 50.84154, mean: 0.04796
[32m[0906 20-25-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34960, current rewards: 53.91756, mean: 0.04857
[32m[0906 20-25-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34968, current rewards: 56.87248, mean: 0.04903
[32m[0906 20-26-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34973, current rewards: 59.81677, mean: 0.04944
[32m[0906 20-26-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34978, current rewards: 62.75706, mean: 0.04981
[32m[0906 20-26-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34985, current rewards: 65.70084, mean: 0.05015
[32m[0906 20-27-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34991, current rewards: 68.64708, mean: 0.05048
[32m[0906 20-27-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34996, current rewards: 73.26467, mean: 0.05196
[32m[0906 20-27-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35000, current rewards: 77.76699, mean: 0.05327
[32m[0906 20-27-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35003, current rewards: 81.82164, mean: 0.05419
[32m[0906 20-28-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35006, current rewards: 86.22169, mean: 0.05527
[32m[0906 20-28-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35010, current rewards: 78.08445, mean: 0.04850
[32m[0906 20-28-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35008, current rewards: 53.29325, mean: 0.03210
[32m[0906 20-29-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35011, current rewards: 58.34296, mean: 0.03412
[32m[0906 20-29-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35010, current rewards: 63.44639, mean: 0.03605
[32m[0906 20-29-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35015, current rewards: 68.54444, mean: 0.03787
[32m[0906 20-29-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35015, current rewards: 73.64154, mean: 0.03959
[32m[0906 20-30-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35021, current rewards: 77.65073, mean: 0.04065
[32m[0906 20-30-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35022, current rewards: 82.94972, mean: 0.04232
[32m[0906 20-30-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35024, current rewards: 88.63137, mean: 0.04410
[32m[0906 20-31-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35026, current rewards: 94.33650, mean: 0.04579
[32m[0906 20-31-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35029, current rewards: 100.04436, mean: 0.04741
[32m[0906 20-31-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35031, current rewards: 105.75084, mean: 0.04896
[32m[0906 20-31-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35030, current rewards: 111.45745, mean: 0.05043
[32m[0906 20-32-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35030, current rewards: 117.16510, mean: 0.05184
[32m[0906 20-32-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35031, current rewards: 99.60541, mean: 0.04312
[32m[0906 20-32-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35022, current rewards: 78.35821, mean: 0.03320
[32m[0906 20-33-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35007, current rewards: 57.18575, mean: 0.02373
[32m[0906 20-33-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34993, current rewards: 7.18575, mean: 0.00292
[32m[0906 20-33-39 @Agent.py:117][0m Average action selection time: 0.3498
[32m[0906 20-33-39 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-33-39 @MBExp.py:227][0m Rewards obtained: [-32.814249986908365], Lows: [71], Highs: [155], Total time: 23964.760754
[32m[0906 20-34-40 @MBExp.py:144][0m ####################################################################
[32m[0906 20-34-40 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 20-34-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33512, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-35-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34035, current rewards: -16.99034, mean: -0.28317
[32m[0906 20-35-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34242, current rewards: -12.57322, mean: -0.11430
[32m[0906 20-35-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34372, current rewards: -8.15845, mean: -0.05099
[32m[0906 20-35-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34566, current rewards: -3.74662, mean: -0.01784
[32m[0906 20-36-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34690, current rewards: -6.40939, mean: -0.02465
[32m[0906 20-36-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34725, current rewards: -18.64081, mean: -0.06013
[32m[0906 20-36-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35082, current rewards: -11.79230, mean: -0.03276
[32m[0906 20-37-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34994, current rewards: -4.86106, mean: -0.01186
[32m[0906 20-37-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34925, current rewards: 2.07158, mean: 0.00450
[32m[0906 20-37-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34946, current rewards: 8.99513, mean: 0.01764
[32m[0906 20-37-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34973, current rewards: 15.93104, mean: 0.02845
[32m[0906 20-38-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34994, current rewards: 22.85653, mean: 0.03747
[32m[0906 20-38-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35009, current rewards: 28.37866, mean: 0.04300
[32m[0906 20-38-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35026, current rewards: 34.86158, mean: 0.04910
[32m[0906 20-39-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35046, current rewards: 13.35642, mean: 0.01757
[32m[0906 20-39-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35051, current rewards: 2.57135, mean: 0.00317
[32m[0906 20-39-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35051, current rewards: 7.06496, mean: 0.00822
[32m[0906 20-40-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35055, current rewards: 11.55701, mean: 0.01270
[32m[0906 20-40-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35060, current rewards: 16.05324, mean: 0.01672
[32m[0906 20-40-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35057, current rewards: 20.54548, mean: 0.02034
[32m[0906 20-40-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35054, current rewards: 26.21040, mean: 0.02473
[32m[0906 20-41-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35054, current rewards: 30.99442, mean: 0.02792
[32m[0906 20-41-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35061, current rewards: -6.33441, mean: -0.00546
[32m[0906 20-41-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35066, current rewards: -2.30598, mean: -0.00191
[32m[0906 20-42-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35068, current rewards: 1.72258, mean: 0.00137
[32m[0906 20-42-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35071, current rewards: 5.75177, mean: 0.00439
[32m[0906 20-42-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35074, current rewards: 9.78096, mean: 0.00719
[32m[0906 20-42-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35073, current rewards: 13.81007, mean: 0.00979
[32m[0906 20-43-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35073, current rewards: -4.29730, mean: -0.00294
[32m[0906 20-43-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35076, current rewards: 0.89274, mean: 0.00059
[32m[0906 20-43-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35074, current rewards: 6.03716, mean: 0.00387
[32m[0906 20-44-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35075, current rewards: 10.99965, mean: 0.00683
[32m[0906 20-44-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35077, current rewards: 16.05093, mean: 0.00967
[32m[0906 20-44-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35088, current rewards: 21.05742, mean: 0.01231
[32m[0906 20-44-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35145, current rewards: 26.07194, mean: 0.01481
[32m[0906 20-45-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35208, current rewards: 30.18969, mean: 0.01668
[32m[0906 20-45-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35268, current rewards: 36.72034, mean: 0.01974
[32m[0906 20-45-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35324, current rewards: 45.92119, mean: 0.02404
[32m[0906 20-46-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35375, current rewards: 50.55203, mean: 0.02579
[32m[0906 20-46-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35426, current rewards: 55.19976, mean: 0.02746
[32m[0906 20-46-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35475, current rewards: 59.85264, mean: 0.02905
[32m[0906 20-47-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35522, current rewards: 64.51045, mean: 0.03057
[32m[0906 20-47-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35570, current rewards: 67.06697, mean: 0.03105
[32m[0906 20-47-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35611, current rewards: 32.08361, mean: 0.01452
[32m[0906 20-48-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35635, current rewards: 36.36215, mean: 0.01609
[32m[0906 20-48-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35622, current rewards: 33.47118, mean: 0.01449
[32m[0906 20-48-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35599, current rewards: 38.33387, mean: 0.01624
[32m[0906 20-48-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35571, current rewards: 43.27148, mean: 0.01795
[32m[0906 20-49-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35545, current rewards: 48.21778, mean: 0.01960
[32m[0906 20-49-29 @Agent.py:117][0m Average action selection time: 0.3553
[32m[0906 20-49-29 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-49-29 @MBExp.py:227][0m Rewards obtained: [45.87463102203229], Lows: [64], Highs: [67], Total time: 24853.588407
[32m[0906 20-50-33 @MBExp.py:144][0m ####################################################################
[32m[0906 20-50-33 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 20-50-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33224, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-50-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33894, current rewards: -13.06912, mean: -0.21782
[32m[0906 20-51-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34137, current rewards: -8.41944, mean: -0.07654
[32m[0906 20-51-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34292, current rewards: -3.87598, mean: -0.02422
[32m[0906 20-51-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34508, current rewards: 0.53499, mean: 0.00255
[32m[0906 20-52-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34635, current rewards: 4.77503, mean: 0.01837
[32m[0906 20-52-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34655, current rewards: 9.07089, mean: 0.02926
[32m[0906 20-52-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34615, current rewards: 13.36914, mean: 0.03714
[32m[0906 20-52-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34582, current rewards: -17.79314, mean: -0.04340
[32m[0906 20-53-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34550, current rewards: -36.38492, mean: -0.07910
[32m[0906 20-53-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34595, current rewards: -30.99341, mean: -0.06077
[32m[0906 20-53-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34654, current rewards: -25.89443, mean: -0.04624
[32m[0906 20-54-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34702, current rewards: -20.82296, mean: -0.03414
[32m[0906 20-54-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34737, current rewards: -15.75335, mean: -0.02387
[32m[0906 20-54-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34773, current rewards: -10.67967, mean: -0.01504
[32m[0906 20-54-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34796, current rewards: -5.60853, mean: -0.00738
[32m[0906 20-55-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34811, current rewards: -20.47354, mean: -0.02528
[32m[0906 20-55-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34833, current rewards: -15.25872, mean: -0.01774
[32m[0906 20-55-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34852, current rewards: -10.17620, mean: -0.01118
[32m[0906 20-56-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34865, current rewards: -5.10045, mean: -0.00531
[32m[0906 20-56-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34880, current rewards: -9.91976, mean: -0.00982
[32m[0906 20-56-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34896, current rewards: -23.31918, mean: -0.02200
[32m[0906 20-57-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34906, current rewards: -12.07190, mean: -0.01088
[32m[0906 20-57-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34913, current rewards: -5.02117, mean: -0.00433
[32m[0906 20-57-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34921, current rewards: -41.19286, mean: -0.03404
[32m[0906 20-57-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34927, current rewards: -74.76885, mean: -0.05934
[32m[0906 20-58-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34929, current rewards: -65.17282, mean: -0.04975
[32m[0906 20-58-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34935, current rewards: -55.55782, mean: -0.04085
[32m[0906 20-58-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34940, current rewards: -46.21594, mean: -0.03278
[32m[0906 20-59-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34946, current rewards: -40.80240, mean: -0.02795
[32m[0906 20-59-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34948, current rewards: -33.55971, mean: -0.02222
[32m[0906 20-59-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34950, current rewards: -26.30909, mean: -0.01686
[32m[0906 20-59-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34952, current rewards: -19.05976, mean: -0.01184
[32m[0906 21-00-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34957, current rewards: -34.73220, mean: -0.02092
[32m[0906 21-00-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34960, current rewards: -27.00730, mean: -0.01579
[32m[0906 21-00-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34964, current rewards: -0.91533, mean: -0.00052
[32m[0906 21-01-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34967, current rewards: 37.19550, mean: 0.02055
[32m[0906 21-01-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34969, current rewards: -15.79178, mean: -0.00849
[32m[0906 21-01-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34970, current rewards: -4.38949, mean: -0.00230
[32m[0906 21-01-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34973, current rewards: 4.14336, mean: 0.00211
[32m[0906 21-02-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34974, current rewards: 12.33416, mean: 0.00614
[32m[0906 21-02-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34975, current rewards: -67.25624, mean: -0.03265
[32m[0906 21-02-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34979, current rewards: -54.98345, mean: -0.02606
[32m[0906 21-03-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34983, current rewards: -45.53429, mean: -0.02108
[32m[0906 21-03-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34986, current rewards: -35.97178, mean: -0.01628
[32m[0906 21-03-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34987, current rewards: -26.41418, mean: -0.01169
[32m[0906 21-04-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34988, current rewards: -16.86694, mean: -0.00730
[32m[0906 21-04-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34978, current rewards: -7.31404, mean: -0.00310
[32m[0906 21-04-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34964, current rewards: -25.78729, mean: -0.01070
[32m[0906 21-04-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34950, current rewards: -20.82461, mean: -0.00847
[32m[0906 21-05-07 @Agent.py:117][0m Average action selection time: 0.3494
[32m[0906 21-05-07 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-05-07 @MBExp.py:227][0m Rewards obtained: [-16.900125917797244], Lows: [155], Highs: [102], Total time: 25727.774073
[32m[0906 21-06-13 @MBExp.py:144][0m ####################################################################
[32m[0906 21-06-13 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 21-06-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33204, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-06-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33878, current rewards: -15.52956, mean: -0.25883
[32m[0906 21-06-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34122, current rewards: -10.51367, mean: -0.09558
[32m[0906 21-07-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34252, current rewards: -5.26909, mean: -0.03293
[32m[0906 21-07-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34497, current rewards: -17.77525, mean: -0.08464
[32m[0906 21-07-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34628, current rewards: -17.10817, mean: -0.06580
[32m[0906 21-08-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34677, current rewards: -12.23113, mean: -0.03946
[32m[0906 21-08-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34634, current rewards: -7.35353, mean: -0.02043
[32m[0906 21-08-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34603, current rewards: -2.47200, mean: -0.00603
[32m[0906 21-08-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34585, current rewards: 2.40391, mean: 0.00523
[32m[0906 21-09-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34614, current rewards: 7.28043, mean: 0.01428
[32m[0906 21-09-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34676, current rewards: 11.93491, mean: 0.02131
[32m[0906 21-09-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34716, current rewards: -8.35111, mean: -0.01369
[32m[0906 21-10-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34757, current rewards: -29.07166, mean: -0.04405
[32m[0906 21-10-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34785, current rewards: -24.59827, mean: -0.03465
[32m[0906 21-10-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34813, current rewards: -20.10681, mean: -0.02646
[32m[0906 21-10-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34834, current rewards: -15.61559, mean: -0.01928
[32m[0906 21-11-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34853, current rewards: -11.12611, mean: -0.01294
[32m[0906 21-11-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34870, current rewards: -6.63643, mean: -0.00729
[32m[0906 21-11-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34883, current rewards: -6.50539, mean: -0.00678
[32m[0906 21-12-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34895, current rewards: -35.92894, mean: -0.03557
[32m[0906 21-12-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34910, current rewards: -29.21107, mean: -0.02756
[32m[0906 21-12-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34923, current rewards: -24.12406, mean: -0.02173
[32m[0906 21-12-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34933, current rewards: -19.03579, mean: -0.01641
[32m[0906 21-13-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34944, current rewards: -13.94462, mean: -0.01152
[32m[0906 21-13-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34951, current rewards: -15.46260, mean: -0.01227
[32m[0906 21-13-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34958, current rewards: -26.94371, mean: -0.02057
[32m[0906 21-14-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34961, current rewards: -15.85506, mean: -0.01166
[32m[0906 21-14-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34967, current rewards: -6.90651, mean: -0.00490
[32m[0906 21-14-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34971, current rewards: -1.78729, mean: -0.00122
[32m[0906 21-15-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34977, current rewards: 3.89295, mean: 0.00258
[32m[0906 21-15-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34982, current rewards: 9.56140, mean: 0.00613
[32m[0906 21-15-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34985, current rewards: 13.12310, mean: 0.00815
[32m[0906 21-15-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34991, current rewards: -23.89067, mean: -0.01439
[32m[0906 21-16-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35001, current rewards: -18.52679, mean: -0.01083
[32m[0906 21-16-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35003, current rewards: -13.21271, mean: -0.00751
[32m[0906 21-16-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35005, current rewards: -7.90055, mean: -0.00436
[32m[0906 21-17-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35009, current rewards: 4.04152, mean: 0.00217
[32m[0906 21-17-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35011, current rewards: 10.21920, mean: 0.00535
[32m[0906 21-17-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35017, current rewards: 16.39688, mean: 0.00837
[32m[0906 21-17-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35017, current rewards: 22.57456, mean: 0.01123
[32m[0906 21-18-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35020, current rewards: 28.75224, mean: 0.01396
[32m[0906 21-18-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35020, current rewards: -2.14735, mean: -0.00102
[32m[0906 21-18-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35025, current rewards: -52.14735, mean: -0.02414
[32m[0906 21-19-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35025, current rewards: -102.14735, mean: -0.04622
[32m[0906 21-19-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35025, current rewards: -152.14735, mean: -0.06732
[32m[0906 21-19-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35026, current rewards: -202.14735, mean: -0.08751
[32m[0906 21-20-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35020, current rewards: -252.14735, mean: -0.10684
[32m[0906 21-20-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35005, current rewards: -302.14735, mean: -0.12537
[32m[0906 21-20-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34992, current rewards: -352.14735, mean: -0.14315
[32m[0906 21-20-48 @Agent.py:117][0m Average action selection time: 0.3498
[32m[0906 21-20-48 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-20-48 @MBExp.py:227][0m Rewards obtained: [-392.1473461267545], Lows: [56], Highs: [508], Total time: 26602.961284
[32m[0906 21-21-55 @MBExp.py:144][0m ####################################################################
[32m[0906 21-21-55 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 21-21-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33274, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-22-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33831, current rewards: -22.30200, mean: -0.37170
[32m[0906 21-22-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34076, current rewards: -17.80122, mean: -0.16183
[32m[0906 21-22-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34244, current rewards: -13.32207, mean: -0.08326
[32m[0906 21-23-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34492, current rewards: -9.20228, mean: -0.04382
[32m[0906 21-23-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34663, current rewards: -5.05940, mean: -0.01946
[32m[0906 21-23-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34696, current rewards: -0.92039, mean: -0.00297
[32m[0906 21-24-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34653, current rewards: 3.21944, mean: 0.00894
[32m[0906 21-24-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34624, current rewards: 7.36486, mean: 0.01796
[32m[0906 21-24-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34607, current rewards: 11.50812, mean: 0.02502
[32m[0906 21-24-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34626, current rewards: 15.64846, mean: 0.03068
[32m[0906 21-25-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34681, current rewards: -1.86846, mean: -0.00334
[32m[0906 21-25-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34734, current rewards: -28.06737, mean: -0.04601
[32m[0906 21-25-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34787, current rewards: -24.43222, mean: -0.03702
[32m[0906 21-26-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34819, current rewards: -20.98843, mean: -0.02956
[32m[0906 21-26-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34846, current rewards: -17.54920, mean: -0.02309
[32m[0906 21-26-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34870, current rewards: -14.10951, mean: -0.01742
[32m[0906 21-26-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34890, current rewards: -10.66721, mean: -0.01240
[32m[0906 21-27-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34908, current rewards: -7.22200, mean: -0.00794
[32m[0906 21-27-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34924, current rewards: -3.77646, mean: -0.00393
[32m[0906 21-27-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34935, current rewards: 1.18833, mean: 0.00118
[32m[0906 21-28-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34956, current rewards: 5.76874, mean: 0.00544
[32m[0906 21-28-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34971, current rewards: 10.23913, mean: 0.00922
[32m[0906 21-28-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34984, current rewards: 14.70471, mean: 0.01268
[32m[0906 21-28-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34996, current rewards: -22.61475, mean: -0.01869
[32m[0906 21-29-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35003, current rewards: -19.86165, mean: -0.01576
[32m[0906 21-29-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35011, current rewards: -14.63656, mean: -0.01117
[32m[0906 21-29-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35019, current rewards: -9.38082, mean: -0.00690
[32m[0906 21-30-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35026, current rewards: -4.41548, mean: -0.00313
[32m[0906 21-30-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35029, current rewards: -16.15695, mean: -0.01107
[32m[0906 21-30-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35034, current rewards: -11.78559, mean: -0.00781
[32m[0906 21-31-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35040, current rewards: -7.02649, mean: -0.00450
[32m[0906 21-31-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35042, current rewards: -2.25881, mean: -0.00140
[32m[0906 21-31-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35048, current rewards: 2.50628, mean: 0.00151
[32m[0906 21-31-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35057, current rewards: 7.27586, mean: 0.00425
[32m[0906 21-32-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35059, current rewards: 12.04329, mean: 0.00684
[32m[0906 21-32-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35063, current rewards: 16.80928, mean: 0.00929
[32m[0906 21-32-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35066, current rewards: 25.39203, mean: 0.01365
[32m[0906 21-33-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35070, current rewards: 9.70844, mean: 0.00508
[32m[0906 21-33-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35086, current rewards: 15.46425, mean: 0.00789
[32m[0906 21-33-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35089, current rewards: 20.01034, mean: 0.00996
[32m[0906 21-33-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35096, current rewards: -33.67606, mean: -0.01635
[32m[0906 21-34-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35096, current rewards: -133.67606, mean: -0.06335
[32m[0906 21-34-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35098, current rewards: -233.67606, mean: -0.10818
[32m[0906 21-34-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35098, current rewards: -333.67606, mean: -0.15098
[32m[0906 21-35-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35099, current rewards: -433.67606, mean: -0.19189
[32m[0906 21-35-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35103, current rewards: -533.67606, mean: -0.23103
[32m[0906 21-35-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35092, current rewards: -633.67606, mean: -0.26851
[32m[0906 21-36-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35076, current rewards: -733.67606, mean: -0.30443
[32m[0906 21-36-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35062, current rewards: -833.67606, mean: -0.33889
[32m[0906 21-36-32 @Agent.py:117][0m Average action selection time: 0.3505
[32m[0906 21-36-32 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-36-32 @MBExp.py:227][0m Rewards obtained: [-913.6760560475027], Lows: [493], Highs: [109], Total time: 27479.903708
[32m[0906 21-37-42 @MBExp.py:144][0m ####################################################################
[32m[0906 21-37-42 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 21-37-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33558, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-38-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33961, current rewards: -24.07342, mean: -0.40122
[32m[0906 21-38-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34144, current rewards: -19.76945, mean: -0.17972
[32m[0906 21-38-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34286, current rewards: -15.35251, mean: -0.09595
[32m[0906 21-38-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34519, current rewards: -11.32822, mean: -0.05394
[32m[0906 21-39-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34637, current rewards: -7.00490, mean: -0.02694
[32m[0906 21-39-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34636, current rewards: -2.68113, mean: -0.00865
[32m[0906 21-39-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34593, current rewards: 1.64843, mean: 0.00458
[32m[0906 21-40-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34557, current rewards: -35.83909, mean: -0.08741
[32m[0906 21-40-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34530, current rewards: -68.86700, mean: -0.14971
[32m[0906 21-40-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34557, current rewards: -89.06541, mean: -0.17464
[32m[0906 21-40-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34617, current rewards: -139.06541, mean: -0.24833
[32m[0906 21-41-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34672, current rewards: -189.06541, mean: -0.30994
[32m[0906 21-41-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34713, current rewards: -239.06541, mean: -0.36222
[32m[0906 21-41-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34745, current rewards: -289.06541, mean: -0.40713
[32m[0906 21-42-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34775, current rewards: -338.01473, mean: -0.44476
[32m[0906 21-42-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34805, current rewards: -356.05747, mean: -0.43958
[32m[0906 21-42-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34827, current rewards: -353.27801, mean: -0.41079
[32m[0906 21-42-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34843, current rewards: -350.74973, mean: -0.38544
[32m[0906 21-43-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34852, current rewards: -370.10168, mean: -0.38552
[32m[0906 21-43-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34870, current rewards: -367.44086, mean: -0.36380
[32m[0906 21-43-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34889, current rewards: -386.90332, mean: -0.36500
[32m[0906 21-44-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34905, current rewards: -384.17004, mean: -0.34610
[32m[0906 21-44-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34918, current rewards: -401.62261, mean: -0.34623
[32m[0906 21-44-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34930, current rewards: -400.93559, mean: -0.33135
[32m[0906 21-45-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34942, current rewards: -415.99869, mean: -0.33016
[32m[0906 21-45-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34946, current rewards: -406.44843, mean: -0.31027
[32m[0906 21-45-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34955, current rewards: -397.78498, mean: -0.29249
[32m[0906 21-45-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34964, current rewards: -387.88845, mean: -0.27510
[32m[0906 21-46-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34968, current rewards: -378.28620, mean: -0.25910
[32m[0906 21-46-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34972, current rewards: -368.68171, mean: -0.24416
[32m[0906 21-46-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34977, current rewards: -367.85665, mean: -0.23581
[32m[0906 21-47-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34982, current rewards: -395.62002, mean: -0.24573
[32m[0906 21-47-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34986, current rewards: -390.26352, mean: -0.23510
[32m[0906 21-47-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34991, current rewards: -384.91655, mean: -0.22510
[32m[0906 21-47-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34993, current rewards: -379.56872, mean: -0.21566
[32m[0906 21-48-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34995, current rewards: -375.44455, mean: -0.20743
[32m[0906 21-48-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34999, current rewards: -370.73144, mean: -0.19932
[32m[0906 21-48-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35003, current rewards: -365.50624, mean: -0.19136
[32m[0906 21-49-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35007, current rewards: -360.48779, mean: -0.18392
[32m[0906 21-49-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35011, current rewards: -397.54842, mean: -0.19779
[32m[0906 21-49-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35012, current rewards: -393.10159, mean: -0.19083
[32m[0906 21-50-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35014, current rewards: -388.57502, mean: -0.18416
[32m[0906 21-50-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35016, current rewards: -384.04848, mean: -0.17780
[32m[0906 21-50-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35017, current rewards: -379.52237, mean: -0.17173
[32m[0906 21-50-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35019, current rewards: -367.08428, mean: -0.16243
[32m[0906 21-51-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35022, current rewards: -361.39938, mean: -0.15645
[32m[0906 21-51-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35012, current rewards: -355.72770, mean: -0.15073
[32m[0906 21-51-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34999, current rewards: -350.05730, mean: -0.14525
[32m[0906 21-52-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34984, current rewards: -344.38675, mean: -0.13999
[32m[0906 21-52-17 @Agent.py:117][0m Average action selection time: 0.3497
[32m[0906 21-52-17 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-52-17 @MBExp.py:227][0m Rewards obtained: [-339.85043014407836], Lows: [66], Highs: [428], Total time: 28354.908924000003
[32m[0906 21-53-28 @MBExp.py:144][0m ####################################################################
[32m[0906 21-53-28 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 21-53-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33228, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-53-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33819, current rewards: -16.36794, mean: -0.27280
[32m[0906 21-54-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34075, current rewards: -12.39976, mean: -0.11273
[32m[0906 21-54-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34254, current rewards: -7.80976, mean: -0.04881
[32m[0906 21-54-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34445, current rewards: -3.91799, mean: -0.01866
[32m[0906 21-54-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34617, current rewards: -0.00988, mean: -0.00004
[32m[0906 21-55-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34642, current rewards: 3.90015, mean: 0.01258
[32m[0906 21-55-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34620, current rewards: 7.81029, mean: 0.02170
[32m[0906 21-55-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34591, current rewards: 17.31457, mean: 0.04223
[32m[0906 21-56-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34562, current rewards: 22.19801, mean: 0.04826
[32m[0906 21-56-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34566, current rewards: 26.39516, mean: 0.05176
[32m[0906 21-56-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34636, current rewards: 30.56799, mean: 0.05459
[32m[0906 21-57-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34690, current rewards: 34.87527, mean: 0.05717
[32m[0906 21-57-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34731, current rewards: 39.22964, mean: 0.05944
[32m[0906 21-57-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34761, current rewards: 43.52969, mean: 0.06131
[32m[0906 21-57-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34794, current rewards: 47.74194, mean: 0.06282
[32m[0906 21-58-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34822, current rewards: 51.87304, mean: 0.06404
[32m[0906 21-58-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34841, current rewards: 56.05363, mean: 0.06518
[32m[0906 21-58-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34866, current rewards: 60.39972, mean: 0.06637
[32m[0906 21-59-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34885, current rewards: 35.66780, mean: 0.03715
[32m[0906 21-59-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34902, current rewards: 31.24455, mean: 0.03094
[32m[0906 21-59-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34912, current rewards: 36.48924, mean: 0.03442
[32m[0906 21-59-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34917, current rewards: 41.73393, mean: 0.03760
[32m[0906 22-00-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34932, current rewards: 46.97861, mean: 0.04050
[32m[0906 22-00-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34936, current rewards: 52.22330, mean: 0.04316
[32m[0906 22-00-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34944, current rewards: 57.46799, mean: 0.04561
[32m[0906 22-01-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34948, current rewards: 62.71268, mean: 0.04787
[32m[0906 22-01-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34955, current rewards: 28.18119, mean: 0.02072
[32m[0906 22-01-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34960, current rewards: -21.81881, mean: -0.01547
[32m[0906 22-01-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34965, current rewards: -71.81881, mean: -0.04919
[32m[0906 22-02-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34970, current rewards: -121.81881, mean: -0.08067
[32m[0906 22-02-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34970, current rewards: -171.81881, mean: -0.11014
[32m[0906 22-02-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34973, current rewards: -221.81881, mean: -0.13778
[32m[0906 22-03-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34978, current rewards: -271.81881, mean: -0.16375
[32m[0906 22-03-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34982, current rewards: -321.81881, mean: -0.18820
[32m[0906 22-03-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34985, current rewards: -371.81881, mean: -0.21126
[32m[0906 22-04-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34986, current rewards: -421.81881, mean: -0.23305
[32m[0906 22-04-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34986, current rewards: -471.81881, mean: -0.25367
[32m[0906 22-04-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34986, current rewards: -521.81881, mean: -0.27320
[32m[0906 22-04-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34986, current rewards: -571.81881, mean: -0.29174
[32m[0906 22-05-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34986, current rewards: -621.81881, mean: -0.30936
[32m[0906 22-05-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34988, current rewards: -671.81881, mean: -0.32613
[32m[0906 22-05-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34988, current rewards: -721.81881, mean: -0.34209
[32m[0906 22-06-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34989, current rewards: -771.81881, mean: -0.35732
[32m[0906 22-06-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34992, current rewards: -821.81881, mean: -0.37186
[32m[0906 22-06-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34993, current rewards: -871.81881, mean: -0.38576
[32m[0906 22-06-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34996, current rewards: -921.81881, mean: -0.39906
[32m[0906 22-07-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34985, current rewards: -971.81881, mean: -0.41179
[32m[0906 22-07-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34970, current rewards: -1021.81881, mean: -0.42399
[32m[0906 22-07-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34955, current rewards: -1071.81881, mean: -0.43570
[32m[0906 22-08-03 @Agent.py:117][0m Average action selection time: 0.3494
[32m[0906 22-08-03 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-08-03 @MBExp.py:227][0m Rewards obtained: [-1111.8188123074287], Lows: [20], Highs: [1196], Total time: 29229.205366000002
[32m[0906 22-09-16 @MBExp.py:144][0m ####################################################################
[32m[0906 22-09-16 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 22-09-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33287, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-09-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33823, current rewards: -26.12781, mean: -0.43546
[32m[0906 22-09-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34048, current rewards: -20.93800, mean: -0.19035
[32m[0906 22-10-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34219, current rewards: -16.00711, mean: -0.10004
[32m[0906 22-10-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34444, current rewards: -10.91841, mean: -0.05199
[32m[0906 22-10-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34609, current rewards: -5.82806, mean: -0.02242
[32m[0906 22-11-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34628, current rewards: -0.73713, mean: -0.00238
[32m[0906 22-11-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34598, current rewards: 4.35289, mean: 0.01209
[32m[0906 22-11-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34573, current rewards: 9.43965, mean: 0.02302
[32m[0906 22-11-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34549, current rewards: 14.53265, mean: 0.03159
[32m[0906 22-12-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34556, current rewards: -21.21740, mean: -0.04160
[32m[0906 22-12-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34621, current rewards: -39.73846, mean: -0.07096
[32m[0906 22-12-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34675, current rewards: -34.60023, mean: -0.05672
[32m[0906 22-13-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34703, current rewards: -29.71942, mean: -0.04503
[32m[0906 22-13-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34741, current rewards: -24.84675, mean: -0.03500
[32m[0906 22-13-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34772, current rewards: -19.97316, mean: -0.02628
[32m[0906 22-13-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34793, current rewards: -15.09167, mean: -0.01863
[32m[0906 22-14-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34819, current rewards: -10.21596, mean: -0.01188
[32m[0906 22-14-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34833, current rewards: -5.34225, mean: -0.00587
[32m[0906 22-14-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34847, current rewards: 0.99029, mean: 0.00103
[32m[0906 22-15-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34864, current rewards: 6.11490, mean: 0.00605
[32m[0906 22-15-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34880, current rewards: 11.08977, mean: 0.01046
[32m[0906 22-15-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34894, current rewards: 9.46714, mean: 0.00853
[32m[0906 22-16-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34897, current rewards: -0.98231, mean: -0.00085
[32m[0906 22-16-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34905, current rewards: 3.46619, mean: 0.00286
[32m[0906 22-16-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34913, current rewards: 7.91557, mean: 0.00628
[32m[0906 22-16-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34917, current rewards: 12.36059, mean: 0.00944
[32m[0906 22-17-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34921, current rewards: 16.95966, mean: 0.01247
[32m[0906 22-17-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34928, current rewards: 21.43749, mean: 0.01520
[32m[0906 22-17-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34935, current rewards: 25.89851, mean: 0.01774
[32m[0906 22-18-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34941, current rewards: 30.35873, mean: 0.02011
[32m[0906 22-18-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34943, current rewards: 34.82202, mean: 0.02232
[32m[0906 22-18-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34950, current rewards: 39.28551, mean: 0.02440
[32m[0906 22-18-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34951, current rewards: 22.06301, mean: 0.01329
[32m[0906 22-19-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34954, current rewards: 26.42056, mean: 0.01545
[32m[0906 22-19-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34959, current rewards: 30.43911, mean: 0.01729
[32m[0906 22-19-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34963, current rewards: 34.59698, mean: 0.01911
[32m[0906 22-20-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34966, current rewards: 39.00555, mean: 0.02097
[32m[0906 22-20-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34971, current rewards: 43.39216, mean: 0.02272
[32m[0906 22-20-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34971, current rewards: 47.78057, mean: 0.02438
[32m[0906 22-21-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34974, current rewards: 52.16710, mean: 0.02595
[32m[0906 22-21-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34977, current rewards: 56.55955, mean: 0.02746
[32m[0906 22-21-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34978, current rewards: 60.94831, mean: 0.02889
[32m[0906 22-21-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34983, current rewards: 65.34826, mean: 0.03025
[32m[0906 22-22-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34984, current rewards: 73.66612, mean: 0.03333
[32m[0906 22-22-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34985, current rewards: 57.19249, mean: 0.02531
[32m[0906 22-22-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34986, current rewards: 43.40559, mean: 0.01879
[32m[0906 22-23-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34977, current rewards: 48.91926, mean: 0.02073
[32m[0906 22-23-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34962, current rewards: 54.41740, mean: 0.02258
[32m[0906 22-23-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34950, current rewards: 59.91558, mean: 0.02436
[32m[0906 22-23-50 @Agent.py:117][0m Average action selection time: 0.3494
[32m[0906 22-23-50 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-23-50 @MBExp.py:227][0m Rewards obtained: [64.31301327189821], Lows: [47], Highs: [81], Total time: 30103.371085000002
[32m[0906 22-25-06 @MBExp.py:144][0m ####################################################################
[32m[0906 22-25-06 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 22-25-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33192, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-25-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33754, current rewards: -97.02388, mean: -1.61706
[32m[0906 22-25-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34042, current rewards: -197.02388, mean: -1.79113
[32m[0906 22-26-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34211, current rewards: -297.02388, mean: -1.85640
[32m[0906 22-26-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34429, current rewards: -397.02388, mean: -1.89059
[32m[0906 22-26-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34590, current rewards: -497.02388, mean: -1.91163
[32m[0906 22-26-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34591, current rewards: -597.02388, mean: -1.92588
[32m[0906 22-27-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34554, current rewards: -697.02388, mean: -1.93618
[32m[0906 22-27-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34527, current rewards: -797.02388, mean: -1.94396
[32m[0906 22-27-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34507, current rewards: -897.02388, mean: -1.95005
[32m[0906 22-28-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34504, current rewards: -997.02388, mean: -1.95495
[32m[0906 22-28-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34578, current rewards: -1097.02388, mean: -1.95897
[32m[0906 22-28-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34632, current rewards: -1197.02388, mean: -1.96233
[32m[0906 22-28-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34678, current rewards: -1297.02388, mean: -1.96519
[32m[0906 22-29-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34718, current rewards: -1397.02388, mean: -1.96764
[32m[0906 22-29-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34749, current rewards: -1497.02388, mean: -1.96977
[32m[0906 22-29-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34777, current rewards: -1597.02388, mean: -1.97163
[32m[0906 22-30-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34806, current rewards: -1697.02388, mean: -1.97328
[32m[0906 22-30-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34831, current rewards: -1797.02388, mean: -1.97475
[32m[0906 22-30-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34855, current rewards: -1897.02388, mean: -1.97607
[32m[0906 22-30-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34868, current rewards: -1997.02388, mean: -1.97725
[32m[0906 22-31-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34888, current rewards: -2097.02388, mean: -1.97832
[32m[0906 22-31-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34901, current rewards: -2197.02388, mean: -1.97930
[32m[0906 22-31-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34909, current rewards: -2297.02388, mean: -1.98019
[32m[0906 22-32-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34921, current rewards: -2397.02388, mean: -1.98101
[32m[0906 22-32-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34928, current rewards: -2497.02388, mean: -1.98176
[32m[0906 22-32-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34935, current rewards: -2597.02388, mean: -1.98246
[32m[0906 22-33-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34943, current rewards: -2697.02388, mean: -1.98311
[32m[0906 22-33-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34950, current rewards: -2797.02388, mean: -1.98370
[32m[0906 22-33-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34957, current rewards: -2897.02388, mean: -1.98426
[32m[0906 22-33-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34964, current rewards: -2997.02388, mean: -1.98478
[32m[0906 22-34-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34971, current rewards: -3097.02388, mean: -1.98527
[32m[0906 22-34-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34978, current rewards: -3197.02388, mean: -1.98573
[32m[0906 22-34-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34985, current rewards: -3297.02388, mean: -1.98616
[32m[0906 22-35-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34989, current rewards: -3397.02388, mean: -1.98656
[32m[0906 22-35-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34991, current rewards: -3497.02388, mean: -1.98695
[32m[0906 22-35-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34992, current rewards: -3597.02388, mean: -1.98731
[32m[0906 22-35-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34996, current rewards: -3697.02388, mean: -1.98765
[32m[0906 22-36-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35001, current rewards: -3797.02388, mean: -1.98797
[32m[0906 22-36-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35003, current rewards: -3897.02388, mean: -1.98828
[32m[0906 22-36-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35008, current rewards: -3997.02388, mean: -1.98857
[32m[0906 22-37-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35010, current rewards: -4097.02388, mean: -1.98885
[32m[0906 22-37-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35012, current rewards: -4197.02388, mean: -1.98911
[32m[0906 22-37-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35011, current rewards: -4297.02388, mean: -1.98936
[32m[0906 22-38-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35013, current rewards: -4397.02388, mean: -1.98960
[32m[0906 22-38-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35016, current rewards: -4497.02388, mean: -1.98983
[32m[0906 22-38-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35017, current rewards: -4597.02388, mean: -1.99005
[32m[0906 22-38-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35007, current rewards: -4697.02388, mean: -1.99026
[32m[0906 22-39-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34990, current rewards: -4797.02388, mean: -1.99047
[32m[0906 22-39-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34977, current rewards: -4897.02388, mean: -1.99066
[32m[0906 22-39-40 @Agent.py:117][0m Average action selection time: 0.3496
[32m[0906 22-39-40 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-39-41 @MBExp.py:227][0m Rewards obtained: [-4977.0238756793115], Lows: [2479], Highs: [20], Total time: 30978.177502000002
[32m[0906 22-40-58 @MBExp.py:144][0m ####################################################################
[32m[0906 22-40-58 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 22-41-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33063, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-41-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33697, current rewards: -14.83337, mean: -0.24722
[32m[0906 22-41-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34020, current rewards: -9.54990, mean: -0.08682
[32m[0906 22-41-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34205, current rewards: -4.19210, mean: -0.02620
[32m[0906 22-42-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34491, current rewards: 0.96835, mean: 0.00461
[32m[0906 22-42-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34613, current rewards: 6.12560, mean: 0.02356
[32m[0906 22-42-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34614, current rewards: 11.28084, mean: 0.03639
[32m[0906 22-43-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34589, current rewards: -6.87077, mean: -0.01909
[32m[0906 22-43-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34553, current rewards: -2.05351, mean: -0.00501
[32m[0906 22-43-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34531, current rewards: 2.55154, mean: 0.00555
[32m[0906 22-43-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34512, current rewards: 7.16396, mean: 0.01405
[32m[0906 22-44-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34582, current rewards: 11.77825, mean: 0.02103
[32m[0906 22-44-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34637, current rewards: 16.39036, mean: 0.02687
[32m[0906 22-44-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34679, current rewards: 21.00583, mean: 0.03183
[32m[0906 22-45-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34728, current rewards: 25.61921, mean: 0.03608
[32m[0906 22-45-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34746, current rewards: 30.23002, mean: 0.03978
[32m[0906 22-45-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34775, current rewards: 34.84443, mean: 0.04302
[32m[0906 22-45-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34791, current rewards: 37.38803, mean: 0.04347
[32m[0906 22-46-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34806, current rewards: 47.69111, mean: 0.05241
[32m[0906 22-46-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34817, current rewards: 56.17530, mean: 0.05852
[32m[0906 22-46-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34840, current rewards: 64.67532, mean: 0.06403
[32m[0906 22-47-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34851, current rewards: 73.16887, mean: 0.06903
[32m[0906 22-47-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34866, current rewards: 81.64861, mean: 0.07356
[32m[0906 22-47-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34885, current rewards: 90.12274, mean: 0.07769
[32m[0906 22-48-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34897, current rewards: 53.82570, mean: 0.04448
[32m[0906 22-48-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34900, current rewards: 59.88293, mean: 0.04753
[32m[0906 22-48-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34907, current rewards: 67.13866, mean: 0.05125
[32m[0906 22-48-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34916, current rewards: 73.70479, mean: 0.05419
[32m[0906 22-49-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34925, current rewards: 53.88386, mean: 0.03822
[32m[0906 22-49-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34928, current rewards: 58.85704, mean: 0.04031
[32m[0906 22-49-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34935, current rewards: 63.76575, mean: 0.04223
[32m[0906 22-50-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34942, current rewards: 68.66632, mean: 0.04402
[32m[0906 22-50-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34947, current rewards: 73.57136, mean: 0.04570
[32m[0906 22-50-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34950, current rewards: 78.46583, mean: 0.04727
[32m[0906 22-50-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34953, current rewards: 41.37860, mean: 0.02420
[32m[0906 22-51-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34958, current rewards: 44.31379, mean: 0.02518
[32m[0906 22-51-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34964, current rewards: 49.07251, mean: 0.02711
[32m[0906 22-51-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34965, current rewards: 53.81941, mean: 0.02894
[32m[0906 22-52-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34966, current rewards: 58.56220, mean: 0.03066
[32m[0906 22-52-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34969, current rewards: 63.30557, mean: 0.03230
[32m[0906 22-52-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34973, current rewards: 68.05145, mean: 0.03386
[32m[0906 22-52-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34976, current rewards: 72.79627, mean: 0.03534
[32m[0906 22-53-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34980, current rewards: 77.53846, mean: 0.03675
[32m[0906 22-53-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34986, current rewards: 81.98090, mean: 0.03795
[32m[0906 22-53-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34990, current rewards: 86.70494, mean: 0.03923
[32m[0906 22-54-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34995, current rewards: 91.42602, mean: 0.04045
[32m[0906 22-54-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34999, current rewards: 96.14495, mean: 0.04162
[32m[0906 22-54-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34994, current rewards: 100.86360, mean: 0.04274
[32m[0906 22-55-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34981, current rewards: 105.58360, mean: 0.04381
[32m[0906 22-55-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34969, current rewards: 85.87190, mean: 0.03491
[32m[0906 22-55-33 @Agent.py:117][0m Average action selection time: 0.3496
[32m[0906 22-55-33 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-55-33 @MBExp.py:227][0m Rewards obtained: [88.47347674455403], Lows: [47], Highs: [86], Total time: 31852.826452
[32m[0906 22-56-52 @MBExp.py:144][0m ####################################################################
[32m[0906 22-56-52 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 22-56-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33189, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-57-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33599, current rewards: -17.49675, mean: -0.29161
[32m[0906 22-57-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33922, current rewards: -12.27360, mean: -0.11158
[32m[0906 22-57-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34142, current rewards: -6.93023, mean: -0.04331
[32m[0906 22-58-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34387, current rewards: -1.58948, mean: -0.00757
[32m[0906 22-58-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34558, current rewards: 3.75608, mean: 0.01445
[32m[0906 22-58-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34558, current rewards: 9.09842, mean: 0.02935
[32m[0906 22-58-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34540, current rewards: 14.44234, mean: 0.04012
[32m[0906 22-59-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34515, current rewards: 19.78656, mean: 0.04826
[32m[0906 22-59-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34495, current rewards: 25.13050, mean: 0.05463
[32m[0906 22-59-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34478, current rewards: 30.47594, mean: 0.05976
[32m[0906 23-00-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34547, current rewards: 35.82177, mean: 0.06397
[32m[0906 23-00-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34600, current rewards: 41.16661, mean: 0.06749
[32m[0906 23-00-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34652, current rewards: 46.51267, mean: 0.07047
[32m[0906 23-00-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34690, current rewards: 51.85754, mean: 0.07304
[32m[0906 23-01-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34722, current rewards: 57.20020, mean: 0.07526
[32m[0906 23-01-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34759, current rewards: 58.33177, mean: 0.07201
[32m[0906 23-01-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34780, current rewards: 24.81327, mean: 0.02885
[32m[0906 23-02-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34798, current rewards: 29.49535, mean: 0.03241
[32m[0906 23-02-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34822, current rewards: 34.09826, mean: 0.03552
[32m[0906 23-02-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34837, current rewards: 38.71463, mean: 0.03833
[32m[0906 23-03-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34855, current rewards: 43.32461, mean: 0.04087
[32m[0906 23-03-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34873, current rewards: 47.93466, mean: 0.04318
[32m[0906 23-03-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34889, current rewards: 51.45321, mean: 0.04436
[32m[0906 23-03-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34898, current rewards: 33.59250, mean: 0.02776
[32m[0906 23-04-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34906, current rewards: 37.39699, mean: 0.02968
[32m[0906 23-04-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34919, current rewards: 41.37342, mean: 0.03158
[32m[0906 23-04-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34930, current rewards: 45.31429, mean: 0.03332
[32m[0906 23-05-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34940, current rewards: 49.25223, mean: 0.03493
[32m[0906 23-05-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34949, current rewards: 53.18977, mean: 0.03643
[32m[0906 23-05-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34957, current rewards: 35.56226, mean: 0.02355
[32m[0906 23-05-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34962, current rewards: 39.02395, mean: 0.02502
[32m[0906 23-06-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34966, current rewards: 42.77477, mean: 0.02657
[32m[0906 23-06-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34971, current rewards: 46.60986, mean: 0.02808
[32m[0906 23-06-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34976, current rewards: 54.20584, mean: 0.03170
[32m[0906 23-07-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34981, current rewards: 58.77653, mean: 0.03340
[32m[0906 23-07-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34987, current rewards: 42.44788, mean: 0.02345
[32m[0906 23-07-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34991, current rewards: 26.38471, mean: 0.01419
[32m[0906 23-08-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34995, current rewards: 30.90749, mean: 0.01618
[32m[0906 23-08-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34999, current rewards: 35.43579, mean: 0.01808
[32m[0906 23-08-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35003, current rewards: 42.51493, mean: 0.02115
[32m[0906 23-08-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35005, current rewards: 56.86437, mean: 0.02760
[32m[0906 23-09-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35007, current rewards: 61.28347, mean: 0.02904
[32m[0906 23-09-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35010, current rewards: 66.44941, mean: 0.03076
[32m[0906 23-09-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35010, current rewards: 71.89356, mean: 0.03253
[32m[0906 23-10-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35011, current rewards: 77.33964, mean: 0.03422
[32m[0906 23-10-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35015, current rewards: 82.78523, mean: 0.03584
[32m[0906 23-10-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35006, current rewards: 88.23256, mean: 0.03739
[32m[0906 23-10-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34992, current rewards: 93.67848, mean: 0.03887
[32m[0906 23-11-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34978, current rewards: 56.69225, mean: 0.02305
[32m[0906 23-11-27 @Agent.py:117][0m Average action selection time: 0.3497
[32m[0906 23-11-27 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-11-27 @MBExp.py:227][0m Rewards obtained: [60.90776822483741], Lows: [64], Highs: [61], Total time: 32727.765851
[32m[0906 23-12-49 @MBExp.py:144][0m ####################################################################
[32m[0906 23-12-49 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 23-12-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33400, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-13-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33720, current rewards: -15.50464, mean: -0.25841
[32m[0906 23-13-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34030, current rewards: -10.68565, mean: -0.09714
[32m[0906 23-13-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34236, current rewards: -5.84342, mean: -0.03652
[32m[0906 23-14-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34499, current rewards: -1.00289, mean: -0.00478
[32m[0906 23-14-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34634, current rewards: 3.83749, mean: 0.01476
[32m[0906 23-14-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34638, current rewards: 8.68178, mean: 0.02801
[32m[0906 23-14-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34611, current rewards: 13.51937, mean: 0.03755
[32m[0906 23-15-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34581, current rewards: 5.19957, mean: 0.01268
[32m[0906 23-15-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34555, current rewards: 0.96635, mean: 0.00210
[32m[0906 23-15-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34541, current rewards: 5.07811, mean: 0.00996
[32m[0906 23-16-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34589, current rewards: 9.14836, mean: 0.01634
[32m[0906 23-16-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34643, current rewards: 13.22235, mean: 0.02168
[32m[0906 23-16-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34691, current rewards: 17.29247, mean: 0.02620
[32m[0906 23-16-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34735, current rewards: 21.36377, mean: 0.03009
[32m[0906 23-17-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34764, current rewards: 25.43530, mean: 0.03347
[32m[0906 23-17-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34796, current rewards: 29.50712, mean: 0.03643
[32m[0906 23-17-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34818, current rewards: 36.16277, mean: 0.04205
[32m[0906 23-18-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34833, current rewards: 41.94406, mean: 0.04609
[32m[0906 23-18-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34852, current rewards: 24.47653, mean: 0.02550
[32m[0906 23-18-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34872, current rewards: 27.96242, mean: 0.02769
[32m[0906 23-18-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34889, current rewards: 31.05263, mean: 0.02929
[32m[0906 23-19-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34901, current rewards: 34.13991, mean: 0.03076
[32m[0906 23-19-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34914, current rewards: 37.22876, mean: 0.03209
[32m[0906 23-19-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34919, current rewards: 1.44647, mean: 0.00120
[32m[0906 23-20-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34928, current rewards: 7.42260, mean: 0.00589
[32m[0906 23-20-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34936, current rewards: 15.07768, mean: 0.01151
[32m[0906 23-20-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34942, current rewards: 22.73276, mean: 0.01672
[32m[0906 23-21-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34948, current rewards: 30.38784, mean: 0.02155
[32m[0906 23-21-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34955, current rewards: 38.04292, mean: 0.02606
[32m[0906 23-21-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34958, current rewards: 45.69800, mean: 0.03026
[32m[0906 23-21-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34963, current rewards: 53.35308, mean: 0.03420
[32m[0906 23-22-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34970, current rewards: 26.41512, mean: 0.01641
[32m[0906 23-22-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34978, current rewards: -23.58488, mean: -0.01421
[32m[0906 23-22-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34980, current rewards: -73.58488, mean: -0.04303
[32m[0906 23-23-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34985, current rewards: -123.58488, mean: -0.07022
[32m[0906 23-23-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34986, current rewards: -173.58488, mean: -0.09590
[32m[0906 23-23-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34987, current rewards: -223.58488, mean: -0.12021
[32m[0906 23-23-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34990, current rewards: -273.58488, mean: -0.14324
[32m[0906 23-24-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34991, current rewards: -323.58488, mean: -0.16509
[32m[0906 23-24-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34990, current rewards: -373.58488, mean: -0.18586
[32m[0906 23-24-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34993, current rewards: -403.24339, mean: -0.19575
[32m[0906 23-25-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34995, current rewards: -399.04348, mean: -0.18912
[32m[0906 23-25-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34997, current rewards: -394.37101, mean: -0.18258
[32m[0906 23-25-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35002, current rewards: -389.71164, mean: -0.17634
[32m[0906 23-26-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35005, current rewards: -385.04926, mean: -0.17038
[32m[0906 23-26-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35007, current rewards: -380.38548, mean: -0.16467
[32m[0906 23-26-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34995, current rewards: -375.72989, mean: -0.15921
[32m[0906 23-26-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34979, current rewards: -371.07651, mean: -0.15397
[32m[0906 23-27-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34966, current rewards: -390.27499, mean: -0.15865
[32m[0906 23-27-23 @Agent.py:117][0m Average action selection time: 0.3496
[32m[0906 23-27-23 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-27-23 @MBExp.py:227][0m Rewards obtained: [-389.5934535147516], Lows: [23], Highs: [546], Total time: 33602.361165
[32m[0906 23-28-47 @MBExp.py:144][0m ####################################################################
[32m[0906 23-28-47 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 23-28-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33286, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-29-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33607, current rewards: -14.84962, mean: -0.24749
[32m[0906 23-29-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33962, current rewards: -9.04336, mean: -0.08221
[32m[0906 23-29-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34171, current rewards: -3.24795, mean: -0.02030
[32m[0906 23-29-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34433, current rewards: 2.55855, mean: 0.01218
[32m[0906 23-30-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34603, current rewards: 8.36584, mean: 0.03218
[32m[0906 23-30-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34588, current rewards: 14.17015, mean: 0.04571
[32m[0906 23-30-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34554, current rewards: 19.97281, mean: 0.05548
[32m[0906 23-31-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34539, current rewards: 25.35377, mean: 0.06184
[32m[0906 23-31-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34519, current rewards: 29.84531, mean: 0.06488
[32m[0906 23-31-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34504, current rewards: 35.55658, mean: 0.06972
[32m[0906 23-32-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34570, current rewards: 41.26402, mean: 0.07369
[32m[0906 23-32-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34618, current rewards: 15.26595, mean: 0.02503
[32m[0906 23-32-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34669, current rewards: 10.38211, mean: 0.01573
[32m[0906 23-32-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34709, current rewards: 15.68943, mean: 0.02210
[32m[0906 23-33-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34750, current rewards: 20.99326, mean: 0.02762
[32m[0906 23-33-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34787, current rewards: 26.30918, mean: 0.03248
[32m[0906 23-33-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34809, current rewards: -15.88709, mean: -0.01847
[32m[0906 23-34-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34826, current rewards: -7.59182, mean: -0.00834
[32m[0906 23-34-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34845, current rewards: -43.72528, mean: -0.04555
[32m[0906 23-34-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34865, current rewards: -35.63898, mean: -0.03529
[32m[0906 23-34-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34881, current rewards: -29.03075, mean: -0.02739
[32m[0906 23-35-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34898, current rewards: -22.42251, mean: -0.02020
[32m[0906 23-35-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34905, current rewards: -15.81428, mean: -0.01363
[32m[0906 23-35-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34912, current rewards: -26.18852, mean: -0.02164
[32m[0906 23-36-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34923, current rewards: -76.18852, mean: -0.06047
[32m[0906 23-36-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34930, current rewards: -126.18852, mean: -0.09633
[32m[0906 23-36-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34936, current rewards: -176.18852, mean: -0.12955
[32m[0906 23-37-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34946, current rewards: -226.18852, mean: -0.16042
[32m[0906 23-37-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34955, current rewards: -276.18852, mean: -0.18917
[32m[0906 23-37-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34962, current rewards: -326.18852, mean: -0.21602
[32m[0906 23-37-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34971, current rewards: -376.18852, mean: -0.24115
[32m[0906 23-38-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34979, current rewards: -426.18852, mean: -0.26471
[32m[0906 23-38-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34983, current rewards: -476.18852, mean: -0.28686
[32m[0906 23-38-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34988, current rewards: -526.18852, mean: -0.30771
[32m[0906 23-39-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34994, current rewards: -576.18852, mean: -0.32738
[32m[0906 23-39-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34993, current rewards: -626.18852, mean: -0.34596
[32m[0906 23-39-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34998, current rewards: -676.18852, mean: -0.36354
[32m[0906 23-39-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35001, current rewards: -726.18852, mean: -0.38020
[32m[0906 23-40-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35007, current rewards: -776.18852, mean: -0.39601
[32m[0906 23-40-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35007, current rewards: -826.18852, mean: -0.41104
[32m[0906 23-40-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35009, current rewards: -876.18852, mean: -0.42533
[32m[0906 23-41-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35013, current rewards: -926.18852, mean: -0.43895
[32m[0906 23-41-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35013, current rewards: -976.18852, mean: -0.45194
[32m[0906 23-41-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35016, current rewards: -1026.18852, mean: -0.46434
[32m[0906 23-41-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35018, current rewards: -1076.18852, mean: -0.47619
[32m[0906 23-42-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35020, current rewards: -1126.18852, mean: -0.48753
[32m[0906 23-42-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35013, current rewards: -1176.18852, mean: -0.49838
[32m[0906 23-42-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35000, current rewards: -1226.18852, mean: -0.50879
[32m[0906 23-43-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34989, current rewards: -1276.18852, mean: -0.51878
[32m[0906 23-43-22 @Agent.py:117][0m Average action selection time: 0.3498
[32m[0906 23-43-22 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-43-22 @MBExp.py:227][0m Rewards obtained: [-1316.1885171125077], Lows: [65], Highs: [1325], Total time: 34477.517772
[32m[0906 23-44-48 @MBExp.py:144][0m ####################################################################
[32m[0906 23-44-48 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 23-44-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33101, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-45-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33485, current rewards: -55.84812, mean: -0.93080
[32m[0906 23-45-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33901, current rewards: -57.38190, mean: -0.52165
[32m[0906 23-45-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34152, current rewards: -60.95646, mean: -0.38098
[32m[0906 23-46-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34417, current rewards: -75.60814, mean: -0.36004
[32m[0906 23-46-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34570, current rewards: -94.03120, mean: -0.36166
[32m[0906 23-46-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34556, current rewards: -140.09237, mean: -0.45191
[32m[0906 23-46-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34534, current rewards: -163.74169, mean: -0.45484
[32m[0906 23-47-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34512, current rewards: -217.07656, mean: -0.52946
[32m[0906 23-47-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34504, current rewards: -231.22760, mean: -0.50267
[32m[0906 23-47-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34491, current rewards: -262.69595, mean: -0.51509
[32m[0906 23-48-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34553, current rewards: -303.13412, mean: -0.54131
[32m[0906 23-48-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34621, current rewards: -342.22511, mean: -0.56102
[32m[0906 23-48-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34667, current rewards: -373.67313, mean: -0.56617
[32m[0906 23-48-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34716, current rewards: -443.19581, mean: -0.62422
[32m[0906 23-49-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34758, current rewards: -543.19581, mean: -0.71473
[32m[0906 23-49-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34791, current rewards: -643.19581, mean: -0.79407
[32m[0906 23-49-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34812, current rewards: -743.19581, mean: -0.86418
[32m[0906 23-50-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34844, current rewards: -843.19581, mean: -0.92659
[32m[0906 23-50-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34871, current rewards: -943.19581, mean: -0.98250
[32m[0906 23-50-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34892, current rewards: -1043.19581, mean: -1.03287
[32m[0906 23-50-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34911, current rewards: -1143.19581, mean: -1.07849
[32m[0906 23-51-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34924, current rewards: -1243.19581, mean: -1.12000
[32m[0906 23-51-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34935, current rewards: -1343.19581, mean: -1.15793
[32m[0906 23-51-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34946, current rewards: -1443.19581, mean: -1.19272
[32m[0906 23-52-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34957, current rewards: -1543.19581, mean: -1.22476
[32m[0906 23-52-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34967, current rewards: -1643.19581, mean: -1.25435
[32m[0906 23-52-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34975, current rewards: -1743.19581, mean: -1.28176
[32m[0906 23-53-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34982, current rewards: -1843.19581, mean: -1.30723
[32m[0906 23-53-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34988, current rewards: -1943.19581, mean: -1.33096
[32m[0906 23-53-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34992, current rewards: -2043.19581, mean: -1.35311
[32m[0906 23-53-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34998, current rewards: -2143.19581, mean: -1.37384
[32m[0906 23-54-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35003, current rewards: -2243.19581, mean: -1.39329
[32m[0906 23-54-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35005, current rewards: -2343.19581, mean: -1.41156
[32m[0906 23-54-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35010, current rewards: -2443.19581, mean: -1.42877
[32m[0906 23-55-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35012, current rewards: -2543.19581, mean: -1.44500
[32m[0906 23-55-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35012, current rewards: -2643.19581, mean: -1.46033
[32m[0906 23-55-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35014, current rewards: -2743.19581, mean: -1.47484
[32m[0906 23-55-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35017, current rewards: -2843.19581, mean: -1.48858
[32m[0906 23-56-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35021, current rewards: -2943.19581, mean: -1.50163
[32m[0906 23-56-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35026, current rewards: -3043.19581, mean: -1.51403
[32m[0906 23-56-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35032, current rewards: -3143.19581, mean: -1.52582
[32m[0906 23-57-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35037, current rewards: -3243.19581, mean: -1.53706
[32m[0906 23-57-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35038, current rewards: -3343.19581, mean: -1.54778
[32m[0906 23-57-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35041, current rewards: -3443.19581, mean: -1.55801
[32m[0906 23-58-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35040, current rewards: -3543.19581, mean: -1.56779
[32m[0906 23-58-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35042, current rewards: -3643.19581, mean: -1.57714
[32m[0906 23-58-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35030, current rewards: -3743.19581, mean: -1.58610
[32m[0906 23-58-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35014, current rewards: -3843.19581, mean: -1.59469
[32m[0906 23-59-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34999, current rewards: -3943.19581, mean: -1.60293
[32m[0906 23-59-23 @Agent.py:117][0m Average action selection time: 0.3499
[32m[0906 23-59-23 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-59-23 @MBExp.py:227][0m Rewards obtained: [-4023.1958065843214], Lows: [1916], Highs: [243], Total time: 35352.91869
[32m[0907 00-00-50 @MBExp.py:144][0m ####################################################################
[32m[0907 00-00-50 @MBExp.py:145][0m Starting training iteration 43.
[32m[0907 00-00-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33348, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-01-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33581, current rewards: -20.53774, mean: -0.34230
[32m[0907 00-01-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33936, current rewards: -15.61447, mean: -0.14195
[32m[0907 00-01-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34177, current rewards: -10.72879, mean: -0.06705
[32m[0907 00-02-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34429, current rewards: -5.84094, mean: -0.02781
[32m[0907 00-02-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34551, current rewards: -0.95574, mean: -0.00368
[32m[0907 00-02-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34515, current rewards: 3.92766, mean: 0.01267
[32m[0907 00-02-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34486, current rewards: 11.94383, mean: 0.03318
[32m[0907 00-03-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34481, current rewards: 16.66367, mean: 0.04064
[32m[0907 00-03-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34466, current rewards: 21.39330, mean: 0.04651
[32m[0907 00-03-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34458, current rewards: 26.12067, mean: 0.05122
[32m[0907 00-04-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34505, current rewards: -10.45848, mean: -0.01868
[32m[0907 00-04-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34558, current rewards: -5.05677, mean: -0.00829
[32m[0907 00-04-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34606, current rewards: 0.35050, mean: 0.00053
[32m[0907 00-04-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34644, current rewards: 5.75775, mean: 0.00811
[32m[0907 00-05-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34682, current rewards: 10.77516, mean: 0.01418
[32m[0907 00-05-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34711, current rewards: 16.25044, mean: 0.02006
[32m[0907 00-05-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34736, current rewards: -21.94434, mean: -0.02552
[32m[0907 00-06-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34758, current rewards: -16.00280, mean: -0.01759
[32m[0907 00-06-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34780, current rewards: -10.13074, mean: -0.01055
[32m[0907 00-06-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34794, current rewards: -4.25945, mean: -0.00422
[32m[0907 00-07-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34809, current rewards: 1.61212, mean: 0.00152
[32m[0907 00-07-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34828, current rewards: -17.31754, mean: -0.01560
[32m[0907 00-07-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34842, current rewards: -24.66955, mean: -0.02127
[32m[0907 00-07-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34856, current rewards: -32.59415, mean: -0.02694
[32m[0907 00-08-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34866, current rewards: -29.86876, mean: -0.02371
[32m[0907 00-08-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34880, current rewards: -26.40350, mean: -0.02016
[32m[0907 00-08-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34882, current rewards: -22.94687, mean: -0.01687
[32m[0907 00-09-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34889, current rewards: -19.30013, mean: -0.01369
[32m[0907 00-09-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34893, current rewards: -15.73839, mean: -0.01078
[32m[0907 00-09-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34898, current rewards: -12.25454, mean: -0.00812
[32m[0907 00-09-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34901, current rewards: -8.81882, mean: -0.00565
[32m[0907 00-10-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34905, current rewards: -2.71761, mean: -0.00169
[32m[0907 00-10-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34908, current rewards: 0.69497, mean: 0.00042
[32m[0907 00-10-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34916, current rewards: 4.26155, mean: 0.00249
[32m[0907 00-11-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34920, current rewards: 7.67069, mean: 0.00436
[32m[0907 00-11-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34925, current rewards: 7.10533, mean: 0.00393
[32m[0907 00-11-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34931, current rewards: -25.58228, mean: -0.01375
[32m[0907 00-11-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34934, current rewards: -20.67091, mean: -0.01082
[32m[0907 00-12-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34938, current rewards: -15.70409, mean: -0.00801
[32m[0907 00-12-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34943, current rewards: -11.47676, mean: -0.00571
[32m[0907 00-12-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34948, current rewards: -6.94000, mean: -0.00337
[32m[0907 00-13-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34952, current rewards: -2.02894, mean: -0.00096
[32m[0907 00-13-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34956, current rewards: 2.88159, mean: 0.00133
[32m[0907 00-13-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34959, current rewards: 7.79430, mean: 0.00353
[32m[0907 00-14-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34962, current rewards: 12.70449, mean: 0.00562
[32m[0907 00-14-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34966, current rewards: -6.26448, mean: -0.00271
[32m[0907 00-14-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34957, current rewards: -1.02546, mean: -0.00043
[32m[0907 00-14-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34944, current rewards: 4.76442, mean: 0.00198
[32m[0907 00-15-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34932, current rewards: 10.92831, mean: 0.00444
[32m[0907 00-15-24 @Agent.py:117][0m Average action selection time: 0.3492
[32m[0907 00-15-24 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-15-24 @MBExp.py:227][0m Rewards obtained: [15.395211192873266], Lows: [66], Highs: [83], Total time: 36226.698073
[32m[0907 00-16-54 @MBExp.py:144][0m ####################################################################
[32m[0907 00-16-54 @MBExp.py:145][0m Starting training iteration 44.
[32m[0907 00-16-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33404, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-17-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34302, current rewards: -17.86894, mean: -0.29782
[32m[0907 00-17-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35013, current rewards: -16.40240, mean: -0.14911
[32m[0907 00-17-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35267, current rewards: -18.23125, mean: -0.11395
[32m[0907 00-18-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35575, current rewards: -19.28947, mean: -0.09185
[32m[0907 00-18-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35772, current rewards: -30.12333, mean: -0.11586
[32m[0907 00-18-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35846, current rewards: -39.11795, mean: -0.12619
[32m[0907 00-19-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35799, current rewards: -53.64012, mean: -0.14900
[32m[0907 00-19-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35869, current rewards: -66.99178, mean: -0.16339
[32m[0907 00-19-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35784, current rewards: -80.50001, mean: -0.17500
[32m[0907 00-19-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35836, current rewards: -96.16786, mean: -0.18856
[32m[0907 00-20-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35982, current rewards: -108.94240, mean: -0.19454
[32m[0907 00-20-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36015, current rewards: -128.54972, mean: -0.21074
[32m[0907 00-20-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35969, current rewards: -129.50406, mean: -0.19622
[32m[0907 00-21-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35916, current rewards: -120.30101, mean: -0.16944
[32m[0907 00-21-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35871, current rewards: -155.60242, mean: -0.20474
[32m[0907 00-21-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35835, current rewards: -145.42546, mean: -0.17954
[32m[0907 00-22-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35803, current rewards: -135.05051, mean: -0.15704
[32m[0907 00-22-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35781, current rewards: -124.78263, mean: -0.13712
[32m[0907 00-22-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35750, current rewards: -135.08067, mean: -0.14071
[32m[0907 00-22-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35722, current rewards: -133.15210, mean: -0.13183
[32m[0907 00-23-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35694, current rewards: -127.51205, mean: -0.12029
[32m[0907 00-23-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35667, current rewards: -121.88131, mean: -0.10980
[32m[0907 00-23-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35645, current rewards: -117.16182, mean: -0.10100
[32m[0907 00-24-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35624, current rewards: -111.99122, mean: -0.09255
[32m[0907 00-24-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35606, current rewards: -106.69422, mean: -0.08468
[32m[0907 00-24-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35587, current rewards: -137.19850, mean: -0.10473
[32m[0907 00-24-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35571, current rewards: -143.35380, mean: -0.10541
[32m[0907 00-25-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35556, current rewards: -141.57300, mean: -0.10041
[32m[0907 00-25-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35544, current rewards: -139.88960, mean: -0.09581
[32m[0907 00-25-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35532, current rewards: -140.22943, mean: -0.09287
[32m[0907 00-26-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35515, current rewards: -137.72110, mean: -0.08828
[32m[0907 00-26-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35502, current rewards: -175.17204, mean: -0.10880
[32m[0907 00-26-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35487, current rewards: -213.26555, mean: -0.12847
[32m[0907 00-27-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35475, current rewards: -251.75598, mean: -0.14723
[32m[0907 00-27-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35465, current rewards: -305.65971, mean: -0.17367
[32m[0907 00-27-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35453, current rewards: -361.69311, mean: -0.19983
[32m[0907 00-27-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35444, current rewards: -399.72972, mean: -0.21491
[32m[0907 00-28-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35436, current rewards: -398.67822, mean: -0.20873
[32m[0907 00-28-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35429, current rewards: -394.58052, mean: -0.20132
[32m[0907 00-28-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35420, current rewards: -391.15981, mean: -0.19461
[32m[0907 00-29-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35415, current rewards: -387.38303, mean: -0.18805
[32m[0907 00-29-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35409, current rewards: -383.58497, mean: -0.18179
[32m[0907 00-29-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35403, current rewards: -379.80415, mean: -0.17584
[32m[0907 00-29-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35399, current rewards: -376.01284, mean: -0.17014
[32m[0907 00-30-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35393, current rewards: -372.22639, mean: -0.16470
[32m[0907 00-30-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35386, current rewards: -368.44092, mean: -0.15950
[32m[0907 00-30-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35362, current rewards: -362.13776, mean: -0.15345
[32m[0907 00-31-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35340, current rewards: -357.45823, mean: -0.14832
[32m[0907 00-31-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35318, current rewards: -352.21353, mean: -0.14318
[32m[0907 00-31-37 @Agent.py:117][0m Average action selection time: 0.3530
[32m[0907 00-31-37 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-31-37 @MBExp.py:227][0m Rewards obtained: [-348.01349359551534], Lows: [292], Highs: [81], Total time: 37109.940378
[32m[0907 00-33-08 @MBExp.py:144][0m ####################################################################
[32m[0907 00-33-08 @MBExp.py:145][0m Starting training iteration 45.
[32m[0907 00-33-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33226, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-33-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33895, current rewards: -22.55018, mean: -0.37584
[32m[0907 00-33-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34064, current rewards: -16.99523, mean: -0.15450
[32m[0907 00-34-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34402, current rewards: -11.51897, mean: -0.07199
[32m[0907 00-34-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34602, current rewards: -6.04115, mean: -0.02877
[32m[0907 00-34-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34606, current rewards: -0.56670, mean: -0.00218
[32m[0907 00-34-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34570, current rewards: -43.22807, mean: -0.13945
[32m[0907 00-35-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34550, current rewards: -33.88134, mean: -0.09411
[32m[0907 00-35-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34531, current rewards: -17.75365, mean: -0.04330
[32m[0907 00-35-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34515, current rewards: 12.96530, mean: 0.02819
[32m[0907 00-36-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34517, current rewards: 43.67999, mean: 0.08565
[32m[0907 00-36-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34578, current rewards: 74.98152, mean: 0.13390
[32m[0907 00-36-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34632, current rewards: 50.73342, mean: 0.08317
[32m[0907 00-36-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34679, current rewards: 56.53593, mean: 0.08566
[32m[0907 00-37-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34723, current rewards: 62.39599, mean: 0.08788
[32m[0907 00-37-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34756, current rewards: 68.24884, mean: 0.08980
[32m[0907 00-37-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34790, current rewards: 74.10146, mean: 0.09148
[32m[0907 00-38-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34820, current rewards: 79.95788, mean: 0.09297
[32m[0907 00-38-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34843, current rewards: 85.81112, mean: 0.09430
[32m[0907 00-38-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34857, current rewards: 91.66175, mean: 0.09548
[32m[0907 00-39-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34873, current rewards: 97.51642, mean: 0.09655
[32m[0907 00-39-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34884, current rewards: 103.37078, mean: 0.09752
[32m[0907 00-39-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34894, current rewards: 65.29498, mean: 0.05882
[32m[0907 00-39-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34899, current rewards: 72.29656, mean: 0.06232
[32m[0907 00-40-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34903, current rewards: 76.66555, mean: 0.06336
[32m[0907 00-40-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34912, current rewards: 81.01522, mean: 0.06430
[32m[0907 00-40-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34920, current rewards: 85.36010, mean: 0.06516
[32m[0907 00-41-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34929, current rewards: 89.71746, mean: 0.06597
[32m[0907 00-41-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34937, current rewards: 94.09265, mean: 0.06673
[32m[0907 00-41-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34941, current rewards: 98.47064, mean: 0.06745
[32m[0907 00-41-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34948, current rewards: 103.62352, mean: 0.06862
[32m[0907 00-42-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34952, current rewards: 111.63168, mean: 0.07156
[32m[0907 00-42-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34955, current rewards: 118.47706, mean: 0.07359
[32m[0907 00-42-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34957, current rewards: 101.58702, mean: 0.06120
[32m[0907 00-43-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34964, current rewards: 86.75836, mean: 0.05074
[32m[0907 00-43-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34971, current rewards: 93.21718, mean: 0.05296
[32m[0907 00-43-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34976, current rewards: 99.67600, mean: 0.05507
[32m[0907 00-44-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34983, current rewards: 106.13483, mean: 0.05706
[32m[0907 00-44-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34986, current rewards: 78.71836, mean: 0.04121
[32m[0907 00-44-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34992, current rewards: 28.71836, mean: 0.01465
[32m[0907 00-44-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34995, current rewards: -21.28164, mean: -0.01059
[32m[0907 00-45-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34996, current rewards: -71.28164, mean: -0.03460
[32m[0907 00-45-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35000, current rewards: -121.28164, mean: -0.05748
[32m[0907 00-45-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34999, current rewards: -171.28164, mean: -0.07930
[32m[0907 00-46-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35002, current rewards: -221.28164, mean: -0.10013
[32m[0907 00-46-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35003, current rewards: -271.28164, mean: -0.12004
[32m[0907 00-46-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35000, current rewards: -321.28164, mean: -0.13908
[32m[0907 00-46-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34985, current rewards: -371.28164, mean: -0.15732
[32m[0907 00-47-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34973, current rewards: -421.28164, mean: -0.17481
[32m[0907 00-47-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34959, current rewards: -471.28164, mean: -0.19158
[32m[0907 00-47-43 @Agent.py:117][0m Average action selection time: 0.3495
[32m[0907 00-47-43 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-47-43 @MBExp.py:227][0m Rewards obtained: [-511.28164238847125], Lows: [77], Highs: [665], Total time: 37984.367662
[32m[0907 00-49-16 @MBExp.py:144][0m ####################################################################
[32m[0907 00-49-16 @MBExp.py:145][0m Starting training iteration 46.
[32m[0907 00-49-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33162, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-49-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33910, current rewards: -54.89279, mean: -0.91488
[32m[0907 00-49-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34166, current rewards: -71.95473, mean: -0.65413
[32m[0907 00-50-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34506, current rewards: -65.01898, mean: -0.40637
[32m[0907 00-50-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34671, current rewards: -59.70060, mean: -0.28429
[32m[0907 00-50-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34657, current rewards: -54.87728, mean: -0.21107
[32m[0907 00-51-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34612, current rewards: -49.81642, mean: -0.16070
[32m[0907 00-51-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34585, current rewards: -45.07385, mean: -0.12521
[32m[0907 00-51-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34560, current rewards: -40.34423, mean: -0.09840
[32m[0907 00-51-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34548, current rewards: -91.86190, mean: -0.19970
[32m[0907 00-52-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34544, current rewards: -95.87631, mean: -0.18799
[32m[0907 00-52-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34595, current rewards: -113.26044, mean: -0.20225
[32m[0907 00-52-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34647, current rewards: -131.07398, mean: -0.21488
[32m[0907 00-53-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34690, current rewards: -145.89813, mean: -0.22106
[32m[0907 00-53-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34680, current rewards: -162.16058, mean: -0.22840
[32m[0907 00-53-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34479, current rewards: -155.73319, mean: -0.20491
[32m[0907 00-53-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34296, current rewards: -149.05302, mean: -0.18402
[32m[0907 00-54-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34131, current rewards: -141.72197, mean: -0.16479
[32m[0907 00-54-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33987, current rewards: -157.21861, mean: -0.17277
[32m[0907 00-54-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33850, current rewards: -149.10516, mean: -0.15532
[32m[0907 00-54-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33729, current rewards: -140.83762, mean: -0.13944
[32m[0907 00-55-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33626, current rewards: -132.56730, mean: -0.12506
[32m[0907 00-55-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33527, current rewards: -124.00118, mean: -0.11171
[32m[0907 00-55-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33435, current rewards: -115.70243, mean: -0.09974
[32m[0907 00-56-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33352, current rewards: -109.58732, mean: -0.09057
[32m[0907 00-56-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33280, current rewards: -144.05601, mean: -0.11433
[32m[0907 00-56-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33210, current rewards: -139.69246, mean: -0.10664
[32m[0907 00-56-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33144, current rewards: -135.38581, mean: -0.09955
[32m[0907 00-57-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33084, current rewards: -131.11632, mean: -0.09299
[32m[0907 00-57-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33023, current rewards: -126.83274, mean: -0.08687
[32m[0907 00-57-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32970, current rewards: -122.51494, mean: -0.08114
[32m[0907 00-57-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32920, current rewards: -118.19236, mean: -0.07576
[32m[0907 00-58-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32875, current rewards: -113.89534, mean: -0.07074
[32m[0907 00-58-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32832, current rewards: -132.57887, mean: -0.07987
[32m[0907 00-58-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32790, current rewards: -145.63925, mean: -0.08517
[32m[0907 00-58-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32750, current rewards: -140.70660, mean: -0.07995
[32m[0907 00-59-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32711, current rewards: -135.57486, mean: -0.07490
[32m[0907 00-59-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32675, current rewards: -130.69910, mean: -0.07027
[32m[0907 00-59-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32640, current rewards: -125.57928, mean: -0.06575
[32m[0907 00-59-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32610, current rewards: -120.56145, mean: -0.06151
[32m[0907 01-00-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32578, current rewards: -136.25032, mean: -0.06779
[32m[0907 01-00-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32549, current rewards: -130.41854, mean: -0.06331
[32m[0907 01-00-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32521, current rewards: -124.66865, mean: -0.05908
[32m[0907 01-00-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32493, current rewards: -129.50000, mean: -0.05995
[32m[0907 01-01-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32469, current rewards: -165.68566, mean: -0.07497
[32m[0907 01-01-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32444, current rewards: -172.61720, mean: -0.07638
[32m[0907 01-01-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32417, current rewards: -165.57299, mean: -0.07168
[32m[0907 01-02-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32382, current rewards: -158.94577, mean: -0.06735
[32m[0907 01-02-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32349, current rewards: -195.47816, mean: -0.08111
[32m[0907 01-02-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32315, current rewards: -189.74815, mean: -0.07713
[32m[0907 01-02-44 @Agent.py:117][0m Average action selection time: 0.3229
[32m[0907 01-02-44 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-02-44 @MBExp.py:227][0m Rewards obtained: [-185.38554956435854], Lows: [202], Highs: [61], Total time: 38792.27271999999
[32m[0907 01-04-11 @MBExp.py:144][0m ####################################################################
[32m[0907 01-04-11 @MBExp.py:145][0m Starting training iteration 47.
[32m[0907 01-04-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29810, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-04-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30380, current rewards: -37.05770, mean: -0.61763
[32m[0907 01-04-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30621, current rewards: -30.54548, mean: -0.27769
[32m[0907 01-05-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30881, current rewards: -23.99019, mean: -0.14994
[32m[0907 01-05-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31012, current rewards: -18.35849, mean: -0.08742
[32m[0907 01-05-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30991, current rewards: -11.75397, mean: -0.04521
[32m[0907 01-05-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30963, current rewards: -5.16403, mean: -0.01666
[32m[0907 01-06-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30942, current rewards: 1.43073, mean: 0.00397
[32m[0907 01-06-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30919, current rewards: 8.01544, mean: 0.01955
[32m[0907 01-06-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30903, current rewards: -8.84777, mean: -0.01923
[32m[0907 01-06-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30898, current rewards: -60.42446, mean: -0.11848
[32m[0907 01-07-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30958, current rewards: -110.42446, mean: -0.19719
[32m[0907 01-07-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30998, current rewards: -160.42446, mean: -0.26299
[32m[0907 01-07-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31043, current rewards: -189.32925, mean: -0.28686
[32m[0907 01-07-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31078, current rewards: -224.25300, mean: -0.31585
[32m[0907 01-08-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31112, current rewards: -274.25300, mean: -0.36086
[32m[0907 01-08-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31139, current rewards: -304.13169, mean: -0.37547
[32m[0907 01-08-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31155, current rewards: -297.36684, mean: -0.34578
[32m[0907 01-08-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31175, current rewards: -290.11221, mean: -0.31880
[32m[0907 01-09-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31186, current rewards: -282.52137, mean: -0.29429
[32m[0907 01-09-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31204, current rewards: -276.03159, mean: -0.27330
[32m[0907 01-09-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31220, current rewards: -313.12665, mean: -0.29540
[32m[0907 01-09-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31235, current rewards: -308.64094, mean: -0.27805
[32m[0907 01-10-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31243, current rewards: -303.75314, mean: -0.26186
[32m[0907 01-10-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31254, current rewards: -298.85997, mean: -0.24699
[32m[0907 01-10-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31259, current rewards: -293.96845, mean: -0.23331
[32m[0907 01-11-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31268, current rewards: -289.08203, mean: -0.22067
[32m[0907 01-11-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31272, current rewards: -284.20195, mean: -0.20897
[32m[0907 01-11-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31279, current rewards: -279.31078, mean: -0.19809
[32m[0907 01-11-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31285, current rewards: -281.99318, mean: -0.19315
[32m[0907 01-12-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31289, current rewards: -292.22993, mean: -0.19353
[32m[0907 01-12-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31291, current rewards: -286.66402, mean: -0.18376
[32m[0907 01-12-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31293, current rewards: -281.11994, mean: -0.17461
[32m[0907 01-12-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31296, current rewards: -277.68223, mean: -0.16728
[32m[0907 01-13-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31301, current rewards: -312.32894, mean: -0.18265
[32m[0907 01-13-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31307, current rewards: -305.05698, mean: -0.17333
[32m[0907 01-13-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31311, current rewards: -297.72614, mean: -0.16449
[32m[0907 01-13-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31312, current rewards: -292.06659, mean: -0.15703
[32m[0907 01-14-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31314, current rewards: -285.83154, mean: -0.14965
[32m[0907 01-14-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31315, current rewards: -279.59200, mean: -0.14265
[32m[0907 01-14-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31315, current rewards: -273.35611, mean: -0.13600
[32m[0907 01-14-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31316, current rewards: -267.11730, mean: -0.12967
[32m[0907 01-15-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31317, current rewards: -260.88308, mean: -0.12364
[32m[0907 01-15-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31320, current rewards: -254.64688, mean: -0.11789
[32m[0907 01-15-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31319, current rewards: -248.41354, mean: -0.11240
[32m[0907 01-15-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31320, current rewards: -242.17550, mean: -0.10716
[32m[0907 01-16-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31315, current rewards: -235.93487, mean: -0.10214
[32m[0907 01-16-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31302, current rewards: -229.68927, mean: -0.09733
[32m[0907 01-16-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31291, current rewards: -227.94985, mean: -0.09458
[32m[0907 01-17-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31278, current rewards: -239.12813, mean: -0.09721
[32m[0907 01-17-13 @Agent.py:117][0m Average action selection time: 0.3127
[32m[0907 01-17-13 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-17-13 @MBExp.py:227][0m Rewards obtained: [-261.85314971732635], Lows: [72], Highs: [369], Total time: 39574.67374399999
[32m[0907 01-18-41 @MBExp.py:144][0m ####################################################################
[32m[0907 01-18-41 @MBExp.py:145][0m Starting training iteration 48.
[32m[0907 01-18-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29861, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-18-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30385, current rewards: -17.99713, mean: -0.29995
[32m[0907 01-19-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30590, current rewards: -13.00683, mean: -0.11824
[32m[0907 01-19-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30855, current rewards: -8.17975, mean: -0.05112
[32m[0907 01-19-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31006, current rewards: -18.21282, mean: -0.08673
[32m[0907 01-20-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30964, current rewards: -16.65639, mean: -0.06406
[32m[0907 01-20-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30928, current rewards: -31.30673, mean: -0.10099
[32m[0907 01-20-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30910, current rewards: -90.86701, mean: -0.25241
[32m[0907 01-20-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30896, current rewards: -140.86701, mean: -0.34358
[32m[0907 01-21-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30880, current rewards: -190.86701, mean: -0.41493
[32m[0907 01-21-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30871, current rewards: -240.86701, mean: -0.47229
[32m[0907 01-21-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30936, current rewards: -290.86701, mean: -0.51941
[32m[0907 01-21-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30990, current rewards: -340.86701, mean: -0.55880
[32m[0907 01-22-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31032, current rewards: -390.86701, mean: -0.59222
[32m[0907 01-22-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31068, current rewards: -440.86701, mean: -0.62094
[32m[0907 01-22-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31093, current rewards: -490.86701, mean: -0.64588
[32m[0907 01-22-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31117, current rewards: -540.86701, mean: -0.66774
[32m[0907 01-23-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31136, current rewards: -590.86701, mean: -0.68705
[32m[0907 01-23-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31155, current rewards: -618.22315, mean: -0.67937
[32m[0907 01-23-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31173, current rewards: -612.12985, mean: -0.63764
[32m[0907 01-23-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31188, current rewards: -605.98392, mean: -0.59998
[32m[0907 01-24-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31203, current rewards: -599.84055, mean: -0.56589
[32m[0907 01-24-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31219, current rewards: -593.69881, mean: -0.53486
[32m[0907 01-24-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31232, current rewards: -587.55632, mean: -0.50651
[32m[0907 01-24-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31245, current rewards: -581.41090, mean: -0.48050
[32m[0907 01-25-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31253, current rewards: -575.26460, mean: -0.45656
[32m[0907 01-25-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31261, current rewards: -594.73063, mean: -0.45399
[32m[0907 01-25-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31264, current rewards: -589.05610, mean: -0.43313
[32m[0907 01-26-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31269, current rewards: -584.28488, mean: -0.41439
[32m[0907 01-26-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31273, current rewards: -578.64577, mean: -0.39633
[32m[0907 01-26-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31273, current rewards: -572.94814, mean: -0.37944
[32m[0907 01-26-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31276, current rewards: -567.24343, mean: -0.36362
[32m[0907 01-27-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31276, current rewards: -561.54456, mean: -0.34879
[32m[0907 01-27-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31282, current rewards: -555.84812, mean: -0.33485
[32m[0907 01-27-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31285, current rewards: -583.97572, mean: -0.34151
[32m[0907 01-27-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31287, current rewards: -609.42156, mean: -0.34626
[32m[0907 01-28-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31289, current rewards: -638.45268, mean: -0.35274
[32m[0907 01-28-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31291, current rewards: -642.54828, mean: -0.34546
[32m[0907 01-28-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31292, current rewards: -660.42938, mean: -0.34577
[32m[0907 01-28-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31295, current rewards: -680.03454, mean: -0.34696
[32m[0907 01-29-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31295, current rewards: -689.17922, mean: -0.34288
[32m[0907 01-29-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31295, current rewards: -683.32432, mean: -0.33171
[32m[0907 01-29-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31297, current rewards: -677.56864, mean: -0.32112
[32m[0907 01-29-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31296, current rewards: -671.81015, mean: -0.31102
[32m[0907 01-30-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31296, current rewards: -665.77789, mean: -0.30126
[32m[0907 01-30-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31297, current rewards: -673.21520, mean: -0.29788
[32m[0907 01-30-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31293, current rewards: -676.84326, mean: -0.29301
[32m[0907 01-31-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31280, current rewards: -670.50636, mean: -0.28411
[32m[0907 01-31-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31268, current rewards: -664.25611, mean: -0.27562
[32m[0907 01-31-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31257, current rewards: -658.03215, mean: -0.26749
[32m[0907 01-31-43 @Agent.py:117][0m Average action selection time: 0.3125
[32m[0907 01-31-43 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-31-43 @MBExp.py:227][0m Rewards obtained: [-653.1603697717197], Lows: [120], Highs: [633], Total time: 40356.497897999994
[32m[0907 01-33-12 @MBExp.py:144][0m ####################################################################
[32m[0907 01-33-12 @MBExp.py:145][0m Starting training iteration 49.
[32m[0907 01-33-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29738, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-33-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30259, current rewards: -23.01246, mean: -0.38354
[32m[0907 01-33-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30523, current rewards: -18.60095, mean: -0.16910
[32m[0907 01-34-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30800, current rewards: -14.18539, mean: -0.08866
[32m[0907 01-34-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30996, current rewards: -9.76441, mean: -0.04650
[32m[0907 01-34-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30937, current rewards: -5.34476, mean: -0.02056
[32m[0907 01-34-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30929, current rewards: -0.92679, mean: -0.00299
[32m[0907 01-35-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30915, current rewards: 3.49375, mean: 0.00970
[32m[0907 01-35-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30894, current rewards: 7.91459, mean: 0.01930
[32m[0907 01-35-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30879, current rewards: 12.33331, mean: 0.02681
[32m[0907 01-35-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30867, current rewards: 16.75427, mean: 0.03285
[32m[0907 01-36-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30926, current rewards: 23.11559, mean: 0.04128
[32m[0907 01-36-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30973, current rewards: -7.79211, mean: -0.01277
[32m[0907 01-36-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31012, current rewards: -6.81531, mean: -0.01033
[32m[0907 01-36-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31042, current rewards: -1.49829, mean: -0.00211
[32m[0907 01-37-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31073, current rewards: 3.83684, mean: 0.00505
[32m[0907 01-37-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31096, current rewards: 9.18106, mean: 0.01133
[32m[0907 01-37-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31130, current rewards: -10.59951, mean: -0.01233
[32m[0907 01-37-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31145, current rewards: -7.08859, mean: -0.00779
[32m[0907 01-38-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31160, current rewards: -3.51190, mean: -0.00366
[32m[0907 01-38-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31180, current rewards: 0.09157, mean: 0.00009
[32m[0907 01-38-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31191, current rewards: 3.57757, mean: 0.00338
[32m[0907 01-38-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31207, current rewards: 7.02278, mean: 0.00633
[32m[0907 01-39-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31215, current rewards: 10.62001, mean: 0.00916
[32m[0907 01-39-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31224, current rewards: 14.15728, mean: 0.01170
[32m[0907 01-39-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31238, current rewards: 11.42693, mean: 0.00907
[32m[0907 01-40-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31247, current rewards: -20.70454, mean: -0.01580
[32m[0907 01-40-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31254, current rewards: -37.34199, mean: -0.02746
[32m[0907 01-40-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31261, current rewards: -52.57539, mean: -0.03729
[32m[0907 01-40-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31267, current rewards: -75.71931, mean: -0.05186
[32m[0907 01-41-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31275, current rewards: -108.58659, mean: -0.07191
[32m[0907 01-41-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31279, current rewards: -120.64323, mean: -0.07734
[32m[0907 01-41-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31282, current rewards: -130.76077, mean: -0.08122
[32m[0907 01-41-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31288, current rewards: -126.53427, mean: -0.07623
[32m[0907 01-42-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31290, current rewards: -121.13647, mean: -0.07084
[32m[0907 01-42-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31295, current rewards: -115.31601, mean: -0.06552
[32m[0907 01-42-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31298, current rewards: -107.80241, mean: -0.05956
[32m[0907 01-42-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31302, current rewards: -101.78077, mean: -0.05472
[32m[0907 01-43-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31305, current rewards: -94.19247, mean: -0.04932
[32m[0907 01-43-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31308, current rewards: -85.95447, mean: -0.04385
[32m[0907 01-43-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31310, current rewards: -80.19523, mean: -0.03990
[32m[0907 01-43-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31310, current rewards: -72.80739, mean: -0.03534
[32m[0907 01-44-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31314, current rewards: -64.49664, mean: -0.03057
[32m[0907 01-44-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31314, current rewards: -83.80283, mean: -0.03880
[32m[0907 01-44-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31313, current rewards: -76.42766, mean: -0.03458
[32m[0907 01-45-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31311, current rewards: -71.53139, mean: -0.03165
[32m[0907 01-45-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31305, current rewards: -66.65237, mean: -0.02885
[32m[0907 01-45-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31291, current rewards: -61.76174, mean: -0.02617
[32m[0907 01-45-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31280, current rewards: -56.87039, mean: -0.02360
[32m[0907 01-46-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31268, current rewards: -51.98336, mean: -0.02113
[32m[0907 01-46-14 @Agent.py:117][0m Average action selection time: 0.3126
[32m[0907 01-46-14 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-46-15 @MBExp.py:227][0m Rewards obtained: [-48.07314436129888], Lows: [56], Highs: [176], Total time: 41138.62572699999
[32m[0907 01-47-46 @MBExp.py:144][0m ####################################################################
[32m[0907 01-47-46 @MBExp.py:145][0m Starting training iteration 50.
[32m[0907 01-47-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29818, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-48-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30270, current rewards: -50.74786, mean: -0.84580
[32m[0907 01-48-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30472, current rewards: -52.85255, mean: -0.48048
[32m[0907 01-48-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30738, current rewards: -62.38530, mean: -0.38991
[32m[0907 01-48-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30891, current rewards: -80.52026, mean: -0.38343
[32m[0907 01-49-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30888, current rewards: -73.25457, mean: -0.28175
[32m[0907 01-49-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30873, current rewards: -85.33477, mean: -0.27527
[32m[0907 01-49-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30865, current rewards: -75.87037, mean: -0.21075
[32m[0907 01-49-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30854, current rewards: -68.82982, mean: -0.16788
[32m[0907 01-50-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30838, current rewards: -58.50670, mean: -0.12719
[32m[0907 01-50-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30828, current rewards: -69.79874, mean: -0.13686
[32m[0907 01-50-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30904, current rewards: -139.98256, mean: -0.24997
[32m[0907 01-50-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30949, current rewards: -163.51277, mean: -0.26805
[32m[0907 01-51-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30987, current rewards: -234.79063, mean: -0.35574
[32m[0907 01-51-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31017, current rewards: -301.62652, mean: -0.42483
[32m[0907 01-51-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31049, current rewards: -372.08071, mean: -0.48958
[32m[0907 01-51-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31072, current rewards: -466.19496, mean: -0.57555
[32m[0907 01-52-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31096, current rewards: -564.02553, mean: -0.65584
[32m[0907 01-52-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31116, current rewards: -664.02553, mean: -0.72970
[32m[0907 01-52-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31140, current rewards: -764.02553, mean: -0.79586
[32m[0907 01-53-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31151, current rewards: -864.02553, mean: -0.85547
[32m[0907 01-53-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31165, current rewards: -947.17130, mean: -0.89356
[32m[0907 01-53-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31178, current rewards: -1026.30483, mean: -0.92460
[32m[0907 01-53-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31191, current rewards: -1107.02870, mean: -0.95434
[32m[0907 01-54-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31203, current rewards: -1173.44078, mean: -0.96979
[32m[0907 01-54-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31214, current rewards: -1192.10766, mean: -0.94612
[32m[0907 01-54-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31223, current rewards: -1204.09862, mean: -0.91916
[32m[0907 01-54-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31235, current rewards: -1218.99628, mean: -0.89632
[32m[0907 01-55-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31246, current rewards: -1221.50037, mean: -0.86631
[32m[0907 01-55-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31255, current rewards: -1215.60261, mean: -0.83260
[32m[0907 01-55-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31264, current rewards: -1239.39392, mean: -0.82079
[32m[0907 01-55-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31268, current rewards: -1259.93445, mean: -0.80765
[32m[0907 01-56-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31272, current rewards: -1266.93176, mean: -0.78691
[32m[0907 01-56-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31275, current rewards: -1271.14197, mean: -0.76575
[32m[0907 01-56-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31279, current rewards: -1301.67323, mean: -0.76121
[32m[0907 01-56-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31283, current rewards: -1324.83429, mean: -0.75275
[32m[0907 01-57-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31288, current rewards: -1319.40975, mean: -0.72896
[32m[0907 01-57-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31291, current rewards: -1315.20239, mean: -0.70710
[32m[0907 01-57-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31294, current rewards: -1310.99091, mean: -0.68638
[32m[0907 01-58-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31298, current rewards: -1301.03561, mean: -0.66379
[32m[0907 01-58-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31300, current rewards: -1334.82069, mean: -0.66409
[32m[0907 01-58-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31304, current rewards: -1367.93589, mean: -0.66405
[32m[0907 01-58-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31306, current rewards: -1399.33968, mean: -0.66319
[32m[0907 01-59-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31312, current rewards: -1421.75247, mean: -0.65822
[32m[0907 01-59-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31317, current rewards: -1467.69397, mean: -0.66411
[32m[0907 01-59-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31320, current rewards: -1504.31377, mean: -0.66563
[32m[0907 01-59-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31316, current rewards: -1540.93646, mean: -0.66707
[32m[0907 02-00-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31308, current rewards: -1607.45053, mean: -0.68112
[32m[0907 02-00-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31294, current rewards: -1634.91495, mean: -0.67839
[32m[0907 02-00-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31281, current rewards: -1628.92427, mean: -0.66216
[32m[0907 02-00-49 @Agent.py:117][0m Average action selection time: 0.3127
[32m[0907 02-00-49 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-00-49 @MBExp.py:227][0m Rewards obtained: [-1624.145304447098], Lows: [909], Highs: [112], Total time: 41921.11945399999
[32m[0907 02-02-22 @MBExp.py:144][0m ####################################################################
[32m[0907 02-02-22 @MBExp.py:145][0m Starting training iteration 51.
[32m[0907 02-02-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29982, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-02-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30346, current rewards: -17.40842, mean: -0.29014
[32m[0907 02-02-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30549, current rewards: -12.66329, mean: -0.11512
[32m[0907 02-03-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30852, current rewards: -7.77936, mean: -0.04862
[32m[0907 02-03-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30966, current rewards: -2.89108, mean: -0.01377
[32m[0907 02-03-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30935, current rewards: 1.99636, mean: 0.00768
[32m[0907 02-03-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30917, current rewards: 6.88747, mean: 0.02222
[32m[0907 02-04-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30902, current rewards: 11.77738, mean: 0.03271
[32m[0907 02-04-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30890, current rewards: 16.66160, mean: 0.04064
[32m[0907 02-04-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30880, current rewards: 21.55222, mean: 0.04685
[32m[0907 02-05-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30874, current rewards: 26.96902, mean: 0.05288
[32m[0907 02-05-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30938, current rewards: 15.14551, mean: 0.02705
[32m[0907 02-05-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30979, current rewards: -3.89590, mean: -0.00639
[32m[0907 02-05-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31019, current rewards: 3.73057, mean: 0.00565
[32m[0907 02-06-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31057, current rewards: 11.36487, mean: 0.01601
[32m[0907 02-06-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31087, current rewards: 19.00067, mean: 0.02500
[32m[0907 02-06-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31114, current rewards: 26.63798, mean: 0.03289
[32m[0907 02-06-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31137, current rewards: 34.27643, mean: 0.03986
[32m[0907 02-07-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31160, current rewards: 40.80634, mean: 0.04484
[32m[0907 02-07-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31179, current rewards: 48.41566, mean: 0.05043
[32m[0907 02-07-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31197, current rewards: 38.75710, mean: 0.03837
[32m[0907 02-07-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31210, current rewards: 41.65583, mean: 0.03930
[32m[0907 02-08-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31225, current rewards: 47.13525, mean: 0.04246
[32m[0907 02-08-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31238, current rewards: 52.61585, mean: 0.04536
[32m[0907 02-08-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31251, current rewards: 58.10332, mean: 0.04802
[32m[0907 02-08-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31255, current rewards: 63.58833, mean: 0.05047
[32m[0907 02-09-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31262, current rewards: 68.89760, mean: 0.05259
[32m[0907 02-09-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31272, current rewards: 74.42333, mean: 0.05472
[32m[0907 02-09-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31279, current rewards: 79.91831, mean: 0.05668
[32m[0907 02-09-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31286, current rewards: 85.43256, mean: 0.05852
[32m[0907 02-10-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31292, current rewards: 90.94380, mean: 0.06023
[32m[0907 02-10-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31298, current rewards: 96.45171, mean: 0.06183
[32m[0907 02-10-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31300, current rewards: 79.75370, mean: 0.04954
[32m[0907 02-11-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31304, current rewards: -20.24630, mean: -0.01220
[32m[0907 02-11-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31308, current rewards: -120.24630, mean: -0.07032
[32m[0907 02-11-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31311, current rewards: -220.24630, mean: -0.12514
[32m[0907 02-11-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31319, current rewards: -320.24630, mean: -0.17693
[32m[0907 02-12-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31323, current rewards: -420.24630, mean: -0.22594
[32m[0907 02-12-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31325, current rewards: -520.24630, mean: -0.27238
[32m[0907 02-12-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31330, current rewards: -620.24630, mean: -0.31645
[32m[0907 02-12-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31332, current rewards: -720.24630, mean: -0.35833
[32m[0907 02-13-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31334, current rewards: -820.24630, mean: -0.39818
[32m[0907 02-13-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31334, current rewards: -920.24630, mean: -0.43614
[32m[0907 02-13-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31332, current rewards: -1020.24630, mean: -0.47234
[32m[0907 02-13-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31333, current rewards: -1120.24630, mean: -0.50690
[32m[0907 02-14-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31334, current rewards: -1220.24630, mean: -0.53993
[32m[0907 02-14-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31328, current rewards: -1320.24630, mean: -0.57154
[32m[0907 02-14-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31315, current rewards: -1420.24630, mean: -0.60180
[32m[0907 02-14-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31303, current rewards: -1520.24630, mean: -0.63081
[32m[0907 02-15-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31291, current rewards: -1620.24630, mean: -0.65864
[32m[0907 02-15-25 @Agent.py:117][0m Average action selection time: 0.3128
[32m[0907 02-15-25 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-15-25 @MBExp.py:227][0m Rewards obtained: [-1700.2462968736377], Lows: [910], Highs: [61], Total time: 42703.848439999994
[32m[0907 02-17-00 @MBExp.py:144][0m ####################################################################
[32m[0907 02-17-00 @MBExp.py:145][0m Starting training iteration 52.
[32m[0907 02-17-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29771, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-17-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30249, current rewards: -95.72992, mean: -1.59550
[32m[0907 02-17-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30501, current rewards: -173.34221, mean: -1.57584
[32m[0907 02-17-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30837, current rewards: -255.59571, mean: -1.59747
[32m[0907 02-18-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30908, current rewards: -333.49811, mean: -1.58809
[32m[0907 02-18-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30897, current rewards: -411.08268, mean: -1.58109
[32m[0907 02-18-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30890, current rewards: -496.21997, mean: -1.60071
[32m[0907 02-18-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30887, current rewards: -578.52249, mean: -1.60701
[32m[0907 02-19-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30882, current rewards: -625.09967, mean: -1.52463
[32m[0907 02-19-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30874, current rewards: -619.24732, mean: -1.34619
[32m[0907 02-19-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30871, current rewards: -615.16827, mean: -1.20621
[32m[0907 02-19-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30933, current rewards: -613.02708, mean: -1.09469
[32m[0907 02-20-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30978, current rewards: -609.57469, mean: -0.99930
[32m[0907 02-20-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31018, current rewards: -606.85669, mean: -0.91948
[32m[0907 02-20-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31054, current rewards: -600.85382, mean: -0.84627
[32m[0907 02-20-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31086, current rewards: -596.90329, mean: -0.78540
[32m[0907 02-21-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31110, current rewards: -594.06094, mean: -0.73341
[32m[0907 02-21-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31124, current rewards: -633.20368, mean: -0.73628
[32m[0907 02-21-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31141, current rewards: -631.12570, mean: -0.69354
[32m[0907 02-22-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31160, current rewards: -628.75330, mean: -0.65495
[32m[0907 02-22-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31174, current rewards: -628.68066, mean: -0.62246
[32m[0907 02-22-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31184, current rewards: -626.70176, mean: -0.59123
[32m[0907 02-22-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31194, current rewards: -624.77007, mean: -0.56286
[32m[0907 02-23-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31205, current rewards: -624.73938, mean: -0.53857
[32m[0907 02-23-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31215, current rewards: -622.41371, mean: -0.51439
[32m[0907 02-23-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31226, current rewards: -624.10235, mean: -0.49532
[32m[0907 02-23-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31232, current rewards: -634.22508, mean: -0.48414
[32m[0907 02-24-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31241, current rewards: -618.27455, mean: -0.45461
[32m[0907 02-24-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31251, current rewards: -602.79012, mean: -0.42751
[32m[0907 02-24-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31258, current rewards: -587.37447, mean: -0.40231
[32m[0907 02-24-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31263, current rewards: -571.94085, mean: -0.37877
[32m[0907 02-25-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31266, current rewards: -556.52524, mean: -0.35675
[32m[0907 02-25-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31271, current rewards: -541.18710, mean: -0.33614
[32m[0907 02-25-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31275, current rewards: -525.79435, mean: -0.31674
[32m[0907 02-25-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31277, current rewards: -515.04531, mean: -0.30120
[32m[0907 02-26-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31301, current rewards: -605.30687, mean: -0.34392
[32m[0907 02-26-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31303, current rewards: -674.24255, mean: -0.37251
[32m[0907 02-26-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31306, current rewards: -738.84806, mean: -0.39723
[32m[0907 02-26-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31308, current rewards: -751.95036, mean: -0.39369
[32m[0907 02-27-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31310, current rewards: -745.05103, mean: -0.38013
[32m[0907 02-27-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31313, current rewards: -736.76937, mean: -0.36655
[32m[0907 02-27-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31317, current rewards: -729.83306, mean: -0.35429
[32m[0907 02-28-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31320, current rewards: -724.78292, mean: -0.34350
[32m[0907 02-28-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31321, current rewards: -721.13606, mean: -0.33386
[32m[0907 02-28-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31321, current rewards: -716.95999, mean: -0.32442
[32m[0907 02-28-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31323, current rewards: -713.21700, mean: -0.31558
[32m[0907 02-29-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31315, current rewards: -709.13662, mean: -0.30699
[32m[0907 02-29-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31303, current rewards: -705.29401, mean: -0.29885
[32m[0907 02-29-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31290, current rewards: -701.39477, mean: -0.29104
[32m[0907 02-29-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31278, current rewards: -764.43882, mean: -0.31075
[32m[0907 02-30-03 @Agent.py:117][0m Average action selection time: 0.3127
[32m[0907 02-30-03 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-30-03 @MBExp.py:227][0m Rewards obtained: [-813.8514057521918], Lows: [553], Highs: [72], Total time: 43486.384419999995
[32m[0907 02-31-40 @MBExp.py:144][0m ####################################################################
[32m[0907 02-31-40 @MBExp.py:145][0m Starting training iteration 53.
[32m[0907 02-31-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29856, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-31-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30266, current rewards: -12.13173, mean: -0.20220
[32m[0907 02-32-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30503, current rewards: -7.51695, mean: -0.06834
[32m[0907 02-32-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30859, current rewards: -2.90218, mean: -0.01814
[32m[0907 02-32-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30938, current rewards: 1.71260, mean: 0.00816
[32m[0907 02-33-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30915, current rewards: -36.27215, mean: -0.13951
[32m[0907 02-33-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30905, current rewards: -34.19998, mean: -0.11032
[32m[0907 02-33-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30899, current rewards: -29.09960, mean: -0.08083
[32m[0907 02-33-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30898, current rewards: -23.84611, mean: -0.05816
[32m[0907 02-34-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30887, current rewards: -61.21682, mean: -0.13308
[32m[0907 02-34-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30885, current rewards: -61.46163, mean: -0.12051
[32m[0907 02-34-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30953, current rewards: -58.69148, mean: -0.10481
[32m[0907 02-34-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30996, current rewards: -55.70410, mean: -0.09132
[32m[0907 02-35-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31034, current rewards: -52.70644, mean: -0.07986
[32m[0907 02-35-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31070, current rewards: -49.72355, mean: -0.07003
[32m[0907 02-35-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31098, current rewards: -46.73465, mean: -0.06149
[32m[0907 02-35-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31125, current rewards: -43.88159, mean: -0.05417
[32m[0907 02-36-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31141, current rewards: -59.29053, mean: -0.06894
[32m[0907 02-36-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31162, current rewards: -75.50376, mean: -0.08297
[32m[0907 02-36-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31180, current rewards: -71.53211, mean: -0.07451
[32m[0907 02-36-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31190, current rewards: -67.64413, mean: -0.06697
[32m[0907 02-37-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31207, current rewards: -63.74752, mean: -0.06014
[32m[0907 02-37-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31217, current rewards: -59.87147, mean: -0.05394
[32m[0907 02-37-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31235, current rewards: -55.97777, mean: -0.04826
[32m[0907 02-37-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31246, current rewards: -52.12133, mean: -0.04308
[32m[0907 02-38-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31255, current rewards: -70.92594, mean: -0.05629
[32m[0907 02-38-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31266, current rewards: -67.62126, mean: -0.05162
[32m[0907 02-38-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31273, current rewards: -66.49400, mean: -0.04889
[32m[0907 02-39-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31278, current rewards: -66.61204, mean: -0.04724
[32m[0907 02-39-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31285, current rewards: -64.40562, mean: -0.04411
[32m[0907 02-39-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31291, current rewards: -63.28178, mean: -0.04191
[32m[0907 02-39-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31297, current rewards: -59.96977, mean: -0.03844
[32m[0907 02-40-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31298, current rewards: -93.46421, mean: -0.05805
[32m[0907 02-40-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31302, current rewards: -89.88187, mean: -0.05415
[32m[0907 02-40-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31305, current rewards: -85.19443, mean: -0.04982
[32m[0907 02-40-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31308, current rewards: -80.71563, mean: -0.04586
[32m[0907 02-41-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31309, current rewards: -76.15626, mean: -0.04208
[32m[0907 02-41-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31314, current rewards: -93.22248, mean: -0.05012
[32m[0907 02-41-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31319, current rewards: -87.58155, mean: -0.04585
[32m[0907 02-41-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31322, current rewards: -81.79591, mean: -0.04173
[32m[0907 02-42-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31324, current rewards: -76.00597, mean: -0.03781
[32m[0907 02-42-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31328, current rewards: -71.88291, mean: -0.03489
[32m[0907 02-42-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31330, current rewards: -71.46596, mean: -0.03387
[32m[0907 02-42-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31332, current rewards: -106.23788, mean: -0.04918
[32m[0907 02-43-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31335, current rewards: -105.33242, mean: -0.04766
[32m[0907 02-43-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31338, current rewards: -105.47581, mean: -0.04667
[32m[0907 02-43-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31335, current rewards: -106.69408, mean: -0.04619
[32m[0907 02-44-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31322, current rewards: -108.91478, mean: -0.04615
[32m[0907 02-44-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31310, current rewards: -108.00955, mean: -0.04482
[32m[0907 02-44-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31298, current rewards: -105.98471, mean: -0.04308
[32m[0907 02-44-43 @Agent.py:117][0m Average action selection time: 0.3129
[32m[0907 02-44-43 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-44-43 @MBExp.py:227][0m Rewards obtained: [-103.39996231753227], Lows: [85], Highs: [127], Total time: 44269.297332999995
[32m[0907 02-46-22 @MBExp.py:144][0m ####################################################################
[32m[0907 02-46-22 @MBExp.py:145][0m Starting training iteration 54.
[32m[0907 02-46-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29820, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-46-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30199, current rewards: -16.50190, mean: -0.27503
[32m[0907 02-46-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30476, current rewards: -10.95641, mean: -0.09960
[32m[0907 02-47-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30843, current rewards: -5.35551, mean: -0.03347
[32m[0907 02-47-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30883, current rewards: 0.23389, mean: 0.00111
[32m[0907 02-47-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30854, current rewards: 5.82657, mean: 0.02241
[32m[0907 02-47-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30845, current rewards: 11.42168, mean: 0.03684
[32m[0907 02-48-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30838, current rewards: 17.01267, mean: 0.04726
[32m[0907 02-48-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30838, current rewards: 22.60975, mean: 0.05515
[32m[0907 02-48-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30832, current rewards: 4.45339, mean: 0.00968
[32m[0907 02-49-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30835, current rewards: -5.20856, mean: -0.01021
[32m[0907 02-49-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30904, current rewards: -7.08622, mean: -0.01265
[32m[0907 02-49-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30950, current rewards: -1.91909, mean: -0.00315
[32m[0907 02-49-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30988, current rewards: 6.09174, mean: 0.00923
[32m[0907 02-50-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31022, current rewards: 13.83067, mean: 0.01948
[32m[0907 02-50-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31053, current rewards: 0.11166, mean: 0.00015
[32m[0907 02-50-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31081, current rewards: -3.01777, mean: -0.00373
[32m[0907 02-50-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31101, current rewards: 0.66271, mean: 0.00077
[32m[0907 02-51-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31123, current rewards: 5.18720, mean: 0.00570
[32m[0907 02-51-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31132, current rewards: 6.47654, mean: 0.00675
[32m[0907 02-51-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31149, current rewards: 12.80185, mean: 0.01268
[32m[0907 02-51-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31163, current rewards: 19.19786, mean: 0.01811
[32m[0907 02-52-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31181, current rewards: 25.57676, mean: 0.02304
[32m[0907 02-52-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31194, current rewards: 31.96408, mean: 0.02756
[32m[0907 02-52-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31205, current rewards: 38.17064, mean: 0.03155
[32m[0907 02-52-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31215, current rewards: 44.57671, mean: 0.03538
[32m[0907 02-53-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31225, current rewards: 50.98016, mean: 0.03892
[32m[0907 02-53-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31236, current rewards: 57.38406, mean: 0.04219
[32m[0907 02-53-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31246, current rewards: 63.79160, mean: 0.04524
[32m[0907 02-53-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31252, current rewards: 70.20106, mean: 0.04808
[32m[0907 02-54-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31260, current rewards: 32.90485, mean: 0.02179
[32m[0907 02-54-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31267, current rewards: 38.43709, mean: 0.02464
[32m[0907 02-54-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31274, current rewards: 43.24164, mean: 0.02686
[32m[0907 02-55-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31280, current rewards: 48.28995, mean: 0.02909
[32m[0907 02-55-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31284, current rewards: 11.75554, mean: 0.00687
[32m[0907 02-55-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31289, current rewards: 17.20212, mean: 0.00977
[32m[0907 02-55-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31290, current rewards: 22.84863, mean: 0.01262
[32m[0907 02-56-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31295, current rewards: 28.50103, mean: 0.01532
[32m[0907 02-56-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31296, current rewards: 34.15028, mean: 0.01788
[32m[0907 02-56-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31298, current rewards: 39.79864, mean: 0.02031
[32m[0907 02-56-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31301, current rewards: 53.29411, mean: 0.02651
[32m[0907 02-57-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31303, current rewards: 17.16212, mean: 0.00833
[32m[0907 02-57-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31306, current rewards: 24.14400, mean: 0.01144
[32m[0907 02-57-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31308, current rewards: 31.64325, mean: 0.01465
[32m[0907 02-57-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31313, current rewards: 39.15304, mean: 0.01772
[32m[0907 02-58-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31315, current rewards: 46.66270, mean: 0.02065
[32m[0907 02-58-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31309, current rewards: 54.17279, mean: 0.02345
[32m[0907 02-58-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31300, current rewards: 61.68306, mean: 0.02614
[32m[0907 02-58-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31289, current rewards: 68.00235, mean: 0.02822
[32m[0907 02-59-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31279, current rewards: 73.25592, mean: 0.02978
[32m[0907 02-59-25 @Agent.py:117][0m Average action selection time: 0.3127
[32m[0907 02-59-25 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-59-25 @MBExp.py:227][0m Rewards obtained: [56.256538678372785], Lows: [100], Highs: [64], Total time: 45051.71823399999
[32m[0907 03-01-05 @MBExp.py:144][0m ####################################################################
[32m[0907 03-01-05 @MBExp.py:145][0m Starting training iteration 55.
[32m[0907 03-01-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29973, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-01-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29951, current rewards: -17.13205, mean: -0.28553
[32m[0907 03-01-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30377, current rewards: -10.29652, mean: -0.09360
[32m[0907 03-01-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30750, current rewards: -3.47498, mean: -0.02172
[32m[0907 03-02-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30802, current rewards: 3.34277, mean: 0.01592
[32m[0907 03-02-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30806, current rewards: 10.16691, mean: 0.03910
[32m[0907 03-02-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30813, current rewards: 16.98740, mean: 0.05480
[32m[0907 03-02-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30816, current rewards: -6.29746, mean: -0.01749
[32m[0907 03-03-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30828, current rewards: -11.53827, mean: -0.02814
[32m[0907 03-03-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30830, current rewards: -5.28212, mean: -0.01148
[32m[0907 03-03-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30835, current rewards: 1.01174, mean: 0.00198
[32m[0907 03-03-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30915, current rewards: 7.30427, mean: 0.01304
[32m[0907 03-04-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30968, current rewards: 13.60129, mean: 0.02230
[32m[0907 03-04-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31033, current rewards: -29.42325, mean: -0.04458
[32m[0907 03-04-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31072, current rewards: -40.95561, mean: -0.05768
[32m[0907 03-05-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31106, current rewards: -31.98590, mean: -0.04209
[32m[0907 03-05-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31131, current rewards: -25.79035, mean: -0.03184
[32m[0907 03-05-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31157, current rewards: -78.04430, mean: -0.09075
[32m[0907 03-05-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31178, current rewards: -71.66836, mean: -0.07876
[32m[0907 03-06-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31198, current rewards: -64.93630, mean: -0.06764
[32m[0907 03-06-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31215, current rewards: -58.20332, mean: -0.05763
[32m[0907 03-06-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31234, current rewards: -51.47272, mean: -0.04856
[32m[0907 03-06-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31247, current rewards: -44.73218, mean: -0.04030
[32m[0907 03-07-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31254, current rewards: -38.45912, mean: -0.03315
[32m[0907 03-07-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31265, current rewards: -32.86931, mean: -0.02716
[32m[0907 03-07-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31275, current rewards: -82.53729, mean: -0.06551
[32m[0907 03-07-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31281, current rewards: -84.32968, mean: -0.06437
[32m[0907 03-08-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31287, current rewards: -78.46599, mean: -0.05770
[32m[0907 03-08-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31294, current rewards: -72.57407, mean: -0.05147
[32m[0907 03-08-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31301, current rewards: -66.69146, mean: -0.04568
[32m[0907 03-08-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31306, current rewards: -60.77575, mean: -0.04025
[32m[0907 03-09-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31313, current rewards: -54.87371, mean: -0.03518
[32m[0907 03-09-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31315, current rewards: -43.28911, mean: -0.02689
[32m[0907 03-09-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31319, current rewards: -79.18977, mean: -0.04770
[32m[0907 03-10-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31326, current rewards: -74.12790, mean: -0.04335
[32m[0907 03-10-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31332, current rewards: -69.33393, mean: -0.03939
[32m[0907 03-10-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31335, current rewards: -64.53881, mean: -0.03566
[32m[0907 03-10-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31338, current rewards: -59.74143, mean: -0.03212
[32m[0907 03-11-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31338, current rewards: -54.94762, mean: -0.02877
[32m[0907 03-11-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31340, current rewards: -50.15170, mean: -0.02559
[32m[0907 03-11-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31342, current rewards: -40.79134, mean: -0.02029
[32m[0907 03-11-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31342, current rewards: -34.57106, mean: -0.01678
[32m[0907 03-12-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31344, current rewards: -28.65318, mean: -0.01358
[32m[0907 03-12-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31346, current rewards: -22.73531, mean: -0.01053
[32m[0907 03-12-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31349, current rewards: -58.19666, mean: -0.02633
[32m[0907 03-12-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31348, current rewards: -108.19666, mean: -0.04787
[32m[0907 03-13-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31338, current rewards: -158.19666, mean: -0.06848
[32m[0907 03-13-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31324, current rewards: -208.19666, mean: -0.08822
[32m[0907 03-13-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31311, current rewards: -258.19666, mean: -0.10714
[32m[0907 03-13-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31299, current rewards: -308.19666, mean: -0.12528
[32m[0907 03-14-08 @Agent.py:117][0m Average action selection time: 0.3129
[32m[0907 03-14-08 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-14-08 @MBExp.py:227][0m Rewards obtained: [-348.1966606927977], Lows: [90], Highs: [432], Total time: 45834.642349999995
[32m[0907 03-15-51 @MBExp.py:144][0m ####################################################################
[32m[0907 03-15-51 @MBExp.py:145][0m Starting training iteration 56.
[32m[0907 03-15-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29969, current rewards: -7.90255, mean: -0.79026
[32m[0907 03-16-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29885, current rewards: -12.86740, mean: -0.21446
[32m[0907 03-16-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30288, current rewards: -6.04163, mean: -0.05492
[32m[0907 03-16-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30713, current rewards: 0.84491, mean: 0.00528
[32m[0907 03-16-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30731, current rewards: 7.73146, mean: 0.03682
[32m[0907 03-17-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30750, current rewards: 14.61709, mean: 0.05622
[32m[0907 03-17-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30757, current rewards: 21.38912, mean: 0.06900
[32m[0907 03-17-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30764, current rewards: 26.67245, mean: 0.07409
[32m[0907 03-17-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30767, current rewards: 32.84608, mean: 0.08011
[32m[0907 03-18-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30772, current rewards: 16.62412, mean: 0.03614
[32m[0907 03-18-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30787, current rewards: 23.01681, mean: 0.04513
[32m[0907 03-18-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30856, current rewards: 29.17776, mean: 0.05210
[32m[0907 03-19-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30911, current rewards: 35.34035, mean: 0.05794
[32m[0907 03-19-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30954, current rewards: 41.48893, mean: 0.06286
[32m[0907 03-19-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30994, current rewards: 47.65511, mean: 0.06712
[32m[0907 03-19-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31027, current rewards: 52.23316, mean: 0.06873
[32m[0907 03-20-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31053, current rewards: 58.18704, mean: 0.07184
[32m[0907 03-20-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31079, current rewards: 63.98276, mean: 0.07440
[32m[0907 03-20-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31103, current rewards: 69.75896, mean: 0.07666
[32m[0907 03-20-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31123, current rewards: 75.54970, mean: 0.07870
[32m[0907 03-21-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31135, current rewards: 81.33641, mean: 0.08053
[32m[0907 03-21-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31147, current rewards: 87.13216, mean: 0.08220
[32m[0907 03-21-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31159, current rewards: 50.03996, mean: 0.04508
[32m[0907 03-21-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31170, current rewards: 57.13198, mean: 0.04925
[32m[0907 03-22-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31179, current rewards: 62.70579, mean: 0.05182
[32m[0907 03-22-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31185, current rewards: 68.31240, mean: 0.05422
[32m[0907 03-22-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31192, current rewards: 73.92690, mean: 0.05643
[32m[0907 03-22-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31204, current rewards: 79.54237, mean: 0.05849
[32m[0907 03-23-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31210, current rewards: 85.15774, mean: 0.06040
[32m[0907 03-23-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31215, current rewards: 90.08175, mean: 0.06170
[32m[0907 03-23-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31222, current rewards: 96.01316, mean: 0.06358
[32m[0907 03-23-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31226, current rewards: 103.13506, mean: 0.06611
[32m[0907 03-24-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31230, current rewards: 87.65638, mean: 0.05444
[32m[0907 03-24-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31233, current rewards: 94.18164, mean: 0.05674
[32m[0907 03-24-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31236, current rewards: 70.87028, mean: 0.04144
[32m[0907 03-25-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31239, current rewards: 66.54769, mean: 0.03781
[32m[0907 03-25-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31242, current rewards: 75.08561, mean: 0.04148
[32m[0907 03-25-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31246, current rewards: 83.62353, mean: 0.04496
[32m[0907 03-25-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31251, current rewards: 92.16145, mean: 0.04825
[32m[0907 03-26-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31257, current rewards: 100.69937, mean: 0.05138
[32m[0907 03-26-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31261, current rewards: 87.32970, mean: 0.04345
[32m[0907 03-26-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31261, current rewards: 37.32970, mean: 0.01812
[32m[0907 03-26-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31265, current rewards: -12.67030, mean: -0.00600
[32m[0907 03-27-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31267, current rewards: -62.67030, mean: -0.02901
[32m[0907 03-27-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31269, current rewards: -112.67030, mean: -0.05098
[32m[0907 03-27-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31270, current rewards: -162.67030, mean: -0.07198
[32m[0907 03-27-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31262, current rewards: -212.67030, mean: -0.09207
[32m[0907 03-28-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31252, current rewards: -262.67030, mean: -0.11130
[32m[0907 03-28-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31241, current rewards: -312.67030, mean: -0.12974
[32m[0907 03-28-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31231, current rewards: -362.67030, mean: -0.14743
[32m[0907 03-28-52 @Agent.py:117][0m Average action selection time: 0.3122
[32m[0907 03-28-52 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-28-52 @MBExp.py:227][0m Rewards obtained: [-402.67030196731866], Lows: [53], Highs: [545], Total time: 46615.934499999996
[32m[0907 03-30-37 @MBExp.py:144][0m ####################################################################
[32m[0907 03-30-37 @MBExp.py:145][0m Starting training iteration 57.
[32m[0907 03-30-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30016, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-30-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29977, current rewards: -24.00946, mean: -0.40016
[32m[0907 03-31-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30273, current rewards: -20.32590, mean: -0.18478
[32m[0907 03-31-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30674, current rewards: -16.57655, mean: -0.10360
[32m[0907 03-31-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30707, current rewards: -12.82674, mean: -0.06108
[32m[0907 03-31-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30727, current rewards: -9.07646, mean: -0.03491
[32m[0907 03-32-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30725, current rewards: -5.25163, mean: -0.01694
[32m[0907 03-32-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30734, current rewards: -1.16959, mean: -0.00325
[32m[0907 03-32-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30740, current rewards: 2.60165, mean: 0.00635
[32m[0907 03-32-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30749, current rewards: 6.37148, mean: 0.01385
[32m[0907 03-33-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30767, current rewards: 15.45693, mean: 0.03031
[32m[0907 03-33-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30845, current rewards: 19.68545, mean: 0.03515
[32m[0907 03-33-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30900, current rewards: 23.77443, mean: 0.03897
[32m[0907 03-34-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30942, current rewards: 27.86102, mean: 0.04221
[32m[0907 03-34-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30981, current rewards: 31.94886, mean: 0.04500
[32m[0907 03-34-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31012, current rewards: 35.30224, mean: 0.04645
[32m[0907 03-34-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31043, current rewards: 39.49173, mean: 0.04876
[32m[0907 03-35-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31066, current rewards: 43.67911, mean: 0.05079
[32m[0907 03-35-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31089, current rewards: -1.52244, mean: -0.00167
[32m[0907 03-35-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31110, current rewards: -7.80125, mean: -0.00813
[32m[0907 03-35-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31130, current rewards: -4.64096, mean: -0.00460
[32m[0907 03-36-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31148, current rewards: -1.46558, mean: -0.00138
[32m[0907 03-36-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31165, current rewards: 1.71123, mean: 0.00154
[32m[0907 03-36-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31178, current rewards: 8.76857, mean: 0.00756
[32m[0907 03-36-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31188, current rewards: 12.56008, mean: 0.01038
[32m[0907 03-37-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31202, current rewards: 16.16391, mean: 0.01283
[32m[0907 03-37-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31213, current rewards: -2.98209, mean: -0.00228
[32m[0907 03-37-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31224, current rewards: 1.38856, mean: 0.00102
[32m[0907 03-37-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31235, current rewards: 5.81813, mean: 0.00413
[32m[0907 03-38-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31243, current rewards: 10.24890, mean: 0.00702
[32m[0907 03-38-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31247, current rewards: 14.67573, mean: 0.00972
[32m[0907 03-38-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31254, current rewards: 18.91763, mean: 0.01213
[32m[0907 03-39-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31259, current rewards: 22.65549, mean: 0.01407
[32m[0907 03-39-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31263, current rewards: 26.93460, mean: 0.01623
[32m[0907 03-39-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31266, current rewards: 31.21373, mean: 0.01825
[32m[0907 03-39-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31273, current rewards: 35.49448, mean: 0.02017
[32m[0907 03-40-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31294, current rewards: 0.15177, mean: 0.00008
[32m[0907 03-40-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31300, current rewards: -0.33891, mean: -0.00018
[32m[0907 03-40-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31305, current rewards: 4.78141, mean: 0.00250
[32m[0907 03-40-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31308, current rewards: 9.93969, mean: 0.00507
[32m[0907 03-41-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31317, current rewards: 17.66700, mean: 0.00879
[32m[0907 03-41-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31320, current rewards: 23.21275, mean: 0.01127
[32m[0907 03-41-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31323, current rewards: 28.75805, mean: 0.01363
[32m[0907 03-41-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31326, current rewards: 34.30364, mean: 0.01588
[32m[0907 03-42-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31332, current rewards: 39.84921, mean: 0.01803
[32m[0907 03-42-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31333, current rewards: 33.17485, mean: 0.01468
[32m[0907 03-42-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31325, current rewards: 25.53389, mean: 0.01105
[32m[0907 03-42-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31314, current rewards: 28.98291, mean: 0.01228
[32m[0907 03-43-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31304, current rewards: 31.94748, mean: 0.01326
[32m[0907 03-43-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31293, current rewards: 35.38726, mean: 0.01439
[32m[0907 03-43-40 @Agent.py:117][0m Average action selection time: 0.3128
[32m[0907 03-43-40 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-43-40 @MBExp.py:227][0m Rewards obtained: [38.14506198823659], Lows: [43], Highs: [83], Total time: 47398.719594999995
[32m[0907 03-45-26 @MBExp.py:144][0m ####################################################################
[32m[0907 03-45-26 @MBExp.py:145][0m Starting training iteration 58.
[32m[0907 03-45-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31852, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-45-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30276, current rewards: -27.49505, mean: -0.45825
[32m[0907 03-46-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30451, current rewards: -22.09113, mean: -0.20083
[32m[0907 03-46-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30747, current rewards: -16.53163, mean: -0.10332
[32m[0907 03-46-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30763, current rewards: -10.98391, mean: -0.05230
[32m[0907 03-46-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30785, current rewards: -5.43309, mean: -0.02090
[32m[0907 03-47-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30789, current rewards: -7.73666, mean: -0.02496
[32m[0907 03-47-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30796, current rewards: -102.79269, mean: -0.28554
[32m[0907 03-47-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30835, current rewards: -137.06364, mean: -0.33430
[32m[0907 03-47-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30835, current rewards: -154.51734, mean: -0.33591
[32m[0907 03-48-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30838, current rewards: -219.99499, mean: -0.43136
[32m[0907 03-48-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30916, current rewards: -304.94073, mean: -0.54454
[32m[0907 03-48-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30975, current rewards: -370.08703, mean: -0.60670
[32m[0907 03-48-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31025, current rewards: -420.47780, mean: -0.63709
[32m[0907 03-49-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31090, current rewards: -454.91611, mean: -0.64073
[32m[0907 03-49-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31119, current rewards: -521.25262, mean: -0.68586
[32m[0907 03-49-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31158, current rewards: -576.66536, mean: -0.71193
[32m[0907 03-49-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31186, current rewards: -640.96496, mean: -0.74531
[32m[0907 03-50-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31204, current rewards: -651.76072, mean: -0.71622
[32m[0907 03-50-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31223, current rewards: -731.33637, mean: -0.76181
[32m[0907 03-50-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31239, current rewards: -831.33637, mean: -0.82311
[32m[0907 03-50-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31254, current rewards: -931.33637, mean: -0.87862
[32m[0907 03-51-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31266, current rewards: -1031.33637, mean: -0.92913
[32m[0907 03-51-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31276, current rewards: -1131.33637, mean: -0.97529
[32m[0907 03-51-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31286, current rewards: -1231.33637, mean: -1.01763
[32m[0907 03-52-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31296, current rewards: -1331.33637, mean: -1.05662
[32m[0907 03-52-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31300, current rewards: -1431.33637, mean: -1.09262
[32m[0907 03-52-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31304, current rewards: -1531.33637, mean: -1.12598
[32m[0907 03-52-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31305, current rewards: -1631.33637, mean: -1.15698
[32m[0907 03-53-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31305, current rewards: -1731.33637, mean: -1.18585
[32m[0907 03-53-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31310, current rewards: -1831.33637, mean: -1.21281
[32m[0907 03-53-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31312, current rewards: -1931.33637, mean: -1.23804
[32m[0907 03-53-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31319, current rewards: -2031.33637, mean: -1.26170
[32m[0907 03-54-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31324, current rewards: -2131.33637, mean: -1.28394
[32m[0907 03-54-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31327, current rewards: -2231.33637, mean: -1.30488
[32m[0907 03-54-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31329, current rewards: -2331.33637, mean: -1.32462
[32m[0907 03-54-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31331, current rewards: -2431.33637, mean: -1.34328
[32m[0907 03-55-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31330, current rewards: -2531.33637, mean: -1.36093
[32m[0907 03-55-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31331, current rewards: -2631.33637, mean: -1.37766
[32m[0907 03-55-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31334, current rewards: -2731.33637, mean: -1.39354
[32m[0907 03-55-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31336, current rewards: -2831.33637, mean: -1.40863
[32m[0907 03-56-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31338, current rewards: -2931.33637, mean: -1.42298
[32m[0907 03-56-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31338, current rewards: -3031.33637, mean: -1.43665
[32m[0907 03-56-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31338, current rewards: -3131.33637, mean: -1.44969
[32m[0907 03-57-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31338, current rewards: -3231.33637, mean: -1.46214
[32m[0907 03-57-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31338, current rewards: -3331.33637, mean: -1.47404
[32m[0907 03-57-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31337, current rewards: -3431.33637, mean: -1.48543
[32m[0907 03-57-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31323, current rewards: -3531.33637, mean: -1.49633
[32m[0907 03-58-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31310, current rewards: -3631.33637, mean: -1.50678
[32m[0907 03-58-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31298, current rewards: -3731.33637, mean: -1.51680
[32m[0907 03-58-29 @Agent.py:117][0m Average action selection time: 0.3129
[32m[0907 03-58-29 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-58-29 @MBExp.py:227][0m Rewards obtained: [-3811.3363714245224], Lows: [1929], Highs: [55], Total time: 48181.642932999996
[32m[0907 04-00-18 @MBExp.py:144][0m ####################################################################
[32m[0907 04-00-18 @MBExp.py:145][0m Starting training iteration 59.
[32m[0907 04-00-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29759, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-00-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29860, current rewards: -33.64668, mean: -0.56078
[32m[0907 04-00-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30158, current rewards: -28.17703, mean: -0.25615
[32m[0907 04-01-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30510, current rewards: -22.83049, mean: -0.14269
[32m[0907 04-01-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30584, current rewards: -17.48438, mean: -0.08326
[32m[0907 04-01-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30639, current rewards: -12.14038, mean: -0.04669
[32m[0907 04-01-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30678, current rewards: -6.92474, mean: -0.02234
[32m[0907 04-02-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30720, current rewards: -3.00100, mean: -0.00834
[32m[0907 04-02-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30737, current rewards: 2.35739, mean: 0.00575
[32m[0907 04-02-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30756, current rewards: 8.04004, mean: 0.01748
[32m[0907 04-02-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30770, current rewards: 13.72397, mean: 0.02691
[32m[0907 04-03-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30851, current rewards: 19.40176, mean: 0.03465
[32m[0907 04-03-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30910, current rewards: 25.08464, mean: 0.04112
[32m[0907 04-03-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30950, current rewards: 30.76431, mean: 0.04661
[32m[0907 04-03-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30992, current rewards: 36.44165, mean: 0.05133
[32m[0907 04-04-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31032, current rewards: 42.01203, mean: 0.05528
[32m[0907 04-04-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31062, current rewards: 47.57695, mean: 0.05874
[32m[0907 04-04-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31086, current rewards: 53.19839, mean: 0.06186
[32m[0907 04-05-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31108, current rewards: 58.82555, mean: 0.06464
[32m[0907 04-05-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31123, current rewards: 64.44725, mean: 0.06713
[32m[0907 04-05-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31145, current rewards: 70.06499, mean: 0.06937
[32m[0907 04-05-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31162, current rewards: 75.69188, mean: 0.07141
[32m[0907 04-06-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31175, current rewards: 80.36914, mean: 0.07240
[32m[0907 04-06-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31183, current rewards: 31.11142, mean: 0.02682
[32m[0907 04-06-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31194, current rewards: -23.28020, mean: -0.01924
[32m[0907 04-06-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31207, current rewards: -74.56785, mean: -0.05918
[32m[0907 04-07-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31212, current rewards: -102.26344, mean: -0.07806
[32m[0907 04-07-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31219, current rewards: -138.47819, mean: -0.10182
[32m[0907 04-07-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31224, current rewards: -123.01285, mean: -0.08724
[32m[0907 04-07-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31232, current rewards: -112.52940, mean: -0.07707
[32m[0907 04-08-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31238, current rewards: -149.37058, mean: -0.09892
[32m[0907 04-08-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31242, current rewards: -179.58717, mean: -0.11512
[32m[0907 04-08-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31248, current rewards: -187.46850, mean: -0.11644
[32m[0907 04-08-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31253, current rewards: -181.11192, mean: -0.10910
[32m[0907 04-09-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31260, current rewards: -174.79649, mean: -0.10222
[32m[0907 04-09-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31265, current rewards: -180.87046, mean: -0.10277
[32m[0907 04-09-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31267, current rewards: -230.87046, mean: -0.12755
[32m[0907 04-10-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31271, current rewards: -280.87046, mean: -0.15101
[32m[0907 04-10-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31275, current rewards: -330.87046, mean: -0.17323
[32m[0907 04-10-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31279, current rewards: -380.87046, mean: -0.19432
[32m[0907 04-10-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31297, current rewards: -404.44620, mean: -0.20122
[32m[0907 04-11-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31301, current rewards: -397.18230, mean: -0.19281
[32m[0907 04-11-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31307, current rewards: -391.17056, mean: -0.18539
[32m[0907 04-11-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31309, current rewards: -385.17900, mean: -0.17832
[32m[0907 04-11-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31312, current rewards: -391.91105, mean: -0.17734
[32m[0907 04-12-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31315, current rewards: -417.20090, mean: -0.18460
[32m[0907 04-12-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31318, current rewards: -411.97601, mean: -0.17834
[32m[0907 04-12-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31306, current rewards: -406.83135, mean: -0.17239
[32m[0907 04-12-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31294, current rewards: -424.42340, mean: -0.17611
[32m[0907 04-13-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31283, current rewards: -422.97604, mean: -0.17194
[32m[0907 04-13-20 @Agent.py:117][0m Average action selection time: 0.3128
[32m[0907 04-13-20 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-13-20 @MBExp.py:227][0m Rewards obtained: [-418.54429515984543], Lows: [218], Highs: [255], Total time: 48964.20892999999
[32m[0907 04-15-10 @MBExp.py:144][0m ####################################################################
[32m[0907 04-15-10 @MBExp.py:145][0m Starting training iteration 60.
[32m[0907 04-15-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29926, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-15-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29967, current rewards: -38.01986, mean: -0.63366
[32m[0907 04-15-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30244, current rewards: -31.84276, mean: -0.28948
[32m[0907 04-15-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30564, current rewards: -25.82929, mean: -0.16143
[32m[0907 04-16-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30636, current rewards: -19.82230, mean: -0.09439
[32m[0907 04-16-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30680, current rewards: -13.80720, mean: -0.05310
[32m[0907 04-16-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30713, current rewards: -7.79758, mean: -0.02515
[32m[0907 04-17-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30731, current rewards: -2.52878, mean: -0.00702
[32m[0907 04-17-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30751, current rewards: 2.79115, mean: 0.00681
[32m[0907 04-17-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30758, current rewards: 7.18822, mean: 0.01563
[32m[0907 04-17-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30773, current rewards: 12.01510, mean: 0.02356
[32m[0907 04-18-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30846, current rewards: 16.84492, mean: 0.03008
[32m[0907 04-18-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30906, current rewards: 21.66867, mean: 0.03552
[32m[0907 04-18-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30958, current rewards: 26.49151, mean: 0.04014
[32m[0907 04-18-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31004, current rewards: 30.32829, mean: 0.04272
[32m[0907 04-19-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31044, current rewards: 36.32792, mean: 0.04780
[32m[0907 04-19-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31079, current rewards: 43.05892, mean: 0.05316
[32m[0907 04-19-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31112, current rewards: 49.62081, mean: 0.05770
[32m[0907 04-19-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31138, current rewards: 56.19254, mean: 0.06175
[32m[0907 04-20-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31152, current rewards: 58.51103, mean: 0.06095
[32m[0907 04-20-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31171, current rewards: 25.25754, mean: 0.02501
[32m[0907 04-20-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31185, current rewards: 30.85718, mean: 0.02911
[32m[0907 04-20-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31198, current rewards: 36.46683, mean: 0.03285
[32m[0907 04-21-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31212, current rewards: 44.11930, mean: 0.03803
[32m[0907 04-21-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31221, current rewards: 49.73799, mean: 0.04111
[32m[0907 04-21-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31228, current rewards: 55.33116, mean: 0.04391
[32m[0907 04-22-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31238, current rewards: 60.92230, mean: 0.04651
[32m[0907 04-22-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31250, current rewards: 66.51711, mean: 0.04891
[32m[0907 04-22-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31257, current rewards: 72.10967, mean: 0.05114
[32m[0907 04-22-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31264, current rewards: 77.70149, mean: 0.05322
[32m[0907 04-23-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31269, current rewards: 83.29174, mean: 0.05516
[32m[0907 04-23-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31273, current rewards: 89.37225, mean: 0.05729
[32m[0907 04-23-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31323, current rewards: 75.26417, mean: 0.04675
[32m[0907 04-23-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31328, current rewards: 80.63122, mean: 0.04857
[32m[0907 04-24-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31330, current rewards: 86.22789, mean: 0.05043
[32m[0907 04-24-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31331, current rewards: 91.81883, mean: 0.05217
[32m[0907 04-24-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31333, current rewards: 97.41776, mean: 0.05382
[32m[0907 04-24-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31333, current rewards: 103.02142, mean: 0.05539
[32m[0907 04-25-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31335, current rewards: 108.61868, mean: 0.05687
[32m[0907 04-25-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31338, current rewards: 114.30255, mean: 0.05832
[32m[0907 04-25-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31339, current rewards: 120.16353, mean: 0.05978
[32m[0907 04-25-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31343, current rewards: 125.76426, mean: 0.06105
[32m[0907 04-26-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31347, current rewards: 131.36508, mean: 0.06226
[32m[0907 04-26-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31350, current rewards: 136.96611, mean: 0.06341
[32m[0907 04-26-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31352, current rewards: 142.56756, mean: 0.06451
[32m[0907 04-27-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31355, current rewards: 148.16449, mean: 0.06556
[32m[0907 04-27-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31361, current rewards: 111.36039, mean: 0.04821
[32m[0907 04-27-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31349, current rewards: 114.92031, mean: 0.04870
[32m[0907 04-27-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31338, current rewards: 118.17114, mean: 0.04903
[32m[0907 04-28-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31326, current rewards: 121.72253, mean: 0.04948
[32m[0907 04-28-14 @Agent.py:117][0m Average action selection time: 0.3132
[32m[0907 04-28-14 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-28-14 @MBExp.py:227][0m Rewards obtained: [124.58591046999764], Lows: [61], Highs: [20], Total time: 49747.791767999995
[32m[0907 04-30-06 @MBExp.py:144][0m ####################################################################
[32m[0907 04-30-06 @MBExp.py:145][0m Starting training iteration 61.
[32m[0907 04-30-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29800, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-30-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29881, current rewards: -24.18621, mean: -0.40310
[32m[0907 04-30-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30159, current rewards: -24.07433, mean: -0.21886
[32m[0907 04-30-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30422, current rewards: -18.89471, mean: -0.11809
[32m[0907 04-31-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30526, current rewards: -13.52926, mean: -0.06443
[32m[0907 04-31-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30584, current rewards: -8.15755, mean: -0.03138
[32m[0907 04-31-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30622, current rewards: -3.58740, mean: -0.01157
[32m[0907 04-31-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30649, current rewards: 1.78468, mean: 0.00496
[32m[0907 04-32-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30676, current rewards: -19.57499, mean: -0.04774
[32m[0907 04-32-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30687, current rewards: -34.52245, mean: -0.07505
[32m[0907 04-32-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30723, current rewards: -32.75597, mean: -0.06423
[32m[0907 04-32-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30792, current rewards: -31.99069, mean: -0.05713
[32m[0907 04-33-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30861, current rewards: -30.13348, mean: -0.04940
[32m[0907 04-33-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30919, current rewards: -28.36880, mean: -0.04298
[32m[0907 04-33-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30962, current rewards: -27.83963, mean: -0.03921
[32m[0907 04-34-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31053, current rewards: -33.47050, mean: -0.04404
[32m[0907 04-34-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31189, current rewards: -96.64901, mean: -0.11932
[32m[0907 04-34-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31213, current rewards: -110.54187, mean: -0.12854
[32m[0907 04-34-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31232, current rewards: -128.46236, mean: -0.14117
[32m[0907 04-35-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31250, current rewards: -148.47858, mean: -0.15467
[32m[0907 04-35-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31262, current rewards: -166.32263, mean: -0.16468
[32m[0907 04-35-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31273, current rewards: -172.52552, mean: -0.16276
[32m[0907 04-35-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31281, current rewards: -169.97673, mean: -0.15313
[32m[0907 04-36-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31290, current rewards: -164.35978, mean: -0.14169
[32m[0907 04-36-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31299, current rewards: -185.61664, mean: -0.15340
[32m[0907 04-36-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31317, current rewards: -249.83851, mean: -0.19828
[32m[0907 04-36-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31320, current rewards: -349.83851, mean: -0.26705
[32m[0907 04-37-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31326, current rewards: -449.83851, mean: -0.33076
[32m[0907 04-37-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31328, current rewards: -549.83851, mean: -0.38996
[32m[0907 04-37-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31331, current rewards: -649.83851, mean: -0.44509
[32m[0907 04-37-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31335, current rewards: -749.83851, mean: -0.49658
[32m[0907 04-38-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31336, current rewards: -849.83851, mean: -0.54477
[32m[0907 04-38-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31338, current rewards: -949.83851, mean: -0.58996
[32m[0907 04-38-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31339, current rewards: -1049.83851, mean: -0.63243
[32m[0907 04-39-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31339, current rewards: -1149.83851, mean: -0.67242
[32m[0907 04-39-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31339, current rewards: -1249.83851, mean: -0.71014
[32m[0907 04-39-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31341, current rewards: -1349.83851, mean: -0.74577
[32m[0907 04-39-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31342, current rewards: -1449.83851, mean: -0.77948
[32m[0907 04-40-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31343, current rewards: -1549.83851, mean: -0.81143
[32m[0907 04-40-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31341, current rewards: -1649.83851, mean: -0.84175
[32m[0907 04-40-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31340, current rewards: -1749.83851, mean: -0.87057
[32m[0907 04-40-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31342, current rewards: -1849.83851, mean: -0.89798
[32m[0907 04-41-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31341, current rewards: -1949.83851, mean: -0.92409
[32m[0907 04-41-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31341, current rewards: -2049.83851, mean: -0.94900
[32m[0907 04-41-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31342, current rewards: -2149.83851, mean: -0.97278
[32m[0907 04-41-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31341, current rewards: -2249.83851, mean: -0.99550
[32m[0907 04-42-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31337, current rewards: -2349.83851, mean: -1.01725
[32m[0907 04-42-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31324, current rewards: -2449.83851, mean: -1.03807
[32m[0907 04-42-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31312, current rewards: -2549.83851, mean: -1.05802
[32m[0907 04-42-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31299, current rewards: -2649.83851, mean: -1.07717
[32m[0907 04-43-09 @Agent.py:117][0m Average action selection time: 0.3129
[32m[0907 04-43-09 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-43-09 @MBExp.py:227][0m Rewards obtained: [-2729.8385136099337], Lows: [1311], Highs: [197], Total time: 50530.722546
[32m[0907 04-45-03 @MBExp.py:144][0m ####################################################################
[32m[0907 04-45-03 @MBExp.py:145][0m Starting training iteration 62.
[32m[0907 04-45-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31775, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-45-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30229, current rewards: -99.00000, mean: -1.65000
[32m[0907 04-45-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30138, current rewards: -199.00000, mean: -1.80909
[32m[0907 04-45-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30094, current rewards: -299.00000, mean: -1.86875
[32m[0907 04-46-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30260, current rewards: -399.00000, mean: -1.90000
[32m[0907 04-46-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30369, current rewards: -499.00000, mean: -1.91923
[32m[0907 04-46-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30451, current rewards: -599.00000, mean: -1.93226
[32m[0907 04-46-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30512, current rewards: -699.00000, mean: -1.94167
[32m[0907 04-47-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30555, current rewards: -799.00000, mean: -1.94878
[32m[0907 04-47-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30587, current rewards: -899.00000, mean: -1.95435
[32m[0907 04-47-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30640, current rewards: -999.00000, mean: -1.95882
[32m[0907 04-47-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30728, current rewards: -1099.00000, mean: -1.96250
[32m[0907 04-48-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30805, current rewards: -1199.00000, mean: -1.96557
[32m[0907 04-48-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30865, current rewards: -1299.00000, mean: -1.96818
[32m[0907 04-48-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30912, current rewards: -1399.00000, mean: -1.97042
[32m[0907 04-48-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30949, current rewards: -1499.00000, mean: -1.97237
[32m[0907 04-49-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30987, current rewards: -1599.00000, mean: -1.97407
[32m[0907 04-49-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31019, current rewards: -1699.00000, mean: -1.97558
[32m[0907 04-49-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31045, current rewards: -1799.00000, mean: -1.97692
[32m[0907 04-50-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31067, current rewards: -1899.00000, mean: -1.97812
[32m[0907 04-50-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31088, current rewards: -1999.00000, mean: -1.97921
[32m[0907 04-50-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31099, current rewards: -2099.00000, mean: -1.98019
[32m[0907 04-50-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31113, current rewards: -2199.00000, mean: -1.98108
[32m[0907 04-51-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31125, current rewards: -2299.00000, mean: -1.98190
[32m[0907 04-51-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31136, current rewards: -2399.00000, mean: -1.98264
[32m[0907 04-51-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31148, current rewards: -2499.00000, mean: -1.98333
[32m[0907 04-51-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31158, current rewards: -2599.00000, mean: -1.98397
[32m[0907 04-52-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31166, current rewards: -2699.00000, mean: -1.98456
[32m[0907 04-52-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31175, current rewards: -2799.00000, mean: -1.98511
[32m[0907 04-52-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31183, current rewards: -2899.00000, mean: -1.98562
[32m[0907 04-52-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31189, current rewards: -2999.00000, mean: -1.98609
[32m[0907 04-53-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31194, current rewards: -3099.00000, mean: -1.98654
[32m[0907 04-53-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31199, current rewards: -3199.00000, mean: -1.98696
[32m[0907 04-53-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31201, current rewards: -3299.00000, mean: -1.98735
[32m[0907 04-53-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31204, current rewards: -3399.00000, mean: -1.98772
[32m[0907 04-54-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31209, current rewards: -3499.00000, mean: -1.98807
[32m[0907 04-54-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31212, current rewards: -3599.00000, mean: -1.98840
[32m[0907 04-54-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31214, current rewards: -3699.00000, mean: -1.98871
[32m[0907 04-54-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31219, current rewards: -3799.00000, mean: -1.98901
[32m[0907 04-55-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31224, current rewards: -3899.00000, mean: -1.98929
[32m[0907 04-55-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31228, current rewards: -3999.00000, mean: -1.98955
[32m[0907 04-55-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31233, current rewards: -4099.00000, mean: -1.98981
[32m[0907 04-56-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31238, current rewards: -4199.00000, mean: -1.99005
[32m[0907 04-56-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31240, current rewards: -4299.00000, mean: -1.99028
[32m[0907 04-56-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31245, current rewards: -4399.00000, mean: -1.99050
[32m[0907 04-56-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31249, current rewards: -4499.00000, mean: -1.99071
[32m[0907 04-57-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31250, current rewards: -4599.00000, mean: -1.99091
[32m[0907 04-57-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31241, current rewards: -4699.00000, mean: -1.99110
[32m[0907 04-57-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31231, current rewards: -4799.00000, mean: -1.99129
[32m[0907 04-57-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31221, current rewards: -4899.00000, mean: -1.99146
[32m[0907 04-58-04 @Agent.py:117][0m Average action selection time: 0.3121
[32m[0907 04-58-04 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-58-04 @MBExp.py:227][0m Rewards obtained: [-4979], Lows: [2479], Highs: [21], Total time: 51311.750408
[32m[0907 04-59-59 @MBExp.py:144][0m ####################################################################
[32m[0907 04-59-59 @MBExp.py:145][0m Starting training iteration 63.
[32m[0907 05-00-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29798, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-00-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31760, current rewards: -60.64233, mean: -1.01071
[32m[0907 05-00-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30867, current rewards: -55.81132, mean: -0.50738
[32m[0907 05-00-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30561, current rewards: -50.45193, mean: -0.31532
[32m[0907 05-01-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30587, current rewards: -44.82520, mean: -0.21345
[32m[0907 05-01-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30630, current rewards: -39.62775, mean: -0.15241
[32m[0907 05-01-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30654, current rewards: -34.07914, mean: -0.10993
[32m[0907 05-01-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30675, current rewards: -28.49951, mean: -0.07917
[32m[0907 05-02-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30685, current rewards: -22.91794, mean: -0.05590
[32m[0907 05-02-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30698, current rewards: -17.33748, mean: -0.03769
[32m[0907 05-02-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30740, current rewards: -11.75226, mean: -0.02304
[32m[0907 05-02-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30993, current rewards: -50.59707, mean: -0.09035
[32m[0907 05-03-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31038, current rewards: -76.25076, mean: -0.12500
[32m[0907 05-03-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31143, current rewards: -110.67156, mean: -0.16768
[32m[0907 05-03-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31199, current rewards: -144.03180, mean: -0.20286
[32m[0907 05-03-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31233, current rewards: -149.60705, mean: -0.19685
[32m[0907 05-04-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31253, current rewards: -151.61055, mean: -0.18717
[32m[0907 05-04-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31273, current rewards: -149.53581, mean: -0.17388
[32m[0907 05-04-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31287, current rewards: -197.23057, mean: -0.21674
[32m[0907 05-05-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31300, current rewards: -190.78050, mean: -0.19873
[32m[0907 05-05-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31311, current rewards: -185.33134, mean: -0.18350
[32m[0907 05-05-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31315, current rewards: -179.96272, mean: -0.16978
[32m[0907 05-05-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31325, current rewards: -174.49037, mean: -0.15720
[32m[0907 05-06-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31336, current rewards: -175.34409, mean: -0.15116
[32m[0907 05-06-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31409, current rewards: -225.12254, mean: -0.18605
[32m[0907 05-06-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31412, current rewards: -218.71969, mean: -0.17359
[32m[0907 05-06-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31411, current rewards: -212.84754, mean: -0.16248
[32m[0907 05-07-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31413, current rewards: -206.97894, mean: -0.15219
[32m[0907 05-07-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31414, current rewards: -201.11167, mean: -0.14263
[32m[0907 05-07-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31419, current rewards: -195.24139, mean: -0.13373
[32m[0907 05-07-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31424, current rewards: -189.37896, mean: -0.12542
[32m[0907 05-08-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31427, current rewards: -183.50786, mean: -0.11763
[32m[0907 05-08-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31429, current rewards: -177.64202, mean: -0.11034
[32m[0907 05-08-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31431, current rewards: -171.77225, mean: -0.10348
[32m[0907 05-08-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31434, current rewards: -165.90622, mean: -0.09702
[32m[0907 05-09-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31433, current rewards: -225.81447, mean: -0.12830
[32m[0907 05-09-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31434, current rewards: -277.41542, mean: -0.15327
[32m[0907 05-09-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31436, current rewards: -335.29692, mean: -0.18027
[32m[0907 05-10-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31435, current rewards: -386.94300, mean: -0.20259
[32m[0907 05-10-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31433, current rewards: -439.34274, mean: -0.22415
[32m[0907 05-10-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31439, current rewards: -501.01086, mean: -0.24926
[32m[0907 05-10-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31439, current rewards: -554.70445, mean: -0.26927
[32m[0907 05-11-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31438, current rewards: -615.49750, mean: -0.29170
[32m[0907 05-11-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31440, current rewards: -676.15581, mean: -0.31304
[32m[0907 05-11-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31444, current rewards: -737.08102, mean: -0.33352
[32m[0907 05-11-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31444, current rewards: -789.10876, mean: -0.34916
[32m[0907 05-12-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31452, current rewards: -828.87768, mean: -0.35882
[32m[0907 05-12-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31439, current rewards: -864.55410, mean: -0.36634
[32m[0907 05-12-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31425, current rewards: -859.36907, mean: -0.35658
[32m[0907 05-12-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31413, current rewards: -853.95318, mean: -0.34714
[32m[0907 05-13-05 @Agent.py:117][0m Average action selection time: 0.3140
[32m[0907 05-13-05 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-13-05 @MBExp.py:227][0m Rewards obtained: [-849.6181138110679], Lows: [430], Highs: [229], Total time: 52097.572187
[32m[0907 05-15-03 @MBExp.py:144][0m ####################################################################
[32m[0907 05-15-03 @MBExp.py:145][0m Starting training iteration 64.
[32m[0907 05-15-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29801, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-15-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30079, current rewards: -59.07339, mean: -0.98456
[32m[0907 05-15-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29917, current rewards: -55.36186, mean: -0.50329
[32m[0907 05-15-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29927, current rewards: -51.70852, mean: -0.32318
[32m[0907 05-16-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29935, current rewards: -46.88762, mean: -0.22327
[32m[0907 05-16-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30032, current rewards: -42.06086, mean: -0.16177
[32m[0907 05-16-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30155, current rewards: -37.25116, mean: -0.12017
[32m[0907 05-16-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30252, current rewards: -32.43017, mean: -0.09008
[32m[0907 05-17-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30323, current rewards: -27.61219, mean: -0.06735
[32m[0907 05-17-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30375, current rewards: -22.80117, mean: -0.04957
[32m[0907 05-17-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30474, current rewards: -17.97223, mean: -0.03524
[32m[0907 05-17-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30566, current rewards: -12.71531, mean: -0.02271
[32m[0907 05-18-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30640, current rewards: 0.62646, mean: 0.00103
[32m[0907 05-18-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30710, current rewards: 6.15282, mean: 0.00932
[32m[0907 05-18-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30765, current rewards: 11.67968, mean: 0.01645
[32m[0907 05-18-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30820, current rewards: -35.85843, mean: -0.04718
[32m[0907 05-19-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30869, current rewards: -50.38566, mean: -0.06220
[32m[0907 05-19-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30911, current rewards: -67.59819, mean: -0.07860
[32m[0907 05-19-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30937, current rewards: -74.00640, mean: -0.08133
[32m[0907 05-20-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30971, current rewards: -77.42414, mean: -0.08065
[32m[0907 05-20-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31001, current rewards: -87.77440, mean: -0.08691
[32m[0907 05-20-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31021, current rewards: -91.64359, mean: -0.08646
[32m[0907 05-20-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31043, current rewards: -95.49226, mean: -0.08603
[32m[0907 05-21-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31082, current rewards: -145.25264, mean: -0.12522
[32m[0907 05-21-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31093, current rewards: -188.95457, mean: -0.15616
[32m[0907 05-21-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31135, current rewards: -223.29993, mean: -0.17722
[32m[0907 05-21-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31147, current rewards: -232.19956, mean: -0.17725
[32m[0907 05-22-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31167, current rewards: -246.73211, mean: -0.18142
[32m[0907 05-22-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31181, current rewards: -272.85347, mean: -0.19351
[32m[0907 05-22-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31190, current rewards: -275.35236, mean: -0.18860
[32m[0907 05-22-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31200, current rewards: -270.29567, mean: -0.17900
[32m[0907 05-23-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31211, current rewards: -265.24164, mean: -0.17003
[32m[0907 05-23-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31217, current rewards: -260.18957, mean: -0.16161
[32m[0907 05-23-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31223, current rewards: -255.13414, mean: -0.15370
[32m[0907 05-23-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31230, current rewards: -250.07548, mean: -0.14624
[32m[0907 05-24-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31239, current rewards: -245.02186, mean: -0.13922
[32m[0907 05-24-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31241, current rewards: -241.07518, mean: -0.13319
[32m[0907 05-24-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31246, current rewards: -236.14917, mean: -0.12696
[32m[0907 05-25-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31249, current rewards: -231.11054, mean: -0.12100
[32m[0907 05-25-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31255, current rewards: -233.77361, mean: -0.11927
[32m[0907 05-25-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31258, current rewards: -255.96265, mean: -0.12734
[32m[0907 05-25-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31261, current rewards: -250.86418, mean: -0.12178
[32m[0907 05-26-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31264, current rewards: -245.91216, mean: -0.11655
[32m[0907 05-26-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31266, current rewards: -240.96964, mean: -0.11156
[32m[0907 05-26-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31270, current rewards: -235.32651, mean: -0.10648
[32m[0907 05-26-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31271, current rewards: -229.83980, mean: -0.10170
[32m[0907 05-27-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31270, current rewards: -225.00905, mean: -0.09741
[32m[0907 05-27-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31259, current rewards: -220.17567, mean: -0.09329
[32m[0907 05-27-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31247, current rewards: -215.34997, mean: -0.08936
[32m[0907 05-27-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31246, current rewards: -249.85302, mean: -0.10157
[32m[0907 05-28-04 @Agent.py:117][0m Average action selection time: 0.3124
[32m[0907 05-28-04 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-28-04 @MBExp.py:227][0m Rewards obtained: [-245.15837268305157], Lows: [244], Highs: [48], Total time: 52879.249968
[32m[0907 05-30-04 @MBExp.py:144][0m ####################################################################
[32m[0907 05-30-04 @MBExp.py:145][0m Starting training iteration 65.
[32m[0907 05-30-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29652, current rewards: -2.61847, mean: -0.26185
[32m[0907 05-30-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29843, current rewards: -17.61175, mean: -0.29353
[32m[0907 05-30-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29750, current rewards: -14.34694, mean: -0.13043
[32m[0907 05-30-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29793, current rewards: -11.20600, mean: -0.07004
[32m[0907 05-31-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29810, current rewards: -7.99691, mean: -0.03808
[32m[0907 05-31-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29849, current rewards: -4.83978, mean: -0.01861
[32m[0907 05-31-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29998, current rewards: -1.63103, mean: -0.00526
[32m[0907 05-31-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30110, current rewards: 1.51195, mean: 0.00420
[32m[0907 05-32-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30190, current rewards: 4.71985, mean: 0.01151
[32m[0907 05-32-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30254, current rewards: 7.85843, mean: 0.01708
[32m[0907 05-32-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30359, current rewards: 11.06306, mean: 0.02169
[32m[0907 05-32-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30462, current rewards: 14.32942, mean: 0.02559
[32m[0907 05-33-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30549, current rewards: 17.53300, mean: 0.02874
[32m[0907 05-33-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30628, current rewards: 19.66745, mean: 0.02980
[32m[0907 05-33-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30702, current rewards: -28.90522, mean: -0.04071
[32m[0907 05-33-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30758, current rewards: -31.66000, mean: -0.04166
[32m[0907 05-34-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30806, current rewards: -26.60952, mean: -0.03285
[32m[0907 05-34-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30844, current rewards: -21.39518, mean: -0.02488
[32m[0907 05-34-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30882, current rewards: -16.17940, mean: -0.01778
[32m[0907 05-35-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30912, current rewards: -8.20277, mean: -0.00854
[32m[0907 05-35-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30942, current rewards: -2.59998, mean: -0.00257
[32m[0907 05-35-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30968, current rewards: 3.12569, mean: 0.00295
[32m[0907 05-35-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30996, current rewards: 8.85303, mean: 0.00798
[32m[0907 05-36-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31017, current rewards: 14.57147, mean: 0.01256
[32m[0907 05-36-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31037, current rewards: -21.36335, mean: -0.01766
[32m[0907 05-36-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31054, current rewards: -18.58445, mean: -0.01475
[32m[0907 05-36-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31070, current rewards: -13.26787, mean: -0.01013
[32m[0907 05-37-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31087, current rewards: -7.96234, mean: -0.00585
[32m[0907 05-37-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31098, current rewards: -2.65271, mean: -0.00188
[32m[0907 05-37-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31111, current rewards: 2.65747, mean: 0.00182
[32m[0907 05-37-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31121, current rewards: 7.96710, mean: 0.00528
[32m[0907 05-38-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31135, current rewards: 13.27515, mean: 0.00851
[32m[0907 05-38-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31147, current rewards: 18.58695, mean: 0.01154
[32m[0907 05-38-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31158, current rewards: 23.89700, mean: 0.01440
[32m[0907 05-38-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31168, current rewards: 29.21033, mean: 0.01708
[32m[0907 05-39-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31172, current rewards: 14.43340, mean: 0.00820
[32m[0907 05-39-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31241, current rewards: -45.90911, mean: -0.02536
[32m[0907 05-39-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31285, current rewards: -79.09287, mean: -0.04252
[32m[0907 05-40-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31293, current rewards: -101.03209, mean: -0.05290
[32m[0907 05-40-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31295, current rewards: -121.21887, mean: -0.06185
[32m[0907 05-40-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31298, current rewards: -122.29143, mean: -0.06084
[32m[0907 05-40-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31303, current rewards: -114.09903, mean: -0.05539
[32m[0907 05-41-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31305, current rewards: -105.84081, mean: -0.05016
[32m[0907 05-41-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31309, current rewards: -87.42265, mean: -0.04047
[32m[0907 05-41-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31312, current rewards: -78.22661, mean: -0.03540
[32m[0907 05-41-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31313, current rewards: -69.25781, mean: -0.03065
[32m[0907 05-42-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31311, current rewards: -101.71847, mean: -0.04403
[32m[0907 05-42-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31299, current rewards: -100.08709, mean: -0.04241
[32m[0907 05-42-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31288, current rewards: -95.73751, mean: -0.03973
[32m[0907 05-42-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31275, current rewards: -91.39223, mean: -0.03715
[32m[0907 05-43-06 @Agent.py:117][0m Average action selection time: 0.3127
[32m[0907 05-43-06 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-43-06 @MBExp.py:227][0m Rewards obtained: [-87.91423235291923], Lows: [128], Highs: [91], Total time: 53661.608154999994
[32m[0907 05-45-08 @MBExp.py:144][0m ####################################################################
[32m[0907 05-45-08 @MBExp.py:145][0m Starting training iteration 66.
[32m[0907 05-45-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31861, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-45-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33594, current rewards: -51.96492, mean: -0.86608
[32m[0907 05-45-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32715, current rewards: -97.05626, mean: -0.88233
[32m[0907 05-45-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32055, current rewards: -173.09893, mean: -1.08187
[32m[0907 05-46-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31624, current rewards: -208.87267, mean: -0.99463
[32m[0907 05-46-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31412, current rewards: -222.50546, mean: -0.85579
[32m[0907 05-46-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31384, current rewards: -269.29471, mean: -0.86869
[32m[0907 05-47-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31297, current rewards: -320.91424, mean: -0.89143
[32m[0907 05-47-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31257, current rewards: -367.86497, mean: -0.89723
[32m[0907 05-47-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31318, current rewards: -455.73946, mean: -0.99074
[32m[0907 05-47-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31401, current rewards: -494.94267, mean: -0.97048
[32m[0907 05-48-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31452, current rewards: -548.31774, mean: -0.97914
[32m[0907 05-48-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31491, current rewards: -583.61772, mean: -0.95675
[32m[0907 05-48-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31531, current rewards: -655.25285, mean: -0.99281
[32m[0907 05-48-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31528, current rewards: -712.17251, mean: -1.00306
[32m[0907 05-49-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31528, current rewards: -755.48162, mean: -0.99405
[32m[0907 05-49-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31531, current rewards: -817.19348, mean: -1.00888
[32m[0907 05-49-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31556, current rewards: -878.83897, mean: -1.02191
[32m[0907 05-49-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31550, current rewards: -928.96852, mean: -1.02084
[32m[0907 05-50-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31569, current rewards: -990.43322, mean: -1.03170
[32m[0907 05-50-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31568, current rewards: -1037.05785, mean: -1.02679
[32m[0907 05-50-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31582, current rewards: -1104.34321, mean: -1.04183
[32m[0907 05-50-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31576, current rewards: -1167.78768, mean: -1.05206
[32m[0907 05-51-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31646, current rewards: -1244.89525, mean: -1.07319
[32m[0907 05-51-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31679, current rewards: -1309.93472, mean: -1.08259
[32m[0907 05-51-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31665, current rewards: -1315.29023, mean: -1.04388
[32m[0907 05-52-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31654, current rewards: -1311.49855, mean: -1.00114
[32m[0907 05-52-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31646, current rewards: -1308.30923, mean: -0.96199
[32m[0907 05-52-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31641, current rewards: -1304.25421, mean: -0.92500
[32m[0907 05-52-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31635, current rewards: -1300.18003, mean: -0.89053
[32m[0907 05-53-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31625, current rewards: -1296.11273, mean: -0.85835
[32m[0907 05-53-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31616, current rewards: -1292.04202, mean: -0.82823
[32m[0907 05-53-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31610, current rewards: -1287.97340, mean: -0.79998
[32m[0907 05-53-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31602, current rewards: -1283.90610, mean: -0.77344
[32m[0907 05-54-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31594, current rewards: -1279.83909, mean: -0.74844
[32m[0907 05-54-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31587, current rewards: -1271.91917, mean: -0.72268
[32m[0907 05-54-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31580, current rewards: -1286.36217, mean: -0.71070
[32m[0907 05-54-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31575, current rewards: -1281.10161, mean: -0.68876
[32m[0907 05-55-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31568, current rewards: -1275.81659, mean: -0.66797
[32m[0907 05-55-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31565, current rewards: -1270.53526, mean: -0.64823
[32m[0907 05-55-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31560, current rewards: -1265.25087, mean: -0.62948
[32m[0907 05-55-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31555, current rewards: -1260.85162, mean: -0.61206
[32m[0907 05-56-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31550, current rewards: -1254.82968, mean: -0.59471
[32m[0907 05-56-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31546, current rewards: -1248.57890, mean: -0.57805
[32m[0907 05-56-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31543, current rewards: -1242.57185, mean: -0.56225
[32m[0907 05-57-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31539, current rewards: -1236.55298, mean: -0.54715
[32m[0907 05-57-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31536, current rewards: -1230.53599, mean: -0.53270
[32m[0907 05-57-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31522, current rewards: -1224.51971, mean: -0.51886
[32m[0907 05-57-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31506, current rewards: -1218.51515, mean: -0.50561
[32m[0907 05-58-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31492, current rewards: -1220.98239, mean: -0.49633
[32m[0907 05-58-16 @Agent.py:117][0m Average action selection time: 0.3148
[32m[0907 05-58-16 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-58-16 @MBExp.py:227][0m Rewards obtained: [-1300.9823867321709], Lows: [692], Highs: [145], Total time: 54449.41691199999
[32m[0907 06-00-18 @MBExp.py:144][0m ####################################################################
[32m[0907 06-00-18 @MBExp.py:145][0m Starting training iteration 67.
[32m[0907 06-00-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.47744, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-00-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37551, current rewards: -79.22482, mean: -1.32041
[32m[0907 06-00-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37161, current rewards: -142.22823, mean: -1.29298
[32m[0907 06-01-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36157, current rewards: -153.35798, mean: -0.95849
[32m[0907 06-01-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34697, current rewards: -148.00655, mean: -0.70479
[32m[0907 06-01-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34195, current rewards: -197.46820, mean: -0.75949
[32m[0907 06-02-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33909, current rewards: -246.83570, mean: -0.79624
[32m[0907 06-02-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33625, current rewards: -324.55535, mean: -0.90154
[32m[0907 06-02-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33283, current rewards: -319.19583, mean: -0.77853
[32m[0907 06-02-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33102, current rewards: -313.53351, mean: -0.68159
[32m[0907 06-03-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32954, current rewards: -309.26707, mean: -0.60641
[32m[0907 06-03-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32828, current rewards: -303.74196, mean: -0.54240
[32m[0907 06-03-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32728, current rewards: -298.22716, mean: -0.48890
[32m[0907 06-03-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32638, current rewards: -292.71302, mean: -0.44350
[32m[0907 06-04-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32565, current rewards: -287.19883, mean: -0.40451
[32m[0907 06-04-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32496, current rewards: -281.68372, mean: -0.37064
[32m[0907 06-04-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32437, current rewards: -276.17065, mean: -0.34095
[32m[0907 06-04-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32385, current rewards: -290.63996, mean: -0.33795
[32m[0907 06-05-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32798, current rewards: -345.16147, mean: -0.37930
[32m[0907 06-05-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32786, current rewards: -397.60561, mean: -0.41417
[32m[0907 06-05-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32809, current rewards: -443.24462, mean: -0.43886
[32m[0907 06-06-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33089, current rewards: -512.91913, mean: -0.48389
[32m[0907 06-06-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33036, current rewards: -527.78304, mean: -0.47548
[32m[0907 06-06-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32973, current rewards: -522.04800, mean: -0.45004
[32m[0907 06-06-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32910, current rewards: -516.70601, mean: -0.42703
[32m[0907 06-07-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32847, current rewards: -511.36461, mean: -0.40584
[32m[0907 06-07-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32790, current rewards: -518.08134, mean: -0.39548
[32m[0907 06-07-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32911, current rewards: -547.20435, mean: -0.40236
[32m[0907 06-08-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33012, current rewards: -573.65692, mean: -0.40685
[32m[0907 06-08-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33154, current rewards: -620.82398, mean: -0.42522
[32m[0907 06-08-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33096, current rewards: -654.88315, mean: -0.43370
[32m[0907 06-08-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33041, current rewards: -690.33163, mean: -0.44252
[32m[0907 06-09-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32995, current rewards: -685.10131, mean: -0.42553
[32m[0907 06-09-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32949, current rewards: -679.84839, mean: -0.40955
[32m[0907 06-09-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32904, current rewards: -674.59550, mean: -0.39450
[32m[0907 06-09-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32874, current rewards: -672.30869, mean: -0.38199
[32m[0907 06-10-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32834, current rewards: -667.10412, mean: -0.36857
[32m[0907 06-10-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32796, current rewards: -662.00371, mean: -0.35592
[32m[0907 06-10-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32759, current rewards: -656.89900, mean: -0.34393
[32m[0907 06-11-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32724, current rewards: -652.81971, mean: -0.33307
[32m[0907 06-11-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32694, current rewards: -647.35281, mean: -0.32207
[32m[0907 06-11-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32666, current rewards: -642.42498, mean: -0.31186
[32m[0907 06-11-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32635, current rewards: -637.51374, mean: -0.30214
[32m[0907 06-12-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32607, current rewards: -631.99159, mean: -0.29259
[32m[0907 06-12-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32578, current rewards: -627.01616, mean: -0.28372
[32m[0907 06-12-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32551, current rewards: -622.01695, mean: -0.27523
[32m[0907 06-12-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32511, current rewards: -617.02176, mean: -0.26711
[32m[0907 06-13-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32474, current rewards: -612.02907, mean: -0.25933
[32m[0907 06-13-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32439, current rewards: -607.02927, mean: -0.25188
[32m[0907 06-13-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32403, current rewards: -602.02646, mean: -0.24473
[32m[0907 06-13-48 @Agent.py:117][0m Average action selection time: 0.3236
[32m[0907 06-13-48 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-13-48 @MBExp.py:227][0m Rewards obtained: [-598.0266284991468], Lows: [304], Highs: [222], Total time: 55259.209983999994
[32m[0907 06-15-53 @MBExp.py:144][0m ####################################################################
[32m[0907 06-15-53 @MBExp.py:145][0m Starting training iteration 68.
[32m[0907 06-15-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.45550, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-16-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.38291, current rewards: -54.52393, mean: -0.90873
[32m[0907 06-16-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34851, current rewards: -125.90292, mean: -1.14457
[32m[0907 06-16-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34426, current rewards: -174.46829, mean: -1.09043
[32m[0907 06-17-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34197, current rewards: -245.13083, mean: -1.16729
[32m[0907 06-17-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34023, current rewards: -304.88277, mean: -1.17263
[32m[0907 06-17-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33832, current rewards: -380.97930, mean: -1.22897
[32m[0907 06-17-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33616, current rewards: -416.22708, mean: -1.15619
[32m[0907 06-18-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33606, current rewards: -504.50908, mean: -1.23051
[32m[0907 06-18-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33660, current rewards: -582.79596, mean: -1.26695
[32m[0907 06-18-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33596, current rewards: -625.21541, mean: -1.22591
[32m[0907 06-19-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33402, current rewards: -675.21541, mean: -1.20574
[32m[0907 06-19-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33239, current rewards: -725.21541, mean: -1.18888
[32m[0907 06-19-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33096, current rewards: -775.21541, mean: -1.17457
[32m[0907 06-19-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32983, current rewards: -825.21541, mean: -1.16228
[32m[0907 06-20-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32878, current rewards: -875.21541, mean: -1.15160
[32m[0907 06-20-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32784, current rewards: -925.21541, mean: -1.14224
[32m[0907 06-20-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32703, current rewards: -975.21541, mean: -1.13397
[32m[0907 06-20-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32626, current rewards: -1025.21541, mean: -1.12661
[32m[0907 06-21-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32561, current rewards: -1075.21541, mean: -1.12002
[32m[0907 06-21-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32506, current rewards: -1125.21541, mean: -1.11407
[32m[0907 06-21-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32447, current rewards: -1175.21541, mean: -1.10869
[32m[0907 06-21-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32403, current rewards: -1225.21541, mean: -1.10380
[32m[0907 06-22-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32360, current rewards: -1275.21541, mean: -1.09932
[32m[0907 06-22-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32322, current rewards: -1325.21541, mean: -1.09522
[32m[0907 06-22-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32289, current rewards: -1375.21541, mean: -1.09144
[32m[0907 06-22-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32341, current rewards: -1425.21541, mean: -1.08795
[32m[0907 06-23-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32445, current rewards: -1475.21541, mean: -1.08472
[32m[0907 06-23-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32543, current rewards: -1525.21541, mean: -1.08171
[32m[0907 06-23-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32645, current rewards: -1575.21541, mean: -1.07891
[32m[0907 06-24-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32789, current rewards: -1625.21541, mean: -1.07630
[32m[0907 06-24-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32867, current rewards: -1649.63600, mean: -1.05746
[32m[0907 06-24-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32939, current rewards: -1646.34556, mean: -1.02257
[32m[0907 06-25-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33006, current rewards: -1643.05512, mean: -0.98979
[32m[0907 06-25-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32981, current rewards: -1639.85579, mean: -0.95898
[32m[0907 06-25-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32936, current rewards: -1637.04080, mean: -0.93014
[32m[0907 06-25-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32893, current rewards: -1634.22582, mean: -0.90289
[32m[0907 06-26-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32854, current rewards: -1631.41083, mean: -0.87710
[32m[0907 06-26-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32816, current rewards: -1628.59585, mean: -0.85267
[32m[0907 06-26-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32779, current rewards: -1625.78086, mean: -0.82948
[32m[0907 06-26-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32746, current rewards: -1622.96588, mean: -0.80745
[32m[0907 06-27-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32711, current rewards: -1620.15090, mean: -0.78648
[32m[0907 06-27-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32680, current rewards: -1617.30706, mean: -0.76650
[32m[0907 06-27-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32649, current rewards: -1614.26963, mean: -0.74735
[32m[0907 06-27-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32619, current rewards: -1660.02664, mean: -0.75114
[32m[0907 06-28-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32578, current rewards: -1710.02664, mean: -0.75665
[32m[0907 06-28-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32538, current rewards: -1760.02664, mean: -0.76192
[32m[0907 06-28-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32499, current rewards: -1810.02664, mean: -0.76696
[32m[0907 06-28-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32463, current rewards: -1860.02664, mean: -0.77180
[32m[0907 06-29-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32412, current rewards: -1910.02664, mean: -0.77643
[32m[0907 06-29-23 @Agent.py:117][0m Average action selection time: 0.3237
[32m[0907 06-29-23 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-29-23 @MBExp.py:227][0m Rewards obtained: [-1950.0266392239173], Lows: [297], Highs: [1422], Total time: 56069.20909
[32m[0907 06-31-29 @MBExp.py:144][0m ####################################################################
[32m[0907 06-31-29 @MBExp.py:145][0m Starting training iteration 69.
[32m[0907 06-31-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29812, current rewards: 0.91689, mean: 0.09169
[32m[0907 06-31-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29887, current rewards: -16.56416, mean: -0.27607
[32m[0907 06-32-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29918, current rewards: -29.76498, mean: -0.27059
[32m[0907 06-32-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30020, current rewards: -24.31173, mean: -0.15195
[32m[0907 06-32-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30212, current rewards: -45.47604, mean: -0.21655
[32m[0907 06-32-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30324, current rewards: -95.47604, mean: -0.36722
[32m[0907 06-33-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30406, current rewards: -145.47604, mean: -0.46928
[32m[0907 06-33-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30576, current rewards: -195.47604, mean: -0.54299
[32m[0907 06-33-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30698, current rewards: -245.47604, mean: -0.59872
[32m[0907 06-33-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30791, current rewards: -295.47604, mean: -0.64234
[32m[0907 06-34-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30862, current rewards: -345.47604, mean: -0.67740
[32m[0907 06-34-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30922, current rewards: -395.47604, mean: -0.70621
[32m[0907 06-34-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30980, current rewards: -445.47604, mean: -0.73029
[32m[0907 06-34-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31024, current rewards: -495.47604, mean: -0.75072
[32m[0907 06-35-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31058, current rewards: -545.47604, mean: -0.76828
[32m[0907 06-35-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31089, current rewards: -595.47604, mean: -0.78352
[32m[0907 06-35-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31112, current rewards: -645.47604, mean: -0.79688
[32m[0907 06-35-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31135, current rewards: -695.47604, mean: -0.80869
[32m[0907 06-36-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31154, current rewards: -745.47604, mean: -0.81920
[32m[0907 06-36-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31168, current rewards: -795.47604, mean: -0.82862
[32m[0907 06-36-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31181, current rewards: -845.47604, mean: -0.83710
[32m[0907 06-37-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31189, current rewards: -895.47604, mean: -0.84479
[32m[0907 06-37-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31199, current rewards: -945.47604, mean: -0.85178
[32m[0907 06-37-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31210, current rewards: -995.47604, mean: -0.85817
[32m[0907 06-37-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31220, current rewards: -1045.47604, mean: -0.86403
[32m[0907 06-38-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31224, current rewards: -1095.47604, mean: -0.86943
[32m[0907 06-38-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31230, current rewards: -1145.47604, mean: -0.87441
[32m[0907 06-38-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31238, current rewards: -1195.47604, mean: -0.87903
[32m[0907 06-38-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31245, current rewards: -1245.47604, mean: -0.88332
[32m[0907 06-39-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31249, current rewards: -1295.47604, mean: -0.88731
[32m[0907 06-39-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31252, current rewards: -1345.47604, mean: -0.89104
[32m[0907 06-39-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31257, current rewards: -1395.47604, mean: -0.89454
[32m[0907 06-39-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31263, current rewards: -1445.47604, mean: -0.89781
[32m[0907 06-40-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31265, current rewards: -1495.47604, mean: -0.90089
[32m[0907 06-40-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31267, current rewards: -1545.47604, mean: -0.90379
[32m[0907 06-40-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31269, current rewards: -1595.47604, mean: -0.90652
[32m[0907 06-40-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31270, current rewards: -1645.47604, mean: -0.90910
[32m[0907 06-41-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31268, current rewards: -1695.47604, mean: -0.91155
[32m[0907 06-41-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31273, current rewards: -1745.47604, mean: -0.91386
[32m[0907 06-41-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31276, current rewards: -1795.47604, mean: -0.91606
[32m[0907 06-41-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31280, current rewards: -1845.47604, mean: -0.91815
[32m[0907 06-42-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31280, current rewards: -1895.47604, mean: -0.92013
[32m[0907 06-42-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31283, current rewards: -1945.47604, mean: -0.92203
[32m[0907 06-42-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31287, current rewards: -1995.47604, mean: -0.92383
[32m[0907 06-43-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31289, current rewards: -2045.47604, mean: -0.92555
[32m[0907 06-43-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31292, current rewards: -2095.47604, mean: -0.92720
[32m[0907 06-43-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31290, current rewards: -2145.47604, mean: -0.92878
[32m[0907 06-43-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31279, current rewards: -2195.47604, mean: -0.93029
[32m[0907 06-44-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31267, current rewards: -2245.47604, mean: -0.93173
[32m[0907 06-44-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31240, current rewards: -2295.47604, mean: -0.93312
[32m[0907 06-44-30 @Agent.py:117][0m Average action selection time: 0.3122
[32m[0907 06-44-30 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-44-30 @MBExp.py:227][0m Rewards obtained: [-2335.4760379427794], Lows: [20], Highs: [2314], Total time: 56850.348901
[32m[0907 06-46-38 @MBExp.py:144][0m ####################################################################
[32m[0907 06-46-38 @MBExp.py:145][0m Starting training iteration 70.
[32m[0907 06-46-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29725, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-46-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29903, current rewards: -96.90872, mean: -1.61515
[32m[0907 06-47-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29909, current rewards: -194.74111, mean: -1.77037
[32m[0907 06-47-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30054, current rewards: -292.45651, mean: -1.82785
[32m[0907 06-47-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30491, current rewards: -382.80170, mean: -1.82287
[32m[0907 06-47-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30870, current rewards: -478.45259, mean: -1.84020
[32m[0907 06-48-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30984, current rewards: -573.50148, mean: -1.85000
[32m[0907 06-48-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31274, current rewards: -668.95977, mean: -1.85822
[32m[0907 06-48-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31536, current rewards: -755.80764, mean: -1.84343
[32m[0907 06-49-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31909, current rewards: -839.92762, mean: -1.82593
[32m[0907 06-49-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32099, current rewards: -933.01706, mean: -1.82945
[32m[0907 06-49-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32290, current rewards: -1021.52307, mean: -1.82415
[32m[0907 06-49-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32379, current rewards: -1112.66033, mean: -1.82403
[32m[0907 06-50-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32534, current rewards: -1195.89072, mean: -1.81196
[32m[0907 06-50-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32628, current rewards: -1293.70311, mean: -1.82212
[32m[0907 06-50-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32674, current rewards: -1388.14877, mean: -1.82651
[32m[0907 06-51-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32752, current rewards: -1488.14877, mean: -1.83722
[32m[0907 06-51-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32772, current rewards: -1585.91308, mean: -1.84408
[32m[0907 06-51-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32871, current rewards: -1685.91308, mean: -1.85265
[32m[0907 06-51-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33067, current rewards: -1785.91308, mean: -1.86033
[32m[0907 06-52-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33125, current rewards: -1883.53188, mean: -1.86488
[32m[0907 06-52-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33233, current rewards: -1983.53188, mean: -1.87126
[32m[0907 06-52-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33264, current rewards: -2083.53188, mean: -1.87706
[32m[0907 06-53-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33264, current rewards: -2167.31475, mean: -1.86837
[32m[0907 06-53-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33326, current rewards: -2267.31475, mean: -1.87381
[32m[0907 06-53-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33450, current rewards: -2351.64745, mean: -1.86639
[32m[0907 06-53-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33514, current rewards: -2433.64484, mean: -1.85774
[32m[0907 06-54-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33453, current rewards: -2533.64484, mean: -1.86297
[32m[0907 06-54-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33533, current rewards: -2621.59907, mean: -1.85929
[32m[0907 06-54-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33576, current rewards: -2704.26349, mean: -1.85224
[32m[0907 06-55-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33566, current rewards: -2788.42683, mean: -1.84664
[32m[0907 06-55-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33509, current rewards: -2873.08686, mean: -1.84172
[32m[0907 06-55-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33482, current rewards: -2952.34776, mean: -1.83376
[32m[0907 06-55-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33432, current rewards: -3027.91033, mean: -1.82404
[32m[0907 06-56-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33441, current rewards: -3094.71815, mean: -1.80978
[32m[0907 06-56-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33404, current rewards: -3168.35126, mean: -1.80020
[32m[0907 06-56-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33348, current rewards: -3256.92199, mean: -1.79940
[32m[0907 06-56-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33293, current rewards: -3356.92199, mean: -1.80480
[32m[0907 06-57-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33241, current rewards: -3456.92199, mean: -1.80991
[32m[0907 06-57-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33192, current rewards: -3556.92199, mean: -1.81476
[32m[0907 06-57-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33145, current rewards: -3656.92199, mean: -1.81936
[32m[0907 06-58-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33102, current rewards: -3756.92199, mean: -1.82375
[32m[0907 06-58-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33061, current rewards: -3856.92199, mean: -1.82793
[32m[0907 06-58-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33022, current rewards: -3956.92199, mean: -1.83191
[32m[0907 06-58-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32983, current rewards: -4056.92199, mean: -1.83571
[32m[0907 06-59-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32946, current rewards: -4156.92199, mean: -1.83935
[32m[0907 06-59-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32892, current rewards: -4256.92199, mean: -1.84282
[32m[0907 06-59-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32826, current rewards: -4356.92199, mean: -1.84615
[32m[0907 06-59-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32763, current rewards: -4456.92199, mean: -1.84935
[32m[0907 07-00-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32701, current rewards: -4556.92199, mean: -1.85241
[32m[0907 07-00-15 @Agent.py:117][0m Average action selection time: 0.3265
[32m[0907 07-00-15 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-00-15 @MBExp.py:227][0m Rewards obtained: [-4636.9219928031325], Lows: [2334], Highs: [25], Total time: 57667.428681
[32m[0907 07-02-26 @MBExp.py:144][0m ####################################################################
[32m[0907 07-02-26 @MBExp.py:145][0m Starting training iteration 71.
[32m[0907 07-02-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31841, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-02-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30788, current rewards: -85.90556, mean: -1.43176
[32m[0907 07-03-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30816, current rewards: -174.05277, mean: -1.58230
[32m[0907 07-03-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30920, current rewards: -258.36425, mean: -1.61478
[32m[0907 07-03-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30892, current rewards: -347.82647, mean: -1.65632
[32m[0907 07-03-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31058, current rewards: -437.28433, mean: -1.68186
[32m[0907 07-04-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31154, current rewards: -516.67647, mean: -1.66670
[32m[0907 07-04-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31241, current rewards: -604.13881, mean: -1.67816
[32m[0907 07-04-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31269, current rewards: -684.54241, mean: -1.66962
[32m[0907 07-04-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31297, current rewards: -768.49470, mean: -1.67064
[32m[0907 07-05-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31313, current rewards: -860.23335, mean: -1.68673
[32m[0907 07-05-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31333, current rewards: -951.99814, mean: -1.70000
[32m[0907 07-05-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31349, current rewards: -1040.11052, mean: -1.70510
[32m[0907 07-05-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31371, current rewards: -1130.82071, mean: -1.71336
[32m[0907 07-06-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31380, current rewards: -1212.24066, mean: -1.70738
[32m[0907 07-06-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31421, current rewards: -1298.77100, mean: -1.70891
[32m[0907 07-06-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31429, current rewards: -1382.23990, mean: -1.70647
[32m[0907 07-06-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31430, current rewards: -1470.08119, mean: -1.70940
[32m[0907 07-07-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31430, current rewards: -1570.08119, mean: -1.72536
[32m[0907 07-07-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31437, current rewards: -1670.08119, mean: -1.73967
[32m[0907 07-07-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31565, current rewards: -1770.08119, mean: -1.75256
[32m[0907 07-08-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31738, current rewards: -1870.08119, mean: -1.76423
[32m[0907 07-08-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31892, current rewards: -1970.08119, mean: -1.77485
[32m[0907 07-08-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32031, current rewards: -2070.08119, mean: -1.78455
[32m[0907 07-08-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32162, current rewards: -2170.08119, mean: -1.79346
[32m[0907 07-09-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32285, current rewards: -2270.08119, mean: -1.80165
[32m[0907 07-09-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32402, current rewards: -2370.08119, mean: -1.80922
[32m[0907 07-09-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32504, current rewards: -2470.08119, mean: -1.81624
[32m[0907 07-10-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32597, current rewards: -2570.08119, mean: -1.82275
[32m[0907 07-10-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32685, current rewards: -2670.08119, mean: -1.82882
[32m[0907 07-10-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32768, current rewards: -2770.08119, mean: -1.83449
[32m[0907 07-10-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32845, current rewards: -2870.08119, mean: -1.83980
[32m[0907 07-11-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32922, current rewards: -2970.08119, mean: -1.84477
[32m[0907 07-11-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32987, current rewards: -3070.08119, mean: -1.84945
[32m[0907 07-11-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33051, current rewards: -3170.08119, mean: -1.85385
[32m[0907 07-12-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33109, current rewards: -3270.08119, mean: -1.85800
[32m[0907 07-12-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33167, current rewards: -3370.08119, mean: -1.86192
[32m[0907 07-12-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33225, current rewards: -3470.08119, mean: -1.86564
[32m[0907 07-13-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33276, current rewards: -3570.08119, mean: -1.86915
[32m[0907 07-13-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33324, current rewards: -3670.08119, mean: -1.87249
[32m[0907 07-13-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33369, current rewards: -3770.08119, mean: -1.87566
[32m[0907 07-13-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33413, current rewards: -3870.08119, mean: -1.87868
[32m[0907 07-14-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33406, current rewards: -3970.08119, mean: -1.88156
[32m[0907 07-14-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33362, current rewards: -4070.08119, mean: -1.88430
[32m[0907 07-14-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33322, current rewards: -4170.08119, mean: -1.88691
[32m[0907 07-14-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33282, current rewards: -4270.08119, mean: -1.88942
[32m[0907 07-15-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33237, current rewards: -4370.08119, mean: -1.89181
[32m[0907 07-15-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33184, current rewards: -4470.08119, mean: -1.89410
[32m[0907 07-15-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33133, current rewards: -4570.08119, mean: -1.89630
[32m[0907 07-16-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33081, current rewards: -4670.08119, mean: -1.89841
[32m[0907 07-16-12 @Agent.py:117][0m Average action selection time: 0.3303
[32m[0907 07-16-12 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-16-12 @MBExp.py:227][0m Rewards obtained: [-4750.08119333901], Lows: [2362], Highs: [40], Total time: 58493.886966
[32m[0907 07-18-24 @MBExp.py:144][0m ####################################################################
[32m[0907 07-18-24 @MBExp.py:145][0m Starting training iteration 72.
[32m[0907 07-18-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31819, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-18-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30378, current rewards: -99.00000, mean: -1.65000
[32m[0907 07-18-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30621, current rewards: -199.00000, mean: -1.80909
[32m[0907 07-19-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30664, current rewards: -299.00000, mean: -1.86875
[32m[0907 07-19-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30715, current rewards: -399.00000, mean: -1.90000
[32m[0907 07-19-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30897, current rewards: -499.00000, mean: -1.91923
[32m[0907 07-20-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30992, current rewards: -599.00000, mean: -1.93226
[32m[0907 07-20-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31083, current rewards: -699.00000, mean: -1.94167
[32m[0907 07-20-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31147, current rewards: -799.00000, mean: -1.94878
[32m[0907 07-20-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31199, current rewards: -899.00000, mean: -1.95435
[32m[0907 07-21-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31244, current rewards: -999.00000, mean: -1.95882
[32m[0907 07-21-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31274, current rewards: -1099.00000, mean: -1.96250
[32m[0907 07-21-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31304, current rewards: -1199.00000, mean: -1.96557
[32m[0907 07-21-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31322, current rewards: -1299.00000, mean: -1.96818
[32m[0907 07-22-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31342, current rewards: -1399.00000, mean: -1.97042
[32m[0907 07-22-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31358, current rewards: -1499.00000, mean: -1.97237
[32m[0907 07-22-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31373, current rewards: -1599.00000, mean: -1.97407
[32m[0907 07-22-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31389, current rewards: -1699.00000, mean: -1.97558
[32m[0907 07-23-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31391, current rewards: -1799.00000, mean: -1.97692
[32m[0907 07-23-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31401, current rewards: -1899.00000, mean: -1.97812
[32m[0907 07-23-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31401, current rewards: -1999.00000, mean: -1.97921
[32m[0907 07-23-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31411, current rewards: -2099.00000, mean: -1.98019
[32m[0907 07-24-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31417, current rewards: -2199.00000, mean: -1.98108
[32m[0907 07-24-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31425, current rewards: -2299.00000, mean: -1.98190
[32m[0907 07-24-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31430, current rewards: -2399.00000, mean: -1.98264
[32m[0907 07-25-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31432, current rewards: -2499.00000, mean: -1.98333
[32m[0907 07-25-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31433, current rewards: -2599.00000, mean: -1.98397
[32m[0907 07-25-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31439, current rewards: -2699.00000, mean: -1.98456
[32m[0907 07-25-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31440, current rewards: -2799.00000, mean: -1.98511
[32m[0907 07-26-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31441, current rewards: -2899.00000, mean: -1.98562
[32m[0907 07-26-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31446, current rewards: -2999.00000, mean: -1.98609
[32m[0907 07-26-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31449, current rewards: -3099.00000, mean: -1.98654
[32m[0907 07-26-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31448, current rewards: -3199.00000, mean: -1.98696
[32m[0907 07-27-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31448, current rewards: -3299.00000, mean: -1.98735
[32m[0907 07-27-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31445, current rewards: -3399.00000, mean: -1.98772
[32m[0907 07-27-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31444, current rewards: -3499.00000, mean: -1.98807
[32m[0907 07-27-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31443, current rewards: -3599.00000, mean: -1.98840
[32m[0907 07-28-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31444, current rewards: -3699.00000, mean: -1.98871
[32m[0907 07-28-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31445, current rewards: -3799.00000, mean: -1.98901
[32m[0907 07-28-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31442, current rewards: -3899.00000, mean: -1.98929
[32m[0907 07-28-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31444, current rewards: -3999.00000, mean: -1.98955
[32m[0907 07-29-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31447, current rewards: -4099.00000, mean: -1.98981
[32m[0907 07-29-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31447, current rewards: -4199.00000, mean: -1.99005
[32m[0907 07-29-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31447, current rewards: -4299.00000, mean: -1.99028
[32m[0907 07-30-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31449, current rewards: -4399.00000, mean: -1.99050
[32m[0907 07-30-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31450, current rewards: -4499.00000, mean: -1.99071
[32m[0907 07-30-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31444, current rewards: -4599.00000, mean: -1.99091
[32m[0907 07-30-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31431, current rewards: -4699.00000, mean: -1.99110
[32m[0907 07-31-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31417, current rewards: -4799.00000, mean: -1.99129
[32m[0907 07-31-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31403, current rewards: -4899.00000, mean: -1.99146
[32m[0907 07-31-30 @Agent.py:117][0m Average action selection time: 0.3139
[32m[0907 07-31-30 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-31-30 @MBExp.py:227][0m Rewards obtained: [-4979], Lows: [2479], Highs: [21], Total time: 59279.400218999996
[32m[0907 07-33-44 @MBExp.py:144][0m ####################################################################
[32m[0907 07-33-44 @MBExp.py:145][0m Starting training iteration 73.
[32m[0907 07-33-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.46319, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-34-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35493, current rewards: -16.94520, mean: -0.28242
[32m[0907 07-34-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33136, current rewards: -96.02961, mean: -0.87300
[32m[0907 07-34-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32258, current rewards: -193.75274, mean: -1.21095
[32m[0907 07-34-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32058, current rewards: -284.13698, mean: -1.35303
[32m[0907 07-35-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31982, current rewards: -379.82042, mean: -1.46085
[32m[0907 07-35-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32074, current rewards: -473.01789, mean: -1.52586
[32m[0907 07-35-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32538, current rewards: -573.01789, mean: -1.59172
[32m[0907 07-35-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32918, current rewards: -673.01789, mean: -1.64151
[32m[0907 07-36-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33604, current rewards: -773.01789, mean: -1.68047
[32m[0907 07-36-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33950, current rewards: -873.01789, mean: -1.71180
[32m[0907 07-36-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34371, current rewards: -973.01789, mean: -1.73753
[32m[0907 07-37-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34151, current rewards: -1073.01789, mean: -1.75905
[32m[0907 07-37-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34073, current rewards: -1173.01789, mean: -1.77730
[32m[0907 07-37-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34007, current rewards: -1270.64069, mean: -1.78963
[32m[0907 07-38-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33983, current rewards: -1352.46713, mean: -1.77956
[32m[0907 07-38-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33864, current rewards: -1452.46713, mean: -1.79317
[32m[0907 07-38-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33747, current rewards: -1552.46713, mean: -1.80519
[32m[0907 07-38-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33658, current rewards: -1652.46713, mean: -1.81590
[32m[0907 07-39-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33631, current rewards: -1752.46713, mean: -1.82549
[32m[0907 07-39-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33534, current rewards: -1852.46713, mean: -1.83413
[32m[0907 07-39-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33459, current rewards: -1952.46713, mean: -1.84195
[32m[0907 07-39-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33383, current rewards: -2052.46713, mean: -1.84907
[32m[0907 07-40-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33387, current rewards: -2152.46713, mean: -1.85558
[32m[0907 07-40-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33393, current rewards: -2230.11240, mean: -1.84307
[32m[0907 07-40-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33481, current rewards: -2286.22761, mean: -1.81447
[32m[0907 07-41-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33423, current rewards: -2357.10382, mean: -1.79932
[32m[0907 07-41-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33461, current rewards: -2431.84013, mean: -1.78812
[32m[0907 07-41-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33450, current rewards: -2507.20154, mean: -1.77816
[32m[0907 07-41-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33457, current rewards: -2560.21977, mean: -1.75358
[32m[0907 07-42-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33447, current rewards: -2621.50700, mean: -1.73610
[32m[0907 07-42-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33564, current rewards: -2676.13317, mean: -1.71547
[32m[0907 07-42-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33518, current rewards: -2743.35256, mean: -1.70395
[32m[0907 07-43-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33482, current rewards: -2838.27487, mean: -1.70980
[32m[0907 07-43-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33423, current rewards: -2929.23922, mean: -1.71301
[32m[0907 07-43-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33368, current rewards: -3029.23922, mean: -1.72116
[32m[0907 07-43-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33313, current rewards: -3129.23922, mean: -1.72886
[32m[0907 07-44-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33264, current rewards: -3229.23922, mean: -1.73615
[32m[0907 07-44-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33215, current rewards: -3329.23922, mean: -1.74306
[32m[0907 07-44-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33168, current rewards: -3429.23922, mean: -1.74961
[32m[0907 07-44-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33125, current rewards: -3529.23922, mean: -1.75584
[32m[0907 07-45-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33085, current rewards: -3629.23922, mean: -1.76177
[32m[0907 07-45-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33048, current rewards: -3729.23922, mean: -1.76741
[32m[0907 07-45-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33009, current rewards: -3829.23922, mean: -1.77280
[32m[0907 07-45-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32968, current rewards: -3929.23922, mean: -1.77794
[32m[0907 07-46-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32919, current rewards: -4029.23922, mean: -1.78285
[32m[0907 07-46-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32871, current rewards: -4129.23922, mean: -1.78755
[32m[0907 07-46-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32827, current rewards: -4229.23922, mean: -1.79205
[32m[0907 07-46-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32787, current rewards: -4329.23922, mean: -1.79636
[32m[0907 07-47-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32745, current rewards: -4429.23922, mean: -1.80050
[32m[0907 07-47-22 @Agent.py:117][0m Average action selection time: 0.3270
[32m[0907 07-47-22 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-47-22 @MBExp.py:227][0m Rewards obtained: [-4509.2392205140495], Lows: [2244], Highs: [68], Total time: 60097.74626099999
[32m[0907 07-49-38 @MBExp.py:144][0m ####################################################################
[32m[0907 07-49-38 @MBExp.py:145][0m Starting training iteration 74.
[32m[0907 07-49-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49714, current rewards: 1.26261, mean: 0.12626
[32m[0907 07-50-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35663, current rewards: -12.82889, mean: -0.21381
[32m[0907 07-50-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34501, current rewards: -110.41652, mean: -1.00379
[32m[0907 07-50-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34430, current rewards: -208.04535, mean: -1.30028
[32m[0907 07-50-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34348, current rewards: -308.04535, mean: -1.46688
[32m[0907 07-51-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34130, current rewards: -405.82227, mean: -1.56085
[32m[0907 07-51-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33901, current rewards: -503.20477, mean: -1.62324
[32m[0907 07-51-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33786, current rewards: -595.46132, mean: -1.65406
[32m[0907 07-51-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33667, current rewards: -682.06311, mean: -1.66357
[32m[0907 07-52-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33536, current rewards: -773.63172, mean: -1.68181
[32m[0907 07-52-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33456, current rewards: -860.79191, mean: -1.68783
[32m[0907 07-52-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33354, current rewards: -947.09091, mean: -1.69123
[32m[0907 07-53-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33327, current rewards: -1033.24660, mean: -1.69385
[32m[0907 07-53-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33315, current rewards: -1128.30047, mean: -1.70955
[32m[0907 07-53-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33319, current rewards: -1216.02004, mean: -1.71270
[32m[0907 07-53-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33358, current rewards: -1302.24225, mean: -1.71348
[32m[0907 07-54-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33292, current rewards: -1387.08485, mean: -1.71245
[32m[0907 07-54-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33275, current rewards: -1467.32056, mean: -1.70619
[32m[0907 07-54-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33406, current rewards: -1560.31127, mean: -1.71463
[32m[0907 07-54-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33394, current rewards: -1644.91901, mean: -1.71346
[32m[0907 07-55-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33342, current rewards: -1707.44364, mean: -1.69054
[32m[0907 07-55-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33277, current rewards: -1762.60107, mean: -1.66283
[32m[0907 07-55-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33208, current rewards: -1826.38863, mean: -1.64540
[32m[0907 07-56-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33161, current rewards: -1887.85382, mean: -1.62746
[32m[0907 07-56-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33087, current rewards: -1920.44020, mean: -1.58714
[32m[0907 07-56-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33026, current rewards: -1947.56344, mean: -1.54569
[32m[0907 07-56-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32963, current rewards: -2027.52536, mean: -1.54773
[32m[0907 07-57-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32905, current rewards: -2127.52536, mean: -1.56436
[32m[0907 07-57-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32905, current rewards: -2227.52536, mean: -1.57981
[32m[0907 07-57-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32980, current rewards: -2327.52536, mean: -1.59420
[32m[0907 07-57-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33054, current rewards: -2427.52536, mean: -1.60763
[32m[0907 07-58-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33130, current rewards: -2527.52536, mean: -1.62021
[32m[0907 07-58-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33248, current rewards: -2627.52536, mean: -1.63200
[32m[0907 07-58-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33313, current rewards: -2727.52536, mean: -1.64309
[32m[0907 07-59-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33368, current rewards: -2827.52536, mean: -1.65352
[32m[0907 07-59-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33420, current rewards: -2927.52536, mean: -1.66337
[32m[0907 07-59-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33465, current rewards: -3027.52536, mean: -1.67267
[32m[0907 08-00-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33415, current rewards: -3127.52536, mean: -1.68147
[32m[0907 08-00-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33364, current rewards: -3227.52536, mean: -1.68980
[32m[0907 08-00-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33313, current rewards: -3327.52536, mean: -1.69772
[32m[0907 08-00-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33265, current rewards: -3427.52536, mean: -1.70524
[32m[0907 08-01-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33222, current rewards: -3527.52536, mean: -1.71239
[32m[0907 08-01-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33178, current rewards: -3627.52536, mean: -1.71921
[32m[0907 08-01-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33120, current rewards: -3727.52536, mean: -1.72571
[32m[0907 08-01-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33066, current rewards: -3827.52536, mean: -1.73191
[32m[0907 08-02-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33013, current rewards: -3927.52536, mean: -1.73784
[32m[0907 08-02-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32961, current rewards: -4027.52536, mean: -1.74352
[32m[0907 08-02-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32913, current rewards: -4127.52536, mean: -1.74895
[32m[0907 08-02-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32868, current rewards: -4227.52536, mean: -1.75416
[32m[0907 08-03-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32814, current rewards: -4327.52536, mean: -1.75916
[32m[0907 08-03-18 @Agent.py:117][0m Average action selection time: 0.3277
[32m[0907 08-03-18 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-03-18 @MBExp.py:227][0m Rewards obtained: [-4407.525355590748], Lows: [2230], Highs: [9], Total time: 60917.62547399999
[32m[0907 08-05-36 @MBExp.py:144][0m ####################################################################
[32m[0907 08-05-36 @MBExp.py:145][0m Starting training iteration 75.
[32m[0907 08-05-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29935, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-05-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30029, current rewards: -97.94156, mean: -1.63236
[32m[0907 08-06-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30357, current rewards: -197.94156, mean: -1.79947
[32m[0907 08-06-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30507, current rewards: -297.94156, mean: -1.86213
[32m[0907 08-06-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30770, current rewards: -397.94156, mean: -1.89496
[32m[0907 08-06-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30908, current rewards: -497.94156, mean: -1.91516
[32m[0907 08-07-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31013, current rewards: -597.94156, mean: -1.92884
[32m[0907 08-07-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31090, current rewards: -697.94156, mean: -1.93873
[32m[0907 08-07-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31143, current rewards: -797.94156, mean: -1.94620
[32m[0907 08-08-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31185, current rewards: -897.94156, mean: -1.95205
[32m[0907 08-08-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31215, current rewards: -997.94156, mean: -1.95675
[32m[0907 08-08-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31244, current rewards: -1097.94156, mean: -1.96061
[32m[0907 08-08-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31273, current rewards: -1197.94156, mean: -1.96384
[32m[0907 08-09-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31291, current rewards: -1297.94156, mean: -1.96658
[32m[0907 08-09-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31309, current rewards: -1397.94156, mean: -1.96893
[32m[0907 08-09-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31321, current rewards: -1497.94156, mean: -1.97098
[32m[0907 08-09-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31326, current rewards: -1597.94156, mean: -1.97277
[32m[0907 08-10-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31341, current rewards: -1697.94156, mean: -1.97435
[32m[0907 08-10-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31349, current rewards: -1797.94156, mean: -1.97576
[32m[0907 08-10-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31353, current rewards: -1897.94156, mean: -1.97702
[32m[0907 08-10-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31360, current rewards: -1997.94156, mean: -1.97816
[32m[0907 08-11-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31363, current rewards: -2097.94156, mean: -1.97919
[32m[0907 08-11-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31363, current rewards: -2197.94156, mean: -1.98013
[32m[0907 08-11-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31369, current rewards: -2297.94156, mean: -1.98098
[32m[0907 08-11-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31374, current rewards: -2397.94156, mean: -1.98177
[32m[0907 08-12-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31373, current rewards: -2497.94156, mean: -1.98249
[32m[0907 08-12-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31379, current rewards: -2597.94156, mean: -1.98316
[32m[0907 08-12-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31381, current rewards: -2697.94156, mean: -1.98378
[32m[0907 08-12-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31382, current rewards: -2797.94156, mean: -1.98436
[32m[0907 08-13-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31382, current rewards: -2897.94156, mean: -1.98489
[32m[0907 08-13-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31384, current rewards: -2997.94156, mean: -1.98539
[32m[0907 08-13-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31385, current rewards: -3097.94156, mean: -1.98586
[32m[0907 08-14-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31385, current rewards: -3197.94156, mean: -1.98630
[32m[0907 08-14-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31385, current rewards: -3297.94156, mean: -1.98671
[32m[0907 08-14-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31384, current rewards: -3397.94156, mean: -1.98710
[32m[0907 08-14-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31386, current rewards: -3497.94156, mean: -1.98747
[32m[0907 08-15-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31386, current rewards: -3597.94156, mean: -1.98781
[32m[0907 08-15-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31387, current rewards: -3697.94156, mean: -1.98814
[32m[0907 08-15-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31384, current rewards: -3797.94156, mean: -1.98845
[32m[0907 08-15-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31383, current rewards: -3897.94156, mean: -1.98875
[32m[0907 08-16-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31384, current rewards: -3997.94156, mean: -1.98903
[32m[0907 08-16-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31383, current rewards: -4097.94156, mean: -1.98929
[32m[0907 08-16-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31379, current rewards: -4197.94156, mean: -1.98955
[32m[0907 08-16-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31365, current rewards: -4297.94156, mean: -1.98979
[32m[0907 08-17-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31349, current rewards: -4397.94156, mean: -1.99002
[32m[0907 08-17-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31333, current rewards: -4497.94156, mean: -1.99024
[32m[0907 08-17-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31319, current rewards: -4597.94156, mean: -1.99045
[32m[0907 08-17-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31306, current rewards: -4697.94156, mean: -1.99065
[32m[0907 08-18-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31294, current rewards: -4797.94156, mean: -1.99085
[32m[0907 08-18-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31276, current rewards: -4897.94156, mean: -1.99103
[32m[0907 08-18-38 @Agent.py:117][0m Average action selection time: 0.3125
[32m[0907 08-18-38 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-18-38 @MBExp.py:227][0m Rewards obtained: [-4977.941561008253], Lows: [2479], Highs: [20], Total time: 61699.68497899999
[32m[0907 08-20-58 @MBExp.py:144][0m ####################################################################
[32m[0907 08-20-58 @MBExp.py:145][0m Starting training iteration 76.
[32m[0907 08-21-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30927, current rewards: -6.85170, mean: -0.68517
[32m[0907 08-21-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32865, current rewards: -74.71363, mean: -1.24523
[32m[0907 08-21-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32155, current rewards: -67.86605, mean: -0.61696
[32m[0907 08-21-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32963, current rewards: -60.09210, mean: -0.37558
[32m[0907 08-22-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33206, current rewards: -114.27098, mean: -0.54415
[32m[0907 08-22-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32894, current rewards: -116.29248, mean: -0.44728
[32m[0907 08-22-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32735, current rewards: -109.65631, mean: -0.35373
[32m[0907 08-22-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32648, current rewards: -103.65832, mean: -0.28794
[32m[0907 08-23-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32519, current rewards: -99.00812, mean: -0.24148
[32m[0907 08-23-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32418, current rewards: -93.46973, mean: -0.20320
[32m[0907 08-23-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32361, current rewards: -88.33754, mean: -0.17321
[32m[0907 08-23-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32280, current rewards: -85.37737, mean: -0.15246
[32m[0907 08-24-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32214, current rewards: -82.41720, mean: -0.13511
[32m[0907 08-24-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32162, current rewards: -101.74231, mean: -0.15416
[32m[0907 08-24-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32113, current rewards: -151.74231, mean: -0.21372
[32m[0907 08-25-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32073, current rewards: -201.74231, mean: -0.26545
[32m[0907 08-25-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32040, current rewards: -251.74231, mean: -0.31079
[32m[0907 08-25-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32006, current rewards: -301.74231, mean: -0.35086
[32m[0907 08-25-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31975, current rewards: -351.74231, mean: -0.38653
[32m[0907 08-26-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31946, current rewards: -401.74231, mean: -0.41848
[32m[0907 08-26-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31921, current rewards: -451.74231, mean: -0.44727
[32m[0907 08-26-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31891, current rewards: -501.74231, mean: -0.47334
[32m[0907 08-26-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31869, current rewards: -551.74231, mean: -0.49707
[32m[0907 08-27-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31851, current rewards: -601.74231, mean: -0.51874
[32m[0907 08-27-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31830, current rewards: -651.74231, mean: -0.53863
[32m[0907 08-27-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31814, current rewards: -701.74231, mean: -0.55694
[32m[0907 08-27-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31799, current rewards: -751.74231, mean: -0.57385
[32m[0907 08-28-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31789, current rewards: -801.74231, mean: -0.58952
[32m[0907 08-28-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31778, current rewards: -851.74231, mean: -0.60407
[32m[0907 08-28-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31766, current rewards: -901.74231, mean: -0.61763
[32m[0907 08-28-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31755, current rewards: -951.74231, mean: -0.63029
[32m[0907 08-29-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31744, current rewards: -1001.74231, mean: -0.64214
[32m[0907 08-29-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31731, current rewards: -1051.74231, mean: -0.65326
[32m[0907 08-29-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31721, current rewards: -1101.74231, mean: -0.66370
[32m[0907 08-30-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31708, current rewards: -1151.74231, mean: -0.67353
[32m[0907 08-30-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31698, current rewards: -1201.74231, mean: -0.68281
[32m[0907 08-30-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31688, current rewards: -1251.74231, mean: -0.69157
[32m[0907 08-30-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31679, current rewards: -1301.74231, mean: -0.69986
[32m[0907 08-31-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31674, current rewards: -1351.74231, mean: -0.70772
[32m[0907 08-31-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31666, current rewards: -1401.74231, mean: -0.71517
[32m[0907 08-31-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31660, current rewards: -1451.74231, mean: -0.72226
[32m[0907 08-31-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31656, current rewards: -1501.74231, mean: -0.72900
[32m[0907 08-32-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31637, current rewards: -1551.74231, mean: -0.73542
[32m[0907 08-32-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31619, current rewards: -1601.74231, mean: -0.74155
[32m[0907 08-32-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31600, current rewards: -1651.74231, mean: -0.74739
[32m[0907 08-32-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31582, current rewards: -1701.74231, mean: -0.75298
[32m[0907 08-33-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31564, current rewards: -1751.74231, mean: -0.75833
[32m[0907 08-33-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31548, current rewards: -1801.74231, mean: -0.76345
[32m[0907 08-33-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31531, current rewards: -1851.74231, mean: -0.76836
[32m[0907 08-33-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31516, current rewards: -1901.74231, mean: -0.77307
[32m[0907 08-34-06 @Agent.py:117][0m Average action selection time: 0.3149
[32m[0907 08-34-06 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-34-06 @MBExp.py:227][0m Rewards obtained: [-1941.7423086213162], Lows: [65], Highs: [1881], Total time: 62487.71153699999
[32m[0907 08-36-28 @MBExp.py:144][0m ####################################################################
[32m[0907 08-36-28 @MBExp.py:145][0m Starting training iteration 77.
[32m[0907 08-36-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29819, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-36-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29875, current rewards: -25.09451, mean: -0.41824
[32m[0907 08-37-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30237, current rewards: -23.89792, mean: -0.21725
[32m[0907 08-37-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30430, current rewards: -21.20841, mean: -0.13255
[32m[0907 08-37-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30659, current rewards: -20.93013, mean: -0.09967
[32m[0907 08-37-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30857, current rewards: -18.92453, mean: -0.07279
[32m[0907 08-38-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30969, current rewards: -16.58648, mean: -0.05350
[32m[0907 08-38-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31057, current rewards: -14.97589, mean: -0.04160
[32m[0907 08-38-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31123, current rewards: -12.38253, mean: -0.03020
[32m[0907 08-38-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31185, current rewards: -11.63300, mean: -0.02529
[32m[0907 08-39-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31229, current rewards: -9.24709, mean: -0.01813
[32m[0907 08-39-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31320, current rewards: -9.55054, mean: -0.01705
[32m[0907 08-39-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31345, current rewards: -51.18371, mean: -0.08391
[32m[0907 08-39-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31361, current rewards: -136.29226, mean: -0.20650
[32m[0907 08-40-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31379, current rewards: -236.29226, mean: -0.33281
[32m[0907 08-40-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31389, current rewards: -336.29226, mean: -0.44249
[32m[0907 08-40-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31403, current rewards: -436.29226, mean: -0.53863
[32m[0907 08-40-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31406, current rewards: -536.29226, mean: -0.62360
[32m[0907 08-41-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31412, current rewards: -636.29226, mean: -0.69922
[32m[0907 08-41-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31419, current rewards: -736.29226, mean: -0.76697
[32m[0907 08-41-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31422, current rewards: -836.29226, mean: -0.82801
[32m[0907 08-42-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31427, current rewards: -936.29226, mean: -0.88329
[32m[0907 08-42-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31431, current rewards: -1036.29226, mean: -0.93360
[32m[0907 08-42-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31434, current rewards: -1136.29226, mean: -0.97956
[32m[0907 08-42-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31435, current rewards: -1236.29226, mean: -1.02173
[32m[0907 08-43-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31433, current rewards: -1336.29226, mean: -1.06055
[32m[0907 08-43-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31430, current rewards: -1436.29226, mean: -1.09641
[32m[0907 08-43-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31431, current rewards: -1536.29226, mean: -1.12963
[32m[0907 08-43-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31426, current rewards: -1636.29226, mean: -1.16049
[32m[0907 08-44-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31425, current rewards: -1736.29226, mean: -1.18924
[32m[0907 08-44-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31428, current rewards: -1836.29226, mean: -1.21609
[32m[0907 08-44-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31428, current rewards: -1936.29226, mean: -1.24121
[32m[0907 08-44-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31427, current rewards: -2036.29226, mean: -1.26478
[32m[0907 08-45-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31423, current rewards: -2136.29226, mean: -1.28692
[32m[0907 08-45-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31422, current rewards: -2236.29226, mean: -1.30777
[32m[0907 08-45-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31421, current rewards: -2336.29226, mean: -1.32744
[32m[0907 08-45-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31419, current rewards: -2436.29226, mean: -1.34602
[32m[0907 08-46-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31418, current rewards: -2536.29226, mean: -1.36360
[32m[0907 08-46-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31419, current rewards: -2636.29226, mean: -1.38026
[32m[0907 08-46-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31416, current rewards: -2736.29226, mean: -1.39607
[32m[0907 08-47-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31419, current rewards: -2836.29226, mean: -1.41109
[32m[0907 08-47-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31420, current rewards: -2936.29226, mean: -1.42538
[32m[0907 08-47-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31404, current rewards: -3036.29226, mean: -1.43900
[32m[0907 08-47-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31389, current rewards: -3136.29226, mean: -1.45199
[32m[0907 08-48-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31374, current rewards: -3236.29226, mean: -1.46439
[32m[0907 08-48-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31360, current rewards: -3336.29226, mean: -1.47624
[32m[0907 08-48-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31345, current rewards: -3436.29226, mean: -1.48757
[32m[0907 08-48-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31331, current rewards: -3536.29226, mean: -1.49843
[32m[0907 08-49-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31318, current rewards: -3636.29226, mean: -1.50883
[32m[0907 08-49-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31305, current rewards: -3736.29226, mean: -1.51882
[32m[0907 08-49-31 @Agent.py:117][0m Average action selection time: 0.3130
[32m[0907 08-49-31 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-49-31 @MBExp.py:227][0m Rewards obtained: [-3816.29225930431], Lows: [1913], Highs: [56], Total time: 63270.83944399999
[32m[0907 08-51-56 @MBExp.py:144][0m ####################################################################
[32m[0907 08-51-56 @MBExp.py:145][0m Starting training iteration 78.
[32m[0907 08-51-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32918, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-52-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32945, current rewards: -58.45305, mean: -0.97422
[32m[0907 08-52-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31255, current rewards: -53.63164, mean: -0.48756
[32m[0907 08-52-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30881, current rewards: -48.72226, mean: -0.30451
[32m[0907 08-53-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30652, current rewards: -42.91012, mean: -0.20433
[32m[0907 08-53-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30522, current rewards: -37.94305, mean: -0.14593
[32m[0907 08-53-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30451, current rewards: -33.02875, mean: -0.10654
[32m[0907 08-53-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30507, current rewards: -28.11435, mean: -0.07810
[32m[0907 08-54-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30619, current rewards: -23.19888, mean: -0.05658
[32m[0907 08-54-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30722, current rewards: -40.71147, mean: -0.08850
[32m[0907 08-54-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30809, current rewards: -36.10592, mean: -0.07080
[32m[0907 08-54-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30865, current rewards: -31.22438, mean: -0.05576
[32m[0907 08-55-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30915, current rewards: -27.17742, mean: -0.04455
[32m[0907 08-55-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30956, current rewards: -22.25546, mean: -0.03372
[32m[0907 08-55-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31003, current rewards: -17.46221, mean: -0.02459
[32m[0907 08-55-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31172, current rewards: -12.66957, mean: -0.01667
[32m[0907 08-56-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31421, current rewards: -7.87772, mean: -0.00973
[32m[0907 08-56-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31638, current rewards: -3.08306, mean: -0.00358
[32m[0907 08-56-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31843, current rewards: 1.71129, mean: 0.00188
[32m[0907 08-57-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32036, current rewards: -0.89259, mean: -0.00093
[32m[0907 08-57-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32204, current rewards: -49.48018, mean: -0.04899
[32m[0907 08-57-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32349, current rewards: -105.67499, mean: -0.09969
[32m[0907 08-57-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32489, current rewards: -155.97832, mean: -0.14052
[32m[0907 08-58-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32608, current rewards: -213.61833, mean: -0.18415
[32m[0907 08-58-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32714, current rewards: -254.69902, mean: -0.21050
[32m[0907 08-58-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32839, current rewards: -324.52995, mean: -0.25756
[32m[0907 08-59-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32927, current rewards: -326.28103, mean: -0.24907
[32m[0907 08-59-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33008, current rewards: -320.48581, mean: -0.23565
[32m[0907 08-59-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33085, current rewards: -314.72896, mean: -0.22321
[32m[0907 09-00-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33158, current rewards: -309.86146, mean: -0.21223
[32m[0907 09-00-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33226, current rewards: -304.99396, mean: -0.20198
[32m[0907 09-00-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33290, current rewards: -300.12646, mean: -0.19239
[32m[0907 09-00-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33348, current rewards: -295.25896, mean: -0.18339
[32m[0907 09-01-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33401, current rewards: -290.39146, mean: -0.17493
[32m[0907 09-01-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33451, current rewards: -306.37361, mean: -0.17917
[32m[0907 09-01-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33499, current rewards: -356.37361, mean: -0.20249
[32m[0907 09-02-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33547, current rewards: -406.37361, mean: -0.22452
[32m[0907 09-02-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33589, current rewards: -456.37361, mean: -0.24536
[32m[0907 09-02-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33630, current rewards: -506.37361, mean: -0.26512
[32m[0907 09-02-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33677, current rewards: -556.37361, mean: -0.28386
[32m[0907 09-03-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33715, current rewards: -606.37361, mean: -0.30168
[32m[0907 09-03-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33745, current rewards: -656.37361, mean: -0.31863
[32m[0907 09-03-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33759, current rewards: -706.37361, mean: -0.33477
[32m[0907 09-04-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33773, current rewards: -756.37361, mean: -0.35017
[32m[0907 09-04-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33785, current rewards: -806.37361, mean: -0.36487
[32m[0907 09-04-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33797, current rewards: -856.37361, mean: -0.37893
[32m[0907 09-04-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33809, current rewards: -906.37361, mean: -0.39237
[32m[0907 09-05-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33820, current rewards: -956.37361, mean: -0.40524
[32m[0907 09-05-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33830, current rewards: -1006.37361, mean: -0.41758
[32m[0907 09-05-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33840, current rewards: -1056.37361, mean: -0.42942
[32m[0907 09-06-02 @Agent.py:117][0m Average action selection time: 0.3385
[32m[0907 09-06-02 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-06-03 @MBExp.py:227][0m Rewards obtained: [-1096.3736072685633], Lows: [148], Highs: [943], Total time: 64117.80640399999
[32m[0907 09-08-45 @MBExp.py:144][0m ####################################################################
[32m[0907 09-08-45 @MBExp.py:145][0m Starting training iteration 79.
[32m[0907 09-08-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32142, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-09-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32145, current rewards: -26.91980, mean: -0.44866
[32m[0907 09-09-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32172, current rewards: -26.52955, mean: -0.24118
[32m[0907 09-09-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32366, current rewards: -21.40703, mean: -0.13379
[32m[0907 09-09-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32597, current rewards: -12.76445, mean: -0.06078
[32m[0907 09-10-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32737, current rewards: -7.17238, mean: -0.02759
[32m[0907 09-10-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32826, current rewards: -1.57108, mean: -0.00507
[32m[0907 09-10-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33032, current rewards: 4.03483, mean: 0.01121
[32m[0907 09-11-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33243, current rewards: -24.15239, mean: -0.05891
[32m[0907 09-11-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33507, current rewards: -28.21813, mean: -0.06134
[32m[0907 09-11-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33708, current rewards: -22.47923, mean: -0.04408
[32m[0907 09-11-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33878, current rewards: -16.81551, mean: -0.03003
[32m[0907 09-12-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34020, current rewards: -11.84978, mean: -0.01943
[32m[0907 09-12-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34132, current rewards: -6.26823, mean: -0.00950
[32m[0907 09-12-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34243, current rewards: -0.66944, mean: -0.00094
[32m[0907 09-13-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34332, current rewards: 4.92980, mean: 0.00649
[32m[0907 09-13-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34412, current rewards: 10.52471, mean: 0.01299
[32m[0907 09-13-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34483, current rewards: 16.11908, mean: 0.01874
[32m[0907 09-13-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34545, current rewards: -18.41051, mean: -0.02023
[32m[0907 09-14-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34603, current rewards: -17.87421, mean: -0.01862
[32m[0907 09-14-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34664, current rewards: -10.13304, mean: -0.01003
[32m[0907 09-14-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34709, current rewards: -1.07960, mean: -0.00102
[32m[0907 09-15-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34756, current rewards: 7.97383, mean: 0.00718
[32m[0907 09-15-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34796, current rewards: 17.02726, mean: 0.01468
[32m[0907 09-15-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34835, current rewards: 26.08070, mean: 0.02155
[32m[0907 09-16-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34873, current rewards: 35.13413, mean: 0.02788
[32m[0907 09-16-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34901, current rewards: 44.18756, mean: 0.03373
[32m[0907 09-16-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34931, current rewards: 52.05992, mean: 0.03828
[32m[0907 09-16-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34960, current rewards: 2.05992, mean: 0.00146
[32m[0907 09-17-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34984, current rewards: -47.94008, mean: -0.03284
[32m[0907 09-17-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35007, current rewards: -97.94008, mean: -0.06486
[32m[0907 09-17-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35026, current rewards: -147.94008, mean: -0.09483
[32m[0907 09-18-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35043, current rewards: -197.94008, mean: -0.12294
[32m[0907 09-18-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35062, current rewards: -247.94008, mean: -0.14936
[32m[0907 09-18-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35082, current rewards: -297.94008, mean: -0.17423
[32m[0907 09-19-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35094, current rewards: -347.94008, mean: -0.19769
[32m[0907 09-19-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35109, current rewards: -397.94008, mean: -0.21986
[32m[0907 09-19-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35122, current rewards: -447.94008, mean: -0.24083
[32m[0907 09-19-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35133, current rewards: -497.94008, mean: -0.26070
[32m[0907 09-20-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35146, current rewards: -547.94008, mean: -0.27956
[32m[0907 09-20-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35157, current rewards: -597.94008, mean: -0.29748
[32m[0907 09-20-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35162, current rewards: -647.94008, mean: -0.31453
[32m[0907 09-21-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35155, current rewards: -697.94008, mean: -0.33078
[32m[0907 09-21-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35147, current rewards: -747.94008, mean: -0.34627
[32m[0907 09-21-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35142, current rewards: -797.94008, mean: -0.36106
[32m[0907 09-21-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35135, current rewards: -847.94008, mean: -0.37519
[32m[0907 09-22-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35126, current rewards: -897.94008, mean: -0.38872
[32m[0907 09-22-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35111, current rewards: -947.94008, mean: -0.40167
[32m[0907 09-22-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35095, current rewards: -997.94008, mean: -0.41408
[32m[0907 09-23-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35081, current rewards: -1047.94008, mean: -0.42599
[32m[0907 09-23-22 @Agent.py:117][0m Average action selection time: 0.3507
[32m[0907 09-23-22 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-23-22 @MBExp.py:227][0m Rewards obtained: [-1087.940075240041], Lows: [49], Highs: [1168], Total time: 64995.36422399999
[32m[0907 09-26-08 @MBExp.py:144][0m ####################################################################
[32m[0907 09-26-08 @MBExp.py:145][0m Starting training iteration 80.
[32m[0907 09-26-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32147, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-26-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32204, current rewards: -35.43278, mean: -0.59055
[32m[0907 09-26-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32220, current rewards: -64.48404, mean: -0.58622
[32m[0907 09-26-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32201, current rewards: -83.60297, mean: -0.52252
[32m[0907 09-27-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32195, current rewards: -116.59420, mean: -0.55521
[32m[0907 09-27-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32218, current rewards: -137.13440, mean: -0.52744
[32m[0907 09-27-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32364, current rewards: -157.73687, mean: -0.50883
[32m[0907 09-28-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32503, current rewards: -189.41889, mean: -0.52616
[32m[0907 09-28-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32772, current rewards: -206.83659, mean: -0.50448
[32m[0907 09-28-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33043, current rewards: -233.97325, mean: -0.50864
[32m[0907 09-28-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33269, current rewards: -258.42202, mean: -0.50671
[32m[0907 09-29-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33450, current rewards: -298.07964, mean: -0.53229
[32m[0907 09-29-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33602, current rewards: -344.44444, mean: -0.56466
[32m[0907 09-29-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33729, current rewards: -364.71478, mean: -0.55260
[32m[0907 09-30-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33841, current rewards: -379.53622, mean: -0.53456
[32m[0907 09-30-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33937, current rewards: -392.31096, mean: -0.51620
[32m[0907 09-30-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34021, current rewards: -407.27800, mean: -0.50281
[32m[0907 09-31-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34089, current rewards: -420.06222, mean: -0.48844
[32m[0907 09-31-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34153, current rewards: -435.00245, mean: -0.47802
[32m[0907 09-31-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34219, current rewards: -445.26412, mean: -0.46382
[32m[0907 09-31-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34276, current rewards: -439.57184, mean: -0.43522
[32m[0907 09-32-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34320, current rewards: -450.15587, mean: -0.42468
[32m[0907 09-32-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34365, current rewards: -543.08785, mean: -0.48927
[32m[0907 09-32-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34408, current rewards: -643.08785, mean: -0.55439
[32m[0907 09-33-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34451, current rewards: -743.08785, mean: -0.61412
[32m[0907 09-33-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34480, current rewards: -843.08785, mean: -0.66912
[32m[0907 09-33-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34513, current rewards: -943.08785, mean: -0.71991
[32m[0907 09-33-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34536, current rewards: -1043.08785, mean: -0.76698
[32m[0907 09-34-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34556, current rewards: -1143.08785, mean: -0.81070
[32m[0907 09-34-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34577, current rewards: -1243.08785, mean: -0.85143
[32m[0907 09-34-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34602, current rewards: -1343.08785, mean: -0.88946
[32m[0907 09-35-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34618, current rewards: -1443.08785, mean: -0.92506
[32m[0907 09-35-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34634, current rewards: -1543.08785, mean: -0.95844
[32m[0907 09-35-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34652, current rewards: -1643.08785, mean: -0.98981
[32m[0907 09-36-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34666, current rewards: -1743.08785, mean: -1.01935
[32m[0907 09-36-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34682, current rewards: -1843.08785, mean: -1.04721
[32m[0907 09-36-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34697, current rewards: -1943.08785, mean: -1.07353
[32m[0907 09-36-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34711, current rewards: -2043.08785, mean: -1.09843
[32m[0907 09-37-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34722, current rewards: -2143.08785, mean: -1.12204
[32m[0907 09-37-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34734, current rewards: -2243.08785, mean: -1.14443
[32m[0907 09-37-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34746, current rewards: -2343.08785, mean: -1.16572
[32m[0907 09-38-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34755, current rewards: -2443.08785, mean: -1.18596
[32m[0907 09-38-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34746, current rewards: -2543.08785, mean: -1.20525
[32m[0907 09-38-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34739, current rewards: -2643.08785, mean: -1.22365
[32m[0907 09-38-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34736, current rewards: -2743.08785, mean: -1.24122
[32m[0907 09-39-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34737, current rewards: -2843.08785, mean: -1.25800
[32m[0907 09-39-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34737, current rewards: -2943.08785, mean: -1.27406
[32m[0907 09-39-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34739, current rewards: -3043.08785, mean: -1.28944
[32m[0907 09-40-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34740, current rewards: -3143.08785, mean: -1.30419
[32m[0907 09-40-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34739, current rewards: -3243.08785, mean: -1.31833
[32m[0907 09-40-37 @Agent.py:117][0m Average action selection time: 0.3474
[32m[0907 09-40-37 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-40-37 @MBExp.py:227][0m Rewards obtained: [-3323.0878470361004], Lows: [1709], Highs: [53], Total time: 65864.632783
[32m[0907 09-43-28 @MBExp.py:144][0m ####################################################################
[32m[0907 09-43-28 @MBExp.py:145][0m Starting training iteration 81.
[32m[0907 09-43-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32647, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-43-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32631, current rewards: -80.92598, mean: -1.34877
[32m[0907 09-44-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36338, current rewards: -111.59802, mean: -1.01453
[32m[0907 09-44-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35214, current rewards: -179.44794, mean: -1.12155
[32m[0907 09-44-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34589, current rewards: -176.73729, mean: -0.84161
[32m[0907 09-44-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34212, current rewards: -173.99136, mean: -0.66920
[32m[0907 09-45-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34042, current rewards: -171.28890, mean: -0.55254
[32m[0907 09-45-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33994, current rewards: -168.58815, mean: -0.46830
[32m[0907 09-45-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34132, current rewards: -165.88661, mean: -0.40460
[32m[0907 09-46-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34310, current rewards: -163.18453, mean: -0.35475
[32m[0907 09-46-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34428, current rewards: -160.48228, mean: -0.31467
[32m[0907 09-46-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34967, current rewards: -189.24872, mean: -0.33794
[32m[0907 09-47-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35013, current rewards: -223.32659, mean: -0.36611
[32m[0907 09-47-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35239, current rewards: -235.19178, mean: -0.35635
[32m[0907 09-47-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35390, current rewards: -292.05946, mean: -0.41135
[32m[0907 09-47-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35565, current rewards: -325.46475, mean: -0.42824
[32m[0907 09-48-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35592, current rewards: -364.74839, mean: -0.45031
[32m[0907 09-48-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35602, current rewards: -376.58229, mean: -0.43789
[32m[0907 09-48-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35634, current rewards: -386.22918, mean: -0.42443
[32m[0907 09-49-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35744, current rewards: -417.98857, mean: -0.43540
[32m[0907 09-49-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35756, current rewards: -488.89279, mean: -0.48405
[32m[0907 09-49-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35746, current rewards: -521.36160, mean: -0.49185
[32m[0907 09-50-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35738, current rewards: -512.57294, mean: -0.46178
[32m[0907 09-50-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35730, current rewards: -503.78427, mean: -0.43430
[32m[0907 09-50-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35727, current rewards: -494.99561, mean: -0.40909
[32m[0907 09-50-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35719, current rewards: -486.20695, mean: -0.38588
[32m[0907 09-51-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35712, current rewards: -498.58221, mean: -0.38060
[32m[0907 09-51-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35710, current rewards: -548.58221, mean: -0.40337
[32m[0907 09-51-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35701, current rewards: -598.58221, mean: -0.42453
[32m[0907 09-52-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35699, current rewards: -648.58221, mean: -0.44423
[32m[0907 09-52-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35698, current rewards: -698.58221, mean: -0.46264
[32m[0907 09-52-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35694, current rewards: -748.58221, mean: -0.47986
[32m[0907 09-53-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35691, current rewards: -798.58221, mean: -0.49601
[32m[0907 09-53-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35684, current rewards: -848.58221, mean: -0.51119
[32m[0907 09-53-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35684, current rewards: -898.58221, mean: -0.52549
[32m[0907 09-53-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35680, current rewards: -948.58221, mean: -0.53897
[32m[0907 09-54-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35677, current rewards: -998.58221, mean: -0.55170
[32m[0907 09-54-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35673, current rewards: -1048.58221, mean: -0.56375
[32m[0907 09-54-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35676, current rewards: -1098.58221, mean: -0.57517
[32m[0907 09-55-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35678, current rewards: -1148.58221, mean: -0.58601
[32m[0907 09-55-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35682, current rewards: -1198.58221, mean: -0.59631
[32m[0907 09-55-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35670, current rewards: -1248.58221, mean: -0.60611
[32m[0907 09-56-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35661, current rewards: -1298.58221, mean: -0.61544
[32m[0907 09-56-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35649, current rewards: -1348.58221, mean: -0.62434
[32m[0907 09-56-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35635, current rewards: -1398.58221, mean: -0.63284
[32m[0907 09-56-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35623, current rewards: -1448.58221, mean: -0.64097
[32m[0907 09-57-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35613, current rewards: -1498.58221, mean: -0.64874
[32m[0907 09-57-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35601, current rewards: -1548.58221, mean: -0.65618
[32m[0907 09-57-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35589, current rewards: -1598.58221, mean: -0.66331
[32m[0907 09-58-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35578, current rewards: -1648.58221, mean: -0.67016
[32m[0907 09-58-18 @Agent.py:117][0m Average action selection time: 0.3557
[32m[0907 09-58-18 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-58-18 @MBExp.py:227][0m Rewards obtained: [-1688.5822059235725], Lows: [198], Highs: [1390], Total time: 66754.69804799999
[32m[0907 10-01-11 @MBExp.py:144][0m ####################################################################
[32m[0907 10-01-11 @MBExp.py:145][0m Starting training iteration 82.
[32m[0907 10-01-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32613, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-01-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33350, current rewards: -29.47379, mean: -0.49123
[32m[0907 10-01-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33177, current rewards: -43.03370, mean: -0.39122
[32m[0907 10-02-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33640, current rewards: -80.31989, mean: -0.50200
[32m[0907 10-02-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33587, current rewards: -119.02098, mean: -0.56677
[32m[0907 10-02-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33405, current rewards: -175.32472, mean: -0.67433
[32m[0907 10-02-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33400, current rewards: -267.83836, mean: -0.86399
[32m[0907 10-03-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33518, current rewards: -355.16050, mean: -0.98656
[32m[0907 10-03-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34439, current rewards: -435.66134, mean: -1.06259
[32m[0907 10-03-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34662, current rewards: -446.19395, mean: -0.96999
[32m[0907 10-04-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34755, current rewards: -440.59689, mean: -0.86392
[32m[0907 10-04-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34821, current rewards: -434.88091, mean: -0.77657
[32m[0907 10-04-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34860, current rewards: -429.17459, mean: -0.70356
[32m[0907 10-05-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34902, current rewards: -423.46771, mean: -0.64162
[32m[0907 10-05-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34957, current rewards: -417.75927, mean: -0.58839
[32m[0907 10-05-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35029, current rewards: -412.04992, mean: -0.54217
[32m[0907 10-05-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35099, current rewards: -406.34387, mean: -0.50166
[32m[0907 10-06-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35163, current rewards: -400.63567, mean: -0.46586
[32m[0907 10-06-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35207, current rewards: -459.84136, mean: -0.50532
[32m[0907 10-06-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35245, current rewards: -454.67243, mean: -0.47362
[32m[0907 10-07-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35275, current rewards: -447.39822, mean: -0.44297
[32m[0907 10-07-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35311, current rewards: -440.12400, mean: -0.41521
[32m[0907 10-07-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35340, current rewards: -432.84979, mean: -0.38995
[32m[0907 10-08-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35373, current rewards: -469.10398, mean: -0.40440
[32m[0907 10-08-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35401, current rewards: -519.10398, mean: -0.42901
[32m[0907 10-08-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35418, current rewards: -569.10398, mean: -0.45167
[32m[0907 10-08-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35440, current rewards: -619.10398, mean: -0.47260
[32m[0907 10-09-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35459, current rewards: -669.10398, mean: -0.49199
[32m[0907 10-09-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35474, current rewards: -719.10398, mean: -0.51000
[32m[0907 10-09-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35490, current rewards: -769.10398, mean: -0.52678
[32m[0907 10-10-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35502, current rewards: -819.10398, mean: -0.54245
[32m[0907 10-10-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35519, current rewards: -869.10398, mean: -0.55712
[32m[0907 10-10-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35514, current rewards: -919.10398, mean: -0.57087
[32m[0907 10-11-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35507, current rewards: -969.10398, mean: -0.58380
[32m[0907 10-11-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35495, current rewards: -1019.10398, mean: -0.59597
[32m[0907 10-11-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35489, current rewards: -1069.10398, mean: -0.60745
[32m[0907 10-11-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35483, current rewards: -1119.10398, mean: -0.61829
[32m[0907 10-12-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35472, current rewards: -1169.10398, mean: -0.62855
[32m[0907 10-12-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35465, current rewards: -1219.10398, mean: -0.63827
[32m[0907 10-12-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35458, current rewards: -1269.10398, mean: -0.64750
[32m[0907 10-13-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35448, current rewards: -1319.10398, mean: -0.65627
[32m[0907 10-13-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35423, current rewards: -1369.10398, mean: -0.66461
[32m[0907 10-13-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35398, current rewards: -1419.10398, mean: -0.67256
[32m[0907 10-13-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35375, current rewards: -1469.10398, mean: -0.68014
[32m[0907 10-14-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35352, current rewards: -1519.10398, mean: -0.68738
[32m[0907 10-14-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35330, current rewards: -1569.10398, mean: -0.69429
[32m[0907 10-14-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35309, current rewards: -1619.10398, mean: -0.70091
[32m[0907 10-15-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35290, current rewards: -1669.10398, mean: -0.70725
[32m[0907 10-15-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35271, current rewards: -1719.10398, mean: -0.71332
[32m[0907 10-15-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35254, current rewards: -1769.10398, mean: -0.71915
[32m[0907 10-15-53 @Agent.py:117][0m Average action selection time: 0.3524
[32m[0907 10-15-53 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-15-53 @MBExp.py:227][0m Rewards obtained: [-1788.2202396375767], Lows: [227], Highs: [1439], Total time: 67636.52846999999
[32m[0907 10-18-35 @MBExp.py:144][0m ####################################################################
[32m[0907 10-18-35 @MBExp.py:145][0m Starting training iteration 83.
[32m[0907 10-18-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31063, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-18-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29734, current rewards: -19.52042, mean: -0.32534
[32m[0907 10-19-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29537, current rewards: -19.95495, mean: -0.18141
[32m[0907 10-19-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29508, current rewards: -20.79653, mean: -0.12998
[32m[0907 10-19-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29495, current rewards: -28.60327, mean: -0.13621
[32m[0907 10-19-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29637, current rewards: -50.75146, mean: -0.19520
[32m[0907 10-20-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29875, current rewards: -63.76804, mean: -0.20570
[32m[0907 10-20-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29882, current rewards: -87.61424, mean: -0.24337
[32m[0907 10-20-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30055, current rewards: -100.85203, mean: -0.24598
[32m[0907 10-20-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30261, current rewards: -124.48961, mean: -0.27063
[32m[0907 10-21-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30986, current rewards: -148.33337, mean: -0.29085
[32m[0907 10-21-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31143, current rewards: -160.89388, mean: -0.28731
[32m[0907 10-21-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31219, current rewards: -159.84076, mean: -0.26203
[32m[0907 10-22-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31254, current rewards: -203.95854, mean: -0.30903
[32m[0907 10-22-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31317, current rewards: -251.69927, mean: -0.35451
[32m[0907 10-22-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31333, current rewards: -301.69927, mean: -0.39697
[32m[0907 10-22-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31342, current rewards: -351.69927, mean: -0.43420
[32m[0907 10-23-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31349, current rewards: -398.26336, mean: -0.46310
[32m[0907 10-23-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31361, current rewards: -448.26336, mean: -0.49260
[32m[0907 10-23-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31368, current rewards: -498.26336, mean: -0.51902
[32m[0907 10-23-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31371, current rewards: -548.26336, mean: -0.54284
[32m[0907 10-24-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31375, current rewards: -598.26336, mean: -0.56440
[32m[0907 10-24-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31376, current rewards: -648.26336, mean: -0.58402
[32m[0907 10-24-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31375, current rewards: -698.26336, mean: -0.60195
[32m[0907 10-24-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31375, current rewards: -748.26336, mean: -0.61840
[32m[0907 10-25-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31379, current rewards: -798.26336, mean: -0.63354
[32m[0907 10-25-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31384, current rewards: -848.26336, mean: -0.64753
[32m[0907 10-25-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31384, current rewards: -898.26336, mean: -0.66049
[32m[0907 10-25-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31385, current rewards: -948.26336, mean: -0.67253
[32m[0907 10-26-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31387, current rewards: -998.26336, mean: -0.68374
[32m[0907 10-26-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31386, current rewards: -1048.26336, mean: -0.69421
[32m[0907 10-26-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31386, current rewards: -1061.59200, mean: -0.68051
[32m[0907 10-27-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31387, current rewards: -1059.20434, mean: -0.65789
[32m[0907 10-27-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31385, current rewards: -1056.81669, mean: -0.63664
[32m[0907 10-27-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31384, current rewards: -1054.42903, mean: -0.61663
[32m[0907 10-27-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31385, current rewards: -1051.95743, mean: -0.59770
[32m[0907 10-28-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31384, current rewards: -1048.99726, mean: -0.57956
[32m[0907 10-28-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31385, current rewards: -1046.03709, mean: -0.56239
[32m[0907 10-28-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31387, current rewards: -1043.07692, mean: -0.54611
[32m[0907 10-28-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31389, current rewards: -1040.11675, mean: -0.53067
[32m[0907 10-29-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31376, current rewards: -1037.15659, mean: -0.51600
[32m[0907 10-29-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31361, current rewards: -1034.19642, mean: -0.50204
[32m[0907 10-29-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31347, current rewards: -1031.23625, mean: -0.48874
[32m[0907 10-29-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31334, current rewards: -1028.29683, mean: -0.47606
[32m[0907 10-30-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31321, current rewards: -1077.24569, mean: -0.48744
[32m[0907 10-30-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31309, current rewards: -1127.24569, mean: -0.49878
[32m[0907 10-30-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31297, current rewards: -1177.24569, mean: -0.50963
[32m[0907 10-30-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31286, current rewards: -1227.24569, mean: -0.52002
[32m[0907 10-31-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31275, current rewards: -1277.24569, mean: -0.52998
[32m[0907 10-31-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31265, current rewards: -1327.24569, mean: -0.53953
[32m[0907 10-31-37 @Agent.py:117][0m Average action selection time: 0.3126
[32m[0907 10-31-37 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-31-37 @MBExp.py:227][0m Rewards obtained: [-1367.2456888462382], Lows: [48], Highs: [1361], Total time: 68418.85339399999
[32m[0907 10-34-15 @MBExp.py:144][0m ####################################################################
[32m[0907 10-34-15 @MBExp.py:145][0m Starting training iteration 84.
[32m[0907 10-34-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28975, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-34-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30386, current rewards: -71.22107, mean: -1.18702
[32m[0907 10-34-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30294, current rewards: -108.79322, mean: -0.98903
[32m[0907 10-35-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30444, current rewards: -157.46453, mean: -0.98415
[32m[0907 10-35-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30382, current rewards: -194.58339, mean: -0.92659
[32m[0907 10-35-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30710, current rewards: -232.26033, mean: -0.89331
[32m[0907 10-35-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30840, current rewards: -307.01556, mean: -0.99037
[32m[0907 10-36-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30786, current rewards: -359.77785, mean: -0.99938
[32m[0907 10-36-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31225, current rewards: -387.89737, mean: -0.94609
[32m[0907 10-36-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31378, current rewards: -432.56838, mean: -0.94037
[32m[0907 10-36-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31488, current rewards: -484.68738, mean: -0.95037
[32m[0907 10-37-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31692, current rewards: -540.19172, mean: -0.96463
[32m[0907 10-37-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31843, current rewards: -625.76923, mean: -1.02585
[32m[0907 10-37-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32086, current rewards: -715.04188, mean: -1.08340
[32m[0907 10-38-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32194, current rewards: -812.98030, mean: -1.14504
[32m[0907 10-38-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32367, current rewards: -908.57460, mean: -1.19549
[32m[0907 10-38-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32405, current rewards: -990.65298, mean: -1.22303
[32m[0907 10-38-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32498, current rewards: -1076.24993, mean: -1.25145
[32m[0907 10-39-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32697, current rewards: -1132.85125, mean: -1.24489
[32m[0907 10-39-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32844, current rewards: -1196.27904, mean: -1.24612
[32m[0907 10-39-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33004, current rewards: -1237.00356, mean: -1.22476
[32m[0907 10-40-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33231, current rewards: -1285.82057, mean: -1.21304
[32m[0907 10-40-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33526, current rewards: -1347.71255, mean: -1.21416
[32m[0907 10-40-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33781, current rewards: -1376.37284, mean: -1.18653
[32m[0907 10-41-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34107, current rewards: -1402.62033, mean: -1.15919
[32m[0907 10-41-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34528, current rewards: -1461.72533, mean: -1.16010
[32m[0907 10-41-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34869, current rewards: -1529.33918, mean: -1.16743
[32m[0907 10-42-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35170, current rewards: -1590.46171, mean: -1.16946
[32m[0907 10-42-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35600, current rewards: -1665.78857, mean: -1.18141
[32m[0907 10-42-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35806, current rewards: -1743.53933, mean: -1.19421
[32m[0907 10-43-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35898, current rewards: -1798.78351, mean: -1.19125
[32m[0907 10-43-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36126, current rewards: -1882.43080, mean: -1.20669
[32m[0907 10-43-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36236, current rewards: -1962.48119, mean: -1.21893
[32m[0907 10-44-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36342, current rewards: -2038.55064, mean: -1.22804
[32m[0907 10-44-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36382, current rewards: -2124.76175, mean: -1.24255
[32m[0907 10-44-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36497, current rewards: -2206.71868, mean: -1.25382
[32m[0907 10-45-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36529, current rewards: -2282.28232, mean: -1.26093
[32m[0907 10-45-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36552, current rewards: -2360.22958, mean: -1.26894
[32m[0907 10-45-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36702, current rewards: -2453.50844, mean: -1.28456
[32m[0907 10-46-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36901, current rewards: -2542.19862, mean: -1.29704
[32m[0907 10-46-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.37145, current rewards: -2633.18091, mean: -1.31004
[32m[0907 10-47-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.37245, current rewards: -2707.46713, mean: -1.31430
[32m[0907 10-47-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.37291, current rewards: -2785.52569, mean: -1.32015
[32m[0907 10-47-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.37392, current rewards: -2834.63483, mean: -1.31233
[32m[0907 10-48-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.37540, current rewards: -2912.47486, mean: -1.31786
[32m[0907 10-48-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.37601, current rewards: -2988.12368, mean: -1.32218
[32m[0907 10-48-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.37723, current rewards: -3064.22704, mean: -1.32651
[32m[0907 10-49-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.37811, current rewards: -3130.24011, mean: -1.32637
[32m[0907 10-49-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.37927, current rewards: -3208.24454, mean: -1.33122
[32m[0907 10-49-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.37999, current rewards: -3286.10953, mean: -1.33582
[32m[0907 10-50-06 @Agent.py:117][0m Average action selection time: 0.3803
[32m[0907 10-50-06 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-50-06 @MBExp.py:227][0m Rewards obtained: [-3329.4160638059884], Lows: [1671], Highs: [132], Total time: 69370.41198399999
[32m[0907 10-53-05 @MBExp.py:144][0m ####################################################################
[32m[0907 10-53-05 @MBExp.py:145][0m Starting training iteration 85.
[32m[0907 10-53-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34076, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-53-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30877, current rewards: -97.73248, mean: -1.62887
[32m[0907 10-53-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30130, current rewards: -197.73248, mean: -1.79757
[32m[0907 10-53-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29936, current rewards: -297.73248, mean: -1.86083
[32m[0907 10-54-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30107, current rewards: -397.73248, mean: -1.89396
[32m[0907 10-54-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30381, current rewards: -497.73248, mean: -1.91436
[32m[0907 10-54-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30584, current rewards: -597.73248, mean: -1.92817
[32m[0907 10-54-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30731, current rewards: -697.73248, mean: -1.93815
[32m[0907 10-55-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30841, current rewards: -780.50485, mean: -1.90367
[32m[0907 10-55-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30926, current rewards: -871.35351, mean: -1.89425
[32m[0907 10-55-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30993, current rewards: -961.04166, mean: -1.88440
[32m[0907 10-55-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31050, current rewards: -1042.58530, mean: -1.86176
[32m[0907 10-56-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31096, current rewards: -1132.15067, mean: -1.85598
[32m[0907 10-56-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31134, current rewards: -1220.06565, mean: -1.84858
[32m[0907 10-56-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31161, current rewards: -1304.79381, mean: -1.83774
[32m[0907 10-57-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31178, current rewards: -1395.63813, mean: -1.83637
[32m[0907 10-57-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31201, current rewards: -1486.57337, mean: -1.83528
[32m[0907 10-57-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31221, current rewards: -1586.57337, mean: -1.84485
[32m[0907 10-57-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31242, current rewards: -1686.57337, mean: -1.85338
[32m[0907 10-58-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31255, current rewards: -1786.57337, mean: -1.86101
[32m[0907 10-58-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31270, current rewards: -1886.57337, mean: -1.86789
[32m[0907 10-58-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31279, current rewards: -1986.57337, mean: -1.87413
[32m[0907 10-58-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31286, current rewards: -2086.57337, mean: -1.87980
[32m[0907 10-59-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31290, current rewards: -2186.57337, mean: -1.88498
[32m[0907 10-59-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31298, current rewards: -2286.57337, mean: -1.88973
[32m[0907 10-59-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31306, current rewards: -2386.57337, mean: -1.89411
[32m[0907 10-59-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31315, current rewards: -2486.57337, mean: -1.89815
[32m[0907 11-00-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31321, current rewards: -2586.57337, mean: -1.90189
[32m[0907 11-00-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31328, current rewards: -2686.57337, mean: -1.90537
[32m[0907 11-00-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31332, current rewards: -2786.57337, mean: -1.90861
[32m[0907 11-00-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31335, current rewards: -2886.57337, mean: -1.91164
[32m[0907 11-01-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31340, current rewards: -2986.57337, mean: -1.91447
[32m[0907 11-01-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31344, current rewards: -3086.57337, mean: -1.91713
[32m[0907 11-01-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31346, current rewards: -3186.57337, mean: -1.91962
[32m[0907 11-02-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31348, current rewards: -3286.57337, mean: -1.92197
[32m[0907 11-02-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31352, current rewards: -3386.57337, mean: -1.92419
[32m[0907 11-02-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31341, current rewards: -3486.57337, mean: -1.92628
[32m[0907 11-02-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31323, current rewards: -3586.57337, mean: -1.92827
[32m[0907 11-03-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31306, current rewards: -3686.57337, mean: -1.93014
[32m[0907 11-03-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31291, current rewards: -3786.57337, mean: -1.93193
[32m[0907 11-03-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31276, current rewards: -3886.57337, mean: -1.93362
[32m[0907 11-03-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31264, current rewards: -3986.57337, mean: -1.93523
[32m[0907 11-04-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31250, current rewards: -4086.57337, mean: -1.93676
[32m[0907 11-04-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31238, current rewards: -4186.57337, mean: -1.93823
[32m[0907 11-04-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31224, current rewards: -4286.57337, mean: -1.93963
[32m[0907 11-04-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31213, current rewards: -4386.57337, mean: -1.94096
[32m[0907 11-05-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31204, current rewards: -4486.57337, mean: -1.94224
[32m[0907 11-05-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31208, current rewards: -4586.57337, mean: -1.94346
[32m[0907 11-05-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31215, current rewards: -4686.57337, mean: -1.94464
[32m[0907 11-05-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31221, current rewards: -4786.57337, mean: -1.94576
[32m[0907 11-06-06 @Agent.py:117][0m Average action selection time: 0.3122
[32m[0907 11-06-06 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-06-06 @MBExp.py:227][0m Rewards obtained: [-4866.573371616352], Lows: [2389], Highs: [91], Total time: 70151.74419299999
[32m[0907 11-08-46 @MBExp.py:144][0m ####################################################################
[32m[0907 11-08-46 @MBExp.py:145][0m Starting training iteration 86.
[32m[0907 11-08-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.48231, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-09-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.41266, current rewards: -68.94069, mean: -1.14901
[32m[0907 11-09-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37500, current rewards: -110.24601, mean: -1.00224
[32m[0907 11-09-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35140, current rewards: -159.19716, mean: -0.99498
[32m[0907 11-09-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33999, current rewards: -205.94343, mean: -0.98068
[32m[0907 11-10-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33849, current rewards: -239.63732, mean: -0.92168
[32m[0907 11-10-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34637, current rewards: -265.20616, mean: -0.85550
[32m[0907 11-10-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34552, current rewards: -294.05212, mean: -0.81681
[32m[0907 11-11-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34229, current rewards: -312.45152, mean: -0.76208
[32m[0907 11-11-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34021, current rewards: -353.49159, mean: -0.76846
[32m[0907 11-11-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33776, current rewards: -394.72552, mean: -0.77397
[32m[0907 11-12-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34591, current rewards: -420.24395, mean: -0.75044
[32m[0907 11-12-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35210, current rewards: -437.28784, mean: -0.71687
[32m[0907 11-12-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35154, current rewards: -458.71217, mean: -0.69502
[32m[0907 11-12-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34970, current rewards: -509.65767, mean: -0.71783
[32m[0907 11-13-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34737, current rewards: -559.58475, mean: -0.73630
[32m[0907 11-13-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34536, current rewards: -609.58475, mean: -0.75257
[32m[0907 11-13-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34360, current rewards: -659.58475, mean: -0.76696
[32m[0907 11-13-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34203, current rewards: -709.58475, mean: -0.77976
[32m[0907 11-14-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34066, current rewards: -759.58475, mean: -0.79123
[32m[0907 11-14-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33939, current rewards: -809.58475, mean: -0.80157
[32m[0907 11-14-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33875, current rewards: -858.53448, mean: -0.80994
[32m[0907 11-15-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34016, current rewards: -893.65800, mean: -0.80510
[32m[0907 11-15-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34159, current rewards: -932.41775, mean: -0.80381
[32m[0907 11-15-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34573, current rewards: -971.57280, mean: -0.80295
[32m[0907 11-16-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34696, current rewards: -1011.38275, mean: -0.80268
[32m[0907 11-16-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35250, current rewards: -1061.38275, mean: -0.81022
[32m[0907 11-16-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35865, current rewards: -1111.38275, mean: -0.81719
[32m[0907 11-17-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36072, current rewards: -1161.38275, mean: -0.82368
[32m[0907 11-17-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36093, current rewards: -1211.31249, mean: -0.82967
[32m[0907 11-17-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36541, current rewards: -1246.97771, mean: -0.82581
[32m[0907 11-18-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.37036, current rewards: -1296.97771, mean: -0.83140
[32m[0907 11-18-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.37480, current rewards: -1346.97771, mean: -0.83663
[32m[0907 11-19-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.37896, current rewards: -1396.97771, mean: -0.84155
[32m[0907 11-19-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.38287, current rewards: -1446.97771, mean: -0.84619
[32m[0907 11-20-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.38243, current rewards: -1494.42281, mean: -0.84910
[32m[0907 11-20-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.38117, current rewards: -1539.09156, mean: -0.85033
[32m[0907 11-20-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.37920, current rewards: -1589.09156, mean: -0.85435
[32m[0907 11-20-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.37734, current rewards: -1639.09156, mean: -0.85816
[32m[0907 11-21-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.37557, current rewards: -1689.09156, mean: -0.86178
[32m[0907 11-21-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.37406, current rewards: -1739.09156, mean: -0.86522
[32m[0907 11-21-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.37262, current rewards: -1789.09156, mean: -0.86849
[32m[0907 11-21-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.37128, current rewards: -1839.09156, mean: -0.87161
[32m[0907 11-22-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36997, current rewards: -1889.09156, mean: -0.87458
[32m[0907 11-22-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36873, current rewards: -1939.09156, mean: -0.87742
[32m[0907 11-22-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36746, current rewards: -1989.09156, mean: -0.88013
[32m[0907 11-22-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36618, current rewards: -2039.09156, mean: -0.88272
[32m[0907 11-23-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36494, current rewards: -2089.09156, mean: -0.88521
[32m[0907 11-23-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36373, current rewards: -2139.09156, mean: -0.88759
[32m[0907 11-23-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36240, current rewards: -2189.09156, mean: -0.88987
[32m[0907 11-23-50 @Agent.py:117][0m Average action selection time: 0.3613
[32m[0907 11-23-50 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-23-50 @MBExp.py:227][0m Rewards obtained: [-2229.091555027121], Lows: [88], Highs: [2095], Total time: 71055.627478
[32m[0907 11-26-31 @MBExp.py:144][0m ####################################################################
[32m[0907 11-26-31 @MBExp.py:145][0m Starting training iteration 87.
[32m[0907 11-26-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35901, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-26-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33636, current rewards: -36.33477, mean: -0.60558
[32m[0907 11-27-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33755, current rewards: -54.44650, mean: -0.49497
[32m[0907 11-27-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33469, current rewards: -71.53246, mean: -0.44708
[32m[0907 11-27-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33177, current rewards: -88.34590, mean: -0.42069
[32m[0907 11-27-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32889, current rewards: -84.61369, mean: -0.32544
[32m[0907 11-28-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32681, current rewards: -80.35154, mean: -0.25920
[32m[0907 11-28-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32540, current rewards: -94.87385, mean: -0.26354
[32m[0907 11-28-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32422, current rewards: -115.56117, mean: -0.28186
[32m[0907 11-29-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32328, current rewards: -111.31990, mean: -0.24200
[32m[0907 11-29-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32258, current rewards: -107.07862, mean: -0.20996
[32m[0907 11-29-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32194, current rewards: -102.83735, mean: -0.18364
[32m[0907 11-29-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32139, current rewards: -98.59607, mean: -0.16163
[32m[0907 11-30-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32092, current rewards: -103.03340, mean: -0.15611
[32m[0907 11-30-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32055, current rewards: -153.03340, mean: -0.21554
[32m[0907 11-30-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32020, current rewards: -203.03340, mean: -0.26715
[32m[0907 11-30-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31992, current rewards: -253.03340, mean: -0.31239
[32m[0907 11-31-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31965, current rewards: -303.03340, mean: -0.35236
[32m[0907 11-31-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31934, current rewards: -353.03340, mean: -0.38795
[32m[0907 11-31-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31912, current rewards: -403.03340, mean: -0.41983
[32m[0907 11-31-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31892, current rewards: -453.03340, mean: -0.44855
[32m[0907 11-32-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31869, current rewards: -503.03340, mean: -0.47456
[32m[0907 11-32-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31851, current rewards: -553.03340, mean: -0.49823
[32m[0907 11-32-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31831, current rewards: -603.03340, mean: -0.51986
[32m[0907 11-32-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31818, current rewards: -653.03340, mean: -0.53970
[32m[0907 11-33-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31802, current rewards: -703.03340, mean: -0.55796
[32m[0907 11-33-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31786, current rewards: -753.03340, mean: -0.57483
[32m[0907 11-33-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31771, current rewards: -803.03340, mean: -0.59047
[32m[0907 11-33-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31755, current rewards: -853.03340, mean: -0.60499
[32m[0907 11-34-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31718, current rewards: -903.03340, mean: -0.61852
[32m[0907 11-34-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31686, current rewards: -953.03340, mean: -0.63115
[32m[0907 11-34-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31653, current rewards: -1003.03340, mean: -0.64297
[32m[0907 11-35-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31625, current rewards: -1053.03340, mean: -0.65406
[32m[0907 11-35-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31599, current rewards: -1103.03340, mean: -0.66448
[32m[0907 11-35-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31572, current rewards: -1153.03340, mean: -0.67429
[32m[0907 11-35-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31545, current rewards: -1203.03340, mean: -0.68354
[32m[0907 11-36-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31524, current rewards: -1253.03340, mean: -0.69228
[32m[0907 11-36-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31503, current rewards: -1303.03340, mean: -0.70056
[32m[0907 11-36-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31483, current rewards: -1353.03340, mean: -0.70839
[32m[0907 11-36-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31474, current rewards: -1403.03340, mean: -0.71583
[32m[0907 11-37-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31477, current rewards: -1453.03340, mean: -0.72290
[32m[0907 11-37-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31476, current rewards: -1503.03340, mean: -0.72963
[32m[0907 11-37-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31475, current rewards: -1553.03340, mean: -0.73603
[32m[0907 11-37-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31475, current rewards: -1603.03340, mean: -0.74215
[32m[0907 11-38-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31477, current rewards: -1653.03340, mean: -0.74798
[32m[0907 11-38-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31476, current rewards: -1703.03340, mean: -0.75355
[32m[0907 11-38-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31467, current rewards: -1753.03340, mean: -0.75889
[32m[0907 11-38-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31452, current rewards: -1803.03340, mean: -0.76400
[32m[0907 11-39-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31433, current rewards: -1853.03340, mean: -0.76889
[32m[0907 11-39-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31399, current rewards: -1903.03340, mean: -0.77359
[32m[0907 11-39-35 @Agent.py:117][0m Average action selection time: 0.3136
[32m[0907 11-39-35 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-39-36 @MBExp.py:227][0m Rewards obtained: [-1943.0334033795498], Lows: [25], Highs: [1937], Total time: 71840.42483999999
[32m[0907 11-42-18 @MBExp.py:144][0m ####################################################################
[32m[0907 11-42-18 @MBExp.py:145][0m Starting training iteration 88.
[32m[0907 11-42-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31858, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-42-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31659, current rewards: -93.68782, mean: -1.56146
[32m[0907 11-42-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31620, current rewards: -162.77265, mean: -1.47975
[32m[0907 11-43-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33007, current rewards: -189.96711, mean: -1.18729
[32m[0907 11-43-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33575, current rewards: -258.89248, mean: -1.23282
[32m[0907 11-43-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34016, current rewards: -349.63659, mean: -1.34476
[32m[0907 11-44-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34305, current rewards: -432.55412, mean: -1.39534
[32m[0907 11-44-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34484, current rewards: -523.19810, mean: -1.45333
[32m[0907 11-44-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34571, current rewards: -614.90472, mean: -1.49977
[32m[0907 11-44-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34668, current rewards: -712.90472, mean: -1.54979
[32m[0907 11-45-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34739, current rewards: -804.49955, mean: -1.57745
[32m[0907 11-45-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34849, current rewards: -900.39519, mean: -1.60785
[32m[0907 11-45-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34973, current rewards: -995.21835, mean: -1.63151
[32m[0907 11-46-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35132, current rewards: -1091.12354, mean: -1.65322
[32m[0907 11-46-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35218, current rewards: -1188.07269, mean: -1.67334
[32m[0907 11-46-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35305, current rewards: -1278.72767, mean: -1.68254
[32m[0907 11-47-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35342, current rewards: -1378.72767, mean: -1.70213
[32m[0907 11-47-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35381, current rewards: -1478.72767, mean: -1.71945
[32m[0907 11-47-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35457, current rewards: -1578.72767, mean: -1.73487
[32m[0907 11-47-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35499, current rewards: -1678.72767, mean: -1.74867
[32m[0907 11-48-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35523, current rewards: -1778.72767, mean: -1.76112
[32m[0907 11-48-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35538, current rewards: -1878.72767, mean: -1.77238
[32m[0907 11-48-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35545, current rewards: -1978.72767, mean: -1.78264
[32m[0907 11-49-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35544, current rewards: -2078.72767, mean: -1.79201
[32m[0907 11-49-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35530, current rewards: -2178.72767, mean: -1.80060
[32m[0907 11-49-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35514, current rewards: -2278.72767, mean: -1.80851
[32m[0907 11-50-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35504, current rewards: -2378.72767, mean: -1.81582
[32m[0907 11-50-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35485, current rewards: -2478.72767, mean: -1.82259
[32m[0907 11-50-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35446, current rewards: -2578.72767, mean: -1.82888
[32m[0907 11-50-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35407, current rewards: -2678.72767, mean: -1.83474
[32m[0907 11-51-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35369, current rewards: -2778.72767, mean: -1.84022
[32m[0907 11-51-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35336, current rewards: -2878.72767, mean: -1.84534
[32m[0907 11-51-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35307, current rewards: -2978.72767, mean: -1.85014
[32m[0907 11-52-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35277, current rewards: -3078.72767, mean: -1.85466
[32m[0907 11-52-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35250, current rewards: -3178.72767, mean: -1.85891
[32m[0907 11-52-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35224, current rewards: -3278.72767, mean: -1.86291
[32m[0907 11-52-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35198, current rewards: -3378.72767, mean: -1.86670
[32m[0907 11-53-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35175, current rewards: -3478.72767, mean: -1.87028
[32m[0907 11-53-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35152, current rewards: -3578.72767, mean: -1.87368
[32m[0907 11-53-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35155, current rewards: -3678.72767, mean: -1.87690
[32m[0907 11-54-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35157, current rewards: -3778.72767, mean: -1.87996
[32m[0907 11-54-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35158, current rewards: -3878.72767, mean: -1.88288
[32m[0907 11-54-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35160, current rewards: -3978.72767, mean: -1.88565
[32m[0907 11-54-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35161, current rewards: -4078.72767, mean: -1.88830
[32m[0907 11-55-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35164, current rewards: -4178.72767, mean: -1.89083
[32m[0907 11-55-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35164, current rewards: -4278.72767, mean: -1.89324
[32m[0907 11-55-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35150, current rewards: -4378.72767, mean: -1.89555
[32m[0907 11-56-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35134, current rewards: -4478.72767, mean: -1.89777
[32m[0907 11-56-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35108, current rewards: -4578.72767, mean: -1.89989
[32m[0907 11-56-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35061, current rewards: -4678.72767, mean: -1.90192
[32m[0907 11-56-54 @Agent.py:117][0m Average action selection time: 0.3502
[32m[0907 11-56-54 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-56-54 @MBExp.py:227][0m Rewards obtained: [-4758.727673438015], Lows: [2363], Highs: [45], Total time: 72716.597216
[32m[0907 11-59-54 @MBExp.py:144][0m ####################################################################
[32m[0907 11-59-54 @MBExp.py:145][0m Starting training iteration 89.
[32m[0907 11-59-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36654, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-00-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35730, current rewards: -72.92615, mean: -1.21544
[32m[0907 12-00-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35513, current rewards: -172.92615, mean: -1.57206
[32m[0907 12-00-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35452, current rewards: -272.92615, mean: -1.70579
[32m[0907 12-01-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35437, current rewards: -372.92615, mean: -1.77584
[32m[0907 12-01-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35396, current rewards: -472.92615, mean: -1.81895
[32m[0907 12-01-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35395, current rewards: -572.92615, mean: -1.84815
[32m[0907 12-02-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35369, current rewards: -672.92615, mean: -1.86924
[32m[0907 12-02-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35349, current rewards: -772.92615, mean: -1.88519
[32m[0907 12-02-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35323, current rewards: -872.92615, mean: -1.89767
[32m[0907 12-02-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35322, current rewards: -972.92615, mean: -1.90770
[32m[0907 12-03-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35312, current rewards: -1072.92615, mean: -1.91594
[32m[0907 12-03-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35308, current rewards: -1172.92615, mean: -1.92283
[32m[0907 12-03-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35306, current rewards: -1272.92615, mean: -1.92868
[32m[0907 12-04-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35223, current rewards: -1372.92615, mean: -1.93370
[32m[0907 12-04-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34972, current rewards: -1472.92615, mean: -1.93806
[32m[0907 12-04-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34765, current rewards: -1572.92615, mean: -1.94188
[32m[0907 12-04-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34575, current rewards: -1672.92615, mean: -1.94526
[32m[0907 12-05-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34402, current rewards: -1772.92615, mean: -1.94827
[32m[0907 12-05-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34249, current rewards: -1872.92615, mean: -1.95096
[32m[0907 12-05-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34107, current rewards: -1972.92615, mean: -1.95339
[32m[0907 12-05-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33984, current rewards: -2072.92615, mean: -1.95559
[32m[0907 12-06-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33869, current rewards: -2172.92615, mean: -1.95759
[32m[0907 12-06-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33765, current rewards: -2272.92615, mean: -1.95942
[32m[0907 12-06-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33668, current rewards: -2372.92615, mean: -1.96110
[32m[0907 12-06-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33581, current rewards: -2472.92615, mean: -1.96264
[32m[0907 12-07-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33501, current rewards: -2572.92615, mean: -1.96407
[32m[0907 12-07-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33427, current rewards: -2672.92615, mean: -1.96539
[32m[0907 12-07-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33345, current rewards: -2772.92615, mean: -1.96661
[32m[0907 12-08-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33258, current rewards: -2872.92615, mean: -1.96776
[32m[0907 12-08-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33176, current rewards: -2972.92615, mean: -1.96883
[32m[0907 12-08-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33100, current rewards: -3072.92615, mean: -1.96982
[32m[0907 12-08-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33027, current rewards: -3172.92615, mean: -1.97076
[32m[0907 12-09-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32956, current rewards: -3272.92615, mean: -1.97164
[32m[0907 12-09-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32891, current rewards: -3372.92615, mean: -1.97247
[32m[0907 12-09-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32829, current rewards: -3472.92615, mean: -1.97325
[32m[0907 12-09-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32770, current rewards: -3572.92615, mean: -1.97399
[32m[0907 12-10-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32715, current rewards: -3672.92615, mean: -1.97469
[32m[0907 12-10-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32663, current rewards: -3772.92615, mean: -1.97535
[32m[0907 12-10-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32619, current rewards: -3872.92615, mean: -1.97598
[32m[0907 12-10-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32589, current rewards: -3972.92615, mean: -1.97658
[32m[0907 12-11-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32562, current rewards: -4072.92615, mean: -1.97715
[32m[0907 12-11-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32537, current rewards: -4172.92615, mean: -1.97769
[32m[0907 12-11-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32510, current rewards: -4272.92615, mean: -1.97821
[32m[0907 12-11-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32487, current rewards: -4372.92615, mean: -1.97870
[32m[0907 12-12-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32464, current rewards: -4472.92615, mean: -1.97917
[32m[0907 12-12-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32432, current rewards: -4572.92615, mean: -1.97962
[32m[0907 12-12-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32397, current rewards: -4672.92615, mean: -1.98005
[32m[0907 12-12-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32366, current rewards: -4772.92615, mean: -1.98047
[32m[0907 12-13-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32326, current rewards: -4872.92615, mean: -1.98086
[32m[0907 12-13-21 @Agent.py:117][0m Average action selection time: 0.3227
[32m[0907 12-13-21 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-13-22 @MBExp.py:227][0m Rewards obtained: [-4952.92615128624], Lows: [2454], Highs: [45], Total time: 73524.187353
[32m[0907 12-16-08 @MBExp.py:144][0m ####################################################################
[32m[0907 12-16-08 @MBExp.py:145][0m Starting training iteration 90.
[32m[0907 12-16-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33805, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-16-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35012, current rewards: -89.74524, mean: -1.49575
[32m[0907 12-16-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33449, current rewards: -157.37677, mean: -1.43070
[32m[0907 12-17-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32870, current rewards: -257.37677, mean: -1.60860
[32m[0907 12-17-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32562, current rewards: -357.37677, mean: -1.70179
[32m[0907 12-17-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32360, current rewards: -457.37677, mean: -1.75914
[32m[0907 12-17-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32231, current rewards: -557.37677, mean: -1.79799
[32m[0907 12-18-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32143, current rewards: -657.37677, mean: -1.82605
[32m[0907 12-18-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32067, current rewards: -757.37677, mean: -1.84726
[32m[0907 12-18-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32023, current rewards: -857.37677, mean: -1.86386
[32m[0907 12-18-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31976, current rewards: -957.37677, mean: -1.87721
[32m[0907 12-19-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31930, current rewards: -1057.37677, mean: -1.88817
[32m[0907 12-19-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31898, current rewards: -1157.37677, mean: -1.89734
[32m[0907 12-19-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31861, current rewards: -1257.37677, mean: -1.90512
[32m[0907 12-19-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31837, current rewards: -1357.37677, mean: -1.91180
[32m[0907 12-20-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31810, current rewards: -1457.37677, mean: -1.91760
[32m[0907 12-20-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31787, current rewards: -1557.37677, mean: -1.92269
[32m[0907 12-20-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31770, current rewards: -1657.37677, mean: -1.92718
[32m[0907 12-20-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31754, current rewards: -1757.37677, mean: -1.93118
[32m[0907 12-21-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31741, current rewards: -1857.37677, mean: -1.93477
[32m[0907 12-21-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31733, current rewards: -1957.37677, mean: -1.93800
[32m[0907 12-21-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31724, current rewards: -2057.37677, mean: -1.94092
[32m[0907 12-22-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31710, current rewards: -2157.37677, mean: -1.94358
[32m[0907 12-22-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31695, current rewards: -2257.37677, mean: -1.94601
[32m[0907 12-22-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31684, current rewards: -2357.37677, mean: -1.94825
[32m[0907 12-22-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31678, current rewards: -2457.37677, mean: -1.95030
[32m[0907 12-23-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31671, current rewards: -2557.37677, mean: -1.95220
[32m[0907 12-23-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31666, current rewards: -2657.37677, mean: -1.95395
[32m[0907 12-23-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31660, current rewards: -2757.37677, mean: -1.95559
[32m[0907 12-23-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31639, current rewards: -2857.37677, mean: -1.95711
[32m[0907 12-24-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31609, current rewards: -2957.37677, mean: -1.95853
[32m[0907 12-24-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31583, current rewards: -3057.37677, mean: -1.95986
[32m[0907 12-24-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31558, current rewards: -3157.37677, mean: -1.96110
[32m[0907 12-24-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31534, current rewards: -3257.37677, mean: -1.96228
[32m[0907 12-25-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31510, current rewards: -3357.37677, mean: -1.96338
[32m[0907 12-25-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31491, current rewards: -3457.37677, mean: -1.96442
[32m[0907 12-25-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31470, current rewards: -3557.37677, mean: -1.96540
[32m[0907 12-25-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31450, current rewards: -3657.37677, mean: -1.96633
[32m[0907 12-26-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31434, current rewards: -3757.37677, mean: -1.96721
[32m[0907 12-26-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31417, current rewards: -3857.37677, mean: -1.96805
[32m[0907 12-26-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31412, current rewards: -3957.37677, mean: -1.96884
[32m[0907 12-26-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31414, current rewards: -4057.37677, mean: -1.96960
[32m[0907 12-27-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31417, current rewards: -4157.37677, mean: -1.97032
[32m[0907 12-27-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31420, current rewards: -4257.37677, mean: -1.97101
[32m[0907 12-27-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31421, current rewards: -4357.37677, mean: -1.97166
[32m[0907 12-27-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31425, current rewards: -4457.37677, mean: -1.97229
[32m[0907 12-28-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31416, current rewards: -4557.37677, mean: -1.97289
[32m[0907 12-28-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31405, current rewards: -4657.37677, mean: -1.97346
[32m[0907 12-28-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31392, current rewards: -4757.37677, mean: -1.97402
[32m[0907 12-29-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31373, current rewards: -4857.37677, mean: -1.97454
[32m[0907 12-29-12 @Agent.py:117][0m Average action selection time: 0.3135
[32m[0907 12-29-12 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-29-12 @MBExp.py:227][0m Rewards obtained: [-4937.37677404746], Lows: [2443], Highs: [52], Total time: 74308.62212
[32m[0907 12-32-00 @MBExp.py:144][0m ####################################################################
[32m[0907 12-32-00 @MBExp.py:145][0m Starting training iteration 91.
[32m[0907 12-32-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31736, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-32-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31723, current rewards: -87.54508, mean: -1.45908
[32m[0907 12-32-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31664, current rewards: -107.00010, mean: -0.97273
[32m[0907 12-32-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32774, current rewards: -124.42627, mean: -0.77766
[32m[0907 12-33-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32538, current rewards: -145.08456, mean: -0.69088
[32m[0907 12-33-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32503, current rewards: -179.99985, mean: -0.69231
[32m[0907 12-33-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32336, current rewards: -179.46755, mean: -0.57893
[32m[0907 12-33-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32234, current rewards: -199.75726, mean: -0.55488
[32m[0907 12-34-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32173, current rewards: -203.11900, mean: -0.49541
[32m[0907 12-34-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32143, current rewards: -263.19591, mean: -0.57217
[32m[0907 12-34-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32122, current rewards: -294.37950, mean: -0.57721
[32m[0907 12-35-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32238, current rewards: -355.06259, mean: -0.63404
[32m[0907 12-35-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32183, current rewards: -403.99369, mean: -0.66228
[32m[0907 12-35-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32140, current rewards: -453.99369, mean: -0.68787
[32m[0907 12-35-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32097, current rewards: -503.99369, mean: -0.70985
[32m[0907 12-36-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32052, current rewards: -498.57469, mean: -0.65602
[32m[0907 12-36-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32024, current rewards: -495.09536, mean: -0.61123
[32m[0907 12-36-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31995, current rewards: -491.61602, mean: -0.57165
[32m[0907 12-36-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31967, current rewards: -488.13669, mean: -0.53641
[32m[0907 12-37-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31942, current rewards: -484.65736, mean: -0.50485
[32m[0907 12-37-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31919, current rewards: -481.17802, mean: -0.47641
[32m[0907 12-37-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31895, current rewards: -477.69869, mean: -0.45066
[32m[0907 12-37-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31870, current rewards: -474.21936, mean: -0.42722
[32m[0907 12-38-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31849, current rewards: -470.27720, mean: -0.40541
[32m[0907 12-38-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31836, current rewards: -490.64875, mean: -0.40549
[32m[0907 12-38-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31823, current rewards: -540.64875, mean: -0.42909
[32m[0907 12-38-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31810, current rewards: -590.64875, mean: -0.45088
[32m[0907 12-39-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31797, current rewards: -640.64875, mean: -0.47107
[32m[0907 12-39-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31784, current rewards: -690.64875, mean: -0.48982
[32m[0907 12-39-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31746, current rewards: -740.64875, mean: -0.50729
[32m[0907 12-39-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31714, current rewards: -790.64875, mean: -0.52361
[32m[0907 12-40-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31685, current rewards: -840.64875, mean: -0.53888
[32m[0907 12-40-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31658, current rewards: -890.64875, mean: -0.55320
[32m[0907 12-40-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31633, current rewards: -940.64875, mean: -0.56666
[32m[0907 12-41-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31609, current rewards: -990.64875, mean: -0.57933
[32m[0907 12-41-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31588, current rewards: -1040.64875, mean: -0.59128
[32m[0907 12-41-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31568, current rewards: -1090.64875, mean: -0.60257
[32m[0907 12-41-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31546, current rewards: -1140.64875, mean: -0.61325
[32m[0907 12-42-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31525, current rewards: -1190.64875, mean: -0.62338
[32m[0907 12-42-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31505, current rewards: -1240.64875, mean: -0.63298
[32m[0907 12-42-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31503, current rewards: -1290.64875, mean: -0.64211
[32m[0907 12-42-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31504, current rewards: -1340.64875, mean: -0.65080
[32m[0907 12-43-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31504, current rewards: -1390.64875, mean: -0.65908
[32m[0907 12-43-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31503, current rewards: -1440.64875, mean: -0.66697
[32m[0907 12-43-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31502, current rewards: -1490.64875, mean: -0.67450
[32m[0907 12-43-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31499, current rewards: -1540.64875, mean: -0.68170
[32m[0907 12-44-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31489, current rewards: -1590.64875, mean: -0.68859
[32m[0907 12-44-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31472, current rewards: -1640.64875, mean: -0.69519
[32m[0907 12-44-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31456, current rewards: -1690.64875, mean: -0.70151
[32m[0907 12-44-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31431, current rewards: -1740.64875, mean: -0.70758
[32m[0907 12-45-06 @Agent.py:117][0m Average action selection time: 0.3141
[32m[0907 12-45-06 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-45-06 @MBExp.py:227][0m Rewards obtained: [-1780.6487475277424], Lows: [189], Highs: [1494], Total time: 75094.519604
[32m[0907 12-47-55 @MBExp.py:144][0m ####################################################################
[32m[0907 12-47-55 @MBExp.py:145][0m Starting training iteration 92.
[32m[0907 12-47-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30790, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-48-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30815, current rewards: -58.78382, mean: -0.97973
[32m[0907 12-48-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31124, current rewards: -108.78382, mean: -0.98894
[32m[0907 12-48-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31265, current rewards: -158.78382, mean: -0.99240
[32m[0907 12-49-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31337, current rewards: -208.78382, mean: -0.99421
[32m[0907 12-49-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31392, current rewards: -258.78382, mean: -0.99532
[32m[0907 12-49-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31435, current rewards: -308.78382, mean: -0.99608
[32m[0907 12-49-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31456, current rewards: -358.78382, mean: -0.99662
[32m[0907 12-50-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31478, current rewards: -408.78382, mean: -0.99703
[32m[0907 12-50-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31490, current rewards: -458.78382, mean: -0.99736
[32m[0907 12-50-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31497, current rewards: -508.78382, mean: -0.99762
[32m[0907 12-50-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31515, current rewards: -558.78382, mean: -0.99783
[32m[0907 12-51-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31512, current rewards: -608.78382, mean: -0.99801
[32m[0907 12-51-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31515, current rewards: -658.78382, mean: -0.99816
[32m[0907 12-51-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31514, current rewards: -708.78382, mean: -0.99829
[32m[0907 12-51-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31511, current rewards: -758.78382, mean: -0.99840
[32m[0907 12-52-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31509, current rewards: -808.78382, mean: -0.99850
[32m[0907 12-52-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31513, current rewards: -858.78382, mean: -0.99859
[32m[0907 12-52-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31517, current rewards: -908.78382, mean: -0.99866
[32m[0907 12-52-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31516, current rewards: -958.78382, mean: -0.99873
[32m[0907 12-53-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31511, current rewards: -1008.78382, mean: -0.99880
[32m[0907 12-53-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31505, current rewards: -1058.78382, mean: -0.99885
[32m[0907 12-53-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31503, current rewards: -1108.78382, mean: -0.99890
[32m[0907 12-54-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31498, current rewards: -1158.78382, mean: -0.99895
[32m[0907 12-54-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31493, current rewards: -1208.78382, mean: -0.99899
[32m[0907 12-54-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31490, current rewards: -1258.78382, mean: -0.99903
[32m[0907 12-54-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31486, current rewards: -1278.65624, mean: -0.97607
[32m[0907 12-55-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31485, current rewards: -1274.85699, mean: -0.93739
[32m[0907 12-55-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31481, current rewards: -1271.05774, mean: -0.90146
[32m[0907 12-55-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31464, current rewards: -1267.25849, mean: -0.86799
[32m[0907 12-55-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31441, current rewards: -1263.45924, mean: -0.83673
[32m[0907 12-56-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31418, current rewards: -1289.99240, mean: -0.82692
[32m[0907 12-56-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31397, current rewards: -1339.99240, mean: -0.83229
[32m[0907 12-56-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31375, current rewards: -1389.99240, mean: -0.83734
[32m[0907 12-56-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31359, current rewards: -1439.99240, mean: -0.84210
[32m[0907 12-57-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31340, current rewards: -1489.99240, mean: -0.84659
[32m[0907 12-57-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31324, current rewards: -1539.99240, mean: -0.85082
[32m[0907 12-57-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31309, current rewards: -1589.99240, mean: -0.85483
[32m[0907 12-57-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31295, current rewards: -1639.99240, mean: -0.85863
[32m[0907 12-58-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31283, current rewards: -1674.05746, mean: -0.85411
[32m[0907 12-58-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31275, current rewards: -1670.25821, mean: -0.83097
[32m[0907 12-58-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31281, current rewards: -1719.18222, mean: -0.83455
[32m[0907 12-58-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31287, current rewards: -1769.18222, mean: -0.83847
[32m[0907 12-59-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31292, current rewards: -1819.18222, mean: -0.84221
[32m[0907 12-59-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31295, current rewards: -1869.18222, mean: -0.84578
[32m[0907 12-59-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31300, current rewards: -1919.18222, mean: -0.84920
[32m[0907 12-59-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31294, current rewards: -1969.18222, mean: -0.85246
[32m[0907 13-00-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31283, current rewards: -2019.18222, mean: -0.85559
[32m[0907 13-00-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31274, current rewards: -2069.18222, mean: -0.85858
[32m[0907 13-00-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31257, current rewards: -2119.18222, mean: -0.86146
[32m[0907 13-00-57 @Agent.py:117][0m Average action selection time: 0.3124
[32m[0907 13-00-57 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-00-57 @MBExp.py:227][0m Rewards obtained: [-2159.1822237742776], Lows: [1], Highs: [2181], Total time: 75876.164374
[32m[0907 13-03-48 @MBExp.py:144][0m ####################################################################
[32m[0907 13-03-48 @MBExp.py:145][0m Starting training iteration 93.
[32m[0907 13-03-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30820, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-04-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31241, current rewards: -91.25375, mean: -1.52090
[32m[0907 13-04-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31081, current rewards: -191.25375, mean: -1.73867
[32m[0907 13-04-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31236, current rewards: -291.25375, mean: -1.82034
[32m[0907 13-04-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31316, current rewards: -391.25375, mean: -1.86311
[32m[0907 13-05-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31379, current rewards: -491.25375, mean: -1.88944
[32m[0907 13-05-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31404, current rewards: -591.25375, mean: -1.90727
[32m[0907 13-05-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31419, current rewards: -691.25375, mean: -1.92015
[32m[0907 13-05-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31432, current rewards: -791.25375, mean: -1.92989
[32m[0907 13-06-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31438, current rewards: -891.25375, mean: -1.93751
[32m[0907 13-06-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31455, current rewards: -991.25375, mean: -1.94363
[32m[0907 13-06-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31464, current rewards: -1091.25375, mean: -1.94867
[32m[0907 13-07-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31466, current rewards: -1191.25375, mean: -1.95287
[32m[0907 13-07-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31467, current rewards: -1291.25375, mean: -1.95645
[32m[0907 13-07-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31569, current rewards: -1391.25375, mean: -1.95951
[32m[0907 13-07-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31814, current rewards: -1491.25375, mean: -1.96218
[32m[0907 13-08-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32027, current rewards: -1591.25375, mean: -1.96451
[32m[0907 13-08-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32222, current rewards: -1691.25375, mean: -1.96657
[32m[0907 13-08-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32404, current rewards: -1791.25375, mean: -1.96841
[32m[0907 13-09-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32570, current rewards: -1891.25375, mean: -1.97006
[32m[0907 13-09-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32718, current rewards: -1991.25375, mean: -1.97154
[32m[0907 13-09-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32862, current rewards: -2091.25375, mean: -1.97288
[32m[0907 13-09-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32988, current rewards: -2191.25375, mean: -1.97410
[32m[0907 13-10-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33111, current rewards: -2291.25375, mean: -1.97522
[32m[0907 13-10-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33216, current rewards: -2391.25375, mean: -1.97624
[32m[0907 13-10-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33318, current rewards: -2491.25375, mean: -1.97719
[32m[0907 13-11-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33410, current rewards: -2591.25375, mean: -1.97806
[32m[0907 13-11-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33495, current rewards: -2691.25375, mean: -1.97886
[32m[0907 13-11-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33568, current rewards: -2791.25375, mean: -1.97961
[32m[0907 13-11-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33606, current rewards: -2891.25375, mean: -1.98031
[32m[0907 13-12-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33652, current rewards: -2991.25375, mean: -1.98096
[32m[0907 13-12-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33683, current rewards: -3091.25375, mean: -1.98157
[32m[0907 13-12-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33722, current rewards: -3191.25375, mean: -1.98215
[32m[0907 13-13-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33753, current rewards: -3291.25375, mean: -1.98268
[32m[0907 13-13-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33775, current rewards: -3391.25375, mean: -1.98319
[32m[0907 13-13-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33798, current rewards: -3491.25375, mean: -1.98367
[32m[0907 13-14-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33813, current rewards: -3591.25375, mean: -1.98412
[32m[0907 13-14-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33826, current rewards: -3691.25375, mean: -1.98455
[32m[0907 13-14-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33766, current rewards: -3791.25375, mean: -1.98495
[32m[0907 13-14-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33691, current rewards: -3891.25375, mean: -1.98533
[32m[0907 13-15-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33629, current rewards: -3991.25375, mean: -1.98570
[32m[0907 13-15-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33576, current rewards: -4091.25375, mean: -1.98605
[32m[0907 13-15-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33529, current rewards: -4191.25375, mean: -1.98638
[32m[0907 13-15-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33484, current rewards: -4291.25375, mean: -1.98669
[32m[0907 13-16-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33442, current rewards: -4391.25375, mean: -1.98699
[32m[0907 13-16-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33400, current rewards: -4491.25375, mean: -1.98728
[32m[0907 13-16-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33360, current rewards: -4591.25375, mean: -1.98756
[32m[0907 13-16-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33323, current rewards: -4691.25375, mean: -1.98782
[32m[0907 13-17-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33285, current rewards: -4791.25375, mean: -1.98807
[32m[0907 13-17-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33236, current rewards: -4891.25375, mean: -1.98831
[32m[0907 13-17-38 @Agent.py:117][0m Average action selection time: 0.3318
[32m[0907 13-17-38 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-17-38 @MBExp.py:227][0m Rewards obtained: [-4971.253746846258], Lows: [2476], Highs: [20], Total time: 76706.499011
[32m[0907 13-20-32 @MBExp.py:144][0m ####################################################################
[32m[0907 13-20-32 @MBExp.py:145][0m Starting training iteration 94.
[32m[0907 13-20-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33936, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-20-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31438, current rewards: -58.90162, mean: -0.98169
[32m[0907 13-21-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31212, current rewards: -108.90162, mean: -0.99001
[32m[0907 13-21-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31355, current rewards: -158.90162, mean: -0.99314
[32m[0907 13-21-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31454, current rewards: -208.90162, mean: -0.99477
[32m[0907 13-21-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31483, current rewards: -258.90162, mean: -0.99578
[32m[0907 13-22-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31491, current rewards: -308.90162, mean: -0.99646
[32m[0907 13-22-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31505, current rewards: -358.90162, mean: -0.99695
[32m[0907 13-22-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31512, current rewards: -408.90162, mean: -0.99732
[32m[0907 13-22-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31517, current rewards: -458.90162, mean: -0.99761
[32m[0907 13-23-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31524, current rewards: -508.90162, mean: -0.99785
[32m[0907 13-23-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31517, current rewards: -558.90162, mean: -0.99804
[32m[0907 13-23-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31509, current rewards: -608.90162, mean: -0.99820
[32m[0907 13-24-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31511, current rewards: -658.90162, mean: -0.99834
[32m[0907 13-24-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31515, current rewards: -708.90162, mean: -0.99845
[32m[0907 13-24-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31523, current rewards: -758.90162, mean: -0.99855
[32m[0907 13-24-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31518, current rewards: -808.90162, mean: -0.99864
[32m[0907 13-25-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31518, current rewards: -858.90162, mean: -0.99872
[32m[0907 13-25-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31523, current rewards: -908.90162, mean: -0.99879
[32m[0907 13-25-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31518, current rewards: -958.90162, mean: -0.99886
[32m[0907 13-25-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31515, current rewards: -1008.90162, mean: -0.99891
[32m[0907 13-26-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31517, current rewards: -1058.90162, mean: -0.99896
[32m[0907 13-26-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31515, current rewards: -1108.90162, mean: -0.99901
[32m[0907 13-26-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31513, current rewards: -1158.90162, mean: -0.99905
[32m[0907 13-26-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31515, current rewards: -1208.90162, mean: -0.99909
[32m[0907 13-27-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31515, current rewards: -1258.90162, mean: -0.99913
[32m[0907 13-27-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31511, current rewards: -1289.37476, mean: -0.98426
[32m[0907 13-27-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31510, current rewards: -1285.13348, mean: -0.94495
[32m[0907 13-27-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31510, current rewards: -1280.89221, mean: -0.90843
[32m[0907 13-28-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31510, current rewards: -1276.65093, mean: -0.87442
[32m[0907 13-28-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31506, current rewards: -1272.72051, mean: -0.84286
[32m[0907 13-28-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31486, current rewards: -1269.03326, mean: -0.81348
[32m[0907 13-28-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31462, current rewards: -1265.34601, mean: -0.78593
[32m[0907 13-29-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31441, current rewards: -1261.65877, mean: -0.76004
[32m[0907 13-29-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31421, current rewards: -1257.97152, mean: -0.73566
[32m[0907 13-29-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31401, current rewards: -1254.28428, mean: -0.71266
[32m[0907 13-30-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31382, current rewards: -1263.48197, mean: -0.69806
[32m[0907 13-30-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31367, current rewards: -1313.48197, mean: -0.70617
[32m[0907 13-30-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31351, current rewards: -1363.48197, mean: -0.71386
[32m[0907 13-30-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31336, current rewards: -1413.48197, mean: -0.72116
[32m[0907 13-31-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31322, current rewards: -1463.48197, mean: -0.72810
[32m[0907 13-31-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31307, current rewards: -1513.48197, mean: -0.73470
[32m[0907 13-31-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31300, current rewards: -1563.48197, mean: -0.74099
[32m[0907 13-31-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31305, current rewards: -1613.48197, mean: -0.74698
[32m[0907 13-32-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31306, current rewards: -1663.48197, mean: -0.75271
[32m[0907 13-32-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31305, current rewards: -1713.48197, mean: -0.75818
[32m[0907 13-32-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31305, current rewards: -1763.48197, mean: -0.76341
[32m[0907 13-32-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31309, current rewards: -1813.48197, mean: -0.76842
[32m[0907 13-33-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31311, current rewards: -1863.48197, mean: -0.77323
[32m[0907 13-33-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31302, current rewards: -1913.48197, mean: -0.77784
[32m[0907 13-33-34 @Agent.py:117][0m Average action selection time: 0.3128
[32m[0907 13-33-34 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-33-35 @MBExp.py:227][0m Rewards obtained: [-1953.4819715029796], Lows: [0], Highs: [1993], Total time: 77489.21362600001
[32m[0907 13-36-29 @MBExp.py:144][0m ####################################################################
[32m[0907 13-36-29 @MBExp.py:145][0m Starting training iteration 95.
[32m[0907 13-36-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32901, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-36-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31164, current rewards: -61.92831, mean: -1.03214
[32m[0907 13-37-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31029, current rewards: -111.92831, mean: -1.01753
[32m[0907 13-37-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30981, current rewards: -161.92831, mean: -1.01205
[32m[0907 13-37-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31147, current rewards: -211.92831, mean: -1.00918
[32m[0907 13-37-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31236, current rewards: -261.92831, mean: -1.00742
[32m[0907 13-38-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31278, current rewards: -311.92831, mean: -1.00622
[32m[0907 13-38-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31315, current rewards: -361.92831, mean: -1.00536
[32m[0907 13-38-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31344, current rewards: -411.92831, mean: -1.00470
[32m[0907 13-38-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31358, current rewards: -461.92831, mean: -1.00419
[32m[0907 13-39-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31365, current rewards: -511.92831, mean: -1.00378
[32m[0907 13-39-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31379, current rewards: -561.92831, mean: -1.00344
[32m[0907 13-39-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31381, current rewards: -562.24454, mean: -0.92171
[32m[0907 13-39-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31381, current rewards: -556.02206, mean: -0.84246
[32m[0907 13-40-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31388, current rewards: -552.81907, mean: -0.77862
[32m[0907 13-40-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31398, current rewards: -549.65934, mean: -0.72324
[32m[0907 13-40-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31399, current rewards: -546.49961, mean: -0.67469
[32m[0907 13-41-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31402, current rewards: -543.33987, mean: -0.63179
[32m[0907 13-41-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31406, current rewards: -579.51834, mean: -0.63683
[32m[0907 13-41-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31408, current rewards: -629.51834, mean: -0.65575
[32m[0907 13-41-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31409, current rewards: -679.51834, mean: -0.67279
[32m[0907 13-42-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31409, current rewards: -729.51834, mean: -0.68822
[32m[0907 13-42-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31412, current rewards: -779.51834, mean: -0.70227
[32m[0907 13-42-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31412, current rewards: -829.51834, mean: -0.71510
[32m[0907 13-42-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31409, current rewards: -879.51834, mean: -0.72687
[32m[0907 13-43-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31413, current rewards: -929.51834, mean: -0.73771
[32m[0907 13-43-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31415, current rewards: -979.51834, mean: -0.74772
[32m[0907 13-43-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31414, current rewards: -1029.51834, mean: -0.75700
[32m[0907 13-43-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31417, current rewards: -1079.51834, mean: -0.76562
[32m[0907 13-44-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31415, current rewards: -1129.51834, mean: -0.77364
[32m[0907 13-44-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31413, current rewards: -1179.51834, mean: -0.78114
[32m[0907 13-44-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31405, current rewards: -1229.51834, mean: -0.78815
[32m[0907 13-44-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31389, current rewards: -1279.51834, mean: -0.79473
[32m[0907 13-45-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31371, current rewards: -1329.51834, mean: -0.80091
[32m[0907 13-45-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31353, current rewards: -1379.51834, mean: -0.80674
[32m[0907 13-45-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31336, current rewards: -1429.51834, mean: -0.81223
[32m[0907 13-45-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31320, current rewards: -1479.51834, mean: -0.81741
[32m[0907 13-46-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31304, current rewards: -1529.51834, mean: -0.82232
[32m[0907 13-46-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31289, current rewards: -1579.51834, mean: -0.82697
[32m[0907 13-46-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31274, current rewards: -1629.51834, mean: -0.83139
[32m[0907 13-46-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31261, current rewards: -1679.51834, mean: -0.83558
[32m[0907 13-47-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31250, current rewards: -1729.51834, mean: -0.83957
[32m[0907 13-47-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31239, current rewards: -1779.51834, mean: -0.84337
[32m[0907 13-47-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31240, current rewards: -1829.51834, mean: -0.84700
[32m[0907 13-48-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31245, current rewards: -1879.51834, mean: -0.85046
[32m[0907 13-48-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31250, current rewards: -1929.51834, mean: -0.85377
[32m[0907 13-48-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31255, current rewards: -1979.51834, mean: -0.85693
[32m[0907 13-48-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31260, current rewards: -2029.51834, mean: -0.85997
[32m[0907 13-49-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31263, current rewards: -2079.51834, mean: -0.86287
[32m[0907 13-49-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31262, current rewards: -2129.51834, mean: -0.86566
[32m[0907 13-49-31 @Agent.py:117][0m Average action selection time: 0.3124
[32m[0907 13-49-31 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-49-31 @MBExp.py:227][0m Rewards obtained: [-2169.518341388805], Lows: [3], Highs: [2189], Total time: 78270.94191800001
[32m[0907 13-52-27 @MBExp.py:144][0m ####################################################################
[32m[0907 13-52-27 @MBExp.py:145][0m Starting training iteration 96.
[32m[0907 13-52-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32918, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-52-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.39272, current rewards: -47.27559, mean: -0.78793
[32m[0907 13-53-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.42614, current rewards: -105.90279, mean: -0.96275
[32m[0907 13-53-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.45232, current rewards: -205.90279, mean: -1.28689
[32m[0907 13-54-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.46973, current rewards: -305.90279, mean: -1.45668
[32m[0907 13-54-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.46309, current rewards: -389.28438, mean: -1.49725
[32m[0907 13-54-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.43934, current rewards: -485.89666, mean: -1.56741
[32m[0907 13-55-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.42214, current rewards: -585.89666, mean: -1.62749
[32m[0907 13-55-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.40915, current rewards: -685.89666, mean: -1.67292
[32m[0907 13-55-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.39894, current rewards: -785.89666, mean: -1.70847
[32m[0907 13-55-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.39078, current rewards: -885.89666, mean: -1.73705
[32m[0907 13-56-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.38389, current rewards: -985.89666, mean: -1.76053
[32m[0907 13-56-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37828, current rewards: -1085.89666, mean: -1.78016
[32m[0907 13-56-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37354, current rewards: -1185.89666, mean: -1.79681
[32m[0907 13-56-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36945, current rewards: -1285.89666, mean: -1.81112
[32m[0907 13-57-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36590, current rewards: -1385.89666, mean: -1.82355
[32m[0907 13-57-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36275, current rewards: -1485.89666, mean: -1.83444
[32m[0907 13-57-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36005, current rewards: -1585.89666, mean: -1.84407
[32m[0907 13-57-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35759, current rewards: -1685.89666, mean: -1.85263
[32m[0907 13-58-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35542, current rewards: -1785.89666, mean: -1.86031
[32m[0907 13-58-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35346, current rewards: -1885.89666, mean: -1.86722
[32m[0907 13-58-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35166, current rewards: -1985.89666, mean: -1.87349
[32m[0907 13-58-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35127, current rewards: -2038.13861, mean: -1.83616
[32m[0907 13-59-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35867, current rewards: -2094.90220, mean: -1.80595
[32m[0907 13-59-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36541, current rewards: -2144.90220, mean: -1.77265
[32m[0907 14-00-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37169, current rewards: -2194.90220, mean: -1.74199
[32m[0907 14-00-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37399, current rewards: -2244.90220, mean: -1.71367
[32m[0907 14-00-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37284, current rewards: -2294.90220, mean: -1.68743
[32m[0907 14-01-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.37051, current rewards: -2344.90220, mean: -1.66305
[32m[0907 14-01-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36897, current rewards: -2394.90220, mean: -1.64034
[32m[0907 14-01-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36693, current rewards: -2444.90220, mean: -1.61914
[32m[0907 14-01-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36503, current rewards: -2494.90220, mean: -1.59930
[32m[0907 14-02-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36324, current rewards: -2544.90220, mean: -1.58068
[32m[0907 14-02-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36156, current rewards: -2594.90220, mean: -1.56319
[32m[0907 14-02-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35999, current rewards: -2600.20305, mean: -1.52059
[32m[0907 14-02-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35850, current rewards: -2592.87869, mean: -1.47323
[32m[0907 14-03-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35709, current rewards: -2585.60448, mean: -1.42851
[32m[0907 14-03-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35574, current rewards: -2578.33026, mean: -1.38620
[32m[0907 14-03-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35466, current rewards: -2586.31065, mean: -1.35409
[32m[0907 14-04-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35372, current rewards: -2636.90332, mean: -1.34536
[32m[0907 14-04-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35286, current rewards: -2677.11388, mean: -1.33190
[32m[0907 14-04-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35207, current rewards: -2722.20148, mean: -1.32146
[32m[0907 14-04-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35126, current rewards: -2763.89440, mean: -1.30990
[32m[0907 14-05-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35043, current rewards: -2806.16253, mean: -1.29915
[32m[0907 14-05-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34958, current rewards: -2844.83906, mean: -1.28726
[32m[0907 14-05-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34846, current rewards: -2894.83906, mean: -1.28090
[32m[0907 14-05-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34738, current rewards: -2944.83906, mean: -1.27482
[32m[0907 14-06-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34635, current rewards: -2994.83906, mean: -1.26900
[32m[0907 14-06-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34535, current rewards: -3044.83906, mean: -1.26342
[32m[0907 14-06-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34438, current rewards: -3094.83906, mean: -1.25806
[32m[0907 14-06-47 @Agent.py:117][0m Average action selection time: 0.3437
[32m[0907 14-06-47 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-06-47 @MBExp.py:227][0m Rewards obtained: [-3134.83906106123], Lows: [1049], Highs: [1090], Total time: 79130.82470200001
[32m[0907 14-09-47 @MBExp.py:144][0m ####################################################################
[32m[0907 14-09-47 @MBExp.py:145][0m Starting training iteration 97.
[32m[0907 14-09-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31713, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-10-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30995, current rewards: -79.60312, mean: -1.32672
[32m[0907 14-10-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31273, current rewards: -120.19221, mean: -1.09266
[32m[0907 14-10-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31339, current rewards: -167.02105, mean: -1.04388
[32m[0907 14-10-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31378, current rewards: -212.81148, mean: -1.01339
[32m[0907 14-11-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31410, current rewards: -261.76150, mean: -1.00677
[32m[0907 14-11-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31482, current rewards: -298.75665, mean: -0.96373
[32m[0907 14-11-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31485, current rewards: -343.48116, mean: -0.95411
[32m[0907 14-11-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31479, current rewards: -389.19351, mean: -0.94925
[32m[0907 14-12-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31546, current rewards: -432.85226, mean: -0.94098
[32m[0907 14-12-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31531, current rewards: -482.85226, mean: -0.94677
[32m[0907 14-12-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31558, current rewards: -531.80086, mean: -0.94964
[32m[0907 14-12-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31546, current rewards: -579.70255, mean: -0.95033
[32m[0907 14-13-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31535, current rewards: -628.64737, mean: -0.95250
[32m[0907 14-13-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31532, current rewards: -672.30707, mean: -0.94691
[32m[0907 14-13-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31527, current rewards: -722.30707, mean: -0.95040
[32m[0907 14-14-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31522, current rewards: -772.30707, mean: -0.95347
[32m[0907 14-14-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31514, current rewards: -822.30707, mean: -0.95617
[32m[0907 14-14-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31501, current rewards: -872.30707, mean: -0.95858
[32m[0907 14-14-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31494, current rewards: -920.21106, mean: -0.95855
[32m[0907 14-15-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31485, current rewards: -969.16091, mean: -0.95957
[32m[0907 14-15-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31475, current rewards: -1018.11012, mean: -0.96048
[32m[0907 14-15-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31475, current rewards: -1068.11012, mean: -0.96226
[32m[0907 14-15-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31470, current rewards: -1103.90511, mean: -0.95164
[32m[0907 14-16-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31481, current rewards: -1136.61568, mean: -0.93935
[32m[0907 14-16-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31498, current rewards: -1173.87592, mean: -0.93165
[32m[0907 14-16-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31485, current rewards: -1210.00155, mean: -0.92367
[32m[0907 14-16-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31492, current rewards: -1247.30395, mean: -0.91714
[32m[0907 14-17-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31484, current rewards: -1284.60624, mean: -0.91107
[32m[0907 14-17-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31457, current rewards: -1321.89966, mean: -0.90541
[32m[0907 14-17-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31435, current rewards: -1357.09284, mean: -0.89874
[32m[0907 14-17-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31436, current rewards: -1397.55723, mean: -0.89587
[32m[0907 14-18-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31425, current rewards: -1439.77020, mean: -0.89427
[32m[0907 14-18-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31401, current rewards: -1484.42690, mean: -0.89423
[32m[0907 14-18-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31389, current rewards: -1530.17049, mean: -0.89484
[32m[0907 14-18-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31372, current rewards: -1574.85905, mean: -0.89481
[32m[0907 14-19-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31360, current rewards: -1620.54800, mean: -0.89533
[32m[0907 14-19-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31358, current rewards: -1664.15992, mean: -0.89471
[32m[0907 14-19-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31371, current rewards: -1708.75744, mean: -0.89464
[32m[0907 14-20-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31372, current rewards: -1743.22353, mean: -0.88940
[32m[0907 14-20-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31421, current rewards: -1778.17363, mean: -0.88466
[32m[0907 14-20-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31428, current rewards: -1815.16263, mean: -0.88115
[32m[0907 14-20-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31436, current rewards: -1853.90864, mean: -0.87863
[32m[0907 14-21-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31447, current rewards: -1907.85503, mean: -0.88327
[32m[0907 14-21-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31420, current rewards: -1901.39620, mean: -0.86036
[32m[0907 14-21-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31384, current rewards: -1894.93737, mean: -0.83847
[32m[0907 14-21-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31349, current rewards: -1888.47854, mean: -0.81752
[32m[0907 14-22-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31317, current rewards: -1883.93468, mean: -0.79828
[32m[0907 14-22-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31288, current rewards: -1879.98072, mean: -0.78007
[32m[0907 14-22-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31258, current rewards: -1876.10221, mean: -0.76264
[32m[0907 14-22-48 @Agent.py:117][0m Average action selection time: 0.3124
[32m[0907 14-22-48 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-22-48 @MBExp.py:227][0m Rewards obtained: [-1872.975311960114], Lows: [60], Highs: [1813], Total time: 79912.48686200002
[32m[0907 14-25-50 @MBExp.py:144][0m ####################################################################
[32m[0907 14-25-50 @MBExp.py:145][0m Starting training iteration 98.
[32m[0907 14-25-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30766, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-26-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31740, current rewards: -75.89194, mean: -1.26487
[32m[0907 14-26-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31589, current rewards: -125.89194, mean: -1.14447
[32m[0907 14-26-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31598, current rewards: -175.89194, mean: -1.09932
[32m[0907 14-26-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31589, current rewards: -225.89194, mean: -1.07568
[32m[0907 14-27-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31553, current rewards: -275.89194, mean: -1.06112
[32m[0907 14-27-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31552, current rewards: -325.89194, mean: -1.05126
[32m[0907 14-27-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31548, current rewards: -375.89194, mean: -1.04414
[32m[0907 14-27-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31539, current rewards: -425.89194, mean: -1.03876
[32m[0907 14-28-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31532, current rewards: -475.89194, mean: -1.03455
[32m[0907 14-28-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31523, current rewards: -525.89194, mean: -1.03116
[32m[0907 14-28-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31518, current rewards: -575.89194, mean: -1.02838
[32m[0907 14-29-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31520, current rewards: -625.89194, mean: -1.02605
[32m[0907 14-29-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31518, current rewards: -675.89194, mean: -1.02408
[32m[0907 14-29-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31514, current rewards: -725.89194, mean: -1.02238
[32m[0907 14-29-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31509, current rewards: -775.89194, mean: -1.02091
[32m[0907 14-30-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31510, current rewards: -825.89194, mean: -1.01962
[32m[0907 14-30-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31511, current rewards: -875.89194, mean: -1.01848
[32m[0907 14-30-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31507, current rewards: -925.89194, mean: -1.01746
[32m[0907 14-30-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31501, current rewards: -975.89194, mean: -1.01655
[32m[0907 14-31-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31496, current rewards: -1025.89194, mean: -1.01573
[32m[0907 14-31-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31489, current rewards: -1075.89194, mean: -1.01499
[32m[0907 14-31-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31484, current rewards: -1125.89194, mean: -1.01432
[32m[0907 14-31-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31479, current rewards: -1175.89194, mean: -1.01370
[32m[0907 14-32-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31476, current rewards: -1225.89194, mean: -1.01313
[32m[0907 14-32-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31458, current rewards: -1275.89194, mean: -1.01261
[32m[0907 14-32-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31431, current rewards: -1325.89194, mean: -1.01213
[32m[0907 14-32-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31404, current rewards: -1375.89194, mean: -1.01169
[32m[0907 14-33-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31380, current rewards: -1425.89194, mean: -1.01127
[32m[0907 14-33-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31356, current rewards: -1475.89194, mean: -1.01088
[32m[0907 14-33-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31335, current rewards: -1525.89194, mean: -1.01052
[32m[0907 14-33-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31314, current rewards: -1575.89194, mean: -1.01019
[32m[0907 14-34-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31297, current rewards: -1625.89194, mean: -1.00987
[32m[0907 14-34-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31280, current rewards: -1675.89194, mean: -1.00957
[32m[0907 14-34-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31264, current rewards: -1725.89194, mean: -1.00929
[32m[0907 14-35-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31249, current rewards: -1775.89194, mean: -1.00903
[32m[0907 14-35-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31233, current rewards: -1825.89194, mean: -1.00878
[32m[0907 14-35-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31228, current rewards: -1875.89194, mean: -1.00854
[32m[0907 14-35-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31239, current rewards: -1925.89194, mean: -1.00832
[32m[0907 14-36-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31247, current rewards: -1975.89194, mean: -1.00811
[32m[0907 14-36-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31252, current rewards: -2025.89194, mean: -1.00791
[32m[0907 14-36-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31259, current rewards: -2075.89194, mean: -1.00771
[32m[0907 14-36-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31265, current rewards: -2125.89194, mean: -1.00753
[32m[0907 14-37-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31272, current rewards: -2175.89194, mean: -1.00736
[32m[0907 14-37-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31256, current rewards: -2225.89194, mean: -1.00719
[32m[0907 14-37-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31225, current rewards: -2275.89194, mean: -1.00703
[32m[0907 14-37-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31195, current rewards: -2325.89194, mean: -1.00688
[32m[0907 14-38-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31167, current rewards: -2375.89194, mean: -1.00673
[32m[0907 14-38-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31139, current rewards: -2425.89194, mean: -1.00659
[32m[0907 14-38-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31113, current rewards: -2475.89194, mean: -1.00646
[32m[0907 14-38-48 @Agent.py:117][0m Average action selection time: 0.3109
[32m[0907 14-38-48 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-38-48 @MBExp.py:227][0m Rewards obtained: [-2515.891942809296], Lows: [17], Highs: [2482], Total time: 80690.59675500002
[32m[0907 14-41-51 @MBExp.py:144][0m ####################################################################
[32m[0907 14-41-51 @MBExp.py:145][0m Starting training iteration 99.
[32m[0907 14-41-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34943, current rewards: 0.61793, mean: 0.06179
[32m[0907 14-42-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31606, current rewards: -7.82025, mean: -0.13034
[32m[0907 14-42-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31629, current rewards: -3.77871, mean: -0.03435
[32m[0907 14-42-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31614, current rewards: 0.26283, mean: 0.00164
[32m[0907 14-42-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31612, current rewards: 4.30436, mean: 0.02050
[32m[0907 14-43-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31582, current rewards: 9.26582, mean: 0.03564
[32m[0907 14-43-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31579, current rewards: 14.82897, mean: 0.04784
[32m[0907 14-43-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31567, current rewards: 20.39212, mean: 0.05664
[32m[0907 14-44-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31569, current rewards: 25.95526, mean: 0.06331
[32m[0907 14-44-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31561, current rewards: 31.51841, mean: 0.06852
[32m[0907 14-44-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31552, current rewards: 37.08156, mean: 0.07271
[32m[0907 14-44-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31546, current rewards: -11.80718, mean: -0.02108
[32m[0907 14-45-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31542, current rewards: -61.80718, mean: -0.10132
[32m[0907 14-45-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31538, current rewards: -111.80718, mean: -0.16940
[32m[0907 14-45-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31533, current rewards: -161.80718, mean: -0.22790
[32m[0907 14-45-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31530, current rewards: -211.80718, mean: -0.27869
[32m[0907 14-46-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31529, current rewards: -261.80718, mean: -0.32322
[32m[0907 14-46-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31528, current rewards: -311.80718, mean: -0.36257
[32m[0907 14-46-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31527, current rewards: -361.80718, mean: -0.39759
[32m[0907 14-46-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31528, current rewards: -411.80718, mean: -0.42897
[32m[0907 14-47-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31529, current rewards: -461.80718, mean: -0.45723
[32m[0907 14-47-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31526, current rewards: -511.80718, mean: -0.48284
[32m[0907 14-47-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31529, current rewards: -561.80718, mean: -0.50613
[32m[0907 14-47-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31525, current rewards: -611.80718, mean: -0.52742
[32m[0907 14-48-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31527, current rewards: -661.80718, mean: -0.54695
[32m[0907 14-48-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31506, current rewards: -711.80718, mean: -0.56493
[32m[0907 14-48-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31482, current rewards: -761.80718, mean: -0.58153
[32m[0907 14-48-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31459, current rewards: -811.80718, mean: -0.59692
[32m[0907 14-49-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31437, current rewards: -861.80718, mean: -0.61121
[32m[0907 14-49-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31416, current rewards: -911.80718, mean: -0.62453
[32m[0907 14-49-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31398, current rewards: -961.80718, mean: -0.63696
[32m[0907 14-50-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31381, current rewards: -1011.80718, mean: -0.64859
[32m[0907 14-50-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31365, current rewards: -1061.80718, mean: -0.65951
[32m[0907 14-50-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31349, current rewards: -1111.80718, mean: -0.66976
[32m[0907 14-50-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31333, current rewards: -1161.80718, mean: -0.67942
[32m[0907 14-51-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31318, current rewards: -1211.80718, mean: -0.68853
[32m[0907 14-51-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31304, current rewards: -1261.80718, mean: -0.69713
[32m[0907 14-51-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31302, current rewards: -1311.80718, mean: -0.70527
[32m[0907 14-51-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31308, current rewards: -1361.80718, mean: -0.71299
[32m[0907 14-52-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31317, current rewards: -1411.80718, mean: -0.72031
[32m[0907 14-52-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31321, current rewards: -1461.80718, mean: -0.72727
[32m[0907 14-52-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31328, current rewards: -1511.80718, mean: -0.73389
[32m[0907 14-52-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31335, current rewards: -1561.80718, mean: -0.74019
[32m[0907 14-53-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31343, current rewards: -1611.80718, mean: -0.74621
[32m[0907 14-53-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31337, current rewards: -1661.80718, mean: -0.75195
[32m[0907 14-53-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31327, current rewards: -1711.80718, mean: -0.75744
[32m[0907 14-53-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31315, current rewards: -1761.80718, mean: -0.76269
[32m[0907 14-54-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31287, current rewards: -1811.80718, mean: -0.76771
[32m[0907 14-54-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31259, current rewards: -1861.80718, mean: -0.77253
[32m[0907 14-54-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31231, current rewards: -1911.80718, mean: -0.77716
[32m[0907 14-54-52 @Agent.py:117][0m Average action selection time: 0.3121
[32m[0907 14-54-52 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-54-52 @MBExp.py:227][0m Rewards obtained: [-1951.8071778414494], Lows: [6], Highs: [1989], Total time: 81471.63142600002
[32m[0907 14-57-58 @MBExp.py:144][0m ####################################################################
[32m[0907 14-57-58 @MBExp.py:145][0m Starting training iteration 100.
[32m[0907 14-58-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.51429, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-58-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.51795, current rewards: -79.96061, mean: -1.33268
[32m[0907 14-58-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.48817, current rewards: -179.96061, mean: -1.63601
[32m[0907 14-59-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.43428, current rewards: -279.96061, mean: -1.74975
[32m[0907 14-59-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.40616, current rewards: -379.96061, mean: -1.80934
[32m[0907 14-59-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.38878, current rewards: -479.96061, mean: -1.84600
[32m[0907 14-59-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37698, current rewards: -579.96061, mean: -1.87084
[32m[0907 15-00-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36840, current rewards: -679.96061, mean: -1.88878
[32m[0907 15-00-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36195, current rewards: -779.96061, mean: -1.90234
[32m[0907 15-00-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35680, current rewards: -879.96061, mean: -1.91296
[32m[0907 15-00-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35268, current rewards: -979.96061, mean: -1.92149
[32m[0907 15-01-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34931, current rewards: -1079.96061, mean: -1.92850
[32m[0907 15-01-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34649, current rewards: -1179.96061, mean: -1.93436
[32m[0907 15-01-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34415, current rewards: -1279.96061, mean: -1.93933
[32m[0907 15-02-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34199, current rewards: -1379.96061, mean: -1.94361
[32m[0907 15-02-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34019, current rewards: -1479.96061, mean: -1.94732
[32m[0907 15-02-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33858, current rewards: -1579.96061, mean: -1.95057
[32m[0907 15-02-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33726, current rewards: -1679.96061, mean: -1.95344
[32m[0907 15-03-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33602, current rewards: -1779.96061, mean: -1.95600
[32m[0907 15-03-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33491, current rewards: -1879.96061, mean: -1.95829
[32m[0907 15-03-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33387, current rewards: -1979.96061, mean: -1.96036
[32m[0907 15-03-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33297, current rewards: -2079.96061, mean: -1.96223
[32m[0907 15-04-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33216, current rewards: -2179.96061, mean: -1.96393
[32m[0907 15-04-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33127, current rewards: -2279.96061, mean: -1.96548
[32m[0907 15-04-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33028, current rewards: -2379.96061, mean: -1.96691
[32m[0907 15-04-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32936, current rewards: -2479.96061, mean: -1.96822
[32m[0907 15-05-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32856, current rewards: -2579.96061, mean: -1.96944
[32m[0907 15-05-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32778, current rewards: -2679.96061, mean: -1.97056
[32m[0907 15-05-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32706, current rewards: -2779.96061, mean: -1.97160
[32m[0907 15-05-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32639, current rewards: -2879.96061, mean: -1.97258
[32m[0907 15-06-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32576, current rewards: -2979.96061, mean: -1.97348
[32m[0907 15-06-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32517, current rewards: -3079.96061, mean: -1.97433
[32m[0907 15-06-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32462, current rewards: -3179.96061, mean: -1.97513
[32m[0907 15-06-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32409, current rewards: -3279.96061, mean: -1.97588
[32m[0907 15-07-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32360, current rewards: -3379.96061, mean: -1.97659
[32m[0907 15-07-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32312, current rewards: -3479.96061, mean: -1.97725
[32m[0907 15-07-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32288, current rewards: -3579.96061, mean: -1.97788
[32m[0907 15-07-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32268, current rewards: -3679.96061, mean: -1.97847
[32m[0907 15-08-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32248, current rewards: -3779.96061, mean: -1.97904
[32m[0907 15-08-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32227, current rewards: -3879.96061, mean: -1.97957
[32m[0907 15-08-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32207, current rewards: -3979.96061, mean: -1.98008
[32m[0907 15-09-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32187, current rewards: -4079.96061, mean: -1.98056
[32m[0907 15-09-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32170, current rewards: -4179.96061, mean: -1.98102
[32m[0907 15-09-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32139, current rewards: -4279.96061, mean: -1.98146
[32m[0907 15-09-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32109, current rewards: -4379.96061, mean: -1.98188
[32m[0907 15-10-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32077, current rewards: -4479.96061, mean: -1.98228
[32m[0907 15-10-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32038, current rewards: -4579.96061, mean: -1.98267
[32m[0907 15-10-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31993, current rewards: -4679.96061, mean: -1.98303
[32m[0907 15-10-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31948, current rewards: -4779.96061, mean: -1.98339
[32m[0907 15-11-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31907, current rewards: -4879.96061, mean: -1.98372
[32m[0907 15-11-15 @Agent.py:117][0m Average action selection time: 0.3187
[32m[0907 15-11-15 @Agent.py:118][0m Rollout length: 2520
[32m[0907 15-11-15 @MBExp.py:227][0m Rewards obtained: [-4959.960612584391], Lows: [2472], Highs: [20], Total time: 82269.23852200003
[32m[0907 15-14-21 @MBExp.py:144][0m ####################################################################
[32m[0907 15-14-21 @MBExp.py:145][0m Starting training iteration 101.
[32m[0907 15-14-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33290, current rewards: -10.00000, mean: -1.00000
[32m[0907 15-14-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32671, current rewards: -94.34998, mean: -1.57250
[32m[0907 15-14-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32152, current rewards: -194.34998, mean: -1.76682
[32m[0907 15-15-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31933, current rewards: -294.34998, mean: -1.83969
[32m[0907 15-15-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31853, current rewards: -394.34998, mean: -1.87786
[32m[0907 15-15-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31795, current rewards: -494.34998, mean: -1.90135
[32m[0907 15-16-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31766, current rewards: -594.34998, mean: -1.91726
[32m[0907 15-16-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31727, current rewards: -694.34998, mean: -1.92875
[32m[0907 15-16-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31790, current rewards: -784.29463, mean: -1.91291
[32m[0907 15-16-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31982, current rewards: -870.74693, mean: -1.89293
[32m[0907 15-17-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31922, current rewards: -970.74693, mean: -1.90343
[32m[0907 15-17-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31889, current rewards: -1070.74693, mean: -1.91205
[32m[0907 15-17-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31852, current rewards: -1170.74693, mean: -1.91926
[32m[0907 15-17-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31819, current rewards: -1270.74693, mean: -1.92537
[32m[0907 15-18-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31787, current rewards: -1370.74693, mean: -1.93063
[32m[0907 15-18-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31765, current rewards: -1470.74693, mean: -1.93519
[32m[0907 15-18-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31749, current rewards: -1570.74693, mean: -1.93919
[32m[0907 15-18-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31732, current rewards: -1670.74693, mean: -1.94273
[32m[0907 15-19-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31718, current rewards: -1770.74693, mean: -1.94588
[32m[0907 15-19-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31698, current rewards: -1870.74693, mean: -1.94869
[32m[0907 15-19-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31683, current rewards: -1970.74693, mean: -1.95123
[32m[0907 15-19-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31670, current rewards: -2070.74693, mean: -1.95353
[32m[0907 15-20-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31658, current rewards: -2170.74693, mean: -1.95563
[32m[0907 15-20-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31625, current rewards: -2270.74693, mean: -1.95754
[32m[0907 15-20-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31584, current rewards: -2370.74693, mean: -1.95929
[32m[0907 15-20-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31549, current rewards: -2470.74693, mean: -1.96091
[32m[0907 15-21-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31518, current rewards: -2570.74693, mean: -1.96240
[32m[0907 15-21-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31488, current rewards: -2670.74693, mean: -1.96378
[32m[0907 15-21-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31461, current rewards: -2770.74693, mean: -1.96507
[32m[0907 15-22-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31434, current rewards: -2870.74693, mean: -1.96627
[32m[0907 15-22-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31407, current rewards: -2970.74693, mean: -1.96738
[32m[0907 15-22-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31386, current rewards: -3070.74693, mean: -1.96843
[32m[0907 15-22-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31366, current rewards: -3170.74693, mean: -1.96941
[32m[0907 15-23-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31349, current rewards: -3270.74693, mean: -1.97033
[32m[0907 15-23-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31331, current rewards: -3370.74693, mean: -1.97120
[32m[0907 15-23-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31317, current rewards: -3470.74693, mean: -1.97202
[32m[0907 15-23-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31323, current rewards: -3570.74693, mean: -1.97279
[32m[0907 15-24-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31327, current rewards: -3670.74693, mean: -1.97352
[32m[0907 15-24-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31333, current rewards: -3770.74693, mean: -1.97421
[32m[0907 15-24-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31337, current rewards: -3870.74693, mean: -1.97487
[32m[0907 15-24-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31341, current rewards: -3970.74693, mean: -1.97550
[32m[0907 15-25-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31341, current rewards: -4070.74693, mean: -1.97609
[32m[0907 15-25-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31345, current rewards: -4170.74693, mean: -1.97666
[32m[0907 15-25-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31336, current rewards: -4270.74693, mean: -1.97720
[32m[0907 15-25-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31322, current rewards: -4370.74693, mean: -1.97771
[32m[0907 15-26-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31309, current rewards: -4470.74693, mean: -1.97821
[32m[0907 15-26-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31284, current rewards: -4570.74693, mean: -1.97868
[32m[0907 15-26-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31255, current rewards: -4670.74693, mean: -1.97913
[32m[0907 15-26-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31223, current rewards: -4770.74693, mean: -1.97956
[32m[0907 15-27-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31196, current rewards: -4870.74693, mean: -1.97998
[32m[0907 15-27-21 @Agent.py:117][0m Average action selection time: 0.3118
[32m[0907 15-27-21 @Agent.py:118][0m Rollout length: 2520
[32m[0907 15-27-22 @MBExp.py:227][0m Rewards obtained: [-4950.746929821678], Lows: [2462], Highs: [29], Total time: 83049.39208600002
[32m[0907 15-30-31 @MBExp.py:144][0m ####################################################################
[32m[0907 15-30-31 @MBExp.py:145][0m Starting training iteration 102.
[32m[0907 15-30-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32741, current rewards: -10.00000, mean: -1.00000
[32m[0907 15-30-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32436, current rewards: -60.00000, mean: -1.00000
[32m[0907 15-31-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32734, current rewards: -110.00000, mean: -1.00000
[32m[0907 15-31-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32333, current rewards: -160.00000, mean: -1.00000
[32m[0907 15-31-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32137, current rewards: -210.00000, mean: -1.00000
[32m[0907 15-31-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32008, current rewards: -260.00000, mean: -1.00000
[32m[0907 15-32-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31935, current rewards: -310.00000, mean: -1.00000
[32m[0907 15-32-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31873, current rewards: -360.00000, mean: -1.00000
[32m[0907 15-32-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31898, current rewards: -410.00000, mean: -1.00000
[32m[0907 15-32-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32256, current rewards: -460.00000, mean: -1.00000
[32m[0907 15-33-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32549, current rewards: -510.00000, mean: -1.00000
[32m[0907 15-33-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32781, current rewards: -560.00000, mean: -1.00000
[32m[0907 15-33-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32975, current rewards: -610.00000, mean: -1.00000
[32m[0907 15-34-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33153, current rewards: -660.00000, mean: -1.00000
[32m[0907 15-34-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33291, current rewards: -710.00000, mean: -1.00000
[32m[0907 15-34-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33426, current rewards: -760.00000, mean: -1.00000
[32m[0907 15-35-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33545, current rewards: -810.00000, mean: -1.00000
[32m[0907 15-35-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33668, current rewards: -860.00000, mean: -1.00000
[32m[0907 15-35-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33801, current rewards: -910.00000, mean: -1.00000
[32m[0907 15-35-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33875, current rewards: -960.00000, mean: -1.00000
[32m[0907 15-36-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33955, current rewards: -1010.00000, mean: -1.00000
[32m[0907 15-36-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34012, current rewards: -1060.00000, mean: -1.00000
[32m[0907 15-36-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34063, current rewards: -1110.00000, mean: -1.00000
[32m[0907 15-37-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34083, current rewards: -1160.00000, mean: -1.00000
[32m[0907 15-37-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34095, current rewards: -1210.00000, mean: -1.00000
[32m[0907 15-37-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34105, current rewards: -1260.00000, mean: -1.00000
[32m[0907 15-37-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34117, current rewards: -1310.00000, mean: -1.00000
[32m[0907 15-38-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34129, current rewards: -1360.00000, mean: -1.00000
[32m[0907 15-38-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34136, current rewards: -1410.00000, mean: -1.00000
[32m[0907 15-38-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34146, current rewards: -1460.00000, mean: -1.00000
[32m[0907 15-39-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34154, current rewards: -1510.00000, mean: -1.00000
[32m[0907 15-39-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34162, current rewards: -1560.00000, mean: -1.00000
[32m[0907 15-39-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34171, current rewards: -1610.00000, mean: -1.00000
[32m[0907 15-39-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34176, current rewards: -1660.00000, mean: -1.00000
[32m[0907 15-40-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34182, current rewards: -1710.00000, mean: -1.00000
[32m[0907 15-40-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34196, current rewards: -1760.00000, mean: -1.00000
[32m[0907 15-40-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34227, current rewards: -1810.00000, mean: -1.00000
[32m[0907 15-41-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34258, current rewards: -1860.00000, mean: -1.00000
[32m[0907 15-41-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34284, current rewards: -1910.00000, mean: -1.00000
[32m[0907 15-41-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34309, current rewards: -1960.00000, mean: -1.00000
[32m[0907 15-42-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34332, current rewards: -2010.00000, mean: -1.00000
[32m[0907 15-42-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34354, current rewards: -2060.00000, mean: -1.00000
[32m[0907 15-42-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34374, current rewards: -2110.00000, mean: -1.00000
[32m[0907 15-42-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34375, current rewards: -2160.00000, mean: -1.00000
[32m[0907 15-43-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34374, current rewards: -2210.00000, mean: -1.00000
[32m[0907 15-43-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34372, current rewards: -2215.59230, mean: -0.98035
[32m[0907 15-43-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34376, current rewards: -2212.59391, mean: -0.95783
[32m[0907 15-44-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34387, current rewards: -2209.59552, mean: -0.93627
[32m[0907 15-44-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34401, current rewards: -2206.59713, mean: -0.91560
[32m[0907 15-44-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34403, current rewards: -2212.07848, mean: -0.89922
[32m[0907 15-44-51 @Agent.py:117][0m Average action selection time: 0.3440
[32m[0907 15-44-51 @Agent.py:118][0m Rollout length: 2520
[32m[0907 15-44-51 @MBExp.py:227][0m Rewards obtained: [-2252.0784830036746], Lows: [0], Highs: [2267], Total time: 83910.19429300002
[32m[0907 15-48-37 @MBExp.py:144][0m ####################################################################
[32m[0907 15-48-37 @MBExp.py:145][0m Starting training iteration 103.
[32m[0907 15-48-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.41277, current rewards: -10.00000, mean: -1.00000
[32m[0907 15-49-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37309, current rewards: -57.71949, mean: -0.96199
[32m[0907 15-49-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36923, current rewards: -107.71949, mean: -0.97927
[32m[0907 15-49-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36763, current rewards: -157.71949, mean: -0.98575
[32m[0907 15-49-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36670, current rewards: -207.71949, mean: -0.98914
[32m[0907 15-50-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36640, current rewards: -257.71949, mean: -0.99123
[32m[0907 15-50-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36631, current rewards: -307.71949, mean: -0.99264
[32m[0907 15-50-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36612, current rewards: -357.71949, mean: -0.99367
[32m[0907 15-51-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36595, current rewards: -407.71949, mean: -0.99444
[32m[0907 15-51-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36578, current rewards: -457.71949, mean: -0.99504
[32m[0907 15-51-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36563, current rewards: -507.71949, mean: -0.99553
[32m[0907 15-52-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36545, current rewards: -557.71949, mean: -0.99593
[32m[0907 15-52-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36523, current rewards: -607.71949, mean: -0.99626
[32m[0907 15-52-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36514, current rewards: -657.71949, mean: -0.99654
[32m[0907 15-52-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36503, current rewards: -707.71949, mean: -0.99679
[32m[0907 15-53-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36492, current rewards: -757.71949, mean: -0.99700
[32m[0907 15-53-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36479, current rewards: -807.71949, mean: -0.99718
[32m[0907 15-53-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36467, current rewards: -857.71949, mean: -0.99735
[32m[0907 15-54-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36456, current rewards: -907.71949, mean: -0.99749
[32m[0907 15-54-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36449, current rewards: -957.71949, mean: -0.99762
[32m[0907 15-54-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36442, current rewards: -1007.71949, mean: -0.99774
[32m[0907 15-55-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36437, current rewards: -1057.71949, mean: -0.99785
[32m[0907 15-55-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36419, current rewards: -1107.71949, mean: -0.99795
[32m[0907 15-55-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36386, current rewards: -1157.71949, mean: -0.99803
[32m[0907 15-55-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36350, current rewards: -1207.71949, mean: -0.99812
[32m[0907 15-56-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36321, current rewards: -1257.71949, mean: -0.99819
[32m[0907 15-56-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36294, current rewards: -1307.71949, mean: -0.99826
[32m[0907 15-56-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36265, current rewards: -1357.71949, mean: -0.99832
[32m[0907 15-57-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36237, current rewards: -1407.71949, mean: -0.99838
[32m[0907 15-57-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36213, current rewards: -1457.71949, mean: -0.99844
[32m[0907 15-57-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36190, current rewards: -1507.71949, mean: -0.99849
[32m[0907 15-58-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36170, current rewards: -1557.71949, mean: -0.99854
[32m[0907 15-58-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36149, current rewards: -1607.71949, mean: -0.99858
[32m[0907 15-58-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36131, current rewards: -1657.71949, mean: -0.99863
[32m[0907 15-58-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36112, current rewards: -1707.71949, mean: -0.99867
[32m[0907 15-59-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36104, current rewards: -1757.71949, mean: -0.99870
[32m[0907 15-59-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36114, current rewards: -1807.71949, mean: -0.99874
[32m[0907 15-59-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36122, current rewards: -1857.71949, mean: -0.99877
[32m[0907 16-00-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36130, current rewards: -1907.71949, mean: -0.99881
[32m[0907 16-00-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36138, current rewards: -1957.71949, mean: -0.99884
[32m[0907 16-00-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36142, current rewards: -2007.71949, mean: -0.99887
[32m[0907 16-01-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36144, current rewards: -2057.71949, mean: -0.99889
[32m[0907 16-01-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36142, current rewards: -2107.71949, mean: -0.99892
[32m[0907 16-01-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36131, current rewards: -2157.71949, mean: -0.99894
[32m[0907 16-01-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36117, current rewards: -2177.52384, mean: -0.98530
[32m[0907 16-02-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36104, current rewards: -2172.06413, mean: -0.96109
[32m[0907 16-02-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36092, current rewards: -2214.68721, mean: -0.95874
[32m[0907 16-02-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36080, current rewards: -2264.68721, mean: -0.95961
[32m[0907 16-03-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36067, current rewards: -2314.68721, mean: -0.96045
[32m[0907 16-03-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36050, current rewards: -2364.68721, mean: -0.96125
[32m[0907 16-03-39 @Agent.py:117][0m Average action selection time: 0.3603
[32m[0907 16-03-39 @Agent.py:118][0m Rollout length: 2520
[32m[0907 16-03-39 @MBExp.py:227][0m Rewards obtained: [-2404.6872054030614], Lows: [0], Highs: [2414], Total time: 84811.76830300002
[32m[0907 16-07-28 @MBExp.py:144][0m ####################################################################
[32m[0907 16-07-28 @MBExp.py:145][0m Starting training iteration 104.
[32m[0907 16-07-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35924, current rewards: -1.55528, mean: -0.15553
[32m[0907 16-07-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36324, current rewards: -43.01056, mean: -0.71684
[32m[0907 16-08-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36315, current rewards: -93.01056, mean: -0.84555
[32m[0907 16-08-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36339, current rewards: -143.01056, mean: -0.89382
[32m[0907 16-08-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36371, current rewards: -178.22215, mean: -0.84868
[32m[0907 16-09-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36354, current rewards: -175.28528, mean: -0.67417
[32m[0907 16-09-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36442, current rewards: -192.14928, mean: -0.61984
[32m[0907 16-09-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36493, current rewards: -188.68420, mean: -0.52412
[32m[0907 16-09-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36531, current rewards: -203.87390, mean: -0.49725
[32m[0907 16-10-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36908, current rewards: -237.99708, mean: -0.51738
[32m[0907 16-10-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36859, current rewards: -287.99708, mean: -0.56470
[32m[0907 16-10-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36814, current rewards: -337.99708, mean: -0.60357
[32m[0907 16-11-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36773, current rewards: -387.99708, mean: -0.63606
[32m[0907 16-11-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36739, current rewards: -437.99708, mean: -0.66363
[32m[0907 16-11-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36703, current rewards: -487.99708, mean: -0.68732
[32m[0907 16-12-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36681, current rewards: -537.99708, mean: -0.70789
[32m[0907 16-12-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36659, current rewards: -587.99708, mean: -0.72592
[32m[0907 16-12-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36639, current rewards: -637.99708, mean: -0.74186
[32m[0907 16-13-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36619, current rewards: -687.99708, mean: -0.75604
[32m[0907 16-13-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36605, current rewards: -737.99708, mean: -0.76875
[32m[0907 16-13-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36588, current rewards: -787.99708, mean: -0.78020
[32m[0907 16-13-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36565, current rewards: -837.99708, mean: -0.79056
[32m[0907 16-14-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36519, current rewards: -887.99708, mean: -0.80000
[32m[0907 16-14-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36476, current rewards: -937.99708, mean: -0.80862
[32m[0907 16-14-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36434, current rewards: -987.99708, mean: -0.81653
[32m[0907 16-15-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36394, current rewards: -1037.99708, mean: -0.82381
[32m[0907 16-15-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36360, current rewards: -1087.99708, mean: -0.83053
[32m[0907 16-15-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36330, current rewards: -1137.99708, mean: -0.83676
[32m[0907 16-16-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36300, current rewards: -1187.99708, mean: -0.84255
[32m[0907 16-16-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36275, current rewards: -1237.99708, mean: -0.84794
[32m[0907 16-16-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36250, current rewards: -1287.99708, mean: -0.85298
[32m[0907 16-16-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36226, current rewards: -1337.99708, mean: -0.85769
[32m[0907 16-17-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36202, current rewards: -1387.99708, mean: -0.86211
[32m[0907 16-17-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36180, current rewards: -1437.99708, mean: -0.86626
[32m[0907 16-17-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36156, current rewards: -1487.99708, mean: -0.87017
[32m[0907 16-18-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36164, current rewards: -1537.99708, mean: -0.87386
[32m[0907 16-18-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36168, current rewards: -1587.99708, mean: -0.87735
[32m[0907 16-18-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36177, current rewards: -1637.99708, mean: -0.88064
[32m[0907 16-19-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36181, current rewards: -1687.99708, mean: -0.88377
[32m[0907 16-19-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36187, current rewards: -1737.99708, mean: -0.88673
[32m[0907 16-19-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36190, current rewards: -1787.99708, mean: -0.88955
[32m[0907 16-19-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36196, current rewards: -1837.99708, mean: -0.89223
[32m[0907 16-20-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36199, current rewards: -1887.99708, mean: -0.89479
[32m[0907 16-20-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36196, current rewards: -1937.99708, mean: -0.89722
[32m[0907 16-20-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36196, current rewards: -1987.99708, mean: -0.89955
[32m[0907 16-21-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36194, current rewards: -2037.99708, mean: -0.90177
[32m[0907 16-21-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36193, current rewards: -2087.99708, mean: -0.90389
[32m[0907 16-21-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36190, current rewards: -2137.99708, mean: -0.90593
[32m[0907 16-22-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36190, current rewards: -2187.99708, mean: -0.90788
[32m[0907 16-22-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36179, current rewards: -2237.99708, mean: -0.90975
[32m[0907 16-22-33 @Agent.py:117][0m Average action selection time: 0.3616
[32m[0907 16-22-33 @Agent.py:118][0m Rollout length: 2520
[32m[0907 16-22-33 @MBExp.py:227][0m Rewards obtained: [-2277.9970768709513], Lows: [25], Highs: [2255], Total time: 85716.72058600002
[32m[0907 16-26-29 @MBExp.py:144][0m ####################################################################
[32m[0907 16-26-29 @MBExp.py:145][0m Starting training iteration 105.
[32m[0907 16-26-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.37282, current rewards: -10.00000, mean: -1.00000
[32m[0907 16-26-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37181, current rewards: -58.94717, mean: -0.98245
[32m[0907 16-27-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37191, current rewards: -108.94717, mean: -0.99043
[32m[0907 16-27-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37169, current rewards: -158.94717, mean: -0.99342
[32m[0907 16-27-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37183, current rewards: -208.94717, mean: -0.99499
[32m[0907 16-28-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37173, current rewards: -258.94717, mean: -0.99595
[32m[0907 16-28-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37168, current rewards: -290.03725, mean: -0.93560
[32m[0907 16-28-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37137, current rewards: -287.50968, mean: -0.79864
[32m[0907 16-29-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37119, current rewards: -284.98212, mean: -0.69508
[32m[0907 16-29-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37110, current rewards: -282.45455, mean: -0.61403
[32m[0907 16-29-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37091, current rewards: -279.92698, mean: -0.54888
[32m[0907 16-29-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37079, current rewards: -277.39942, mean: -0.49536
[32m[0907 16-30-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37074, current rewards: -274.87185, mean: -0.45061
[32m[0907 16-30-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37072, current rewards: -314.36805, mean: -0.47632
[32m[0907 16-30-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37064, current rewards: -364.36805, mean: -0.51319
[32m[0907 16-31-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37058, current rewards: -414.36805, mean: -0.54522
[32m[0907 16-31-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37052, current rewards: -464.36805, mean: -0.57329
[32m[0907 16-31-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37058, current rewards: -514.36805, mean: -0.59810
[32m[0907 16-32-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37057, current rewards: -564.36805, mean: -0.62018
[32m[0907 16-32-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37048, current rewards: -614.36805, mean: -0.63997
[32m[0907 16-32-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37047, current rewards: -664.36805, mean: -0.65779
[32m[0907 16-33-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37044, current rewards: -714.36805, mean: -0.67393
[32m[0907 16-33-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37030, current rewards: -764.36805, mean: -0.68862
[32m[0907 16-33-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36993, current rewards: -814.36805, mean: -0.70204
[32m[0907 16-33-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36959, current rewards: -864.36805, mean: -0.71435
[32m[0907 16-34-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36925, current rewards: -914.36805, mean: -0.72569
[32m[0907 16-34-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36895, current rewards: -964.36805, mean: -0.73616
[32m[0907 16-34-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36871, current rewards: -1014.36805, mean: -0.74586
[32m[0907 16-35-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36846, current rewards: -1064.36805, mean: -0.75487
[32m[0907 16-35-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36826, current rewards: -1114.36805, mean: -0.76327
[32m[0907 16-35-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36806, current rewards: -1164.36805, mean: -0.77110
[32m[0907 16-36-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36787, current rewards: -1214.36805, mean: -0.77844
[32m[0907 16-36-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36769, current rewards: -1264.36805, mean: -0.78532
[32m[0907 16-36-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36748, current rewards: -1314.36805, mean: -0.79179
[32m[0907 16-36-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36729, current rewards: -1364.36805, mean: -0.79788
[32m[0907 16-37-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36712, current rewards: -1414.36805, mean: -0.80362
[32m[0907 16-37-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36716, current rewards: -1464.36805, mean: -0.80904
[32m[0907 16-37-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36721, current rewards: -1514.36805, mean: -0.81418
[32m[0907 16-38-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36725, current rewards: -1564.36805, mean: -0.81904
[32m[0907 16-38-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36732, current rewards: -1614.36805, mean: -0.82366
[32m[0907 16-38-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36740, current rewards: -1664.36805, mean: -0.82804
[32m[0907 16-39-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36743, current rewards: -1714.36805, mean: -0.83222
[32m[0907 16-39-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36736, current rewards: -1764.36805, mean: -0.83619
[32m[0907 16-39-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36720, current rewards: -1814.36805, mean: -0.83999
[32m[0907 16-40-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36706, current rewards: -1864.36805, mean: -0.84361
[32m[0907 16-40-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36694, current rewards: -1914.36805, mean: -0.84707
[32m[0907 16-40-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36681, current rewards: -1964.36805, mean: -0.85038
[32m[0907 16-40-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36669, current rewards: -2014.36805, mean: -0.85355
[32m[0907 16-41-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36658, current rewards: -2064.36805, mean: -0.85658
[32m[0907 16-41-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36646, current rewards: -2114.36805, mean: -0.85950
[32m[0907 16-41-46 @Agent.py:117][0m Average action selection time: 0.3663
[32m[0907 16-41-46 @Agent.py:118][0m Rollout length: 2520
[32m[0907 16-41-46 @MBExp.py:227][0m Rewards obtained: [-2154.3680466371507], Lows: [0], Highs: [2171], Total time: 86633.29777900003
[32m[0907 16-45-45 @MBExp.py:144][0m ####################################################################
[32m[0907 16-45-45 @MBExp.py:145][0m Starting training iteration 106.
[32m[0907 16-45-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.37799, current rewards: 0.68005, mean: 0.06800
[32m[0907 16-46-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37123, current rewards: -5.78600, mean: -0.09643
[32m[0907 16-46-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36997, current rewards: 0.67283, mean: 0.00612
[32m[0907 16-46-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36984, current rewards: 7.13166, mean: 0.04457
[32m[0907 16-47-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36978, current rewards: 13.52431, mean: 0.06440
[32m[0907 16-47-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36969, current rewards: 19.56958, mean: 0.07527
[32m[0907 16-47-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36947, current rewards: 25.61484, mean: 0.08263
[32m[0907 16-47-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36936, current rewards: 31.66011, mean: 0.08794
[32m[0907 16-48-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36926, current rewards: 37.70537, mean: 0.09196
[32m[0907 16-48-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36921, current rewards: 43.75064, mean: 0.09511
[32m[0907 16-48-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36912, current rewards: 36.34504, mean: 0.07126
[32m[0907 16-49-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36902, current rewards: -13.65496, mean: -0.02438
[32m[0907 16-49-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36904, current rewards: -63.65496, mean: -0.10435
[32m[0907 16-49-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36907, current rewards: -113.65496, mean: -0.17220
[32m[0907 16-50-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36910, current rewards: -163.65496, mean: -0.23050
[32m[0907 16-50-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36913, current rewards: -213.65496, mean: -0.28112
[32m[0907 16-50-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36911, current rewards: -263.65496, mean: -0.32550
[32m[0907 16-51-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36906, current rewards: -313.65496, mean: -0.36472
[32m[0907 16-51-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36907, current rewards: -363.65496, mean: -0.39962
[32m[0907 16-51-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36911, current rewards: -413.65496, mean: -0.43089
[32m[0907 16-51-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36907, current rewards: -463.65496, mean: -0.45906
[32m[0907 16-52-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36906, current rewards: -513.65496, mean: -0.48458
[32m[0907 16-52-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36883, current rewards: -563.65496, mean: -0.50780
[32m[0907 16-52-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36854, current rewards: -613.65496, mean: -0.52901
[32m[0907 16-53-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36827, current rewards: -663.65496, mean: -0.54848
[32m[0907 16-53-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36796, current rewards: -713.65496, mean: -0.56639
[32m[0907 16-53-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36772, current rewards: -763.65496, mean: -0.58294
[32m[0907 16-54-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36749, current rewards: -813.65496, mean: -0.59828
[32m[0907 16-54-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36729, current rewards: -863.65496, mean: -0.61252
[32m[0907 16-54-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36709, current rewards: -913.65496, mean: -0.62579
[32m[0907 16-54-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36690, current rewards: -963.65496, mean: -0.63818
[32m[0907 16-55-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36671, current rewards: -1013.65496, mean: -0.64978
[32m[0907 16-55-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36654, current rewards: -1063.65496, mean: -0.66066
[32m[0907 16-55-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36635, current rewards: -1113.65496, mean: -0.67088
[32m[0907 16-56-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36620, current rewards: -1163.65496, mean: -0.68050
[32m[0907 16-56-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36608, current rewards: -1213.65496, mean: -0.68958
[32m[0907 16-56-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36616, current rewards: -1263.65496, mean: -0.69815
[32m[0907 16-57-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36625, current rewards: -1313.65496, mean: -0.70627
[32m[0907 16-57-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36633, current rewards: -1363.65496, mean: -0.71396
[32m[0907 16-57-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36641, current rewards: -1413.65496, mean: -0.72125
[32m[0907 16-58-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36649, current rewards: -1463.65496, mean: -0.72819
[32m[0907 16-58-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36654, current rewards: -1513.65496, mean: -0.73478
[32m[0907 16-58-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36642, current rewards: -1563.65496, mean: -0.74107
[32m[0907 16-58-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36631, current rewards: -1613.65496, mean: -0.74706
[32m[0907 16-59-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36617, current rewards: -1663.65496, mean: -0.75279
[32m[0907 16-59-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36606, current rewards: -1713.65496, mean: -0.75825
[32m[0907 16-59-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36594, current rewards: -1763.65496, mean: -0.76349
[32m[0907 17-00-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36583, current rewards: -1813.65496, mean: -0.76850
[32m[0907 17-00-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36572, current rewards: -1863.65496, mean: -0.77330
[32m[0907 17-00-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36561, current rewards: -1913.65496, mean: -0.77791
[32m[0907 17-00-59 @Agent.py:117][0m Average action selection time: 0.3655
[32m[0907 17-00-59 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-01-00 @MBExp.py:227][0m Rewards obtained: [-1953.6549582370933], Lows: [6], Highs: [2002], Total time: 87547.80360000003
[32m[0907 17-05-00 @MBExp.py:144][0m ####################################################################
[32m[0907 17-05-00 @MBExp.py:145][0m Starting training iteration 107.
[32m[0907 17-05-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36823, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-05-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37161, current rewards: -60.00000, mean: -1.00000
[32m[0907 17-05-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37112, current rewards: -110.00000, mean: -1.00000
[32m[0907 17-06-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37115, current rewards: -160.00000, mean: -1.00000
[32m[0907 17-06-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37097, current rewards: -210.00000, mean: -1.00000
[32m[0907 17-06-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37115, current rewards: -260.00000, mean: -1.00000
[32m[0907 17-06-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37118, current rewards: -310.00000, mean: -1.00000
[32m[0907 17-07-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37099, current rewards: -360.00000, mean: -1.00000
[32m[0907 17-07-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37096, current rewards: -410.00000, mean: -1.00000
[32m[0907 17-07-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37099, current rewards: -460.00000, mean: -1.00000
[32m[0907 17-08-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37097, current rewards: -510.00000, mean: -1.00000
[32m[0907 17-08-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37092, current rewards: -560.00000, mean: -1.00000
[32m[0907 17-08-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37090, current rewards: -610.00000, mean: -1.00000
[32m[0907 17-09-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37085, current rewards: -660.00000, mean: -1.00000
[32m[0907 17-09-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37082, current rewards: -710.00000, mean: -1.00000
[32m[0907 17-09-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37067, current rewards: -760.00000, mean: -1.00000
[32m[0907 17-10-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37064, current rewards: -810.00000, mean: -1.00000
[32m[0907 17-10-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37065, current rewards: -860.00000, mean: -1.00000
[32m[0907 17-10-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37055, current rewards: -910.00000, mean: -1.00000
[32m[0907 17-10-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37053, current rewards: -960.00000, mean: -1.00000
[32m[0907 17-11-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37048, current rewards: -1008.99535, mean: -0.99901
[32m[0907 17-11-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37236, current rewards: -1055.68893, mean: -0.99593
[32m[0907 17-11-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37236, current rewards: -1100.10247, mean: -0.99108
[32m[0907 17-12-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37223, current rewards: -1150.10247, mean: -0.99147
[32m[0907 17-12-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37207, current rewards: -1200.10247, mean: -0.99182
[32m[0907 17-12-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37190, current rewards: -1250.10247, mean: -0.99214
[32m[0907 17-13-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37180, current rewards: -1300.10247, mean: -0.99244
[32m[0907 17-13-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37168, current rewards: -1350.10247, mean: -0.99272
[32m[0907 17-13-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.37133, current rewards: -1400.10247, mean: -0.99298
[32m[0907 17-14-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.37097, current rewards: -1450.10247, mean: -0.99322
[32m[0907 17-14-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.37065, current rewards: -1500.10247, mean: -0.99345
[32m[0907 17-14-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.37035, current rewards: -1550.10247, mean: -0.99366
[32m[0907 17-14-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.37005, current rewards: -1600.10247, mean: -0.99385
[32m[0907 17-15-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36976, current rewards: -1650.10247, mean: -0.99404
[32m[0907 17-15-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36951, current rewards: -1700.10247, mean: -0.99421
[32m[0907 17-15-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36923, current rewards: -1750.10247, mean: -0.99438
[32m[0907 17-16-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36902, current rewards: -1800.10247, mean: -0.99453
[32m[0907 17-16-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36880, current rewards: -1798.64097, mean: -0.96701
[32m[0907 17-16-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36858, current rewards: -1793.07782, mean: -0.93878
[32m[0907 17-17-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36838, current rewards: -1787.51467, mean: -0.91200
[32m[0907 17-17-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36818, current rewards: -1781.95153, mean: -0.88654
[32m[0907 17-17-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36801, current rewards: -1808.61501, mean: -0.87797
[32m[0907 17-17-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36783, current rewards: -1858.61501, mean: -0.88086
[32m[0907 17-18-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36767, current rewards: -1908.61501, mean: -0.88362
[32m[0907 17-18-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36753, current rewards: -1958.61501, mean: -0.88625
[32m[0907 17-18-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36739, current rewards: -2008.61501, mean: -0.88877
[32m[0907 17-19-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36727, current rewards: -2058.61501, mean: -0.89118
[32m[0907 17-19-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36713, current rewards: -2108.61501, mean: -0.89348
[32m[0907 17-19-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36701, current rewards: -2158.61501, mean: -0.89569
[32m[0907 17-20-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36691, current rewards: -2208.61501, mean: -0.89781
[32m[0907 17-20-18 @Agent.py:117][0m Average action selection time: 0.3667
[32m[0907 17-20-18 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-20-18 @MBExp.py:227][0m Rewards obtained: [-2248.6150051367913], Lows: [6], Highs: [2262], Total time: 88465.41663300003
[32m[0907 17-24-21 @MBExp.py:144][0m ####################################################################
[32m[0907 17-24-21 @MBExp.py:145][0m Starting training iteration 108.
[32m[0907 17-24-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.37049, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-24-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37074, current rewards: -100.00000, mean: -1.66667
[32m[0907 17-25-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37056, current rewards: -200.00000, mean: -1.81818
[32m[0907 17-25-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37035, current rewards: -300.00000, mean: -1.87500
[32m[0907 17-25-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37030, current rewards: -400.00000, mean: -1.90476
[32m[0907 17-25-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37023, current rewards: -500.00000, mean: -1.92308
[32m[0907 17-26-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37027, current rewards: -600.00000, mean: -1.93548
[32m[0907 17-26-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37018, current rewards: -700.00000, mean: -1.94444
[32m[0907 17-26-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37009, current rewards: -800.00000, mean: -1.95122
[32m[0907 17-27-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37005, current rewards: -900.00000, mean: -1.95652
[32m[0907 17-27-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37005, current rewards: -1000.00000, mean: -1.96078
[32m[0907 17-27-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36997, current rewards: -1100.00000, mean: -1.96429
[32m[0907 17-28-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36993, current rewards: -1200.00000, mean: -1.96721
[32m[0907 17-28-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36986, current rewards: -1300.00000, mean: -1.96970
[32m[0907 17-28-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36986, current rewards: -1400.00000, mean: -1.97183
[32m[0907 17-29-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36985, current rewards: -1500.00000, mean: -1.97368
[32m[0907 17-29-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36985, current rewards: -1600.00000, mean: -1.97531
[32m[0907 17-29-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36978, current rewards: -1700.00000, mean: -1.97674
[32m[0907 17-29-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36971, current rewards: -1800.00000, mean: -1.97802
[32m[0907 17-30-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36969, current rewards: -1900.00000, mean: -1.97917
[32m[0907 17-30-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36971, current rewards: -2000.00000, mean: -1.98020
[32m[0907 17-30-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36970, current rewards: -2100.00000, mean: -1.98113
[32m[0907 17-31-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36962, current rewards: -2200.00000, mean: -1.98198
[32m[0907 17-31-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36962, current rewards: -2300.00000, mean: -1.98276
[32m[0907 17-31-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36959, current rewards: -2400.00000, mean: -1.98347
[32m[0907 17-32-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36957, current rewards: -2500.00000, mean: -1.98413
[32m[0907 17-32-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36955, current rewards: -2600.00000, mean: -1.98473
[32m[0907 17-32-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36952, current rewards: -2700.00000, mean: -1.98529
[32m[0907 17-33-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36919, current rewards: -2800.00000, mean: -1.98582
[32m[0907 17-33-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36888, current rewards: -2900.00000, mean: -1.98630
[32m[0907 17-33-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36861, current rewards: -3000.00000, mean: -1.98675
[32m[0907 17-33-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36837, current rewards: -3100.00000, mean: -1.98718
[32m[0907 17-34-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36812, current rewards: -3200.00000, mean: -1.98758
[32m[0907 17-34-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36788, current rewards: -3300.00000, mean: -1.98795
[32m[0907 17-34-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36768, current rewards: -3400.00000, mean: -1.98830
[32m[0907 17-35-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36748, current rewards: -3500.00000, mean: -1.98864
[32m[0907 17-35-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36727, current rewards: -3600.00000, mean: -1.98895
[32m[0907 17-35-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36709, current rewards: -3700.00000, mean: -1.98925
[32m[0907 17-36-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36692, current rewards: -3800.00000, mean: -1.98953
[32m[0907 17-36-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36675, current rewards: -3900.00000, mean: -1.98980
[32m[0907 17-36-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36661, current rewards: -4000.00000, mean: -1.99005
[32m[0907 17-36-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36648, current rewards: -4100.00000, mean: -1.99029
[32m[0907 17-37-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36647, current rewards: -4200.00000, mean: -1.99052
[32m[0907 17-37-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36635, current rewards: -4300.00000, mean: -1.99074
[32m[0907 17-37-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36622, current rewards: -4400.00000, mean: -1.99095
[32m[0907 17-38-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36609, current rewards: -4500.00000, mean: -1.99115
[32m[0907 17-38-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36599, current rewards: -4600.00000, mean: -1.99134
[32m[0907 17-38-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36588, current rewards: -4700.00000, mean: -1.99153
[32m[0907 17-39-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36576, current rewards: -4800.00000, mean: -1.99170
[32m[0907 17-39-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36567, current rewards: -4900.00000, mean: -1.99187
[32m[0907 17-39-36 @Agent.py:117][0m Average action selection time: 0.3655
[32m[0907 17-39-36 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-39-36 @MBExp.py:227][0m Rewards obtained: [-4980], Lows: [2480], Highs: [20], Total time: 89380.00298900003
[32m[0907 17-43-41 @MBExp.py:144][0m ####################################################################
[32m[0907 17-43-41 @MBExp.py:145][0m Starting training iteration 109.
[32m[0907 17-43-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.39880, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-44-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37594, current rewards: -97.93196, mean: -1.63220
[32m[0907 17-44-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37339, current rewards: -197.93196, mean: -1.79938
[32m[0907 17-44-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37219, current rewards: -297.93196, mean: -1.86207
[32m[0907 17-44-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37196, current rewards: -397.93196, mean: -1.89491
[32m[0907 17-45-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37160, current rewards: -497.93196, mean: -1.91512
[32m[0907 17-45-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37125, current rewards: -597.93196, mean: -1.92881
[32m[0907 17-45-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37103, current rewards: -697.93196, mean: -1.93870
[32m[0907 17-46-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37092, current rewards: -797.93196, mean: -1.94618
[32m[0907 17-46-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37115, current rewards: -895.75673, mean: -1.94730
[32m[0907 17-46-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37120, current rewards: -945.75673, mean: -1.85442
[32m[0907 17-47-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37110, current rewards: -995.75673, mean: -1.77814
[32m[0907 17-47-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37098, current rewards: -1045.75673, mean: -1.71436
[32m[0907 17-47-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37088, current rewards: -1095.75673, mean: -1.66024
[32m[0907 17-48-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37077, current rewards: -1145.75673, mean: -1.61374
[32m[0907 17-48-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37066, current rewards: -1195.75673, mean: -1.57336
[32m[0907 17-48-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37059, current rewards: -1245.75673, mean: -1.53797
[32m[0907 17-49-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37052, current rewards: -1295.75673, mean: -1.50669
[32m[0907 17-49-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37038, current rewards: -1345.75673, mean: -1.47885
[32m[0907 17-49-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37032, current rewards: -1395.75673, mean: -1.45391
[32m[0907 17-49-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37029, current rewards: -1445.75673, mean: -1.43144
[32m[0907 17-50-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37027, current rewards: -1495.75673, mean: -1.41109
[32m[0907 17-50-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37026, current rewards: -1545.75673, mean: -1.39257
[32m[0907 17-50-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37024, current rewards: -1595.75673, mean: -1.37565
[32m[0907 17-51-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37018, current rewards: -1645.75673, mean: -1.36013
[32m[0907 17-51-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37019, current rewards: -1679.55606, mean: -1.33298
[32m[0907 17-51-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37015, current rewards: -1671.69652, mean: -1.27610
[32m[0907 17-52-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37009, current rewards: -1664.71622, mean: -1.22406
[32m[0907 17-52-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36978, current rewards: -1661.71049, mean: -1.17852
[32m[0907 17-52-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36952, current rewards: -1658.71210, mean: -1.13610
[32m[0907 17-52-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36924, current rewards: -1655.71371, mean: -1.09650
[32m[0907 17-53-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36898, current rewards: -1652.71532, mean: -1.05943
[32m[0907 17-53-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36875, current rewards: -1649.71693, mean: -1.02467
[32m[0907 17-53-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36852, current rewards: -1646.71854, mean: -0.99200
[32m[0907 17-54-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36830, current rewards: -1643.72015, mean: -0.96124
[32m[0907 17-54-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36809, current rewards: -1640.72176, mean: -0.93223
[32m[0907 17-54-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36790, current rewards: -1636.81139, mean: -0.90432
[32m[0907 17-55-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36775, current rewards: -1653.30564, mean: -0.88887
[32m[0907 17-55-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36760, current rewards: -1703.30564, mean: -0.89178
[32m[0907 17-55-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36743, current rewards: -1753.30564, mean: -0.89454
[32m[0907 17-56-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36731, current rewards: -1803.30564, mean: -0.89717
[32m[0907 17-56-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36723, current rewards: -1853.30564, mean: -0.89966
[32m[0907 17-56-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36714, current rewards: -1903.30564, mean: -0.90204
[32m[0907 17-56-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36703, current rewards: -1953.30564, mean: -0.90431
[32m[0907 17-57-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36688, current rewards: -2003.30564, mean: -0.90647
[32m[0907 17-57-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36675, current rewards: -2053.30564, mean: -0.90854
[32m[0907 17-57-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36664, current rewards: -2103.30564, mean: -0.91052
[32m[0907 17-58-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36655, current rewards: -2153.30564, mean: -0.91242
[32m[0907 17-58-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36645, current rewards: -2203.30564, mean: -0.91423
[32m[0907 17-58-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36635, current rewards: -2253.30564, mean: -0.91598
[32m[0907 17-58-57 @Agent.py:117][0m Average action selection time: 0.3663
[32m[0907 17-58-57 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-58-58 @MBExp.py:227][0m Rewards obtained: [-2293.305636114973], Lows: [438], Highs: [1465], Total time: 90296.56662300004
[32m[0907 18-03-06 @MBExp.py:144][0m ####################################################################
[32m[0907 18-03-06 @MBExp.py:145][0m Starting training iteration 110.
[32m[0907 18-03-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36376, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-03-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36896, current rewards: -60.00000, mean: -1.00000
[32m[0907 18-03-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37022, current rewards: -110.00000, mean: -1.00000
[32m[0907 18-04-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37052, current rewards: -160.00000, mean: -1.00000
[32m[0907 18-04-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37055, current rewards: -210.00000, mean: -1.00000
[32m[0907 18-04-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37071, current rewards: -260.00000, mean: -1.00000
[32m[0907 18-05-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37084, current rewards: -310.00000, mean: -1.00000
[32m[0907 18-05-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37073, current rewards: -360.00000, mean: -1.00000
[32m[0907 18-05-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37069, current rewards: -410.00000, mean: -1.00000
[32m[0907 18-05-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37060, current rewards: -460.00000, mean: -1.00000
[32m[0907 18-06-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37045, current rewards: -510.00000, mean: -1.00000
[32m[0907 18-06-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37028, current rewards: -560.00000, mean: -1.00000
[32m[0907 18-06-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37026, current rewards: -610.00000, mean: -1.00000
[32m[0907 18-07-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37020, current rewards: -660.00000, mean: -1.00000
[32m[0907 18-07-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37016, current rewards: -710.00000, mean: -1.00000
[32m[0907 18-07-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37014, current rewards: -760.00000, mean: -1.00000
[32m[0907 18-08-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37015, current rewards: -810.00000, mean: -1.00000
[32m[0907 18-08-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37012, current rewards: -860.00000, mean: -1.00000
[32m[0907 18-08-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37010, current rewards: -910.00000, mean: -1.00000
[32m[0907 18-09-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37004, current rewards: -960.00000, mean: -1.00000
[32m[0907 18-09-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36999, current rewards: -1010.00000, mean: -1.00000
[32m[0907 18-09-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36995, current rewards: -1060.00000, mean: -1.00000
[32m[0907 18-09-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36997, current rewards: -1110.00000, mean: -1.00000
[32m[0907 18-10-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36997, current rewards: -1160.00000, mean: -1.00000
[32m[0907 18-10-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36990, current rewards: -1210.00000, mean: -1.00000
[32m[0907 18-10-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36987, current rewards: -1260.00000, mean: -1.00000
[32m[0907 18-11-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36984, current rewards: -1310.00000, mean: -1.00000
[32m[0907 18-11-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36958, current rewards: -1360.00000, mean: -1.00000
[32m[0907 18-11-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36928, current rewards: -1410.00000, mean: -1.00000
[32m[0907 18-12-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36899, current rewards: -1460.00000, mean: -1.00000
[32m[0907 18-12-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36875, current rewards: -1510.00000, mean: -1.00000
[32m[0907 18-12-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36851, current rewards: -1560.00000, mean: -1.00000
[32m[0907 18-12-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36830, current rewards: -1610.00000, mean: -1.00000
[32m[0907 18-13-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36810, current rewards: -1660.00000, mean: -1.00000
[32m[0907 18-13-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36791, current rewards: -1710.00000, mean: -1.00000
[32m[0907 18-13-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36773, current rewards: -1760.00000, mean: -1.00000
[32m[0907 18-14-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36756, current rewards: -1810.00000, mean: -1.00000
[32m[0907 18-14-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36744, current rewards: -1860.00000, mean: -1.00000
[32m[0907 18-14-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36730, current rewards: -1910.00000, mean: -1.00000
[32m[0907 18-15-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36718, current rewards: -1960.00000, mean: -1.00000
[32m[0907 18-15-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36705, current rewards: -2010.00000, mean: -1.00000
[32m[0907 18-15-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36709, current rewards: -2060.00000, mean: -1.00000
[32m[0907 18-16-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36694, current rewards: -2110.00000, mean: -1.00000
[32m[0907 18-16-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36683, current rewards: -2160.00000, mean: -1.00000
[32m[0907 18-16-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36670, current rewards: -2210.00000, mean: -1.00000
[32m[0907 18-16-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36657, current rewards: -2260.00000, mean: -1.00000
[32m[0907 18-17-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36645, current rewards: -2310.00000, mean: -1.00000
[32m[0907 18-17-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36633, current rewards: -2360.00000, mean: -1.00000
[32m[0907 18-17-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36622, current rewards: -2410.00000, mean: -1.00000
[32m[0907 18-18-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36613, current rewards: -2460.00000, mean: -1.00000
[32m[0907 18-18-21 @Agent.py:117][0m Average action selection time: 0.3660
[32m[0907 18-18-21 @Agent.py:118][0m Rollout length: 2520
[32m[0907 18-18-22 @MBExp.py:227][0m Rewards obtained: [-2500], Lows: [0], Highs: [2500], Total time: 91212.55632300004
[32m[0907 18-22-32 @MBExp.py:144][0m ####################################################################
[32m[0907 18-22-32 @MBExp.py:145][0m Starting training iteration 111.
[32m[0907 18-22-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.38426, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-22-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37807, current rewards: -81.74244, mean: -1.36237
[32m[0907 18-23-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37452, current rewards: -155.39850, mean: -1.41271
[32m[0907 18-23-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37318, current rewards: -216.23455, mean: -1.35147
[32m[0907 18-23-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37663, current rewards: -280.17978, mean: -1.33419
[32m[0907 18-24-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37536, current rewards: -348.83854, mean: -1.34169
[32m[0907 18-24-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37439, current rewards: -399.08690, mean: -1.28738
[32m[0907 18-24-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37381, current rewards: -436.36960, mean: -1.21214
[32m[0907 18-25-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37333, current rewards: -460.21039, mean: -1.12246
[32m[0907 18-25-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37282, current rewards: -489.12850, mean: -1.06332
[32m[0907 18-25-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37243, current rewards: -558.23673, mean: -1.09458
[32m[0907 18-26-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37213, current rewards: -609.23673, mean: -1.08792
[32m[0907 18-26-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37213, current rewards: -669.26561, mean: -1.09716
[32m[0907 18-26-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37191, current rewards: -726.26561, mean: -1.10040
[32m[0907 18-26-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37168, current rewards: -789.43294, mean: -1.11188
[32m[0907 18-27-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37155, current rewards: -841.36732, mean: -1.10706
[32m[0907 18-27-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37141, current rewards: -880.61170, mean: -1.08717
[32m[0907 18-27-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37125, current rewards: -958.42617, mean: -1.11445
[32m[0907 18-28-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37110, current rewards: -995.32201, mean: -1.09376
[32m[0907 18-28-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37108, current rewards: -1067.58475, mean: -1.11207
[32m[0907 18-28-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37121, current rewards: -1129.50454, mean: -1.11832
[32m[0907 18-29-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37109, current rewards: -1221.50454, mean: -1.15236
[32m[0907 18-29-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37098, current rewards: -1271.50454, mean: -1.14550
[32m[0907 18-29-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37088, current rewards: -1321.50454, mean: -1.13923
[32m[0907 18-30-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37076, current rewards: -1371.50454, mean: -1.13347
[32m[0907 18-30-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37068, current rewards: -1421.50454, mean: -1.12818
[32m[0907 18-30-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37053, current rewards: -1471.50454, mean: -1.12329
[32m[0907 18-30-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37016, current rewards: -1521.50454, mean: -1.11875
[32m[0907 18-31-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36984, current rewards: -1583.33012, mean: -1.12293
[32m[0907 18-31-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36952, current rewards: -1630.10207, mean: -1.11651
[32m[0907 18-31-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36924, current rewards: -1703.92832, mean: -1.12843
[32m[0907 18-32-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36897, current rewards: -1760.30345, mean: -1.12840
[32m[0907 18-32-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36874, current rewards: -1830.99170, mean: -1.13726
[32m[0907 18-32-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36853, current rewards: -1907.27109, mean: -1.14896
[32m[0907 18-33-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36834, current rewards: -1990.63841, mean: -1.16412
[32m[0907 18-33-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36813, current rewards: -2084.55869, mean: -1.18441
[32m[0907 18-33-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36795, current rewards: -2156.55869, mean: -1.19147
[32m[0907 18-33-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36776, current rewards: -2206.55869, mean: -1.18632
[32m[0907 18-34-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36757, current rewards: -2256.55869, mean: -1.18144
[32m[0907 18-34-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36739, current rewards: -2306.55869, mean: -1.17682
[32m[0907 18-34-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36720, current rewards: -2356.55869, mean: -1.17242
[32m[0907 18-35-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36712, current rewards: -2406.55869, mean: -1.16823
[32m[0907 18-35-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36690, current rewards: -2456.55869, mean: -1.16425
[32m[0907 18-35-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36668, current rewards: -2506.55869, mean: -1.16044
[32m[0907 18-36-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36645, current rewards: -2556.55869, mean: -1.15681
[32m[0907 18-36-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36622, current rewards: -2606.55869, mean: -1.15334
[32m[0907 18-36-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36601, current rewards: -2656.55869, mean: -1.15003
[32m[0907 18-36-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36579, current rewards: -2697.77082, mean: -1.14312
[32m[0907 18-37-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36557, current rewards: -2789.77082, mean: -1.15758
[32m[0907 18-37-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36536, current rewards: -2849.11558, mean: -1.15818
[32m[0907 18-37-45 @Agent.py:117][0m Average action selection time: 0.3652
[32m[0907 18-37-45 @Agent.py:118][0m Rollout length: 2520
[32m[0907 18-37-45 @MBExp.py:227][0m Rewards obtained: [-2884.8063653828754], Lows: [735], Highs: [1462], Total time: 92126.33134500004
[32m[0907 18-41-52 @MBExp.py:144][0m ####################################################################
[32m[0907 18-41-52 @MBExp.py:145][0m Starting training iteration 112.
[32m[0907 18-41-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35569, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-42-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36286, current rewards: -100.00000, mean: -1.66667
[32m[0907 18-42-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36296, current rewards: -200.00000, mean: -1.81818
[32m[0907 18-42-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36328, current rewards: -300.00000, mean: -1.87500
[32m[0907 18-43-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36315, current rewards: -400.00000, mean: -1.90476
[32m[0907 18-43-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36288, current rewards: -500.00000, mean: -1.92308
[32m[0907 18-43-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36293, current rewards: -600.00000, mean: -1.93548
[32m[0907 18-44-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36279, current rewards: -700.00000, mean: -1.94444
[32m[0907 18-44-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36259, current rewards: -800.00000, mean: -1.95122
[32m[0907 18-44-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36250, current rewards: -900.00000, mean: -1.95652
[32m[0907 18-44-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36252, current rewards: -1000.00000, mean: -1.96078
[32m[0907 18-45-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36249, current rewards: -1100.00000, mean: -1.96429
[32m[0907 18-45-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36243, current rewards: -1200.00000, mean: -1.96721
[32m[0907 18-45-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36241, current rewards: -1300.00000, mean: -1.96970
[32m[0907 18-46-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36246, current rewards: -1400.00000, mean: -1.97183
[32m[0907 18-46-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36237, current rewards: -1500.00000, mean: -1.97368
[32m[0907 18-46-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36232, current rewards: -1600.00000, mean: -1.97531
[32m[0907 18-47-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36228, current rewards: -1700.00000, mean: -1.97674
[32m[0907 18-47-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36224, current rewards: -1800.00000, mean: -1.97802
[32m[0907 18-47-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36218, current rewards: -1900.00000, mean: -1.97917
[32m[0907 18-47-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36215, current rewards: -2000.00000, mean: -1.98020
[32m[0907 18-48-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36214, current rewards: -2100.00000, mean: -1.98113
[32m[0907 18-48-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36207, current rewards: -2200.00000, mean: -1.98198
[32m[0907 18-48-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36202, current rewards: -2300.00000, mean: -1.98276
[32m[0907 18-49-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36199, current rewards: -2400.00000, mean: -1.98347
[32m[0907 18-49-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36197, current rewards: -2500.00000, mean: -1.98413
[32m[0907 18-49-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36175, current rewards: -2600.00000, mean: -1.98473
[32m[0907 18-50-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36151, current rewards: -2700.00000, mean: -1.98529
[32m[0907 18-50-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36123, current rewards: -2800.00000, mean: -1.98582
[32m[0907 18-50-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36098, current rewards: -2900.00000, mean: -1.98630
[32m[0907 18-50-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36078, current rewards: -3000.00000, mean: -1.98675
[32m[0907 18-51-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36054, current rewards: -3100.00000, mean: -1.98718
[32m[0907 18-51-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36036, current rewards: -3200.00000, mean: -1.98758
[32m[0907 18-51-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36016, current rewards: -3300.00000, mean: -1.98795
[32m[0907 18-52-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35998, current rewards: -3400.00000, mean: -1.98830
[32m[0907 18-52-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35981, current rewards: -3500.00000, mean: -1.98864
[32m[0907 18-52-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35966, current rewards: -3600.00000, mean: -1.98895
[32m[0907 18-53-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35952, current rewards: -3700.00000, mean: -1.98925
[32m[0907 18-53-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35939, current rewards: -3800.00000, mean: -1.98953
[32m[0907 18-53-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35926, current rewards: -3900.00000, mean: -1.98980
[32m[0907 18-53-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35928, current rewards: -4000.00000, mean: -1.99005
[32m[0907 18-54-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35920, current rewards: -4100.00000, mean: -1.99029
[32m[0907 18-54-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35909, current rewards: -4200.00000, mean: -1.99052
[32m[0907 18-54-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35897, current rewards: -4300.00000, mean: -1.99074
[32m[0907 18-55-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35888, current rewards: -4400.00000, mean: -1.99095
[32m[0907 18-55-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35877, current rewards: -4500.00000, mean: -1.99115
[32m[0907 18-55-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35867, current rewards: -4600.00000, mean: -1.99134
[32m[0907 18-55-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35858, current rewards: -4700.00000, mean: -1.99153
[32m[0907 18-56-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35851, current rewards: -4800.00000, mean: -1.99170
[32m[0907 18-56-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35842, current rewards: -4900.00000, mean: -1.99187
[32m[0907 18-56-49 @Agent.py:117][0m Average action selection time: 0.3583
[32m[0907 18-56-49 @Agent.py:118][0m Rollout length: 2520
[32m[0907 18-56-49 @MBExp.py:227][0m Rewards obtained: [-4980], Lows: [2480], Highs: [20], Total time: 93023.01270800004
[32m[0907 19-00-58 @MBExp.py:144][0m ####################################################################
[32m[0907 19-00-58 @MBExp.py:145][0m Starting training iteration 113.
[32m[0907 19-01-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35612, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-01-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36199, current rewards: -97.00000, mean: -1.61667
[32m[0907 19-01-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36223, current rewards: -197.00000, mean: -1.79091
[32m[0907 19-01-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36258, current rewards: -297.00000, mean: -1.85625
[32m[0907 19-02-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36264, current rewards: -397.00000, mean: -1.89048
[32m[0907 19-02-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36284, current rewards: -497.00000, mean: -1.91154
[32m[0907 19-02-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36292, current rewards: -597.00000, mean: -1.92581
[32m[0907 19-03-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36288, current rewards: -697.00000, mean: -1.93611
[32m[0907 19-03-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36288, current rewards: -797.00000, mean: -1.94390
[32m[0907 19-03-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36282, current rewards: -897.00000, mean: -1.95000
[32m[0907 19-04-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36276, current rewards: -997.00000, mean: -1.95490
[32m[0907 19-04-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36281, current rewards: -1097.00000, mean: -1.95893
[32m[0907 19-04-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36281, current rewards: -1197.00000, mean: -1.96230
[32m[0907 19-04-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36274, current rewards: -1297.00000, mean: -1.96515
[32m[0907 19-05-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36268, current rewards: -1397.00000, mean: -1.96761
[32m[0907 19-05-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36267, current rewards: -1497.00000, mean: -1.96974
[32m[0907 19-05-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36268, current rewards: -1597.00000, mean: -1.97160
[32m[0907 19-06-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36262, current rewards: -1697.00000, mean: -1.97326
[32m[0907 19-06-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36257, current rewards: -1797.00000, mean: -1.97473
[32m[0907 19-06-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36260, current rewards: -1897.00000, mean: -1.97604
[32m[0907 19-07-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36258, current rewards: -1997.00000, mean: -1.97723
[32m[0907 19-07-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36249, current rewards: -2097.00000, mean: -1.97830
[32m[0907 19-07-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36249, current rewards: -2197.00000, mean: -1.97928
[32m[0907 19-07-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36247, current rewards: -2297.00000, mean: -1.98017
[32m[0907 19-08-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36244, current rewards: -2397.00000, mean: -1.98099
[32m[0907 19-08-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36229, current rewards: -2497.00000, mean: -1.98175
[32m[0907 19-08-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36200, current rewards: -2597.00000, mean: -1.98244
[32m[0907 19-09-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36177, current rewards: -2697.00000, mean: -1.98309
[32m[0907 19-09-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36152, current rewards: -2797.00000, mean: -1.98369
[32m[0907 19-09-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36130, current rewards: -2897.00000, mean: -1.98425
[32m[0907 19-10-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36108, current rewards: -2997.00000, mean: -1.98477
[32m[0907 19-10-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36088, current rewards: -3097.00000, mean: -1.98526
[32m[0907 19-10-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36071, current rewards: -3197.00000, mean: -1.98571
[32m[0907 19-10-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36053, current rewards: -3297.00000, mean: -1.98614
[32m[0907 19-11-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36036, current rewards: -3397.00000, mean: -1.98655
[32m[0907 19-11-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36020, current rewards: -3497.00000, mean: -1.98693
[32m[0907 19-11-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36004, current rewards: -3597.00000, mean: -1.98729
[32m[0907 19-12-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35990, current rewards: -3697.00000, mean: -1.98763
[32m[0907 19-12-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35978, current rewards: -3797.00000, mean: -1.98796
[32m[0907 19-12-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35966, current rewards: -3897.00000, mean: -1.98827
[32m[0907 19-13-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35977, current rewards: -3997.00000, mean: -1.98856
[32m[0907 19-13-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35976, current rewards: -4097.00000, mean: -1.98883
[32m[0907 19-13-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35957, current rewards: -4197.00000, mean: -1.98910
[32m[0907 19-13-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35937, current rewards: -4297.00000, mean: -1.98935
[32m[0907 19-14-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35916, current rewards: -4397.00000, mean: -1.98959
[32m[0907 19-14-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35881, current rewards: -4497.00000, mean: -1.98982
[32m[0907 19-14-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35848, current rewards: -4597.00000, mean: -1.99004
[32m[0907 19-15-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35815, current rewards: -4697.00000, mean: -1.99025
[32m[0907 19-15-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35783, current rewards: -4797.00000, mean: -1.99046
[32m[0907 19-15-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35752, current rewards: -4897.00000, mean: -1.99065
[32m[0907 19-15-51 @Agent.py:117][0m Average action selection time: 0.3573
[32m[0907 19-15-51 @Agent.py:118][0m Rollout length: 2520
[32m[0907 19-15-52 @MBExp.py:227][0m Rewards obtained: [-4977], Lows: [2477], Highs: [23], Total time: 93917.12793500004
[32m[0907 19-19-41 @MBExp.py:144][0m ####################################################################
[32m[0907 19-19-41 @MBExp.py:145][0m Starting training iteration 114.
[32m[0907 19-19-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35461, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-20-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35359, current rewards: -60.00000, mean: -1.00000
[32m[0907 19-20-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35288, current rewards: -110.00000, mean: -1.00000
[32m[0907 19-20-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35317, current rewards: -160.00000, mean: -1.00000
[32m[0907 19-20-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35349, current rewards: -210.00000, mean: -1.00000
[32m[0907 19-21-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35334, current rewards: -260.00000, mean: -1.00000
[32m[0907 19-21-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35308, current rewards: -310.00000, mean: -1.00000
[32m[0907 19-21-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35293, current rewards: -360.00000, mean: -1.00000
[32m[0907 19-22-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35295, current rewards: -410.00000, mean: -1.00000
[32m[0907 19-22-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35280, current rewards: -460.00000, mean: -1.00000
[32m[0907 19-22-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35267, current rewards: -510.00000, mean: -1.00000
[32m[0907 19-22-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35264, current rewards: -560.00000, mean: -1.00000
[32m[0907 19-23-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35261, current rewards: -610.00000, mean: -1.00000
[32m[0907 19-23-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35253, current rewards: -641.34396, mean: -0.97173
[32m[0907 19-23-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35253, current rewards: -633.04384, mean: -0.89161
[32m[0907 19-24-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35250, current rewards: -624.74372, mean: -0.82203
[32m[0907 19-24-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35250, current rewards: -616.44360, mean: -0.76104
[32m[0907 19-24-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35244, current rewards: -608.14348, mean: -0.70714
[32m[0907 19-25-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35238, current rewards: -627.54351, mean: -0.68961
[32m[0907 19-25-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35238, current rewards: -677.54351, mean: -0.70577
[32m[0907 19-25-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35232, current rewards: -727.54351, mean: -0.72034
[32m[0907 19-25-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35220, current rewards: -777.54351, mean: -0.73353
[32m[0907 19-26-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35216, current rewards: -827.54351, mean: -0.74553
[32m[0907 19-26-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35209, current rewards: -877.54351, mean: -0.75650
[32m[0907 19-26-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35209, current rewards: -927.54351, mean: -0.76656
[32m[0907 19-27-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35197, current rewards: -977.54351, mean: -0.77583
[32m[0907 19-27-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35161, current rewards: -1027.54351, mean: -0.78438
[32m[0907 19-27-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35133, current rewards: -1077.54351, mean: -0.79231
[32m[0907 19-27-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35107, current rewards: -1127.54351, mean: -0.79968
[32m[0907 19-28-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35080, current rewards: -1177.54351, mean: -0.80654
[32m[0907 19-28-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35057, current rewards: -1227.54351, mean: -0.81294
[32m[0907 19-28-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35035, current rewards: -1277.54351, mean: -0.81894
[32m[0907 19-29-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35017, current rewards: -1327.54351, mean: -0.82456
[32m[0907 19-29-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34989, current rewards: -1377.54351, mean: -0.82985
[32m[0907 19-29-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34868, current rewards: -1427.54351, mean: -0.83482
[32m[0907 19-29-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34752, current rewards: -1477.54351, mean: -0.83951
[32m[0907 19-30-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34641, current rewards: -1527.54351, mean: -0.84395
[32m[0907 19-30-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34536, current rewards: -1577.54351, mean: -0.84814
[32m[0907 19-30-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34436, current rewards: -1627.54351, mean: -0.85212
[32m[0907 19-30-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34345, current rewards: -1677.54351, mean: -0.85589
[32m[0907 19-31-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34273, current rewards: -1727.54351, mean: -0.85947
[32m[0907 19-31-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34207, current rewards: -1777.54351, mean: -0.86289
[32m[0907 19-31-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34143, current rewards: -1827.54351, mean: -0.86613
[32m[0907 19-31-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34082, current rewards: -1877.54351, mean: -0.86923
[32m[0907 19-32-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34023, current rewards: -1927.54351, mean: -0.87219
[32m[0907 19-32-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33954, current rewards: -1977.54351, mean: -0.87502
[32m[0907 19-32-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33883, current rewards: -2027.54351, mean: -0.87772
[32m[0907 19-32-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33814, current rewards: -2077.54351, mean: -0.88032
[32m[0907 19-33-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33750, current rewards: -2127.54351, mean: -0.88280
[32m[0907 19-33-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33688, current rewards: -2177.54351, mean: -0.88518
[32m[0907 19-33-42 @Agent.py:117][0m Average action selection time: 0.3364
[32m[0907 19-33-42 @Agent.py:118][0m Rollout length: 2520
[32m[0907 19-33-43 @MBExp.py:227][0m Rewards obtained: [-2217.5435145652123], Lows: [0], Highs: [2256], Total time: 94759.00324800004
[32m[0907 19-37-30 @MBExp.py:144][0m ####################################################################
[32m[0907 19-37-30 @MBExp.py:145][0m Starting training iteration 115.
[32m[0907 19-37-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36886, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-37-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35645, current rewards: -58.94442, mean: -0.98241
[32m[0907 19-38-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35708, current rewards: -108.94442, mean: -0.99040
[32m[0907 19-38-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35750, current rewards: -158.94442, mean: -0.99340
[32m[0907 19-38-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35738, current rewards: -208.94442, mean: -0.99497
[32m[0907 19-39-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35749, current rewards: -258.94442, mean: -0.99594
[32m[0907 19-39-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35746, current rewards: -308.94442, mean: -0.99659
[32m[0907 19-39-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35746, current rewards: -358.94442, mean: -0.99707
[32m[0907 19-39-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35750, current rewards: -408.94442, mean: -0.99743
[32m[0907 19-40-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35746, current rewards: -458.94442, mean: -0.99771
[32m[0907 19-40-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35737, current rewards: -508.94442, mean: -0.99793
[32m[0907 19-40-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35744, current rewards: -558.94442, mean: -0.99812
[32m[0907 19-41-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35738, current rewards: -608.94442, mean: -0.99827
[32m[0907 19-41-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35731, current rewards: -658.94442, mean: -0.99840
[32m[0907 19-41-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35732, current rewards: -708.94442, mean: -0.99851
[32m[0907 19-42-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35720, current rewards: -758.94442, mean: -0.99861
[32m[0907 19-42-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35711, current rewards: -808.94442, mean: -0.99870
[32m[0907 19-42-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35780, current rewards: -858.94442, mean: -0.99877
[32m[0907 19-42-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35832, current rewards: -908.94442, mean: -0.99884
[32m[0907 19-43-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35873, current rewards: -958.94442, mean: -0.99890
[32m[0907 19-43-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35892, current rewards: -1008.94442, mean: -0.99895
[32m[0907 19-43-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35874, current rewards: -1058.94442, mean: -0.99900
[32m[0907 19-44-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35862, current rewards: -1108.94442, mean: -0.99905
[32m[0907 19-44-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35854, current rewards: -1158.94442, mean: -0.99909
[32m[0907 19-44-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35845, current rewards: -1208.94442, mean: -0.99913
[32m[0907 19-45-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35810, current rewards: -1258.94442, mean: -0.99916
[32m[0907 19-45-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35776, current rewards: -1308.94442, mean: -0.99919
[32m[0907 19-45-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35745, current rewards: -1358.94442, mean: -0.99922
[32m[0907 19-45-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35711, current rewards: -1408.94442, mean: -0.99925
[32m[0907 19-46-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35684, current rewards: -1458.94442, mean: -0.99928
[32m[0907 19-46-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35657, current rewards: -1508.94442, mean: -0.99930
[32m[0907 19-46-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35633, current rewards: -1558.94442, mean: -0.99932
[32m[0907 19-47-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35608, current rewards: -1608.94442, mean: -0.99934
[32m[0907 19-47-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35586, current rewards: -1658.94442, mean: -0.99936
[32m[0907 19-47-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35566, current rewards: -1708.94442, mean: -0.99938
[32m[0907 19-47-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35548, current rewards: -1758.94442, mean: -0.99940
[32m[0907 19-48-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35527, current rewards: -1808.94442, mean: -0.99942
[32m[0907 19-48-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35510, current rewards: -1858.94442, mean: -0.99943
[32m[0907 19-48-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35495, current rewards: -1894.82338, mean: -0.99205
[32m[0907 19-49-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35490, current rewards: -1890.51170, mean: -0.96455
[32m[0907 19-49-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35495, current rewards: -1886.20001, mean: -0.93841
[32m[0907 19-49-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35501, current rewards: -1881.88833, mean: -0.91354
[32m[0907 19-49-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35505, current rewards: -1877.80492, mean: -0.88995
[32m[0907 19-50-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35510, current rewards: -1874.06239, mean: -0.86762
[32m[0907 19-50-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35510, current rewards: -1870.31986, mean: -0.84630
[32m[0907 19-50-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35498, current rewards: -1866.57732, mean: -0.82592
[32m[0907 19-51-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35483, current rewards: -1862.83479, mean: -0.80642
[32m[0907 19-51-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35471, current rewards: -1859.09225, mean: -0.78775
[32m[0907 19-51-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35458, current rewards: -1855.34972, mean: -0.76985
[32m[0907 19-52-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35447, current rewards: -1869.87965, mean: -0.76011
[32m[0907 19-52-16 @Agent.py:117][0m Average action selection time: 0.3544
[32m[0907 19-52-16 @Agent.py:118][0m Rollout length: 2520
[32m[0907 19-52-16 @MBExp.py:227][0m Rewards obtained: [-1909.8796461445625], Lows: [0], Highs: [1953], Total time: 95645.78675900004
[32m[0907 19-56-19 @MBExp.py:144][0m ####################################################################
[32m[0907 19-56-19 @MBExp.py:145][0m Starting training iteration 116.
[32m[0907 19-56-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34286, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-56-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35228, current rewards: -60.00000, mean: -1.00000
[32m[0907 19-56-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35674, current rewards: -110.00000, mean: -1.00000
[32m[0907 19-57-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35929, current rewards: -160.00000, mean: -1.00000
[32m[0907 19-57-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36086, current rewards: -210.00000, mean: -1.00000
[32m[0907 19-57-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36136, current rewards: -260.00000, mean: -1.00000
[32m[0907 19-58-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36261, current rewards: -310.00000, mean: -1.00000
[32m[0907 19-58-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36307, current rewards: -360.00000, mean: -1.00000
[32m[0907 19-58-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36326, current rewards: -410.00000, mean: -1.00000
[32m[0907 19-59-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36371, current rewards: -460.00000, mean: -1.00000
[32m[0907 19-59-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36412, current rewards: -510.00000, mean: -1.00000
[32m[0907 19-59-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36457, current rewards: -560.00000, mean: -1.00000
[32m[0907 20-00-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36465, current rewards: -610.00000, mean: -1.00000
[32m[0907 20-00-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36469, current rewards: -660.00000, mean: -1.00000
[32m[0907 20-00-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36453, current rewards: -710.00000, mean: -1.00000
[32m[0907 20-00-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36433, current rewards: -760.00000, mean: -1.00000
[32m[0907 20-01-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36408, current rewards: -810.00000, mean: -1.00000
[32m[0907 20-01-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36379, current rewards: -860.00000, mean: -1.00000
[32m[0907 20-01-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36335, current rewards: -910.00000, mean: -1.00000
[32m[0907 20-02-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36300, current rewards: -960.00000, mean: -1.00000
[32m[0907 20-02-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36268, current rewards: -1010.00000, mean: -1.00000
[32m[0907 20-02-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36231, current rewards: -1060.00000, mean: -1.00000
[32m[0907 20-03-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36207, current rewards: -1110.00000, mean: -1.00000
[32m[0907 20-03-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36184, current rewards: -1160.00000, mean: -1.00000
[32m[0907 20-03-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36142, current rewards: -1210.00000, mean: -1.00000
[32m[0907 20-03-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36093, current rewards: -1260.00000, mean: -1.00000
[32m[0907 20-04-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36053, current rewards: -1310.00000, mean: -1.00000
[32m[0907 20-04-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36020, current rewards: -1360.00000, mean: -1.00000
[32m[0907 20-04-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35990, current rewards: -1410.00000, mean: -1.00000
[32m[0907 20-05-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35959, current rewards: -1460.00000, mean: -1.00000
[32m[0907 20-05-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35916, current rewards: -1510.00000, mean: -1.00000
[32m[0907 20-05-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35875, current rewards: -1560.00000, mean: -1.00000
[32m[0907 20-05-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35837, current rewards: -1610.00000, mean: -1.00000
[32m[0907 20-06-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35803, current rewards: -1660.00000, mean: -1.00000
[32m[0907 20-06-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35772, current rewards: -1710.00000, mean: -1.00000
[32m[0907 20-06-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35743, current rewards: -1760.00000, mean: -1.00000
[32m[0907 20-07-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35714, current rewards: -1810.00000, mean: -1.00000
[32m[0907 20-07-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35686, current rewards: -1860.00000, mean: -1.00000
[32m[0907 20-07-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35658, current rewards: -1910.00000, mean: -1.00000
[32m[0907 20-07-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35657, current rewards: -1960.00000, mean: -1.00000
[32m[0907 20-08-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35654, current rewards: -2010.00000, mean: -1.00000
[32m[0907 20-08-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35653, current rewards: -2053.49926, mean: -0.99684
[32m[0907 20-08-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35648, current rewards: -2071.30141, mean: -0.98166
[32m[0907 20-09-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35644, current rewards: -2121.30141, mean: -0.98208
[32m[0907 20-09-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35640, current rewards: -2171.30141, mean: -0.98249
[32m[0907 20-09-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35619, current rewards: -2221.30141, mean: -0.98288
[32m[0907 20-10-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35600, current rewards: -2271.30141, mean: -0.98325
[32m[0907 20-10-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35580, current rewards: -2321.30141, mean: -0.98360
[32m[0907 20-10-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35562, current rewards: -2371.30141, mean: -0.98394
[32m[0907 20-10-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35544, current rewards: -2421.30141, mean: -0.98427
[32m[0907 20-11-08 @Agent.py:117][0m Average action selection time: 0.3553
[32m[0907 20-11-08 @Agent.py:118][0m Rollout length: 2520
[32m[0907 20-11-08 @MBExp.py:227][0m Rewards obtained: [-2460.2536563618733], Lows: [0], Highs: [2463], Total time: 96534.88989200004
[32m[0907 20-15-15 @MBExp.py:144][0m ####################################################################
[32m[0907 20-15-15 @MBExp.py:145][0m Starting training iteration 117.
[32m[0907 20-15-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.47750, current rewards: 0.56473, mean: 0.05647
[32m[0907 20-15-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.52624, current rewards: -78.58197, mean: -1.30970
[32m[0907 20-16-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.45357, current rewards: -178.58197, mean: -1.62347
[32m[0907 20-16-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.42194, current rewards: -278.58197, mean: -1.74114
[32m[0907 20-16-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.39959, current rewards: -378.58197, mean: -1.80277
[32m[0907 20-16-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.38334, current rewards: -478.58197, mean: -1.84070
[32m[0907 20-17-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37240, current rewards: -578.58197, mean: -1.86639
[32m[0907 20-17-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36438, current rewards: -678.58197, mean: -1.88495
[32m[0907 20-17-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35840, current rewards: -778.58197, mean: -1.89898
[32m[0907 20-17-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35372, current rewards: -878.58197, mean: -1.90996
[32m[0907 20-18-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34997, current rewards: -978.58197, mean: -1.91879
[32m[0907 20-18-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34682, current rewards: -1078.58197, mean: -1.92604
[32m[0907 20-18-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34429, current rewards: -1178.58197, mean: -1.93210
[32m[0907 20-19-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34211, current rewards: -1278.58197, mean: -1.93725
[32m[0907 20-19-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34018, current rewards: -1378.58197, mean: -1.94166
[32m[0907 20-19-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33857, current rewards: -1478.58197, mean: -1.94550
[32m[0907 20-19-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33710, current rewards: -1578.58197, mean: -1.94887
[32m[0907 20-20-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33581, current rewards: -1678.58197, mean: -1.95184
[32m[0907 20-20-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33466, current rewards: -1778.58197, mean: -1.95449
[32m[0907 20-20-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33364, current rewards: -1878.58197, mean: -1.95686
[32m[0907 20-20-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33271, current rewards: -1978.58197, mean: -1.95899
[32m[0907 20-21-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33183, current rewards: -2078.58197, mean: -1.96093
[32m[0907 20-21-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33103, current rewards: -2178.58197, mean: -1.96269
[32m[0907 20-21-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33008, current rewards: -2278.58197, mean: -1.96429
[32m[0907 20-21-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32917, current rewards: -2378.58197, mean: -1.96577
[32m[0907 20-22-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32830, current rewards: -2478.58197, mean: -1.96713
[32m[0907 20-22-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32838, current rewards: -2578.58197, mean: -1.96838
[32m[0907 20-22-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32894, current rewards: -2678.58197, mean: -1.96955
[32m[0907 20-23-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32949, current rewards: -2778.58197, mean: -1.97063
[32m[0907 20-23-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32996, current rewards: -2878.58197, mean: -1.97163
[32m[0907 20-23-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33040, current rewards: -2978.58197, mean: -1.97257
[32m[0907 20-23-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33008, current rewards: -3078.58197, mean: -1.97345
[32m[0907 20-24-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32938, current rewards: -3178.58197, mean: -1.97427
[32m[0907 20-24-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32871, current rewards: -3278.58197, mean: -1.97505
[32m[0907 20-24-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32816, current rewards: -3378.58197, mean: -1.97578
[32m[0907 20-24-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32758, current rewards: -3478.58197, mean: -1.97647
[32m[0907 20-25-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32703, current rewards: -3578.58197, mean: -1.97712
[32m[0907 20-25-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32659, current rewards: -3678.58197, mean: -1.97773
[32m[0907 20-25-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32630, current rewards: -3778.58197, mean: -1.97832
[32m[0907 20-25-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32601, current rewards: -3878.58197, mean: -1.97887
[32m[0907 20-26-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32569, current rewards: -3978.58197, mean: -1.97939
[32m[0907 20-26-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32540, current rewards: -4078.58197, mean: -1.97989
[32m[0907 20-26-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32517, current rewards: -4178.58197, mean: -1.98037
[32m[0907 20-26-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32493, current rewards: -4278.58197, mean: -1.98082
[32m[0907 20-27-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32458, current rewards: -4378.58197, mean: -1.98126
[32m[0907 20-27-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32420, current rewards: -4478.58197, mean: -1.98167
[32m[0907 20-27-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32384, current rewards: -4578.58197, mean: -1.98207
[32m[0907 20-27-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32349, current rewards: -4678.58197, mean: -1.98245
[32m[0907 20-28-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32317, current rewards: -4778.58197, mean: -1.98281
[32m[0907 20-28-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32286, current rewards: -4878.58197, mean: -1.98316
[32m[0907 20-28-42 @Agent.py:117][0m Average action selection time: 0.3225
[32m[0907 20-28-42 @Agent.py:118][0m Rollout length: 2520
[32m[0907 20-28-42 @MBExp.py:227][0m Rewards obtained: [-4958.581971673325], Lows: [2480], Highs: [0], Total time: 97341.97507200003
[32m[0907 20-32-19 @MBExp.py:144][0m ####################################################################
[32m[0907 20-32-19 @MBExp.py:145][0m Starting training iteration 118.
[32m[0907 20-32-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30837, current rewards: -10.00000, mean: -1.00000
[32m[0907 20-32-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35658, current rewards: -65.22695, mean: -1.08712
[32m[0907 20-32-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33709, current rewards: -165.22695, mean: -1.50206
[32m[0907 20-33-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33036, current rewards: -265.22695, mean: -1.65767
[32m[0907 20-33-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32651, current rewards: -365.22695, mean: -1.73918
[32m[0907 20-33-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32425, current rewards: -465.22695, mean: -1.78933
[32m[0907 20-33-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32270, current rewards: -565.22695, mean: -1.82331
[32m[0907 20-34-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32154, current rewards: -665.22695, mean: -1.84785
[32m[0907 20-34-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32069, current rewards: -765.22695, mean: -1.86641
[32m[0907 20-34-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32008, current rewards: -865.22695, mean: -1.88093
[32m[0907 20-35-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31940, current rewards: -965.22695, mean: -1.89260
[32m[0907 20-35-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31882, current rewards: -1065.22695, mean: -1.90219
[32m[0907 20-35-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31842, current rewards: -1165.22695, mean: -1.91021
[32m[0907 20-35-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31809, current rewards: -1265.22695, mean: -1.91701
[32m[0907 20-36-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31776, current rewards: -1365.22695, mean: -1.92285
[32m[0907 20-36-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31749, current rewards: -1465.22695, mean: -1.92793
[32m[0907 20-36-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31732, current rewards: -1565.22695, mean: -1.93238
[32m[0907 20-36-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31717, current rewards: -1665.22695, mean: -1.93631
[32m[0907 20-37-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31701, current rewards: -1765.22695, mean: -1.93981
[32m[0907 20-37-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31688, current rewards: -1865.22695, mean: -1.94294
[32m[0907 20-37-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31678, current rewards: -1965.22695, mean: -1.94577
[32m[0907 20-37-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31675, current rewards: -2065.22695, mean: -1.94833
[32m[0907 20-38-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31676, current rewards: -2165.22695, mean: -1.95065
[32m[0907 20-38-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31657, current rewards: -2265.22695, mean: -1.95278
[32m[0907 20-38-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31640, current rewards: -2365.22695, mean: -1.95473
[32m[0907 20-38-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31626, current rewards: -2465.22695, mean: -1.95653
[32m[0907 20-39-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31611, current rewards: -2565.22695, mean: -1.95819
[32m[0907 20-39-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31599, current rewards: -2665.22695, mean: -1.95973
[32m[0907 20-39-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31585, current rewards: -2765.22695, mean: -1.96115
[32m[0907 20-40-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31573, current rewards: -2865.22695, mean: -1.96248
[32m[0907 20-40-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31563, current rewards: -2965.22695, mean: -1.96373
[32m[0907 20-40-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31551, current rewards: -3065.22695, mean: -1.96489
[32m[0907 20-40-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31613, current rewards: -3165.22695, mean: -1.96598
[32m[0907 20-41-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31698, current rewards: -3265.22695, mean: -1.96700
[32m[0907 20-41-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31777, current rewards: -3365.22695, mean: -1.96797
[32m[0907 20-41-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31851, current rewards: -3465.22695, mean: -1.96888
[32m[0907 20-41-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31921, current rewards: -3565.22695, mean: -1.96974
[32m[0907 20-42-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32012, current rewards: -3665.22695, mean: -1.97055
[32m[0907 20-42-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32098, current rewards: -3765.22695, mean: -1.97132
[32m[0907 20-42-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32178, current rewards: -3865.22695, mean: -1.97205
[32m[0907 20-43-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32252, current rewards: -3965.22695, mean: -1.97275
[32m[0907 20-43-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32319, current rewards: -4065.22695, mean: -1.97341
[32m[0907 20-43-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32387, current rewards: -4165.22695, mean: -1.97404
[32m[0907 20-44-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32454, current rewards: -4265.22695, mean: -1.97464
[32m[0907 20-44-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32502, current rewards: -4365.22695, mean: -1.97522
[32m[0907 20-44-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32543, current rewards: -4465.22695, mean: -1.97576
[32m[0907 20-44-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32578, current rewards: -4565.22695, mean: -1.97629
[32m[0907 20-45-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32616, current rewards: -4665.22695, mean: -1.97679
[32m[0907 20-45-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32652, current rewards: -4765.22695, mean: -1.97727
[32m[0907 20-45-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32686, current rewards: -4865.22695, mean: -1.97773
[32m[0907 20-45-57 @Agent.py:117][0m Average action selection time: 0.3271
[32m[0907 20-45-57 @Agent.py:118][0m Rollout length: 2520
[32m[0907 20-45-58 @MBExp.py:227][0m Rewards obtained: [-4945.226954932121], Lows: [2460], Highs: [27], Total time: 98160.61222600003
[32m[0907 20-49-59 @MBExp.py:144][0m ####################################################################
[32m[0907 20-49-59 @MBExp.py:145][0m Starting training iteration 119.
[32m[0907 20-50-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34592, current rewards: -10.00000, mean: -1.00000
[32m[0907 20-50-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.42987, current rewards: -79.00000, mean: -1.31667
[32m[0907 20-50-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.39545, current rewards: -133.88926, mean: -1.21718
[32m[0907 20-51-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.38240, current rewards: -183.88926, mean: -1.14931
[32m[0907 20-51-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37575, current rewards: -233.88926, mean: -1.11376
[32m[0907 20-51-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37157, current rewards: -283.88926, mean: -1.09188
[32m[0907 20-51-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36874, current rewards: -333.88926, mean: -1.07706
[32m[0907 20-52-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36663, current rewards: -383.88926, mean: -1.06636
[32m[0907 20-52-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36499, current rewards: -433.88926, mean: -1.05827
[32m[0907 20-52-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36383, current rewards: -483.88926, mean: -1.05193
[32m[0907 20-53-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36292, current rewards: -533.88926, mean: -1.04684
[32m[0907 20-53-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36208, current rewards: -583.88926, mean: -1.04266
[32m[0907 20-53-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36142, current rewards: -633.88926, mean: -1.03916
[32m[0907 20-53-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36085, current rewards: -683.88926, mean: -1.03620
[32m[0907 20-54-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36034, current rewards: -733.88926, mean: -1.03365
[32m[0907 20-54-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35984, current rewards: -783.88926, mean: -1.03143
[32m[0907 20-54-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35955, current rewards: -833.88926, mean: -1.02949
[32m[0907 20-55-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35922, current rewards: -883.88926, mean: -1.02778
[32m[0907 20-55-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35893, current rewards: -933.88926, mean: -1.02625
[32m[0907 20-55-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35870, current rewards: -983.88926, mean: -1.02488
[32m[0907 20-56-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35841, current rewards: -1033.88926, mean: -1.02365
[32m[0907 20-56-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35808, current rewards: -1083.88926, mean: -1.02254
[32m[0907 20-56-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35756, current rewards: -1133.88926, mean: -1.02152
[32m[0907 20-56-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35708, current rewards: -1183.88926, mean: -1.02059
[32m[0907 20-57-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35666, current rewards: -1233.88926, mean: -1.01974
[32m[0907 20-57-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35626, current rewards: -1283.88926, mean: -1.01896
[32m[0907 20-57-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35586, current rewards: -1333.88926, mean: -1.01824
[32m[0907 20-58-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35552, current rewards: -1383.88926, mean: -1.01757
[32m[0907 20-58-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35519, current rewards: -1433.88926, mean: -1.01694
[32m[0907 20-58-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35489, current rewards: -1483.88926, mean: -1.01636
[32m[0907 20-58-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35459, current rewards: -1533.88926, mean: -1.01582
[32m[0907 20-59-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35430, current rewards: -1583.88926, mean: -1.01531
[32m[0907 20-59-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35404, current rewards: -1633.88926, mean: -1.01484
[32m[0907 20-59-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35380, current rewards: -1683.88926, mean: -1.01439
[32m[0907 21-00-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35359, current rewards: -1733.88926, mean: -1.01397
[32m[0907 21-00-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35338, current rewards: -1783.88926, mean: -1.01357
[32m[0907 21-00-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35331, current rewards: -1833.88926, mean: -1.01320
[32m[0907 21-00-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35336, current rewards: -1876.51392, mean: -1.00888
[32m[0907 21-01-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35343, current rewards: -1873.83287, mean: -0.98106
[32m[0907 21-01-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35346, current rewards: -1871.15181, mean: -0.95467
[32m[0907 21-01-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35347, current rewards: -1868.47076, mean: -0.92959
[32m[0907 21-02-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35347, current rewards: -1865.68946, mean: -0.90567
[32m[0907 21-02-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35349, current rewards: -1862.44357, mean: -0.88267
[32m[0907 21-02-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35351, current rewards: -1859.19769, mean: -0.86074
[32m[0907 21-03-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35343, current rewards: -1855.95181, mean: -0.83980
[32m[0907 21-03-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35328, current rewards: -1852.70592, mean: -0.81978
[32m[0907 21-03-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35316, current rewards: -1849.46004, mean: -0.80063
[32m[0907 21-03-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35301, current rewards: -1846.21415, mean: -0.78229
[32m[0907 21-04-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35287, current rewards: -1842.96827, mean: -0.76472
[32m[0907 21-04-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35273, current rewards: -1839.76899, mean: -0.74787
[32m[0907 21-04-41 @Agent.py:117][0m Average action selection time: 0.3526
[32m[0907 21-04-41 @Agent.py:118][0m Rollout length: 2520
[32m[0907 21-04-41 @MBExp.py:227][0m Rewards obtained: [-1861.8574295394337], Lows: [25], Highs: [1850], Total time: 99042.91259000002
[32m[0907 21-08-52 @MBExp.py:144][0m ####################################################################
[32m[0907 21-08-52 @MBExp.py:145][0m Starting training iteration 120.
[32m[0907 21-08-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36935, current rewards: -10.00000, mean: -1.00000
[32m[0907 21-09-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35129, current rewards: -73.94937, mean: -1.23249
[32m[0907 21-09-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35324, current rewards: -123.94937, mean: -1.12681
[32m[0907 21-09-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35359, current rewards: -173.94937, mean: -1.08718
[32m[0907 21-10-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35364, current rewards: -223.94937, mean: -1.06643
[32m[0907 21-10-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35374, current rewards: -273.94937, mean: -1.05365
[32m[0907 21-10-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35384, current rewards: -323.94937, mean: -1.04500
[32m[0907 21-10-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35383, current rewards: -373.94937, mean: -1.03875
[32m[0907 21-11-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35382, current rewards: -423.94937, mean: -1.03402
[32m[0907 21-11-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35399, current rewards: -473.94937, mean: -1.03032
[32m[0907 21-11-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35392, current rewards: -523.94937, mean: -1.02735
[32m[0907 21-12-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35382, current rewards: -573.94937, mean: -1.02491
[32m[0907 21-12-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35379, current rewards: -623.94937, mean: -1.02287
[32m[0907 21-12-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35383, current rewards: -673.94937, mean: -1.02114
[32m[0907 21-13-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35385, current rewards: -723.94937, mean: -1.01965
[32m[0907 21-13-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35385, current rewards: -773.94937, mean: -1.01835
[32m[0907 21-13-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35393, current rewards: -823.94937, mean: -1.01722
[32m[0907 21-13-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35388, current rewards: -873.94937, mean: -1.01622
[32m[0907 21-14-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35383, current rewards: -923.94937, mean: -1.01533
[32m[0907 21-14-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35374, current rewards: -973.94937, mean: -1.01453
[32m[0907 21-14-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35373, current rewards: -1023.94937, mean: -1.01381
[32m[0907 21-15-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35224, current rewards: -1073.94937, mean: -1.01316
[32m[0907 21-15-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35079, current rewards: -1123.94937, mean: -1.01257
[32m[0907 21-15-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34943, current rewards: -1173.94937, mean: -1.01203
[32m[0907 21-15-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34818, current rewards: -1223.94937, mean: -1.01153
[32m[0907 21-16-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34704, current rewards: -1273.94937, mean: -1.01107
[32m[0907 21-16-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34599, current rewards: -1323.94937, mean: -1.01065
[32m[0907 21-16-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34500, current rewards: -1373.94937, mean: -1.01026
[32m[0907 21-16-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34410, current rewards: -1423.94937, mean: -1.00989
[32m[0907 21-17-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34325, current rewards: -1473.94937, mean: -1.00955
[32m[0907 21-17-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34247, current rewards: -1523.94937, mean: -1.00924
[32m[0907 21-17-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34175, current rewards: -1573.94937, mean: -1.00894
[32m[0907 21-18-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34104, current rewards: -1623.94937, mean: -1.00866
[32m[0907 21-18-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34037, current rewards: -1665.50465, mean: -1.00332
[32m[0907 21-18-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33975, current rewards: -1715.50465, mean: -1.00322
[32m[0907 21-18-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33918, current rewards: -1765.50465, mean: -1.00313
[32m[0907 21-19-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33863, current rewards: -1815.50465, mean: -1.00304
[32m[0907 21-19-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33811, current rewards: -1865.50465, mean: -1.00296
[32m[0907 21-19-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33763, current rewards: -1915.50465, mean: -1.00288
[32m[0907 21-19-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33717, current rewards: -1965.50465, mean: -1.00281
[32m[0907 21-20-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33673, current rewards: -2015.50465, mean: -1.00274
[32m[0907 21-20-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33632, current rewards: -2060.24233, mean: -1.00012
[32m[0907 21-20-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33592, current rewards: -2056.96692, mean: -0.97487
[32m[0907 21-20-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33553, current rewards: -2053.67648, mean: -0.95078
[32m[0907 21-21-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33452, current rewards: -2050.38604, mean: -0.92778
[32m[0907 21-21-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33324, current rewards: -2047.09561, mean: -0.90579
[32m[0907 21-21-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33203, current rewards: -2072.58200, mean: -0.89722
[32m[0907 21-21-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33086, current rewards: -2122.58200, mean: -0.89940
[32m[0907 21-22-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32975, current rewards: -2172.58200, mean: -0.90149
[32m[0907 21-22-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32870, current rewards: -2222.58200, mean: -0.90349
[32m[0907 21-22-31 @Agent.py:117][0m Average action selection time: 0.3277
[32m[0907 21-22-31 @Agent.py:118][0m Rollout length: 2520
[32m[0907 21-22-32 @MBExp.py:227][0m Rewards obtained: [-2262.582003559145], Lows: [18], Highs: [2243], Total time: 99862.91441600003
