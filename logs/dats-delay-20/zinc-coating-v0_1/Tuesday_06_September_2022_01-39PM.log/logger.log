[32m[0906 13-39-54 @logger.py:99][0m Log file set to /app/logs/dats-delay-20/zinc-coating-v0_1/Tuesday_06_September_2022_01-39PM.log
[32m[0906 13-39-54 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00002, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -59.45805, mean: -0.99097
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -103.68295, mean: -0.94257
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -153.69255, mean: -0.96058
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -199.66460, mean: -0.95078
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -251.68426, mean: -0.96802
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -299.93030, mean: -0.96752
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -349.14873, mean: -0.96986
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -401.87350, mean: -0.98018
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -447.45865, mean: -0.97274
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -502.38735, mean: -0.98507
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -552.10830, mean: -0.98591
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -596.48236, mean: -0.97784
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -642.23611, mean: -0.97309
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -696.55657, mean: -0.98107
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -745.44240, mean: -0.98085
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -794.15751, mean: -0.98044
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -835.86443, mean: -0.97194
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -884.72856, mean: -0.97223
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -942.06412, mean: -0.98132
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1014.17458, mean: -1.00413
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1071.05815, mean: -1.01043
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1140.50644, mean: -1.02748
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1200.20923, mean: -1.03466
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1246.50574, mean: -1.03017
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1303.63992, mean: -1.03463
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1352.66448, mean: -1.03257
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1409.11723, mean: -1.03612
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1463.28993, mean: -1.03779
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1506.15532, mean: -1.03161
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1565.21187, mean: -1.03656
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -1629.81041, mean: -1.04475
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -1690.23793, mean: -1.04984
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -1746.98509, mean: -1.05240
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -1823.04945, mean: -1.06611
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -1897.33694, mean: -1.07803
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -1956.66856, mean: -1.08103
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2035.29458, mean: -1.09424
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2107.70952, mean: -1.10351
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2168.02779, mean: -1.10614
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2226.05139, mean: -1.10749
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2300.05771, mean: -1.11653
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2362.74142, mean: -1.11978
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2415.87009, mean: -1.11846
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2472.21451, mean: -1.11865
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2531.19564, mean: -1.12000
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2587.94273, mean: -1.12032
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2642.95636, mean: -1.11990
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2701.94069, mean: -1.12114
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2743.21702, mean: -1.11513
[32m[0906 13-39-55 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-39-55 @Agent.py:118][0m Rollout length: 2520
[32m[0906 13-39-57 @MBExp.py:144][0m ####################################################################
[32m[0906 13-39-57 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-39-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.25744, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.24911, current rewards: -83.37983, mean: -1.38966
[32m[0906 13-40-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.26481, current rewards: -183.37983, mean: -1.66709
[32m[0906 13-40-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.27794, current rewards: -283.37983, mean: -1.77112
[32m[0906 13-40-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29085, current rewards: -383.37983, mean: -1.82562
[32m[0906 13-41-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29862, current rewards: -483.37983, mean: -1.85915
[32m[0906 13-41-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30635, current rewards: -583.37983, mean: -1.88187
[32m[0906 13-41-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31547, current rewards: -683.37983, mean: -1.89828
[32m[0906 13-42-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32200, current rewards: -783.37983, mean: -1.91068
[32m[0906 13-42-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32698, current rewards: -883.37983, mean: -1.92039
[32m[0906 13-42-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33108, current rewards: -983.37983, mean: -1.92820
[32m[0906 13-43-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33445, current rewards: -1083.37983, mean: -1.93461
[32m[0906 13-43-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33674, current rewards: -1183.37983, mean: -1.93997
[32m[0906 13-43-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33869, current rewards: -1283.37983, mean: -1.94451
[32m[0906 13-43-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34038, current rewards: -1383.37983, mean: -1.94842
[32m[0906 13-44-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34204, current rewards: -1483.37983, mean: -1.95182
[32m[0906 13-44-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34348, current rewards: -1549.32114, mean: -1.91274
[32m[0906 13-44-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34464, current rewards: -1599.32114, mean: -1.85968
[32m[0906 13-45-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34584, current rewards: -1649.32114, mean: -1.81244
[32m[0906 13-45-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34678, current rewards: -1699.32114, mean: -1.77013
[32m[0906 13-45-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34761, current rewards: -1749.32114, mean: -1.73200
[32m[0906 13-46-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34844, current rewards: -1799.32114, mean: -1.69747
[32m[0906 13-46-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34916, current rewards: -1849.32114, mean: -1.66606
[32m[0906 13-46-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34981, current rewards: -1899.32114, mean: -1.63735
[32m[0906 13-47-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35016, current rewards: -1931.38089, mean: -1.59618
[32m[0906 13-47-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35051, current rewards: -1928.53071, mean: -1.53058
[32m[0906 13-47-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35085, current rewards: -1948.93462, mean: -1.48774
[32m[0906 13-47-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35121, current rewards: -1998.93462, mean: -1.46980
[32m[0906 13-48-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35147, current rewards: -2048.93462, mean: -1.45315
[32m[0906 13-48-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35178, current rewards: -2098.93462, mean: -1.43763
[32m[0906 13-48-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35212, current rewards: -2148.93462, mean: -1.42314
[32m[0906 13-49-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35241, current rewards: -2198.93462, mean: -1.40957
[32m[0906 13-49-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35267, current rewards: -2248.93462, mean: -1.39685
[32m[0906 13-49-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35298, current rewards: -2298.93462, mean: -1.38490
[32m[0906 13-50-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35330, current rewards: -2348.93462, mean: -1.37365
[32m[0906 13-50-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35366, current rewards: -2398.93462, mean: -1.36303
[32m[0906 13-50-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35400, current rewards: -2448.93462, mean: -1.35300
[32m[0906 13-50-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35428, current rewards: -2498.93462, mean: -1.34351
[32m[0906 13-51-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35456, current rewards: -2548.93462, mean: -1.33452
[32m[0906 13-51-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35480, current rewards: -2598.93462, mean: -1.32599
[32m[0906 13-51-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35503, current rewards: -2648.93462, mean: -1.31788
[32m[0906 13-52-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35524, current rewards: -2698.93462, mean: -1.31016
[32m[0906 13-52-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35545, current rewards: -2748.93462, mean: -1.30281
[32m[0906 13-52-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35567, current rewards: -2798.93462, mean: -1.29580
[32m[0906 13-53-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35577, current rewards: -2848.93462, mean: -1.28911
[32m[0906 13-53-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35584, current rewards: -2898.93462, mean: -1.28271
[32m[0906 13-53-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35593, current rewards: -2948.93462, mean: -1.27660
[32m[0906 13-53-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35606, current rewards: -2998.93462, mean: -1.27074
[32m[0906 13-54-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35615, current rewards: -3048.93462, mean: -1.26512
[32m[0906 13-54-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35626, current rewards: -3098.93462, mean: -1.25973
[32m[0906 13-54-48 @Agent.py:117][0m Average action selection time: 0.3564
[32m[0906 13-54-48 @Agent.py:118][0m Rollout length: 2520
[32m[0906 13-54-48 @MBExp.py:227][0m Rewards obtained: [-3138.9346173382455], Lows: [749], Highs: [1648], Total time: 891.670886
[32m[0906 13-54-53 @MBExp.py:144][0m ####################################################################
[32m[0906 13-54-53 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-54-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36479, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-55-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36223, current rewards: -21.40513, mean: -0.35675
[32m[0906 13-55-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36219, current rewards: -10.74161, mean: -0.09765
[32m[0906 13-55-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36165, current rewards: -0.08568, mean: -0.00054
[32m[0906 13-56-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36243, current rewards: 10.57693, mean: 0.05037
[32m[0906 13-56-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36224, current rewards: 21.21734, mean: 0.08161
[32m[0906 13-56-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36121, current rewards: 31.86778, mean: 0.10280
[32m[0906 13-57-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36065, current rewards: 15.11560, mean: 0.04199
[32m[0906 13-57-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36022, current rewards: -84.88440, mean: -0.20704
[32m[0906 13-57-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35999, current rewards: -184.88440, mean: -0.40192
[32m[0906 13-57-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35958, current rewards: -284.88440, mean: -0.55860
[32m[0906 13-58-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35961, current rewards: -384.88440, mean: -0.68729
[32m[0906 13-58-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35977, current rewards: -484.88440, mean: -0.79489
[32m[0906 13-58-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35986, current rewards: -508.69197, mean: -0.77075
[32m[0906 13-59-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36011, current rewards: -503.12877, mean: -0.70863
[32m[0906 13-59-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36021, current rewards: -497.56562, mean: -0.65469
[32m[0906 13-59-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36032, current rewards: -491.27320, mean: -0.60651
[32m[0906 14-00-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36041, current rewards: -484.95777, mean: -0.56390
[32m[0906 14-00-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36036, current rewards: -484.27389, mean: -0.53217
[32m[0906 14-00-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36027, current rewards: -534.27389, mean: -0.55654
[32m[0906 14-00-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36029, current rewards: -584.27389, mean: -0.57849
[32m[0906 14-01-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36040, current rewards: -634.27389, mean: -0.59837
[32m[0906 14-01-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36038, current rewards: -684.27389, mean: -0.61646
[32m[0906 14-01-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36019, current rewards: -734.27389, mean: -0.63299
[32m[0906 14-02-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36004, current rewards: -784.27389, mean: -0.64816
[32m[0906 14-02-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35997, current rewards: -834.27389, mean: -0.66212
[32m[0906 14-02-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35986, current rewards: -884.27389, mean: -0.67502
[32m[0906 14-03-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35981, current rewards: -934.27389, mean: -0.68697
[32m[0906 14-03-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35989, current rewards: -984.27389, mean: -0.69807
[32m[0906 14-03-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35988, current rewards: -1034.27389, mean: -0.70841
[32m[0906 14-03-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36005, current rewards: -1084.27389, mean: -0.71806
[32m[0906 14-04-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36028, current rewards: -1134.27389, mean: -0.72710
[32m[0906 14-04-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36049, current rewards: -1184.27389, mean: -0.73557
[32m[0906 14-04-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36059, current rewards: -1234.27389, mean: -0.74354
[32m[0906 14-05-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36061, current rewards: -1284.27389, mean: -0.75104
[32m[0906 14-05-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36057, current rewards: -1334.27389, mean: -0.75811
[32m[0906 14-05-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36050, current rewards: -1384.27389, mean: -0.76479
[32m[0906 14-06-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36041, current rewards: -1434.27389, mean: -0.77111
[32m[0906 14-06-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36033, current rewards: -1484.27389, mean: -0.77711
[32m[0906 14-06-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36028, current rewards: -1534.27389, mean: -0.78279
[32m[0906 14-06-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36016, current rewards: -1584.27389, mean: -0.78820
[32m[0906 14-07-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36021, current rewards: -1634.27389, mean: -0.79334
[32m[0906 14-07-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36033, current rewards: -1684.27389, mean: -0.79823
[32m[0906 14-07-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36045, current rewards: -1734.27389, mean: -0.80290
[32m[0906 14-08-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36047, current rewards: -1784.27389, mean: -0.80736
[32m[0906 14-08-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36039, current rewards: -1834.27389, mean: -0.81163
[32m[0906 14-08-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36030, current rewards: -1884.27389, mean: -0.81570
[32m[0906 14-09-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36021, current rewards: -1934.27389, mean: -0.81961
[32m[0906 14-09-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36016, current rewards: -1984.27389, mean: -0.82335
[32m[0906 14-09-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36011, current rewards: -2034.27389, mean: -0.82694
[32m[0906 14-09-54 @Agent.py:117][0m Average action selection time: 0.3601
[32m[0906 14-09-54 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-09-54 @MBExp.py:227][0m Rewards obtained: [-2074.2738892000834], Lows: [278], Highs: [1621], Total time: 1792.5662240000001
[32m[0906 14-10-01 @MBExp.py:144][0m ####################################################################
[32m[0906 14-10-01 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 14-10-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36690, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-10-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36063, current rewards: -99.00000, mean: -1.65000
[32m[0906 14-10-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36117, current rewards: -199.00000, mean: -1.80909
[32m[0906 14-10-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36140, current rewards: -299.00000, mean: -1.86875
[32m[0906 14-11-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36286, current rewards: -399.00000, mean: -1.90000
[32m[0906 14-11-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36374, current rewards: -499.00000, mean: -1.91923
[32m[0906 14-11-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36355, current rewards: -599.00000, mean: -1.93226
[32m[0906 14-12-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36305, current rewards: -699.00000, mean: -1.94167
[32m[0906 14-12-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36293, current rewards: -799.00000, mean: -1.94878
[32m[0906 14-12-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36243, current rewards: -899.00000, mean: -1.95435
[32m[0906 14-13-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36211, current rewards: -999.00000, mean: -1.95882
[32m[0906 14-13-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36174, current rewards: -1099.00000, mean: -1.96250
[32m[0906 14-13-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36133, current rewards: -1199.00000, mean: -1.96557
[32m[0906 14-13-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36099, current rewards: -1299.00000, mean: -1.96818
[32m[0906 14-14-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36073, current rewards: -1399.00000, mean: -1.97042
[32m[0906 14-14-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36058, current rewards: -1499.00000, mean: -1.97237
[32m[0906 14-14-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36034, current rewards: -1599.00000, mean: -1.97407
[32m[0906 14-15-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36017, current rewards: -1699.00000, mean: -1.97558
[32m[0906 14-15-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36001, current rewards: -1799.00000, mean: -1.97692
[32m[0906 14-15-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35988, current rewards: -1899.00000, mean: -1.97812
[32m[0906 14-16-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35977, current rewards: -1999.00000, mean: -1.97921
[32m[0906 14-16-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35987, current rewards: -2099.00000, mean: -1.98019
[32m[0906 14-16-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35995, current rewards: -2199.00000, mean: -1.98108
[32m[0906 14-16-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36005, current rewards: -2299.00000, mean: -1.98190
[32m[0906 14-17-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36013, current rewards: -2399.00000, mean: -1.98264
[32m[0906 14-17-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36022, current rewards: -2499.00000, mean: -1.98333
[32m[0906 14-17-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36027, current rewards: -2599.00000, mean: -1.98397
[32m[0906 14-18-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36031, current rewards: -2699.00000, mean: -1.98456
[32m[0906 14-18-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36041, current rewards: -2799.00000, mean: -1.98511
[32m[0906 14-18-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36045, current rewards: -2899.00000, mean: -1.98562
[32m[0906 14-19-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36036, current rewards: -2999.00000, mean: -1.98609
[32m[0906 14-19-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36027, current rewards: -3099.00000, mean: -1.98654
[32m[0906 14-19-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36016, current rewards: -3199.00000, mean: -1.98696
[32m[0906 14-19-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36003, current rewards: -3299.00000, mean: -1.98735
[32m[0906 14-20-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35996, current rewards: -3399.00000, mean: -1.98772
[32m[0906 14-20-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35986, current rewards: -3499.00000, mean: -1.98807
[32m[0906 14-20-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35977, current rewards: -3599.00000, mean: -1.98840
[32m[0906 14-21-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35964, current rewards: -3699.00000, mean: -1.98871
[32m[0906 14-21-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35955, current rewards: -3799.00000, mean: -1.98901
[32m[0906 14-21-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35946, current rewards: -3899.00000, mean: -1.98929
[32m[0906 14-22-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35937, current rewards: -3999.00000, mean: -1.98955
[32m[0906 14-22-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35930, current rewards: -4099.00000, mean: -1.98981
[32m[0906 14-22-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35919, current rewards: -4199.00000, mean: -1.99005
[32m[0906 14-22-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35910, current rewards: -4299.00000, mean: -1.99028
[32m[0906 14-23-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35900, current rewards: -4399.00000, mean: -1.99050
[32m[0906 14-23-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35897, current rewards: -4499.00000, mean: -1.99071
[32m[0906 14-23-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35891, current rewards: -4599.00000, mean: -1.99091
[32m[0906 14-24-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35886, current rewards: -4699.00000, mean: -1.99110
[32m[0906 14-24-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35892, current rewards: -4799.00000, mean: -1.99129
[32m[0906 14-24-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35897, current rewards: -4899.00000, mean: -1.99146
[32m[0906 14-24-59 @Agent.py:117][0m Average action selection time: 0.3590
[32m[0906 14-24-59 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-24-59 @MBExp.py:227][0m Rewards obtained: [-4979], Lows: [2479], Highs: [21], Total time: 2690.663461
[32m[0906 14-25-08 @MBExp.py:144][0m ####################################################################
[32m[0906 14-25-08 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 14-25-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36238, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-25-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35567, current rewards: -60.00000, mean: -1.00000
[32m[0906 14-25-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35604, current rewards: -110.00000, mean: -1.00000
[32m[0906 14-26-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35498, current rewards: -160.00000, mean: -1.00000
[32m[0906 14-26-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35512, current rewards: -198.41341, mean: -0.94483
[32m[0906 14-26-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35508, current rewards: -238.93292, mean: -0.91897
[32m[0906 14-26-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35471, current rewards: -288.93292, mean: -0.93204
[32m[0906 14-27-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35462, current rewards: -338.93292, mean: -0.94148
[32m[0906 14-27-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35495, current rewards: -388.93292, mean: -0.94862
[32m[0906 14-27-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35507, current rewards: -438.93292, mean: -0.95420
[32m[0906 14-28-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35516, current rewards: -488.93292, mean: -0.95869
[32m[0906 14-28-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35524, current rewards: -538.93292, mean: -0.96238
[32m[0906 14-28-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35518, current rewards: -588.93292, mean: -0.96546
[32m[0906 14-29-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35516, current rewards: -638.93292, mean: -0.96808
[32m[0906 14-29-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35515, current rewards: -688.93292, mean: -0.97033
[32m[0906 14-29-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35511, current rewards: -738.93292, mean: -0.97228
[32m[0906 14-29-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35531, current rewards: -771.01434, mean: -0.95187
[32m[0906 14-30-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35576, current rewards: -809.76863, mean: -0.94159
[32m[0906 14-30-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35583, current rewards: -803.72336, mean: -0.88321
[32m[0906 14-30-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35579, current rewards: -797.67810, mean: -0.83091
[32m[0906 14-31-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35571, current rewards: -791.63283, mean: -0.78379
[32m[0906 14-31-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35562, current rewards: -785.58757, mean: -0.74112
[32m[0906 14-31-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35556, current rewards: -779.54230, mean: -0.70229
[32m[0906 14-32-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35548, current rewards: -773.49704, mean: -0.66681
[32m[0906 14-32-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35542, current rewards: -767.66450, mean: -0.63443
[32m[0906 14-32-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35539, current rewards: -783.15751, mean: -0.62155
[32m[0906 14-32-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35531, current rewards: -833.15751, mean: -0.63600
[32m[0906 14-33-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35524, current rewards: -883.15751, mean: -0.64938
[32m[0906 14-33-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35518, current rewards: -933.15751, mean: -0.66181
[32m[0906 14-33-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35512, current rewards: -983.15751, mean: -0.67340
[32m[0906 14-34-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35505, current rewards: -1033.15751, mean: -0.68421
[32m[0906 14-34-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35499, current rewards: -1083.15751, mean: -0.69433
[32m[0906 14-34-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35500, current rewards: -1133.15751, mean: -0.70382
[32m[0906 14-34-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35499, current rewards: -1183.15751, mean: -0.71275
[32m[0906 14-35-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35503, current rewards: -1233.15751, mean: -0.72114
[32m[0906 14-35-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35506, current rewards: -1283.15751, mean: -0.72907
[32m[0906 14-35-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35508, current rewards: -1333.15751, mean: -0.73655
[32m[0906 14-36-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35510, current rewards: -1383.15751, mean: -0.74363
[32m[0906 14-36-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35510, current rewards: -1433.15751, mean: -0.75034
[32m[0906 14-36-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35511, current rewards: -1483.15751, mean: -0.75671
[32m[0906 14-37-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35511, current rewards: -1533.15751, mean: -0.76276
[32m[0906 14-37-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35511, current rewards: -1583.15751, mean: -0.76852
[32m[0906 14-37-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35512, current rewards: -1633.15751, mean: -0.77401
[32m[0906 14-37-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35512, current rewards: -1683.15751, mean: -0.77924
[32m[0906 14-38-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35511, current rewards: -1733.15751, mean: -0.78423
[32m[0906 14-38-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35509, current rewards: -1783.15751, mean: -0.78901
[32m[0906 14-38-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35506, current rewards: -1833.15751, mean: -0.79357
[32m[0906 14-39-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35503, current rewards: -1883.15751, mean: -0.79795
[32m[0906 14-39-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35510, current rewards: -1933.15751, mean: -0.80214
[32m[0906 14-39-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35518, current rewards: -1983.15751, mean: -0.80616
[32m[0906 14-39-56 @Agent.py:117][0m Average action selection time: 0.3552
[32m[0906 14-39-56 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-39-56 @MBExp.py:227][0m Rewards obtained: [-2023.1575058801675], Lows: [20], Highs: [2033], Total time: 3579.402459
[32m[0906 14-40-08 @MBExp.py:144][0m ####################################################################
[32m[0906 14-40-08 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 14-40-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36092, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-40-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35608, current rewards: -100.00000, mean: -1.66667
[32m[0906 14-40-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35758, current rewards: -200.00000, mean: -1.81818
[32m[0906 14-41-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35545, current rewards: -300.00000, mean: -1.87500
[32m[0906 14-41-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35526, current rewards: -400.00000, mean: -1.90476
[32m[0906 14-41-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35527, current rewards: -500.00000, mean: -1.92308
[32m[0906 14-41-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35484, current rewards: -600.00000, mean: -1.93548
[32m[0906 14-42-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35452, current rewards: -700.00000, mean: -1.94444
[32m[0906 14-42-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35462, current rewards: -800.00000, mean: -1.95122
[32m[0906 14-42-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35474, current rewards: -900.00000, mean: -1.95652
[32m[0906 14-43-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35450, current rewards: -1000.00000, mean: -1.96078
[32m[0906 14-43-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35445, current rewards: -1100.00000, mean: -1.96429
[32m[0906 14-43-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35430, current rewards: -1200.00000, mean: -1.96721
[32m[0906 14-44-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35417, current rewards: -1300.00000, mean: -1.96970
[32m[0906 14-44-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35409, current rewards: -1400.00000, mean: -1.97183
[32m[0906 14-44-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35405, current rewards: -1500.00000, mean: -1.97368
[32m[0906 14-44-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35406, current rewards: -1600.00000, mean: -1.97531
[32m[0906 14-45-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35422, current rewards: -1700.00000, mean: -1.97674
[32m[0906 14-45-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35430, current rewards: -1800.00000, mean: -1.97802
[32m[0906 14-45-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35433, current rewards: -1900.00000, mean: -1.97917
[32m[0906 14-46-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35443, current rewards: -2000.00000, mean: -1.98020
[32m[0906 14-46-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35470, current rewards: -2100.00000, mean: -1.98113
[32m[0906 14-46-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35492, current rewards: -2200.00000, mean: -1.98198
[32m[0906 14-47-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35531, current rewards: -2300.00000, mean: -1.98276
[32m[0906 14-47-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35561, current rewards: -2400.00000, mean: -1.98347
[32m[0906 14-47-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35571, current rewards: -2500.00000, mean: -1.98413
[32m[0906 14-47-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35578, current rewards: -2600.00000, mean: -1.98473
[32m[0906 14-48-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35593, current rewards: -2700.00000, mean: -1.98529
[32m[0906 14-48-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35605, current rewards: -2800.00000, mean: -1.98582
[32m[0906 14-48-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35615, current rewards: -2900.00000, mean: -1.98630
[32m[0906 14-49-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35628, current rewards: -3000.00000, mean: -1.98675
[32m[0906 14-49-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35641, current rewards: -3100.00000, mean: -1.98718
[32m[0906 14-49-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35664, current rewards: -3200.00000, mean: -1.98758
[32m[0906 14-50-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35690, current rewards: -3300.00000, mean: -1.98795
[32m[0906 14-50-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35715, current rewards: -3400.00000, mean: -1.98830
[32m[0906 14-50-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35739, current rewards: -3500.00000, mean: -1.98864
[32m[0906 14-50-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35761, current rewards: -3600.00000, mean: -1.98895
[32m[0906 14-51-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35785, current rewards: -3700.00000, mean: -1.98925
[32m[0906 14-51-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35797, current rewards: -3800.00000, mean: -1.98953
[32m[0906 14-51-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35800, current rewards: -3900.00000, mean: -1.98980
[32m[0906 14-52-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35803, current rewards: -4000.00000, mean: -1.99005
[32m[0906 14-52-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35796, current rewards: -4100.00000, mean: -1.99029
[32m[0906 14-52-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35784, current rewards: -4200.00000, mean: -1.99052
[32m[0906 14-53-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35774, current rewards: -4300.00000, mean: -1.99074
[32m[0906 14-53-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35762, current rewards: -4400.00000, mean: -1.99095
[32m[0906 14-53-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35752, current rewards: -4500.00000, mean: -1.99115
[32m[0906 14-53-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35748, current rewards: -4600.00000, mean: -1.99134
[32m[0906 14-54-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35739, current rewards: -4700.00000, mean: -1.99153
[32m[0906 14-54-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35743, current rewards: -4800.00000, mean: -1.99170
[32m[0906 14-54-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35746, current rewards: -4900.00000, mean: -1.99187
[32m[0906 14-55-02 @Agent.py:117][0m Average action selection time: 0.3574
[32m[0906 14-55-02 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-55-02 @MBExp.py:227][0m Rewards obtained: [-4980], Lows: [2480], Highs: [20], Total time: 4473.593022999999
[32m[0906 14-55-15 @MBExp.py:144][0m ####################################################################
[32m[0906 14-55-15 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 14-55-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35414, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-55-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34973, current rewards: -58.07280, mean: -0.96788
[32m[0906 14-55-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35320, current rewards: -50.96521, mean: -0.46332
[32m[0906 14-56-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35292, current rewards: -44.63968, mean: -0.27900
[32m[0906 14-56-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35396, current rewards: -38.32208, mean: -0.18249
[32m[0906 14-56-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35480, current rewards: -51.14043, mean: -0.19669
[32m[0906 14-57-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35515, current rewards: -87.42615, mean: -0.28202
[32m[0906 14-57-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35513, current rewards: -82.66842, mean: -0.22963
[32m[0906 14-57-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35619, current rewards: -77.95637, mean: -0.19014
[32m[0906 14-57-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35689, current rewards: -73.24532, mean: -0.15923
[32m[0906 14-58-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35680, current rewards: -68.53501, mean: -0.13438
[32m[0906 14-58-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35661, current rewards: -63.82888, mean: -0.11398
[32m[0906 14-58-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35648, current rewards: -81.09246, mean: -0.13294
[32m[0906 14-59-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35636, current rewards: -77.28756, mean: -0.11710
[32m[0906 14-59-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35631, current rewards: -73.20278, mean: -0.10310
[32m[0906 14-59-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35642, current rewards: -69.11853, mean: -0.09095
[32m[0906 15-00-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35646, current rewards: -64.92333, mean: -0.08015
[32m[0906 15-00-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35672, current rewards: -82.26579, mean: -0.09566
[32m[0906 15-00-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35696, current rewards: -102.69229, mean: -0.11285
[32m[0906 15-00-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35720, current rewards: -129.41029, mean: -0.13480
[32m[0906 15-01-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35749, current rewards: -155.07668, mean: -0.15354
[32m[0906 15-01-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35759, current rewards: -176.50685, mean: -0.16652
[32m[0906 15-01-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35750, current rewards: -205.34504, mean: -0.18500
[32m[0906 15-02-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35744, current rewards: -227.83927, mean: -0.19641
[32m[0906 15-02-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35737, current rewards: -252.44677, mean: -0.20863
[32m[0906 15-02-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35735, current rewards: -280.17817, mean: -0.22236
[32m[0906 15-03-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35729, current rewards: -293.36333, mean: -0.22394
[32m[0906 15-03-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35727, current rewards: -307.01127, mean: -0.22574
[32m[0906 15-03-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35722, current rewards: -329.36248, mean: -0.23359
[32m[0906 15-03-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35733, current rewards: -340.15167, mean: -0.23298
[32m[0906 15-04-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35766, current rewards: -347.60709, mean: -0.23020
[32m[0906 15-04-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35793, current rewards: -365.79701, mean: -0.23449
[32m[0906 15-04-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35819, current rewards: -382.99382, mean: -0.23788
[32m[0906 15-05-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35842, current rewards: -437.24305, mean: -0.26340
[32m[0906 15-05-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35855, current rewards: -436.47916, mean: -0.25525
[32m[0906 15-05-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35849, current rewards: -433.66418, mean: -0.24640
[32m[0906 15-06-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35848, current rewards: -430.84919, mean: -0.23804
[32m[0906 15-06-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35852, current rewards: -428.03421, mean: -0.23013
[32m[0906 15-06-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35842, current rewards: -425.21922, mean: -0.22263
[32m[0906 15-06-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35833, current rewards: -429.79834, mean: -0.21928
[32m[0906 15-07-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35830, current rewards: -479.79834, mean: -0.23871
[32m[0906 15-07-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35826, current rewards: -529.79834, mean: -0.25718
[32m[0906 15-07-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35826, current rewards: -579.79834, mean: -0.27479
[32m[0906 15-08-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35823, current rewards: -629.79834, mean: -0.29157
[32m[0906 15-08-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35826, current rewards: -679.79834, mean: -0.30760
[32m[0906 15-08-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35834, current rewards: -729.79834, mean: -0.32292
[32m[0906 15-09-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35841, current rewards: -779.79834, mean: -0.33758
[32m[0906 15-09-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35833, current rewards: -829.79834, mean: -0.35161
[32m[0906 15-09-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35842, current rewards: -879.79834, mean: -0.36506
[32m[0906 15-09-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35842, current rewards: -929.79834, mean: -0.37797
[32m[0906 15-10-11 @Agent.py:117][0m Average action selection time: 0.3585
[32m[0906 15-10-11 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-10-11 @MBExp.py:227][0m Rewards obtained: [-969.7983352726346], Lows: [53], Highs: [983], Total time: 5370.382667999999
[32m[0906 15-10-27 @MBExp.py:144][0m ####################################################################
[32m[0906 15-10-27 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 15-10-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35444, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-10-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35588, current rewards: -45.22180, mean: -0.75370
[32m[0906 15-11-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35692, current rewards: -65.56360, mean: -0.59603
[32m[0906 15-11-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35520, current rewards: -93.31024, mean: -0.58319
[32m[0906 15-11-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35590, current rewards: -121.05585, mean: -0.57646
[32m[0906 15-12-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35666, current rewards: -144.50270, mean: -0.55578
[32m[0906 15-12-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35708, current rewards: -163.75912, mean: -0.52826
[32m[0906 15-12-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35692, current rewards: -183.08653, mean: -0.50857
[32m[0906 15-12-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35716, current rewards: -208.99049, mean: -0.50973
[32m[0906 15-13-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35741, current rewards: -236.73460, mean: -0.51464
[32m[0906 15-13-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35813, current rewards: -253.91704, mean: -0.49788
[32m[0906 15-13-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35837, current rewards: -271.13032, mean: -0.48416
[32m[0906 15-14-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35831, current rewards: -297.85767, mean: -0.48829
[32m[0906 15-14-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35820, current rewards: -325.63166, mean: -0.49338
[32m[0906 15-14-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35816, current rewards: -344.92921, mean: -0.48582
[32m[0906 15-14-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35808, current rewards: -415.12082, mean: -0.54621
[32m[0906 15-15-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35811, current rewards: -487.52837, mean: -0.60189
[32m[0906 15-15-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35816, current rewards: -549.83770, mean: -0.63935
[32m[0906 15-15-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35826, current rewards: -599.58817, mean: -0.65889
[32m[0906 15-16-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35850, current rewards: -655.59357, mean: -0.68291
[32m[0906 15-16-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35874, current rewards: -715.81555, mean: -0.70873
[32m[0906 15-16-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35900, current rewards: -761.34620, mean: -0.71825
[32m[0906 15-17-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35934, current rewards: -823.64704, mean: -0.74202
[32m[0906 15-17-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35956, current rewards: -877.58781, mean: -0.75654
[32m[0906 15-17-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35956, current rewards: -929.39837, mean: -0.76810
[32m[0906 15-18-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35957, current rewards: -991.70103, mean: -0.78706
[32m[0906 15-18-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35968, current rewards: -1051.92293, mean: -0.80299
[32m[0906 15-18-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35974, current rewards: -1149.60092, mean: -0.84529
[32m[0906 15-18-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35962, current rewards: -1249.60092, mean: -0.88624
[32m[0906 15-19-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35948, current rewards: -1349.60092, mean: -0.92438
[32m[0906 15-19-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35938, current rewards: -1449.60092, mean: -0.96000
[32m[0906 15-19-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35930, current rewards: -1549.60092, mean: -0.99333
[32m[0906 15-20-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35922, current rewards: -1649.60092, mean: -1.02460
[32m[0906 15-20-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35918, current rewards: -1749.60092, mean: -1.05398
[32m[0906 15-20-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35913, current rewards: -1849.60092, mean: -1.08164
[32m[0906 15-20-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35907, current rewards: -1949.60092, mean: -1.10773
[32m[0906 15-21-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35901, current rewards: -2049.60092, mean: -1.13238
[32m[0906 15-21-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35894, current rewards: -2149.60092, mean: -1.15570
[32m[0906 15-21-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35889, current rewards: -2249.60092, mean: -1.17780
[32m[0906 15-22-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35882, current rewards: -2349.60092, mean: -1.19878
[32m[0906 15-22-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35877, current rewards: -2416.77812, mean: -1.20238
[32m[0906 15-22-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35873, current rewards: -2417.79177, mean: -1.17369
[32m[0906 15-23-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35869, current rewards: -2417.15910, mean: -1.14557
[32m[0906 15-23-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35864, current rewards: -2416.52408, mean: -1.11876
[32m[0906 15-23-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35864, current rewards: -2418.04359, mean: -1.09414
[32m[0906 15-23-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35864, current rewards: -2417.42223, mean: -1.06966
[32m[0906 15-24-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35858, current rewards: -2420.42696, mean: -1.04780
[32m[0906 15-24-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35839, current rewards: -2421.30727, mean: -1.02598
[32m[0906 15-24-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35841, current rewards: -2422.10449, mean: -1.00502
[32m[0906 15-25-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35838, current rewards: -2425.33198, mean: -0.98591
[32m[0906 15-25-23 @Agent.py:117][0m Average action selection time: 0.3583
[32m[0906 15-25-23 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-25-23 @MBExp.py:227][0m Rewards obtained: [-2427.0301031143695], Lows: [1073], Highs: [368], Total time: 6266.872385999999
[32m[0906 15-25-41 @MBExp.py:144][0m ####################################################################
[32m[0906 15-25-41 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 15-25-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34845, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-26-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35231, current rewards: -41.01683, mean: -0.68361
[32m[0906 15-26-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35329, current rewards: -91.01683, mean: -0.82743
[32m[0906 15-26-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35323, current rewards: -141.01683, mean: -0.88136
[32m[0906 15-26-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35485, current rewards: -191.01683, mean: -0.90960
[32m[0906 15-27-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35559, current rewards: -241.01683, mean: -0.92699
[32m[0906 15-27-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35586, current rewards: -291.01683, mean: -0.93876
[32m[0906 15-27-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35537, current rewards: -341.01683, mean: -0.94727
[32m[0906 15-28-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35589, current rewards: -391.01683, mean: -0.95370
[32m[0906 15-28-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35632, current rewards: -441.01683, mean: -0.95873
[32m[0906 15-28-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35653, current rewards: -491.01683, mean: -0.96278
[32m[0906 15-29-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35675, current rewards: -541.01683, mean: -0.96610
[32m[0906 15-29-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35688, current rewards: -591.01683, mean: -0.96888
[32m[0906 15-29-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35694, current rewards: -641.01683, mean: -0.97124
[32m[0906 15-29-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35706, current rewards: -691.01683, mean: -0.97326
[32m[0906 15-30-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35721, current rewards: -741.01683, mean: -0.97502
[32m[0906 15-30-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35722, current rewards: -791.01683, mean: -0.97656
[32m[0906 15-30-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35722, current rewards: -841.01683, mean: -0.97793
[32m[0906 15-31-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35726, current rewards: -891.01683, mean: -0.97914
[32m[0906 15-31-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35737, current rewards: -941.01683, mean: -0.98023
[32m[0906 15-31-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35764, current rewards: -967.55304, mean: -0.95797
[32m[0906 15-32-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35770, current rewards: -987.01954, mean: -0.93115
[32m[0906 15-32-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35792, current rewards: -1006.49680, mean: -0.90675
[32m[0906 15-32-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35813, current rewards: -1030.18405, mean: -0.88809
[32m[0906 15-32-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35836, current rewards: -1044.09871, mean: -0.86289
[32m[0906 15-33-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35859, current rewards: -1056.15546, mean: -0.83822
[32m[0906 15-33-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35876, current rewards: -1073.55316, mean: -0.81951
[32m[0906 15-33-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35895, current rewards: -1089.79368, mean: -0.80132
[32m[0906 15-34-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35894, current rewards: -1102.95793, mean: -0.78224
[32m[0906 15-34-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35888, current rewards: -1152.92848, mean: -0.78968
[32m[0906 15-34-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35890, current rewards: -1172.16285, mean: -0.77627
[32m[0906 15-35-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35892, current rewards: -1197.01382, mean: -0.76732
[32m[0906 15-35-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35877, current rewards: -1241.76931, mean: -0.77129
[32m[0906 15-35-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35870, current rewards: -1291.76931, mean: -0.77817
[32m[0906 15-35-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35864, current rewards: -1339.67212, mean: -0.78343
[32m[0906 15-36-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35859, current rewards: -1389.67212, mean: -0.78959
[32m[0906 15-36-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35852, current rewards: -1439.67212, mean: -0.79540
[32m[0906 15-36-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35852, current rewards: -1489.67212, mean: -0.80090
[32m[0906 15-37-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35847, current rewards: -1539.67212, mean: -0.80611
[32m[0906 15-37-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35845, current rewards: -1589.67212, mean: -0.81106
[32m[0906 15-37-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35846, current rewards: -1635.47160, mean: -0.81367
[32m[0906 15-38-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35843, current rewards: -1677.05115, mean: -0.81410
[32m[0906 15-38-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35827, current rewards: -1743.64969, mean: -0.82637
[32m[0906 15-38-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35811, current rewards: -1737.19084, mean: -0.80426
[32m[0906 15-38-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35778, current rewards: -1730.73201, mean: -0.78314
[32m[0906 15-39-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35681, current rewards: -1724.27319, mean: -0.76295
[32m[0906 15-39-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35588, current rewards: -1738.13954, mean: -0.75244
[32m[0906 15-39-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35489, current rewards: -1788.13954, mean: -0.75769
[32m[0906 15-39-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35405, current rewards: -1838.13954, mean: -0.76271
[32m[0906 15-40-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35326, current rewards: -1888.13954, mean: -0.76754
[32m[0906 15-40-23 @Agent.py:117][0m Average action selection time: 0.3527
[32m[0906 15-40-23 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-40-23 @MBExp.py:227][0m Rewards obtained: [-1928.1395416682326], Lows: [40], Highs: [1893], Total time: 7149.164343999999
[32m[0906 15-40-40 @MBExp.py:144][0m ####################################################################
[32m[0906 15-40-40 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 15-40-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30876, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-40-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31223, current rewards: -16.59161, mean: -0.27653
[32m[0906 15-41-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31269, current rewards: -11.75449, mean: -0.10686
[32m[0906 15-41-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31329, current rewards: -6.91416, mean: -0.04321
[32m[0906 15-41-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31393, current rewards: -2.07609, mean: -0.00989
[32m[0906 15-42-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31426, current rewards: 2.75965, mean: 0.01061
[32m[0906 15-42-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31427, current rewards: 7.60041, mean: 0.02452
[32m[0906 15-42-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31374, current rewards: 12.30601, mean: 0.03418
[32m[0906 15-42-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31410, current rewards: 17.06074, mean: 0.04161
[32m[0906 15-43-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31442, current rewards: 22.08316, mean: 0.04801
[32m[0906 15-43-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31470, current rewards: 27.14918, mean: 0.05323
[32m[0906 15-43-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31483, current rewards: 32.21302, mean: 0.05752
[32m[0906 15-43-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31501, current rewards: 37.27475, mean: 0.06111
[32m[0906 15-44-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31535, current rewards: -7.85064, mean: -0.01189
[32m[0906 15-44-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31543, current rewards: -30.47419, mean: -0.04292
[32m[0906 15-44-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31545, current rewards: -74.58967, mean: -0.09814
[32m[0906 15-44-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31557, current rewards: -158.01343, mean: -0.19508
[32m[0906 15-45-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31568, current rewards: -195.00518, mean: -0.22675
[32m[0906 15-45-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31573, current rewards: -229.81826, mean: -0.25255
[32m[0906 15-45-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31577, current rewards: -260.28835, mean: -0.27113
[32m[0906 15-45-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31584, current rewards: -273.38350, mean: -0.27068
[32m[0906 15-46-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31586, current rewards: -312.04156, mean: -0.29438
[32m[0906 15-46-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31583, current rewards: -392.11090, mean: -0.35325
[32m[0906 15-46-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31580, current rewards: -481.81424, mean: -0.41536
[32m[0906 15-47-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31581, current rewards: -547.93253, mean: -0.45284
[32m[0906 15-47-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31581, current rewards: -584.57070, mean: -0.46395
[32m[0906 15-47-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31581, current rewards: -631.90499, mean: -0.48237
[32m[0906 15-47-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31589, current rewards: -685.75303, mean: -0.50423
[32m[0906 15-48-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31587, current rewards: -739.58895, mean: -0.52453
[32m[0906 15-48-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31587, current rewards: -776.22347, mean: -0.53166
[32m[0906 15-48-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31590, current rewards: -812.24066, mean: -0.53791
[32m[0906 15-48-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31589, current rewards: -854.89016, mean: -0.54801
[32m[0906 15-49-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31591, current rewards: -908.75053, mean: -0.56444
[32m[0906 15-49-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31590, current rewards: -963.32215, mean: -0.58031
[32m[0906 15-49-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31587, current rewards: -1006.83236, mean: -0.58879
[32m[0906 15-49-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31586, current rewards: -1067.70316, mean: -0.60665
[32m[0906 15-50-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31586, current rewards: -1127.53905, mean: -0.62295
[32m[0906 15-50-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31594, current rewards: -1187.36424, mean: -0.63837
[32m[0906 15-50-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31597, current rewards: -1237.19068, mean: -0.64774
[32m[0906 15-51-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31595, current rewards: -1280.61836, mean: -0.65338
[32m[0906 15-51-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31594, current rewards: -1336.39832, mean: -0.66487
[32m[0906 15-51-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31594, current rewards: -1398.44813, mean: -0.67886
[32m[0906 15-51-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31591, current rewards: -1457.38175, mean: -0.69070
[32m[0906 15-52-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31590, current rewards: -1506.14691, mean: -0.69729
[32m[0906 15-52-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31588, current rewards: -1553.83704, mean: -0.70309
[32m[0906 15-52-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31589, current rewards: -1607.58096, mean: -0.71132
[32m[0906 15-52-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31588, current rewards: -1669.61613, mean: -0.72278
[32m[0906 15-53-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31571, current rewards: -1730.60571, mean: -0.73331
[32m[0906 15-53-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31571, current rewards: -1771.35261, mean: -0.73500
[32m[0906 15-53-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31573, current rewards: -1821.06634, mean: -0.74027
[32m[0906 15-53-50 @Agent.py:117][0m Average action selection time: 0.3157
[32m[0906 15-53-50 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-53-50 @MBExp.py:227][0m Rewards obtained: [-1818.6076132427943], Lows: [933], Highs: [145], Total time: 7939.035754999999
[32m[0906 15-54-09 @MBExp.py:144][0m ####################################################################
[32m[0906 15-54-09 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 15-54-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30925, current rewards: -7.90174, mean: -0.79017
[32m[0906 15-54-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31234, current rewards: -43.75587, mean: -0.72926
[32m[0906 15-54-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31204, current rewards: -84.83489, mean: -0.77123
[32m[0906 15-54-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31196, current rewards: -133.01692, mean: -0.83136
[32m[0906 15-55-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31294, current rewards: -187.64208, mean: -0.89353
[32m[0906 15-55-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31351, current rewards: -237.98290, mean: -0.91532
[32m[0906 15-55-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31402, current rewards: -275.37533, mean: -0.88831
[32m[0906 15-56-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31337, current rewards: -314.76825, mean: -0.87436
[32m[0906 15-56-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31382, current rewards: -360.58261, mean: -0.87947
[32m[0906 15-56-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31405, current rewards: -415.14113, mean: -0.90248
[32m[0906 15-56-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31436, current rewards: -447.64347, mean: -0.87773
[32m[0906 15-57-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31464, current rewards: -485.08122, mean: -0.86622
[32m[0906 15-57-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31480, current rewards: -521.10086, mean: -0.85426
[32m[0906 15-57-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31498, current rewards: -556.87469, mean: -0.84375
[32m[0906 15-57-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31517, current rewards: -592.67213, mean: -0.83475
[32m[0906 15-58-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31517, current rewards: -616.05901, mean: -0.81060
[32m[0906 15-58-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31529, current rewards: -647.76451, mean: -0.79971
[32m[0906 15-58-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31531, current rewards: -669.02926, mean: -0.77794
[32m[0906 15-58-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31531, current rewards: -693.15511, mean: -0.76171
[32m[0906 15-59-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31528, current rewards: -773.49496, mean: -0.80572
[32m[0906 15-59-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31532, current rewards: -763.95691, mean: -0.75639
[32m[0906 15-59-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31534, current rewards: -754.03372, mean: -0.71135
[32m[0906 15-59-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31532, current rewards: -744.12174, mean: -0.67038
[32m[0906 16-00-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31531, current rewards: -734.20540, mean: -0.63294
[32m[0906 16-00-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31531, current rewards: -722.24839, mean: -0.59690
[32m[0906 16-00-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31529, current rewards: -707.73522, mean: -0.56169
[32m[0906 16-01-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31527, current rewards: -695.06885, mean: -0.53059
[32m[0906 16-01-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31527, current rewards: -728.56439, mean: -0.53571
[32m[0906 16-01-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31524, current rewards: -765.97483, mean: -0.54324
[32m[0906 16-01-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31519, current rewards: -800.46757, mean: -0.54827
[32m[0906 16-02-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31518, current rewards: -837.60610, mean: -0.55471
[32m[0906 16-02-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31524, current rewards: -879.38687, mean: -0.56371
[32m[0906 16-02-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31526, current rewards: -920.35364, mean: -0.57165
[32m[0906 16-02-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31523, current rewards: -965.74515, mean: -0.58177
[32m[0906 16-03-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31521, current rewards: -1001.10642, mean: -0.58544
[32m[0906 16-03-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31521, current rewards: -996.52262, mean: -0.56621
[32m[0906 16-03-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31520, current rewards: -991.82718, mean: -0.54797
[32m[0906 16-03-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31518, current rewards: -987.13453, mean: -0.53072
[32m[0906 16-04-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31517, current rewards: -982.44108, mean: -0.51437
[32m[0906 16-04-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31514, current rewards: -977.75045, mean: -0.49885
[32m[0906 16-04-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31513, current rewards: -977.62448, mean: -0.48638
[32m[0906 16-04-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31512, current rewards: -988.70029, mean: -0.47995
[32m[0906 16-05-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31512, current rewards: -984.97107, mean: -0.46681
[32m[0906 16-05-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31515, current rewards: -981.31071, mean: -0.45431
[32m[0906 16-05-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31515, current rewards: -977.65349, mean: -0.44238
[32m[0906 16-06-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31515, current rewards: -973.99636, mean: -0.43097
[32m[0906 16-06-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31512, current rewards: -970.34035, mean: -0.42006
[32m[0906 16-06-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31498, current rewards: -966.68395, mean: -0.40961
[32m[0906 16-06-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31499, current rewards: -963.02360, mean: -0.39959
[32m[0906 16-07-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31501, current rewards: -959.36719, mean: -0.38999
[32m[0906 16-07-17 @Agent.py:117][0m Average action selection time: 0.3150
[32m[0906 16-07-17 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-07-17 @MBExp.py:227][0m Rewards obtained: [-968.8797176732188], Lows: [604], Highs: [48], Total time: 8727.149359
[32m[0906 16-07-38 @MBExp.py:144][0m ####################################################################
[32m[0906 16-07-38 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 16-07-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30838, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-07-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31319, current rewards: -31.41244, mean: -0.52354
[32m[0906 16-08-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31224, current rewards: -39.31270, mean: -0.35739
[32m[0906 16-08-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31240, current rewards: -62.46174, mean: -0.39039
[32m[0906 16-08-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31402, current rewards: -84.08872, mean: -0.40042
[32m[0906 16-08-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31455, current rewards: -103.38895, mean: -0.39765
[32m[0906 16-09-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31419, current rewards: -138.71010, mean: -0.44745
[32m[0906 16-09-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31354, current rewards: -174.05031, mean: -0.48347
[32m[0906 16-09-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31384, current rewards: -201.59196, mean: -0.49169
[32m[0906 16-10-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31402, current rewards: -250.32616, mean: -0.54419
[32m[0906 16-10-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31443, current rewards: -292.12932, mean: -0.57280
[32m[0906 16-10-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31451, current rewards: -308.22602, mean: -0.55040
[32m[0906 16-10-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31464, current rewards: -300.13571, mean: -0.49203
[32m[0906 16-11-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31480, current rewards: -292.04617, mean: -0.44249
[32m[0906 16-11-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31488, current rewards: -283.95388, mean: -0.39994
[32m[0906 16-11-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31507, current rewards: -277.61591, mean: -0.36528
[32m[0906 16-11-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31513, current rewards: -271.81621, mean: -0.33558
[32m[0906 16-12-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31512, current rewards: -265.67775, mean: -0.30893
[32m[0906 16-12-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31513, current rewards: -259.55135, mean: -0.28522
[32m[0906 16-12-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31512, current rewards: -253.42633, mean: -0.26399
[32m[0906 16-12-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31517, current rewards: -247.29824, mean: -0.24485
[32m[0906 16-13-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31519, current rewards: -265.74450, mean: -0.25070
[32m[0906 16-13-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31519, current rewards: -258.33706, mean: -0.23274
[32m[0906 16-13-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31515, current rewards: -252.45153, mean: -0.21763
[32m[0906 16-13-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31515, current rewards: -255.13153, mean: -0.21085
[32m[0906 16-14-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31518, current rewards: -247.59209, mean: -0.19650
[32m[0906 16-14-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31517, current rewards: -240.02039, mean: -0.18322
[32m[0906 16-14-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31514, current rewards: -266.86465, mean: -0.19622
[32m[0906 16-15-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31511, current rewards: -269.29133, mean: -0.19099
[32m[0906 16-15-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31511, current rewards: -263.72146, mean: -0.18063
[32m[0906 16-15-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31513, current rewards: -258.14714, mean: -0.17096
[32m[0906 16-15-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31515, current rewards: -252.57440, mean: -0.16191
[32m[0906 16-16-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31513, current rewards: -247.90369, mean: -0.15398
[32m[0906 16-16-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31513, current rewards: -243.97636, mean: -0.14697
[32m[0906 16-16-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31510, current rewards: -240.04085, mean: -0.14037
[32m[0906 16-16-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31511, current rewards: -236.10476, mean: -0.13415
[32m[0906 16-17-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31509, current rewards: -234.24707, mean: -0.12942
[32m[0906 16-17-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31508, current rewards: -267.42121, mean: -0.14377
[32m[0906 16-17-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31507, current rewards: -255.89339, mean: -0.13398
[32m[0906 16-17-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31505, current rewards: -244.59722, mean: -0.12479
[32m[0906 16-18-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31505, current rewards: -230.94412, mean: -0.11490
[32m[0906 16-18-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31511, current rewards: -213.34351, mean: -0.10356
[32m[0906 16-18-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31514, current rewards: -198.99970, mean: -0.09431
[32m[0906 16-18-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31515, current rewards: -184.63206, mean: -0.08548
[32m[0906 16-19-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31514, current rewards: -170.28930, mean: -0.07705
[32m[0906 16-19-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31512, current rewards: -155.94507, mean: -0.06900
[32m[0906 16-19-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31511, current rewards: -141.61358, mean: -0.06130
[32m[0906 16-20-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31496, current rewards: -152.74020, mean: -0.06472
[32m[0906 16-20-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31494, current rewards: -140.61186, mean: -0.05835
[32m[0906 16-20-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31495, current rewards: -188.91021, mean: -0.07679
[32m[0906 16-20-46 @Agent.py:117][0m Average action selection time: 0.3150
[32m[0906 16-20-46 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-20-46 @MBExp.py:227][0m Rewards obtained: [-204.07984783844915], Lows: [281], Highs: [61], Total time: 9515.118896
[32m[0906 16-21-08 @MBExp.py:144][0m ####################################################################
[32m[0906 16-21-08 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 16-21-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30848, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-21-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31342, current rewards: -16.42018, mean: -0.27367
[32m[0906 16-21-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31154, current rewards: -10.66178, mean: -0.09693
[32m[0906 16-21-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31167, current rewards: -4.90389, mean: -0.03065
[32m[0906 16-22-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31275, current rewards: 0.83897, mean: 0.00400
[32m[0906 16-22-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31334, current rewards: 6.59548, mean: 0.02537
[32m[0906 16-22-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31342, current rewards: 12.34566, mean: 0.03982
[32m[0906 16-23-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31280, current rewards: 26.72611, mean: 0.07424
[32m[0906 16-23-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31308, current rewards: 32.99405, mean: 0.08047
[32m[0906 16-23-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31330, current rewards: 38.75913, mean: 0.08426
[32m[0906 16-23-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31371, current rewards: 44.53593, mean: 0.08733
[32m[0906 16-24-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31383, current rewards: 50.29697, mean: 0.08982
[32m[0906 16-24-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31390, current rewards: 56.05930, mean: 0.09190
[32m[0906 16-24-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31407, current rewards: 61.82023, mean: 0.09367
[32m[0906 16-24-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31413, current rewards: 67.58084, mean: 0.09518
[32m[0906 16-25-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31425, current rewards: 73.00982, mean: 0.09607
[32m[0906 16-25-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31428, current rewards: 38.43653, mean: 0.04745
[32m[0906 16-25-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31430, current rewards: 44.96794, mean: 0.05229
[32m[0906 16-25-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31436, current rewards: 51.34616, mean: 0.05642
[32m[0906 16-26-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31440, current rewards: 57.72440, mean: 0.06013
[32m[0906 16-26-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31438, current rewards: 64.10419, mean: 0.06347
[32m[0906 16-26-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31455, current rewards: 60.33639, mean: 0.05692
[32m[0906 16-26-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31455, current rewards: 53.61865, mean: 0.04831
[32m[0906 16-27-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31459, current rewards: 58.91791, mean: 0.05079
[32m[0906 16-27-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31462, current rewards: 65.55154, mean: 0.05417
[32m[0906 16-27-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31464, current rewards: 70.90674, mean: 0.05628
[32m[0906 16-28-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31465, current rewards: 76.26378, mean: 0.05822
[32m[0906 16-28-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31464, current rewards: 80.84315, mean: 0.05944
[32m[0906 16-28-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31464, current rewards: 84.43126, mean: 0.05988
[32m[0906 16-28-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31463, current rewards: 88.03286, mean: 0.06030
[32m[0906 16-29-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31459, current rewards: 91.63578, mean: 0.06069
[32m[0906 16-29-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31457, current rewards: 95.23986, mean: 0.06105
[32m[0906 16-29-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31455, current rewards: 98.89845, mean: 0.06143
[32m[0906 16-29-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31453, current rewards: 102.51907, mean: 0.06176
[32m[0906 16-30-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31451, current rewards: 106.13912, mean: 0.06207
[32m[0906 16-30-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31447, current rewards: 109.76178, mean: 0.06236
[32m[0906 16-30-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31446, current rewards: 113.38706, mean: 0.06264
[32m[0906 16-30-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31443, current rewards: 117.01106, mean: 0.06291
[32m[0906 16-31-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31442, current rewards: 81.68412, mean: 0.04277
[32m[0906 16-31-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31442, current rewards: 90.27179, mean: 0.04606
[32m[0906 16-31-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31446, current rewards: 107.93445, mean: 0.05370
[32m[0906 16-31-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31446, current rewards: 117.10035, mean: 0.05684
[32m[0906 16-32-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31445, current rewards: 126.27853, mean: 0.05985
[32m[0906 16-32-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31442, current rewards: 135.45491, mean: 0.06271
[32m[0906 16-32-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31443, current rewards: 144.63666, mean: 0.06545
[32m[0906 16-32-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31445, current rewards: 153.81245, mean: 0.06806
[32m[0906 16-33-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31444, current rewards: 162.98615, mean: 0.07056
[32m[0906 16-33-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31429, current rewards: 172.15742, mean: 0.07295
[32m[0906 16-33-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31422, current rewards: 136.56668, mean: 0.05667
[32m[0906 16-34-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31426, current rewards: 146.63054, mean: 0.05961
[32m[0906 16-34-14 @Agent.py:117][0m Average action selection time: 0.3143
[32m[0906 16-34-14 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-34-14 @MBExp.py:227][0m Rewards obtained: [154.7489815080635], Lows: [59], Highs: [41], Total time: 10301.37818
[32m[0906 16-34-39 @MBExp.py:144][0m ####################################################################
[32m[0906 16-34-39 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 16-34-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30939, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-34-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31402, current rewards: -39.98590, mean: -0.66643
[32m[0906 16-35-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31161, current rewards: -76.26579, mean: -0.69333
[32m[0906 16-35-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31191, current rewards: -112.54663, mean: -0.70342
[32m[0906 16-35-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31355, current rewards: -147.76116, mean: -0.70362
[32m[0906 16-36-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31409, current rewards: -182.98723, mean: -0.70380
[32m[0906 16-36-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31408, current rewards: -220.04648, mean: -0.70983
[32m[0906 16-36-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31339, current rewards: -258.41307, mean: -0.71781
[32m[0906 16-36-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31360, current rewards: -292.51800, mean: -0.71346
[32m[0906 16-37-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31401, current rewards: -323.42162, mean: -0.70309
[32m[0906 16-37-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31434, current rewards: -365.95194, mean: -0.71755
[32m[0906 16-37-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31476, current rewards: -399.01352, mean: -0.71252
[32m[0906 16-37-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31495, current rewards: -428.84438, mean: -0.70302
[32m[0906 16-38-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31511, current rewards: -453.97868, mean: -0.68785
[32m[0906 16-38-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31517, current rewards: -448.28976, mean: -0.63139
[32m[0906 16-38-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31523, current rewards: -442.57741, mean: -0.58234
[32m[0906 16-38-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31532, current rewards: -436.86978, mean: -0.53935
[32m[0906 16-39-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31539, current rewards: -431.16402, mean: -0.50135
[32m[0906 16-39-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31545, current rewards: -425.45599, mean: -0.46753
[32m[0906 16-39-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31547, current rewards: -419.75304, mean: -0.43724
[32m[0906 16-39-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31548, current rewards: -414.04194, mean: -0.40994
[32m[0906 16-40-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31550, current rewards: -408.33447, mean: -0.38522
[32m[0906 16-40-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31551, current rewards: -419.75639, mean: -0.37816
[32m[0906 16-40-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31552, current rewards: -440.99281, mean: -0.38017
[32m[0906 16-41-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31558, current rewards: -435.63171, mean: -0.36003
[32m[0906 16-41-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31554, current rewards: -430.28484, mean: -0.34150
[32m[0906 16-41-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31556, current rewards: -424.94140, mean: -0.32438
[32m[0906 16-41-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31557, current rewards: -419.59354, mean: -0.30852
[32m[0906 16-42-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31557, current rewards: -414.24593, mean: -0.29379
[32m[0906 16-42-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31556, current rewards: -408.90154, mean: -0.28007
[32m[0906 16-42-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31553, current rewards: -403.55573, mean: -0.26726
[32m[0906 16-42-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31550, current rewards: -397.93066, mean: -0.25508
[32m[0906 16-43-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31547, current rewards: -392.70955, mean: -0.24392
[32m[0906 16-43-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31544, current rewards: -387.48907, mean: -0.23343
[32m[0906 16-43-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31541, current rewards: -382.27055, mean: -0.22355
[32m[0906 16-43-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31539, current rewards: -377.05020, mean: -0.21423
[32m[0906 16-44-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31537, current rewards: -371.82911, mean: -0.20543
[32m[0906 16-44-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31535, current rewards: -366.60542, mean: -0.19710
[32m[0906 16-44-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31534, current rewards: -361.38687, mean: -0.18921
[32m[0906 16-44-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31531, current rewards: -371.69126, mean: -0.18964
[32m[0906 16-45-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31529, current rewards: -368.19246, mean: -0.18318
[32m[0906 16-45-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31531, current rewards: -387.00770, mean: -0.18787
[32m[0906 16-45-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31529, current rewards: -383.44960, mean: -0.18173
[32m[0906 16-46-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31528, current rewards: -379.90720, mean: -0.17588
[32m[0906 16-46-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31527, current rewards: -376.36804, mean: -0.17030
[32m[0906 16-46-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31525, current rewards: -413.93668, mean: -0.18316
[32m[0906 16-46-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31526, current rewards: -409.00677, mean: -0.17706
[32m[0906 16-47-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31512, current rewards: -411.39310, mean: -0.17432
[32m[0906 16-47-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31503, current rewards: -419.20598, mean: -0.17394
[32m[0906 16-47-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31505, current rewards: -416.01354, mean: -0.16911
[32m[0906 16-47-47 @Agent.py:117][0m Average action selection time: 0.3151
[32m[0906 16-47-47 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-47-47 @MBExp.py:227][0m Rewards obtained: [-413.4490159316181], Lows: [55], Highs: [506], Total time: 11089.64425
[32m[0906 16-48-13 @MBExp.py:144][0m ####################################################################
[32m[0906 16-48-13 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 16-48-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30984, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-48-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31297, current rewards: -17.33222, mean: -0.28887
[32m[0906 16-48-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31085, current rewards: -12.47004, mean: -0.11336
[32m[0906 16-49-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31179, current rewards: -7.60641, mean: -0.04754
[32m[0906 16-49-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31286, current rewards: -2.74391, mean: -0.01307
[32m[0906 16-49-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31350, current rewards: 2.11260, mean: 0.00813
[32m[0906 16-49-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31363, current rewards: -6.34059, mean: -0.02045
[32m[0906 16-50-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31306, current rewards: -3.09373, mean: -0.00859
[32m[0906 16-50-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31309, current rewards: 0.12971, mean: 0.00032
[32m[0906 16-50-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31342, current rewards: 3.35461, mean: 0.00729
[32m[0906 16-50-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31377, current rewards: 6.57529, mean: 0.01289
[32m[0906 16-51-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31395, current rewards: 9.79709, mean: 0.01749
[32m[0906 16-51-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31419, current rewards: 13.01550, mean: 0.02134
[32m[0906 16-51-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31429, current rewards: -6.47397, mean: -0.00981
[32m[0906 16-51-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31441, current rewards: -39.36839, mean: -0.05545
[32m[0906 16-52-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31452, current rewards: -33.80727, mean: -0.04448
[32m[0906 16-52-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31460, current rewards: -28.82078, mean: -0.03558
[32m[0906 16-52-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31468, current rewards: -23.83776, mean: -0.02772
[32m[0906 16-53-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31467, current rewards: -18.84769, mean: -0.02071
[32m[0906 16-53-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31469, current rewards: -13.86278, mean: -0.01444
[32m[0906 16-53-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31470, current rewards: -8.87955, mean: -0.00879
[32m[0906 16-53-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31472, current rewards: -3.89056, mean: -0.00367
[32m[0906 16-54-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31474, current rewards: 1.09911, mean: 0.00099
[32m[0906 16-54-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31476, current rewards: 6.08711, mean: 0.00525
[32m[0906 16-54-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31477, current rewards: 11.07444, mean: 0.00915
[32m[0906 16-54-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31477, current rewards: -5.87485, mean: -0.00466
[32m[0906 16-55-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31480, current rewards: -0.03354, mean: -0.00003
[32m[0906 16-55-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31477, current rewards: 5.88142, mean: 0.00432
[32m[0906 16-55-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31473, current rewards: 11.80165, mean: 0.00837
[32m[0906 16-55-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31474, current rewards: 17.71766, mean: 0.01214
[32m[0906 16-56-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31474, current rewards: 23.38565, mean: 0.01549
[32m[0906 16-56-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31471, current rewards: 28.56136, mean: 0.01831
[32m[0906 16-56-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31467, current rewards: 34.16213, mean: 0.02122
[32m[0906 16-56-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31466, current rewards: 39.76903, mean: 0.02396
[32m[0906 16-57-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31463, current rewards: 45.36735, mean: 0.02653
[32m[0906 16-57-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31464, current rewards: 50.95796, mean: 0.02895
[32m[0906 16-57-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31463, current rewards: 56.55395, mean: 0.03125
[32m[0906 16-57-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31461, current rewards: 19.00889, mean: 0.01022
[32m[0906 16-58-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31461, current rewards: 22.58761, mean: 0.01183
[32m[0906 16-58-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31457, current rewards: 25.59946, mean: 0.01306
[32m[0906 16-58-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31455, current rewards: 28.81647, mean: 0.01434
[32m[0906 16-59-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31454, current rewards: 32.03343, mean: 0.01555
[32m[0906 16-59-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31452, current rewards: 35.25150, mean: 0.01671
[32m[0906 16-59-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31452, current rewards: 38.46871, mean: 0.01781
[32m[0906 16-59-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31451, current rewards: 41.68553, mean: 0.01886
[32m[0906 17-00-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31451, current rewards: 18.58150, mean: 0.00822
[32m[0906 17-00-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31450, current rewards: 4.81140, mean: 0.00208
[32m[0906 17-00-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31436, current rewards: 9.30365, mean: 0.00394
[32m[0906 17-00-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31424, current rewards: 13.13451, mean: 0.00545
[32m[0906 17-01-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31429, current rewards: 17.00449, mean: 0.00691
[32m[0906 17-01-20 @Agent.py:117][0m Average action selection time: 0.3143
[32m[0906 17-01-20 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-01-20 @MBExp.py:227][0m Rewards obtained: [20.107607134982622], Lows: [45], Highs: [104], Total time: 11875.998716999999
[32m[0906 17-01-47 @MBExp.py:144][0m ####################################################################
[32m[0906 17-01-47 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 17-01-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30750, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-02-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31259, current rewards: -16.43281, mean: -0.27388
[32m[0906 17-02-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31090, current rewards: -10.47141, mean: -0.09519
[32m[0906 17-02-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31176, current rewards: -4.47157, mean: -0.02795
[32m[0906 17-02-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31306, current rewards: 1.52541, mean: 0.00726
[32m[0906 17-03-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31339, current rewards: 7.52297, mean: 0.02893
[32m[0906 17-03-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31348, current rewards: 13.52362, mean: 0.04362
[32m[0906 17-03-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31285, current rewards: 19.52607, mean: 0.05424
[32m[0906 17-03-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31293, current rewards: 25.52449, mean: 0.06225
[32m[0906 17-04-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31331, current rewards: 31.52233, mean: 0.06853
[32m[0906 17-04-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31357, current rewards: -5.18246, mean: -0.01016
[32m[0906 17-04-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31379, current rewards: 0.92326, mean: 0.00165
[32m[0906 17-04-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31395, current rewards: 6.97912, mean: 0.01144
[32m[0906 17-05-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31404, current rewards: 13.76559, mean: 0.02086
[32m[0906 17-05-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31409, current rewards: 4.49245, mean: 0.00633
[32m[0906 17-05-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31412, current rewards: 10.71428, mean: 0.01410
[32m[0906 17-06-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31417, current rewards: 16.94039, mean: 0.02091
[32m[0906 17-06-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31423, current rewards: 23.16831, mean: 0.02694
[32m[0906 17-06-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31433, current rewards: 29.39405, mean: 0.03230
[32m[0906 17-06-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31442, current rewards: 35.61644, mean: 0.03710
[32m[0906 17-07-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31452, current rewards: 20.13783, mean: 0.01994
[32m[0906 17-07-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31455, current rewards: 30.08282, mean: 0.02838
[32m[0906 17-07-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31452, current rewards: 40.74330, mean: 0.03671
[32m[0906 17-07-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31455, current rewards: 50.86043, mean: 0.04385
[32m[0906 17-08-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31457, current rewards: 60.97362, mean: 0.05039
[32m[0906 17-08-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31457, current rewards: 43.77503, mean: 0.03474
[32m[0906 17-08-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31454, current rewards: 50.74309, mean: 0.03874
[32m[0906 17-08-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31457, current rewards: 57.57727, mean: 0.04234
[32m[0906 17-09-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31459, current rewards: 64.40713, mean: 0.04568
[32m[0906 17-09-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31460, current rewards: 71.23627, mean: 0.04879
[32m[0906 17-09-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31462, current rewards: 77.34208, mean: 0.05122
[32m[0906 17-09-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31463, current rewards: 83.82884, mean: 0.05374
[32m[0906 17-10-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31464, current rewards: 47.67405, mean: 0.02961
[32m[0906 17-10-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31465, current rewards: 56.21791, mean: 0.03387
[32m[0906 17-10-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31462, current rewards: 65.44656, mean: 0.03827
[32m[0906 17-11-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31458, current rewards: 74.63958, mean: 0.04241
[32m[0906 17-11-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31457, current rewards: 83.83689, mean: 0.04632
[32m[0906 17-11-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31456, current rewards: 93.02869, mean: 0.05002
[32m[0906 17-11-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31457, current rewards: 103.15795, mean: 0.05401
[32m[0906 17-12-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31459, current rewards: 112.70869, mean: 0.05750
[32m[0906 17-12-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31458, current rewards: 122.26985, mean: 0.06083
[32m[0906 17-12-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31455, current rewards: 131.84712, mean: 0.06400
[32m[0906 17-12-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31455, current rewards: 141.39258, mean: 0.06701
[32m[0906 17-13-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31455, current rewards: 126.57280, mean: 0.05860
[32m[0906 17-13-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31454, current rewards: 132.37889, mean: 0.05990
[32m[0906 17-13-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31453, current rewards: 138.29276, mean: 0.06119
[32m[0906 17-13-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31452, current rewards: 143.34393, mean: 0.06205
[32m[0906 17-14-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31438, current rewards: 148.98620, mean: 0.06313
[32m[0906 17-14-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31423, current rewards: 154.55422, mean: 0.06413
[32m[0906 17-14-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31425, current rewards: 160.13364, mean: 0.06509
[32m[0906 17-14-54 @Agent.py:117][0m Average action selection time: 0.3142
[32m[0906 17-14-54 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-14-54 @MBExp.py:227][0m Rewards obtained: [164.58899686447597], Lows: [50], Highs: [81], Total time: 12662.212989999998
[32m[0906 17-15-23 @MBExp.py:144][0m ####################################################################
[32m[0906 17-15-23 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 17-15-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30872, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-15-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31285, current rewards: -16.66964, mean: -0.27783
[32m[0906 17-15-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31106, current rewards: -11.22819, mean: -0.10207
[32m[0906 17-16-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31179, current rewards: -5.85262, mean: -0.03658
[32m[0906 17-16-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31277, current rewards: -0.47127, mean: -0.00224
[32m[0906 17-16-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31336, current rewards: -36.52628, mean: -0.14049
[32m[0906 17-17-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31331, current rewards: -27.84960, mean: -0.08984
[32m[0906 17-17-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31265, current rewards: -19.65490, mean: -0.05460
[32m[0906 17-17-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31267, current rewards: -11.46322, mean: -0.02796
[32m[0906 17-17-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31306, current rewards: -71.51612, mean: -0.15547
[32m[0906 17-18-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31340, current rewards: -171.51612, mean: -0.33631
[32m[0906 17-18-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31365, current rewards: -271.51612, mean: -0.48485
[32m[0906 17-18-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31392, current rewards: -371.51612, mean: -0.60904
[32m[0906 17-18-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31408, current rewards: -471.51612, mean: -0.71442
[32m[0906 17-19-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31421, current rewards: -571.51612, mean: -0.80495
[32m[0906 17-19-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31433, current rewards: -671.51612, mean: -0.88357
[32m[0906 17-19-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31440, current rewards: -771.51612, mean: -0.95249
[32m[0906 17-19-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31442, current rewards: -871.51612, mean: -1.01339
[32m[0906 17-20-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31447, current rewards: -971.51612, mean: -1.06760
[32m[0906 17-20-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31450, current rewards: -1071.51612, mean: -1.11616
[32m[0906 17-20-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31461, current rewards: -1114.48760, mean: -1.10345
[32m[0906 17-20-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31464, current rewards: -1109.39602, mean: -1.04660
[32m[0906 17-21-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31466, current rewards: -1105.43787, mean: -0.99589
[32m[0906 17-21-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31467, current rewards: -1100.60360, mean: -0.94880
[32m[0906 17-21-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31467, current rewards: -1095.77334, mean: -0.90560
[32m[0906 17-22-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31466, current rewards: -1090.94204, mean: -0.86583
[32m[0906 17-22-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31465, current rewards: -1086.11070, mean: -0.82909
[32m[0906 17-22-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31464, current rewards: -1081.27677, mean: -0.79506
[32m[0906 17-22-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31465, current rewards: -1076.44231, mean: -0.76343
[32m[0906 17-23-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31463, current rewards: -1071.61071, mean: -0.73398
[32m[0906 17-23-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31464, current rewards: -1091.38643, mean: -0.72277
[32m[0906 17-23-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31464, current rewards: -1082.60639, mean: -0.69398
[32m[0906 17-23-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31464, current rewards: -1076.48365, mean: -0.66862
[32m[0906 17-24-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31462, current rewards: -1070.18964, mean: -0.64469
[32m[0906 17-24-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31461, current rewards: -1063.80172, mean: -0.62211
[32m[0906 17-24-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31459, current rewards: -1057.41198, mean: -0.60080
[32m[0906 17-24-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31460, current rewards: -1051.11130, mean: -0.58072
[32m[0906 17-25-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31460, current rewards: -1087.27256, mean: -0.58456
[32m[0906 17-25-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31460, current rewards: -1081.41286, mean: -0.56618
[32m[0906 17-25-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31457, current rewards: -1077.80285, mean: -0.54990
[32m[0906 17-25-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31455, current rewards: -1072.97203, mean: -0.53382
[32m[0906 17-26-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31454, current rewards: -1068.20028, mean: -0.51854
[32m[0906 17-26-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31454, current rewards: -1063.42570, mean: -0.50399
[32m[0906 17-26-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31453, current rewards: -1058.65018, mean: -0.49012
[32m[0906 17-26-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31451, current rewards: -1083.21481, mean: -0.49014
[32m[0906 17-27-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31451, current rewards: -1175.35854, mean: -0.52007
[32m[0906 17-27-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31451, current rewards: -1270.34770, mean: -0.54993
[32m[0906 17-27-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31438, current rewards: -1367.86585, mean: -0.57960
[32m[0906 17-28-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31424, current rewards: -1467.86585, mean: -0.60907
[32m[0906 17-28-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31425, current rewards: -1567.86585, mean: -0.63734
[32m[0906 17-28-30 @Agent.py:117][0m Average action selection time: 0.3143
[32m[0906 17-28-30 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-28-30 @MBExp.py:227][0m Rewards obtained: [-1647.865851219145], Lows: [885], Highs: [60], Total time: 13448.475496
[32m[0906 17-29-01 @MBExp.py:144][0m ####################################################################
[32m[0906 17-29-01 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 17-29-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30813, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-29-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31177, current rewards: -14.99250, mean: -0.24988
[32m[0906 17-29-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31048, current rewards: -10.18407, mean: -0.09258
[32m[0906 17-29-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31139, current rewards: -5.44477, mean: -0.03403
[32m[0906 17-30-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31253, current rewards: -0.70217, mean: -0.00334
[32m[0906 17-30-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31310, current rewards: 4.04357, mean: 0.01555
[32m[0906 17-30-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31306, current rewards: 16.20349, mean: 0.05227
[32m[0906 17-30-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31251, current rewards: 21.40713, mean: 0.05946
[32m[0906 17-31-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31239, current rewards: 26.45922, mean: 0.06453
[32m[0906 17-31-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31287, current rewards: 31.49460, mean: 0.06847
[32m[0906 17-31-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31322, current rewards: 43.36847, mean: 0.08504
[32m[0906 17-31-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31356, current rewards: 57.91660, mean: 0.10342
[32m[0906 17-32-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31373, current rewards: 63.57723, mean: 0.10422
[32m[0906 17-32-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31381, current rewards: 69.23558, mean: 0.10490
[32m[0906 17-32-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31390, current rewards: 7.36509, mean: 0.01037
[32m[0906 17-33-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31396, current rewards: -92.63491, mean: -0.12189
[32m[0906 17-33-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31400, current rewards: -192.63491, mean: -0.23782
[32m[0906 17-33-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31402, current rewards: -292.63491, mean: -0.34027
[32m[0906 17-33-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31408, current rewards: -392.63491, mean: -0.43147
[32m[0906 17-34-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31414, current rewards: -492.63491, mean: -0.51316
[32m[0906 17-34-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31419, current rewards: -592.63491, mean: -0.58677
[32m[0906 17-34-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31423, current rewards: -692.63491, mean: -0.65343
[32m[0906 17-34-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31430, current rewards: -730.15242, mean: -0.65779
[32m[0906 17-35-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31429, current rewards: -725.03056, mean: -0.62503
[32m[0906 17-35-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31433, current rewards: -718.89837, mean: -0.59413
[32m[0906 17-35-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31436, current rewards: -712.20169, mean: -0.56524
[32m[0906 17-35-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31439, current rewards: -705.89426, mean: -0.53885
[32m[0906 17-36-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31439, current rewards: -726.88960, mean: -0.53448
[32m[0906 17-36-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31439, current rewards: -780.10696, mean: -0.55327
[32m[0906 17-36-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31439, current rewards: -839.55744, mean: -0.57504
[32m[0906 17-36-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31441, current rewards: -899.45915, mean: -0.59567
[32m[0906 17-37-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31441, current rewards: -971.52848, mean: -0.62277
[32m[0906 17-37-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31443, current rewards: -1039.03547, mean: -0.64536
[32m[0906 17-37-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31441, current rewards: -1112.34698, mean: -0.67009
[32m[0906 17-37-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31439, current rewards: -1195.64066, mean: -0.69921
[32m[0906 17-38-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31437, current rewards: -1212.39292, mean: -0.68886
[32m[0906 17-38-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31438, current rewards: -1206.09282, mean: -0.66635
[32m[0906 17-38-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31438, current rewards: -1199.74857, mean: -0.64503
[32m[0906 17-39-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31437, current rewards: -1197.66252, mean: -0.62705
[32m[0906 17-39-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31437, current rewards: -1229.71635, mean: -0.62741
[32m[0906 17-39-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31438, current rewards: -1223.65730, mean: -0.60878
[32m[0906 17-39-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31438, current rewards: -1216.85153, mean: -0.59070
[32m[0906 17-40-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31438, current rewards: -1210.28510, mean: -0.57359
[32m[0906 17-40-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31438, current rewards: -1203.63819, mean: -0.55724
[32m[0906 17-40-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31439, current rewards: -1197.03069, mean: -0.54164
[32m[0906 17-40-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31438, current rewards: -1190.39860, mean: -0.52673
[32m[0906 17-41-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31437, current rewards: -1183.78010, mean: -0.51246
[32m[0906 17-41-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31424, current rewards: -1177.15572, mean: -0.49879
[32m[0906 17-41-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31410, current rewards: -1170.53166, mean: -0.48570
[32m[0906 17-41-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31412, current rewards: -1163.91058, mean: -0.47313
[32m[0906 17-42-07 @Agent.py:117][0m Average action selection time: 0.3141
[32m[0906 17-42-07 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-42-07 @MBExp.py:227][0m Rewards obtained: [-1158.6157082441355], Lows: [697], Highs: [41], Total time: 14234.386031999999
[32m[0906 17-42-40 @MBExp.py:144][0m ####################################################################
[32m[0906 17-42-40 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 17-42-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31018, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-42-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31099, current rewards: -46.06836, mean: -0.76781
[32m[0906 17-43-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30970, current rewards: -92.34538, mean: -0.83950
[32m[0906 17-43-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31085, current rewards: -122.23036, mean: -0.76394
[32m[0906 17-43-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31208, current rewards: -153.05330, mean: -0.72883
[32m[0906 17-44-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31277, current rewards: -181.77263, mean: -0.69913
[32m[0906 17-44-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31279, current rewards: -210.22714, mean: -0.67815
[32m[0906 17-44-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31218, current rewards: -241.66618, mean: -0.67129
[32m[0906 17-44-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31188, current rewards: -240.26978, mean: -0.58602
[32m[0906 17-45-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31234, current rewards: -243.76017, mean: -0.52991
[32m[0906 17-45-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31275, current rewards: -253.20383, mean: -0.49648
[32m[0906 17-45-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31299, current rewards: -277.60135, mean: -0.49572
[32m[0906 17-45-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31323, current rewards: -288.06918, mean: -0.47224
[32m[0906 17-46-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31340, current rewards: -307.02572, mean: -0.46519
[32m[0906 17-46-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31361, current rewards: -321.60617, mean: -0.45297
[32m[0906 17-46-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31371, current rewards: -331.66914, mean: -0.43641
[32m[0906 17-46-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31383, current rewards: -347.57585, mean: -0.42911
[32m[0906 17-47-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31387, current rewards: -377.00599, mean: -0.43838
[32m[0906 17-47-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31394, current rewards: -396.40509, mean: -0.43561
[32m[0906 17-47-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31404, current rewards: -392.24890, mean: -0.40859
[32m[0906 17-47-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31404, current rewards: -389.57593, mean: -0.38572
[32m[0906 17-48-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31410, current rewards: -386.96104, mean: -0.36506
[32m[0906 17-48-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31419, current rewards: -384.34887, mean: -0.34626
[32m[0906 17-48-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31419, current rewards: -400.76861, mean: -0.34549
[32m[0906 17-49-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31420, current rewards: -388.66902, mean: -0.32121
[32m[0906 17-49-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31423, current rewards: -376.63196, mean: -0.29891
[32m[0906 17-49-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31429, current rewards: -364.64954, mean: -0.27836
[32m[0906 17-49-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31426, current rewards: -359.49523, mean: -0.26433
[32m[0906 17-50-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31424, current rewards: -351.65108, mean: -0.24940
[32m[0906 17-50-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31424, current rewards: -343.24517, mean: -0.23510
[32m[0906 17-50-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31426, current rewards: -334.85203, mean: -0.22176
[32m[0906 17-50-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31426, current rewards: -324.74565, mean: -0.20817
[32m[0906 17-51-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31425, current rewards: -316.14335, mean: -0.19636
[32m[0906 17-51-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31427, current rewards: -308.03092, mean: -0.18556
[32m[0906 17-51-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31427, current rewards: -299.92756, mean: -0.17540
[32m[0906 17-51-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31428, current rewards: -291.83175, mean: -0.16581
[32m[0906 17-52-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31429, current rewards: -283.74099, mean: -0.15676
[32m[0906 17-52-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31428, current rewards: -275.65335, mean: -0.14820
[32m[0906 17-52-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31426, current rewards: -267.53023, mean: -0.14007
[32m[0906 17-52-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31424, current rewards: -260.58185, mean: -0.13295
[32m[0906 17-53-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31424, current rewards: -253.10856, mean: -0.12592
[32m[0906 17-53-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31423, current rewards: -244.62316, mean: -0.11875
[32m[0906 17-53-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31421, current rewards: -236.13690, mean: -0.11191
[32m[0906 17-54-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31421, current rewards: -270.46240, mean: -0.12521
[32m[0906 17-54-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31421, current rewards: -255.16911, mean: -0.11546
[32m[0906 17-54-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31422, current rewards: -240.16762, mean: -0.10627
[32m[0906 17-54-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31423, current rewards: -225.16308, mean: -0.09747
[32m[0906 17-55-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31411, current rewards: -229.80159, mean: -0.09737
[32m[0906 17-55-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31399, current rewards: -232.95033, mean: -0.09666
[32m[0906 17-55-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31396, current rewards: -212.05695, mean: -0.08620
[32m[0906 17-55-46 @Agent.py:117][0m Average action selection time: 0.3140
[32m[0906 17-55-46 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-55-46 @MBExp.py:227][0m Rewards obtained: [-235.08728590960152], Lows: [206], Highs: [212], Total time: 15019.993193999999
[32m[0906 17-56-21 @MBExp.py:144][0m ####################################################################
[32m[0906 17-56-21 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 17-56-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31048, current rewards: -2.65584, mean: -0.26558
[32m[0906 17-56-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31042, current rewards: 0.58417, mean: 0.00974
[32m[0906 17-56-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30930, current rewards: 4.04203, mean: 0.03675
[32m[0906 17-57-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31021, current rewards: 7.50308, mean: 0.04689
[32m[0906 17-57-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31168, current rewards: 10.96464, mean: 0.05221
[32m[0906 17-57-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31236, current rewards: 14.41999, mean: 0.05546
[32m[0906 17-57-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31237, current rewards: 17.81179, mean: 0.05746
[32m[0906 17-58-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31187, current rewards: 21.23794, mean: 0.05899
[32m[0906 17-58-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31149, current rewards: 24.66361, mean: 0.06016
[32m[0906 17-58-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31223, current rewards: 28.08921, mean: 0.06106
[32m[0906 17-59-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31246, current rewards: 31.51485, mean: 0.06179
[32m[0906 17-59-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31280, current rewards: 34.93967, mean: 0.06239
[32m[0906 17-59-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31296, current rewards: 18.07221, mean: 0.02963
[32m[0906 17-59-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31312, current rewards: 25.11507, mean: 0.03805
[32m[0906 18-00-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31325, current rewards: 31.75322, mean: 0.04472
[32m[0906 18-00-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31337, current rewards: 39.23598, mean: 0.05163
[32m[0906 18-00-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31344, current rewards: 46.80536, mean: 0.05778
[32m[0906 18-00-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31346, current rewards: 54.37663, mean: 0.06323
[32m[0906 18-01-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31355, current rewards: 61.95074, mean: 0.06808
[32m[0906 18-01-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31359, current rewards: 69.51226, mean: 0.07241
[32m[0906 18-01-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31366, current rewards: 77.08131, mean: 0.07632
[32m[0906 18-01-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31376, current rewards: 84.64103, mean: 0.07985
[32m[0906 18-02-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31379, current rewards: 79.16335, mean: 0.07132
[32m[0906 18-02-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31380, current rewards: 86.72979, mean: 0.07477
[32m[0906 18-02-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31383, current rewards: 94.03438, mean: 0.07771
[32m[0906 18-02-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31385, current rewards: 101.35937, mean: 0.08044
[32m[0906 18-03-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31387, current rewards: 108.66169, mean: 0.08295
[32m[0906 18-03-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31390, current rewards: 115.96843, mean: 0.08527
[32m[0906 18-03-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31391, current rewards: 80.40403, mean: 0.05702
[32m[0906 18-04-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31394, current rewards: 86.02553, mean: 0.05892
[32m[0906 18-04-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31394, current rewards: 94.72368, mean: 0.06273
[32m[0906 18-04-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31396, current rewards: 103.42805, mean: 0.06630
[32m[0906 18-04-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31395, current rewards: 109.90777, mean: 0.06827
[32m[0906 18-05-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31397, current rewards: 117.08920, mean: 0.07054
[32m[0906 18-05-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31397, current rewards: 123.47367, mean: 0.07221
[32m[0906 18-05-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31398, current rewards: 129.34366, mean: 0.07349
[32m[0906 18-05-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31397, current rewards: 135.32210, mean: 0.07476
[32m[0906 18-06-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31399, current rewards: 141.28197, mean: 0.07596
[32m[0906 18-06-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31397, current rewards: 125.96894, mean: 0.06595
[32m[0906 18-06-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31396, current rewards: 130.13925, mean: 0.06640
[32m[0906 18-06-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31396, current rewards: 135.97711, mean: 0.06765
[32m[0906 18-07-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31396, current rewards: 141.78023, mean: 0.06883
[32m[0906 18-07-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31394, current rewards: 147.58695, mean: 0.06995
[32m[0906 18-07-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31393, current rewards: 153.38628, mean: 0.07101
[32m[0906 18-07-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31393, current rewards: 159.19150, mean: 0.07203
[32m[0906 18-08-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31394, current rewards: 164.99545, mean: 0.07301
[32m[0906 18-08-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31395, current rewards: 170.80118, mean: 0.07394
[32m[0906 18-08-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31381, current rewards: 183.52823, mean: 0.07777
[32m[0906 18-08-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31368, current rewards: 188.93167, mean: 0.07839
[32m[0906 18-09-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31367, current rewards: 194.39368, mean: 0.07902
[32m[0906 18-09-26 @Agent.py:117][0m Average action selection time: 0.3137
[32m[0906 18-09-26 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-09-26 @MBExp.py:227][0m Rewards obtained: [198.76743454181772], Lows: [23], Highs: [51], Total time: 15804.803488999998
[32m[0906 18-10-03 @MBExp.py:144][0m ####################################################################
[32m[0906 18-10-03 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 18-10-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31460, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-10-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30963, current rewards: -23.26237, mean: -0.38771
[32m[0906 18-10-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30935, current rewards: -21.22385, mean: -0.19294
[32m[0906 18-10-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31040, current rewards: -18.13518, mean: -0.11334
[32m[0906 18-11-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31190, current rewards: -16.26287, mean: -0.07744
[32m[0906 18-11-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31262, current rewards: -12.41802, mean: -0.04776
[32m[0906 18-11-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31273, current rewards: -9.08569, mean: -0.02931
[32m[0906 18-11-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31225, current rewards: -48.33050, mean: -0.13425
[32m[0906 18-12-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31193, current rewards: -37.93423, mean: -0.09252
[32m[0906 18-12-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31250, current rewards: -26.21831, mean: -0.05700
[32m[0906 18-12-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31568, current rewards: -14.48692, mean: -0.02841
[32m[0906 18-13-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31904, current rewards: -2.76049, mean: -0.00493
[32m[0906 18-13-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32195, current rewards: 8.97505, mean: 0.01471
[32m[0906 18-13-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32453, current rewards: 17.73983, mean: 0.02688
[32m[0906 18-13-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32684, current rewards: 22.06571, mean: 0.03108
[32m[0906 18-14-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32892, current rewards: 27.16335, mean: 0.03574
[32m[0906 18-14-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33072, current rewards: 32.30522, mean: 0.03988
[32m[0906 18-14-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33226, current rewards: 37.45007, mean: 0.04355
[32m[0906 18-15-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33370, current rewards: 42.59130, mean: 0.04680
[32m[0906 18-15-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33492, current rewards: 27.60442, mean: 0.02875
[32m[0906 18-15-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33606, current rewards: 33.63563, mean: 0.03330
[32m[0906 18-16-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33711, current rewards: 39.44798, mean: 0.03722
[32m[0906 18-16-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33804, current rewards: 47.07323, mean: 0.04241
[32m[0906 18-16-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33906, current rewards: 51.70777, mean: 0.04458
[32m[0906 18-16-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34017, current rewards: 56.07115, mean: 0.04634
[32m[0906 18-17-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34117, current rewards: 60.40554, mean: 0.04794
[32m[0906 18-17-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34191, current rewards: 64.73831, mean: 0.04942
[32m[0906 18-17-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34233, current rewards: 69.07182, mean: 0.05079
[32m[0906 18-18-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34276, current rewards: 73.39692, mean: 0.05205
[32m[0906 18-18-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34318, current rewards: 77.72554, mean: 0.05324
[32m[0906 18-18-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34352, current rewards: 58.28005, mean: 0.03860
[32m[0906 18-19-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34389, current rewards: 55.50543, mean: 0.03558
[32m[0906 18-19-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34421, current rewards: 60.20953, mean: 0.03740
[32m[0906 18-19-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34451, current rewards: 64.68305, mean: 0.03897
[32m[0906 18-19-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34482, current rewards: 69.15403, mean: 0.04044
[32m[0906 18-20-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34509, current rewards: 73.62621, mean: 0.04183
[32m[0906 18-20-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34537, current rewards: 78.09830, mean: 0.04315
[32m[0906 18-20-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34562, current rewards: 62.05401, mean: 0.03336
[32m[0906 18-21-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34583, current rewards: 54.22361, mean: 0.02839
[32m[0906 18-21-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34604, current rewards: 49.96013, mean: 0.02549
[32m[0906 18-21-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34631, current rewards: 58.25130, mean: 0.02898
[32m[0906 18-21-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34657, current rewards: 65.93068, mean: 0.03201
[32m[0906 18-22-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34685, current rewards: 74.14631, mean: 0.03514
[32m[0906 18-22-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34711, current rewards: 81.88445, mean: 0.03791
[32m[0906 18-22-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34733, current rewards: 90.03732, mean: 0.04074
[32m[0906 18-23-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34755, current rewards: 97.83820, mean: 0.04329
[32m[0906 18-23-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34773, current rewards: 105.93304, mean: 0.04586
[32m[0906 18-23-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34777, current rewards: 99.05272, mean: 0.04197
[32m[0906 18-24-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34777, current rewards: 106.65925, mean: 0.04426
[32m[0906 18-24-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34784, current rewards: 84.36640, mean: 0.03430
[32m[0906 18-24-33 @Agent.py:117][0m Average action selection time: 0.3480
[32m[0906 18-24-33 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-24-34 @MBExp.py:227][0m Rewards obtained: [76.92484683135511], Lows: [69], Highs: [100], Total time: 16675.481648999998
[32m[0906 18-25-18 @MBExp.py:144][0m ####################################################################
[32m[0906 18-25-18 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 18-25-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35402, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-25-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34958, current rewards: -38.86961, mean: -0.64783
[32m[0906 18-25-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35233, current rewards: -138.86961, mean: -1.26245
[32m[0906 18-26-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35522, current rewards: -235.89132, mean: -1.47432
[32m[0906 18-26-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35529, current rewards: -247.61166, mean: -1.17910
[32m[0906 18-26-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35504, current rewards: -344.61166, mean: -1.32543
[32m[0906 18-27-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35423, current rewards: -444.61166, mean: -1.43423
[32m[0906 18-27-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35313, current rewards: -544.61166, mean: -1.51281
[32m[0906 18-27-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35229, current rewards: -644.61166, mean: -1.57222
[32m[0906 18-28-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35265, current rewards: -744.61166, mean: -1.61872
[32m[0906 18-28-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35287, current rewards: -844.61166, mean: -1.65610
[32m[0906 18-28-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35309, current rewards: -850.71301, mean: -1.51913
[32m[0906 18-28-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35359, current rewards: -844.46672, mean: -1.38437
[32m[0906 18-29-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35398, current rewards: -837.28964, mean: -1.26862
[32m[0906 18-29-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35427, current rewards: -884.85478, mean: -1.24627
[32m[0906 18-29-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35455, current rewards: -913.13038, mean: -1.20149
[32m[0906 18-30-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35457, current rewards: -968.06686, mean: -1.19514
[32m[0906 18-30-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35453, current rewards: -1039.08266, mean: -1.20824
[32m[0906 18-30-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35447, current rewards: -1131.51648, mean: -1.24342
[32m[0906 18-30-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35443, current rewards: -1201.39528, mean: -1.25145
[32m[0906 18-31-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35439, current rewards: -1291.45041, mean: -1.27866
[32m[0906 18-31-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35433, current rewards: -1363.69024, mean: -1.28650
[32m[0906 18-31-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35420, current rewards: -1361.85555, mean: -1.22690
[32m[0906 18-32-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35385, current rewards: -1356.77565, mean: -1.16963
[32m[0906 18-32-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35227, current rewards: -1351.74832, mean: -1.11715
[32m[0906 18-32-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35084, current rewards: -1346.72072, mean: -1.06883
[32m[0906 18-32-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34953, current rewards: -1341.69349, mean: -1.02419
[32m[0906 18-33-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34830, current rewards: -1336.66745, mean: -0.98284
[32m[0906 18-33-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34715, current rewards: -1331.64315, mean: -0.94443
[32m[0906 18-33-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34602, current rewards: -1326.61610, mean: -0.90864
[32m[0906 18-33-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34502, current rewards: -1319.99518, mean: -0.87417
[32m[0906 18-34-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34405, current rewards: -1312.78439, mean: -0.84153
[32m[0906 18-34-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34315, current rewards: -1329.29896, mean: -0.82565
[32m[0906 18-34-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34233, current rewards: -1326.10739, mean: -0.79886
[32m[0906 18-35-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34153, current rewards: -1323.12061, mean: -0.77375
[32m[0906 18-35-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34076, current rewards: -1320.18268, mean: -0.75010
[32m[0906 18-35-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34003, current rewards: -1317.20122, mean: -0.72774
[32m[0906 18-35-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33935, current rewards: -1314.25931, mean: -0.70659
[32m[0906 18-36-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33870, current rewards: -1311.19868, mean: -0.68649
[32m[0906 18-36-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33809, current rewards: -1307.69132, mean: -0.66719
[32m[0906 18-36-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33751, current rewards: -1304.44401, mean: -0.64898
[32m[0906 18-36-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33696, current rewards: -1301.22394, mean: -0.63166
[32m[0906 18-37-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33641, current rewards: -1314.50844, mean: -0.62299
[32m[0906 18-37-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33588, current rewards: -1387.95612, mean: -0.64257
[32m[0906 18-37-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33539, current rewards: -1476.41431, mean: -0.66806
[32m[0906 18-37-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33490, current rewards: -1552.86565, mean: -0.68711
[32m[0906 18-38-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33452, current rewards: -1635.76672, mean: -0.70812
[32m[0906 18-38-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33395, current rewards: -1708.26605, mean: -0.72384
[32m[0906 18-38-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33341, current rewards: -1767.99052, mean: -0.73361
[32m[0906 18-38-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33295, current rewards: -1758.67000, mean: -0.71491
[32m[0906 18-39-10 @Agent.py:117][0m Average action selection time: 0.3327
[32m[0906 18-39-10 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-39-10 @MBExp.py:227][0m Rewards obtained: [-1751.5265735343523], Lows: [926], Highs: [100], Total time: 17507.744049999998
[32m[0906 18-39-51 @MBExp.py:144][0m ####################################################################
[32m[0906 18-39-51 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 18-39-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30850, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-40-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30876, current rewards: -15.36432, mean: -0.25607
[32m[0906 18-40-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30837, current rewards: -4.80600, mean: -0.04369
[32m[0906 18-40-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30965, current rewards: 5.57224, mean: 0.03483
[32m[0906 18-40-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31124, current rewards: 15.94230, mean: 0.07592
[32m[0906 18-41-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31209, current rewards: 31.72605, mean: 0.12202
[32m[0906 18-41-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31197, current rewards: 40.04603, mean: 0.12918
[32m[0906 18-41-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31150, current rewards: 7.29927, mean: 0.02028
[32m[0906 18-41-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31120, current rewards: 8.31940, mean: 0.02029
[32m[0906 18-42-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31183, current rewards: 13.30599, mean: 0.02893
[32m[0906 18-42-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31220, current rewards: 19.11364, mean: 0.03748
[32m[0906 18-42-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31248, current rewards: 24.92893, mean: 0.04452
[32m[0906 18-43-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31273, current rewards: 30.73998, mean: 0.05039
[32m[0906 18-43-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31300, current rewards: 36.55325, mean: 0.05538
[32m[0906 18-43-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31322, current rewards: 42.36969, mean: 0.05968
[32m[0906 18-43-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31329, current rewards: 48.18985, mean: 0.06341
[32m[0906 18-44-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31347, current rewards: 54.00187, mean: 0.06667
[32m[0906 18-44-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31356, current rewards: 59.81520, mean: 0.06955
[32m[0906 18-44-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31366, current rewards: 65.62459, mean: 0.07211
[32m[0906 18-44-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31372, current rewards: 71.44109, mean: 0.07442
[32m[0906 18-45-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31376, current rewards: 77.25344, mean: 0.07649
[32m[0906 18-45-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31388, current rewards: 62.68064, mean: 0.05913
[32m[0906 18-45-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31394, current rewards: 68.07438, mean: 0.06133
[32m[0906 18-45-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31394, current rewards: 72.46406, mean: 0.06247
[32m[0906 18-46-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31399, current rewards: 76.84544, mean: 0.06351
[32m[0906 18-46-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31405, current rewards: 81.22400, mean: 0.06446
[32m[0906 18-46-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31407, current rewards: 85.60532, mean: 0.06535
[32m[0906 18-46-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31406, current rewards: 89.98690, mean: 0.06617
[32m[0906 18-47-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31409, current rewards: 94.36708, mean: 0.06693
[32m[0906 18-47-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31409, current rewards: 98.62884, mean: 0.06755
[32m[0906 18-47-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31412, current rewards: 102.97705, mean: 0.06820
[32m[0906 18-48-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31413, current rewards: 64.91443, mean: 0.04161
[32m[0906 18-48-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31412, current rewards: 69.16279, mean: 0.04296
[32m[0906 18-48-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31415, current rewards: 72.57603, mean: 0.04372
[32m[0906 18-48-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31415, current rewards: 75.96818, mean: 0.04443
[32m[0906 18-49-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31416, current rewards: 79.35962, mean: 0.04509
[32m[0906 18-49-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31420, current rewards: 82.75108, mean: 0.04572
[32m[0906 18-49-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31422, current rewards: 73.32045, mean: 0.03942
[32m[0906 18-49-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31422, current rewards: 43.48084, mean: 0.02276
[32m[0906 18-50-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31424, current rewards: 24.56934, mean: 0.01254
[32m[0906 18-50-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31425, current rewards: 5.52674, mean: 0.00275
[32m[0906 18-50-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31427, current rewards: -19.90881, mean: -0.00966
[32m[0906 18-50-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31426, current rewards: -47.44420, mean: -0.02249
[32m[0906 18-51-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31427, current rewards: -73.89760, mean: -0.03421
[32m[0906 18-51-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31428, current rewards: -92.79109, mean: -0.04199
[32m[0906 18-51-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31425, current rewards: -111.79160, mean: -0.04947
[32m[0906 18-51-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31424, current rewards: -108.77487, mean: -0.04709
[32m[0906 18-52-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31409, current rewards: -127.63178, mean: -0.05408
[32m[0906 18-52-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31395, current rewards: -164.39494, mean: -0.06821
[32m[0906 18-52-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31385, current rewards: -179.45736, mean: -0.07295
[32m[0906 18-52-56 @Agent.py:117][0m Average action selection time: 0.3139
[32m[0906 18-52-56 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-52-56 @MBExp.py:227][0m Rewards obtained: [-176.4738169467509], Lows: [66], Highs: [280], Total time: 18292.981369999998
[32m[0906 18-53-38 @MBExp.py:144][0m ####################################################################
[32m[0906 18-53-38 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 18-53-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30861, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-53-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30793, current rewards: -10.49315, mean: -0.17489
[32m[0906 18-54-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30799, current rewards: -4.52351, mean: -0.04112
[32m[0906 18-54-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30962, current rewards: 4.27976, mean: 0.02675
[32m[0906 18-54-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31097, current rewards: 11.47810, mean: 0.05466
[32m[0906 18-54-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31181, current rewards: 18.77381, mean: 0.07221
[32m[0906 18-55-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31177, current rewards: 26.16948, mean: 0.08442
[32m[0906 18-55-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31129, current rewards: 33.73290, mean: 0.09370
[32m[0906 18-55-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31093, current rewards: 41.27342, mean: 0.10067
[32m[0906 18-56-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31135, current rewards: 45.91111, mean: 0.09981
[32m[0906 18-56-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31180, current rewards: 51.62058, mean: 0.10122
[32m[0906 18-56-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31222, current rewards: 57.32505, mean: 0.10237
[32m[0906 18-56-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31257, current rewards: 62.81970, mean: 0.10298
[32m[0906 18-57-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31284, current rewards: 67.50123, mean: 0.10227
[32m[0906 18-57-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31294, current rewards: 72.85694, mean: 0.10262
[32m[0906 18-57-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31312, current rewards: 78.20319, mean: 0.10290
[32m[0906 18-57-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31326, current rewards: 83.55127, mean: 0.10315
[32m[0906 18-58-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31334, current rewards: 88.90919, mean: 0.10338
[32m[0906 18-58-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31346, current rewards: 93.43973, mean: 0.10268
[32m[0906 18-58-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31354, current rewards: 97.73613, mean: 0.10181
[32m[0906 18-58-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31363, current rewards: 102.56619, mean: 0.10155
[32m[0906 18-59-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31366, current rewards: 110.44373, mean: 0.10419
[32m[0906 18-59-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31373, current rewards: 115.37684, mean: 0.10394
[32m[0906 18-59-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31383, current rewards: 120.30767, mean: 0.10371
[32m[0906 18-59-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31391, current rewards: 125.24084, mean: 0.10350
[32m[0906 19-00-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31395, current rewards: 130.17721, mean: 0.10332
[32m[0906 19-00-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31400, current rewards: 135.10990, mean: 0.10314
[32m[0906 19-00-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31399, current rewards: 123.24831, mean: 0.09062
[32m[0906 19-01-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31404, current rewards: 107.03294, mean: 0.07591
[32m[0906 19-01-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31403, current rewards: 121.80044, mean: 0.08342
[32m[0906 19-01-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31405, current rewards: 127.01014, mean: 0.08411
[32m[0906 19-01-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31402, current rewards: 144.05875, mean: 0.09235
[32m[0906 19-02-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31400, current rewards: 111.47871, mean: 0.06924
[32m[0906 19-02-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31401, current rewards: 123.40807, mean: 0.07434
[32m[0906 19-02-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31404, current rewards: 133.75441, mean: 0.07822
[32m[0906 19-02-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31403, current rewards: 144.10909, mean: 0.08188
[32m[0906 19-03-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31400, current rewards: 154.46413, mean: 0.08534
[32m[0906 19-03-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31399, current rewards: 162.19938, mean: 0.08720
[32m[0906 19-03-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31397, current rewards: 167.57228, mean: 0.08773
[32m[0906 19-03-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31396, current rewards: 174.36072, mean: 0.08896
[32m[0906 19-04-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31396, current rewards: 181.15029, mean: 0.09012
[32m[0906 19-04-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31397, current rewards: 164.59199, mean: 0.07990
[32m[0906 19-04-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31397, current rewards: 169.13880, mean: 0.08016
[32m[0906 19-04-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31395, current rewards: 173.53466, mean: 0.08034
[32m[0906 19-05-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31396, current rewards: 177.91565, mean: 0.08050
[32m[0906 19-05-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31396, current rewards: 182.29939, mean: 0.08066
[32m[0906 19-05-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31396, current rewards: 186.68107, mean: 0.08081
[32m[0906 19-05-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31382, current rewards: 149.43125, mean: 0.06332
[32m[0906 19-06-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31369, current rewards: 154.62321, mean: 0.06416
[32m[0906 19-06-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31359, current rewards: 159.79579, mean: 0.06496
[32m[0906 19-06-43 @Agent.py:117][0m Average action selection time: 0.3136
[32m[0906 19-06-43 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-06-43 @MBExp.py:227][0m Rewards obtained: [163.9290932426465], Lows: [68], Highs: [40], Total time: 19077.608321999996
[32m[0906 19-07-27 @MBExp.py:144][0m ####################################################################
[32m[0906 19-07-27 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 19-07-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30964, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-07-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30906, current rewards: -39.27602, mean: -0.65460
[32m[0906 19-08-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30911, current rewards: -34.82603, mean: -0.31660
[32m[0906 19-08-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31039, current rewards: -39.02499, mean: -0.24391
[32m[0906 19-08-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31142, current rewards: -63.43364, mean: -0.30206
[32m[0906 19-08-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31222, current rewards: -87.29166, mean: -0.33574
[32m[0906 19-09-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31217, current rewards: -97.24544, mean: -0.31369
[32m[0906 19-09-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31176, current rewards: -124.83147, mean: -0.34675
[32m[0906 19-09-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31140, current rewards: -150.42837, mean: -0.36690
[32m[0906 19-09-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31177, current rewards: -163.42242, mean: -0.35527
[32m[0906 19-10-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31227, current rewards: -210.72609, mean: -0.41319
[32m[0906 19-10-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31267, current rewards: -261.10126, mean: -0.46625
[32m[0906 19-10-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31294, current rewards: -283.04083, mean: -0.46400
[32m[0906 19-10-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31330, current rewards: -321.47422, mean: -0.48708
[32m[0906 19-11-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31351, current rewards: -336.51499, mean: -0.47396
[32m[0906 19-11-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31370, current rewards: -352.38579, mean: -0.46367
[32m[0906 19-11-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31382, current rewards: -381.51356, mean: -0.47100
[32m[0906 19-11-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31394, current rewards: -481.51356, mean: -0.55990
[32m[0906 19-12-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31409, current rewards: -581.51356, mean: -0.63903
[32m[0906 19-12-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31416, current rewards: -681.51356, mean: -0.70991
[32m[0906 19-12-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31426, current rewards: -781.51356, mean: -0.77378
[32m[0906 19-13-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31433, current rewards: -881.51356, mean: -0.83162
[32m[0906 19-13-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31436, current rewards: -981.51356, mean: -0.88425
[32m[0906 19-13-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31439, current rewards: -1081.51356, mean: -0.93234
[32m[0906 19-13-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31442, current rewards: -1181.51356, mean: -0.97646
[32m[0906 19-14-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31443, current rewards: -1281.51356, mean: -1.01707
[32m[0906 19-14-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31446, current rewards: -1381.51356, mean: -1.05459
[32m[0906 19-14-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31449, current rewards: -1481.51356, mean: -1.08935
[32m[0906 19-14-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31453, current rewards: -1581.51356, mean: -1.12164
[32m[0906 19-15-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31453, current rewards: -1681.51356, mean: -1.15172
[32m[0906 19-15-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31452, current rewards: -1781.51356, mean: -1.17981
[32m[0906 19-15-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31453, current rewards: -1881.51356, mean: -1.20610
[32m[0906 19-15-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31453, current rewards: -1981.51356, mean: -1.23075
[32m[0906 19-16-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31455, current rewards: -2081.51356, mean: -1.25392
[32m[0906 19-16-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31456, current rewards: -2181.51356, mean: -1.27574
[32m[0906 19-16-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31457, current rewards: -2281.51356, mean: -1.29631
[32m[0906 19-16-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31458, current rewards: -2381.51356, mean: -1.31575
[32m[0906 19-17-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31460, current rewards: -2481.51356, mean: -1.33415
[32m[0906 19-17-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31462, current rewards: -2581.51356, mean: -1.35158
[32m[0906 19-17-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31464, current rewards: -2681.51356, mean: -1.36812
[32m[0906 19-18-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31463, current rewards: -2781.51356, mean: -1.38384
[32m[0906 19-18-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31464, current rewards: -2881.51356, mean: -1.39879
[32m[0906 19-18-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31463, current rewards: -2981.51356, mean: -1.41304
[32m[0906 19-18-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31462, current rewards: -3081.51356, mean: -1.42663
[32m[0906 19-19-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31462, current rewards: -3181.51356, mean: -1.43960
[32m[0906 19-19-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31461, current rewards: -3281.51356, mean: -1.45200
[32m[0906 19-19-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31461, current rewards: -3381.51356, mean: -1.46386
[32m[0906 19-19-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31446, current rewards: -3481.51356, mean: -1.47522
[32m[0906 19-20-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31435, current rewards: -3581.51356, mean: -1.48611
[32m[0906 19-20-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31422, current rewards: -3681.51356, mean: -1.49655
[32m[0906 19-20-33 @Agent.py:117][0m Average action selection time: 0.3142
[32m[0906 19-20-33 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-20-33 @MBExp.py:227][0m Rewards obtained: [-3761.5135582699368], Lows: [1914], Highs: [35], Total time: 19863.714707999996
[32m[0906 19-21-19 @MBExp.py:144][0m ####################################################################
[32m[0906 19-21-19 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 19-21-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30798, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-21-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30863, current rewards: -54.16063, mean: -0.90268
[32m[0906 19-21-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30874, current rewards: -154.16063, mean: -1.40146
[32m[0906 19-22-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31043, current rewards: -254.16063, mean: -1.58850
[32m[0906 19-22-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31233, current rewards: -303.78242, mean: -1.44658
[32m[0906 19-22-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31305, current rewards: -403.78242, mean: -1.55301
[32m[0906 19-22-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31272, current rewards: -445.41705, mean: -1.43683
[32m[0906 19-23-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31215, current rewards: -428.55324, mean: -1.19043
[32m[0906 19-23-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31172, current rewards: -415.32266, mean: -1.01298
[32m[0906 19-23-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31202, current rewards: -402.04949, mean: -0.87402
[32m[0906 19-23-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31242, current rewards: -388.80692, mean: -0.76237
[32m[0906 19-24-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31266, current rewards: -380.08082, mean: -0.67872
[32m[0906 19-24-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31291, current rewards: -409.06661, mean: -0.67060
[32m[0906 19-24-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31316, current rewards: -391.58356, mean: -0.59331
[32m[0906 19-25-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31332, current rewards: -374.17481, mean: -0.52701
[32m[0906 19-25-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31338, current rewards: -356.69638, mean: -0.46934
[32m[0906 19-25-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31352, current rewards: -339.16095, mean: -0.41872
[32m[0906 19-25-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31371, current rewards: -321.66143, mean: -0.37402
[32m[0906 19-26-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31379, current rewards: -304.19543, mean: -0.33428
[32m[0906 19-26-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31382, current rewards: -296.82484, mean: -0.30919
[32m[0906 19-26-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31388, current rewards: -286.51699, mean: -0.28368
[32m[0906 19-26-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31394, current rewards: -276.47355, mean: -0.26082
[32m[0906 19-27-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31400, current rewards: -266.44372, mean: -0.24004
[32m[0906 19-27-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31406, current rewards: -256.40926, mean: -0.22104
[32m[0906 19-27-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31412, current rewards: -246.36911, mean: -0.20361
[32m[0906 19-27-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31415, current rewards: -236.31998, mean: -0.18756
[32m[0906 19-28-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31421, current rewards: -226.27029, mean: -0.17273
[32m[0906 19-28-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31421, current rewards: -217.94780, mean: -0.16026
[32m[0906 19-28-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31426, current rewards: -211.53674, mean: -0.15003
[32m[0906 19-28-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31430, current rewards: -204.60806, mean: -0.14014
[32m[0906 19-29-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31436, current rewards: -197.74571, mean: -0.13096
[32m[0906 19-29-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31442, current rewards: -190.87589, mean: -0.12236
[32m[0906 19-29-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31457, current rewards: -184.02277, mean: -0.11430
[32m[0906 19-30-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31573, current rewards: -177.15953, mean: -0.10672
[32m[0906 19-30-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31681, current rewards: -203.10861, mean: -0.11878
[32m[0906 19-30-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31782, current rewards: -207.09230, mean: -0.11767
[32m[0906 19-30-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31874, current rewards: -215.02090, mean: -0.11880
[32m[0906 19-31-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31962, current rewards: -251.77450, mean: -0.13536
[32m[0906 19-31-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32044, current rewards: -272.25747, mean: -0.14254
[32m[0906 19-31-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32124, current rewards: -309.89078, mean: -0.15811
[32m[0906 19-32-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32198, current rewards: -326.38237, mean: -0.16238
[32m[0906 19-32-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32274, current rewards: -368.25814, mean: -0.17877
[32m[0906 19-32-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32342, current rewards: -385.38332, mean: -0.18265
[32m[0906 19-33-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32410, current rewards: -426.65754, mean: -0.19753
[32m[0906 19-33-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32475, current rewards: -440.01252, mean: -0.19910
[32m[0906 19-33-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32534, current rewards: -439.40900, mean: -0.19443
[32m[0906 19-33-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32591, current rewards: -424.23869, mean: -0.18365
[32m[0906 19-34-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32629, current rewards: -402.88574, mean: -0.17071
[32m[0906 19-34-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32665, current rewards: -387.65903, mean: -0.16085
[32m[0906 19-34-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32700, current rewards: -366.73536, mean: -0.14908
[32m[0906 19-34-58 @Agent.py:117][0m Average action selection time: 0.3273
[32m[0906 19-34-58 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-34-58 @MBExp.py:227][0m Rewards obtained: [-356.65557907519866], Lows: [424], Highs: [20], Total time: 20682.717492999996
[32m[0906 19-35-52 @MBExp.py:144][0m ####################################################################
[32m[0906 19-35-52 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 19-35-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34687, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-36-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34500, current rewards: -17.97154, mean: -0.29953
[32m[0906 19-36-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34500, current rewards: -9.86780, mean: -0.08971
[32m[0906 19-36-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34679, current rewards: -1.68490, mean: -0.01053
[32m[0906 19-37-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34859, current rewards: 6.89501, mean: 0.03283
[32m[0906 19-37-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34972, current rewards: 15.50148, mean: 0.05962
[32m[0906 19-37-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34929, current rewards: 24.10887, mean: 0.07777
[32m[0906 19-37-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34864, current rewards: 32.70596, mean: 0.09085
[32m[0906 19-38-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34809, current rewards: 41.31072, mean: 0.10076
[32m[0906 19-38-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34831, current rewards: 49.88534, mean: 0.10845
[32m[0906 19-38-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34867, current rewards: 58.46974, mean: 0.11465
[32m[0906 19-39-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34903, current rewards: 67.06619, mean: 0.11976
[32m[0906 19-39-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34925, current rewards: 75.65668, mean: 0.12403
[32m[0906 19-39-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34948, current rewards: 65.50595, mean: 0.09925
[32m[0906 19-40-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34977, current rewards: 67.73952, mean: 0.09541
[32m[0906 19-40-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34997, current rewards: 75.64306, mean: 0.09953
[32m[0906 19-40-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35016, current rewards: 83.56784, mean: 0.10317
[32m[0906 19-40-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35032, current rewards: 91.49936, mean: 0.10639
[32m[0906 19-41-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35046, current rewards: 99.43746, mean: 0.10927
[32m[0906 19-41-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35053, current rewards: 107.03110, mean: 0.11149
[32m[0906 19-41-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35060, current rewards: 114.95445, mean: 0.11382
[32m[0906 19-42-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35064, current rewards: 122.89647, mean: 0.11594
[32m[0906 19-42-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35074, current rewards: 130.81415, mean: 0.11785
[32m[0906 19-42-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35079, current rewards: 138.74444, mean: 0.11961
[32m[0906 19-42-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35083, current rewards: 146.67915, mean: 0.12122
[32m[0906 19-43-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35084, current rewards: 132.59299, mean: 0.10523
[32m[0906 19-43-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35092, current rewards: 137.41047, mean: 0.10489
[32m[0906 19-43-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35100, current rewards: 135.32383, mean: 0.09950
[32m[0906 19-44-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35101, current rewards: 142.48688, mean: 0.10105
[32m[0906 19-44-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35102, current rewards: 149.74135, mean: 0.10256
[32m[0906 19-44-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34990, current rewards: 156.99796, mean: 0.10397
[32m[0906 19-44-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34877, current rewards: 121.40310, mean: 0.07782
[32m[0906 19-45-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34774, current rewards: 128.50648, mean: 0.07982
[32m[0906 19-45-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34676, current rewards: 135.77409, mean: 0.08179
[32m[0906 19-45-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34583, current rewards: 143.05377, mean: 0.08366
[32m[0906 19-45-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34496, current rewards: 149.90931, mean: 0.08518
[32m[0906 19-46-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34413, current rewards: 157.07718, mean: 0.08678
[32m[0906 19-46-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34333, current rewards: 164.29819, mean: 0.08833
[32m[0906 19-46-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34256, current rewards: 171.50898, mean: 0.08980
[32m[0906 19-47-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34183, current rewards: 178.72828, mean: 0.09119
[32m[0906 19-47-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34114, current rewards: 139.12169, mean: 0.06921
[32m[0906 19-47-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34047, current rewards: 123.45891, mean: 0.05993
[32m[0906 19-47-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33985, current rewards: 129.68343, mean: 0.06146
[32m[0906 19-48-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33926, current rewards: 135.91942, mean: 0.06293
[32m[0906 19-48-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33869, current rewards: 142.15565, mean: 0.06432
[32m[0906 19-48-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33816, current rewards: 148.39173, mean: 0.06566
[32m[0906 19-48-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33764, current rewards: 128.27691, mean: 0.05553
[32m[0906 19-49-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33700, current rewards: 135.12783, mean: 0.05726
[32m[0906 19-49-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33639, current rewards: 142.06848, mean: 0.05895
[32m[0906 19-49-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33581, current rewards: 149.00325, mean: 0.06057
[32m[0906 19-49-51 @Agent.py:117][0m Average action selection time: 0.3354
[32m[0906 19-49-51 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-49-51 @MBExp.py:227][0m Rewards obtained: [154.55367316096059], Lows: [61], Highs: [85], Total time: 21521.827600999997
[32m[0906 19-50-40 @MBExp.py:144][0m ####################################################################
[32m[0906 19-50-40 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 19-50-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30892, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-50-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30858, current rewards: -16.19897, mean: -0.26998
[32m[0906 19-51-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30846, current rewards: -12.69913, mean: -0.11545
[32m[0906 19-51-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31015, current rewards: -9.19957, mean: -0.05750
[32m[0906 19-51-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31138, current rewards: -5.69978, mean: -0.02714
[32m[0906 19-52-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31237, current rewards: -2.20284, mean: -0.00847
[32m[0906 19-52-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31201, current rewards: 1.29526, mean: 0.00418
[32m[0906 19-52-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31157, current rewards: 4.79479, mean: 0.01332
[32m[0906 19-52-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31127, current rewards: 8.29587, mean: 0.02023
[32m[0906 19-53-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31150, current rewards: 11.96259, mean: 0.02601
[32m[0906 19-53-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31192, current rewards: 16.37826, mean: 0.03211
[32m[0906 19-53-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31231, current rewards: -20.12072, mean: -0.03593
[32m[0906 19-53-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31256, current rewards: -15.48414, mean: -0.02538
[32m[0906 19-54-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31286, current rewards: -10.85444, mean: -0.01645
[32m[0906 19-54-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31310, current rewards: -6.22275, mean: -0.00876
[32m[0906 19-54-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31318, current rewards: -1.59450, mean: -0.00210
[32m[0906 19-54-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31330, current rewards: 3.03268, mean: 0.00374
[32m[0906 19-55-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31340, current rewards: 7.66079, mean: 0.00891
[32m[0906 19-55-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31347, current rewards: 13.01308, mean: 0.01430
[32m[0906 19-55-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31351, current rewards: 9.30013, mean: 0.00969
[32m[0906 19-55-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31350, current rewards: -16.46979, mean: -0.01631
[32m[0906 19-56-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31352, current rewards: -9.19557, mean: -0.00868
[32m[0906 19-56-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31357, current rewards: -1.92136, mean: -0.00173
[32m[0906 19-56-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31360, current rewards: -0.37457, mean: -0.00032
[32m[0906 19-57-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31363, current rewards: -50.37457, mean: -0.04163
[32m[0906 19-57-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31368, current rewards: -100.37457, mean: -0.07966
[32m[0906 19-57-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31370, current rewards: -150.37457, mean: -0.11479
[32m[0906 19-57-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31377, current rewards: -200.37457, mean: -0.14733
[32m[0906 19-58-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31375, current rewards: -250.37457, mean: -0.17757
[32m[0906 19-58-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31375, current rewards: -300.37457, mean: -0.20574
[32m[0906 19-58-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31374, current rewards: -350.37457, mean: -0.23204
[32m[0906 19-58-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31377, current rewards: -400.37457, mean: -0.25665
[32m[0906 19-59-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31375, current rewards: -450.37457, mean: -0.27974
[32m[0906 19-59-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31374, current rewards: -500.37457, mean: -0.30143
[32m[0906 19-59-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31374, current rewards: -550.37457, mean: -0.32186
[32m[0906 19-59-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31376, current rewards: -600.37457, mean: -0.34112
[32m[0906 20-00-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31377, current rewards: -650.37457, mean: -0.35932
[32m[0906 20-00-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31378, current rewards: -700.37457, mean: -0.37655
[32m[0906 20-00-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31380, current rewards: -750.37457, mean: -0.39287
[32m[0906 20-00-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31378, current rewards: -800.37457, mean: -0.40835
[32m[0906 20-01-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31379, current rewards: -850.37457, mean: -0.42307
[32m[0906 20-01-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31379, current rewards: -900.37457, mean: -0.43708
[32m[0906 20-01-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31380, current rewards: -950.37457, mean: -0.45041
[32m[0906 20-01-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31381, current rewards: -1000.37457, mean: -0.46314
[32m[0906 20-02-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31381, current rewards: -1050.37457, mean: -0.47528
[32m[0906 20-02-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31383, current rewards: -1100.37457, mean: -0.48689
[32m[0906 20-02-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31383, current rewards: -1150.37457, mean: -0.49800
[32m[0906 20-03-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31370, current rewards: -1200.37457, mean: -0.50863
[32m[0906 20-03-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31358, current rewards: -1250.37457, mean: -0.51883
[32m[0906 20-03-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31346, current rewards: -1300.37457, mean: -0.52861
[32m[0906 20-03-44 @Agent.py:117][0m Average action selection time: 0.3134
[32m[0906 20-03-44 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-03-45 @MBExp.py:227][0m Rewards obtained: [-1340.3745667300104], Lows: [40], Highs: [1365], Total time: 22305.872110999997
[32m[0906 20-04-36 @MBExp.py:144][0m ####################################################################
[32m[0906 20-04-36 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 20-04-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31070, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-04-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30915, current rewards: -15.79622, mean: -0.26327
[32m[0906 20-05-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30879, current rewards: -10.38605, mean: -0.09442
[32m[0906 20-05-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31081, current rewards: -5.03144, mean: -0.03145
[32m[0906 20-05-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31220, current rewards: 0.32977, mean: 0.00157
[32m[0906 20-05-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31295, current rewards: 5.68616, mean: 0.02187
[32m[0906 20-06-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31258, current rewards: 11.04403, mean: 0.03563
[32m[0906 20-06-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31199, current rewards: 16.40587, mean: 0.04557
[32m[0906 20-06-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31167, current rewards: 21.75958, mean: 0.05307
[32m[0906 20-07-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31164, current rewards: 27.11376, mean: 0.05894
[32m[0906 20-07-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31200, current rewards: 32.27849, mean: 0.06329
[32m[0906 20-07-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31236, current rewards: 38.78863, mean: 0.06927
[32m[0906 20-07-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31264, current rewards: 45.30411, mean: 0.07427
[32m[0906 20-08-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31284, current rewards: 51.81787, mean: 0.07851
[32m[0906 20-08-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31307, current rewards: 26.37526, mean: 0.03715
[32m[0906 20-08-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31328, current rewards: 24.01106, mean: 0.03159
[32m[0906 20-08-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31337, current rewards: 32.26311, mean: 0.03983
[32m[0906 20-09-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31354, current rewards: 40.50841, mean: 0.04710
[32m[0906 20-09-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31366, current rewards: 48.76871, mean: 0.05359
[32m[0906 20-09-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31386, current rewards: 56.68454, mean: 0.05905
[32m[0906 20-09-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31392, current rewards: 61.44454, mean: 0.06084
[32m[0906 20-10-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31403, current rewards: 66.97551, mean: 0.06318
[32m[0906 20-10-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31411, current rewards: 72.50393, mean: 0.06532
[32m[0906 20-10-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31413, current rewards: 78.03441, mean: 0.06727
[32m[0906 20-10-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31416, current rewards: 83.57019, mean: 0.06907
[32m[0906 20-11-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31419, current rewards: 89.10299, mean: 0.07072
[32m[0906 20-11-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31427, current rewards: 94.63236, mean: 0.07224
[32m[0906 20-11-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31428, current rewards: 100.16188, mean: 0.07365
[32m[0906 20-12-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31431, current rewards: 105.68569, mean: 0.07495
[32m[0906 20-12-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31435, current rewards: 52.19028, mean: 0.03575
[32m[0906 20-12-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31437, current rewards: 4.11656, mean: 0.00273
[32m[0906 20-12-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31438, current rewards: -37.70751, mean: -0.02417
[32m[0906 20-13-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31437, current rewards: -69.98829, mean: -0.04347
[32m[0906 20-13-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31437, current rewards: -79.99193, mean: -0.04819
[32m[0906 20-13-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31496, current rewards: -130.04312, mean: -0.07605
[32m[0906 20-13-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31597, current rewards: -163.83938, mean: -0.09309
[32m[0906 20-14-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31693, current rewards: -222.01846, mean: -0.12266
[32m[0906 20-14-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31790, current rewards: -275.24870, mean: -0.14798
[32m[0906 20-14-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31882, current rewards: -308.48231, mean: -0.16151
[32m[0906 20-15-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31965, current rewards: -349.49907, mean: -0.17832
[32m[0906 20-15-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32046, current rewards: -404.88905, mean: -0.20144
[32m[0906 20-15-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32125, current rewards: -453.37508, mean: -0.22008
[32m[0906 20-15-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32199, current rewards: -486.29953, mean: -0.23047
[32m[0906 20-16-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32266, current rewards: -528.92411, mean: -0.24487
[32m[0906 20-16-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32331, current rewards: -586.90799, mean: -0.26557
[32m[0906 20-16-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32391, current rewards: -631.16744, mean: -0.27928
[32m[0906 20-17-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32450, current rewards: -663.85426, mean: -0.28738
[32m[0906 20-17-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32491, current rewards: -711.16150, mean: -0.30134
[32m[0906 20-17-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32530, current rewards: -769.22934, mean: -0.31918
[32m[0906 20-17-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32566, current rewards: -808.91042, mean: -0.32883
[32m[0906 20-18-12 @Agent.py:117][0m Average action selection time: 0.3259
[32m[0906 20-18-12 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-18-12 @MBExp.py:227][0m Rewards obtained: [-844.7535806379557], Lows: [571], Highs: [41], Total time: 23121.304149999996
[32m[0906 20-19-11 @MBExp.py:144][0m ####################################################################
[32m[0906 20-19-11 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 20-19-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34347, current rewards: -6.84825, mean: -0.68482
[32m[0906 20-19-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34372, current rewards: -31.13882, mean: -0.51898
[32m[0906 20-19-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34367, current rewards: -26.08893, mean: -0.23717
[32m[0906 20-20-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34578, current rewards: -21.03905, mean: -0.13149
[32m[0906 20-20-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34754, current rewards: -15.98918, mean: -0.07614
[32m[0906 20-20-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34860, current rewards: -10.93930, mean: -0.04207
[32m[0906 20-20-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34831, current rewards: -5.88942, mean: -0.01900
[32m[0906 20-21-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34786, current rewards: -0.83955, mean: -0.00233
[32m[0906 20-21-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34744, current rewards: -15.06496, mean: -0.03674
[32m[0906 20-21-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34748, current rewards: -65.06496, mean: -0.14145
[32m[0906 20-22-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34802, current rewards: -115.06496, mean: -0.22562
[32m[0906 20-22-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34834, current rewards: -165.06496, mean: -0.29476
[32m[0906 20-22-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34879, current rewards: -215.06496, mean: -0.35257
[32m[0906 20-23-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34910, current rewards: -265.06496, mean: -0.40161
[32m[0906 20-23-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34934, current rewards: -315.06496, mean: -0.44375
[32m[0906 20-23-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34948, current rewards: -365.06496, mean: -0.48035
[32m[0906 20-23-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34960, current rewards: -415.06496, mean: -0.51243
[32m[0906 20-24-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34974, current rewards: -465.06496, mean: -0.54077
[32m[0906 20-24-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34986, current rewards: -515.06496, mean: -0.56601
[32m[0906 20-24-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35002, current rewards: -565.06496, mean: -0.58861
[32m[0906 20-25-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35007, current rewards: -615.06496, mean: -0.60898
[32m[0906 20-25-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35014, current rewards: -665.06496, mean: -0.62742
[32m[0906 20-25-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35018, current rewards: -715.06496, mean: -0.64420
[32m[0906 20-25-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35024, current rewards: -765.06496, mean: -0.65954
[32m[0906 20-26-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35030, current rewards: -815.06496, mean: -0.67361
[32m[0906 20-26-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35037, current rewards: -865.06496, mean: -0.68656
[32m[0906 20-26-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35041, current rewards: -915.06496, mean: -0.69852
[32m[0906 20-27-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35042, current rewards: -965.06496, mean: -0.70961
[32m[0906 20-27-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35043, current rewards: -1015.06496, mean: -0.71990
[32m[0906 20-27-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35047, current rewards: -1065.06496, mean: -0.72950
[32m[0906 20-28-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35051, current rewards: -1115.06496, mean: -0.73845
[32m[0906 20-28-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35056, current rewards: -1165.06496, mean: -0.74684
[32m[0906 20-28-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35058, current rewards: -1215.06496, mean: -0.75470
[32m[0906 20-28-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35061, current rewards: -1265.06496, mean: -0.76209
[32m[0906 20-29-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35062, current rewards: -1315.06496, mean: -0.76904
[32m[0906 20-29-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35066, current rewards: -1365.06496, mean: -0.77561
[32m[0906 20-29-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35068, current rewards: -1415.06496, mean: -0.78180
[32m[0906 20-30-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35071, current rewards: -1465.06496, mean: -0.78767
[32m[0906 20-30-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35076, current rewards: -1515.06496, mean: -0.79323
[32m[0906 20-30-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35080, current rewards: -1565.06496, mean: -0.79850
[32m[0906 20-30-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35079, current rewards: -1615.06496, mean: -0.80351
[32m[0906 20-31-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35080, current rewards: -1665.06496, mean: -0.80828
[32m[0906 20-31-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35080, current rewards: -1715.06496, mean: -0.81283
[32m[0906 20-31-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35081, current rewards: -1765.06496, mean: -0.81716
[32m[0906 20-32-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35081, current rewards: -1815.06496, mean: -0.82130
[32m[0906 20-32-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35081, current rewards: -1865.06496, mean: -0.82525
[32m[0906 20-32-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35079, current rewards: -1915.06496, mean: -0.82903
[32m[0906 20-32-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35064, current rewards: -1965.06496, mean: -0.83265
[32m[0906 20-33-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35051, current rewards: -2015.06496, mean: -0.83613
[32m[0906 20-33-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35035, current rewards: -2065.06496, mean: -0.83946
[32m[0906 20-33-47 @Agent.py:117][0m Average action selection time: 0.3502
[32m[0906 20-33-47 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-33-47 @MBExp.py:227][0m Rewards obtained: [-2105.064955803523], Lows: [16], Highs: [2114], Total time: 23997.455336999996
[32m[0906 20-34-48 @MBExp.py:144][0m ####################################################################
[32m[0906 20-34-48 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 20-34-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34556, current rewards: 0.69790, mean: 0.06979
[32m[0906 20-35-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34471, current rewards: 5.84957, mean: 0.09749
[32m[0906 20-35-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34455, current rewards: 11.63537, mean: 0.10578
[32m[0906 20-35-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34617, current rewards: 17.43084, mean: 0.10894
[32m[0906 20-36-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34780, current rewards: 23.22103, mean: 0.11058
[32m[0906 20-36-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34878, current rewards: 29.01446, mean: 0.11159
[32m[0906 20-36-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34834, current rewards: 34.80486, mean: 0.11227
[32m[0906 20-36-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35176, current rewards: 40.59729, mean: 0.11277
[32m[0906 20-37-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35090, current rewards: 46.73425, mean: 0.11399
[32m[0906 20-37-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35043, current rewards: 52.69252, mean: 0.11455
[32m[0906 20-37-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35071, current rewards: 46.33856, mean: 0.09086
[32m[0906 20-38-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35090, current rewards: -1.15650, mean: -0.00207
[32m[0906 20-38-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35107, current rewards: -41.04885, mean: -0.06729
[32m[0906 20-38-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35119, current rewards: -80.34191, mean: -0.12173
[32m[0906 20-38-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35132, current rewards: -117.55074, mean: -0.16556
[32m[0906 20-39-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35141, current rewards: -144.51800, mean: -0.19016
[32m[0906 20-39-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35143, current rewards: -155.83224, mean: -0.19239
[32m[0906 20-39-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35150, current rewards: -185.24371, mean: -0.21540
[32m[0906 20-40-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35156, current rewards: -206.88219, mean: -0.22734
[32m[0906 20-40-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35161, current rewards: -204.25227, mean: -0.21276
[32m[0906 20-40-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35165, current rewards: -201.59331, mean: -0.19960
[32m[0906 20-41-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35171, current rewards: -198.94448, mean: -0.18768
[32m[0906 20-41-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35174, current rewards: -196.31160, mean: -0.17686
[32m[0906 20-41-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35173, current rewards: -194.37963, mean: -0.16757
[32m[0906 20-41-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35173, current rewards: -191.50323, mean: -0.15827
[32m[0906 20-42-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35166, current rewards: -229.30081, mean: -0.18198
[32m[0906 20-42-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35163, current rewards: -224.52256, mean: -0.17139
[32m[0906 20-42-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35162, current rewards: -219.67695, mean: -0.16153
[32m[0906 20-43-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35161, current rewards: -214.86945, mean: -0.15239
[32m[0906 20-43-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35161, current rewards: -210.17562, mean: -0.14396
[32m[0906 20-43-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35156, current rewards: -205.40234, mean: -0.13603
[32m[0906 20-43-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35156, current rewards: -200.51915, mean: -0.12854
[32m[0906 20-44-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35158, current rewards: -195.73119, mean: -0.12157
[32m[0906 20-44-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35162, current rewards: -190.12195, mean: -0.11453
[32m[0906 20-44-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35201, current rewards: -185.15651, mean: -0.10828
[32m[0906 20-45-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35263, current rewards: -193.50178, mean: -0.10994
[32m[0906 20-45-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35325, current rewards: -197.63488, mean: -0.10919
[32m[0906 20-45-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35382, current rewards: -192.71164, mean: -0.10361
[32m[0906 20-46-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35436, current rewards: -187.79280, mean: -0.09832
[32m[0906 20-46-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35487, current rewards: -182.86872, mean: -0.09330
[32m[0906 20-46-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35535, current rewards: -177.94756, mean: -0.08853
[32m[0906 20-47-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35582, current rewards: -174.13036, mean: -0.08453
[32m[0906 20-47-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35631, current rewards: -170.10886, mean: -0.08062
[32m[0906 20-47-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35673, current rewards: -166.03475, mean: -0.07687
[32m[0906 20-47-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35715, current rewards: -161.95849, mean: -0.07328
[32m[0906 20-48-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35711, current rewards: -179.20852, mean: -0.07930
[32m[0906 20-48-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35694, current rewards: -174.86099, mean: -0.07570
[32m[0906 20-48-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35667, current rewards: -170.92674, mean: -0.07243
[32m[0906 20-49-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35639, current rewards: -166.99174, mean: -0.06929
[32m[0906 20-49-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35613, current rewards: -162.39731, mean: -0.06602
[32m[0906 20-49-38 @Agent.py:117][0m Average action selection time: 0.3559
[32m[0906 20-49-38 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-49-39 @MBExp.py:227][0m Rewards obtained: [-158.27657198055658], Lows: [160], Highs: [62], Total time: 24887.780380999997
[32m[0906 20-50-42 @MBExp.py:144][0m ####################################################################
[32m[0906 20-50-42 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 20-50-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34422, current rewards: 1.26892, mean: 0.12689
[32m[0906 20-51-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34479, current rewards: -18.41596, mean: -0.30693
[32m[0906 20-51-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34457, current rewards: -6.54861, mean: -0.05953
[32m[0906 20-51-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34683, current rewards: 3.51687, mean: 0.02198
[32m[0906 20-51-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34810, current rewards: 13.47221, mean: 0.06415
[32m[0906 20-52-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34889, current rewards: 23.42662, mean: 0.09010
[32m[0906 20-52-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34831, current rewards: 8.20362, mean: 0.02646
[32m[0906 20-52-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34766, current rewards: 12.46760, mean: 0.03463
[32m[0906 20-53-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34726, current rewards: 17.82270, mean: 0.04347
[32m[0906 20-53-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34700, current rewards: 22.94682, mean: 0.04988
[32m[0906 20-53-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34763, current rewards: 28.07014, mean: 0.05504
[32m[0906 20-53-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34804, current rewards: 33.19044, mean: 0.05927
[32m[0906 20-54-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34837, current rewards: 38.31236, mean: 0.06281
[32m[0906 20-54-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34866, current rewards: 43.44090, mean: 0.06582
[32m[0906 20-54-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34886, current rewards: 19.13282, mean: 0.02695
[32m[0906 20-55-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34902, current rewards: -64.56612, mean: -0.08496
[32m[0906 20-55-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34923, current rewards: -155.15464, mean: -0.19155
[32m[0906 20-55-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34937, current rewards: -245.59225, mean: -0.28557
[32m[0906 20-56-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34951, current rewards: -331.29477, mean: -0.36406
[32m[0906 20-56-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34967, current rewards: -421.76458, mean: -0.43934
[32m[0906 20-56-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34984, current rewards: -512.20662, mean: -0.50714
[32m[0906 20-56-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34990, current rewards: -597.88803, mean: -0.56405
[32m[0906 20-57-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34996, current rewards: -688.34247, mean: -0.62013
[32m[0906 20-57-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35007, current rewards: -774.07126, mean: -0.66730
[32m[0906 20-57-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35013, current rewards: -858.32033, mean: -0.70936
[32m[0906 20-58-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35016, current rewards: -863.52718, mean: -0.68534
[32m[0906 20-58-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35021, current rewards: -857.43957, mean: -0.65453
[32m[0906 20-58-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35027, current rewards: -851.32295, mean: -0.62597
[32m[0906 20-58-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35027, current rewards: -845.19339, mean: -0.59943
[32m[0906 20-59-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35027, current rewards: -845.44253, mean: -0.57907
[32m[0906 20-59-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35031, current rewards: -878.26231, mean: -0.58163
[32m[0906 20-59-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35037, current rewards: -871.31030, mean: -0.55853
[32m[0906 21-00-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35039, current rewards: -865.29120, mean: -0.53745
[32m[0906 21-00-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35041, current rewards: -858.62723, mean: -0.51725
[32m[0906 21-00-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35042, current rewards: -851.96520, mean: -0.49823
[32m[0906 21-00-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35045, current rewards: -873.03208, mean: -0.49604
[32m[0906 21-01-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35047, current rewards: -878.97328, mean: -0.48562
[32m[0906 21-01-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35049, current rewards: -870.68234, mean: -0.46811
[32m[0906 21-01-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35049, current rewards: -862.38793, mean: -0.45151
[32m[0906 21-02-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35048, current rewards: -854.09707, mean: -0.43576
[32m[0906 21-02-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35050, current rewards: -847.53806, mean: -0.42166
[32m[0906 21-02-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35053, current rewards: -839.35518, mean: -0.40745
[32m[0906 21-03-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35053, current rewards: -831.21645, mean: -0.39394
[32m[0906 21-03-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35055, current rewards: -823.06878, mean: -0.38105
[32m[0906 21-03-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35055, current rewards: -839.82499, mean: -0.38001
[32m[0906 21-03-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35057, current rewards: -835.63071, mean: -0.36975
[32m[0906 21-04-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35055, current rewards: -831.42691, mean: -0.35993
[32m[0906 21-04-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35040, current rewards: -827.22145, mean: -0.35052
[32m[0906 21-04-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35026, current rewards: -821.72372, mean: -0.34096
[32m[0906 21-05-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35013, current rewards: -817.61300, mean: -0.33236
[32m[0906 21-05-17 @Agent.py:117][0m Average action selection time: 0.3499
[32m[0906 21-05-17 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-05-17 @MBExp.py:227][0m Rewards obtained: [-812.7966038867285], Lows: [518], Highs: [61], Total time: 25763.238459999997
[32m[0906 21-06-22 @MBExp.py:144][0m ####################################################################
[32m[0906 21-06-22 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 21-06-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34338, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-06-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34401, current rewards: -36.94742, mean: -0.61579
[32m[0906 21-07-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34366, current rewards: -38.52818, mean: -0.35026
[32m[0906 21-07-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34643, current rewards: -57.94589, mean: -0.36216
[32m[0906 21-07-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34776, current rewards: -89.19157, mean: -0.42472
[32m[0906 21-07-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34889, current rewards: -76.62613, mean: -0.29472
[32m[0906 21-08-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34824, current rewards: -111.34883, mean: -0.35919
[32m[0906 21-08-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34784, current rewards: -145.66606, mean: -0.40463
[32m[0906 21-08-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34749, current rewards: -152.93019, mean: -0.37300
[32m[0906 21-09-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34728, current rewards: -159.26224, mean: -0.34622
[32m[0906 21-09-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34779, current rewards: -197.35109, mean: -0.38696
[32m[0906 21-09-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34818, current rewards: -207.18341, mean: -0.36997
[32m[0906 21-09-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34858, current rewards: -243.75960, mean: -0.39961
[32m[0906 21-10-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34891, current rewards: -278.80901, mean: -0.42244
[32m[0906 21-10-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34910, current rewards: -313.69606, mean: -0.44183
[32m[0906 21-10-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34937, current rewards: -348.13356, mean: -0.45807
[32m[0906 21-11-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34955, current rewards: -392.88861, mean: -0.48505
[32m[0906 21-11-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34979, current rewards: -435.51741, mean: -0.50642
[32m[0906 21-11-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34996, current rewards: -477.75618, mean: -0.52501
[32m[0906 21-11-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35011, current rewards: -520.23586, mean: -0.54191
[32m[0906 21-12-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35020, current rewards: -562.79906, mean: -0.55723
[32m[0906 21-12-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35029, current rewards: -552.87988, mean: -0.52158
[32m[0906 21-12-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35041, current rewards: -511.80957, mean: -0.46109
[32m[0906 21-13-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35046, current rewards: -499.64018, mean: -0.43072
[32m[0906 21-13-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35047, current rewards: -477.95234, mean: -0.39500
[32m[0906 21-13-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35054, current rewards: -465.82424, mean: -0.36970
[32m[0906 21-14-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35060, current rewards: -498.02507, mean: -0.38017
[32m[0906 21-14-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35064, current rewards: -529.82349, mean: -0.38958
[32m[0906 21-14-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35065, current rewards: -579.25498, mean: -0.41082
[32m[0906 21-14-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35066, current rewards: -628.91850, mean: -0.43077
[32m[0906 21-15-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35065, current rewards: -668.83659, mean: -0.44294
[32m[0906 21-15-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35069, current rewards: -714.26442, mean: -0.45786
[32m[0906 21-15-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35071, current rewards: -718.89931, mean: -0.44652
[32m[0906 21-16-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35075, current rewards: -715.74793, mean: -0.43117
[32m[0906 21-16-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35079, current rewards: -712.19425, mean: -0.41649
[32m[0906 21-16-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35085, current rewards: -708.40148, mean: -0.40250
[32m[0906 21-16-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35088, current rewards: -704.49863, mean: -0.38923
[32m[0906 21-17-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35090, current rewards: -737.23832, mean: -0.39636
[32m[0906 21-17-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35093, current rewards: -739.73592, mean: -0.38730
[32m[0906 21-17-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35099, current rewards: -778.44097, mean: -0.39716
[32m[0906 21-18-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35097, current rewards: -791.63451, mean: -0.39385
[32m[0906 21-18-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35100, current rewards: -818.82664, mean: -0.39749
[32m[0906 21-18-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35101, current rewards: -852.84030, mean: -0.40419
[32m[0906 21-19-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35103, current rewards: -883.28622, mean: -0.40893
[32m[0906 21-19-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35103, current rewards: -912.98037, mean: -0.41311
[32m[0906 21-19-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35106, current rewards: -942.78668, mean: -0.41716
[32m[0906 21-19-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35101, current rewards: -996.36639, mean: -0.43133
[32m[0906 21-20-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35086, current rewards: -1041.90337, mean: -0.44148
[32m[0906 21-20-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35071, current rewards: -1078.60830, mean: -0.44756
[32m[0906 21-20-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35056, current rewards: -1143.92395, mean: -0.46501
[32m[0906 21-20-59 @Agent.py:117][0m Average action selection time: 0.3503
[32m[0906 21-20-59 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-20-59 @MBExp.py:227][0m Rewards obtained: [-1182.4353961239142], Lows: [793], Highs: [80], Total time: 26639.693938999997
[32m[0906 21-22-06 @MBExp.py:144][0m ####################################################################
[32m[0906 21-22-06 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 21-22-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34388, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-22-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34444, current rewards: -18.77815, mean: -0.31297
[32m[0906 21-22-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34423, current rewards: -10.93973, mean: -0.09945
[32m[0906 21-23-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34685, current rewards: -2.13822, mean: -0.01336
[32m[0906 21-23-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34861, current rewards: 6.69458, mean: 0.03188
[32m[0906 21-23-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34952, current rewards: 16.09700, mean: 0.06191
[32m[0906 21-23-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34876, current rewards: -6.55361, mean: -0.02114
[32m[0906 21-24-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34820, current rewards: 1.96768, mean: 0.00547
[32m[0906 21-24-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34770, current rewards: -10.49894, mean: -0.02561
[32m[0906 21-24-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34731, current rewards: -7.71456, mean: -0.01677
[32m[0906 21-25-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34790, current rewards: -3.71346, mean: -0.00728
[32m[0906 21-25-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34838, current rewards: 0.28966, mean: 0.00052
[32m[0906 21-25-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34883, current rewards: 4.29680, mean: 0.00704
[32m[0906 21-25-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34907, current rewards: 8.30310, mean: 0.01258
[32m[0906 21-26-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34926, current rewards: 12.21876, mean: 0.01721
[32m[0906 21-26-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34948, current rewards: 16.29629, mean: 0.02144
[32m[0906 21-26-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34962, current rewards: -17.77374, mean: -0.02194
[32m[0906 21-27-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34981, current rewards: -11.38870, mean: -0.01324
[32m[0906 21-27-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34993, current rewards: -5.49642, mean: -0.00604
[32m[0906 21-27-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35008, current rewards: 0.37694, mean: 0.00039
[32m[0906 21-28-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35015, current rewards: 6.24754, mean: 0.00619
[32m[0906 21-28-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35023, current rewards: 12.12210, mean: 0.01144
[32m[0906 21-28-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35035, current rewards: 25.84378, mean: 0.02328
[32m[0906 21-28-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35043, current rewards: 33.22967, mean: 0.02865
[32m[0906 21-29-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35051, current rewards: 15.55121, mean: 0.01285
[32m[0906 21-29-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35062, current rewards: 22.08549, mean: 0.01753
[32m[0906 21-29-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35067, current rewards: 31.18775, mean: 0.02381
[32m[0906 21-30-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35073, current rewards: 30.89555, mean: 0.02272
[32m[0906 21-30-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35078, current rewards: 22.86762, mean: 0.01622
[32m[0906 21-30-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35085, current rewards: 28.76791, mean: 0.01970
[32m[0906 21-30-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35088, current rewards: 33.79406, mean: 0.02238
[32m[0906 21-31-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35091, current rewards: 39.01190, mean: 0.02501
[32m[0906 21-31-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35096, current rewards: 44.44920, mean: 0.02761
[32m[0906 21-31-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35099, current rewards: 49.88836, mean: 0.03005
[32m[0906 21-32-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35100, current rewards: 13.44283, mean: 0.00786
[32m[0906 21-32-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35101, current rewards: 21.09005, mean: 0.01198
[32m[0906 21-32-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35107, current rewards: 28.66696, mean: 0.01584
[32m[0906 21-32-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35108, current rewards: 36.24899, mean: 0.01949
[32m[0906 21-33-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35111, current rewards: 43.81952, mean: 0.02294
[32m[0906 21-33-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35112, current rewards: 51.39401, mean: 0.02622
[32m[0906 21-33-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35116, current rewards: 58.96986, mean: 0.02934
[32m[0906 21-34-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35119, current rewards: 66.55364, mean: 0.03231
[32m[0906 21-34-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35121, current rewards: 74.13020, mean: 0.03513
[32m[0906 21-34-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35122, current rewards: 81.70313, mean: 0.03783
[32m[0906 21-35-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35120, current rewards: 48.39934, mean: 0.02190
[32m[0906 21-35-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35121, current rewards: 47.39023, mean: 0.02097
[32m[0906 21-35-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35115, current rewards: 52.79098, mean: 0.02285
[32m[0906 21-35-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35099, current rewards: 57.98809, mean: 0.02457
[32m[0906 21-36-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35085, current rewards: 63.90115, mean: 0.02651
[32m[0906 21-36-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35071, current rewards: 69.86853, mean: 0.02840
[32m[0906 21-36-42 @Agent.py:117][0m Average action selection time: 0.3505
[32m[0906 21-36-42 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-36-42 @MBExp.py:227][0m Rewards obtained: [74.64474903559272], Lows: [80], Highs: [83], Total time: 27516.497450999996
[32m[0906 21-37-52 @MBExp.py:144][0m ####################################################################
[32m[0906 21-37-52 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 21-37-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34342, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-38-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34471, current rewards: -15.59796, mean: -0.25997
[32m[0906 21-38-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34442, current rewards: -9.45879, mean: -0.08599
[32m[0906 21-38-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34712, current rewards: -3.34920, mean: -0.02093
[32m[0906 21-39-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34854, current rewards: 2.72502, mean: 0.01298
[32m[0906 21-39-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34870, current rewards: -31.77526, mean: -0.12221
[32m[0906 21-39-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34798, current rewards: -24.67594, mean: -0.07960
[32m[0906 21-39-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34739, current rewards: -17.57939, mean: -0.04883
[32m[0906 21-40-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34696, current rewards: -10.48283, mean: -0.02557
[32m[0906 21-40-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34661, current rewards: -3.38628, mean: -0.00736
[32m[0906 21-40-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34732, current rewards: 3.71027, mean: 0.00728
[32m[0906 21-41-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34785, current rewards: -42.86394, mean: -0.07654
[32m[0906 21-41-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34824, current rewards: -92.86394, mean: -0.15224
[32m[0906 21-41-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34852, current rewards: -142.86394, mean: -0.21646
[32m[0906 21-41-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34876, current rewards: -192.86394, mean: -0.27164
[32m[0906 21-42-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34905, current rewards: -242.86394, mean: -0.31956
[32m[0906 21-42-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34928, current rewards: -292.86394, mean: -0.36156
[32m[0906 21-42-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34940, current rewards: -342.86394, mean: -0.39868
[32m[0906 21-43-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34952, current rewards: -392.86394, mean: -0.43172
[32m[0906 21-43-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34976, current rewards: -442.86394, mean: -0.46132
[32m[0906 21-43-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34992, current rewards: -492.86394, mean: -0.48798
[32m[0906 21-44-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35007, current rewards: -542.86394, mean: -0.51214
[32m[0906 21-44-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35014, current rewards: -592.86394, mean: -0.53411
[32m[0906 21-44-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35024, current rewards: -642.86394, mean: -0.55419
[32m[0906 21-44-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35035, current rewards: -692.86394, mean: -0.57261
[32m[0906 21-45-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35044, current rewards: -742.86394, mean: -0.58957
[32m[0906 21-45-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35050, current rewards: -792.86394, mean: -0.60524
[32m[0906 21-45-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35051, current rewards: -842.86394, mean: -0.61975
[32m[0906 21-46-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35054, current rewards: -892.86394, mean: -0.63324
[32m[0906 21-46-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35063, current rewards: -942.86394, mean: -0.64580
[32m[0906 21-46-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35064, current rewards: -992.86394, mean: -0.65753
[32m[0906 21-46-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35069, current rewards: -1042.86394, mean: -0.66850
[32m[0906 21-47-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35073, current rewards: -1092.86394, mean: -0.67880
[32m[0906 21-47-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35077, current rewards: -1142.86394, mean: -0.68847
[32m[0906 21-47-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35082, current rewards: -1192.86394, mean: -0.69758
[32m[0906 21-48-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35088, current rewards: -1242.86394, mean: -0.70617
[32m[0906 21-48-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35092, current rewards: -1292.86394, mean: -0.71429
[32m[0906 21-48-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35094, current rewards: -1342.86394, mean: -0.72197
[32m[0906 21-49-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35094, current rewards: -1392.86394, mean: -0.72925
[32m[0906 21-49-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35097, current rewards: -1442.86394, mean: -0.73616
[32m[0906 21-49-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35102, current rewards: -1492.86394, mean: -0.74272
[32m[0906 21-49-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35106, current rewards: -1542.86394, mean: -0.74896
[32m[0906 21-50-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35108, current rewards: -1592.86394, mean: -0.75491
[32m[0906 21-50-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35109, current rewards: -1642.86394, mean: -0.76059
[32m[0906 21-50-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35110, current rewards: -1692.86394, mean: -0.76600
[32m[0906 21-51-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35110, current rewards: -1742.86394, mean: -0.77118
[32m[0906 21-51-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35107, current rewards: -1792.86394, mean: -0.77613
[32m[0906 21-51-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35090, current rewards: -1842.86394, mean: -0.78087
[32m[0906 21-51-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35075, current rewards: -1892.86394, mean: -0.78542
[32m[0906 21-52-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35060, current rewards: -1942.86394, mean: -0.78978
[32m[0906 21-52-28 @Agent.py:117][0m Average action selection time: 0.3503
[32m[0906 21-52-28 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-52-28 @MBExp.py:227][0m Rewards obtained: [-1982.863940430771], Lows: [21], Highs: [2007], Total time: 28393.010257999995
[32m[0906 21-53-39 @MBExp.py:144][0m ####################################################################
[32m[0906 21-53-39 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 21-53-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34547, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-54-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34497, current rewards: -16.49001, mean: -0.27483
[32m[0906 21-54-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34438, current rewards: -10.48896, mean: -0.09535
[32m[0906 21-54-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34708, current rewards: -4.46564, mean: -0.02791
[32m[0906 21-54-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34825, current rewards: 4.77881, mean: 0.02276
[32m[0906 21-55-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34875, current rewards: 11.01333, mean: 0.04236
[32m[0906 21-55-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34807, current rewards: 17.22567, mean: 0.05557
[32m[0906 21-55-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34755, current rewards: 23.43407, mean: 0.06509
[32m[0906 21-56-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34704, current rewards: 29.64033, mean: 0.07229
[32m[0906 21-56-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34660, current rewards: 35.84616, mean: 0.07793
[32m[0906 21-56-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34718, current rewards: 42.05081, mean: 0.08245
[32m[0906 21-56-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34758, current rewards: 48.26242, mean: 0.08618
[32m[0906 21-57-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34792, current rewards: 54.12095, mean: 0.08872
[32m[0906 21-57-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34816, current rewards: 58.02183, mean: 0.08791
[32m[0906 21-57-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34862, current rewards: 42.49987, mean: 0.05986
[32m[0906 21-58-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34895, current rewards: 46.99368, mean: 0.06183
[32m[0906 21-58-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34914, current rewards: 51.54679, mean: 0.06364
[32m[0906 21-58-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34940, current rewards: 56.09441, mean: 0.06523
[32m[0906 21-58-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34960, current rewards: 60.64763, mean: 0.06665
[32m[0906 21-59-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34973, current rewards: 22.61084, mean: 0.02355
[32m[0906 21-59-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34984, current rewards: 28.28077, mean: 0.02800
[32m[0906 21-59-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34997, current rewards: 34.59619, mean: 0.03264
[32m[0906 22-00-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35004, current rewards: 40.91162, mean: 0.03686
[32m[0906 22-00-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35010, current rewards: 47.22704, mean: 0.04071
[32m[0906 22-00-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35019, current rewards: 19.75321, mean: 0.01632
[32m[0906 22-01-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35024, current rewards: -30.24679, mean: -0.02401
[32m[0906 22-01-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35036, current rewards: -80.24679, mean: -0.06126
[32m[0906 22-01-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35037, current rewards: -130.24679, mean: -0.09577
[32m[0906 22-01-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35038, current rewards: -180.24679, mean: -0.12783
[32m[0906 22-02-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35040, current rewards: -230.24679, mean: -0.15770
[32m[0906 22-02-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35043, current rewards: -280.24679, mean: -0.18559
[32m[0906 22-02-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35045, current rewards: -330.24679, mean: -0.21170
[32m[0906 22-03-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35048, current rewards: -380.24679, mean: -0.23618
[32m[0906 22-03-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35048, current rewards: -430.24679, mean: -0.25918
[32m[0906 22-03-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35049, current rewards: -480.24679, mean: -0.28085
[32m[0906 22-03-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35048, current rewards: -530.24679, mean: -0.30128
[32m[0906 22-04-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35050, current rewards: -580.24679, mean: -0.32058
[32m[0906 22-04-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35051, current rewards: -630.24679, mean: -0.33884
[32m[0906 22-04-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35053, current rewards: -680.24679, mean: -0.35615
[32m[0906 22-05-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35056, current rewards: -730.24679, mean: -0.37257
[32m[0906 22-05-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35056, current rewards: -780.24679, mean: -0.38818
[32m[0906 22-05-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35060, current rewards: -830.24679, mean: -0.40303
[32m[0906 22-05-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35063, current rewards: -880.24679, mean: -0.41718
[32m[0906 22-06-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35061, current rewards: -930.24679, mean: -0.43067
[32m[0906 22-06-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35061, current rewards: -980.24679, mean: -0.44355
[32m[0906 22-06-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35061, current rewards: -1030.24679, mean: -0.45586
[32m[0906 22-07-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35056, current rewards: -1080.24679, mean: -0.46764
[32m[0906 22-07-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35040, current rewards: -1130.24679, mean: -0.47892
[32m[0906 22-07-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35025, current rewards: -1180.24679, mean: -0.48973
[32m[0906 22-08-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35011, current rewards: -1230.24679, mean: -0.50010
[32m[0906 22-08-14 @Agent.py:117][0m Average action selection time: 0.3498
[32m[0906 22-08-14 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-08-14 @MBExp.py:227][0m Rewards obtained: [-1270.2467874510558], Lows: [21], Highs: [1360], Total time: 29268.291968999994
[32m[0906 22-09-27 @MBExp.py:144][0m ####################################################################
[32m[0906 22-09-27 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 22-09-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34201, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-09-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34326, current rewards: -12.30135, mean: -0.20502
[32m[0906 22-10-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34377, current rewards: -3.23105, mean: -0.02937
[32m[0906 22-10-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34677, current rewards: 3.07750, mean: 0.01923
[32m[0906 22-10-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34838, current rewards: 9.82175, mean: 0.04677
[32m[0906 22-10-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34889, current rewards: 16.63991, mean: 0.06400
[32m[0906 22-11-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34808, current rewards: 23.46412, mean: 0.07569
[32m[0906 22-11-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34766, current rewards: 30.28653, mean: 0.08413
[32m[0906 22-11-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34724, current rewards: 37.09463, mean: 0.09047
[32m[0906 22-12-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34690, current rewards: 43.91424, mean: 0.09547
[32m[0906 22-12-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34757, current rewards: 50.72826, mean: 0.09947
[32m[0906 22-12-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34805, current rewards: 18.00343, mean: 0.03215
[32m[0906 22-13-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34838, current rewards: 25.29012, mean: 0.04146
[32m[0906 22-13-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34879, current rewards: 26.42189, mean: 0.04003
[32m[0906 22-13-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34906, current rewards: 29.66102, mean: 0.04178
[32m[0906 22-13-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34926, current rewards: 33.06823, mean: 0.04351
[32m[0906 22-14-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34943, current rewards: 14.28118, mean: 0.01763
[32m[0906 22-14-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34952, current rewards: 19.44801, mean: 0.02261
[32m[0906 22-14-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34966, current rewards: 24.31364, mean: 0.02672
[32m[0906 22-15-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34977, current rewards: 28.75332, mean: 0.02995
[32m[0906 22-15-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34988, current rewards: 12.12107, mean: 0.01200
[32m[0906 22-15-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34997, current rewards: 15.06516, mean: 0.01421
[32m[0906 22-15-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35007, current rewards: 18.04058, mean: 0.01625
[32m[0906 22-16-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35012, current rewards: 21.01792, mean: 0.01812
[32m[0906 22-16-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35017, current rewards: 23.99738, mean: 0.01983
[32m[0906 22-16-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35024, current rewards: 26.97292, mean: 0.02141
[32m[0906 22-17-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35025, current rewards: 29.94880, mean: 0.02286
[32m[0906 22-17-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35033, current rewards: 32.92347, mean: 0.02421
[32m[0906 22-17-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35034, current rewards: 35.81149, mean: 0.02540
[32m[0906 22-17-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35037, current rewards: 38.74147, mean: 0.02654
[32m[0906 22-18-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35039, current rewards: 41.67139, mean: 0.02760
[32m[0906 22-18-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35040, current rewards: 24.18137, mean: 0.01550
[32m[0906 22-18-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35042, current rewards: 27.59059, mean: 0.01714
[32m[0906 22-19-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35043, current rewards: 30.87734, mean: 0.01860
[32m[0906 22-19-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35045, current rewards: 34.14863, mean: 0.01997
[32m[0906 22-19-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35049, current rewards: 37.42178, mean: 0.02126
[32m[0906 22-20-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35051, current rewards: 42.59599, mean: 0.02353
[32m[0906 22-20-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35054, current rewards: 47.24419, mean: 0.02540
[32m[0906 22-20-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35052, current rewards: -52.75581, mean: -0.02762
[32m[0906 22-20-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35055, current rewards: -152.75581, mean: -0.07794
[32m[0906 22-21-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35059, current rewards: -252.75581, mean: -0.12575
[32m[0906 22-21-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35063, current rewards: -352.75581, mean: -0.17124
[32m[0906 22-21-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35065, current rewards: -422.45448, mean: -0.20022
[32m[0906 22-22-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35066, current rewards: -417.87261, mean: -0.19346
[32m[0906 22-22-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35068, current rewards: -412.80738, mean: -0.18679
[32m[0906 22-22-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35068, current rewards: -407.88543, mean: -0.18048
[32m[0906 22-22-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35061, current rewards: -421.84272, mean: -0.18262
[32m[0906 22-23-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35046, current rewards: -521.84272, mean: -0.22112
[32m[0906 22-23-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35031, current rewards: -621.84272, mean: -0.25803
[32m[0906 22-23-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35016, current rewards: -721.84272, mean: -0.29343
[32m[0906 22-24-03 @Agent.py:117][0m Average action selection time: 0.3499
[32m[0906 22-24-03 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-24-03 @MBExp.py:227][0m Rewards obtained: [-801.8427185497168], Lows: [456], Highs: [99], Total time: 30143.674160999995
[32m[0906 22-25-18 @MBExp.py:144][0m ####################################################################
[32m[0906 22-25-18 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 22-25-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34477, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-25-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34440, current rewards: -41.87388, mean: -0.69790
[32m[0906 22-25-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34411, current rewards: -38.19188, mean: -0.34720
[32m[0906 22-26-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34655, current rewards: -23.78000, mean: -0.14862
[32m[0906 22-26-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34793, current rewards: -15.76850, mean: -0.07509
[32m[0906 22-26-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34799, current rewards: -7.82099, mean: -0.03008
[32m[0906 22-27-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34733, current rewards: 0.10103, mean: 0.00033
[32m[0906 22-27-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34688, current rewards: 8.02793, mean: 0.02230
[32m[0906 22-27-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34663, current rewards: 15.91594, mean: 0.03882
[32m[0906 22-27-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34640, current rewards: 23.81350, mean: 0.05177
[32m[0906 22-28-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34707, current rewards: 31.71838, mean: 0.06219
[32m[0906 22-28-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34774, current rewards: 41.18755, mean: 0.07355
[32m[0906 22-28-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34819, current rewards: 49.44396, mean: 0.08106
[32m[0906 22-29-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34855, current rewards: 22.33932, mean: 0.03385
[32m[0906 22-29-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34888, current rewards: 26.76802, mean: 0.03770
[32m[0906 22-29-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34918, current rewards: 35.72114, mean: 0.04700
[32m[0906 22-30-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34938, current rewards: 43.97752, mean: 0.05429
[32m[0906 22-30-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34958, current rewards: 51.75212, mean: 0.06018
[32m[0906 22-30-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34974, current rewards: 59.68152, mean: 0.06558
[32m[0906 22-30-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34988, current rewards: 67.78329, mean: 0.07061
[32m[0906 22-31-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34997, current rewards: 75.65263, mean: 0.07490
[32m[0906 22-31-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35006, current rewards: 83.57031, mean: 0.07884
[32m[0906 22-31-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35014, current rewards: 65.56679, mean: 0.05907
[32m[0906 22-32-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35024, current rewards: 51.57617, mean: 0.04446
[32m[0906 22-32-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35032, current rewards: 56.37807, mean: 0.04659
[32m[0906 22-32-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35038, current rewards: 61.17791, mean: 0.04855
[32m[0906 22-32-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35044, current rewards: 65.97574, mean: 0.05036
[32m[0906 22-33-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35049, current rewards: 70.07992, mean: 0.05153
[32m[0906 22-33-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35055, current rewards: 74.82961, mean: 0.05307
[32m[0906 22-33-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35056, current rewards: 79.53625, mean: 0.05448
[32m[0906 22-34-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35057, current rewards: 84.23930, mean: 0.05579
[32m[0906 22-34-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35063, current rewards: 88.94269, mean: 0.05701
[32m[0906 22-34-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35065, current rewards: 93.64459, mean: 0.05816
[32m[0906 22-35-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35068, current rewards: 98.34869, mean: 0.05925
[32m[0906 22-35-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35071, current rewards: 98.67380, mean: 0.05770
[32m[0906 22-35-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35074, current rewards: 60.57630, mean: 0.03442
[32m[0906 22-35-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35076, current rewards: 43.68262, mean: 0.02413
[32m[0906 22-36-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35076, current rewards: 49.68086, mean: 0.02671
[32m[0906 22-36-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35079, current rewards: 55.65674, mean: 0.02914
[32m[0906 22-36-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35080, current rewards: 61.63224, mean: 0.03145
[32m[0906 22-37-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35082, current rewards: 67.60996, mean: 0.03364
[32m[0906 22-37-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35084, current rewards: 73.58419, mean: 0.03572
[32m[0906 22-37-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35082, current rewards: 79.55773, mean: 0.03771
[32m[0906 22-37-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35085, current rewards: 62.52141, mean: 0.02895
[32m[0906 22-38-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35086, current rewards: 59.72521, mean: 0.02702
[32m[0906 22-38-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35088, current rewards: 65.99379, mean: 0.02920
[32m[0906 22-38-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35080, current rewards: 72.77965, mean: 0.03151
[32m[0906 22-39-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35066, current rewards: 79.56390, mean: 0.03371
[32m[0906 22-39-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35050, current rewards: 86.34064, mean: 0.03583
[32m[0906 22-39-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35035, current rewards: 93.11911, mean: 0.03785
[32m[0906 22-39-54 @Agent.py:117][0m Average action selection time: 0.3501
[32m[0906 22-39-54 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-39-54 @MBExp.py:227][0m Rewards obtained: [98.54098195610199], Lows: [70], Highs: [95], Total time: 31019.536775999994
[32m[0906 22-41-11 @MBExp.py:144][0m ####################################################################
[32m[0906 22-41-11 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 22-41-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34391, current rewards: 0.55808, mean: 0.05581
[32m[0906 22-41-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34425, current rewards: 7.06088, mean: 0.11768
[32m[0906 22-41-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34413, current rewards: -44.28273, mean: -0.40257
[32m[0906 22-42-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34708, current rewards: -73.45775, mean: -0.45911
[32m[0906 22-42-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34804, current rewards: -104.59608, mean: -0.49808
[32m[0906 22-42-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34801, current rewards: -133.36930, mean: -0.51296
[32m[0906 22-42-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34747, current rewards: -161.98714, mean: -0.52254
[32m[0906 22-43-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34702, current rewards: -193.28578, mean: -0.53690
[32m[0906 22-43-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34660, current rewards: -217.41294, mean: -0.53028
[32m[0906 22-43-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34635, current rewards: -213.01340, mean: -0.46307
[32m[0906 22-44-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34687, current rewards: -208.70865, mean: -0.40923
[32m[0906 22-44-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34740, current rewards: -204.61550, mean: -0.36538
[32m[0906 22-44-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34789, current rewards: -241.77061, mean: -0.39635
[32m[0906 22-45-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34829, current rewards: -281.53822, mean: -0.42657
[32m[0906 22-45-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34865, current rewards: -335.33754, mean: -0.47231
[32m[0906 22-45-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34892, current rewards: -389.29818, mean: -0.51223
[32m[0906 22-45-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34917, current rewards: -432.15008, mean: -0.53352
[32m[0906 22-46-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34936, current rewards: -433.94037, mean: -0.50458
[32m[0906 22-46-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34953, current rewards: -429.44655, mean: -0.47192
[32m[0906 22-46-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34969, current rewards: -425.30548, mean: -0.44303
[32m[0906 22-47-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34981, current rewards: -420.93308, mean: -0.41677
[32m[0906 22-47-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34988, current rewards: -416.55726, mean: -0.39298
[32m[0906 22-47-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35002, current rewards: -412.18285, mean: -0.37134
[32m[0906 22-47-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35010, current rewards: -401.14792, mean: -0.34582
[32m[0906 22-48-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35016, current rewards: -395.65000, mean: -0.32698
[32m[0906 22-48-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35020, current rewards: -390.98905, mean: -0.31031
[32m[0906 22-48-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35029, current rewards: -386.32911, mean: -0.29491
[32m[0906 22-49-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35033, current rewards: -382.02225, mean: -0.28090
[32m[0906 22-49-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35037, current rewards: -377.51651, mean: -0.26774
[32m[0906 22-49-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35044, current rewards: -372.99346, mean: -0.25547
[32m[0906 22-50-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35051, current rewards: -368.47039, mean: -0.24402
[32m[0906 22-50-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35061, current rewards: -391.12300, mean: -0.25072
[32m[0906 22-50-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35070, current rewards: -402.11569, mean: -0.24976
[32m[0906 22-50-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35075, current rewards: -435.43766, mean: -0.26231
[32m[0906 22-51-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35077, current rewards: -427.57379, mean: -0.25004
[32m[0906 22-51-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35079, current rewards: -461.75590, mean: -0.26236
[32m[0906 22-51-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35080, current rewards: -453.55544, mean: -0.25058
[32m[0906 22-52-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35083, current rewards: -444.55186, mean: -0.23901
[32m[0906 22-52-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35084, current rewards: -435.59656, mean: -0.22806
[32m[0906 22-52-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35089, current rewards: -426.64346, mean: -0.21768
[32m[0906 22-52-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35093, current rewards: -417.87800, mean: -0.20790
[32m[0906 22-53-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35096, current rewards: -447.24695, mean: -0.21711
[32m[0906 22-53-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35096, current rewards: -492.68827, mean: -0.23350
[32m[0906 22-53-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35096, current rewards: -529.48553, mean: -0.24513
[32m[0906 22-54-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35096, current rewards: -565.83937, mean: -0.25604
[32m[0906 22-54-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35099, current rewards: -611.86238, mean: -0.27074
[32m[0906 22-54-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35093, current rewards: -663.09897, mean: -0.28706
[32m[0906 22-54-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35078, current rewards: -684.65268, mean: -0.29011
[32m[0906 22-55-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35064, current rewards: -676.18787, mean: -0.28058
[32m[0906 22-55-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35050, current rewards: -667.17955, mean: -0.27121
[32m[0906 22-55-47 @Agent.py:117][0m Average action selection time: 0.3502
[32m[0906 22-55-47 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-55-47 @MBExp.py:227][0m Rewards obtained: [-660.0431913052729], Lows: [472], Highs: [23], Total time: 31895.761561999992
[32m[0906 22-57-06 @MBExp.py:144][0m ####################################################################
[32m[0906 22-57-06 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 22-57-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34493, current rewards: 1.19153, mean: 0.11915
[32m[0906 22-57-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34474, current rewards: 6.52210, mean: 0.10870
[32m[0906 22-57-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34491, current rewards: 15.85448, mean: 0.14413
[32m[0906 22-58-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34795, current rewards: 22.20205, mean: 0.13876
[32m[0906 22-58-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34885, current rewards: 27.96876, mean: 0.13318
[32m[0906 22-58-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34848, current rewards: 24.33900, mean: 0.09361
[32m[0906 22-58-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34777, current rewards: 17.92076, mean: 0.05781
[32m[0906 22-59-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34717, current rewards: 23.56346, mean: 0.06545
[32m[0906 22-59-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34678, current rewards: 29.20268, mean: 0.07123
[32m[0906 22-59-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34649, current rewards: 34.93045, mean: 0.07594
[32m[0906 23-00-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34705, current rewards: 41.98289, mean: 0.08232
[32m[0906 23-00-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34764, current rewards: 47.44239, mean: 0.08472
[32m[0906 23-00-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34813, current rewards: 52.88742, mean: 0.08670
[32m[0906 23-00-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34852, current rewards: 58.33322, mean: 0.08838
[32m[0906 23-01-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34880, current rewards: 63.78307, mean: 0.08984
[32m[0906 23-01-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34899, current rewards: 69.23346, mean: 0.09110
[32m[0906 23-01-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34920, current rewards: 48.90298, mean: 0.06037
[32m[0906 23-02-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34938, current rewards: 35.27716, mean: 0.04102
[32m[0906 23-02-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34954, current rewards: -28.28342, mean: -0.03108
[32m[0906 23-02-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34968, current rewards: -128.28342, mean: -0.13363
[32m[0906 23-03-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34979, current rewards: -228.28342, mean: -0.22602
[32m[0906 23-03-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34986, current rewards: -328.28342, mean: -0.30970
[32m[0906 23-03-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34997, current rewards: -428.28342, mean: -0.38584
[32m[0906 23-03-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35005, current rewards: -528.28342, mean: -0.45542
[32m[0906 23-04-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35014, current rewards: -628.28342, mean: -0.51924
[32m[0906 23-04-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35024, current rewards: -728.28342, mean: -0.57800
[32m[0906 23-04-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35033, current rewards: -828.28342, mean: -0.63228
[32m[0906 23-05-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35041, current rewards: -928.28342, mean: -0.68256
[32m[0906 23-05-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35049, current rewards: -1028.28342, mean: -0.72928
[32m[0906 23-05-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35054, current rewards: -1128.28342, mean: -0.77280
[32m[0906 23-05-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35058, current rewards: -1228.28342, mean: -0.81343
[32m[0906 23-06-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35063, current rewards: -1328.28342, mean: -0.85146
[32m[0906 23-06-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35065, current rewards: -1428.28342, mean: -0.88713
[32m[0906 23-06-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35069, current rewards: -1528.28342, mean: -0.92065
[32m[0906 23-07-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35075, current rewards: -1628.28342, mean: -0.95221
[32m[0906 23-07-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35077, current rewards: -1728.28342, mean: -0.98198
[32m[0906 23-07-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35080, current rewards: -1828.28342, mean: -1.01010
[32m[0906 23-07-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35086, current rewards: -1928.28342, mean: -1.03671
[32m[0906 23-08-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35090, current rewards: -2028.28342, mean: -1.06193
[32m[0906 23-08-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35096, current rewards: -2128.28342, mean: -1.08586
[32m[0906 23-08-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35101, current rewards: -2228.28342, mean: -1.10860
[32m[0906 23-09-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35102, current rewards: -2328.28342, mean: -1.13023
[32m[0906 23-09-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35106, current rewards: -2428.28342, mean: -1.15085
[32m[0906 23-09-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35108, current rewards: -2528.28342, mean: -1.17050
[32m[0906 23-10-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35109, current rewards: -2628.28342, mean: -1.18927
[32m[0906 23-10-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35108, current rewards: -2728.28342, mean: -1.20721
[32m[0906 23-10-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35100, current rewards: -2828.28342, mean: -1.22437
[32m[0906 23-10-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35086, current rewards: -2928.28342, mean: -1.24080
[32m[0906 23-11-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35070, current rewards: -3028.28342, mean: -1.25655
[32m[0906 23-11-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35053, current rewards: -3128.28342, mean: -1.27166
[32m[0906 23-11-42 @Agent.py:117][0m Average action selection time: 0.3502
[32m[0906 23-11-42 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-11-43 @MBExp.py:227][0m Rewards obtained: [-3208.2834244078254], Lows: [1638], Highs: [40], Total time: 32772.050513999995
[32m[0906 23-13-04 @MBExp.py:144][0m ####################################################################
[32m[0906 23-13-04 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 23-13-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34428, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-13-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34385, current rewards: -14.50449, mean: -0.24174
[32m[0906 23-13-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34460, current rewards: -8.07809, mean: -0.07344
[32m[0906 23-13-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34700, current rewards: -1.63160, mean: -0.01020
[32m[0906 23-14-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34841, current rewards: 4.82460, mean: 0.02297
[32m[0906 23-14-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34815, current rewards: 11.26521, mean: 0.04333
[32m[0906 23-14-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34754, current rewards: 17.71904, mean: 0.05716
[32m[0906 23-15-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34710, current rewards: 24.15339, mean: 0.06709
[32m[0906 23-15-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34678, current rewards: 32.59232, mean: 0.07949
[32m[0906 23-15-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34655, current rewards: 42.98565, mean: 0.09345
[32m[0906 23-16-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34707, current rewards: 50.67136, mean: 0.09936
[32m[0906 23-16-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34757, current rewards: 58.34691, mean: 0.10419
[32m[0906 23-16-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34797, current rewards: 19.50501, mean: 0.03198
[32m[0906 23-16-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34831, current rewards: 25.27555, mean: 0.03830
[32m[0906 23-17-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34864, current rewards: 31.04436, mean: 0.04372
[32m[0906 23-17-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34889, current rewards: 36.82129, mean: 0.04845
[32m[0906 23-17-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34914, current rewards: 17.81960, mean: 0.02200
[32m[0906 23-18-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34932, current rewards: 22.35989, mean: 0.02600
[32m[0906 23-18-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34946, current rewards: 27.32421, mean: 0.03003
[32m[0906 23-18-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34962, current rewards: 32.35636, mean: 0.03370
[32m[0906 23-18-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34978, current rewards: 37.38852, mean: 0.03702
[32m[0906 23-19-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34983, current rewards: 42.41232, mean: 0.04001
[32m[0906 23-19-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34993, current rewards: 47.43939, mean: 0.04274
[32m[0906 23-19-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35000, current rewards: 10.26734, mean: 0.00885
[32m[0906 23-20-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35006, current rewards: 15.15651, mean: 0.01253
[32m[0906 23-20-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35015, current rewards: 20.82805, mean: 0.01653
[32m[0906 23-20-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35026, current rewards: 26.08401, mean: 0.01991
[32m[0906 23-21-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35039, current rewards: 31.22571, mean: 0.02296
[32m[0906 23-21-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35041, current rewards: 36.36821, mean: 0.02579
[32m[0906 23-21-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35047, current rewards: 39.42046, mean: 0.02700
[32m[0906 23-21-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35056, current rewards: 4.36567, mean: 0.00289
[32m[0906 23-22-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35060, current rewards: 10.90922, mean: 0.00699
[32m[0906 23-22-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35061, current rewards: 17.50325, mean: 0.01087
[32m[0906 23-22-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35064, current rewards: 25.14513, mean: 0.01515
[32m[0906 23-23-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35065, current rewards: 31.80070, mean: 0.01860
[32m[0906 23-23-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35068, current rewards: 38.44799, mean: 0.02185
[32m[0906 23-23-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35069, current rewards: 45.09230, mean: 0.02491
[32m[0906 23-23-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35069, current rewards: 51.73352, mean: 0.02781
[32m[0906 23-24-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35070, current rewards: 58.37935, mean: 0.03057
[32m[0906 23-24-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35072, current rewards: 65.02891, mean: 0.03318
[32m[0906 23-24-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35072, current rewards: 71.67268, mean: 0.03566
[32m[0906 23-25-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35074, current rewards: 76.96006, mean: 0.03736
[32m[0906 23-25-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35075, current rewards: 82.59339, mean: 0.03914
[32m[0906 23-25-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35077, current rewards: 46.34544, mean: 0.02146
[32m[0906 23-25-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35079, current rewards: 51.51459, mean: 0.02331
[32m[0906 23-26-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35079, current rewards: 57.04166, mean: 0.02524
[32m[0906 23-26-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35069, current rewards: 62.56505, mean: 0.02708
[32m[0906 23-26-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35054, current rewards: 68.09315, mean: 0.02885
[32m[0906 23-27-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35039, current rewards: 73.62044, mean: 0.03055
[32m[0906 23-27-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35022, current rewards: 79.57585, mean: 0.03235
[32m[0906 23-27-39 @Agent.py:117][0m Average action selection time: 0.3500
[32m[0906 23-27-39 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-27-39 @MBExp.py:227][0m Rewards obtained: [73.37403533431777], Lows: [89], Highs: [40], Total time: 33647.602657999996
[32m[0906 23-29-02 @MBExp.py:144][0m ####################################################################
[32m[0906 23-29-02 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 23-29-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34384, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-29-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34373, current rewards: -43.30011, mean: -0.72167
[32m[0906 23-29-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34504, current rewards: -37.14265, mean: -0.33766
[32m[0906 23-29-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34739, current rewards: -30.98228, mean: -0.19364
[32m[0906 23-30-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34873, current rewards: -24.81619, mean: -0.11817
[32m[0906 23-30-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34825, current rewards: -18.65639, mean: -0.07176
[32m[0906 23-30-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34754, current rewards: -12.48527, mean: -0.04028
[32m[0906 23-31-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34713, current rewards: -6.31157, mean: -0.01753
[32m[0906 23-31-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34676, current rewards: -0.14387, mean: -0.00035
[32m[0906 23-31-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34647, current rewards: -23.70459, mean: -0.05153
[32m[0906 23-31-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34694, current rewards: -29.06199, mean: -0.05698
[32m[0906 23-32-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34757, current rewards: -20.98770, mean: -0.03748
[32m[0906 23-32-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34796, current rewards: -12.91342, mean: -0.02117
[32m[0906 23-32-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34839, current rewards: -4.83913, mean: -0.00733
[32m[0906 23-33-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34874, current rewards: 3.23516, mean: 0.00456
[32m[0906 23-33-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34897, current rewards: 11.30944, mean: 0.01488
[32m[0906 23-33-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34916, current rewards: 19.04676, mean: 0.02351
[32m[0906 23-34-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34933, current rewards: 21.83023, mean: 0.02538
[32m[0906 23-34-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34952, current rewards: 25.41087, mean: 0.02792
[32m[0906 23-34-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34964, current rewards: 31.56236, mean: 0.03288
[32m[0906 23-34-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34976, current rewards: 14.00096, mean: 0.01386
[32m[0906 23-35-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34985, current rewards: 20.25132, mean: 0.01911
[32m[0906 23-35-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34996, current rewards: 26.19393, mean: 0.02360
[32m[0906 23-35-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35008, current rewards: 32.14451, mean: 0.02771
[32m[0906 23-36-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35013, current rewards: 38.10783, mean: 0.03149
[32m[0906 23-36-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35021, current rewards: 10.26887, mean: 0.00815
[32m[0906 23-36-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35024, current rewards: 16.02470, mean: 0.01223
[32m[0906 23-36-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35031, current rewards: 22.29374, mean: 0.01639
[32m[0906 23-37-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35039, current rewards: 28.55902, mean: 0.02025
[32m[0906 23-37-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35041, current rewards: -7.72499, mean: -0.00529
[32m[0906 23-37-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35047, current rewards: -1.90731, mean: -0.00126
[32m[0906 23-38-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35056, current rewards: 6.21947, mean: 0.00399
[32m[0906 23-38-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35060, current rewards: 14.35804, mean: 0.00892
[32m[0906 23-38-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35064, current rewards: 3.03318, mean: 0.00183
[32m[0906 23-39-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35070, current rewards: -15.13580, mean: -0.00885
[32m[0906 23-39-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35075, current rewards: -10.84425, mean: -0.00616
[32m[0906 23-39-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35081, current rewards: -6.55192, mean: -0.00362
[32m[0906 23-39-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35085, current rewards: -2.26296, mean: -0.00122
[32m[0906 23-40-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35089, current rewards: 2.02743, mean: 0.00106
[32m[0906 23-40-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35090, current rewards: 6.31979, mean: 0.00322
[32m[0906 23-40-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35094, current rewards: 10.61081, mean: 0.00528
[32m[0906 23-41-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35097, current rewards: 14.74427, mean: 0.00716
[32m[0906 23-41-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35096, current rewards: 19.03764, mean: 0.00902
[32m[0906 23-41-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35097, current rewards: 23.33072, mean: 0.01080
[32m[0906 23-41-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35099, current rewards: 8.08021, mean: 0.00366
[32m[0906 23-42-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35099, current rewards: 13.78899, mean: 0.00610
[32m[0906 23-42-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35088, current rewards: 19.99849, mean: 0.00866
[32m[0906 23-42-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35074, current rewards: 26.19932, mean: 0.01110
[32m[0906 23-43-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35059, current rewards: 32.39754, mean: 0.01344
[32m[0906 23-43-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35041, current rewards: 37.58819, mean: 0.01528
[32m[0906 23-43-38 @Agent.py:117][0m Average action selection time: 0.3501
[32m[0906 23-43-38 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-43-38 @MBExp.py:227][0m Rewards obtained: [42.40747187583488], Lows: [92], Highs: [61], Total time: 34523.572916
[32m[0906 23-45-03 @MBExp.py:144][0m ####################################################################
[32m[0906 23-45-03 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 23-45-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34131, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-45-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34367, current rewards: -24.85723, mean: -0.41429
[32m[0906 23-45-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34506, current rewards: -20.73329, mean: -0.18848
[32m[0906 23-45-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34774, current rewards: -16.88499, mean: -0.10553
[32m[0906 23-46-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34896, current rewards: -12.96856, mean: -0.06176
[32m[0906 23-46-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34830, current rewards: -9.02980, mean: -0.03473
[32m[0906 23-46-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34756, current rewards: -5.13727, mean: -0.01657
[32m[0906 23-47-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34709, current rewards: -1.23991, mean: -0.00344
[32m[0906 23-47-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34670, current rewards: 2.31231, mean: 0.00564
[32m[0906 23-47-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34635, current rewards: 6.48254, mean: 0.01409
[32m[0906 23-48-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34673, current rewards: 10.64040, mean: 0.02086
[32m[0906 23-48-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34729, current rewards: 14.40954, mean: 0.02573
[32m[0906 23-48-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34778, current rewards: -0.09497, mean: -0.00016
[32m[0906 23-48-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34820, current rewards: -19.40192, mean: -0.02940
[32m[0906 23-49-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34849, current rewards: -14.70476, mean: -0.02071
[32m[0906 23-49-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34875, current rewards: -10.02803, mean: -0.01319
[32m[0906 23-49-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34901, current rewards: -5.70759, mean: -0.00705
[32m[0906 23-50-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34928, current rewards: -1.03763, mean: -0.00121
[32m[0906 23-50-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34950, current rewards: 3.52862, mean: 0.00388
[32m[0906 23-50-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34966, current rewards: 8.09426, mean: 0.00843
[32m[0906 23-50-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34980, current rewards: 12.66101, mean: 0.01254
[32m[0906 23-51-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34995, current rewards: 17.22698, mean: 0.01625
[32m[0906 23-51-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35008, current rewards: 21.79402, mean: 0.01963
[32m[0906 23-51-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35018, current rewards: 26.35715, mean: 0.02272
[32m[0906 23-52-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35032, current rewards: 31.44046, mean: 0.02598
[32m[0906 23-52-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35036, current rewards: 37.23367, mean: 0.02955
[32m[0906 23-52-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35045, current rewards: 24.46192, mean: 0.01867
[32m[0906 23-53-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35052, current rewards: 23.76232, mean: 0.01747
[32m[0906 23-53-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35057, current rewards: 29.55404, mean: 0.02096
[32m[0906 23-53-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35061, current rewards: 35.34493, mean: 0.02421
[32m[0906 23-53-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35065, current rewards: 41.13932, mean: 0.02724
[32m[0906 23-54-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35066, current rewards: 46.93004, mean: 0.03008
[32m[0906 23-54-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35069, current rewards: 52.71092, mean: 0.03274
[32m[0906 23-54-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35072, current rewards: 57.10112, mean: 0.03440
[32m[0906 23-55-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35075, current rewards: 43.42034, mean: 0.02539
[32m[0906 23-55-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35079, current rewards: 25.35360, mean: 0.01441
[32m[0906 23-55-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35082, current rewards: 31.21826, mean: 0.01725
[32m[0906 23-55-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35083, current rewards: 37.10142, mean: 0.01995
[32m[0906 23-56-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35087, current rewards: 42.98277, mean: 0.02250
[32m[0906 23-56-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35090, current rewards: 48.86226, mean: 0.02493
[32m[0906 23-56-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35093, current rewards: 54.74357, mean: 0.02724
[32m[0906 23-57-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35095, current rewards: 61.75520, mean: 0.02998
[32m[0906 23-57-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35095, current rewards: 67.80335, mean: 0.03213
[32m[0906 23-57-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35096, current rewards: 73.85244, mean: 0.03419
[32m[0906 23-57-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35096, current rewards: 79.89666, mean: 0.03615
[32m[0906 23-58-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35096, current rewards: 85.94570, mean: 0.03803
[32m[0906 23-58-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35085, current rewards: 91.99640, mean: 0.03983
[32m[0906 23-58-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35068, current rewards: 98.04688, mean: 0.04155
[32m[0906 23-59-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35052, current rewards: 104.09578, mean: 0.04319
[32m[0906 23-59-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35033, current rewards: 67.25847, mean: 0.02734
[32m[0906 23-59-39 @Agent.py:117][0m Average action selection time: 0.3501
[32m[0906 23-59-39 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-59-39 @MBExp.py:227][0m Rewards obtained: [71.48444193783706], Lows: [61], Highs: [49], Total time: 35399.364104
[32m[0907 00-01-06 @MBExp.py:144][0m ####################################################################
[32m[0907 00-01-06 @MBExp.py:145][0m Starting training iteration 43.
[32m[0907 00-01-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34395, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-01-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34829, current rewards: -17.91125, mean: -0.29852
[32m[0907 00-01-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34767, current rewards: -11.91495, mean: -0.10832
[32m[0907 00-02-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34932, current rewards: -7.02241, mean: -0.04389
[32m[0907 00-02-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35024, current rewards: -2.37044, mean: -0.01129
[32m[0907 00-02-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34934, current rewards: -5.44053, mean: -0.02093
[32m[0907 00-02-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34841, current rewards: -5.03852, mean: -0.01625
[32m[0907 00-03-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34775, current rewards: 0.87443, mean: 0.00243
[32m[0907 00-03-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34736, current rewards: 4.97354, mean: 0.01213
[32m[0907 00-03-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34707, current rewards: 10.68479, mean: 0.02323
[32m[0907 00-04-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34735, current rewards: 16.38347, mean: 0.03212
[32m[0907 00-04-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34787, current rewards: 22.07811, mean: 0.03943
[32m[0907 00-04-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34820, current rewards: 27.77942, mean: 0.04554
[32m[0907 00-04-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34850, current rewards: 33.47645, mean: 0.05072
[32m[0907 00-05-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34876, current rewards: 39.17205, mean: 0.05517
[32m[0907 00-05-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34900, current rewards: 44.86969, mean: 0.05904
[32m[0907 00-05-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34928, current rewards: 38.97582, mean: 0.04812
[32m[0907 00-06-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34940, current rewards: 45.80395, mean: 0.05326
[32m[0907 00-06-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34957, current rewards: 51.72990, mean: 0.05685
[32m[0907 00-06-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34971, current rewards: 34.22701, mean: 0.03565
[32m[0907 00-06-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34986, current rewards: 40.48323, mean: 0.04008
[32m[0907 00-07-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34994, current rewards: 44.98119, mean: 0.04244
[32m[0907 00-07-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35005, current rewards: 49.48175, mean: 0.04458
[32m[0907 00-07-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35011, current rewards: 53.97430, mean: 0.04653
[32m[0907 00-08-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35024, current rewards: 59.14927, mean: 0.04888
[32m[0907 00-08-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35028, current rewards: 64.54978, mean: 0.05123
[32m[0907 00-08-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35036, current rewards: 69.08827, mean: 0.05274
[32m[0907 00-09-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35041, current rewards: 79.22134, mean: 0.05825
[32m[0907 00-09-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35046, current rewards: 85.26217, mean: 0.06047
[32m[0907 00-09-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35050, current rewards: 91.29823, mean: 0.06253
[32m[0907 00-09-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35056, current rewards: 97.31892, mean: 0.06445
[32m[0907 00-10-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35061, current rewards: 73.66115, mean: 0.04722
[32m[0907 00-10-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35067, current rewards: 71.11926, mean: 0.04417
[32m[0907 00-10-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35071, current rewards: 73.63621, mean: 0.04436
[32m[0907 00-11-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35073, current rewards: 79.07275, mean: 0.04624
[32m[0907 00-11-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35080, current rewards: 84.54858, mean: 0.04804
[32m[0907 00-11-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35084, current rewards: 90.01856, mean: 0.04973
[32m[0907 00-11-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35086, current rewards: 95.48592, mean: 0.05134
[32m[0907 00-12-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35089, current rewards: 100.95767, mean: 0.05286
[32m[0907 00-12-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35092, current rewards: 106.42763, mean: 0.05430
[32m[0907 00-12-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35092, current rewards: 67.49746, mean: 0.03358
[32m[0907 00-13-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35094, current rewards: 77.54229, mean: 0.03764
[32m[0907 00-13-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35098, current rewards: 84.95891, mean: 0.04026
[32m[0907 00-13-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35099, current rewards: 90.86281, mean: 0.04207
[32m[0907 00-14-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35098, current rewards: 96.66623, mean: 0.04374
[32m[0907 00-14-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35099, current rewards: 78.26086, mean: 0.03463
[32m[0907 00-14-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35089, current rewards: 84.18488, mean: 0.03644
[32m[0907 00-14-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35073, current rewards: 90.16037, mean: 0.03820
[32m[0907 00-15-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35059, current rewards: 96.12557, mean: 0.03989
[32m[0907 00-15-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35038, current rewards: 101.20127, mean: 0.04114
[32m[0907 00-15-42 @Agent.py:117][0m Average action selection time: 0.3501
[32m[0907 00-15-42 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-15-42 @MBExp.py:227][0m Rewards obtained: [105.9570936153457], Lows: [63], Highs: [62], Total time: 36275.318984
[32m[0907 00-17-11 @MBExp.py:144][0m ####################################################################
[32m[0907 00-17-11 @MBExp.py:145][0m Starting training iteration 44.
[32m[0907 00-17-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34581, current rewards: 1.27441, mean: 0.12744
[32m[0907 00-17-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34520, current rewards: -9.47210, mean: -0.15787
[32m[0907 00-17-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34649, current rewards: -6.53633, mean: -0.05942
[32m[0907 00-18-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34830, current rewards: -1.60932, mean: -0.01006
[32m[0907 00-18-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34915, current rewards: 4.66310, mean: 0.02221
[32m[0907 00-18-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34824, current rewards: 10.58097, mean: 0.04070
[32m[0907 00-18-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34761, current rewards: 16.49885, mean: 0.05322
[32m[0907 00-19-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34716, current rewards: 22.28980, mean: 0.06192
[32m[0907 00-19-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34674, current rewards: -23.40788, mean: -0.05709
[32m[0907 00-19-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34652, current rewards: -73.40788, mean: -0.15958
[32m[0907 00-20-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34699, current rewards: -123.40788, mean: -0.24198
[32m[0907 00-20-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34761, current rewards: -173.40788, mean: -0.30966
[32m[0907 00-20-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34813, current rewards: -223.40788, mean: -0.36624
[32m[0907 00-21-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34851, current rewards: -273.40788, mean: -0.41425
[32m[0907 00-21-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34882, current rewards: -323.40788, mean: -0.45550
[32m[0907 00-21-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34913, current rewards: -373.40788, mean: -0.49133
[32m[0907 00-21-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34940, current rewards: -423.40788, mean: -0.52273
[32m[0907 00-22-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34957, current rewards: -473.40788, mean: -0.55047
[32m[0907 00-22-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34974, current rewards: -523.40788, mean: -0.57517
[32m[0907 00-22-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34993, current rewards: -573.40788, mean: -0.59730
[32m[0907 00-23-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35008, current rewards: -623.40788, mean: -0.61724
[32m[0907 00-23-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35020, current rewards: -673.40788, mean: -0.63529
[32m[0907 00-23-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35027, current rewards: -723.40788, mean: -0.65172
[32m[0907 00-23-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35036, current rewards: -773.40788, mean: -0.66673
[32m[0907 00-24-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35047, current rewards: -823.40788, mean: -0.68050
[32m[0907 00-24-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35052, current rewards: -873.40788, mean: -0.69318
[32m[0907 00-24-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35059, current rewards: -923.40788, mean: -0.70489
[32m[0907 00-25-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35064, current rewards: -973.40788, mean: -0.71574
[32m[0907 00-25-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35071, current rewards: -1023.40788, mean: -0.72582
[32m[0907 00-25-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35076, current rewards: -1073.40788, mean: -0.73521
[32m[0907 00-26-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35081, current rewards: -1123.40788, mean: -0.74398
[32m[0907 00-26-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35083, current rewards: -1173.40788, mean: -0.75218
[32m[0907 00-26-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35084, current rewards: -1223.40788, mean: -0.75988
[32m[0907 00-26-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35086, current rewards: -1273.40788, mean: -0.76711
[32m[0907 00-27-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35089, current rewards: -1323.40788, mean: -0.77392
[32m[0907 00-27-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35091, current rewards: -1373.40788, mean: -0.78035
[32m[0907 00-27-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35093, current rewards: -1423.40788, mean: -0.78641
[32m[0907 00-28-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35093, current rewards: -1473.40788, mean: -0.79215
[32m[0907 00-28-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35093, current rewards: -1523.40788, mean: -0.79760
[32m[0907 00-28-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35095, current rewards: -1573.40788, mean: -0.80276
[32m[0907 00-28-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35097, current rewards: -1623.40788, mean: -0.80767
[32m[0907 00-29-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35097, current rewards: -1673.40788, mean: -0.81233
[32m[0907 00-29-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35100, current rewards: -1723.40788, mean: -0.81678
[32m[0907 00-29-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35102, current rewards: -1773.40788, mean: -0.82102
[32m[0907 00-30-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35104, current rewards: -1823.40788, mean: -0.82507
[32m[0907 00-30-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35106, current rewards: -1873.40788, mean: -0.82894
[32m[0907 00-30-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35093, current rewards: -1923.40788, mean: -0.83264
[32m[0907 00-30-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35076, current rewards: -1973.40788, mean: -0.83619
[32m[0907 00-31-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35060, current rewards: -2023.40788, mean: -0.83959
[32m[0907 00-31-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35045, current rewards: -2073.40788, mean: -0.84285
[32m[0907 00-31-47 @Agent.py:117][0m Average action selection time: 0.3502
[32m[0907 00-31-47 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-31-47 @MBExp.py:227][0m Rewards obtained: [-2113.4078828158235], Lows: [17], Highs: [2136], Total time: 37151.506838
[32m[0907 00-33-18 @MBExp.py:144][0m ####################################################################
[32m[0907 00-33-18 @MBExp.py:145][0m Starting training iteration 45.
[32m[0907 00-33-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34475, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-33-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34427, current rewards: -18.32544, mean: -0.30542
[32m[0907 00-33-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34608, current rewards: -10.34450, mean: -0.09404
[32m[0907 00-34-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34826, current rewards: -1.48545, mean: -0.00928
[32m[0907 00-34-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34882, current rewards: 7.35432, mean: 0.03502
[32m[0907 00-34-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34791, current rewards: 16.22215, mean: 0.06239
[32m[0907 00-35-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34733, current rewards: 25.09644, mean: 0.08096
[32m[0907 00-35-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34690, current rewards: 32.99989, mean: 0.09167
[32m[0907 00-35-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34652, current rewards: -2.30949, mean: -0.00563
[32m[0907 00-35-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34626, current rewards: 9.09922, mean: 0.01978
[32m[0907 00-36-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34671, current rewards: 21.16058, mean: 0.04149
[32m[0907 00-36-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34721, current rewards: 33.54318, mean: 0.05990
[32m[0907 00-36-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34769, current rewards: 44.40417, mean: 0.07279
[32m[0907 00-37-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34803, current rewards: 12.97731, mean: 0.01966
[32m[0907 00-37-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34841, current rewards: 9.95264, mean: 0.01402
[32m[0907 00-37-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34868, current rewards: 14.59138, mean: 0.01920
[32m[0907 00-38-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34887, current rewards: 19.20363, mean: 0.02371
[32m[0907 00-38-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34907, current rewards: 23.85612, mean: 0.02774
[32m[0907 00-38-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34920, current rewards: 28.39300, mean: 0.03120
[32m[0907 00-38-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34943, current rewards: 33.04240, mean: 0.03442
[32m[0907 00-39-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34954, current rewards: 37.63765, mean: 0.03726
[32m[0907 00-39-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34963, current rewards: 42.24550, mean: 0.03985
[32m[0907 00-39-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34974, current rewards: 46.91929, mean: 0.04227
[32m[0907 00-40-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34982, current rewards: 51.38999, mean: 0.04430
[32m[0907 00-40-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34984, current rewards: 55.88328, mean: 0.04618
[32m[0907 00-40-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35008, current rewards: 39.96142, mean: 0.03172
[32m[0907 00-40-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35016, current rewards: 43.95042, mean: 0.03355
[32m[0907 00-41-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35021, current rewards: 53.51671, mean: 0.03935
[32m[0907 00-41-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35024, current rewards: 63.28554, mean: 0.04488
[32m[0907 00-41-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35031, current rewards: 72.88643, mean: 0.04992
[32m[0907 00-42-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35035, current rewards: 77.78031, mean: 0.05151
[32m[0907 00-42-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35042, current rewards: 63.36448, mean: 0.04062
[32m[0907 00-42-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35043, current rewards: 32.73691, mean: 0.02033
[32m[0907 00-43-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35046, current rewards: 40.71461, mean: 0.02453
[32m[0907 00-43-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35048, current rewards: 51.40908, mean: 0.03006
[32m[0907 00-43-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35052, current rewards: 64.06439, mean: 0.03640
[32m[0907 00-43-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35073, current rewards: 13.03584, mean: 0.00720
[32m[0907 00-44-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35075, current rewards: 22.80364, mean: 0.01226
[32m[0907 00-44-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35080, current rewards: 35.82050, mean: 0.01875
[32m[0907 00-44-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35083, current rewards: 48.80701, mean: 0.02490
[32m[0907 00-45-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35084, current rewards: 59.55960, mean: 0.02963
[32m[0907 00-45-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35086, current rewards: 72.71288, mean: 0.03530
[32m[0907 00-45-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35089, current rewards: 85.75828, mean: 0.04064
[32m[0907 00-45-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35091, current rewards: 98.84291, mean: 0.04576
[32m[0907 00-46-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35092, current rewards: 111.92827, mean: 0.05065
[32m[0907 00-46-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35091, current rewards: 79.31669, mean: 0.03510
[32m[0907 00-46-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35080, current rewards: 91.04903, mean: 0.03942
[32m[0907 00-47-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35064, current rewards: 102.72811, mean: 0.04353
[32m[0907 00-47-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35049, current rewards: 109.31071, mean: 0.04536
[32m[0907 00-47-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35035, current rewards: 122.61235, mean: 0.04984
[32m[0907 00-47-54 @Agent.py:117][0m Average action selection time: 0.3501
[32m[0907 00-47-54 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-47-54 @MBExp.py:227][0m Rewards obtained: [134.61772064938634], Lows: [118], Highs: [61], Total time: 38027.456045
[32m[0907 00-49-26 @MBExp.py:144][0m ####################################################################
[32m[0907 00-49-26 @MBExp.py:145][0m Starting training iteration 46.
[32m[0907 00-49-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34439, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-49-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34498, current rewards: -39.67742, mean: -0.66129
[32m[0907 00-50-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34658, current rewards: -70.28486, mean: -0.63895
[32m[0907 00-50-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34842, current rewards: -98.64329, mean: -0.61652
[32m[0907 00-50-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34881, current rewards: -138.89447, mean: -0.66140
[32m[0907 00-50-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34778, current rewards: -145.44924, mean: -0.55942
[32m[0907 00-51-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34727, current rewards: -148.20548, mean: -0.47808
[32m[0907 00-51-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34682, current rewards: -142.03268, mean: -0.39454
[32m[0907 00-51-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34650, current rewards: -137.31996, mean: -0.33493
[32m[0907 00-52-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34638, current rewards: -132.33514, mean: -0.28769
[32m[0907 00-52-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34689, current rewards: -127.36766, mean: -0.24974
[32m[0907 00-52-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34740, current rewards: -122.40149, mean: -0.21857
[32m[0907 00-52-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34792, current rewards: -130.03086, mean: -0.21317
[32m[0907 00-53-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34831, current rewards: -171.90605, mean: -0.26046
[32m[0907 00-53-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34648, current rewards: -165.14201, mean: -0.23259
[32m[0907 00-53-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34463, current rewards: -175.54601, mean: -0.23098
[32m[0907 00-54-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34284, current rewards: -225.54601, mean: -0.27845
[32m[0907 00-54-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34125, current rewards: -275.54601, mean: -0.32040
[32m[0907 00-54-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33980, current rewards: -325.54601, mean: -0.35774
[32m[0907 00-54-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33852, current rewards: -375.54601, mean: -0.39119
[32m[0907 00-55-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33736, current rewards: -425.54601, mean: -0.42133
[32m[0907 00-55-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33627, current rewards: -475.54601, mean: -0.44863
[32m[0907 00-55-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33527, current rewards: -525.54601, mean: -0.47346
[32m[0907 00-55-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33439, current rewards: -575.54601, mean: -0.49616
[32m[0907 00-56-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33356, current rewards: -570.63341, mean: -0.47160
[32m[0907 00-56-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33286, current rewards: -570.87421, mean: -0.45307
[32m[0907 00-56-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33216, current rewards: -620.87421, mean: -0.47395
[32m[0907 00-56-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33147, current rewards: -670.87421, mean: -0.49329
[32m[0907 00-57-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33085, current rewards: -720.87421, mean: -0.51126
[32m[0907 00-57-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33028, current rewards: -770.87421, mean: -0.52800
[32m[0907 00-57-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32979, current rewards: -820.87421, mean: -0.54363
[32m[0907 00-58-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32930, current rewards: -870.87421, mean: -0.55825
[32m[0907 00-58-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32885, current rewards: -920.87421, mean: -0.57197
[32m[0907 00-58-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32842, current rewards: -970.87421, mean: -0.58486
[32m[0907 00-58-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32800, current rewards: -1020.87421, mean: -0.59700
[32m[0907 00-59-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32763, current rewards: -1070.87421, mean: -0.60845
[32m[0907 00-59-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32727, current rewards: -1120.87421, mean: -0.61927
[32m[0907 00-59-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32693, current rewards: -1170.87421, mean: -0.62950
[32m[0907 00-59-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32659, current rewards: -1220.87421, mean: -0.63920
[32m[0907 01-00-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32628, current rewards: -1270.87421, mean: -0.64841
[32m[0907 01-00-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32599, current rewards: -1320.87421, mean: -0.65715
[32m[0907 01-00-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32569, current rewards: -1370.87421, mean: -0.66547
[32m[0907 01-00-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32542, current rewards: -1420.87421, mean: -0.67340
[32m[0907 01-01-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32516, current rewards: -1470.87421, mean: -0.68096
[32m[0907 01-01-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32489, current rewards: -1520.87421, mean: -0.68818
[32m[0907 01-01-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32463, current rewards: -1570.87421, mean: -0.69508
[32m[0907 01-01-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32427, current rewards: -1620.87421, mean: -0.70168
[32m[0907 01-02-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32392, current rewards: -1670.87421, mean: -0.70800
[32m[0907 01-02-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32360, current rewards: -1720.87421, mean: -0.71406
[32m[0907 01-02-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32327, current rewards: -1770.87421, mean: -0.71987
[32m[0907 01-02-54 @Agent.py:117][0m Average action selection time: 0.3229
[32m[0907 01-02-54 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-02-54 @MBExp.py:227][0m Rewards obtained: [-1810.8742067340681], Lows: [29], Highs: [1822], Total time: 38835.335905
[32m[0907 01-04-20 @MBExp.py:144][0m ####################################################################
[32m[0907 01-04-20 @MBExp.py:145][0m Starting training iteration 47.
[32m[0907 01-04-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30851, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-04-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30884, current rewards: -19.05702, mean: -0.31762
[32m[0907 01-04-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31043, current rewards: -14.80148, mean: -0.13456
[32m[0907 01-05-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31184, current rewards: -10.51865, mean: -0.06574
[32m[0907 01-05-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31170, current rewards: -6.24142, mean: -0.02972
[32m[0907 01-05-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31123, current rewards: -1.96323, mean: -0.00755
[32m[0907 01-05-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31085, current rewards: 2.31390, mean: 0.00746
[32m[0907 01-06-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31049, current rewards: 10.50512, mean: 0.02918
[32m[0907 01-06-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31020, current rewards: 15.34948, mean: 0.03744
[32m[0907 01-06-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30999, current rewards: 20.24656, mean: 0.04401
[32m[0907 01-06-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31034, current rewards: 25.14171, mean: 0.04930
[32m[0907 01-07-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31084, current rewards: 30.03846, mean: 0.05364
[32m[0907 01-07-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31121, current rewards: 34.93670, mean: 0.05727
[32m[0907 01-07-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31158, current rewards: 39.83673, mean: 0.06036
[32m[0907 01-08-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31192, current rewards: 44.73208, mean: 0.06300
[32m[0907 01-08-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31214, current rewards: 48.87980, mean: 0.06432
[32m[0907 01-08-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31239, current rewards: 30.99116, mean: 0.03826
[32m[0907 01-08-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31258, current rewards: 36.70299, mean: 0.04268
[32m[0907 01-09-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31273, current rewards: 42.20518, mean: 0.04638
[32m[0907 01-09-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31285, current rewards: 47.70660, mean: 0.04969
[32m[0907 01-09-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31296, current rewards: 44.76577, mean: 0.04432
[32m[0907 01-09-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31303, current rewards: 16.12531, mean: 0.01521
[32m[0907 01-10-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31314, current rewards: 22.16257, mean: 0.01997
[32m[0907 01-10-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31322, current rewards: 28.55846, mean: 0.02462
[32m[0907 01-10-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31324, current rewards: 38.66457, mean: 0.03195
[32m[0907 01-10-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31330, current rewards: 20.72731, mean: 0.01645
[32m[0907 01-11-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31334, current rewards: 24.38052, mean: 0.01861
[32m[0907 01-11-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31337, current rewards: 27.91822, mean: 0.02053
[32m[0907 01-11-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31340, current rewards: 31.44930, mean: 0.02230
[32m[0907 01-11-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31340, current rewards: 34.98049, mean: 0.02396
[32m[0907 01-12-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31344, current rewards: 38.51202, mean: 0.02550
[32m[0907 01-12-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31343, current rewards: 42.04459, mean: 0.02695
[32m[0907 01-12-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31349, current rewards: 28.25023, mean: 0.01755
[32m[0907 01-13-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31352, current rewards: 32.17406, mean: 0.01938
[32m[0907 01-13-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31354, current rewards: 35.93785, mean: 0.02102
[32m[0907 01-13-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31354, current rewards: 39.61221, mean: 0.02251
[32m[0907 01-13-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31358, current rewards: 43.29118, mean: 0.02392
[32m[0907 01-14-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31358, current rewards: 46.98423, mean: 0.02526
[32m[0907 01-14-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31356, current rewards: 60.74117, mean: 0.03180
[32m[0907 01-14-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31357, current rewards: 66.93865, mean: 0.03415
[32m[0907 01-14-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31359, current rewards: 76.35664, mean: 0.03799
[32m[0907 01-15-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31359, current rewards: 82.49626, mean: 0.04005
[32m[0907 01-15-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31360, current rewards: 88.39225, mean: 0.04189
[32m[0907 01-15-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31359, current rewards: 94.28597, mean: 0.04365
[32m[0907 01-15-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31358, current rewards: 100.17834, mean: 0.04533
[32m[0907 01-16-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31360, current rewards: 106.07404, mean: 0.04694
[32m[0907 01-16-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31348, current rewards: 111.96848, mean: 0.04847
[32m[0907 01-16-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31336, current rewards: 117.86850, mean: 0.04994
[32m[0907 01-16-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31324, current rewards: 125.42917, mean: 0.05205
[32m[0907 01-17-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31313, current rewards: 116.30306, mean: 0.04728
[32m[0907 01-17-23 @Agent.py:117][0m Average action selection time: 0.3129
[32m[0907 01-17-23 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-17-23 @MBExp.py:227][0m Rewards obtained: [121.17839789023077], Lows: [44], Highs: [57], Total time: 39618.271585
[32m[0907 01-18-50 @MBExp.py:144][0m ####################################################################
[32m[0907 01-18-50 @MBExp.py:145][0m Starting training iteration 48.
[32m[0907 01-18-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30819, current rewards: 0.74851, mean: 0.07485
[32m[0907 01-19-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30888, current rewards: 5.81449, mean: 0.09691
[32m[0907 01-19-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31043, current rewards: 11.06216, mean: 0.10057
[32m[0907 01-19-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31234, current rewards: 16.34213, mean: 0.10214
[32m[0907 01-19-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31218, current rewards: 21.66201, mean: 0.10315
[32m[0907 01-20-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31148, current rewards: 26.94169, mean: 0.10362
[32m[0907 01-20-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31096, current rewards: 32.21996, mean: 0.10394
[32m[0907 01-20-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31056, current rewards: 39.22950, mean: 0.10897
[32m[0907 01-20-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31029, current rewards: 44.94206, mean: 0.10961
[32m[0907 01-21-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31006, current rewards: 50.61913, mean: 0.11004
[32m[0907 01-21-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31051, current rewards: 3.95975, mean: 0.00776
[32m[0907 01-21-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31101, current rewards: -46.04025, mean: -0.08221
[32m[0907 01-22-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31134, current rewards: -96.04025, mean: -0.15744
[32m[0907 01-22-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31168, current rewards: -146.04025, mean: -0.22127
[32m[0907 01-22-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31198, current rewards: -196.04025, mean: -0.27611
[32m[0907 01-22-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31219, current rewards: -246.04025, mean: -0.32374
[32m[0907 01-23-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31238, current rewards: -296.04025, mean: -0.36548
[32m[0907 01-23-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31258, current rewards: -346.04025, mean: -0.40237
[32m[0907 01-23-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31273, current rewards: -396.04025, mean: -0.43521
[32m[0907 01-23-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31292, current rewards: -446.04025, mean: -0.46463
[32m[0907 01-24-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31307, current rewards: -496.04025, mean: -0.49113
[32m[0907 01-24-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31315, current rewards: -546.04025, mean: -0.51513
[32m[0907 01-24-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31324, current rewards: -596.04025, mean: -0.53697
[32m[0907 01-24-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31336, current rewards: -646.04025, mean: -0.55693
[32m[0907 01-25-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31341, current rewards: -696.04025, mean: -0.57524
[32m[0907 01-25-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31343, current rewards: -746.04025, mean: -0.59210
[32m[0907 01-25-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31347, current rewards: -796.04025, mean: -0.60766
[32m[0907 01-25-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31349, current rewards: -846.04025, mean: -0.62209
[32m[0907 01-26-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31353, current rewards: -896.04025, mean: -0.63549
[32m[0907 01-26-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31358, current rewards: -946.04025, mean: -0.64797
[32m[0907 01-26-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31356, current rewards: -996.04025, mean: -0.65963
[32m[0907 01-27-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31355, current rewards: -1046.04025, mean: -0.67054
[32m[0907 01-27-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31359, current rewards: -1096.04025, mean: -0.68077
[32m[0907 01-27-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31360, current rewards: -1146.04025, mean: -0.69039
[32m[0907 01-27-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31363, current rewards: -1196.04025, mean: -0.69944
[32m[0907 01-28-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31364, current rewards: -1246.04025, mean: -0.70798
[32m[0907 01-28-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31362, current rewards: -1296.04025, mean: -0.71604
[32m[0907 01-28-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31364, current rewards: -1346.04025, mean: -0.72368
[32m[0907 01-28-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31364, current rewards: -1396.04025, mean: -0.73091
[32m[0907 01-29-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31367, current rewards: -1446.04025, mean: -0.73778
[32m[0907 01-29-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31366, current rewards: -1496.04025, mean: -0.74430
[32m[0907 01-29-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31366, current rewards: -1546.04025, mean: -0.75050
[32m[0907 01-29-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31369, current rewards: -1596.04025, mean: -0.75642
[32m[0907 01-30-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31369, current rewards: -1646.04025, mean: -0.76206
[32m[0907 01-30-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31368, current rewards: -1696.04025, mean: -0.76744
[32m[0907 01-30-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31368, current rewards: -1746.04025, mean: -0.77258
[32m[0907 01-30-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31353, current rewards: -1796.04025, mean: -0.77751
[32m[0907 01-31-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31338, current rewards: -1846.04025, mean: -0.78222
[32m[0907 01-31-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31324, current rewards: -1896.04025, mean: -0.78674
[32m[0907 01-31-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31310, current rewards: -1946.04025, mean: -0.79107
[32m[0907 01-31-53 @Agent.py:117][0m Average action selection time: 0.3129
[32m[0907 01-31-53 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-31-53 @MBExp.py:227][0m Rewards obtained: [-1986.040245885501], Lows: [0], Highs: [2037], Total time: 40401.095722000005
[32m[0907 01-33-22 @MBExp.py:144][0m ####################################################################
[32m[0907 01-33-22 @MBExp.py:145][0m Starting training iteration 49.
[32m[0907 01-33-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30760, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-33-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30810, current rewards: -68.72913, mean: -1.14549
[32m[0907 01-33-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31003, current rewards: -72.14077, mean: -0.65583
[32m[0907 01-34-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31205, current rewards: -68.08353, mean: -0.42552
[32m[0907 01-34-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31175, current rewards: -63.98404, mean: -0.30469
[32m[0907 01-34-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31118, current rewards: -59.88493, mean: -0.23033
[32m[0907 01-34-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31062, current rewards: -55.78162, mean: -0.17994
[32m[0907 01-35-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31018, current rewards: -71.56127, mean: -0.19878
[32m[0907 01-35-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30980, current rewards: -66.68613, mean: -0.16265
[32m[0907 01-35-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30954, current rewards: -63.13911, mean: -0.13726
[32m[0907 01-36-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30992, current rewards: -59.74158, mean: -0.11714
[32m[0907 01-36-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31031, current rewards: -56.41150, mean: -0.10073
[32m[0907 01-36-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31076, current rewards: -109.14772, mean: -0.17893
[32m[0907 01-36-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31126, current rewards: -160.88138, mean: -0.24376
[32m[0907 01-37-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31158, current rewards: -249.55708, mean: -0.35149
[32m[0907 01-37-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31180, current rewards: -349.55708, mean: -0.45994
[32m[0907 01-37-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31201, current rewards: -449.55708, mean: -0.55501
[32m[0907 01-37-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31223, current rewards: -549.55708, mean: -0.63902
[32m[0907 01-38-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31243, current rewards: -649.55708, mean: -0.71380
[32m[0907 01-38-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31261, current rewards: -749.55708, mean: -0.78079
[32m[0907 01-38-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31272, current rewards: -849.55708, mean: -0.84115
[32m[0907 01-38-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31287, current rewards: -949.55708, mean: -0.89581
[32m[0907 01-39-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31299, current rewards: -1049.55708, mean: -0.94555
[32m[0907 01-39-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31310, current rewards: -1149.55708, mean: -0.99100
[32m[0907 01-39-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31316, current rewards: -1249.55708, mean: -1.03269
[32m[0907 01-39-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31323, current rewards: -1349.55708, mean: -1.07108
[32m[0907 01-40-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31332, current rewards: -1449.55708, mean: -1.10653
[32m[0907 01-40-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31338, current rewards: -1549.55708, mean: -1.13938
[32m[0907 01-40-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31346, current rewards: -1649.55708, mean: -1.16990
[32m[0907 01-41-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31350, current rewards: -1749.55708, mean: -1.19833
[32m[0907 01-41-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31355, current rewards: -1849.55708, mean: -1.22487
[32m[0907 01-41-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31357, current rewards: -1949.55708, mean: -1.24972
[32m[0907 01-41-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31361, current rewards: -2049.55708, mean: -1.27302
[32m[0907 01-42-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31362, current rewards: -2149.55708, mean: -1.29491
[32m[0907 01-42-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31366, current rewards: -2249.55708, mean: -1.31553
[32m[0907 01-42-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31363, current rewards: -2349.55708, mean: -1.33498
[32m[0907 01-42-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31367, current rewards: -2449.55708, mean: -1.35335
[32m[0907 01-43-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31368, current rewards: -2549.55708, mean: -1.37073
[32m[0907 01-43-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31367, current rewards: -2649.55708, mean: -1.38720
[32m[0907 01-43-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31366, current rewards: -2749.55708, mean: -1.40284
[32m[0907 01-43-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31368, current rewards: -2849.55708, mean: -1.41769
[32m[0907 01-44-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31364, current rewards: -2949.55708, mean: -1.43182
[32m[0907 01-44-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31361, current rewards: -3049.55708, mean: -1.44529
[32m[0907 01-44-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31362, current rewards: -3149.55708, mean: -1.45813
[32m[0907 01-44-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31361, current rewards: -3249.55708, mean: -1.47039
[32m[0907 01-45-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31361, current rewards: -3349.55708, mean: -1.48210
[32m[0907 01-45-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31346, current rewards: -3449.55708, mean: -1.49331
[32m[0907 01-45-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31332, current rewards: -3549.55708, mean: -1.50405
[32m[0907 01-45-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31318, current rewards: -3649.55708, mean: -1.51434
[32m[0907 01-46-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31304, current rewards: -3749.55708, mean: -1.52421
[32m[0907 01-46-25 @Agent.py:117][0m Average action selection time: 0.3128
[32m[0907 01-46-25 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-46-25 @MBExp.py:227][0m Rewards obtained: [-3829.5570784124448], Lows: [1896], Highs: [84], Total time: 41183.75019300001
[32m[0907 01-47-56 @MBExp.py:144][0m ####################################################################
[32m[0907 01-47-56 @MBExp.py:145][0m Starting training iteration 50.
[32m[0907 01-47-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30735, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-48-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30741, current rewards: -29.07806, mean: -0.48463
[32m[0907 01-48-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30966, current rewards: -40.73591, mean: -0.37033
[32m[0907 01-48-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31159, current rewards: -36.84811, mean: -0.23030
[32m[0907 01-49-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31110, current rewards: -29.99239, mean: -0.14282
[32m[0907 01-49-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31051, current rewards: -23.00641, mean: -0.08849
[32m[0907 01-49-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31015, current rewards: -16.02319, mean: -0.05169
[32m[0907 01-49-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30993, current rewards: -7.44504, mean: -0.02068
[32m[0907 01-50-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30965, current rewards: -1.35567, mean: -0.00331
[32m[0907 01-50-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30954, current rewards: 5.48913, mean: 0.01193
[32m[0907 01-50-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30998, current rewards: 12.33176, mean: 0.02418
[32m[0907 01-50-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31048, current rewards: 19.18142, mean: 0.03425
[32m[0907 01-51-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31088, current rewards: 26.01929, mean: 0.04265
[32m[0907 01-51-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31122, current rewards: -10.27548, mean: -0.01557
[32m[0907 01-51-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31153, current rewards: -7.53519, mean: -0.01061
[32m[0907 01-51-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31173, current rewards: -4.36619, mean: -0.00574
[32m[0907 01-52-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31192, current rewards: 1.42904, mean: 0.00176
[32m[0907 01-52-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31207, current rewards: 7.22426, mean: 0.00840
[32m[0907 01-52-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31219, current rewards: 13.01949, mean: 0.01431
[32m[0907 01-52-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31232, current rewards: 18.81472, mean: 0.01960
[32m[0907 01-53-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31244, current rewards: 24.60995, mean: 0.02437
[32m[0907 01-53-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31258, current rewards: 30.40518, mean: 0.02868
[32m[0907 01-53-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31268, current rewards: 36.20040, mean: 0.03261
[32m[0907 01-53-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31278, current rewards: 27.48887, mean: 0.02370
[32m[0907 01-54-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31288, current rewards: -22.51113, mean: -0.01860
[32m[0907 01-54-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31295, current rewards: -72.51113, mean: -0.05755
[32m[0907 01-54-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31305, current rewards: -122.51113, mean: -0.09352
[32m[0907 01-55-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31317, current rewards: -172.51113, mean: -0.12685
[32m[0907 01-55-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31322, current rewards: -222.51113, mean: -0.15781
[32m[0907 01-55-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31324, current rewards: -272.51113, mean: -0.18665
[32m[0907 01-55-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31330, current rewards: -322.51113, mean: -0.21358
[32m[0907 01-56-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31333, current rewards: -372.51113, mean: -0.23879
[32m[0907 01-56-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31336, current rewards: -422.51113, mean: -0.26243
[32m[0907 01-56-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31337, current rewards: -472.51113, mean: -0.28465
[32m[0907 01-56-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31338, current rewards: -522.51113, mean: -0.30556
[32m[0907 01-57-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31343, current rewards: -572.51113, mean: -0.32529
[32m[0907 01-57-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31344, current rewards: -622.51113, mean: -0.34393
[32m[0907 01-57-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31349, current rewards: -672.51113, mean: -0.36157
[32m[0907 01-57-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31352, current rewards: -722.51113, mean: -0.37828
[32m[0907 01-58-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31357, current rewards: -772.51113, mean: -0.39414
[32m[0907 01-58-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31361, current rewards: -822.51113, mean: -0.40921
[32m[0907 01-58-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31362, current rewards: -872.51113, mean: -0.42355
[32m[0907 01-58-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31363, current rewards: -922.51113, mean: -0.43721
[32m[0907 01-59-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31366, current rewards: -972.51113, mean: -0.45024
[32m[0907 01-59-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31368, current rewards: -1022.51113, mean: -0.46267
[32m[0907 01-59-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31370, current rewards: -1072.51113, mean: -0.47456
[32m[0907 02-00-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31356, current rewards: -1122.51113, mean: -0.48594
[32m[0907 02-00-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31342, current rewards: -1172.51113, mean: -0.49683
[32m[0907 02-00-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31329, current rewards: -1222.51113, mean: -0.50727
[32m[0907 02-00-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31316, current rewards: -1272.51113, mean: -0.51728
[32m[0907 02-00-59 @Agent.py:117][0m Average action selection time: 0.3129
[32m[0907 02-00-59 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-00-59 @MBExp.py:227][0m Rewards obtained: [-1312.5111277504325], Lows: [20], Highs: [1398], Total time: 41966.73788300001
[32m[0907 02-02-32 @MBExp.py:144][0m ####################################################################
[32m[0907 02-02-32 @MBExp.py:145][0m Starting training iteration 51.
[32m[0907 02-02-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30739, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-02-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30769, current rewards: -52.20957, mean: -0.87016
[32m[0907 02-03-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31117, current rewards: -84.66519, mean: -0.76968
[32m[0907 02-03-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31328, current rewards: -121.61819, mean: -0.76011
[32m[0907 02-03-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31212, current rewards: -157.46352, mean: -0.74983
[32m[0907 02-03-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31146, current rewards: -188.89078, mean: -0.72650
[32m[0907 02-04-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31093, current rewards: -225.82006, mean: -0.72845
[32m[0907 02-04-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31059, current rewards: -258.25215, mean: -0.71737
[32m[0907 02-04-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31024, current rewards: -308.68813, mean: -0.75290
[32m[0907 02-04-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31006, current rewards: -302.76642, mean: -0.65819
[32m[0907 02-05-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31042, current rewards: -297.81839, mean: -0.58396
[32m[0907 02-05-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31088, current rewards: -292.87759, mean: -0.52300
[32m[0907 02-05-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31129, current rewards: -287.93125, mean: -0.47202
[32m[0907 02-05-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31170, current rewards: -282.98984, mean: -0.42877
[32m[0907 02-06-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31194, current rewards: -292.29383, mean: -0.41168
[32m[0907 02-06-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31215, current rewards: -291.73281, mean: -0.38386
[32m[0907 02-06-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31231, current rewards: -286.04869, mean: -0.35315
[32m[0907 02-07-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31249, current rewards: -280.39992, mean: -0.32605
[32m[0907 02-07-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31270, current rewards: -274.75590, mean: -0.30193
[32m[0907 02-07-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31287, current rewards: -300.80917, mean: -0.31334
[32m[0907 02-07-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31297, current rewards: -305.63628, mean: -0.30261
[32m[0907 02-08-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31314, current rewards: -301.06029, mean: -0.28402
[32m[0907 02-08-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31321, current rewards: -299.35809, mean: -0.26969
[32m[0907 02-08-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31350, current rewards: -311.42122, mean: -0.26847
[32m[0907 02-08-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31360, current rewards: -304.88633, mean: -0.25197
[32m[0907 02-09-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31363, current rewards: -314.04626, mean: -0.24924
[32m[0907 02-09-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31367, current rewards: -322.95304, mean: -0.24653
[32m[0907 02-09-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31370, current rewards: -316.22118, mean: -0.23252
[32m[0907 02-09-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31372, current rewards: -309.29568, mean: -0.21936
[32m[0907 02-10-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31378, current rewards: -302.37896, mean: -0.20711
[32m[0907 02-10-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31382, current rewards: -295.46271, mean: -0.19567
[32m[0907 02-10-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31385, current rewards: -291.10447, mean: -0.18661
[32m[0907 02-10-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31390, current rewards: -284.04093, mean: -0.17642
[32m[0907 02-11-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31394, current rewards: -276.93102, mean: -0.16683
[32m[0907 02-11-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31399, current rewards: -269.80720, mean: -0.15778
[32m[0907 02-11-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31402, current rewards: -286.87340, mean: -0.16300
[32m[0907 02-12-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31405, current rewards: -281.97484, mean: -0.15579
[32m[0907 02-12-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31407, current rewards: -276.87821, mean: -0.14886
[32m[0907 02-12-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31409, current rewards: -271.80707, mean: -0.14231
[32m[0907 02-12-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31415, current rewards: -264.17547, mean: -0.13478
[32m[0907 02-13-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31419, current rewards: -259.66803, mean: -0.12919
[32m[0907 02-13-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31420, current rewards: -254.71453, mean: -0.12365
[32m[0907 02-13-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31419, current rewards: -249.75006, mean: -0.11836
[32m[0907 02-13-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31418, current rewards: -244.78810, mean: -0.11333
[32m[0907 02-14-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31420, current rewards: -238.48700, mean: -0.10791
[32m[0907 02-14-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31416, current rewards: -219.45015, mean: -0.09710
[32m[0907 02-14-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31402, current rewards: -204.62784, mean: -0.08858
[32m[0907 02-14-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31389, current rewards: -189.93576, mean: -0.08048
[32m[0907 02-15-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31375, current rewards: -176.08536, mean: -0.07306
[32m[0907 02-15-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31362, current rewards: -161.81733, mean: -0.06578
[32m[0907 02-15-36 @Agent.py:117][0m Average action selection time: 0.3134
[32m[0907 02-15-36 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-15-36 @MBExp.py:227][0m Rewards obtained: [-150.38783104775604], Lows: [51], Highs: [344], Total time: 42750.81651800001
[32m[0907 02-17-11 @MBExp.py:144][0m ####################################################################
[32m[0907 02-17-11 @MBExp.py:145][0m Starting training iteration 52.
[32m[0907 02-17-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30661, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-17-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31085, current rewards: -21.81035, mean: -0.36351
[32m[0907 02-17-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31167, current rewards: -18.90150, mean: -0.17183
[32m[0907 02-18-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31244, current rewards: -14.01904, mean: -0.08762
[32m[0907 02-18-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31145, current rewards: -30.94459, mean: -0.14736
[32m[0907 02-18-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31635, current rewards: -70.30901, mean: -0.27042
[32m[0907 02-18-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31514, current rewards: -72.76007, mean: -0.23471
[32m[0907 02-19-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31424, current rewards: -68.13360, mean: -0.18926
[32m[0907 02-19-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31356, current rewards: -63.52971, mean: -0.15495
[32m[0907 02-19-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31301, current rewards: -58.91200, mean: -0.12807
[32m[0907 02-19-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31326, current rewards: -54.29421, mean: -0.10646
[32m[0907 02-20-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31332, current rewards: -49.67916, mean: -0.08871
[32m[0907 02-20-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31348, current rewards: -39.50397, mean: -0.06476
[32m[0907 02-20-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31354, current rewards: -34.92087, mean: -0.05291
[32m[0907 02-20-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31360, current rewards: -30.19072, mean: -0.04252
[32m[0907 02-21-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31377, current rewards: -25.65371, mean: -0.03375
[32m[0907 02-21-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31385, current rewards: -21.11472, mean: -0.02607
[32m[0907 02-21-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31387, current rewards: -16.57588, mean: -0.01927
[32m[0907 02-21-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31397, current rewards: -12.04299, mean: -0.01323
[32m[0907 02-22-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31399, current rewards: -22.13883, mean: -0.02306
[32m[0907 02-22-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31408, current rewards: -43.18085, mean: -0.04275
[32m[0907 02-22-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31408, current rewards: -38.73302, mean: -0.03654
[32m[0907 02-23-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31412, current rewards: -32.85418, mean: -0.02960
[32m[0907 02-23-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31409, current rewards: -27.50702, mean: -0.02371
[32m[0907 02-23-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31412, current rewards: -22.15986, mean: -0.01831
[32m[0907 02-23-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31415, current rewards: -16.81270, mean: -0.01334
[32m[0907 02-24-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31420, current rewards: -46.88773, mean: -0.03579
[32m[0907 02-24-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31423, current rewards: -96.88773, mean: -0.07124
[32m[0907 02-24-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31425, current rewards: -146.88773, mean: -0.10418
[32m[0907 02-24-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31424, current rewards: -196.88773, mean: -0.13485
[32m[0907 02-25-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31428, current rewards: -246.88773, mean: -0.16350
[32m[0907 02-25-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31430, current rewards: -296.88773, mean: -0.19031
[32m[0907 02-25-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31431, current rewards: -346.88773, mean: -0.21546
[32m[0907 02-25-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31432, current rewards: -396.88773, mean: -0.23909
[32m[0907 02-26-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31431, current rewards: -446.88773, mean: -0.26134
[32m[0907 02-26-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31431, current rewards: -496.88773, mean: -0.28232
[32m[0907 02-26-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31430, current rewards: -546.88773, mean: -0.30215
[32m[0907 02-26-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31432, current rewards: -596.88773, mean: -0.32091
[32m[0907 02-27-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31435, current rewards: -646.88773, mean: -0.33868
[32m[0907 02-27-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31436, current rewards: -696.88773, mean: -0.35555
[32m[0907 02-27-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31436, current rewards: -746.88773, mean: -0.37159
[32m[0907 02-27-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31437, current rewards: -796.88773, mean: -0.38684
[32m[0907 02-28-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31438, current rewards: -846.88773, mean: -0.40137
[32m[0907 02-28-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31439, current rewards: -896.88773, mean: -0.41523
[32m[0907 02-28-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31439, current rewards: -946.88773, mean: -0.42846
[32m[0907 02-29-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31436, current rewards: -996.88773, mean: -0.44110
[32m[0907 02-29-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31421, current rewards: -1046.88773, mean: -0.45320
[32m[0907 02-29-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31409, current rewards: -1096.88773, mean: -0.46478
[32m[0907 02-29-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31397, current rewards: -1146.88773, mean: -0.47589
[32m[0907 02-30-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31384, current rewards: -1196.88773, mean: -0.48654
[32m[0907 02-30-15 @Agent.py:117][0m Average action selection time: 0.3136
[32m[0907 02-30-15 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-30-15 @MBExp.py:227][0m Rewards obtained: [-1236.887726296402], Lows: [45], Highs: [1273], Total time: 43535.48270000001
[32m[0907 02-31-52 @MBExp.py:144][0m ####################################################################
[32m[0907 02-31-52 @MBExp.py:145][0m Starting training iteration 53.
[32m[0907 02-31-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30781, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-32-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31221, current rewards: -42.10271, mean: -0.70171
[32m[0907 02-32-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31615, current rewards: -49.44832, mean: -0.44953
[32m[0907 02-32-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31515, current rewards: -49.44545, mean: -0.30903
[32m[0907 02-32-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31371, current rewards: -45.68554, mean: -0.21755
[32m[0907 02-33-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31284, current rewards: -38.17220, mean: -0.14682
[32m[0907 02-33-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31210, current rewards: -29.13495, mean: -0.09398
[32m[0907 02-33-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31174, current rewards: -24.02520, mean: -0.06674
[32m[0907 02-34-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31130, current rewards: -18.90044, mean: -0.04610
[32m[0907 02-34-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31111, current rewards: -13.77464, mean: -0.02994
[32m[0907 02-34-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31167, current rewards: -8.64821, mean: -0.01696
[32m[0907 02-34-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31234, current rewards: -26.27751, mean: -0.04692
[32m[0907 02-35-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31266, current rewards: -21.57814, mean: -0.03537
[32m[0907 02-35-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31286, current rewards: -16.99277, mean: -0.02575
[32m[0907 02-35-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31305, current rewards: -12.56653, mean: -0.01770
[32m[0907 02-35-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31324, current rewards: -7.96784, mean: -0.01048
[32m[0907 02-36-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31336, current rewards: -3.36614, mean: -0.00416
[32m[0907 02-36-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31347, current rewards: 1.23959, mean: 0.00144
[32m[0907 02-36-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31353, current rewards: 5.84174, mean: 0.00642
[32m[0907 02-36-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31364, current rewards: -64.22429, mean: -0.06690
[32m[0907 02-37-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31374, current rewards: -57.81576, mean: -0.05724
[32m[0907 02-37-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31383, current rewards: -51.51268, mean: -0.04860
[32m[0907 02-37-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31390, current rewards: -45.46741, mean: -0.04096
[32m[0907 02-37-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31395, current rewards: -39.42215, mean: -0.03398
[32m[0907 02-38-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31401, current rewards: -33.37688, mean: -0.02758
[32m[0907 02-38-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31404, current rewards: -27.33161, mean: -0.02169
[32m[0907 02-38-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31409, current rewards: -21.28635, mean: -0.01625
[32m[0907 02-39-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31410, current rewards: -36.53828, mean: -0.02687
[32m[0907 02-39-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31412, current rewards: -86.53828, mean: -0.06137
[32m[0907 02-39-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31415, current rewards: -136.53828, mean: -0.09352
[32m[0907 02-39-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31416, current rewards: -186.53828, mean: -0.12354
[32m[0907 02-40-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31420, current rewards: -236.53828, mean: -0.15163
[32m[0907 02-40-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31421, current rewards: -286.53828, mean: -0.17797
[32m[0907 02-40-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31424, current rewards: -336.53828, mean: -0.20273
[32m[0907 02-40-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31424, current rewards: -386.53828, mean: -0.22605
[32m[0907 02-41-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31427, current rewards: -436.53828, mean: -0.24803
[32m[0907 02-41-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31428, current rewards: -486.53828, mean: -0.26881
[32m[0907 02-41-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31430, current rewards: -536.53828, mean: -0.28846
[32m[0907 02-41-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31431, current rewards: -586.53828, mean: -0.30709
[32m[0907 02-42-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31431, current rewards: -636.53828, mean: -0.32476
[32m[0907 02-42-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31432, current rewards: -686.53828, mean: -0.34156
[32m[0907 02-42-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31433, current rewards: -736.53828, mean: -0.35754
[32m[0907 02-42-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31434, current rewards: -786.53828, mean: -0.37277
[32m[0907 02-43-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31435, current rewards: -836.53828, mean: -0.38729
[32m[0907 02-43-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31436, current rewards: -886.53828, mean: -0.40115
[32m[0907 02-43-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31429, current rewards: -936.53828, mean: -0.41440
[32m[0907 02-43-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31416, current rewards: -986.53828, mean: -0.42707
[32m[0907 02-44-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31403, current rewards: -1036.53828, mean: -0.43921
[32m[0907 02-44-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31391, current rewards: -1086.53828, mean: -0.45085
[32m[0907 02-44-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31376, current rewards: -1136.53828, mean: -0.46201
[32m[0907 02-44-57 @Agent.py:117][0m Average action selection time: 0.3135
[32m[0907 02-44-57 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-44-57 @MBExp.py:227][0m Rewards obtained: [-1176.5382849501564], Lows: [46], Highs: [1227], Total time: 44319.96357300001
[32m[0907 02-46-35 @MBExp.py:144][0m ####################################################################
[32m[0907 02-46-35 @MBExp.py:145][0m Starting training iteration 54.
[32m[0907 02-46-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30878, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-46-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32122, current rewards: -29.34043, mean: -0.48901
[32m[0907 02-47-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32349, current rewards: -37.59873, mean: -0.34181
[32m[0907 02-47-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32074, current rewards: -41.23040, mean: -0.25769
[32m[0907 02-47-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32171, current rewards: -44.58072, mean: -0.21229
[32m[0907 02-47-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32241, current rewards: -68.81922, mean: -0.26469
[32m[0907 02-48-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32093, current rewards: -66.71331, mean: -0.21520
[32m[0907 02-48-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31949, current rewards: -84.94111, mean: -0.23595
[32m[0907 02-48-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31810, current rewards: -80.13631, mean: -0.19545
[32m[0907 02-49-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31730, current rewards: -77.22712, mean: -0.16789
[32m[0907 02-49-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31709, current rewards: -74.08568, mean: -0.14527
[32m[0907 02-49-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31696, current rewards: -68.59785, mean: -0.12250
[32m[0907 02-49-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31679, current rewards: -63.43782, mean: -0.10400
[32m[0907 02-50-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31669, current rewards: -58.64600, mean: -0.08886
[32m[0907 02-50-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31659, current rewards: -53.47955, mean: -0.07532
[32m[0907 02-50-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31652, current rewards: -48.05580, mean: -0.06323
[32m[0907 02-50-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31647, current rewards: -42.82843, mean: -0.05287
[32m[0907 02-51-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31641, current rewards: -37.62644, mean: -0.04375
[32m[0907 02-51-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31631, current rewards: -32.41640, mean: -0.03562
[32m[0907 02-51-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31628, current rewards: -27.21007, mean: -0.02834
[32m[0907 02-51-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31625, current rewards: -64.17041, mean: -0.06354
[32m[0907 02-52-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31634, current rewards: -67.77869, mean: -0.06394
[32m[0907 02-52-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31631, current rewards: -63.22456, mean: -0.05696
[32m[0907 02-52-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31630, current rewards: -58.58430, mean: -0.05050
[32m[0907 02-52-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31626, current rewards: -54.06410, mean: -0.04468
[32m[0907 02-53-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31622, current rewards: -49.54199, mean: -0.03932
[32m[0907 02-53-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31621, current rewards: -45.02314, mean: -0.03437
[32m[0907 02-53-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31619, current rewards: -40.50214, mean: -0.02978
[32m[0907 02-54-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31612, current rewards: -35.98146, mean: -0.02552
[32m[0907 02-54-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31611, current rewards: -50.00131, mean: -0.03425
[32m[0907 02-54-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31615, current rewards: -84.63166, mean: -0.05605
[32m[0907 02-54-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31612, current rewards: -184.63166, mean: -0.11835
[32m[0907 02-55-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31609, current rewards: -284.63166, mean: -0.17679
[32m[0907 02-55-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31604, current rewards: -384.63166, mean: -0.23171
[32m[0907 02-55-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31602, current rewards: -484.63166, mean: -0.28341
[32m[0907 02-55-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31598, current rewards: -584.63166, mean: -0.33218
[32m[0907 02-56-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31593, current rewards: -684.63166, mean: -0.37825
[32m[0907 02-56-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31592, current rewards: -784.63166, mean: -0.42184
[32m[0907 02-56-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31586, current rewards: -884.63166, mean: -0.46316
[32m[0907 02-56-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31582, current rewards: -984.63166, mean: -0.50236
[32m[0907 02-57-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31579, current rewards: -1084.63166, mean: -0.53962
[32m[0907 02-57-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31577, current rewards: -1184.63166, mean: -0.57506
[32m[0907 02-57-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31575, current rewards: -1284.63166, mean: -0.60883
[32m[0907 02-57-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31573, current rewards: -1384.63166, mean: -0.64103
[32m[0907 02-58-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31569, current rewards: -1484.63166, mean: -0.67178
[32m[0907 02-58-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31556, current rewards: -1584.63166, mean: -0.70116
[32m[0907 02-58-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31539, current rewards: -1684.63166, mean: -0.72928
[32m[0907 02-59-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31523, current rewards: -1784.63166, mean: -0.75620
[32m[0907 02-59-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31510, current rewards: -1884.63166, mean: -0.78200
[32m[0907 02-59-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31488, current rewards: -1984.63166, mean: -0.80676
[32m[0907 02-59-42 @Agent.py:117][0m Average action selection time: 0.3146
[32m[0907 02-59-42 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-59-42 @MBExp.py:227][0m Rewards obtained: [-2064.6316600301307], Lows: [1048], Highs: [113], Total time: 45107.13935500001
[32m[0907 03-01-23 @MBExp.py:144][0m ####################################################################
[32m[0907 03-01-23 @MBExp.py:145][0m Starting training iteration 55.
[32m[0907 03-01-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32873, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-01-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31313, current rewards: -68.00322, mean: -1.13339
[32m[0907 03-01-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31532, current rewards: -64.04959, mean: -0.58227
[32m[0907 03-02-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31337, current rewards: -60.12899, mean: -0.37581
[32m[0907 03-02-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31227, current rewards: -56.21118, mean: -0.26767
[32m[0907 03-02-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31159, current rewards: -51.42028, mean: -0.19777
[32m[0907 03-02-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31114, current rewards: -47.32099, mean: -0.15265
[32m[0907 03-03-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31091, current rewards: -43.25210, mean: -0.12014
[32m[0907 03-03-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31064, current rewards: -39.17659, mean: -0.09555
[32m[0907 03-03-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31069, current rewards: -35.10174, mean: -0.07631
[32m[0907 03-04-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31129, current rewards: -31.02773, mean: -0.06084
[32m[0907 03-04-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31175, current rewards: -70.29487, mean: -0.12553
[32m[0907 03-04-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31211, current rewards: -64.01975, mean: -0.10495
[32m[0907 03-04-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31244, current rewards: -51.94010, mean: -0.07870
[32m[0907 03-05-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31265, current rewards: -41.05141, mean: -0.05782
[32m[0907 03-05-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31294, current rewards: -32.31061, mean: -0.04251
[32m[0907 03-05-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31310, current rewards: -29.47681, mean: -0.03639
[32m[0907 03-05-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31330, current rewards: -23.45679, mean: -0.02728
[32m[0907 03-06-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31349, current rewards: -18.23015, mean: -0.02003
[32m[0907 03-06-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31360, current rewards: -13.07561, mean: -0.01362
[32m[0907 03-06-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31369, current rewards: -7.92254, mean: -0.00784
[32m[0907 03-06-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31379, current rewards: -3.24080, mean: -0.00306
[32m[0907 03-07-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31386, current rewards: 1.82968, mean: 0.00165
[32m[0907 03-07-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31393, current rewards: 6.84544, mean: 0.00590
[32m[0907 03-07-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31402, current rewards: -10.19671, mean: -0.00843
[32m[0907 03-07-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31407, current rewards: -69.40690, mean: -0.05508
[32m[0907 03-08-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31407, current rewards: -64.43790, mean: -0.04919
[32m[0907 03-08-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31412, current rewards: -59.08496, mean: -0.04344
[32m[0907 03-08-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31417, current rewards: -53.59746, mean: -0.03801
[32m[0907 03-09-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31422, current rewards: -44.64837, mean: -0.03058
[32m[0907 03-09-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31428, current rewards: -38.61510, mean: -0.02557
[32m[0907 03-09-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31430, current rewards: -32.32185, mean: -0.02072
[32m[0907 03-09-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31431, current rewards: -26.01748, mean: -0.01616
[32m[0907 03-10-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31436, current rewards: -20.46285, mean: -0.01233
[32m[0907 03-10-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31441, current rewards: -15.48573, mean: -0.00906
[32m[0907 03-10-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31444, current rewards: -10.51265, mean: -0.00597
[32m[0907 03-10-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31443, current rewards: -5.54099, mean: -0.00306
[32m[0907 03-11-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31443, current rewards: -0.85977, mean: -0.00046
[32m[0907 03-11-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31445, current rewards: 3.61910, mean: 0.00189
[32m[0907 03-11-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31448, current rewards: 8.42370, mean: 0.00430
[32m[0907 03-11-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31448, current rewards: 13.24046, mean: 0.00659
[32m[0907 03-12-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31448, current rewards: -23.19086, mean: -0.01126
[32m[0907 03-12-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31449, current rewards: -18.64553, mean: -0.00884
[32m[0907 03-12-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31451, current rewards: -14.17573, mean: -0.00656
[32m[0907 03-12-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31451, current rewards: -9.67884, mean: -0.00438
[32m[0907 03-13-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31439, current rewards: -5.18460, mean: -0.00229
[32m[0907 03-13-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31425, current rewards: -1.01839, mean: -0.00044
[32m[0907 03-13-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31410, current rewards: 3.56856, mean: 0.00151
[32m[0907 03-14-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31397, current rewards: 8.03148, mean: 0.00333
[32m[0907 03-14-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31375, current rewards: 12.54759, mean: 0.00510
[32m[0907 03-14-27 @Agent.py:117][0m Average action selection time: 0.3135
[32m[0907 03-14-27 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-14-27 @MBExp.py:227][0m Rewards obtained: [16.140391437127576], Lows: [99], Highs: [42], Total time: 45891.50415300001
[32m[0907 03-16-09 @MBExp.py:144][0m ####################################################################
[32m[0907 03-16-09 @MBExp.py:145][0m Starting training iteration 56.
[32m[0907 03-16-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30651, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-16-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31239, current rewards: -79.94511, mean: -1.33242
[32m[0907 03-16-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31386, current rewards: -78.36235, mean: -0.71239
[32m[0907 03-16-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31207, current rewards: -71.13249, mean: -0.44458
[32m[0907 03-17-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31118, current rewards: -62.44694, mean: -0.29737
[32m[0907 03-17-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31056, current rewards: -55.66209, mean: -0.21408
[32m[0907 03-17-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31010, current rewards: -49.06161, mean: -0.15826
[32m[0907 03-18-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30984, current rewards: -42.46721, mean: -0.11796
[32m[0907 03-18-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30958, current rewards: -35.85946, mean: -0.08746
[32m[0907 03-18-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30970, current rewards: -29.26587, mean: -0.06362
[32m[0907 03-18-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31035, current rewards: -22.65750, mean: -0.04443
[32m[0907 03-19-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31083, current rewards: -16.05265, mean: -0.02867
[32m[0907 03-19-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31124, current rewards: -25.89105, mean: -0.04244
[32m[0907 03-19-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31175, current rewards: -79.94801, mean: -0.12113
[32m[0907 03-19-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31203, current rewards: -135.49398, mean: -0.19084
[32m[0907 03-20-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31228, current rewards: -184.65759, mean: -0.24297
[32m[0907 03-20-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31247, current rewards: -225.14365, mean: -0.27796
[32m[0907 03-20-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31265, current rewards: -254.80263, mean: -0.29628
[32m[0907 03-20-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31275, current rewards: -247.72694, mean: -0.27223
[32m[0907 03-21-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31283, current rewards: -240.60241, mean: -0.25063
[32m[0907 03-21-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31296, current rewards: -233.82203, mean: -0.23151
[32m[0907 03-21-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31304, current rewards: -235.82691, mean: -0.22248
[32m[0907 03-21-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31309, current rewards: -263.37719, mean: -0.23728
[32m[0907 03-22-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31313, current rewards: -255.78063, mean: -0.22050
[32m[0907 03-22-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31318, current rewards: -248.24940, mean: -0.20516
[32m[0907 03-22-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31326, current rewards: -240.72046, mean: -0.19105
[32m[0907 03-22-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31329, current rewards: -233.19039, mean: -0.17801
[32m[0907 03-23-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31331, current rewards: -225.65524, mean: -0.16592
[32m[0907 03-23-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31413, current rewards: -279.35702, mean: -0.19813
[32m[0907 03-23-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31514, current rewards: -315.77140, mean: -0.21628
[32m[0907 03-24-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31517, current rewards: -326.61237, mean: -0.21630
[32m[0907 03-24-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31515, current rewards: -320.76338, mean: -0.20562
[32m[0907 03-24-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31513, current rewards: -314.10077, mean: -0.19509
[32m[0907 03-24-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31510, current rewards: -307.44076, mean: -0.18521
[32m[0907 03-25-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31509, current rewards: -351.04516, mean: -0.20529
[32m[0907 03-25-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31508, current rewards: -374.03185, mean: -0.21252
[32m[0907 03-25-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31508, current rewards: -390.87540, mean: -0.21595
[32m[0907 03-25-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31506, current rewards: -422.89671, mean: -0.22736
[32m[0907 03-26-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31505, current rewards: -453.29669, mean: -0.23733
[32m[0907 03-26-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31503, current rewards: -486.58098, mean: -0.24826
[32m[0907 03-26-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31500, current rewards: -498.83227, mean: -0.24818
[32m[0907 03-26-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31500, current rewards: -516.48068, mean: -0.25072
[32m[0907 03-27-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31499, current rewards: -549.96649, mean: -0.26065
[32m[0907 03-27-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31497, current rewards: -580.10747, mean: -0.26857
[32m[0907 03-27-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31495, current rewards: -609.00899, mean: -0.27557
[32m[0907 03-28-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31480, current rewards: -626.20668, mean: -0.27708
[32m[0907 03-28-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31464, current rewards: -630.42889, mean: -0.27291
[32m[0907 03-28-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31450, current rewards: -614.73673, mean: -0.26048
[32m[0907 03-28-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31435, current rewards: -599.57485, mean: -0.24879
[32m[0907 03-29-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31410, current rewards: -583.83978, mean: -0.23733
[32m[0907 03-29-14 @Agent.py:117][0m Average action selection time: 0.3139
[32m[0907 03-29-14 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-29-14 @MBExp.py:227][0m Rewards obtained: [-571.3325734924057], Lows: [391], Highs: [115], Total time: 46676.79808800001
[32m[0907 03-30-58 @MBExp.py:144][0m ####################################################################
[32m[0907 03-30-58 @MBExp.py:145][0m Starting training iteration 57.
[32m[0907 03-31-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.39050, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-31-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32829, current rewards: -55.72556, mean: -0.92876
[32m[0907 03-31-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32053, current rewards: -155.72556, mean: -1.41569
[32m[0907 03-31-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31689, current rewards: -255.72556, mean: -1.59828
[32m[0907 03-32-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31479, current rewards: -355.72556, mean: -1.69393
[32m[0907 03-32-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31357, current rewards: -455.72556, mean: -1.75279
[32m[0907 03-32-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31267, current rewards: -555.72556, mean: -1.79266
[32m[0907 03-32-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31209, current rewards: -655.72556, mean: -1.82146
[32m[0907 03-33-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31158, current rewards: -755.72556, mean: -1.84323
[32m[0907 03-33-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31174, current rewards: -855.72556, mean: -1.86027
[32m[0907 03-33-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31221, current rewards: -955.72556, mean: -1.87397
[32m[0907 03-33-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31254, current rewards: -1055.72556, mean: -1.88522
[32m[0907 03-34-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31291, current rewards: -1155.72556, mean: -1.89463
[32m[0907 03-34-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31307, current rewards: -1255.72556, mean: -1.90261
[32m[0907 03-34-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31334, current rewards: -1355.72556, mean: -1.90947
[32m[0907 03-34-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31350, current rewards: -1455.72556, mean: -1.91543
[32m[0907 03-35-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31365, current rewards: -1555.72556, mean: -1.92065
[32m[0907 03-35-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31375, current rewards: -1655.72556, mean: -1.92526
[32m[0907 03-35-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31386, current rewards: -1755.72556, mean: -1.92937
[32m[0907 03-36-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31399, current rewards: -1855.72556, mean: -1.93305
[32m[0907 03-36-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31405, current rewards: -1955.72556, mean: -1.93636
[32m[0907 03-36-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31409, current rewards: -2055.72556, mean: -1.93936
[32m[0907 03-36-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31415, current rewards: -2155.72556, mean: -1.94210
[32m[0907 03-37-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31423, current rewards: -2255.72556, mean: -1.94459
[32m[0907 03-37-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31429, current rewards: -2355.72556, mean: -1.94688
[32m[0907 03-37-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31432, current rewards: -2455.72556, mean: -1.94899
[32m[0907 03-37-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31435, current rewards: -2555.72556, mean: -1.95094
[32m[0907 03-38-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31441, current rewards: -2655.72556, mean: -1.95274
[32m[0907 03-38-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31447, current rewards: -2755.72556, mean: -1.95442
[32m[0907 03-38-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31455, current rewards: -2855.72556, mean: -1.95598
[32m[0907 03-38-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31458, current rewards: -2955.72556, mean: -1.95743
[32m[0907 03-39-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31462, current rewards: -3055.72556, mean: -1.95880
[32m[0907 03-39-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31464, current rewards: -3155.72556, mean: -1.96008
[32m[0907 03-39-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31463, current rewards: -3255.72556, mean: -1.96128
[32m[0907 03-39-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31467, current rewards: -3355.72556, mean: -1.96241
[32m[0907 03-40-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31468, current rewards: -3455.72556, mean: -1.96348
[32m[0907 03-40-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31472, current rewards: -3555.72556, mean: -1.96449
[32m[0907 03-40-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31475, current rewards: -3655.72556, mean: -1.96544
[32m[0907 03-40-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31474, current rewards: -3755.72556, mean: -1.96635
[32m[0907 03-41-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31473, current rewards: -3855.72556, mean: -1.96721
[32m[0907 03-41-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31475, current rewards: -3955.72556, mean: -1.96802
[32m[0907 03-41-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31476, current rewards: -4055.72556, mean: -1.96880
[32m[0907 03-42-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31476, current rewards: -4155.72556, mean: -1.96954
[32m[0907 03-42-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31475, current rewards: -4255.72556, mean: -1.97024
[32m[0907 03-42-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31469, current rewards: -4355.72556, mean: -1.97092
[32m[0907 03-42-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31454, current rewards: -4455.72556, mean: -1.97156
[32m[0907 03-43-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31441, current rewards: -4555.72556, mean: -1.97218
[32m[0907 03-43-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31426, current rewards: -4655.72556, mean: -1.97277
[32m[0907 03-43-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31413, current rewards: -4755.72556, mean: -1.97333
[32m[0907 03-43-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31388, current rewards: -4855.72556, mean: -1.97387
[32m[0907 03-44-03 @Agent.py:117][0m Average action selection time: 0.3136
[32m[0907 03-44-03 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-44-03 @MBExp.py:227][0m Rewards obtained: [-4935.725563509837], Lows: [2459], Highs: [21], Total time: 47461.536148000014
[32m[0907 03-45-49 @MBExp.py:144][0m ####################################################################
[32m[0907 03-45-49 @MBExp.py:145][0m Starting training iteration 58.
[32m[0907 03-45-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30823, current rewards: 1.32305, mean: 0.13231
[32m[0907 03-46-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31153, current rewards: -21.97983, mean: -0.36633
[32m[0907 03-46-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31123, current rewards: -71.97983, mean: -0.65436
[32m[0907 03-46-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31052, current rewards: -109.25278, mean: -0.68283
[32m[0907 03-46-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31041, current rewards: -149.75979, mean: -0.71314
[32m[0907 03-47-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30999, current rewards: -185.95188, mean: -0.71520
[32m[0907 03-47-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30974, current rewards: -209.37534, mean: -0.67540
[32m[0907 03-47-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30964, current rewards: -238.15106, mean: -0.66153
[32m[0907 03-47-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30956, current rewards: -272.18612, mean: -0.66387
[32m[0907 03-48-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30997, current rewards: -311.57045, mean: -0.67733
[32m[0907 03-48-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31058, current rewards: -315.00750, mean: -0.61766
[32m[0907 03-48-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31104, current rewards: -315.04508, mean: -0.56258
[32m[0907 03-48-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31149, current rewards: -306.30458, mean: -0.50214
[32m[0907 03-49-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31186, current rewards: -301.49434, mean: -0.45681
[32m[0907 03-49-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31216, current rewards: -296.63176, mean: -0.41779
[32m[0907 03-49-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31238, current rewards: -291.77112, mean: -0.38391
[32m[0907 03-50-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31260, current rewards: -286.90562, mean: -0.35420
[32m[0907 03-50-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31276, current rewards: -282.03936, mean: -0.32795
[32m[0907 03-50-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31290, current rewards: -277.17696, mean: -0.30459
[32m[0907 03-50-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31304, current rewards: -272.31836, mean: -0.28366
[32m[0907 03-51-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31312, current rewards: -266.27066, mean: -0.26363
[32m[0907 03-51-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31375, current rewards: -300.74005, mean: -0.28372
[32m[0907 03-51-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31382, current rewards: -305.37378, mean: -0.27511
[32m[0907 03-51-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31404, current rewards: -300.23948, mean: -0.25883
[32m[0907 03-52-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31433, current rewards: -295.67118, mean: -0.24436
[32m[0907 03-52-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31469, current rewards: -291.02164, mean: -0.23097
[32m[0907 03-52-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31471, current rewards: -286.51125, mean: -0.21871
[32m[0907 03-52-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31509, current rewards: -281.96347, mean: -0.20733
[32m[0907 03-53-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31511, current rewards: -277.63526, mean: -0.19690
[32m[0907 03-53-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31513, current rewards: -285.66186, mean: -0.19566
[32m[0907 03-53-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31511, current rewards: -319.77436, mean: -0.21177
[32m[0907 03-54-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31511, current rewards: -329.80207, mean: -0.21141
[32m[0907 03-54-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31507, current rewards: -325.69277, mean: -0.20229
[32m[0907 03-54-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31510, current rewards: -321.64768, mean: -0.19376
[32m[0907 03-54-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31509, current rewards: -317.60358, mean: -0.18573
[32m[0907 03-55-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31503, current rewards: -313.55826, mean: -0.17816
[32m[0907 03-55-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31502, current rewards: -309.51570, mean: -0.17100
[32m[0907 03-55-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31500, current rewards: -301.23532, mean: -0.16195
[32m[0907 03-55-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31498, current rewards: -338.42387, mean: -0.17719
[32m[0907 03-56-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31496, current rewards: -334.04951, mean: -0.17043
[32m[0907 03-56-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31493, current rewards: -330.13520, mean: -0.16425
[32m[0907 03-56-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31491, current rewards: -326.22368, mean: -0.15836
[32m[0907 03-56-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31489, current rewards: -322.31140, mean: -0.15275
[32m[0907 03-57-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31486, current rewards: -318.40023, mean: -0.14741
[32m[0907 03-57-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31483, current rewards: -314.48703, mean: -0.14230
[32m[0907 03-57-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31473, current rewards: -344.04115, mean: -0.15223
[32m[0907 03-57-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31457, current rewards: -347.38680, mean: -0.15038
[32m[0907 03-58-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31442, current rewards: -346.10349, mean: -0.14665
[32m[0907 03-58-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31428, current rewards: -345.31118, mean: -0.14328
[32m[0907 03-58-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31398, current rewards: -341.63685, mean: -0.13888
[32m[0907 03-58-54 @Agent.py:117][0m Average action selection time: 0.3137
[32m[0907 03-58-54 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-58-54 @MBExp.py:227][0m Rewards obtained: [-338.6366830669373], Lows: [70], Highs: [391], Total time: 48246.532967000014
[32m[0907 04-00-41 @MBExp.py:144][0m ####################################################################
[32m[0907 04-00-41 @MBExp.py:145][0m Starting training iteration 59.
[32m[0907 04-00-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30957, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-01-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31973, current rewards: -58.95946, mean: -0.98266
[32m[0907 04-01-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31474, current rewards: -108.95946, mean: -0.99054
[32m[0907 04-01-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31310, current rewards: -158.95946, mean: -0.99350
[32m[0907 04-01-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31200, current rewards: -208.95946, mean: -0.99505
[32m[0907 04-02-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31153, current rewards: -258.95946, mean: -0.99600
[32m[0907 04-02-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31098, current rewards: -308.95946, mean: -0.99664
[32m[0907 04-02-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31071, current rewards: -358.95946, mean: -0.99711
[32m[0907 04-02-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31047, current rewards: -408.95946, mean: -0.99746
[32m[0907 04-03-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31089, current rewards: -458.95946, mean: -0.99774
[32m[0907 04-03-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31140, current rewards: -508.95946, mean: -0.99796
[32m[0907 04-03-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31180, current rewards: -558.95946, mean: -0.99814
[32m[0907 04-03-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31208, current rewards: -608.95946, mean: -0.99829
[32m[0907 04-04-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31236, current rewards: -658.95946, mean: -0.99842
[32m[0907 04-04-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31258, current rewards: -708.95946, mean: -0.99853
[32m[0907 04-04-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31272, current rewards: -758.95946, mean: -0.99863
[32m[0907 04-04-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31289, current rewards: -797.17170, mean: -0.98416
[32m[0907 04-05-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31300, current rewards: -793.59096, mean: -0.92278
[32m[0907 04-05-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31312, current rewards: -790.01022, mean: -0.86814
[32m[0907 04-05-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31320, current rewards: -786.42948, mean: -0.81920
[32m[0907 04-05-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31322, current rewards: -823.70711, mean: -0.81555
[32m[0907 04-06-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31334, current rewards: -873.70711, mean: -0.82425
[32m[0907 04-06-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31346, current rewards: -923.70711, mean: -0.83217
[32m[0907 04-06-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31353, current rewards: -973.70711, mean: -0.83940
[32m[0907 04-07-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31353, current rewards: -1023.70711, mean: -0.84604
[32m[0907 04-07-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31357, current rewards: -1073.70711, mean: -0.85215
[32m[0907 04-07-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31360, current rewards: -1123.70711, mean: -0.85779
[32m[0907 04-07-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31363, current rewards: -1173.70711, mean: -0.86302
[32m[0907 04-08-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31365, current rewards: -1223.70711, mean: -0.86788
[32m[0907 04-08-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31369, current rewards: -1273.70711, mean: -0.87240
[32m[0907 04-08-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31370, current rewards: -1323.70711, mean: -0.87663
[32m[0907 04-08-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31374, current rewards: -1373.70711, mean: -0.88058
[32m[0907 04-09-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31375, current rewards: -1423.70711, mean: -0.88429
[32m[0907 04-09-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31377, current rewards: -1473.70711, mean: -0.88778
[32m[0907 04-09-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31380, current rewards: -1523.70711, mean: -0.89106
[32m[0907 04-09-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31380, current rewards: -1573.70711, mean: -0.89415
[32m[0907 04-10-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31383, current rewards: -1623.70711, mean: -0.89708
[32m[0907 04-10-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31383, current rewards: -1673.70711, mean: -0.89984
[32m[0907 04-10-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31385, current rewards: -1723.70711, mean: -0.90246
[32m[0907 04-10-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31387, current rewards: -1773.70711, mean: -0.90495
[32m[0907 04-11-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31389, current rewards: -1823.70711, mean: -0.90732
[32m[0907 04-11-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31388, current rewards: -1873.70711, mean: -0.90957
[32m[0907 04-11-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31391, current rewards: -1923.70711, mean: -0.91171
[32m[0907 04-12-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31394, current rewards: -1973.70711, mean: -0.91375
[32m[0907 04-12-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31397, current rewards: -2023.70711, mean: -0.91570
[32m[0907 04-12-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31388, current rewards: -2073.70711, mean: -0.91757
[32m[0907 04-12-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31376, current rewards: -2123.70711, mean: -0.91935
[32m[0907 04-13-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31364, current rewards: -2134.07120, mean: -0.90427
[32m[0907 04-13-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31351, current rewards: -2129.02133, mean: -0.88341
[32m[0907 04-13-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31323, current rewards: -2123.97145, mean: -0.86340
[32m[0907 04-13-44 @Agent.py:117][0m Average action selection time: 0.3130
[32m[0907 04-13-44 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-13-44 @MBExp.py:227][0m Rewards obtained: [-2119.9315498310316], Lows: [11], Highs: [2131], Total time: 49029.70234400001
[32m[0907 04-15-34 @MBExp.py:144][0m ####################################################################
[32m[0907 04-15-34 @MBExp.py:145][0m Starting training iteration 60.
[32m[0907 04-15-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30958, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-15-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31211, current rewards: -35.25466, mean: -0.58758
[32m[0907 04-16-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31100, current rewards: -30.42227, mean: -0.27657
[32m[0907 04-16-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31045, current rewards: -24.89981, mean: -0.15562
[32m[0907 04-16-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31020, current rewards: -18.73052, mean: -0.08919
[32m[0907 04-16-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31003, current rewards: -12.56207, mean: -0.04832
[32m[0907 04-17-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30984, current rewards: -6.39040, mean: -0.02061
[32m[0907 04-17-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30969, current rewards: -0.22248, mean: -0.00062
[32m[0907 04-17-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30962, current rewards: 5.94665, mean: 0.01450
[32m[0907 04-17-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31019, current rewards: 12.11600, mean: 0.02634
[32m[0907 04-18-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31087, current rewards: 18.28344, mean: 0.03585
[32m[0907 04-18-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31166, current rewards: -38.36924, mean: -0.06852
[32m[0907 04-18-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31208, current rewards: -76.54685, mean: -0.12549
[32m[0907 04-19-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31244, current rewards: -134.50124, mean: -0.20379
[32m[0907 04-19-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31276, current rewards: -208.57508, mean: -0.29377
[32m[0907 04-19-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31297, current rewards: -280.18046, mean: -0.36866
[32m[0907 04-19-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31317, current rewards: -351.70948, mean: -0.43421
[32m[0907 04-20-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31332, current rewards: -425.68528, mean: -0.49498
[32m[0907 04-20-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31343, current rewards: -494.91136, mean: -0.54386
[32m[0907 04-20-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31353, current rewards: -540.49331, mean: -0.56301
[32m[0907 04-20-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31366, current rewards: -628.49331, mean: -0.62227
[32m[0907 04-21-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31374, current rewards: -728.49331, mean: -0.68726
[32m[0907 04-21-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31381, current rewards: -828.49331, mean: -0.74639
[32m[0907 04-21-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31383, current rewards: -928.49331, mean: -0.80043
[32m[0907 04-21-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31387, current rewards: -1028.49331, mean: -0.84999
[32m[0907 04-22-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31395, current rewards: -1128.49331, mean: -0.89563
[32m[0907 04-22-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31400, current rewards: -1228.49331, mean: -0.93778
[32m[0907 04-22-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31406, current rewards: -1328.49331, mean: -0.97683
[32m[0907 04-22-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31409, current rewards: -1428.49331, mean: -1.01312
[32m[0907 04-23-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31413, current rewards: -1528.49331, mean: -1.04691
[32m[0907 04-23-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31415, current rewards: -1628.49331, mean: -1.07847
[32m[0907 04-23-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31419, current rewards: -1728.49331, mean: -1.10801
[32m[0907 04-24-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31420, current rewards: -1828.49331, mean: -1.13571
[32m[0907 04-24-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31422, current rewards: -1928.49331, mean: -1.16174
[32m[0907 04-24-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31426, current rewards: -2028.49331, mean: -1.18625
[32m[0907 04-24-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31426, current rewards: -2128.49331, mean: -1.20937
[32m[0907 04-25-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31431, current rewards: -2228.49331, mean: -1.23121
[32m[0907 04-25-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31432, current rewards: -2328.49331, mean: -1.25188
[32m[0907 04-25-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31434, current rewards: -2428.49331, mean: -1.27146
[32m[0907 04-25-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31434, current rewards: -2528.49331, mean: -1.29005
[32m[0907 04-26-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31435, current rewards: -2628.49331, mean: -1.30771
[32m[0907 04-26-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31437, current rewards: -2728.49331, mean: -1.32451
[32m[0907 04-26-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31438, current rewards: -2828.49331, mean: -1.34052
[32m[0907 04-26-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31439, current rewards: -2928.49331, mean: -1.35578
[32m[0907 04-27-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31440, current rewards: -3028.49331, mean: -1.37036
[32m[0907 04-27-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31428, current rewards: -3128.49331, mean: -1.38429
[32m[0907 04-27-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31413, current rewards: -3228.49331, mean: -1.39762
[32m[0907 04-27-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31400, current rewards: -3328.49331, mean: -1.41038
[32m[0907 04-28-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31387, current rewards: -3428.49331, mean: -1.42261
[32m[0907 04-28-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31360, current rewards: -3528.49331, mean: -1.43435
[32m[0907 04-28-38 @Agent.py:117][0m Average action selection time: 0.3134
[32m[0907 04-28-38 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-28-38 @MBExp.py:227][0m Rewards obtained: [-3608.49331254592], Lows: [1830], Highs: [57], Total time: 49813.765455000015
[32m[0907 04-30-29 @MBExp.py:144][0m ####################################################################
[32m[0907 04-30-29 @MBExp.py:145][0m Starting training iteration 61.
[32m[0907 04-30-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30800, current rewards: 1.57817, mean: 0.15782
[32m[0907 04-30-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32506, current rewards: -40.27745, mean: -0.67129
[32m[0907 04-31-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32154, current rewards: -119.16545, mean: -1.08332
[32m[0907 04-31-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33110, current rewards: -190.82695, mean: -1.19267
[32m[0907 04-31-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32822, current rewards: -249.89761, mean: -1.18999
[32m[0907 04-31-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32880, current rewards: -336.67600, mean: -1.29491
[32m[0907 04-32-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32548, current rewards: -362.31341, mean: -1.16875
[32m[0907 04-32-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32305, current rewards: -354.60676, mean: -0.98502
[32m[0907 04-32-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32146, current rewards: -391.45867, mean: -0.95478
[32m[0907 04-32-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32169, current rewards: -441.91991, mean: -0.96070
[32m[0907 04-33-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32150, current rewards: -494.54286, mean: -0.96969
[32m[0907 04-33-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32104, current rewards: -549.31137, mean: -0.98091
[32m[0907 04-33-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32062, current rewards: -596.25352, mean: -0.97746
[32m[0907 04-34-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32067, current rewards: -672.37647, mean: -1.01875
[32m[0907 04-34-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32065, current rewards: -716.75401, mean: -1.00951
[32m[0907 04-34-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32034, current rewards: -713.17903, mean: -0.93839
[32m[0907 04-34-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32201, current rewards: -752.78141, mean: -0.92936
[32m[0907 04-35-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32283, current rewards: -779.23331, mean: -0.90609
[32m[0907 04-35-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32568, current rewards: -827.21580, mean: -0.90903
[32m[0907 04-35-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32882, current rewards: -894.95353, mean: -0.93224
[32m[0907 04-36-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32924, current rewards: -932.41477, mean: -0.92318
[32m[0907 04-36-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33075, current rewards: -998.54505, mean: -0.94202
[32m[0907 04-36-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33059, current rewards: -1016.03353, mean: -0.91535
[32m[0907 04-36-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33232, current rewards: -1073.74067, mean: -0.92564
[32m[0907 04-37-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33429, current rewards: -1149.61308, mean: -0.95009
[32m[0907 04-37-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33449, current rewards: -1208.89645, mean: -0.95944
[32m[0907 04-37-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33371, current rewards: -1297.85827, mean: -0.99073
[32m[0907 04-38-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33300, current rewards: -1397.85827, mean: -1.02784
[32m[0907 04-38-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33234, current rewards: -1497.85827, mean: -1.06231
[32m[0907 04-38-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33168, current rewards: -1597.85827, mean: -1.09442
[32m[0907 04-38-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33109, current rewards: -1697.85827, mean: -1.12441
[32m[0907 04-39-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33055, current rewards: -1797.85827, mean: -1.15247
[32m[0907 04-39-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33003, current rewards: -1897.85827, mean: -1.17879
[32m[0907 04-39-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32955, current rewards: -1997.85827, mean: -1.20353
[32m[0907 04-39-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32909, current rewards: -2097.85827, mean: -1.22682
[32m[0907 04-40-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32865, current rewards: -2197.85827, mean: -1.24878
[32m[0907 04-40-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32825, current rewards: -2297.85827, mean: -1.26953
[32m[0907 04-40-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32788, current rewards: -2397.85827, mean: -1.28917
[32m[0907 04-40-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32750, current rewards: -2497.85827, mean: -1.30778
[32m[0907 04-41-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32714, current rewards: -2597.85827, mean: -1.32544
[32m[0907 04-41-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32680, current rewards: -2697.85827, mean: -1.34222
[32m[0907 04-41-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32647, current rewards: -2797.85827, mean: -1.35818
[32m[0907 04-41-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32615, current rewards: -2897.85827, mean: -1.37339
[32m[0907 04-42-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32578, current rewards: -2997.85827, mean: -1.38790
[32m[0907 04-42-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32536, current rewards: -3097.85827, mean: -1.40175
[32m[0907 04-42-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32498, current rewards: -3197.85827, mean: -1.41498
[32m[0907 04-43-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32461, current rewards: -3297.85827, mean: -1.42764
[32m[0907 04-43-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32418, current rewards: -3397.85827, mean: -1.43977
[32m[0907 04-43-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32364, current rewards: -3497.85827, mean: -1.45139
[32m[0907 04-43-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32307, current rewards: -3597.85827, mean: -1.46254
[32m[0907 04-43-56 @Agent.py:117][0m Average action selection time: 0.3225
[32m[0907 04-43-56 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-43-56 @MBExp.py:227][0m Rewards obtained: [-3677.8582730397347], Lows: [1876], Highs: [46], Total time: 50620.772868000015
[32m[0907 04-45-50 @MBExp.py:144][0m ####################################################################
[32m[0907 04-45-50 @MBExp.py:145][0m Starting training iteration 62.
[32m[0907 04-45-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.51412, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-46-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.39736, current rewards: -65.70037, mean: -1.09501
[32m[0907 04-46-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35724, current rewards: -140.45053, mean: -1.27682
[32m[0907 04-46-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34220, current rewards: -240.45053, mean: -1.50282
[32m[0907 04-47-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33447, current rewards: -340.45053, mean: -1.62119
[32m[0907 04-47-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32955, current rewards: -440.45053, mean: -1.69404
[32m[0907 04-47-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32621, current rewards: -540.45053, mean: -1.74339
[32m[0907 04-47-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32475, current rewards: -640.45053, mean: -1.77903
[32m[0907 04-48-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32373, current rewards: -740.45053, mean: -1.80598
[32m[0907 04-48-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32292, current rewards: -840.45053, mean: -1.82707
[32m[0907 04-48-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32230, current rewards: -940.45053, mean: -1.84402
[32m[0907 04-48-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32172, current rewards: -1040.45053, mean: -1.85795
[32m[0907 04-49-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32123, current rewards: -1140.45053, mean: -1.86959
[32m[0907 04-49-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32068, current rewards: -1240.45053, mean: -1.87947
[32m[0907 04-49-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32030, current rewards: -1340.45053, mean: -1.88796
[32m[0907 04-49-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31998, current rewards: -1440.45053, mean: -1.89533
[32m[0907 04-50-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31974, current rewards: -1540.45053, mean: -1.90179
[32m[0907 04-50-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31951, current rewards: -1640.45053, mean: -1.90750
[32m[0907 04-50-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31931, current rewards: -1740.45053, mean: -1.91258
[32m[0907 04-50-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31908, current rewards: -1840.45053, mean: -1.91714
[32m[0907 04-51-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31886, current rewards: -1940.45053, mean: -1.92124
[32m[0907 04-51-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31869, current rewards: -2040.45053, mean: -1.92495
[32m[0907 04-51-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31854, current rewards: -2140.45053, mean: -1.92833
[32m[0907 04-52-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31834, current rewards: -2240.45053, mean: -1.93142
[32m[0907 04-52-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31816, current rewards: -2340.45053, mean: -1.93426
[32m[0907 04-52-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31799, current rewards: -2440.45053, mean: -1.93687
[32m[0907 04-52-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31787, current rewards: -2540.45053, mean: -1.93928
[32m[0907 04-53-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31771, current rewards: -2640.45053, mean: -1.94151
[32m[0907 04-53-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31760, current rewards: -2740.45053, mean: -1.94358
[32m[0907 04-53-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31750, current rewards: -2840.45053, mean: -1.94551
[32m[0907 04-53-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31739, current rewards: -2940.45053, mean: -1.94732
[32m[0907 04-54-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31731, current rewards: -3040.45053, mean: -1.94901
[32m[0907 04-54-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31723, current rewards: -3140.45053, mean: -1.95059
[32m[0907 04-54-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31712, current rewards: -3240.45053, mean: -1.95208
[32m[0907 04-54-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31704, current rewards: -3340.45053, mean: -1.95348
[32m[0907 04-55-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31697, current rewards: -3440.45053, mean: -1.95480
[32m[0907 04-55-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31694, current rewards: -3540.45053, mean: -1.95605
[32m[0907 04-55-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31686, current rewards: -3640.45053, mean: -1.95723
[32m[0907 04-55-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31681, current rewards: -3740.45053, mean: -1.95835
[32m[0907 04-56-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31676, current rewards: -3840.45053, mean: -1.95941
[32m[0907 04-56-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31669, current rewards: -3940.45053, mean: -1.96042
[32m[0907 04-56-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31667, current rewards: -4040.45053, mean: -1.96138
[32m[0907 04-56-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31661, current rewards: -4140.45053, mean: -1.96230
[32m[0907 04-57-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31645, current rewards: -4240.45053, mean: -1.96317
[32m[0907 04-57-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31623, current rewards: -4340.45053, mean: -1.96400
[32m[0907 04-57-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31605, current rewards: -4440.45053, mean: -1.96480
[32m[0907 04-58-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31587, current rewards: -4540.45053, mean: -1.96556
[32m[0907 04-58-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31554, current rewards: -4640.45053, mean: -1.96629
[32m[0907 04-58-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31519, current rewards: -4740.45053, mean: -1.96699
[32m[0907 04-58-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31474, current rewards: -4840.45053, mean: -1.96766
[32m[0907 04-58-56 @Agent.py:117][0m Average action selection time: 0.3144
[32m[0907 04-58-56 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-58-57 @MBExp.py:227][0m Rewards obtained: [-4920.450532382625], Lows: [2449], Highs: [27], Total time: 51407.29841600001
[32m[0907 05-00-52 @MBExp.py:144][0m ####################################################################
[32m[0907 05-00-52 @MBExp.py:145][0m Starting training iteration 63.
[32m[0907 05-00-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.51312, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-01-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37381, current rewards: -70.67998, mean: -1.17800
[32m[0907 05-01-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34423, current rewards: -167.83481, mean: -1.52577
[32m[0907 05-01-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33307, current rewards: -226.18229, mean: -1.41364
[32m[0907 05-02-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32821, current rewards: -305.02294, mean: -1.45249
[32m[0907 05-02-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32510, current rewards: -317.09923, mean: -1.21961
[32m[0907 05-02-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32661, current rewards: -372.66110, mean: -1.20213
[32m[0907 05-02-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32700, current rewards: -439.78437, mean: -1.22162
[32m[0907 05-03-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32648, current rewards: -516.96922, mean: -1.26090
[32m[0907 05-03-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32523, current rewards: -592.92568, mean: -1.28897
[32m[0907 05-03-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32431, current rewards: -649.44485, mean: -1.27342
[32m[0907 05-03-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32464, current rewards: -687.46182, mean: -1.22761
[32m[0907 05-04-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32509, current rewards: -694.71854, mean: -1.13888
[32m[0907 05-04-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32427, current rewards: -745.33012, mean: -1.12929
[32m[0907 05-04-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32369, current rewards: -845.33012, mean: -1.19061
[32m[0907 05-04-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32316, current rewards: -945.33012, mean: -1.24386
[32m[0907 05-05-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32273, current rewards: -1045.33012, mean: -1.29053
[32m[0907 05-05-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32233, current rewards: -1145.33012, mean: -1.33178
[32m[0907 05-05-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32193, current rewards: -1245.33012, mean: -1.36849
[32m[0907 05-06-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32158, current rewards: -1345.33012, mean: -1.40139
[32m[0907 05-06-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32126, current rewards: -1445.33012, mean: -1.43102
[32m[0907 05-06-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32090, current rewards: -1545.33012, mean: -1.45786
[32m[0907 05-06-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32063, current rewards: -1645.33012, mean: -1.48228
[32m[0907 05-07-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32042, current rewards: -1745.33012, mean: -1.50459
[32m[0907 05-07-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32020, current rewards: -1845.33012, mean: -1.52507
[32m[0907 05-07-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31999, current rewards: -1912.59834, mean: -1.51794
[32m[0907 05-07-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32266, current rewards: -1959.82460, mean: -1.49605
[32m[0907 05-08-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32434, current rewards: -2032.25392, mean: -1.49430
[32m[0907 05-08-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32447, current rewards: -2125.00307, mean: -1.50709
[32m[0907 05-08-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32490, current rewards: -2212.76185, mean: -1.51559
[32m[0907 05-09-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32503, current rewards: -2305.13023, mean: -1.52658
[32m[0907 05-09-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32538, current rewards: -2391.06980, mean: -1.53274
[32m[0907 05-09-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32573, current rewards: -2476.25412, mean: -1.53805
[32m[0907 05-09-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32538, current rewards: -2535.10471, mean: -1.52717
[32m[0907 05-10-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32541, current rewards: -2618.48795, mean: -1.53128
[32m[0907 05-10-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32529, current rewards: -2696.33310, mean: -1.53201
[32m[0907 05-10-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32505, current rewards: -2760.91889, mean: -1.52537
[32m[0907 05-10-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32477, current rewards: -2810.06952, mean: -1.51079
[32m[0907 05-11-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32462, current rewards: -2870.11664, mean: -1.50268
[32m[0907 05-11-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32506, current rewards: -2921.56628, mean: -1.49060
[32m[0907 05-11-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32481, current rewards: -2942.15228, mean: -1.46376
[32m[0907 05-12-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32466, current rewards: -2946.50996, mean: -1.43034
[32m[0907 05-12-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32439, current rewards: -2946.25075, mean: -1.39633
[32m[0907 05-12-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32409, current rewards: -2943.91186, mean: -1.36292
[32m[0907 05-12-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32374, current rewards: -2940.62208, mean: -1.33060
[32m[0907 05-13-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32339, current rewards: -2937.31292, mean: -1.29970
[32m[0907 05-13-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32287, current rewards: -2934.02201, mean: -1.27014
[32m[0907 05-13-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32236, current rewards: -2930.72049, mean: -1.24183
[32m[0907 05-13-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32171, current rewards: -2927.42286, mean: -1.21470
[32m[0907 05-14-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32107, current rewards: -2924.12728, mean: -1.18867
[32m[0907 05-14-14 @Agent.py:117][0m Average action selection time: 0.3207
[32m[0907 05-14-14 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-14-14 @MBExp.py:227][0m Rewards obtained: [-2921.4893410419463], Lows: [1506], Highs: [49], Total time: 52209.77369100001
[32m[0907 05-16-12 @MBExp.py:144][0m ####################################################################
[32m[0907 05-16-12 @MBExp.py:145][0m Starting training iteration 64.
[32m[0907 05-16-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49252, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-16-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.40750, current rewards: -68.50589, mean: -1.14176
[32m[0907 05-16-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36276, current rewards: -168.50589, mean: -1.53187
[32m[0907 05-17-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34580, current rewards: -266.22783, mean: -1.66392
[32m[0907 05-17-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33688, current rewards: -366.22783, mean: -1.74394
[32m[0907 05-17-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33230, current rewards: -466.22783, mean: -1.79318
[32m[0907 05-17-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32966, current rewards: -566.22783, mean: -1.82654
[32m[0907 05-18-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32772, current rewards: -666.22783, mean: -1.85063
[32m[0907 05-18-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32635, current rewards: -766.22783, mean: -1.86885
[32m[0907 05-18-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32525, current rewards: -866.22783, mean: -1.88310
[32m[0907 05-18-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32434, current rewards: -966.22783, mean: -1.89456
[32m[0907 05-19-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32359, current rewards: -1066.22783, mean: -1.90398
[32m[0907 05-19-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32299, current rewards: -1166.22783, mean: -1.91185
[32m[0907 05-19-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32251, current rewards: -1266.22783, mean: -1.91853
[32m[0907 05-20-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32204, current rewards: -1366.22783, mean: -1.92426
[32m[0907 05-20-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32168, current rewards: -1466.22783, mean: -1.92925
[32m[0907 05-20-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32134, current rewards: -1566.22783, mean: -1.93361
[32m[0907 05-20-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32100, current rewards: -1666.22783, mean: -1.93747
[32m[0907 05-21-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32070, current rewards: -1766.22783, mean: -1.94091
[32m[0907 05-21-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32044, current rewards: -1866.22783, mean: -1.94399
[32m[0907 05-21-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32019, current rewards: -1966.22783, mean: -1.94676
[32m[0907 05-21-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31999, current rewards: -2066.22783, mean: -1.94927
[32m[0907 05-22-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31978, current rewards: -2166.22783, mean: -1.95156
[32m[0907 05-22-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31960, current rewards: -2266.22783, mean: -1.95364
[32m[0907 05-22-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31944, current rewards: -2366.22783, mean: -1.95556
[32m[0907 05-22-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31930, current rewards: -2466.22783, mean: -1.95732
[32m[0907 05-23-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31919, current rewards: -2566.22783, mean: -1.95895
[32m[0907 05-23-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31902, current rewards: -2666.22783, mean: -1.96046
[32m[0907 05-23-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31894, current rewards: -2766.22783, mean: -1.96186
[32m[0907 05-23-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31881, current rewards: -2866.22783, mean: -1.96317
[32m[0907 05-24-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31866, current rewards: -2966.22783, mean: -1.96439
[32m[0907 05-24-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31854, current rewards: -3066.22783, mean: -1.96553
[32m[0907 05-24-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31841, current rewards: -3166.22783, mean: -1.96660
[32m[0907 05-25-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31829, current rewards: -3266.22783, mean: -1.96761
[32m[0907 05-25-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31817, current rewards: -3366.22783, mean: -1.96855
[32m[0907 05-25-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31804, current rewards: -3466.22783, mean: -1.96945
[32m[0907 05-25-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31800, current rewards: -3566.22783, mean: -1.97029
[32m[0907 05-26-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31793, current rewards: -3666.22783, mean: -1.97109
[32m[0907 05-26-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31785, current rewards: -3766.22783, mean: -1.97185
[32m[0907 05-26-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31778, current rewards: -3866.22783, mean: -1.97257
[32m[0907 05-26-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31770, current rewards: -3966.22783, mean: -1.97325
[32m[0907 05-27-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31755, current rewards: -4066.22783, mean: -1.97390
[32m[0907 05-27-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31733, current rewards: -4166.22783, mean: -1.97452
[32m[0907 05-27-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31712, current rewards: -4266.22783, mean: -1.97511
[32m[0907 05-27-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31693, current rewards: -4366.22783, mean: -1.97567
[32m[0907 05-28-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31667, current rewards: -4466.22783, mean: -1.97621
[32m[0907 05-28-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31629, current rewards: -4566.22783, mean: -1.97672
[32m[0907 05-28-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31586, current rewards: -4666.22783, mean: -1.97722
[32m[0907 05-28-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31536, current rewards: -4766.22783, mean: -1.97769
[32m[0907 05-29-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31491, current rewards: -4866.22783, mean: -1.97814
[32m[0907 05-29-19 @Agent.py:117][0m Average action selection time: 0.3147
[32m[0907 05-29-19 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-29-19 @MBExp.py:227][0m Rewards obtained: [-4946.227832125693], Lows: [2455], Highs: [37], Total time: 52997.10152800001
[32m[0907 05-31-18 @MBExp.py:144][0m ####################################################################
[32m[0907 05-31-18 @MBExp.py:145][0m Starting training iteration 65.
[32m[0907 05-31-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49324, current rewards: -2.63882, mean: -0.26388
[32m[0907 05-31-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.38923, current rewards: -50.98831, mean: -0.84981
[32m[0907 05-31-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35271, current rewards: -46.30391, mean: -0.42094
[32m[0907 05-32-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33891, current rewards: -39.85074, mean: -0.24907
[32m[0907 05-32-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33166, current rewards: -34.42486, mean: -0.16393
[32m[0907 05-32-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32864, current rewards: -28.99473, mean: -0.11152
[32m[0907 05-33-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32654, current rewards: -23.56519, mean: -0.07602
[32m[0907 05-33-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32488, current rewards: -34.76488, mean: -0.09657
[32m[0907 05-33-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32383, current rewards: -79.51936, mean: -0.19395
[32m[0907 05-33-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32301, current rewards: -110.17998, mean: -0.23952
[32m[0907 05-34-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32227, current rewards: -130.00789, mean: -0.25492
[32m[0907 05-34-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32165, current rewards: -154.30625, mean: -0.27555
[32m[0907 05-34-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32112, current rewards: -178.98902, mean: -0.29342
[32m[0907 05-34-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32075, current rewards: -201.02873, mean: -0.30459
[32m[0907 05-35-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32040, current rewards: -235.36026, mean: -0.33149
[32m[0907 05-35-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32009, current rewards: -259.55186, mean: -0.34152
[32m[0907 05-35-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31976, current rewards: -282.62880, mean: -0.34892
[32m[0907 05-35-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31949, current rewards: -343.70768, mean: -0.39966
[32m[0907 05-36-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31925, current rewards: -352.05055, mean: -0.38687
[32m[0907 05-36-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31903, current rewards: -346.56725, mean: -0.36101
[32m[0907 05-36-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31892, current rewards: -341.06415, mean: -0.33769
[32m[0907 05-36-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31875, current rewards: -335.55723, mean: -0.31656
[32m[0907 05-37-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31859, current rewards: -330.05217, mean: -0.29734
[32m[0907 05-37-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31840, current rewards: -324.54841, mean: -0.27978
[32m[0907 05-37-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31825, current rewards: -319.04177, mean: -0.26367
[32m[0907 05-38-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31812, current rewards: -313.53545, mean: -0.24884
[32m[0907 05-38-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31801, current rewards: -308.02835, mean: -0.23514
[32m[0907 05-38-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31789, current rewards: -301.25655, mean: -0.22151
[32m[0907 05-38-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31778, current rewards: -295.65597, mean: -0.20969
[32m[0907 05-39-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31766, current rewards: -314.42329, mean: -0.21536
[32m[0907 05-39-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31755, current rewards: -312.32765, mean: -0.20684
[32m[0907 05-39-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31744, current rewards: -314.92835, mean: -0.20188
[32m[0907 05-39-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31747, current rewards: -319.63883, mean: -0.19853
[32m[0907 05-40-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31743, current rewards: -320.32041, mean: -0.19296
[32m[0907 05-40-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31732, current rewards: -319.82217, mean: -0.18703
[32m[0907 05-40-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31730, current rewards: -325.24500, mean: -0.18480
[32m[0907 05-40-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31746, current rewards: -330.84248, mean: -0.18279
[32m[0907 05-41-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31740, current rewards: -341.80856, mean: -0.18377
[32m[0907 05-41-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31735, current rewards: -341.59767, mean: -0.17885
[32m[0907 05-41-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31727, current rewards: -343.44605, mean: -0.17523
[32m[0907 05-41-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31723, current rewards: -347.49251, mean: -0.17288
[32m[0907 05-42-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31706, current rewards: -349.67642, mean: -0.16975
[32m[0907 05-42-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31703, current rewards: -382.79125, mean: -0.18142
[32m[0907 05-42-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31684, current rewards: -414.85191, mean: -0.19206
[32m[0907 05-42-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31662, current rewards: -432.35350, mean: -0.19564
[32m[0907 05-43-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31631, current rewards: -436.00985, mean: -0.19292
[32m[0907 05-43-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31594, current rewards: -439.36389, mean: -0.19020
[32m[0907 05-43-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31544, current rewards: -440.62660, mean: -0.18671
[32m[0907 05-43-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31494, current rewards: -441.88924, mean: -0.18336
[32m[0907 05-44-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31454, current rewards: -460.78072, mean: -0.18731
[32m[0907 05-44-25 @Agent.py:117][0m Average action selection time: 0.3143
[32m[0907 05-44-25 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-44-25 @MBExp.py:227][0m Rewards obtained: [-480.374922166107], Lows: [250], Highs: [212], Total time: 53783.521201
[32m[0907 05-46-26 @MBExp.py:144][0m ####################################################################
[32m[0907 05-46-26 @MBExp.py:145][0m Starting training iteration 66.
[32m[0907 05-46-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32703, current rewards: 0.85604, mean: 0.08560
[32m[0907 05-46-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31178, current rewards: -71.81130, mean: -1.19686
[32m[0907 05-47-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30995, current rewards: -154.03611, mean: -1.40033
[32m[0907 05-47-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31258, current rewards: -247.32273, mean: -1.54577
[32m[0907 05-47-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31229, current rewards: -322.78389, mean: -1.53707
[32m[0907 05-47-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31440, current rewards: -393.01594, mean: -1.51160
[32m[0907 05-48-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31458, current rewards: -473.43509, mean: -1.52721
[32m[0907 05-48-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31481, current rewards: -566.65804, mean: -1.57405
[32m[0907 05-48-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31488, current rewards: -641.36306, mean: -1.56430
[32m[0907 05-48-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31491, current rewards: -741.36306, mean: -1.61166
[32m[0907 05-49-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31491, current rewards: -841.36306, mean: -1.64973
[32m[0907 05-49-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31502, current rewards: -941.36306, mean: -1.68101
[32m[0907 05-49-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31504, current rewards: -1041.36306, mean: -1.70715
[32m[0907 05-49-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31503, current rewards: -1141.36306, mean: -1.72934
[32m[0907 05-50-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31502, current rewards: -1241.36306, mean: -1.74840
[32m[0907 05-50-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31497, current rewards: -1341.36306, mean: -1.76495
[32m[0907 05-50-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31492, current rewards: -1441.36306, mean: -1.77946
[32m[0907 05-50-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31492, current rewards: -1541.36306, mean: -1.79228
[32m[0907 05-51-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31486, current rewards: -1641.36306, mean: -1.80370
[32m[0907 05-51-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31486, current rewards: -1741.36306, mean: -1.81392
[32m[0907 05-51-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31486, current rewards: -1841.36306, mean: -1.82313
[32m[0907 05-52-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31485, current rewards: -1941.36306, mean: -1.83147
[32m[0907 05-52-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31477, current rewards: -2041.36306, mean: -1.83907
[32m[0907 05-52-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31476, current rewards: -2141.36306, mean: -1.84600
[32m[0907 05-52-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31477, current rewards: -2241.36306, mean: -1.85237
[32m[0907 05-53-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31475, current rewards: -2341.36306, mean: -1.85822
[32m[0907 05-53-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31475, current rewards: -2441.36306, mean: -1.86364
[32m[0907 05-53-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31473, current rewards: -2541.36306, mean: -1.86865
[32m[0907 05-53-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31475, current rewards: -2641.36306, mean: -1.87331
[32m[0907 05-54-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31474, current rewards: -2741.36306, mean: -1.87765
[32m[0907 05-54-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31473, current rewards: -2841.36306, mean: -1.88170
[32m[0907 05-54-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31468, current rewards: -2941.36306, mean: -1.88549
[32m[0907 05-54-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31466, current rewards: -3041.36306, mean: -1.88905
[32m[0907 05-55-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31465, current rewards: -3141.36306, mean: -1.89239
[32m[0907 05-55-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31465, current rewards: -3241.36306, mean: -1.89553
[32m[0907 05-55-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31464, current rewards: -3341.36306, mean: -1.89850
[32m[0907 05-55-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31464, current rewards: -3441.36306, mean: -1.90131
[32m[0907 05-56-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31463, current rewards: -3541.36306, mean: -1.90396
[32m[0907 05-56-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31461, current rewards: -3641.36306, mean: -1.90647
[32m[0907 05-56-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31460, current rewards: -3741.36306, mean: -1.90886
[32m[0907 05-56-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31457, current rewards: -3841.36306, mean: -1.91113
[32m[0907 05-57-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31457, current rewards: -3941.36306, mean: -1.91328
[32m[0907 05-57-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31446, current rewards: -4041.36306, mean: -1.91534
[32m[0907 05-57-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31432, current rewards: -4141.36306, mean: -1.91730
[32m[0907 05-58-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31416, current rewards: -4241.36306, mean: -1.91917
[32m[0907 05-58-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31400, current rewards: -4341.36306, mean: -1.92096
[32m[0907 05-58-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31366, current rewards: -4441.36306, mean: -1.92267
[32m[0907 05-58-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31319, current rewards: -4541.36306, mean: -1.92431
[32m[0907 05-59-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31271, current rewards: -4641.36306, mean: -1.92588
[32m[0907 05-59-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31226, current rewards: -4741.36306, mean: -1.92738
[32m[0907 05-59-26 @Agent.py:117][0m Average action selection time: 0.3119
[32m[0907 05-59-26 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-59-26 @MBExp.py:227][0m Rewards obtained: [-4821.363057269357], Lows: [2411], Highs: [14], Total time: 54564.029129
[32m[0907 06-01-29 @MBExp.py:144][0m ####################################################################
[32m[0907 06-01-29 @MBExp.py:145][0m Starting training iteration 67.
[32m[0907 06-01-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.51660, current rewards: 1.20711, mean: 0.12071
[32m[0907 06-01-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37580, current rewards: -34.24905, mean: -0.57082
[32m[0907 06-02-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35204, current rewards: -46.93365, mean: -0.42667
[32m[0907 06-02-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33829, current rewards: -51.86082, mean: -0.32413
[32m[0907 06-02-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33472, current rewards: -65.91408, mean: -0.31388
[32m[0907 06-02-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33135, current rewards: -77.71881, mean: -0.29892
[32m[0907 06-03-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32984, current rewards: -81.12644, mean: -0.26170
[32m[0907 06-03-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32851, current rewards: -91.03897, mean: -0.25289
[32m[0907 06-03-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32782, current rewards: -103.47597, mean: -0.25238
[32m[0907 06-04-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32883, current rewards: -109.58545, mean: -0.23823
[32m[0907 06-04-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32920, current rewards: -111.87331, mean: -0.21936
[32m[0907 06-04-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33001, current rewards: -115.46434, mean: -0.20619
[32m[0907 06-04-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33000, current rewards: -144.14060, mean: -0.23630
[32m[0907 06-05-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32923, current rewards: -175.34657, mean: -0.26568
[32m[0907 06-05-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32831, current rewards: -210.61919, mean: -0.29665
[32m[0907 06-05-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32808, current rewards: -229.59757, mean: -0.30210
[32m[0907 06-05-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32751, current rewards: -265.71826, mean: -0.32805
[32m[0907 06-06-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32694, current rewards: -309.94810, mean: -0.36040
[32m[0907 06-06-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32629, current rewards: -366.80769, mean: -0.40309
[32m[0907 06-06-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32577, current rewards: -410.86648, mean: -0.42799
[32m[0907 06-06-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32524, current rewards: -441.52560, mean: -0.43715
[32m[0907 06-07-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32476, current rewards: -470.51040, mean: -0.44388
[32m[0907 06-07-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32431, current rewards: -495.22813, mean: -0.44615
[32m[0907 06-07-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32391, current rewards: -524.86932, mean: -0.45247
[32m[0907 06-08-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32355, current rewards: -551.16890, mean: -0.45551
[32m[0907 06-08-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32335, current rewards: -592.30962, mean: -0.47009
[32m[0907 06-08-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32321, current rewards: -619.78261, mean: -0.47312
[32m[0907 06-08-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32291, current rewards: -649.26461, mean: -0.47740
[32m[0907 06-09-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32276, current rewards: -675.45004, mean: -0.47904
[32m[0907 06-09-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32249, current rewards: -696.43330, mean: -0.47701
[32m[0907 06-09-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32227, current rewards: -722.99122, mean: -0.47880
[32m[0907 06-09-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32205, current rewards: -720.93661, mean: -0.46214
[32m[0907 06-10-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32185, current rewards: -714.77331, mean: -0.44396
[32m[0907 06-10-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32163, current rewards: -703.33229, mean: -0.42369
[32m[0907 06-10-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32141, current rewards: -692.83730, mean: -0.40517
[32m[0907 06-10-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32122, current rewards: -680.61754, mean: -0.38671
[32m[0907 06-11-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32104, current rewards: -687.31519, mean: -0.37973
[32m[0907 06-11-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32088, current rewards: -713.38020, mean: -0.38354
[32m[0907 06-11-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32072, current rewards: -702.47317, mean: -0.36779
[32m[0907 06-11-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32059, current rewards: -684.67244, mean: -0.34932
[32m[0907 06-12-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32041, current rewards: -668.00145, mean: -0.33234
[32m[0907 06-12-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32028, current rewards: -652.17808, mean: -0.31659
[32m[0907 06-12-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32001, current rewards: -636.29852, mean: -0.30156
[32m[0907 06-13-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31997, current rewards: -654.10343, mean: -0.30283
[32m[0907 06-13-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31988, current rewards: -684.70553, mean: -0.30982
[32m[0907 06-13-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31978, current rewards: -701.33482, mean: -0.31033
[32m[0907 06-13-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31947, current rewards: -724.01678, mean: -0.31343
[32m[0907 06-14-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31884, current rewards: -718.20863, mean: -0.30433
[32m[0907 06-14-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31826, current rewards: -710.43779, mean: -0.29479
[32m[0907 06-14-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31771, current rewards: -702.73448, mean: -0.28566
[32m[0907 06-14-43 @Agent.py:117][0m Average action selection time: 0.3173
[32m[0907 06-14-43 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-14-43 @MBExp.py:227][0m Rewards obtained: [-696.5665397312521], Lows: [273], Highs: [464], Total time: 55358.043515000005
[32m[0907 06-16-48 @MBExp.py:144][0m ####################################################################
[32m[0907 06-16-48 @MBExp.py:145][0m Starting training iteration 68.
[32m[0907 06-16-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30881, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-17-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30925, current rewards: -25.78599, mean: -0.42977
[32m[0907 06-17-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31011, current rewards: -27.97077, mean: -0.25428
[32m[0907 06-17-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30967, current rewards: -38.19817, mean: -0.23874
[32m[0907 06-17-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31101, current rewards: -45.15644, mean: -0.21503
[32m[0907 06-18-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31277, current rewards: -49.81967, mean: -0.19161
[32m[0907 06-18-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31323, current rewards: -57.16239, mean: -0.18439
[32m[0907 06-18-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31344, current rewards: -73.33483, mean: -0.20371
[32m[0907 06-18-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31359, current rewards: -98.36292, mean: -0.23991
[32m[0907 06-19-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31369, current rewards: -108.94364, mean: -0.23683
[32m[0907 06-19-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31377, current rewards: -104.10809, mean: -0.20413
[32m[0907 06-19-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31387, current rewards: -99.63345, mean: -0.17792
[32m[0907 06-20-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31404, current rewards: -94.23523, mean: -0.15448
[32m[0907 06-20-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31405, current rewards: -88.83641, mean: -0.13460
[32m[0907 06-20-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31411, current rewards: -83.43769, mean: -0.11752
[32m[0907 06-20-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31410, current rewards: -78.04333, mean: -0.10269
[32m[0907 06-21-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31413, current rewards: -72.64338, mean: -0.08968
[32m[0907 06-21-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31428, current rewards: -78.32375, mean: -0.09107
[32m[0907 06-21-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31493, current rewards: -93.99608, mean: -0.10329
[32m[0907 06-21-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31488, current rewards: -86.11848, mean: -0.08971
[32m[0907 06-22-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31487, current rewards: -79.55562, mean: -0.07877
[32m[0907 06-22-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31485, current rewards: -72.84398, mean: -0.06872
[32m[0907 06-22-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31483, current rewards: -66.17270, mean: -0.05962
[32m[0907 06-22-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31563, current rewards: -59.48124, mean: -0.05128
[32m[0907 06-23-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31714, current rewards: -97.79866, mean: -0.08083
[32m[0907 06-23-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31854, current rewards: -126.50296, mean: -0.10040
[32m[0907 06-23-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31985, current rewards: -176.50296, mean: -0.13474
[32m[0907 06-24-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32178, current rewards: -176.57118, mean: -0.12983
[32m[0907 06-24-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32290, current rewards: -173.36885, mean: -0.12296
[32m[0907 06-24-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32390, current rewards: -170.16652, mean: -0.11655
[32m[0907 06-24-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32484, current rewards: -166.96420, mean: -0.11057
[32m[0907 06-25-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32481, current rewards: -203.13159, mean: -0.13021
[32m[0907 06-25-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32449, current rewards: -253.13159, mean: -0.15722
[32m[0907 06-25-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32417, current rewards: -303.13159, mean: -0.18261
[32m[0907 06-26-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32388, current rewards: -353.13159, mean: -0.20651
[32m[0907 06-26-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32358, current rewards: -403.13159, mean: -0.22905
[32m[0907 06-26-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32331, current rewards: -453.13159, mean: -0.25035
[32m[0907 06-26-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32306, current rewards: -503.13159, mean: -0.27050
[32m[0907 06-27-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32281, current rewards: -553.13159, mean: -0.28960
[32m[0907 06-27-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32260, current rewards: -603.13159, mean: -0.30772
[32m[0907 06-27-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32239, current rewards: -653.13159, mean: -0.32494
[32m[0907 06-27-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32220, current rewards: -703.13159, mean: -0.34133
[32m[0907 06-28-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32187, current rewards: -753.13159, mean: -0.35693
[32m[0907 06-28-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32155, current rewards: -803.13159, mean: -0.37182
[32m[0907 06-28-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32124, current rewards: -853.13159, mean: -0.38603
[32m[0907 06-28-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32095, current rewards: -903.13159, mean: -0.39962
[32m[0907 06-29-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32051, current rewards: -953.13159, mean: -0.41261
[32m[0907 06-29-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32002, current rewards: -1003.13159, mean: -0.42506
[32m[0907 06-29-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31942, current rewards: -1053.13159, mean: -0.43698
[32m[0907 06-29-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31882, current rewards: -1103.13159, mean: -0.44843
[32m[0907 06-30-05 @Agent.py:117][0m Average action selection time: 0.3184
[32m[0907 06-30-05 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-30-05 @MBExp.py:227][0m Rewards obtained: [-1143.1315904282164], Lows: [49], Highs: [1172], Total time: 56154.719465
[32m[0907 06-32-11 @MBExp.py:144][0m ####################################################################
[32m[0907 06-32-11 @MBExp.py:145][0m Starting training iteration 69.
[32m[0907 06-32-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30823, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-32-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30865, current rewards: -18.16480, mean: -0.30275
[32m[0907 06-32-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30843, current rewards: -11.86380, mean: -0.10785
[32m[0907 06-33-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30857, current rewards: -5.90980, mean: -0.03694
[32m[0907 06-33-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31043, current rewards: 0.06443, mean: 0.00031
[32m[0907 06-33-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31165, current rewards: 6.03889, mean: 0.02323
[32m[0907 06-33-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31243, current rewards: 12.00815, mean: 0.03874
[32m[0907 06-34-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31298, current rewards: 17.98079, mean: 0.04995
[32m[0907 06-34-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31341, current rewards: 23.95376, mean: 0.05842
[32m[0907 06-34-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31373, current rewards: 4.71827, mean: 0.01026
[32m[0907 06-34-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31409, current rewards: -85.67418, mean: -0.16799
[32m[0907 06-35-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31416, current rewards: -181.48925, mean: -0.32409
[32m[0907 06-35-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31427, current rewards: -281.48925, mean: -0.46146
[32m[0907 06-35-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31450, current rewards: -381.48925, mean: -0.57801
[32m[0907 06-35-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31456, current rewards: -481.48925, mean: -0.67815
[32m[0907 06-36-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31478, current rewards: -581.48925, mean: -0.76512
[32m[0907 06-36-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31479, current rewards: -681.48925, mean: -0.84134
[32m[0907 06-36-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31479, current rewards: -781.48925, mean: -0.90871
[32m[0907 06-36-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31477, current rewards: -881.48925, mean: -0.96867
[32m[0907 06-37-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31477, current rewards: -981.48925, mean: -1.02238
[32m[0907 06-37-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31478, current rewards: -1081.48925, mean: -1.07078
[32m[0907 06-37-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31476, current rewards: -1181.48925, mean: -1.11461
[32m[0907 06-38-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31472, current rewards: -1238.93640, mean: -1.11616
[32m[0907 06-38-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31475, current rewards: -1229.01237, mean: -1.05949
[32m[0907 06-38-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31477, current rewards: -1218.80319, mean: -1.00728
[32m[0907 06-38-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31476, current rewards: -1211.00324, mean: -0.96111
[32m[0907 06-39-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31476, current rewards: -1236.30959, mean: -0.94375
[32m[0907 06-39-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31472, current rewards: -1251.41569, mean: -0.92016
[32m[0907 06-39-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31490, current rewards: -1307.97752, mean: -0.92764
[32m[0907 06-39-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31580, current rewards: -1389.57407, mean: -0.95176
[32m[0907 06-40-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31585, current rewards: -1456.81915, mean: -0.96478
[32m[0907 06-40-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31592, current rewards: -1535.33284, mean: -0.98419
[32m[0907 06-40-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31599, current rewards: -1620.85717, mean: -1.00674
[32m[0907 06-40-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31599, current rewards: -1694.35966, mean: -1.02070
[32m[0907 06-41-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31613, current rewards: -1774.44953, mean: -1.03769
[32m[0907 06-41-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31612, current rewards: -1852.32528, mean: -1.05246
[32m[0907 06-41-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31619, current rewards: -1926.30444, mean: -1.06426
[32m[0907 06-42-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31614, current rewards: -2026.30444, mean: -1.08941
[32m[0907 06-42-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31610, current rewards: -2126.30444, mean: -1.11325
[32m[0907 06-42-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31608, current rewards: -2226.30444, mean: -1.13587
[32m[0907 06-42-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31603, current rewards: -2326.30444, mean: -1.15737
[32m[0907 06-43-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31599, current rewards: -2426.30444, mean: -1.17782
[32m[0907 06-43-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31594, current rewards: -2526.30444, mean: -1.19730
[32m[0907 06-43-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31587, current rewards: -2626.30444, mean: -1.21588
[32m[0907 06-43-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31569, current rewards: -2726.30444, mean: -1.23362
[32m[0907 06-44-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31548, current rewards: -2826.30444, mean: -1.25058
[32m[0907 06-44-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31511, current rewards: -2926.30444, mean: -1.26680
[32m[0907 06-44-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31468, current rewards: -3026.30444, mean: -1.28233
[32m[0907 06-44-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31418, current rewards: -3126.30444, mean: -1.29722
[32m[0907 06-45-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31368, current rewards: -3226.30444, mean: -1.31151
[32m[0907 06-45-15 @Agent.py:117][0m Average action selection time: 0.3133
[32m[0907 06-45-15 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-45-15 @MBExp.py:227][0m Rewards obtained: [-3306.304436829867], Lows: [1686], Highs: [54], Total time: 56938.712112
[32m[0907 06-47-24 @MBExp.py:144][0m ####################################################################
[32m[0907 06-47-24 @MBExp.py:145][0m Starting training iteration 70.
[32m[0907 06-47-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30826, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-47-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30887, current rewards: -99.00000, mean: -1.65000
[32m[0907 06-47-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30859, current rewards: -199.00000, mean: -1.80909
[32m[0907 06-48-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30869, current rewards: -299.00000, mean: -1.86875
[32m[0907 06-48-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31070, current rewards: -399.00000, mean: -1.90000
[32m[0907 06-48-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31197, current rewards: -499.00000, mean: -1.91923
[32m[0907 06-49-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31275, current rewards: -599.00000, mean: -1.93226
[32m[0907 06-49-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31327, current rewards: -699.00000, mean: -1.94167
[32m[0907 06-49-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31348, current rewards: -799.00000, mean: -1.94878
[32m[0907 06-49-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31374, current rewards: -899.00000, mean: -1.95435
[32m[0907 06-50-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31402, current rewards: -999.00000, mean: -1.95882
[32m[0907 06-50-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31425, current rewards: -1099.00000, mean: -1.96250
[32m[0907 06-50-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31432, current rewards: -1199.00000, mean: -1.96557
[32m[0907 06-50-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31443, current rewards: -1299.00000, mean: -1.96818
[32m[0907 06-51-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31444, current rewards: -1399.00000, mean: -1.97042
[32m[0907 06-51-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31451, current rewards: -1499.00000, mean: -1.97237
[32m[0907 06-51-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31457, current rewards: -1599.00000, mean: -1.97407
[32m[0907 06-51-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31459, current rewards: -1699.00000, mean: -1.97558
[32m[0907 06-52-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31461, current rewards: -1799.00000, mean: -1.97692
[32m[0907 06-52-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31464, current rewards: -1899.00000, mean: -1.97812
[32m[0907 06-52-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31463, current rewards: -1999.00000, mean: -1.97921
[32m[0907 06-52-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31462, current rewards: -2099.00000, mean: -1.98019
[32m[0907 06-53-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31462, current rewards: -2199.00000, mean: -1.98108
[32m[0907 06-53-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31462, current rewards: -2299.00000, mean: -1.98190
[32m[0907 06-53-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31464, current rewards: -2399.00000, mean: -1.98264
[32m[0907 06-54-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31466, current rewards: -2499.00000, mean: -1.98333
[32m[0907 06-54-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31468, current rewards: -2599.00000, mean: -1.98397
[32m[0907 06-54-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31469, current rewards: -2699.00000, mean: -1.98456
[32m[0907 06-54-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31468, current rewards: -2799.00000, mean: -1.98511
[32m[0907 06-55-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31467, current rewards: -2899.00000, mean: -1.98562
[32m[0907 06-55-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31470, current rewards: -2999.00000, mean: -1.98609
[32m[0907 06-55-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31468, current rewards: -3099.00000, mean: -1.98654
[32m[0907 06-55-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31468, current rewards: -3199.00000, mean: -1.98696
[32m[0907 06-56-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31467, current rewards: -3299.00000, mean: -1.98735
[32m[0907 06-56-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31463, current rewards: -3399.00000, mean: -1.98772
[32m[0907 06-56-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31462, current rewards: -3499.00000, mean: -1.98807
[32m[0907 06-56-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31462, current rewards: -3599.00000, mean: -1.98840
[32m[0907 06-57-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31462, current rewards: -3699.00000, mean: -1.98871
[32m[0907 06-57-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31460, current rewards: -3799.00000, mean: -1.98901
[32m[0907 06-57-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31459, current rewards: -3899.00000, mean: -1.98929
[32m[0907 06-57-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31456, current rewards: -3999.00000, mean: -1.98955
[32m[0907 06-58-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31456, current rewards: -4099.00000, mean: -1.98981
[32m[0907 06-58-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31455, current rewards: -4199.00000, mean: -1.99005
[32m[0907 06-58-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31454, current rewards: -4299.00000, mean: -1.99028
[32m[0907 06-58-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31453, current rewards: -4399.00000, mean: -1.99050
[32m[0907 06-59-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31441, current rewards: -4499.00000, mean: -1.99071
[32m[0907 06-59-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31406, current rewards: -4599.00000, mean: -1.99091
[32m[0907 06-59-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31372, current rewards: -4699.00000, mean: -1.99110
[32m[0907 06-59-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31340, current rewards: -4799.00000, mean: -1.99129
[32m[0907 07-00-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31308, current rewards: -4899.00000, mean: -1.99146
[32m[0907 07-00-26 @Agent.py:117][0m Average action selection time: 0.3127
[32m[0907 07-00-26 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-00-26 @MBExp.py:227][0m Rewards obtained: [-4979], Lows: [2479], Highs: [21], Total time: 57721.21114
[32m[0907 07-02-36 @MBExp.py:144][0m ####################################################################
[32m[0907 07-02-36 @MBExp.py:145][0m Starting training iteration 71.
[32m[0907 07-02-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.51388, current rewards: -0.48947, mean: -0.04895
[32m[0907 07-03-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.39453, current rewards: -28.80588, mean: -0.48010
[32m[0907 07-03-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35552, current rewards: -23.30591, mean: -0.21187
[32m[0907 07-03-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34104, current rewards: -17.71444, mean: -0.11072
[32m[0907 07-03-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33511, current rewards: -12.12982, mean: -0.05776
[32m[0907 07-04-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33168, current rewards: -6.54261, mean: -0.02516
[32m[0907 07-04-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32925, current rewards: -0.95444, mean: -0.00308
[32m[0907 07-04-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32742, current rewards: 4.63207, mean: 0.01287
[32m[0907 07-04-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32902, current rewards: -60.50935, mean: -0.14758
[32m[0907 07-05-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32769, current rewards: -86.35130, mean: -0.18772
[32m[0907 07-05-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32660, current rewards: -81.84461, mean: -0.16048
[32m[0907 07-05-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32548, current rewards: -77.35137, mean: -0.13813
[32m[0907 07-05-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32453, current rewards: -72.85726, mean: -0.11944
[32m[0907 07-06-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32384, current rewards: -68.36258, mean: -0.10358
[32m[0907 07-06-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32328, current rewards: -63.87222, mean: -0.08996
[32m[0907 07-06-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32276, current rewards: -59.37889, mean: -0.07813
[32m[0907 07-06-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32229, current rewards: -54.88358, mean: -0.06776
[32m[0907 07-07-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32188, current rewards: -43.54644, mean: -0.05064
[32m[0907 07-07-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32160, current rewards: -38.16342, mean: -0.04194
[32m[0907 07-07-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32268, current rewards: -33.49007, mean: -0.03489
[32m[0907 07-08-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32453, current rewards: -94.64907, mean: -0.09371
[32m[0907 07-08-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32588, current rewards: -194.64907, mean: -0.18363
[32m[0907 07-08-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32709, current rewards: -294.64907, mean: -0.26545
[32m[0907 07-08-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32814, current rewards: -394.64907, mean: -0.34021
[32m[0907 07-09-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32917, current rewards: -494.64907, mean: -0.40880
[32m[0907 07-09-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33011, current rewards: -594.64907, mean: -0.47194
[32m[0907 07-09-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33098, current rewards: -694.64907, mean: -0.53027
[32m[0907 07-10-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33180, current rewards: -794.64907, mean: -0.58430
[32m[0907 07-10-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33249, current rewards: -894.64907, mean: -0.63450
[32m[0907 07-10-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33317, current rewards: -994.64907, mean: -0.68127
[32m[0907 07-11-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33380, current rewards: -1094.64907, mean: -0.72493
[32m[0907 07-11-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33441, current rewards: -1194.64907, mean: -0.76580
[32m[0907 07-11-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33498, current rewards: -1294.64907, mean: -0.80413
[32m[0907 07-11-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33553, current rewards: -1394.64907, mean: -0.84015
[32m[0907 07-12-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33603, current rewards: -1494.64907, mean: -0.87406
[32m[0907 07-12-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33650, current rewards: -1594.64907, mean: -0.90605
[32m[0907 07-12-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33696, current rewards: -1694.64907, mean: -0.93627
[32m[0907 07-13-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33737, current rewards: -1794.64907, mean: -0.96487
[32m[0907 07-13-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33777, current rewards: -1894.64907, mean: -0.99196
[32m[0907 07-13-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33818, current rewards: -1994.64907, mean: -1.01768
[32m[0907 07-13-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33855, current rewards: -2094.64907, mean: -1.04211
[32m[0907 07-14-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33826, current rewards: -2194.64907, mean: -1.06536
[32m[0907 07-14-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33772, current rewards: -2294.64907, mean: -1.08751
[32m[0907 07-14-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33721, current rewards: -2394.64907, mean: -1.10863
[32m[0907 07-15-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33671, current rewards: -2494.64907, mean: -1.12880
[32m[0907 07-15-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33615, current rewards: -2594.64907, mean: -1.14807
[32m[0907 07-15-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33552, current rewards: -2694.64907, mean: -1.16651
[32m[0907 07-15-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33493, current rewards: -2794.64907, mean: -1.18417
[32m[0907 07-16-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33431, current rewards: -2894.64907, mean: -1.20110
[32m[0907 07-16-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33351, current rewards: -2994.64907, mean: -1.21734
[32m[0907 07-16-29 @Agent.py:117][0m Average action selection time: 0.3328
[32m[0907 07-16-29 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-16-29 @MBExp.py:227][0m Rewards obtained: [-3074.64907367006], Lows: [1560], Highs: [55], Total time: 58554.013097999996
[32m[0907 07-18-40 @MBExp.py:144][0m ####################################################################
[32m[0907 07-18-40 @MBExp.py:145][0m Starting training iteration 72.
[32m[0907 07-18-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49420, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-19-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.41151, current rewards: -58.88657, mean: -0.98144
[32m[0907 07-19-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36559, current rewards: -80.30971, mean: -0.73009
[32m[0907 07-19-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35140, current rewards: -85.17877, mean: -0.53237
[32m[0907 07-19-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35203, current rewards: -100.20898, mean: -0.47719
[32m[0907 07-20-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34776, current rewards: -115.95794, mean: -0.44599
[32m[0907 07-20-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34278, current rewards: -139.31136, mean: -0.44939
[32m[0907 07-20-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33914, current rewards: -157.31688, mean: -0.43699
[32m[0907 07-20-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33640, current rewards: -171.27069, mean: -0.41773
[32m[0907 07-21-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33466, current rewards: -189.19697, mean: -0.41130
[32m[0907 07-21-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33342, current rewards: -205.01936, mean: -0.40200
[32m[0907 07-21-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33198, current rewards: -227.11314, mean: -0.40556
[32m[0907 07-22-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33091, current rewards: -256.83890, mean: -0.42105
[32m[0907 07-22-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32978, current rewards: -256.95791, mean: -0.38933
[32m[0907 07-22-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33054, current rewards: -271.62086, mean: -0.38256
[32m[0907 07-22-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32959, current rewards: -276.62488, mean: -0.36398
[32m[0907 07-23-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32922, current rewards: -277.79837, mean: -0.34296
[32m[0907 07-23-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32917, current rewards: -291.57507, mean: -0.33904
[32m[0907 07-23-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32848, current rewards: -289.26054, mean: -0.31787
[32m[0907 07-23-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32792, current rewards: -286.01973, mean: -0.29794
[32m[0907 07-24-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32732, current rewards: -282.98600, mean: -0.28018
[32m[0907 07-24-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32677, current rewards: -279.96237, mean: -0.26412
[32m[0907 07-24-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32649, current rewards: -289.30165, mean: -0.26063
[32m[0907 07-25-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32875, current rewards: -333.78189, mean: -0.28774
[32m[0907 07-25-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32820, current rewards: -330.67459, mean: -0.27328
[32m[0907 07-25-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32775, current rewards: -325.71074, mean: -0.25850
[32m[0907 07-25-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32782, current rewards: -331.77641, mean: -0.25326
[32m[0907 07-26-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32989, current rewards: -359.32158, mean: -0.26421
[32m[0907 07-26-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33042, current rewards: -434.89626, mean: -0.30844
[32m[0907 07-26-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33043, current rewards: -472.18692, mean: -0.32342
[32m[0907 07-27-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33099, current rewards: -529.38683, mean: -0.35059
[32m[0907 07-27-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33043, current rewards: -552.63297, mean: -0.35425
[32m[0907 07-27-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33015, current rewards: -567.20030, mean: -0.35230
[32m[0907 07-27-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33156, current rewards: -578.80484, mean: -0.34868
[32m[0907 07-28-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33114, current rewards: -632.23298, mean: -0.36973
[32m[0907 07-28-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33069, current rewards: -645.02017, mean: -0.36649
[32m[0907 07-28-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33044, current rewards: -651.06001, mean: -0.35970
[32m[0907 07-28-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33002, current rewards: -701.78091, mean: -0.37730
[32m[0907 07-29-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32976, current rewards: -710.44955, mean: -0.37196
[32m[0907 07-29-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32947, current rewards: -767.70319, mean: -0.39169
[32m[0907 07-29-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32915, current rewards: -779.23632, mean: -0.38768
[32m[0907 07-29-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32881, current rewards: -809.80234, mean: -0.39311
[32m[0907 07-30-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32851, current rewards: -803.75250, mean: -0.38093
[32m[0907 07-30-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32814, current rewards: -799.55781, mean: -0.37017
[32m[0907 07-30-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32770, current rewards: -794.88799, mean: -0.35968
[32m[0907 07-31-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32727, current rewards: -789.86206, mean: -0.34950
[32m[0907 07-31-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32684, current rewards: -784.39699, mean: -0.33957
[32m[0907 07-31-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32642, current rewards: -777.51010, mean: -0.32945
[32m[0907 07-31-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32575, current rewards: -764.88892, mean: -0.31738
[32m[0907 07-32-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32575, current rewards: -775.89814, mean: -0.31541
[32m[0907 07-32-14 @Agent.py:117][0m Average action selection time: 0.3254
[32m[0907 07-32-14 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-32-15 @MBExp.py:227][0m Rewards obtained: [-776.677010700759], Lows: [277], Highs: [442], Total time: 59368.26094199999
[32m[0907 07-34-28 @MBExp.py:144][0m ####################################################################
[32m[0907 07-34-28 @MBExp.py:145][0m Starting training iteration 73.
[32m[0907 07-34-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31699, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-34-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32509, current rewards: -83.18189, mean: -1.38636
[32m[0907 07-35-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33296, current rewards: -149.82427, mean: -1.36204
[32m[0907 07-35-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32901, current rewards: -215.70482, mean: -1.34816
[32m[0907 07-35-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33426, current rewards: -257.77889, mean: -1.22752
[32m[0907 07-35-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34082, current rewards: -311.76891, mean: -1.19911
[32m[0907 07-36-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34460, current rewards: -365.02983, mean: -1.17752
[32m[0907 07-36-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34622, current rewards: -402.54599, mean: -1.11818
[32m[0907 07-36-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34714, current rewards: -418.60742, mean: -1.02099
[32m[0907 07-37-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34593, current rewards: -461.90438, mean: -1.00414
[32m[0907 07-37-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34430, current rewards: -539.69018, mean: -1.05822
[32m[0907 07-37-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34182, current rewards: -632.62134, mean: -1.12968
[32m[0907 07-37-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33989, current rewards: -732.62134, mean: -1.20102
[32m[0907 07-38-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33805, current rewards: -832.62134, mean: -1.26155
[32m[0907 07-38-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33646, current rewards: -932.62134, mean: -1.31355
[32m[0907 07-38-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33510, current rewards: -1032.62134, mean: -1.35871
[32m[0907 07-38-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33391, current rewards: -1132.62134, mean: -1.39830
[32m[0907 07-39-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33282, current rewards: -1232.62134, mean: -1.43328
[32m[0907 07-39-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33193, current rewards: -1332.62134, mean: -1.46442
[32m[0907 07-39-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33102, current rewards: -1432.62134, mean: -1.49231
[32m[0907 07-40-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33033, current rewards: -1532.62134, mean: -1.51745
[32m[0907 07-40-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32962, current rewards: -1632.62134, mean: -1.54021
[32m[0907 07-40-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32898, current rewards: -1732.62134, mean: -1.56092
[32m[0907 07-40-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32837, current rewards: -1832.62134, mean: -1.57985
[32m[0907 07-41-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32783, current rewards: -1932.62134, mean: -1.59721
[32m[0907 07-41-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32736, current rewards: -2032.62134, mean: -1.61319
[32m[0907 07-41-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32689, current rewards: -2132.62134, mean: -1.62796
[32m[0907 07-41-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32646, current rewards: -2232.62134, mean: -1.64163
[32m[0907 07-42-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32604, current rewards: -2332.62134, mean: -1.65434
[32m[0907 07-42-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32564, current rewards: -2432.62134, mean: -1.66618
[32m[0907 07-42-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32529, current rewards: -2532.62134, mean: -1.67723
[32m[0907 07-42-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32497, current rewards: -2632.62134, mean: -1.68758
[32m[0907 07-43-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32467, current rewards: -2732.62134, mean: -1.69728
[32m[0907 07-43-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32438, current rewards: -2832.62134, mean: -1.70640
[32m[0907 07-43-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32411, current rewards: -2932.62134, mean: -1.71498
[32m[0907 07-43-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32385, current rewards: -3032.62134, mean: -1.72308
[32m[0907 07-44-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32358, current rewards: -3132.62134, mean: -1.73073
[32m[0907 07-44-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32335, current rewards: -3232.62134, mean: -1.73797
[32m[0907 07-44-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32313, current rewards: -3332.62134, mean: -1.74483
[32m[0907 07-45-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32291, current rewards: -3432.62134, mean: -1.75134
[32m[0907 07-45-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32270, current rewards: -3532.62134, mean: -1.75752
[32m[0907 07-45-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32254, current rewards: -3632.62134, mean: -1.76341
[32m[0907 07-45-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32232, current rewards: -3732.62134, mean: -1.76901
[32m[0907 07-46-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32200, current rewards: -3832.62134, mean: -1.77436
[32m[0907 07-46-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32167, current rewards: -3932.62134, mean: -1.77947
[32m[0907 07-46-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32136, current rewards: -4032.62134, mean: -1.78435
[32m[0907 07-46-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32107, current rewards: -4132.62134, mean: -1.78901
[32m[0907 07-47-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32080, current rewards: -4232.62134, mean: -1.79348
[32m[0907 07-47-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32044, current rewards: -4332.62134, mean: -1.79777
[32m[0907 07-47-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31983, current rewards: -4432.62134, mean: -1.80188
[32m[0907 07-47-47 @Agent.py:117][0m Average action selection time: 0.3194
[32m[0907 07-47-47 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-47-47 @MBExp.py:227][0m Rewards obtained: [-4512.621342391747], Lows: [2252], Highs: [44], Total time: 60167.358609999996
[32m[0907 07-50-03 @MBExp.py:144][0m ####################################################################
[32m[0907 07-50-03 @MBExp.py:145][0m Starting training iteration 74.
[32m[0907 07-50-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32821, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-50-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31288, current rewards: -33.74089, mean: -0.56235
[32m[0907 07-50-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31458, current rewards: -51.85853, mean: -0.47144
[32m[0907 07-50-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31617, current rewards: -66.41079, mean: -0.41507
[32m[0907 07-51-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31776, current rewards: -76.86959, mean: -0.36605
[32m[0907 07-51-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31955, current rewards: -88.43388, mean: -0.34013
[32m[0907 07-51-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31997, current rewards: -111.13042, mean: -0.35849
[32m[0907 07-51-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31930, current rewards: -136.54530, mean: -0.37929
[32m[0907 07-52-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31951, current rewards: -145.81800, mean: -0.35565
[32m[0907 07-52-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31913, current rewards: -148.88133, mean: -0.32366
[32m[0907 07-52-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31871, current rewards: -151.70459, mean: -0.29746
[32m[0907 07-53-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31877, current rewards: -159.52645, mean: -0.28487
[32m[0907 07-53-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31846, current rewards: -165.16322, mean: -0.27076
[32m[0907 07-53-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31824, current rewards: -166.36767, mean: -0.25207
[32m[0907 07-53-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31800, current rewards: -191.81016, mean: -0.27016
[32m[0907 07-54-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31801, current rewards: -255.22711, mean: -0.33583
[32m[0907 07-54-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31785, current rewards: -257.58020, mean: -0.31800
[32m[0907 07-54-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31838, current rewards: -273.88175, mean: -0.31847
[32m[0907 07-54-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31865, current rewards: -275.82164, mean: -0.30310
[32m[0907 07-55-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31849, current rewards: -326.79193, mean: -0.34041
[32m[0907 07-55-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32039, current rewards: -379.01987, mean: -0.37527
[32m[0907 07-55-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32012, current rewards: -418.71603, mean: -0.39502
[32m[0907 07-55-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32012, current rewards: -416.86642, mean: -0.37556
[32m[0907 07-56-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31987, current rewards: -413.50025, mean: -0.35647
[32m[0907 07-56-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31969, current rewards: -410.10042, mean: -0.33893
[32m[0907 07-56-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31947, current rewards: -405.92440, mean: -0.32216
[32m[0907 07-57-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31928, current rewards: -402.56411, mean: -0.30730
[32m[0907 07-57-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31929, current rewards: -399.06465, mean: -0.29343
[32m[0907 07-57-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32045, current rewards: -395.39108, mean: -0.28042
[32m[0907 07-57-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32152, current rewards: -391.98681, mean: -0.26848
[32m[0907 07-58-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32260, current rewards: -388.41452, mean: -0.25723
[32m[0907 07-58-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32413, current rewards: -384.83007, mean: -0.24669
[32m[0907 07-58-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32512, current rewards: -381.46062, mean: -0.23693
[32m[0907 07-59-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32628, current rewards: -415.35680, mean: -0.25021
[32m[0907 07-59-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32746, current rewards: -457.12605, mean: -0.26733
[32m[0907 07-59-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32816, current rewards: -506.38897, mean: -0.28772
[32m[0907 07-59-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32835, current rewards: -558.30491, mean: -0.30846
[32m[0907 08-00-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32810, current rewards: -594.42814, mean: -0.31959
[32m[0907 08-00-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32801, current rewards: -642.83287, mean: -0.33656
[32m[0907 08-00-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32808, current rewards: -688.07608, mean: -0.35106
[32m[0907 08-01-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32795, current rewards: -722.53425, mean: -0.35947
[32m[0907 08-01-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32772, current rewards: -763.59944, mean: -0.37068
[32m[0907 08-01-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32734, current rewards: -790.85084, mean: -0.37481
[32m[0907 08-01-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32698, current rewards: -816.03039, mean: -0.37779
[32m[0907 08-02-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32691, current rewards: -859.82309, mean: -0.38906
[32m[0907 08-02-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32674, current rewards: -903.64830, mean: -0.39984
[32m[0907 08-02-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32632, current rewards: -966.44759, mean: -0.41838
[32m[0907 08-02-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32590, current rewards: -993.40486, mean: -0.42093
[32m[0907 08-03-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32547, current rewards: -992.71190, mean: -0.41191
[32m[0907 08-03-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32485, current rewards: -985.80543, mean: -0.40073
[32m[0907 08-03-35 @Agent.py:117][0m Average action selection time: 0.3243
[32m[0907 08-03-35 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-03-35 @MBExp.py:227][0m Rewards obtained: [-968.5754005914156], Lows: [375], Highs: [433], Total time: 60978.842711
[32m[0907 08-05-52 @MBExp.py:144][0m ####################################################################
[32m[0907 08-05-52 @MBExp.py:145][0m Starting training iteration 75.
[32m[0907 08-05-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30644, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-06-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31118, current rewards: -41.56878, mean: -0.69281
[32m[0907 08-06-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31036, current rewards: -82.94222, mean: -0.75402
[32m[0907 08-06-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31226, current rewards: -101.33046, mean: -0.63332
[32m[0907 08-06-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31492, current rewards: -161.38686, mean: -0.76851
[32m[0907 08-07-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31488, current rewards: -256.99840, mean: -0.98846
[32m[0907 08-07-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31556, current rewards: -347.81878, mean: -1.12200
[32m[0907 08-07-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31856, current rewards: -407.72156, mean: -1.13256
[32m[0907 08-08-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31884, current rewards: -450.10291, mean: -1.09781
[32m[0907 08-08-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31874, current rewards: -470.67464, mean: -1.02321
[32m[0907 08-08-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31851, current rewards: -467.39294, mean: -0.91646
[32m[0907 08-08-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31837, current rewards: -461.63309, mean: -0.82434
[32m[0907 08-09-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31813, current rewards: -455.64570, mean: -0.74696
[32m[0907 08-09-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31796, current rewards: -449.38532, mean: -0.68089
[32m[0907 08-09-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31778, current rewards: -443.27639, mean: -0.62433
[32m[0907 08-09-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31785, current rewards: -518.97367, mean: -0.68286
[32m[0907 08-10-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31767, current rewards: -618.97367, mean: -0.76417
[32m[0907 08-10-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31751, current rewards: -718.97367, mean: -0.83602
[32m[0907 08-10-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31738, current rewards: -818.97367, mean: -0.89997
[32m[0907 08-10-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31724, current rewards: -918.97367, mean: -0.95726
[32m[0907 08-11-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31713, current rewards: -1018.97367, mean: -1.00888
[32m[0907 08-11-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31707, current rewards: -1118.97367, mean: -1.05564
[32m[0907 08-11-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31700, current rewards: -1218.97367, mean: -1.09817
[32m[0907 08-12-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31689, current rewards: -1318.97367, mean: -1.13705
[32m[0907 08-12-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31680, current rewards: -1418.97367, mean: -1.17271
[32m[0907 08-12-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31673, current rewards: -1518.97367, mean: -1.20553
[32m[0907 08-12-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31668, current rewards: -1618.97367, mean: -1.23586
[32m[0907 08-13-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31662, current rewards: -1718.97367, mean: -1.26395
[32m[0907 08-13-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31655, current rewards: -1818.97367, mean: -1.29005
[32m[0907 08-13-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31649, current rewards: -1918.97367, mean: -1.31437
[32m[0907 08-13-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31642, current rewards: -2018.97367, mean: -1.33707
[32m[0907 08-14-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31635, current rewards: -2118.97367, mean: -1.35832
[32m[0907 08-14-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31633, current rewards: -2218.97367, mean: -1.37824
[32m[0907 08-14-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31631, current rewards: -2318.97367, mean: -1.39697
[32m[0907 08-14-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31627, current rewards: -2418.97367, mean: -1.41460
[32m[0907 08-15-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31624, current rewards: -2518.97367, mean: -1.43124
[32m[0907 08-15-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31620, current rewards: -2618.97367, mean: -1.44695
[32m[0907 08-15-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31615, current rewards: -2718.97367, mean: -1.46181
[32m[0907 08-15-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31612, current rewards: -2818.97367, mean: -1.47590
[32m[0907 08-16-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31608, current rewards: -2918.97367, mean: -1.48927
[32m[0907 08-16-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31603, current rewards: -3018.97367, mean: -1.50198
[32m[0907 08-16-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31590, current rewards: -3118.97367, mean: -1.51406
[32m[0907 08-16-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31573, current rewards: -3218.97367, mean: -1.52558
[32m[0907 08-17-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31554, current rewards: -3318.97367, mean: -1.53656
[32m[0907 08-17-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31537, current rewards: -3418.97367, mean: -1.54705
[32m[0907 08-17-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31520, current rewards: -3518.97367, mean: -1.55707
[32m[0907 08-18-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31506, current rewards: -3618.97367, mean: -1.56666
[32m[0907 08-18-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31490, current rewards: -3718.97367, mean: -1.57584
[32m[0907 08-18-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31462, current rewards: -3818.97367, mean: -1.58464
[32m[0907 08-18-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31420, current rewards: -3918.97367, mean: -1.59308
[32m[0907 08-18-57 @Agent.py:117][0m Average action selection time: 0.3138
[32m[0907 08-18-57 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-18-57 @MBExp.py:227][0m Rewards obtained: [-3998.973671265123], Lows: [2015], Highs: [41], Total time: 61764.100611999995
[32m[0907 08-21-17 @MBExp.py:144][0m ####################################################################
[32m[0907 08-21-17 @MBExp.py:145][0m Starting training iteration 76.
[32m[0907 08-21-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32923, current rewards: 0.56473, mean: 0.05647
[32m[0907 08-21-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34988, current rewards: -57.28125, mean: -0.95469
[32m[0907 08-21-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33948, current rewards: -131.37962, mean: -1.19436
[32m[0907 08-22-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33663, current rewards: -193.67019, mean: -1.21044
[32m[0907 08-22-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33206, current rewards: -249.72333, mean: -1.18916
[32m[0907 08-22-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33319, current rewards: -318.64812, mean: -1.22557
[32m[0907 08-22-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33078, current rewards: -409.06257, mean: -1.31956
[32m[0907 08-23-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32922, current rewards: -506.81665, mean: -1.40782
[32m[0907 08-23-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32837, current rewards: -606.81665, mean: -1.48004
[32m[0907 08-23-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32891, current rewards: -697.32772, mean: -1.51593
[32m[0907 08-24-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32791, current rewards: -792.55199, mean: -1.55402
[32m[0907 08-24-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32716, current rewards: -876.03619, mean: -1.56435
[32m[0907 08-24-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32655, current rewards: -955.61787, mean: -1.56659
[32m[0907 08-24-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32640, current rewards: -1029.89992, mean: -1.56045
[32m[0907 08-25-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32560, current rewards: -1119.69381, mean: -1.57703
[32m[0907 08-25-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32490, current rewards: -1219.69381, mean: -1.60486
[32m[0907 08-25-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32428, current rewards: -1319.69381, mean: -1.62925
[32m[0907 08-25-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32374, current rewards: -1419.69381, mean: -1.65081
[32m[0907 08-26-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32328, current rewards: -1519.69381, mean: -1.66999
[32m[0907 08-26-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32285, current rewards: -1619.69381, mean: -1.68718
[32m[0907 08-26-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32256, current rewards: -1710.43620, mean: -1.69350
[32m[0907 08-26-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32215, current rewards: -1801.52186, mean: -1.69955
[32m[0907 08-27-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32178, current rewards: -1892.47127, mean: -1.70493
[32m[0907 08-27-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32155, current rewards: -1979.06385, mean: -1.70609
[32m[0907 08-27-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32124, current rewards: -2070.20168, mean: -1.71091
[32m[0907 08-28-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32098, current rewards: -2165.90376, mean: -1.71897
[32m[0907 08-28-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32083, current rewards: -2263.69371, mean: -1.72801
[32m[0907 08-28-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32058, current rewards: -2363.69371, mean: -1.73801
[32m[0907 08-28-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32038, current rewards: -2463.69371, mean: -1.74730
[32m[0907 08-29-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32016, current rewards: -2563.69371, mean: -1.75595
[32m[0907 08-29-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31997, current rewards: -2663.69371, mean: -1.76404
[32m[0907 08-29-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31982, current rewards: -2763.69371, mean: -1.77160
[32m[0907 08-29-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31966, current rewards: -2827.70443, mean: -1.75634
[32m[0907 08-30-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31952, current rewards: -2917.09863, mean: -1.75729
[32m[0907 08-30-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31938, current rewards: -3012.13048, mean: -1.76148
[32m[0907 08-30-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31925, current rewards: -3083.56844, mean: -1.75203
[32m[0907 08-30-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31913, current rewards: -3113.91618, mean: -1.72040
[32m[0907 08-31-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31903, current rewards: -3213.91618, mean: -1.72791
[32m[0907 08-31-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31891, current rewards: -3313.91618, mean: -1.73503
[32m[0907 08-31-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31879, current rewards: -3413.91618, mean: -1.74179
[32m[0907 08-31-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31865, current rewards: -3513.91618, mean: -1.74822
[32m[0907 08-32-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31839, current rewards: -3613.91618, mean: -1.75433
[32m[0907 08-32-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31815, current rewards: -3713.91618, mean: -1.76015
[32m[0907 08-32-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31793, current rewards: -3813.91618, mean: -1.76570
[32m[0907 08-32-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31771, current rewards: -3913.91618, mean: -1.77100
[32m[0907 08-33-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31749, current rewards: -4013.91618, mean: -1.77607
[32m[0907 08-33-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31728, current rewards: -4113.91618, mean: -1.78092
[32m[0907 08-33-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31707, current rewards: -4213.91618, mean: -1.78556
[32m[0907 08-34-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31684, current rewards: -4313.91618, mean: -1.79001
[32m[0907 08-34-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31636, current rewards: -4413.91618, mean: -1.79427
[32m[0907 08-34-27 @Agent.py:117][0m Average action selection time: 0.3161
[32m[0907 08-34-27 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-34-28 @MBExp.py:227][0m Rewards obtained: [-4493.916177056957], Lows: [2252], Highs: [43], Total time: 62554.964091999995
[32m[0907 08-36-49 @MBExp.py:144][0m ####################################################################
[32m[0907 08-36-49 @MBExp.py:145][0m Starting training iteration 77.
[32m[0907 08-36-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.39000, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-37-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34476, current rewards: -53.85014, mean: -0.89750
[32m[0907 08-37-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33305, current rewards: -64.62247, mean: -0.58748
[32m[0907 08-37-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32796, current rewards: -61.02835, mean: -0.38143
[32m[0907 08-37-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32535, current rewards: -55.83212, mean: -0.26587
[32m[0907 08-38-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32359, current rewards: -48.50094, mean: -0.18654
[32m[0907 08-38-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32247, current rewards: -39.50774, mean: -0.12744
[32m[0907 08-38-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32158, current rewards: -27.44041, mean: -0.07622
[32m[0907 08-39-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32141, current rewards: -39.63377, mean: -0.09667
[32m[0907 08-39-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32109, current rewards: -55.81334, mean: -0.12133
[32m[0907 08-39-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32064, current rewards: -52.96328, mean: -0.10385
[32m[0907 08-39-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32029, current rewards: -49.81481, mean: -0.08896
[32m[0907 08-40-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31999, current rewards: -71.92357, mean: -0.11791
[32m[0907 08-40-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31964, current rewards: -125.91598, mean: -0.19078
[32m[0907 08-40-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31950, current rewards: -143.72133, mean: -0.20242
[32m[0907 08-40-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31925, current rewards: -155.82389, mean: -0.20503
[32m[0907 08-41-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31899, current rewards: -154.31806, mean: -0.19052
[32m[0907 08-41-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31882, current rewards: -155.89220, mean: -0.18127
[32m[0907 08-41-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31890, current rewards: -158.51858, mean: -0.17420
[32m[0907 08-41-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31893, current rewards: -201.06302, mean: -0.20944
[32m[0907 08-42-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31947, current rewards: -193.23855, mean: -0.19133
[32m[0907 08-42-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32303, current rewards: -181.49567, mean: -0.17122
[32m[0907 08-42-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32346, current rewards: -173.68975, mean: -0.15648
[32m[0907 08-43-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32713, current rewards: -162.09532, mean: -0.13974
[32m[0907 08-43-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33100, current rewards: -155.09061, mean: -0.12817
[32m[0907 08-43-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33467, current rewards: -148.66734, mean: -0.11799
[32m[0907 08-44-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33814, current rewards: -142.31607, mean: -0.10864
[32m[0907 08-44-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34130, current rewards: -136.18862, mean: -0.10014
[32m[0907 08-44-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34427, current rewards: -129.81715, mean: -0.09207
[32m[0907 08-45-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34715, current rewards: -123.50292, mean: -0.08459
[32m[0907 08-45-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34912, current rewards: -126.22339, mean: -0.08359
[32m[0907 08-45-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34881, current rewards: -196.03916, mean: -0.12567
[32m[0907 08-46-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34813, current rewards: -227.76283, mean: -0.14147
[32m[0907 08-46-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34778, current rewards: -292.66530, mean: -0.17630
[32m[0907 08-46-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34683, current rewards: -365.86190, mean: -0.21395
[32m[0907 08-47-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34711, current rewards: -386.54969, mean: -0.21963
[32m[0907 08-47-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34843, current rewards: -428.41920, mean: -0.23670
[32m[0907 08-47-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34742, current rewards: -487.00456, mean: -0.26183
[32m[0907 08-47-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34728, current rewards: -537.09041, mean: -0.28120
[32m[0907 08-48-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34649, current rewards: -600.02706, mean: -0.30614
[32m[0907 08-48-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34703, current rewards: -626.06706, mean: -0.31148
[32m[0907 08-48-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34693, current rewards: -658.67887, mean: -0.31975
[32m[0907 08-49-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34664, current rewards: -674.14888, mean: -0.31950
[32m[0907 08-49-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34620, current rewards: -711.46600, mean: -0.32938
[32m[0907 08-49-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34624, current rewards: -761.70552, mean: -0.34466
[32m[0907 08-49-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34557, current rewards: -797.99486, mean: -0.35310
[32m[0907 08-50-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34476, current rewards: -825.83974, mean: -0.35751
[32m[0907 08-50-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34405, current rewards: -834.71166, mean: -0.35369
[32m[0907 08-50-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34313, current rewards: -835.19728, mean: -0.34655
[32m[0907 08-50-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34263, current rewards: -862.91780, mean: -0.35078
[32m[0907 08-51-04 @Agent.py:117][0m Average action selection time: 0.3420
[32m[0907 08-51-04 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-51-05 @MBExp.py:227][0m Rewards obtained: [-865.614764739294], Lows: [253], Highs: [575], Total time: 63410.793484999995
[32m[0907 08-53-28 @MBExp.py:144][0m ####################################################################
[32m[0907 08-53-28 @MBExp.py:145][0m Starting training iteration 78.
[32m[0907 08-53-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30735, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-53-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30825, current rewards: -18.13884, mean: -0.30231
[32m[0907 08-54-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31221, current rewards: -11.00707, mean: -0.10006
[32m[0907 08-54-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31361, current rewards: -3.86879, mean: -0.02418
[32m[0907 08-54-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31409, current rewards: 3.25920, mean: 0.01552
[32m[0907 08-54-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31444, current rewards: 10.39812, mean: 0.03999
[32m[0907 08-55-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31460, current rewards: 17.53093, mean: 0.05655
[32m[0907 08-55-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31485, current rewards: 24.18286, mean: 0.06717
[32m[0907 08-55-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31772, current rewards: -20.65159, mean: -0.05037
[32m[0907 08-55-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32051, current rewards: -15.61453, mean: -0.03394
[32m[0907 08-56-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32365, current rewards: -10.99792, mean: -0.02156
[32m[0907 08-56-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32636, current rewards: -6.37228, mean: -0.01138
[32m[0907 08-56-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32863, current rewards: -1.75688, mean: -0.00288
[32m[0907 08-57-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33053, current rewards: 2.86250, mean: 0.00434
[32m[0907 08-57-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33222, current rewards: 7.48512, mean: 0.01054
[32m[0907 08-57-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33368, current rewards: 12.06949, mean: 0.01588
[32m[0907 08-57-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33481, current rewards: 16.20417, mean: 0.02001
[32m[0907 08-58-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33587, current rewards: 20.65053, mean: 0.02401
[32m[0907 08-58-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33676, current rewards: -4.66883, mean: -0.00513
[32m[0907 08-58-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33753, current rewards: 0.11717, mean: 0.00012
[32m[0907 08-59-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33825, current rewards: 4.91425, mean: 0.00487
[32m[0907 08-59-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33894, current rewards: 9.70118, mean: 0.00915
[32m[0907 08-59-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33955, current rewards: 14.48710, mean: 0.01305
[32m[0907 09-00-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34011, current rewards: 19.27010, mean: 0.01661
[32m[0907 09-00-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34060, current rewards: 26.85797, mean: 0.02220
[32m[0907 09-00-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34104, current rewards: 31.71694, mean: 0.02517
[32m[0907 09-00-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34147, current rewards: 36.59474, mean: 0.02793
[32m[0907 09-01-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34187, current rewards: 41.46841, mean: 0.03049
[32m[0907 09-01-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34220, current rewards: 46.33804, mean: 0.03286
[32m[0907 09-01-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34255, current rewards: 9.12422, mean: 0.00625
[32m[0907 09-02-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34286, current rewards: -23.38879, mean: -0.01549
[32m[0907 09-02-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34317, current rewards: -32.62161, mean: -0.02091
[32m[0907 09-02-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34347, current rewards: -66.60626, mean: -0.04137
[32m[0907 09-02-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34379, current rewards: -99.77106, mean: -0.06010
[32m[0907 09-03-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34406, current rewards: -104.66766, mean: -0.06121
[32m[0907 09-03-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34416, current rewards: -98.76167, mean: -0.05611
[32m[0907 09-03-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34416, current rewards: -92.89486, mean: -0.05132
[32m[0907 09-04-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34416, current rewards: -87.02870, mean: -0.04679
[32m[0907 09-04-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34414, current rewards: -81.16600, mean: -0.04250
[32m[0907 09-04-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34413, current rewards: -75.29706, mean: -0.03842
[32m[0907 09-05-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34412, current rewards: -68.56604, mean: -0.03411
[32m[0907 09-05-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34411, current rewards: -62.52951, mean: -0.03035
[32m[0907 09-05-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34411, current rewards: -56.62030, mean: -0.02683
[32m[0907 09-05-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34410, current rewards: -50.71474, mean: -0.02348
[32m[0907 09-06-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34426, current rewards: -98.31285, mean: -0.04449
[32m[0907 09-06-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34424, current rewards: -108.90271, mean: -0.04819
[32m[0907 09-06-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34423, current rewards: -104.55716, mean: -0.04526
[32m[0907 09-07-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34407, current rewards: -96.05062, mean: -0.04070
[32m[0907 09-07-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34386, current rewards: -82.88119, mean: -0.03439
[32m[0907 09-07-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34366, current rewards: -73.86410, mean: -0.03003
[32m[0907 09-07-47 @Agent.py:117][0m Average action selection time: 0.3435
[32m[0907 09-07-47 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-07-48 @MBExp.py:227][0m Rewards obtained: [-66.70762337056996], Lows: [149], Highs: [67], Total time: 64270.31423599999
[32m[0907 09-10-27 @MBExp.py:144][0m ####################################################################
[32m[0907 09-10-27 @MBExp.py:145][0m Starting training iteration 79.
[32m[0907 09-10-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35535, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-10-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34659, current rewards: -58.92221, mean: -0.98204
[32m[0907 09-11-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35337, current rewards: -97.32786, mean: -0.88480
[32m[0907 09-11-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35857, current rewards: -144.16297, mean: -0.90102
[32m[0907 09-11-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36047, current rewards: -194.16297, mean: -0.92459
[32m[0907 09-12-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36314, current rewards: -244.16297, mean: -0.93909
[32m[0907 09-12-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36280, current rewards: -294.16297, mean: -0.94891
[32m[0907 09-12-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36280, current rewards: -344.16297, mean: -0.95601
[32m[0907 09-12-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36310, current rewards: -394.16297, mean: -0.96137
[32m[0907 09-13-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36324, current rewards: -444.16297, mean: -0.96557
[32m[0907 09-13-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36369, current rewards: -494.16297, mean: -0.96895
[32m[0907 09-13-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36378, current rewards: -544.16297, mean: -0.97172
[32m[0907 09-14-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36354, current rewards: -594.16297, mean: -0.97404
[32m[0907 09-14-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36340, current rewards: -644.16297, mean: -0.97600
[32m[0907 09-14-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36496, current rewards: -694.16297, mean: -0.97769
[32m[0907 09-15-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36455, current rewards: -744.16297, mean: -0.97916
[32m[0907 09-15-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36416, current rewards: -794.16297, mean: -0.98045
[32m[0907 09-15-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36375, current rewards: -844.16297, mean: -0.98158
[32m[0907 09-15-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36334, current rewards: -894.16297, mean: -0.98260
[32m[0907 09-16-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36410, current rewards: -944.16297, mean: -0.98350
[32m[0907 09-16-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36415, current rewards: -994.16297, mean: -0.98432
[32m[0907 09-16-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36395, current rewards: -1068.16297, mean: -1.00770
[32m[0907 09-17-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36482, current rewards: -1079.91705, mean: -0.97290
[32m[0907 09-17-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36447, current rewards: -1128.84893, mean: -0.97315
[32m[0907 09-17-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36427, current rewards: -1178.84893, mean: -0.97426
[32m[0907 09-18-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36483, current rewards: -1228.84893, mean: -0.97528
[32m[0907 09-18-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36496, current rewards: -1278.84893, mean: -0.97622
[32m[0907 09-18-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36519, current rewards: -1328.84893, mean: -0.97709
[32m[0907 09-19-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36565, current rewards: -1378.84893, mean: -0.97791
[32m[0907 09-19-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36654, current rewards: -1434.34524, mean: -0.98243
[32m[0907 09-19-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36623, current rewards: -1505.70135, mean: -0.99715
[32m[0907 09-19-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36595, current rewards: -1605.70135, mean: -1.02930
[32m[0907 09-20-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36568, current rewards: -1705.70135, mean: -1.05944
[32m[0907 09-20-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36542, current rewards: -1805.70135, mean: -1.08777
[32m[0907 09-20-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36506, current rewards: -1905.70135, mean: -1.11445
[32m[0907 09-21-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36457, current rewards: -2005.70135, mean: -1.13960
[32m[0907 09-21-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36412, current rewards: -2105.70135, mean: -1.16337
[32m[0907 09-21-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36369, current rewards: -2205.70135, mean: -1.18586
[32m[0907 09-22-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36328, current rewards: -2305.70135, mean: -1.20717
[32m[0907 09-22-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36288, current rewards: -2405.70135, mean: -1.22740
[32m[0907 09-22-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36242, current rewards: -2505.70135, mean: -1.24662
[32m[0907 09-22-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36198, current rewards: -2605.70135, mean: -1.26490
[32m[0907 09-23-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36155, current rewards: -2705.70135, mean: -1.28232
[32m[0907 09-23-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36105, current rewards: -2805.70135, mean: -1.29894
[32m[0907 09-23-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36060, current rewards: -2905.70135, mean: -1.31480
[32m[0907 09-24-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36024, current rewards: -3005.70135, mean: -1.32996
[32m[0907 09-24-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35989, current rewards: -3105.70135, mean: -1.34446
[32m[0907 09-24-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35955, current rewards: -3205.70135, mean: -1.35835
[32m[0907 09-24-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35924, current rewards: -3305.70135, mean: -1.37166
[32m[0907 09-25-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35874, current rewards: -3405.70135, mean: -1.38443
[32m[0907 09-25-24 @Agent.py:117][0m Average action selection time: 0.3584
[32m[0907 09-25-24 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-25-24 @MBExp.py:227][0m Rewards obtained: [-3485.701346260029], Lows: [1057], Highs: [1376], Total time: 65167.01424599999
[32m[0907 09-28-05 @MBExp.py:144][0m ####################################################################
[32m[0907 09-28-05 @MBExp.py:145][0m Starting training iteration 80.
[32m[0907 09-28-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34404, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-28-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34881, current rewards: -75.60764, mean: -1.26013
[32m[0907 09-28-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35107, current rewards: -82.79715, mean: -0.75270
[32m[0907 09-29-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35195, current rewards: -92.09199, mean: -0.57557
[32m[0907 09-29-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35235, current rewards: -96.82763, mean: -0.46108
[32m[0907 09-29-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35256, current rewards: -107.80204, mean: -0.41462
[32m[0907 09-29-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35280, current rewards: -167.32159, mean: -0.53975
[32m[0907 09-30-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35297, current rewards: -241.89906, mean: -0.67194
[32m[0907 09-30-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35301, current rewards: -308.97720, mean: -0.75360
[32m[0907 09-30-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35308, current rewards: -379.98423, mean: -0.82605
[32m[0907 09-31-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35318, current rewards: -451.17334, mean: -0.88465
[32m[0907 09-31-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35328, current rewards: -539.10626, mean: -0.96269
[32m[0907 09-31-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35333, current rewards: -612.53142, mean: -1.00415
[32m[0907 09-31-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35332, current rewards: -694.94046, mean: -1.05294
[32m[0907 09-32-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35330, current rewards: -766.65232, mean: -1.07979
[32m[0907 09-32-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35332, current rewards: -813.94728, mean: -1.07098
[32m[0907 09-32-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35330, current rewards: -883.86381, mean: -1.09119
[32m[0907 09-33-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35356, current rewards: -901.72354, mean: -1.04852
[32m[0907 09-33-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35362, current rewards: -954.10753, mean: -1.04847
[32m[0907 09-33-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35357, current rewards: -1023.50390, mean: -1.06615
[32m[0907 09-34-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35353, current rewards: -1097.52342, mean: -1.08666
[32m[0907 09-34-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35353, current rewards: -1171.77921, mean: -1.10545
[32m[0907 09-34-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35353, current rewards: -1223.10967, mean: -1.10190
[32m[0907 09-34-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35350, current rewards: -1300.88788, mean: -1.12146
[32m[0907 09-35-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35347, current rewards: -1316.98869, mean: -1.08842
[32m[0907 09-35-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35340, current rewards: -1310.68044, mean: -1.04022
[32m[0907 09-35-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35336, current rewards: -1304.44271, mean: -0.99576
[32m[0907 09-36-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35334, current rewards: -1298.20744, mean: -0.95456
[32m[0907 09-36-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35331, current rewards: -1291.97040, mean: -0.91629
[32m[0907 09-36-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35332, current rewards: -1285.73363, mean: -0.88064
[32m[0907 09-36-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35324, current rewards: -1280.04352, mean: -0.84771
[32m[0907 09-37-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35322, current rewards: -1274.43396, mean: -0.81694
[32m[0907 09-37-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35321, current rewards: -1268.18869, mean: -0.78769
[32m[0907 09-37-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35339, current rewards: -1318.43796, mean: -0.79424
[32m[0907 09-38-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35328, current rewards: -1350.14207, mean: -0.78956
[32m[0907 09-38-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35337, current rewards: -1360.35526, mean: -0.77293
[32m[0907 09-38-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35327, current rewards: -1380.01524, mean: -0.76244
[32m[0907 09-39-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35316, current rewards: -1395.19353, mean: -0.75010
[32m[0907 09-39-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35321, current rewards: -1408.27199, mean: -0.73732
[32m[0907 09-39-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35332, current rewards: -1459.84637, mean: -0.74482
[32m[0907 09-39-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35318, current rewards: -1459.68493, mean: -0.72621
[32m[0907 09-40-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35311, current rewards: -1507.91774, mean: -0.73200
[32m[0907 09-40-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35320, current rewards: -1518.77224, mean: -0.71980
[32m[0907 09-40-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35291, current rewards: -1588.19413, mean: -0.73528
[32m[0907 09-41-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35269, current rewards: -1667.26357, mean: -0.75442
[32m[0907 09-41-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35259, current rewards: -1732.56466, mean: -0.76662
[32m[0907 09-41-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35249, current rewards: -1751.20802, mean: -0.75810
[32m[0907 09-41-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35239, current rewards: -1826.73978, mean: -0.77404
[32m[0907 09-42-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35229, current rewards: -1894.12357, mean: -0.78594
[32m[0907 09-42-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35203, current rewards: -1975.71961, mean: -0.80314
[32m[0907 09-42-45 @Agent.py:117][0m Average action selection time: 0.3518
[32m[0907 09-42-45 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-42-45 @MBExp.py:227][0m Rewards obtained: [-2039.2516552052034], Lows: [1128], Highs: [62], Total time: 66047.29882799998
[32m[0907 09-45-32 @MBExp.py:144][0m ####################################################################
[32m[0907 09-45-32 @MBExp.py:145][0m Starting training iteration 81.
[32m[0907 09-45-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34500, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-45-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35459, current rewards: -97.92212, mean: -1.63204
[32m[0907 09-46-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35587, current rewards: -197.92212, mean: -1.79929
[32m[0907 09-46-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35634, current rewards: -297.92212, mean: -1.86201
[32m[0907 09-46-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35681, current rewards: -397.92212, mean: -1.89487
[32m[0907 09-47-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35688, current rewards: -497.92212, mean: -1.91509
[32m[0907 09-47-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35691, current rewards: -597.92212, mean: -1.92878
[32m[0907 09-47-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35685, current rewards: -697.92212, mean: -1.93867
[32m[0907 09-47-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35696, current rewards: -797.92212, mean: -1.94615
[32m[0907 09-48-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35689, current rewards: -897.92212, mean: -1.95200
[32m[0907 09-48-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35692, current rewards: -997.92212, mean: -1.95671
[32m[0907 09-48-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35684, current rewards: -1097.92212, mean: -1.96058
[32m[0907 09-49-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35675, current rewards: -1197.92212, mean: -1.96381
[32m[0907 09-49-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35682, current rewards: -1297.92212, mean: -1.96655
[32m[0907 09-49-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35675, current rewards: -1397.92212, mean: -1.96890
[32m[0907 09-50-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35670, current rewards: -1497.92212, mean: -1.97095
[32m[0907 09-50-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35673, current rewards: -1597.92212, mean: -1.97274
[32m[0907 09-50-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35669, current rewards: -1697.92212, mean: -1.97433
[32m[0907 09-50-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35669, current rewards: -1797.92212, mean: -1.97574
[32m[0907 09-51-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35662, current rewards: -1897.92212, mean: -1.97700
[32m[0907 09-51-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35663, current rewards: -1997.92212, mean: -1.97814
[32m[0907 09-51-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35666, current rewards: -2097.92212, mean: -1.97917
[32m[0907 09-52-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35662, current rewards: -2197.92212, mean: -1.98011
[32m[0907 09-52-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35656, current rewards: -2297.92212, mean: -1.98097
[32m[0907 09-52-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35656, current rewards: -2397.92212, mean: -1.98175
[32m[0907 09-53-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35655, current rewards: -2497.92212, mean: -1.98248
[32m[0907 09-53-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35654, current rewards: -2597.92212, mean: -1.98315
[32m[0907 09-53-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35656, current rewards: -2697.92212, mean: -1.98377
[32m[0907 09-53-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35658, current rewards: -2797.92212, mean: -1.98434
[32m[0907 09-54-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35655, current rewards: -2897.92212, mean: -1.98488
[32m[0907 09-54-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35656, current rewards: -2997.92212, mean: -1.98538
[32m[0907 09-54-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35662, current rewards: -3097.92212, mean: -1.98585
[32m[0907 09-55-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35670, current rewards: -3197.92212, mean: -1.98629
[32m[0907 09-55-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35678, current rewards: -3297.92212, mean: -1.98670
[32m[0907 09-55-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35668, current rewards: -3397.92212, mean: -1.98709
[32m[0907 09-56-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35661, current rewards: -3497.92212, mean: -1.98746
[32m[0907 09-56-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35647, current rewards: -3597.92212, mean: -1.98780
[32m[0907 09-56-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35630, current rewards: -3697.92212, mean: -1.98813
[32m[0907 09-56-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35616, current rewards: -3797.92212, mean: -1.98844
[32m[0907 09-57-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35604, current rewards: -3897.92212, mean: -1.98874
[32m[0907 09-57-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35593, current rewards: -3997.92212, mean: -1.98902
[32m[0907 09-57-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35581, current rewards: -4097.92212, mean: -1.98928
[32m[0907 09-58-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35571, current rewards: -4197.92212, mean: -1.98954
[32m[0907 09-58-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35557, current rewards: -4297.92212, mean: -1.98978
[32m[0907 09-58-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35535, current rewards: -4397.92212, mean: -1.99001
[32m[0907 09-58-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35528, current rewards: -4497.92212, mean: -1.99023
[32m[0907 09-59-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35511, current rewards: -4597.92212, mean: -1.99044
[32m[0907 09-59-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35490, current rewards: -4697.92212, mean: -1.99064
[32m[0907 09-59-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35467, current rewards: -4797.92212, mean: -1.99084
[32m[0907 10-00-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35432, current rewards: -4897.92212, mean: -1.99103
[32m[0907 10-00-18 @Agent.py:117][0m Average action selection time: 0.3540
[32m[0907 10-00-18 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-00-18 @MBExp.py:227][0m Rewards obtained: [-4977.922121408782], Lows: [2479], Highs: [20], Total time: 66933.13484199998
[32m[0907 10-03-07 @MBExp.py:144][0m ####################################################################
[32m[0907 10-03-07 @MBExp.py:145][0m Starting training iteration 82.
[32m[0907 10-03-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34754, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-03-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35408, current rewards: -58.77538, mean: -0.97959
[32m[0907 10-03-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35493, current rewards: -55.04999, mean: -0.50045
[32m[0907 10-04-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35696, current rewards: -54.00347, mean: -0.33752
[32m[0907 10-04-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35672, current rewards: -55.17241, mean: -0.26273
[32m[0907 10-04-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35724, current rewards: -87.32607, mean: -0.33587
[32m[0907 10-04-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35703, current rewards: -80.68929, mean: -0.26029
[32m[0907 10-05-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35704, current rewards: -82.30582, mean: -0.22863
[32m[0907 10-05-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35800, current rewards: -146.77164, mean: -0.35798
[32m[0907 10-05-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35845, current rewards: -222.77873, mean: -0.48430
[32m[0907 10-06-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35889, current rewards: -298.24562, mean: -0.58480
[32m[0907 10-06-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35901, current rewards: -372.72352, mean: -0.66558
[32m[0907 10-06-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35910, current rewards: -417.27888, mean: -0.68406
[32m[0907 10-07-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35915, current rewards: -494.50108, mean: -0.74924
[32m[0907 10-07-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35923, current rewards: -561.67823, mean: -0.79110
[32m[0907 10-07-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35928, current rewards: -624.82216, mean: -0.82213
[32m[0907 10-07-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35938, current rewards: -686.47853, mean: -0.84750
[32m[0907 10-08-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35936, current rewards: -757.24516, mean: -0.88052
[32m[0907 10-08-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35942, current rewards: -783.43323, mean: -0.86092
[32m[0907 10-08-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35953, current rewards: -807.63050, mean: -0.84128
[32m[0907 10-09-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35970, current rewards: -873.83518, mean: -0.86518
[32m[0907 10-09-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35971, current rewards: -897.50631, mean: -0.84670
[32m[0907 10-09-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35967, current rewards: -963.84517, mean: -0.86833
[32m[0907 10-10-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35997, current rewards: -998.58914, mean: -0.86085
[32m[0907 10-10-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36009, current rewards: -1043.42380, mean: -0.86233
[32m[0907 10-10-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35986, current rewards: -1101.64041, mean: -0.87432
[32m[0907 10-10-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35964, current rewards: -1159.53796, mean: -0.88514
[32m[0907 10-11-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35938, current rewards: -1165.79435, mean: -0.85720
[32m[0907 10-11-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35912, current rewards: -1157.42473, mean: -0.82087
[32m[0907 10-11-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35888, current rewards: -1149.88753, mean: -0.78759
[32m[0907 10-12-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35938, current rewards: -1219.11221, mean: -0.80736
[32m[0907 10-12-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35974, current rewards: -1278.63404, mean: -0.81964
[32m[0907 10-12-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36001, current rewards: -1358.33053, mean: -0.84368
[32m[0907 10-13-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35974, current rewards: -1356.56296, mean: -0.81721
[32m[0907 10-13-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35960, current rewards: -1388.63777, mean: -0.81207
[32m[0907 10-13-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35941, current rewards: -1458.96648, mean: -0.82896
[32m[0907 10-13-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35899, current rewards: -1472.13260, mean: -0.81333
[32m[0907 10-14-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35858, current rewards: -1478.34202, mean: -0.79481
[32m[0907 10-14-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35822, current rewards: -1514.49827, mean: -0.79293
[32m[0907 10-14-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35785, current rewards: -1545.49189, mean: -0.78852
[32m[0907 10-15-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35751, current rewards: -1554.05267, mean: -0.77316
[32m[0907 10-15-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35885, current rewards: -1581.67104, mean: -0.76780
[32m[0907 10-15-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35905, current rewards: -1581.78720, mean: -0.74966
[32m[0907 10-16-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35865, current rewards: -1584.77173, mean: -0.73369
[32m[0907 10-16-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35832, current rewards: -1635.94123, mean: -0.74024
[32m[0907 10-16-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35802, current rewards: -1641.70632, mean: -0.72642
[32m[0907 10-16-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35768, current rewards: -1706.83054, mean: -0.73889
[32m[0907 10-17-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35668, current rewards: -1737.75355, mean: -0.73634
[32m[0907 10-17-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35562, current rewards: -1740.60746, mean: -0.72224
[32m[0907 10-17-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35447, current rewards: -1732.93223, mean: -0.70444
[32m[0907 10-17-52 @Agent.py:117][0m Average action selection time: 0.3536
[32m[0907 10-17-52 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-17-52 @MBExp.py:227][0m Rewards obtained: [-1726.927597695545], Lows: [932], Highs: [168], Total time: 67817.86755899999
[32m[0907 10-20-24 @MBExp.py:144][0m ####################################################################
[32m[0907 10-20-24 @MBExp.py:145][0m Starting training iteration 83.
[32m[0907 10-20-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32938, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-20-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31964, current rewards: -52.12207, mean: -0.86870
[32m[0907 10-20-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31836, current rewards: -98.48787, mean: -0.89534
[32m[0907 10-21-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31768, current rewards: -146.55078, mean: -0.91594
[32m[0907 10-21-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31729, current rewards: -205.34269, mean: -0.97782
[32m[0907 10-21-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31718, current rewards: -258.50777, mean: -0.99426
[32m[0907 10-22-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31694, current rewards: -298.87969, mean: -0.96413
[32m[0907 10-22-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31682, current rewards: -359.20595, mean: -0.99779
[32m[0907 10-22-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31664, current rewards: -417.71362, mean: -1.01881
[32m[0907 10-22-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31748, current rewards: -474.08518, mean: -1.03062
[32m[0907 10-23-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31722, current rewards: -501.74559, mean: -0.98381
[32m[0907 10-23-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31699, current rewards: -495.70739, mean: -0.88519
[32m[0907 10-23-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31677, current rewards: -490.12760, mean: -0.80349
[32m[0907 10-23-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31661, current rewards: -484.55711, mean: -0.73418
[32m[0907 10-24-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31693, current rewards: -525.02528, mean: -0.73947
[32m[0907 10-24-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31678, current rewards: -516.76435, mean: -0.67995
[32m[0907 10-24-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31662, current rewards: -511.02449, mean: -0.63089
[32m[0907 10-24-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31651, current rewards: -505.33327, mean: -0.58760
[32m[0907 10-25-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31640, current rewards: -499.65703, mean: -0.54907
[32m[0907 10-25-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31632, current rewards: -493.96884, mean: -0.51455
[32m[0907 10-25-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31620, current rewards: -488.28365, mean: -0.48345
[32m[0907 10-25-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31611, current rewards: -521.42243, mean: -0.49191
[32m[0907 10-26-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31605, current rewards: -514.32588, mean: -0.46336
[32m[0907 10-26-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31598, current rewards: -507.22932, mean: -0.43727
[32m[0907 10-26-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31587, current rewards: -500.13277, mean: -0.41333
[32m[0907 10-27-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31582, current rewards: -493.03622, mean: -0.39130
[32m[0907 10-27-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31579, current rewards: -485.93967, mean: -0.37095
[32m[0907 10-27-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31572, current rewards: -494.83015, mean: -0.36385
[32m[0907 10-27-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31568, current rewards: -544.83015, mean: -0.38640
[32m[0907 10-28-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31560, current rewards: -594.83015, mean: -0.40742
[32m[0907 10-28-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31558, current rewards: -642.60482, mean: -0.42557
[32m[0907 10-28-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31552, current rewards: -692.60482, mean: -0.44398
[32m[0907 10-28-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31551, current rewards: -742.60482, mean: -0.46125
[32m[0907 10-29-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31532, current rewards: -792.60482, mean: -0.47747
[32m[0907 10-29-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31512, current rewards: -842.60482, mean: -0.49275
[32m[0907 10-29-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31494, current rewards: -892.60482, mean: -0.50716
[32m[0907 10-29-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31476, current rewards: -942.60482, mean: -0.52078
[32m[0907 10-30-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31458, current rewards: -988.36200, mean: -0.53138
[32m[0907 10-30-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31441, current rewards: -1048.26353, mean: -0.54883
[32m[0907 10-30-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31427, current rewards: -1106.88155, mean: -0.56474
[32m[0907 10-30-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31422, current rewards: -1176.20518, mean: -0.58518
[32m[0907 10-31-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31413, current rewards: -1236.14608, mean: -0.60007
[32m[0907 10-31-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31402, current rewards: -1312.23889, mean: -0.62191
[32m[0907 10-31-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31394, current rewards: -1377.17352, mean: -0.63758
[32m[0907 10-31-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31381, current rewards: -1444.72760, mean: -0.65372
[32m[0907 10-32-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31374, current rewards: -1492.54732, mean: -0.66042
[32m[0907 10-32-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31361, current rewards: -1553.28081, mean: -0.67242
[32m[0907 10-32-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31350, current rewards: -1620.41227, mean: -0.68662
[32m[0907 10-33-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31341, current rewards: -1690.65275, mean: -0.70152
[32m[0907 10-33-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31323, current rewards: -1742.79593, mean: -0.70845
[32m[0907 10-33-27 @Agent.py:117][0m Average action selection time: 0.3130
[32m[0907 10-33-27 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-33-27 @MBExp.py:227][0m Rewards obtained: [-1741.0263643228545], Lows: [707], Highs: [513], Total time: 68601.10311
[32m[0907 10-36-01 @MBExp.py:144][0m ####################################################################
[32m[0907 10-36-01 @MBExp.py:145][0m Starting training iteration 84.
[32m[0907 10-36-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30729, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-36-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34354, current rewards: -84.00000, mean: -1.40000
[32m[0907 10-36-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33710, current rewards: -164.29843, mean: -1.49362
[32m[0907 10-36-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33668, current rewards: -261.72060, mean: -1.63575
[32m[0907 10-37-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33225, current rewards: -343.55758, mean: -1.63599
[32m[0907 10-37-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33325, current rewards: -434.98589, mean: -1.67302
[32m[0907 10-37-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33455, current rewards: -527.80606, mean: -1.70260
[32m[0907 10-38-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33554, current rewards: -627.80606, mean: -1.74391
[32m[0907 10-38-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33390, current rewards: -714.37044, mean: -1.74237
[32m[0907 10-38-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33392, current rewards: -814.37044, mean: -1.77037
[32m[0907 10-38-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33332, current rewards: -914.37044, mean: -1.79288
[32m[0907 10-39-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33179, current rewards: -1009.29592, mean: -1.80231
[32m[0907 10-39-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33077, current rewards: -1102.79071, mean: -1.80785
[32m[0907 10-39-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33237, current rewards: -1200.71481, mean: -1.81926
[32m[0907 10-39-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33538, current rewards: -1298.56537, mean: -1.82897
[32m[0907 10-40-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33735, current rewards: -1385.79628, mean: -1.82342
[32m[0907 10-40-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34079, current rewards: -1474.78362, mean: -1.82072
[32m[0907 10-40-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34465, current rewards: -1570.39637, mean: -1.82604
[32m[0907 10-41-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34899, current rewards: -1658.50269, mean: -1.82253
[32m[0907 10-41-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35270, current rewards: -1751.27137, mean: -1.82424
[32m[0907 10-42-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35535, current rewards: -1838.75940, mean: -1.82055
[32m[0907 10-42-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35769, current rewards: -1925.58348, mean: -1.81659
[32m[0907 10-42-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36053, current rewards: -2009.03518, mean: -1.80994
[32m[0907 10-43-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36198, current rewards: -2062.34185, mean: -1.77788
[32m[0907 10-43-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36189, current rewards: -2135.30465, mean: -1.76471
[32m[0907 10-43-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36158, current rewards: -2218.77686, mean: -1.76093
[32m[0907 10-43-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36190, current rewards: -2298.00632, mean: -1.75420
[32m[0907 10-44-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36153, current rewards: -2357.36582, mean: -1.73336
[32m[0907 10-44-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36155, current rewards: -2408.81851, mean: -1.70838
[32m[0907 10-44-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36125, current rewards: -2463.70389, mean: -1.68747
[32m[0907 10-45-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36095, current rewards: -2535.25894, mean: -1.67898
[32m[0907 10-45-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36069, current rewards: -2595.76149, mean: -1.66395
[32m[0907 10-45-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36044, current rewards: -2650.60759, mean: -1.64634
[32m[0907 10-46-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36197, current rewards: -2726.04260, mean: -1.64219
[32m[0907 10-46-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36300, current rewards: -2793.26100, mean: -1.63349
[32m[0907 10-46-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36387, current rewards: -2861.80597, mean: -1.62603
[32m[0907 10-47-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36491, current rewards: -2942.23311, mean: -1.62554
[32m[0907 10-47-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36650, current rewards: -3008.47934, mean: -1.61746
[32m[0907 10-47-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36744, current rewards: -3090.82418, mean: -1.61823
[32m[0907 10-48-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36807, current rewards: -3190.82418, mean: -1.62797
[32m[0907 10-48-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36868, current rewards: -3290.82418, mean: -1.63723
[32m[0907 10-48-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36881, current rewards: -3390.82418, mean: -1.64603
[32m[0907 10-49-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36885, current rewards: -3490.82418, mean: -1.65442
[32m[0907 10-49-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36913, current rewards: -3590.82418, mean: -1.66242
[32m[0907 10-49-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36982, current rewards: -3690.82418, mean: -1.67006
[32m[0907 10-49-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.37048, current rewards: -3790.82418, mean: -1.67736
[32m[0907 10-50-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.37094, current rewards: -3890.82418, mean: -1.68434
[32m[0907 10-50-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.37047, current rewards: -3990.82418, mean: -1.69103
[32m[0907 10-50-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36993, current rewards: -4090.82418, mean: -1.69744
[32m[0907 10-51-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36941, current rewards: -4190.82418, mean: -1.70359
[32m[0907 10-51-24 @Agent.py:117][0m Average action selection time: 0.3688
[32m[0907 10-51-24 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-51-24 @MBExp.py:227][0m Rewards obtained: [-4270.824184718123], Lows: [2135], Highs: [75], Total time: 69524.01016399999
[32m[0907 10-54-10 @MBExp.py:144][0m ####################################################################
[32m[0907 10-54-10 @MBExp.py:145][0m Starting training iteration 85.
[32m[0907 10-54-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33807, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-54-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31990, current rewards: -19.58606, mean: -0.32643
[32m[0907 10-54-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31856, current rewards: -21.29759, mean: -0.19361
[32m[0907 10-55-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31791, current rewards: -44.33440, mean: -0.27709
[32m[0907 10-55-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31757, current rewards: -44.10587, mean: -0.21003
[32m[0907 10-55-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31731, current rewards: -40.24252, mean: -0.15478
[32m[0907 10-55-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31710, current rewards: -36.54153, mean: -0.11788
[32m[0907 10-56-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31701, current rewards: -32.83909, mean: -0.09122
[32m[0907 10-56-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31690, current rewards: -29.13772, mean: -0.07107
[32m[0907 10-56-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31681, current rewards: -25.43504, mean: -0.05529
[32m[0907 10-56-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31683, current rewards: -43.21421, mean: -0.08473
[32m[0907 10-57-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31744, current rewards: -41.03365, mean: -0.07327
[32m[0907 10-57-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31727, current rewards: -38.19522, mean: -0.06262
[32m[0907 10-57-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31716, current rewards: -35.43323, mean: -0.05369
[32m[0907 10-57-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31700, current rewards: -32.67026, mean: -0.04601
[32m[0907 10-58-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31728, current rewards: -52.51653, mean: -0.06910
[32m[0907 10-58-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31739, current rewards: -129.05202, mean: -0.15932
[32m[0907 10-58-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31735, current rewards: -153.81551, mean: -0.17886
[32m[0907 10-58-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31726, current rewards: -147.11155, mean: -0.16166
[32m[0907 10-59-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31821, current rewards: -185.29797, mean: -0.19302
[32m[0907 10-59-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31869, current rewards: -199.47931, mean: -0.19750
[32m[0907 10-59-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31936, current rewards: -235.97944, mean: -0.22262
[32m[0907 11-00-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31996, current rewards: -263.01566, mean: -0.23695
[32m[0907 11-00-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32004, current rewards: -293.72773, mean: -0.25321
[32m[0907 11-00-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32097, current rewards: -325.20259, mean: -0.26876
[32m[0907 11-00-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32174, current rewards: -368.43500, mean: -0.29241
[32m[0907 11-01-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32244, current rewards: -398.49325, mean: -0.30419
[32m[0907 11-01-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32317, current rewards: -411.23057, mean: -0.30238
[32m[0907 11-01-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32369, current rewards: -464.59636, mean: -0.32950
[32m[0907 11-02-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32405, current rewards: -502.07414, mean: -0.34389
[32m[0907 11-02-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32373, current rewards: -514.06180, mean: -0.34044
[32m[0907 11-02-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32324, current rewards: -506.22042, mean: -0.32450
[32m[0907 11-02-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32274, current rewards: -500.38839, mean: -0.31080
[32m[0907 11-03-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32228, current rewards: -494.57068, mean: -0.29793
[32m[0907 11-03-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32184, current rewards: -488.74888, mean: -0.28582
[32m[0907 11-03-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32143, current rewards: -483.27034, mean: -0.27459
[32m[0907 11-03-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32105, current rewards: -478.20370, mean: -0.26420
[32m[0907 11-04-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32070, current rewards: -472.46821, mean: -0.25402
[32m[0907 11-04-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32036, current rewards: -466.73504, mean: -0.24436
[32m[0907 11-04-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32003, current rewards: -461.00000, mean: -0.23520
[32m[0907 11-04-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31972, current rewards: -455.26303, mean: -0.22650
[32m[0907 11-05-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31947, current rewards: -449.53202, mean: -0.21822
[32m[0907 11-05-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31966, current rewards: -519.20013, mean: -0.24607
[32m[0907 11-05-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32011, current rewards: -576.82425, mean: -0.26705
[32m[0907 11-05-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32032, current rewards: -633.06665, mean: -0.28646
[32m[0907 11-06-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32035, current rewards: -713.13600, mean: -0.31555
[32m[0907 11-06-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32008, current rewards: -758.40841, mean: -0.32832
[32m[0907 11-06-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32043, current rewards: -791.97253, mean: -0.33558
[32m[0907 11-07-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32075, current rewards: -842.43822, mean: -0.34956
[32m[0907 11-07-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32044, current rewards: -881.15766, mean: -0.35819
[32m[0907 11-07-31 @Agent.py:117][0m Average action selection time: 0.3201
[32m[0907 11-07-31 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-07-31 @MBExp.py:227][0m Rewards obtained: [-876.9990426755916], Lows: [519], Highs: [89], Total time: 70324.989924
[32m[0907 11-10-08 @MBExp.py:144][0m ####################################################################
[32m[0907 11-10-08 @MBExp.py:145][0m Starting training iteration 86.
[32m[0907 11-10-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30897, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-10-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31592, current rewards: -71.59493, mean: -1.19325
[32m[0907 11-10-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31879, current rewards: -123.88867, mean: -1.12626
[32m[0907 11-10-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31810, current rewards: -176.46917, mean: -1.10293
[32m[0907 11-11-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31753, current rewards: -246.88302, mean: -1.17563
[32m[0907 11-11-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31945, current rewards: -316.43372, mean: -1.21705
[32m[0907 11-11-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31997, current rewards: -378.14495, mean: -1.21982
[32m[0907 11-12-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32042, current rewards: -420.35358, mean: -1.16765
[32m[0907 11-12-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32087, current rewards: -476.99998, mean: -1.16341
[32m[0907 11-12-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32056, current rewards: -540.47545, mean: -1.17495
[32m[0907 11-12-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32099, current rewards: -587.99203, mean: -1.15293
[32m[0907 11-13-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32146, current rewards: -687.99203, mean: -1.22856
[32m[0907 11-13-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32108, current rewards: -783.14713, mean: -1.28385
[32m[0907 11-13-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32125, current rewards: -880.66744, mean: -1.33434
[32m[0907 11-13-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32116, current rewards: -972.86384, mean: -1.37023
[32m[0907 11-14-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32102, current rewards: -1059.89911, mean: -1.39460
[32m[0907 11-14-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32118, current rewards: -1146.41973, mean: -1.41533
[32m[0907 11-14-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32144, current rewards: -1238.45642, mean: -1.44007
[32m[0907 11-15-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32123, current rewards: -1320.50566, mean: -1.45111
[32m[0907 11-15-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32112, current rewards: -1410.19530, mean: -1.46895
[32m[0907 11-15-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32116, current rewards: -1495.84873, mean: -1.48104
[32m[0907 11-15-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32130, current rewards: -1584.98737, mean: -1.49527
[32m[0907 11-16-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32102, current rewards: -1598.34945, mean: -1.43995
[32m[0907 11-16-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32076, current rewards: -1592.30791, mean: -1.37268
[32m[0907 11-16-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32056, current rewards: -1586.54603, mean: -1.31120
[32m[0907 11-16-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32038, current rewards: -1580.78734, mean: -1.25459
[32m[0907 11-17-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32020, current rewards: -1575.03193, mean: -1.20231
[32m[0907 11-17-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31999, current rewards: -1569.27574, mean: -1.15388
[32m[0907 11-17-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31985, current rewards: -1564.95819, mean: -1.10990
[32m[0907 11-17-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31971, current rewards: -1558.66209, mean: -1.06758
[32m[0907 11-18-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31957, current rewards: -1567.05466, mean: -1.03778
[32m[0907 11-18-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31946, current rewards: -1610.68304, mean: -1.03249
[32m[0907 11-18-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31913, current rewards: -1606.90708, mean: -0.99808
[32m[0907 11-18-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31881, current rewards: -1603.60657, mean: -0.96603
[32m[0907 11-19-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31850, current rewards: -1600.31591, mean: -0.93586
[32m[0907 11-19-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31821, current rewards: -1597.02137, mean: -0.90740
[32m[0907 11-19-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31792, current rewards: -1593.72790, mean: -0.88051
[32m[0907 11-20-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31767, current rewards: -1590.43422, mean: -0.85507
[32m[0907 11-20-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31742, current rewards: -1587.14105, mean: -0.83096
[32m[0907 11-20-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31718, current rewards: -1583.84668, mean: -0.80809
[32m[0907 11-20-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31697, current rewards: -1580.55316, mean: -0.78634
[32m[0907 11-21-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31675, current rewards: -1577.25959, mean: -0.76566
[32m[0907 11-21-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31676, current rewards: -1573.96661, mean: -0.74596
[32m[0907 11-21-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31672, current rewards: -1570.67344, mean: -0.72716
[32m[0907 11-21-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31668, current rewards: -1567.50198, mean: -0.70928
[32m[0907 11-22-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31676, current rewards: -1575.94838, mean: -0.69732
[32m[0907 11-22-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31715, current rewards: -1624.21036, mean: -0.70312
[32m[0907 11-22-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31708, current rewards: -1682.35608, mean: -0.71286
[32m[0907 11-22-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31690, current rewards: -1676.90251, mean: -0.69581
[32m[0907 11-23-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31672, current rewards: -1672.19512, mean: -0.67975
[32m[0907 11-23-20 @Agent.py:117][0m Average action selection time: 0.3166
[32m[0907 11-23-20 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-23-21 @MBExp.py:227][0m Rewards obtained: [-1668.4375345859635], Lows: [915], Highs: [42], Total time: 71117.191788
[32m[0907 11-26-00 @MBExp.py:144][0m ####################################################################
[32m[0907 11-26-00 @MBExp.py:145][0m Starting training iteration 87.
[32m[0907 11-26-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29763, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-26-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29947, current rewards: -52.49963, mean: -0.87499
[32m[0907 11-26-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30433, current rewards: -83.73211, mean: -0.76120
[32m[0907 11-26-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30838, current rewards: -111.91634, mean: -0.69948
[32m[0907 11-27-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31028, current rewards: -139.47001, mean: -0.66414
[32m[0907 11-27-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31151, current rewards: -178.17135, mean: -0.68527
[32m[0907 11-27-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31252, current rewards: -199.26710, mean: -0.64280
[32m[0907 11-27-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31313, current rewards: -215.16038, mean: -0.59767
[32m[0907 11-28-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31358, current rewards: -236.98369, mean: -0.57801
[32m[0907 11-28-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31374, current rewards: -256.80212, mean: -0.55827
[32m[0907 11-28-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31391, current rewards: -274.62460, mean: -0.53848
[32m[0907 11-28-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31410, current rewards: -290.78266, mean: -0.51925
[32m[0907 11-29-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31419, current rewards: -322.46948, mean: -0.52864
[32m[0907 11-29-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31430, current rewards: -347.88805, mean: -0.52710
[32m[0907 11-29-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31449, current rewards: -371.24973, mean: -0.52289
[32m[0907 11-29-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31460, current rewards: -393.60530, mean: -0.51790
[32m[0907 11-30-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31464, current rewards: -414.91925, mean: -0.51225
[32m[0907 11-30-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31467, current rewards: -439.42221, mean: -0.51096
[32m[0907 11-30-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31475, current rewards: -463.90708, mean: -0.50979
[32m[0907 11-31-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31485, current rewards: -489.42974, mean: -0.50982
[32m[0907 11-31-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31490, current rewards: -511.75965, mean: -0.50669
[32m[0907 11-31-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31512, current rewards: -563.84746, mean: -0.53193
[32m[0907 11-31-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31527, current rewards: -654.69537, mean: -0.58982
[32m[0907 11-32-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31530, current rewards: -746.14427, mean: -0.64323
[32m[0907 11-32-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31526, current rewards: -799.09784, mean: -0.66041
[32m[0907 11-32-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31522, current rewards: -795.82117, mean: -0.63160
[32m[0907 11-32-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31518, current rewards: -785.27192, mean: -0.59944
[32m[0907 11-33-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31516, current rewards: -780.59749, mean: -0.57397
[32m[0907 11-33-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31517, current rewards: -773.72716, mean: -0.54874
[32m[0907 11-33-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31516, current rewards: -766.90545, mean: -0.52528
[32m[0907 11-33-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31515, current rewards: -760.08868, mean: -0.50337
[32m[0907 11-34-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31491, current rewards: -781.07213, mean: -0.50069
[32m[0907 11-34-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31469, current rewards: -790.68963, mean: -0.49111
[32m[0907 11-34-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31449, current rewards: -792.52761, mean: -0.47743
[32m[0907 11-34-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31428, current rewards: -767.80222, mean: -0.44901
[32m[0907 11-35-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31410, current rewards: -751.50305, mean: -0.42699
[32m[0907 11-35-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31393, current rewards: -744.14211, mean: -0.41113
[32m[0907 11-35-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31376, current rewards: -730.94483, mean: -0.39298
[32m[0907 11-35-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31358, current rewards: -721.15354, mean: -0.37757
[32m[0907 11-36-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31345, current rewards: -717.65637, mean: -0.36615
[32m[0907 11-36-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31331, current rewards: -714.53239, mean: -0.35549
[32m[0907 11-36-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31322, current rewards: -708.10851, mean: -0.34374
[32m[0907 11-37-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31351, current rewards: -754.41787, mean: -0.35754
[32m[0907 11-37-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31384, current rewards: -787.46100, mean: -0.36457
[32m[0907 11-37-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31387, current rewards: -865.74881, mean: -0.39174
[32m[0907 11-37-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31427, current rewards: -916.16075, mean: -0.40538
[32m[0907 11-38-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31434, current rewards: -921.78535, mean: -0.39904
[32m[0907 11-38-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31437, current rewards: -917.24759, mean: -0.38866
[32m[0907 11-38-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31431, current rewards: -912.89167, mean: -0.37879
[32m[0907 11-38-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31420, current rewards: -908.57837, mean: -0.36934
[32m[0907 11-39-06 @Agent.py:117][0m Average action selection time: 0.3141
[32m[0907 11-39-06 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-39-06 @MBExp.py:227][0m Rewards obtained: [-905.132381575012], Lows: [373], Highs: [510], Total time: 71903.156422
[32m[0907 11-41-46 @MBExp.py:144][0m ####################################################################
[32m[0907 11-41-46 @MBExp.py:145][0m Starting training iteration 88.
[32m[0907 11-41-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30040, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-42-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30087, current rewards: -52.48642, mean: -0.87477
[32m[0907 11-42-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30512, current rewards: -102.48642, mean: -0.93169
[32m[0907 11-42-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30850, current rewards: -152.48642, mean: -0.95304
[32m[0907 11-42-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31041, current rewards: -202.48642, mean: -0.96422
[32m[0907 11-43-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31134, current rewards: -252.48642, mean: -0.97110
[32m[0907 11-43-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31438, current rewards: -302.48642, mean: -0.97576
[32m[0907 11-43-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31966, current rewards: -352.48642, mean: -0.97913
[32m[0907 11-43-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32423, current rewards: -399.23808, mean: -0.97375
[32m[0907 11-44-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32755, current rewards: -449.23808, mean: -0.97660
[32m[0907 11-44-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32997, current rewards: -492.87943, mean: -0.96643
[32m[0907 11-44-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33330, current rewards: -510.14155, mean: -0.91097
[32m[0907 11-45-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33506, current rewards: -545.70906, mean: -0.89461
[32m[0907 11-45-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33682, current rewards: -590.88273, mean: -0.89528
[32m[0907 11-45-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33866, current rewards: -640.88273, mean: -0.90265
[32m[0907 11-46-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34024, current rewards: -690.88273, mean: -0.90906
[32m[0907 11-46-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34157, current rewards: -740.88273, mean: -0.91467
[32m[0907 11-46-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34278, current rewards: -790.88273, mean: -0.91963
[32m[0907 11-46-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34380, current rewards: -840.88273, mean: -0.92405
[32m[0907 11-47-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34452, current rewards: -890.88273, mean: -0.92800
[32m[0907 11-47-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34563, current rewards: -940.88273, mean: -0.93157
[32m[0907 11-47-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34655, current rewards: -990.88273, mean: -0.93480
[32m[0907 11-48-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34725, current rewards: -1040.88273, mean: -0.93773
[32m[0907 11-48-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34777, current rewards: -1090.88273, mean: -0.94042
[32m[0907 11-48-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34817, current rewards: -1140.88273, mean: -0.94288
[32m[0907 11-49-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34853, current rewards: -1190.88273, mean: -0.94515
[32m[0907 11-49-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34878, current rewards: -1240.88273, mean: -0.94724
[32m[0907 11-49-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34891, current rewards: -1290.88273, mean: -0.94918
[32m[0907 11-49-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34902, current rewards: -1340.88273, mean: -0.95098
[32m[0907 11-50-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34907, current rewards: -1356.69243, mean: -0.92924
[32m[0907 11-50-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34901, current rewards: -1351.54678, mean: -0.89506
[32m[0907 11-50-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34883, current rewards: -1346.40113, mean: -0.86308
[32m[0907 11-51-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34866, current rewards: -1341.25548, mean: -0.83308
[32m[0907 11-51-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34853, current rewards: -1336.10983, mean: -0.80489
[32m[0907 11-51-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34838, current rewards: -1331.98838, mean: -0.77894
[32m[0907 11-52-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34826, current rewards: -1329.02821, mean: -0.75513
[32m[0907 11-52-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34814, current rewards: -1326.06804, mean: -0.73263
[32m[0907 11-52-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34803, current rewards: -1323.10787, mean: -0.71135
[32m[0907 11-52-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34795, current rewards: -1320.14770, mean: -0.69118
[32m[0907 11-53-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34785, current rewards: -1317.18754, mean: -0.67203
[32m[0907 11-53-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34777, current rewards: -1357.65471, mean: -0.67545
[32m[0907 11-53-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34785, current rewards: -1407.65471, mean: -0.68333
[32m[0907 11-54-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34796, current rewards: -1457.65471, mean: -0.69083
[32m[0907 11-54-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34807, current rewards: -1507.65471, mean: -0.69799
[32m[0907 11-54-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34817, current rewards: -1557.65471, mean: -0.70482
[32m[0907 11-54-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34830, current rewards: -1607.65471, mean: -0.71135
[32m[0907 11-55-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34838, current rewards: -1657.65471, mean: -0.71760
[32m[0907 11-55-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34847, current rewards: -1672.35835, mean: -0.70863
[32m[0907 11-55-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34844, current rewards: -1668.87901, mean: -0.69248
[32m[0907 11-56-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34834, current rewards: -1665.39968, mean: -0.67699
[32m[0907 11-56-18 @Agent.py:117][0m Average action selection time: 0.3483
[32m[0907 11-56-18 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-56-18 @MBExp.py:227][0m Rewards obtained: [-1662.6246189879676], Lows: [16], Highs: [1696], Total time: 72774.616481
[32m[0907 11-59-15 @MBExp.py:144][0m ####################################################################
[32m[0907 11-59-15 @MBExp.py:145][0m Starting training iteration 89.
[32m[0907 11-59-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.43164, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-59-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37262, current rewards: -82.91028, mean: -1.38184
[32m[0907 11-59-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36857, current rewards: -102.99745, mean: -0.93634
[32m[0907 12-00-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36925, current rewards: -118.76794, mean: -0.74230
[32m[0907 12-00-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37447, current rewards: -191.40120, mean: -0.91143
[32m[0907 12-00-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37122, current rewards: -203.84052, mean: -0.78400
[32m[0907 12-01-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36993, current rewards: -231.16553, mean: -0.74570
[32m[0907 12-01-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36764, current rewards: -246.58299, mean: -0.68495
[32m[0907 12-01-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36720, current rewards: -253.53238, mean: -0.61837
[32m[0907 12-02-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36564, current rewards: -249.04962, mean: -0.54141
[32m[0907 12-02-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36448, current rewards: -244.53892, mean: -0.47949
[32m[0907 12-02-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36344, current rewards: -240.93294, mean: -0.43024
[32m[0907 12-02-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36264, current rewards: -237.69657, mean: -0.38967
[32m[0907 12-03-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36175, current rewards: -234.34570, mean: -0.35507
[32m[0907 12-03-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36116, current rewards: -230.99368, mean: -0.32534
[32m[0907 12-03-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36069, current rewards: -227.64096, mean: -0.29953
[32m[0907 12-04-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35918, current rewards: -263.56286, mean: -0.32539
[32m[0907 12-04-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35667, current rewards: -266.06753, mean: -0.30938
[32m[0907 12-04-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35459, current rewards: -304.18966, mean: -0.33427
[32m[0907 12-04-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35271, current rewards: -330.90100, mean: -0.34469
[32m[0907 12-05-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35088, current rewards: -371.60429, mean: -0.36793
[32m[0907 12-05-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34921, current rewards: -421.60429, mean: -0.39774
[32m[0907 12-05-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34764, current rewards: -471.60429, mean: -0.42487
[32m[0907 12-05-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34626, current rewards: -521.60429, mean: -0.44966
[32m[0907 12-06-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34497, current rewards: -571.60429, mean: -0.47240
[32m[0907 12-06-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34375, current rewards: -621.60429, mean: -0.49334
[32m[0907 12-06-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34268, current rewards: -671.60429, mean: -0.51268
[32m[0907 12-07-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34170, current rewards: -721.60429, mean: -0.53059
[32m[0907 12-07-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34073, current rewards: -771.60429, mean: -0.54724
[32m[0907 12-07-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33997, current rewards: -799.68440, mean: -0.54773
[32m[0907 12-07-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33915, current rewards: -839.13827, mean: -0.55572
[32m[0907 12-08-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33817, current rewards: -877.74665, mean: -0.56266
[32m[0907 12-08-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33750, current rewards: -921.41517, mean: -0.57231
[32m[0907 12-08-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33710, current rewards: -970.35623, mean: -0.58455
[32m[0907 12-08-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33630, current rewards: -1019.29284, mean: -0.59608
[32m[0907 12-09-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33588, current rewards: -1067.14146, mean: -0.60633
[32m[0907 12-09-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33611, current rewards: -1116.01139, mean: -0.61658
[32m[0907 12-09-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33578, current rewards: -1158.58722, mean: -0.62290
[32m[0907 12-09-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33573, current rewards: -1204.35158, mean: -0.63055
[32m[0907 12-10-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33591, current rewards: -1225.40752, mean: -0.62521
[32m[0907 12-10-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33595, current rewards: -1288.63771, mean: -0.64111
[32m[0907 12-10-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33664, current rewards: -1331.41237, mean: -0.64632
[32m[0907 12-11-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33652, current rewards: -1365.79225, mean: -0.64729
[32m[0907 12-11-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33614, current rewards: -1395.07345, mean: -0.64587
[32m[0907 12-11-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33685, current rewards: -1420.38949, mean: -0.64271
[32m[0907 12-11-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33660, current rewards: -1448.55494, mean: -0.64095
[32m[0907 12-12-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33612, current rewards: -1476.03761, mean: -0.63898
[32m[0907 12-12-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33573, current rewards: -1507.04863, mean: -0.63858
[32m[0907 12-12-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33515, current rewards: -1555.79650, mean: -0.64556
[32m[0907 12-12-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33460, current rewards: -1605.79650, mean: -0.65276
[32m[0907 12-13-11 @Agent.py:117][0m Average action selection time: 0.3341
[32m[0907 12-13-11 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-13-11 @MBExp.py:227][0m Rewards obtained: [-1645.7965024540615], Lows: [158], Highs: [1413], Total time: 73610.574084
[32m[0907 12-15-56 @MBExp.py:144][0m ####################################################################
[32m[0907 12-15-56 @MBExp.py:145][0m Starting training iteration 90.
[32m[0907 12-15-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30774, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-16-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31819, current rewards: -71.01713, mean: -1.18362
[32m[0907 12-16-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32599, current rewards: -168.89122, mean: -1.53537
[32m[0907 12-16-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32708, current rewards: -266.62383, mean: -1.66640
[32m[0907 12-17-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32935, current rewards: -359.30345, mean: -1.71097
[32m[0907 12-17-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33118, current rewards: -456.71252, mean: -1.75659
[32m[0907 12-17-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33340, current rewards: -549.59303, mean: -1.77288
[32m[0907 12-17-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33183, current rewards: -645.31085, mean: -1.79253
[32m[0907 12-18-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33103, current rewards: -740.81248, mean: -1.80686
[32m[0907 12-18-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33132, current rewards: -836.08468, mean: -1.81758
[32m[0907 12-18-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33177, current rewards: -929.04554, mean: -1.82166
[32m[0907 12-19-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33198, current rewards: -1021.76730, mean: -1.82458
[32m[0907 12-19-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33130, current rewards: -1119.40123, mean: -1.83508
[32m[0907 12-19-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33009, current rewards: -1219.40123, mean: -1.84758
[32m[0907 12-19-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32908, current rewards: -1319.40123, mean: -1.85831
[32m[0907 12-20-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32846, current rewards: -1419.40123, mean: -1.86763
[32m[0907 12-20-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32778, current rewards: -1519.40123, mean: -1.87580
[32m[0907 12-20-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32798, current rewards: -1608.19936, mean: -1.87000
[32m[0907 12-20-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32728, current rewards: -1708.19936, mean: -1.87714
[32m[0907 12-21-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32691, current rewards: -1808.19936, mean: -1.88354
[32m[0907 12-21-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32719, current rewards: -1905.90037, mean: -1.88703
[32m[0907 12-21-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32683, current rewards: -2005.90037, mean: -1.89236
[32m[0907 12-21-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32634, current rewards: -2101.67954, mean: -1.89340
[32m[0907 12-22-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32592, current rewards: -2177.62012, mean: -1.87726
[32m[0907 12-22-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32563, current rewards: -2238.06008, mean: -1.84964
[32m[0907 12-22-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32524, current rewards: -2299.25630, mean: -1.82481
[32m[0907 12-23-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32485, current rewards: -2360.81035, mean: -1.80215
[32m[0907 12-23-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32451, current rewards: -2428.33568, mean: -1.78554
[32m[0907 12-23-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32415, current rewards: -2489.15643, mean: -1.76536
[32m[0907 12-23-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32377, current rewards: -2564.05661, mean: -1.75620
[32m[0907 12-24-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32324, current rewards: -2635.99226, mean: -1.74569
[32m[0907 12-24-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32274, current rewards: -2713.46935, mean: -1.73940
[32m[0907 12-24-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32235, current rewards: -2775.98630, mean: -1.72422
[32m[0907 12-24-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32197, current rewards: -2844.29328, mean: -1.71343
[32m[0907 12-25-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32157, current rewards: -2914.12487, mean: -1.70417
[32m[0907 12-25-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32119, current rewards: -2997.05066, mean: -1.70287
[32m[0907 12-25-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32082, current rewards: -3094.20021, mean: -1.70950
[32m[0907 12-25-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32053, current rewards: -3189.20258, mean: -1.71463
[32m[0907 12-26-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32020, current rewards: -3286.87481, mean: -1.72088
[32m[0907 12-26-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31987, current rewards: -3381.37723, mean: -1.72519
[32m[0907 12-26-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31966, current rewards: -3476.03454, mean: -1.72937
[32m[0907 12-26-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31958, current rewards: -3536.27833, mean: -1.71664
[32m[0907 12-27-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31946, current rewards: -3593.41532, mean: -1.70304
[32m[0907 12-27-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31937, current rewards: -3646.45373, mean: -1.68817
[32m[0907 12-27-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31929, current rewards: -3696.66349, mean: -1.67270
[32m[0907 12-27-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31922, current rewards: -3747.25420, mean: -1.65808
[32m[0907 12-28-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31904, current rewards: -3798.06604, mean: -1.64418
[32m[0907 12-28-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31880, current rewards: -3846.70472, mean: -1.62996
[32m[0907 12-28-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31862, current rewards: -3888.48372, mean: -1.61348
[32m[0907 12-28-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31833, current rewards: -3959.53760, mean: -1.60957
[32m[0907 12-29-11 @Agent.py:117][0m Average action selection time: 0.3180
[32m[0907 12-29-11 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-29-11 @MBExp.py:227][0m Rewards obtained: [-4030.7880444232596], Lows: [2037], Highs: [43], Total time: 74406.332989
[32m[0907 12-31-58 @MBExp.py:144][0m ####################################################################
[32m[0907 12-31-58 @MBExp.py:145][0m Starting training iteration 91.
[32m[0907 12-32-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33244, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-32-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31973, current rewards: -95.77275, mean: -1.59621
[32m[0907 12-32-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31836, current rewards: -193.64098, mean: -1.76037
[32m[0907 12-32-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31773, current rewards: -286.53049, mean: -1.79082
[32m[0907 12-33-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31836, current rewards: -382.30124, mean: -1.82048
[32m[0907 12-33-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31911, current rewards: -477.89247, mean: -1.83805
[32m[0907 12-33-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31847, current rewards: -571.15083, mean: -1.84242
[32m[0907 12-33-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31913, current rewards: -671.15083, mean: -1.86431
[32m[0907 12-34-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32284, current rewards: -746.13442, mean: -1.81984
[32m[0907 12-34-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32983, current rewards: -833.04182, mean: -1.81096
[32m[0907 12-34-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33513, current rewards: -918.94800, mean: -1.80186
[32m[0907 12-35-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33897, current rewards: -1007.27439, mean: -1.79870
[32m[0907 12-35-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34303, current rewards: -1094.12664, mean: -1.79365
[32m[0907 12-35-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34526, current rewards: -1187.57571, mean: -1.79936
[32m[0907 12-36-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34847, current rewards: -1280.67907, mean: -1.80377
[32m[0907 12-36-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34854, current rewards: -1378.49624, mean: -1.81381
[32m[0907 12-36-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34725, current rewards: -1475.82956, mean: -1.82201
[32m[0907 12-36-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34610, current rewards: -1575.82956, mean: -1.83236
[32m[0907 12-37-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34434, current rewards: -1675.82956, mean: -1.84157
[32m[0907 12-37-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34286, current rewards: -1775.82956, mean: -1.84982
[32m[0907 12-37-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34340, current rewards: -1856.77982, mean: -1.83840
[32m[0907 12-38-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34212, current rewards: -1943.43925, mean: -1.83343
[32m[0907 12-38-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34090, current rewards: -2027.63741, mean: -1.82670
[32m[0907 12-38-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33978, current rewards: -2127.63741, mean: -1.83417
[32m[0907 12-38-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33873, current rewards: -2227.63741, mean: -1.84102
[32m[0907 12-39-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33776, current rewards: -2327.63741, mean: -1.84733
[32m[0907 12-39-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33689, current rewards: -2427.63741, mean: -1.85316
[32m[0907 12-39-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33593, current rewards: -2527.63741, mean: -1.85856
[32m[0907 12-39-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33495, current rewards: -2627.63741, mean: -1.86357
[32m[0907 12-40-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33401, current rewards: -2727.63741, mean: -1.86824
[32m[0907 12-40-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33314, current rewards: -2827.63741, mean: -1.87261
[32m[0907 12-40-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33232, current rewards: -2927.63741, mean: -1.87669
[32m[0907 12-40-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33156, current rewards: -3027.63741, mean: -1.88052
[32m[0907 12-41-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33085, current rewards: -3127.63741, mean: -1.88412
[32m[0907 12-41-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33018, current rewards: -3227.63741, mean: -1.88751
[32m[0907 12-41-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32954, current rewards: -3327.63741, mean: -1.89070
[32m[0907 12-41-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32893, current rewards: -3427.63741, mean: -1.89372
[32m[0907 12-42-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32836, current rewards: -3527.63741, mean: -1.89658
[32m[0907 12-42-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32788, current rewards: -3627.63741, mean: -1.89929
[32m[0907 12-42-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32758, current rewards: -3727.63741, mean: -1.90186
[32m[0907 12-42-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32728, current rewards: -3827.63741, mean: -1.90430
[32m[0907 12-43-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32699, current rewards: -3927.63741, mean: -1.90662
[32m[0907 12-43-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32669, current rewards: -4027.63741, mean: -1.90883
[32m[0907 12-43-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32642, current rewards: -4127.63741, mean: -1.91094
[32m[0907 12-43-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32616, current rewards: -4227.63741, mean: -1.91296
[32m[0907 12-44-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32576, current rewards: -4327.63741, mean: -1.91488
[32m[0907 12-44-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32535, current rewards: -4427.63741, mean: -1.91673
[32m[0907 12-44-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32493, current rewards: -4527.63741, mean: -1.91849
[32m[0907 12-45-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32437, current rewards: -4627.63741, mean: -1.92018
[32m[0907 12-45-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32372, current rewards: -4727.63741, mean: -1.92180
[32m[0907 12-45-27 @Agent.py:117][0m Average action selection time: 0.3232
[32m[0907 12-45-27 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-45-27 @MBExp.py:227][0m Rewards obtained: [-4807.63740864971], Lows: [2393], Highs: [39], Total time: 75214.964193
[32m[0907 12-48-16 @MBExp.py:144][0m ####################################################################
[32m[0907 12-48-16 @MBExp.py:145][0m Starting training iteration 92.
[32m[0907 12-48-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.52451, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-48-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35428, current rewards: -56.25555, mean: -0.93759
[32m[0907 12-48-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33880, current rewards: -102.04274, mean: -0.92766
[32m[0907 12-49-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33515, current rewards: -147.81190, mean: -0.92382
[32m[0907 12-49-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33152, current rewards: -197.81190, mean: -0.94196
[32m[0907 12-49-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32879, current rewards: -247.81190, mean: -0.95312
[32m[0907 12-49-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32665, current rewards: -297.81190, mean: -0.96068
[32m[0907 12-50-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32894, current rewards: -344.66111, mean: -0.95739
[32m[0907 12-50-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32860, current rewards: -388.13636, mean: -0.94667
[32m[0907 12-50-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32810, current rewards: -434.29987, mean: -0.94413
[32m[0907 12-51-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32761, current rewards: -480.83235, mean: -0.94281
[32m[0907 12-51-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32698, current rewards: -525.41955, mean: -0.93825
[32m[0907 12-51-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32691, current rewards: -570.16461, mean: -0.93470
[32m[0907 12-51-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32629, current rewards: -615.83292, mean: -0.93308
[32m[0907 12-52-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32576, current rewards: -660.52990, mean: -0.93032
[32m[0907 12-52-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32582, current rewards: -708.43147, mean: -0.93215
[32m[0907 12-52-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32694, current rewards: -760.47297, mean: -0.93886
[32m[0907 12-52-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32688, current rewards: -806.08540, mean: -0.93731
[32m[0907 12-53-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32656, current rewards: -852.86717, mean: -0.93722
[32m[0907 12-53-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32681, current rewards: -896.53892, mean: -0.93389
[32m[0907 12-53-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32675, current rewards: -941.24475, mean: -0.93193
[32m[0907 12-54-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32686, current rewards: -991.24475, mean: -0.93514
[32m[0907 12-54-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32666, current rewards: -1041.24475, mean: -0.93806
[32m[0907 12-54-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32667, current rewards: -1087.75439, mean: -0.93772
[32m[0907 12-54-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32826, current rewards: -1131.07922, mean: -0.93478
[32m[0907 12-55-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32781, current rewards: -1172.80963, mean: -0.93080
[32m[0907 12-55-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32734, current rewards: -1214.11367, mean: -0.92680
[32m[0907 12-55-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32694, current rewards: -1260.76709, mean: -0.92703
[32m[0907 12-55-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32670, current rewards: -1310.66452, mean: -0.92955
[32m[0907 12-56-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32630, current rewards: -1344.56871, mean: -0.92094
[32m[0907 12-56-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32566, current rewards: -1350.28743, mean: -0.89423
[32m[0907 12-56-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32513, current rewards: -1358.18627, mean: -0.87063
[32m[0907 12-56-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32457, current rewards: -1371.66350, mean: -0.85196
[32m[0907 12-57-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32405, current rewards: -1377.43859, mean: -0.82978
[32m[0907 12-57-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32374, current rewards: -1383.02976, mean: -0.80879
[32m[0907 12-57-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32329, current rewards: -1389.90461, mean: -0.78972
[32m[0907 12-58-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32325, current rewards: -1408.05429, mean: -0.77793
[32m[0907 12-58-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32282, current rewards: -1457.00011, mean: -0.78333
[32m[0907 12-58-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32260, current rewards: -1504.89289, mean: -0.78790
[32m[0907 12-58-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32242, current rewards: -1552.78853, mean: -0.79224
[32m[0907 12-59-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32226, current rewards: -1598.54792, mean: -0.79530
[32m[0907 12-59-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32218, current rewards: -1644.33795, mean: -0.79822
[32m[0907 12-59-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32209, current rewards: -1687.99953, mean: -0.80000
[32m[0907 12-59-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32188, current rewards: -1733.78848, mean: -0.80268
[32m[0907 13-00-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32158, current rewards: -1778.51614, mean: -0.80476
[32m[0907 13-00-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32137, current rewards: -1828.26090, mean: -0.80897
[32m[0907 13-00-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32110, current rewards: -1859.99380, mean: -0.80519
[32m[0907 13-00-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32066, current rewards: -1853.81612, mean: -0.78552
[32m[0907 13-01-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32008, current rewards: -1856.54673, mean: -0.77035
[32m[0907 13-01-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31949, current rewards: -1906.54673, mean: -0.77502
[32m[0907 13-01-34 @Agent.py:117][0m Average action selection time: 0.3190
[32m[0907 13-01-34 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-01-34 @MBExp.py:227][0m Rewards obtained: [-1946.546731321659], Lows: [71], Highs: [1858], Total time: 76013.300514
[32m[0907 13-04-26 @MBExp.py:144][0m ####################################################################
[32m[0907 13-04-26 @MBExp.py:145][0m Starting training iteration 93.
[32m[0907 13-04-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31714, current rewards: 1.56020, mean: 0.15602
[32m[0907 13-04-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31647, current rewards: 9.44284, mean: 0.15738
[32m[0907 13-05-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31630, current rewards: 17.30238, mean: 0.15729
[32m[0907 13-05-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31629, current rewards: 25.16192, mean: 0.15726
[32m[0907 13-05-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31620, current rewards: 33.02146, mean: 0.15725
[32m[0907 13-05-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31610, current rewards: 38.56662, mean: 0.14833
[32m[0907 13-06-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31605, current rewards: -11.43338, mean: -0.03688
[32m[0907 13-06-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31617, current rewards: -61.43338, mean: -0.17065
[32m[0907 13-06-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31612, current rewards: -111.43338, mean: -0.27179
[32m[0907 13-06-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31605, current rewards: -161.43338, mean: -0.35094
[32m[0907 13-07-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31601, current rewards: -211.43338, mean: -0.41458
[32m[0907 13-07-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31592, current rewards: -261.43338, mean: -0.46685
[32m[0907 13-07-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31849, current rewards: -311.43338, mean: -0.51055
[32m[0907 13-07-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32118, current rewards: -361.43338, mean: -0.54763
[32m[0907 13-08-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32341, current rewards: -411.43338, mean: -0.57948
[32m[0907 13-08-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32539, current rewards: -461.43338, mean: -0.60715
[32m[0907 13-08-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32725, current rewards: -511.43338, mean: -0.63140
[32m[0907 13-09-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32885, current rewards: -561.43338, mean: -0.65283
[32m[0907 13-09-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33030, current rewards: -611.43338, mean: -0.67190
[32m[0907 13-09-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33169, current rewards: -661.43338, mean: -0.68899
[32m[0907 13-10-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33295, current rewards: -711.43338, mean: -0.70439
[32m[0907 13-10-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33421, current rewards: -761.43338, mean: -0.71833
[32m[0907 13-10-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33529, current rewards: -811.43338, mean: -0.73102
[32m[0907 13-10-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33619, current rewards: -861.43338, mean: -0.74261
[32m[0907 13-11-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33714, current rewards: -911.43338, mean: -0.75325
[32m[0907 13-11-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33789, current rewards: -961.43338, mean: -0.76304
[32m[0907 13-11-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33853, current rewards: -1011.43338, mean: -0.77209
[32m[0907 13-12-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33885, current rewards: -1061.43338, mean: -0.78047
[32m[0907 13-12-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33921, current rewards: -1111.43338, mean: -0.78825
[32m[0907 13-12-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33952, current rewards: -1161.43338, mean: -0.79550
[32m[0907 13-12-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33984, current rewards: -1211.43338, mean: -0.80227
[32m[0907 13-13-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34003, current rewards: -1261.43338, mean: -0.80861
[32m[0907 13-13-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34026, current rewards: -1311.43338, mean: -0.81455
[32m[0907 13-13-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34037, current rewards: -1361.43338, mean: -0.82014
[32m[0907 13-14-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34049, current rewards: -1411.43338, mean: -0.82540
[32m[0907 13-14-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34025, current rewards: -1461.43338, mean: -0.83036
[32m[0907 13-14-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33940, current rewards: -1511.43338, mean: -0.83505
[32m[0907 13-14-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33855, current rewards: -1561.43338, mean: -0.83948
[32m[0907 13-15-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33794, current rewards: -1611.43338, mean: -0.84368
[32m[0907 13-15-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33737, current rewards: -1661.43338, mean: -0.84767
[32m[0907 13-15-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33684, current rewards: -1711.43338, mean: -0.85146
[32m[0907 13-15-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33634, current rewards: -1761.43338, mean: -0.85506
[32m[0907 13-16-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33584, current rewards: -1811.43338, mean: -0.85850
[32m[0907 13-16-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33538, current rewards: -1861.43338, mean: -0.86177
[32m[0907 13-16-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33492, current rewards: -1911.43338, mean: -0.86490
[32m[0907 13-17-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33450, current rewards: -1961.43338, mean: -0.86789
[32m[0907 13-17-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33410, current rewards: -2011.43338, mean: -0.87075
[32m[0907 13-17-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33341, current rewards: -2061.43338, mean: -0.87349
[32m[0907 13-17-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33260, current rewards: -2111.43338, mean: -0.87611
[32m[0907 13-18-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33176, current rewards: -2161.43338, mean: -0.87863
[32m[0907 13-18-14 @Agent.py:117][0m Average action selection time: 0.3311
[32m[0907 13-18-14 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-18-14 @MBExp.py:227][0m Rewards obtained: [-2201.4333844995], Lows: [0], Highs: [2242], Total time: 76841.8064
[32m[0907 13-21-08 @MBExp.py:144][0m ####################################################################
[32m[0907 13-21-08 @MBExp.py:145][0m Starting training iteration 94.
[32m[0907 13-21-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33004, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-21-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32650, current rewards: -60.00000, mean: -1.00000
[32m[0907 13-21-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32222, current rewards: -108.75493, mean: -0.98868
[32m[0907 13-22-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35000, current rewards: -158.75493, mean: -0.99222
[32m[0907 13-22-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34871, current rewards: -205.44463, mean: -0.97831
[32m[0907 13-22-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34244, current rewards: -255.44463, mean: -0.98248
[32m[0907 13-22-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33816, current rewards: -346.76942, mean: -1.11861
[32m[0907 13-23-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33516, current rewards: -446.76942, mean: -1.24103
[32m[0907 13-23-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33328, current rewards: -544.57983, mean: -1.32824
[32m[0907 13-23-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33269, current rewards: -637.66143, mean: -1.38622
[32m[0907 13-23-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33230, current rewards: -728.46695, mean: -1.42837
[32m[0907 13-24-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33887, current rewards: -778.57310, mean: -1.39031
[32m[0907 13-24-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33800, current rewards: -839.85544, mean: -1.37681
[32m[0907 13-24-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33853, current rewards: -890.68786, mean: -1.34953
[32m[0907 13-25-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33687, current rewards: -990.68786, mean: -1.39534
[32m[0907 13-25-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33546, current rewards: -1090.68786, mean: -1.43512
[32m[0907 13-25-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33422, current rewards: -1190.68786, mean: -1.46999
[32m[0907 13-25-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33316, current rewards: -1290.68786, mean: -1.50080
[32m[0907 13-26-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33216, current rewards: -1390.68786, mean: -1.52823
[32m[0907 13-26-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33127, current rewards: -1490.68786, mean: -1.55280
[32m[0907 13-26-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33049, current rewards: -1590.68786, mean: -1.57494
[32m[0907 13-26-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32974, current rewards: -1690.68786, mean: -1.59499
[32m[0907 13-27-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32906, current rewards: -1790.68786, mean: -1.61323
[32m[0907 13-27-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32846, current rewards: -1890.68786, mean: -1.62990
[32m[0907 13-27-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32789, current rewards: -1990.68786, mean: -1.64520
[32m[0907 13-28-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32737, current rewards: -2090.68786, mean: -1.65928
[32m[0907 13-28-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32693, current rewards: -2190.68786, mean: -1.67228
[32m[0907 13-28-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32646, current rewards: -2290.68786, mean: -1.68433
[32m[0907 13-28-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32582, current rewards: -2390.68786, mean: -1.69552
[32m[0907 13-29-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32522, current rewards: -2490.68786, mean: -1.70595
[32m[0907 13-29-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32463, current rewards: -2590.68786, mean: -1.71569
[32m[0907 13-29-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32409, current rewards: -2690.68786, mean: -1.72480
[32m[0907 13-29-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32355, current rewards: -2790.68786, mean: -1.73335
[32m[0907 13-30-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32306, current rewards: -2890.68786, mean: -1.74138
[32m[0907 13-30-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32261, current rewards: -2990.68786, mean: -1.74894
[32m[0907 13-30-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32218, current rewards: -3090.68786, mean: -1.75607
[32m[0907 13-30-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32178, current rewards: -3190.68786, mean: -1.76281
[32m[0907 13-31-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32137, current rewards: -3290.68786, mean: -1.76919
[32m[0907 13-31-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32101, current rewards: -3390.68786, mean: -1.77523
[32m[0907 13-31-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32075, current rewards: -3490.68786, mean: -1.78096
[32m[0907 13-31-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32060, current rewards: -3590.68786, mean: -1.78641
[32m[0907 13-32-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32041, current rewards: -3690.68786, mean: -1.79160
[32m[0907 13-32-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32025, current rewards: -3790.68786, mean: -1.79653
[32m[0907 13-32-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32009, current rewards: -3890.68786, mean: -1.80124
[32m[0907 13-32-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31997, current rewards: -3990.68786, mean: -1.80574
[32m[0907 13-33-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31985, current rewards: -4090.68786, mean: -1.81004
[32m[0907 13-33-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31950, current rewards: -4190.68786, mean: -1.81415
[32m[0907 13-33-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31897, current rewards: -4290.68786, mean: -1.81809
[32m[0907 13-33-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31839, current rewards: -4390.68786, mean: -1.82186
[32m[0907 13-34-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31781, current rewards: -4490.68786, mean: -1.82548
[32m[0907 13-34-22 @Agent.py:117][0m Average action selection time: 0.3174
[32m[0907 13-34-22 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-34-22 @MBExp.py:227][0m Rewards obtained: [-4570.687856157665], Lows: [2155], Highs: [273], Total time: 77635.956364
[32m[0907 13-37-18 @MBExp.py:144][0m ####################################################################
[32m[0907 13-37-18 @MBExp.py:145][0m Starting training iteration 95.
[32m[0907 13-37-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.45369, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-37-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37525, current rewards: -82.81078, mean: -1.38018
[32m[0907 13-37-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36345, current rewards: -148.14300, mean: -1.34675
[32m[0907 13-38-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35234, current rewards: -234.94785, mean: -1.46842
[32m[0907 13-38-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34764, current rewards: -326.07616, mean: -1.55274
[32m[0907 13-38-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34572, current rewards: -413.04404, mean: -1.58863
[32m[0907 13-39-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34378, current rewards: -501.51902, mean: -1.61780
[32m[0907 13-39-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34418, current rewards: -586.79119, mean: -1.62998
[32m[0907 13-39-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34321, current rewards: -677.74524, mean: -1.65304
[32m[0907 13-39-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34239, current rewards: -744.41029, mean: -1.61828
[32m[0907 13-40-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34156, current rewards: -818.23451, mean: -1.60438
[32m[0907 13-40-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34159, current rewards: -878.74168, mean: -1.56918
[32m[0907 13-40-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34143, current rewards: -931.87504, mean: -1.52766
[32m[0907 13-41-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34187, current rewards: -970.56080, mean: -1.47055
[32m[0907 13-41-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34190, current rewards: -1008.44836, mean: -1.42035
[32m[0907 13-41-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34395, current rewards: -1077.82257, mean: -1.41819
[32m[0907 13-41-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34314, current rewards: -1123.84499, mean: -1.38746
[32m[0907 13-42-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34279, current rewards: -1183.65668, mean: -1.37634
[32m[0907 13-42-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34280, current rewards: -1216.25699, mean: -1.33655
[32m[0907 13-42-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34157, current rewards: -1284.46196, mean: -1.33798
[32m[0907 13-43-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34019, current rewards: -1384.46196, mean: -1.37075
[32m[0907 13-43-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33894, current rewards: -1484.46196, mean: -1.40044
[32m[0907 13-43-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33779, current rewards: -1584.46196, mean: -1.42744
[32m[0907 13-43-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33680, current rewards: -1684.46196, mean: -1.45212
[32m[0907 13-44-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33588, current rewards: -1784.46196, mean: -1.47476
[32m[0907 13-44-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33503, current rewards: -1884.46196, mean: -1.49560
[32m[0907 13-44-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33419, current rewards: -1984.46196, mean: -1.51486
[32m[0907 13-44-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33322, current rewards: -2084.46196, mean: -1.53269
[32m[0907 13-45-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33232, current rewards: -2184.46196, mean: -1.54926
[32m[0907 13-45-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33147, current rewards: -2284.46196, mean: -1.56470
[32m[0907 13-45-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33068, current rewards: -2384.46196, mean: -1.57911
[32m[0907 13-45-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32994, current rewards: -2484.46196, mean: -1.59260
[32m[0907 13-46-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32923, current rewards: -2584.46196, mean: -1.60526
[32m[0907 13-46-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32858, current rewards: -2684.46196, mean: -1.61715
[32m[0907 13-46-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32795, current rewards: -2784.46196, mean: -1.62834
[32m[0907 13-46-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32738, current rewards: -2884.46196, mean: -1.63890
[32m[0907 13-47-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32683, current rewards: -2984.46196, mean: -1.64887
[32m[0907 13-47-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32630, current rewards: -3084.46196, mean: -1.65831
[32m[0907 13-47-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32590, current rewards: -3184.46196, mean: -1.66726
[32m[0907 13-47-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32562, current rewards: -3284.46196, mean: -1.67575
[32m[0907 13-48-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32536, current rewards: -3384.46196, mean: -1.68381
[32m[0907 13-48-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32509, current rewards: -3484.46196, mean: -1.69149
[32m[0907 13-48-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32481, current rewards: -3584.46196, mean: -1.69880
[32m[0907 13-48-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32457, current rewards: -3684.46196, mean: -1.70577
[32m[0907 13-49-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32433, current rewards: -3784.46196, mean: -1.71243
[32m[0907 13-49-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32378, current rewards: -3884.46196, mean: -1.71879
[32m[0907 13-49-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32306, current rewards: -3984.46196, mean: -1.72488
[32m[0907 13-49-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32236, current rewards: -4084.46196, mean: -1.73070
[32m[0907 13-50-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32169, current rewards: -4184.46196, mean: -1.73629
[32m[0907 13-50-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32104, current rewards: -4284.46196, mean: -1.74165
[32m[0907 13-50-40 @Agent.py:117][0m Average action selection time: 0.3205
[32m[0907 13-50-40 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-50-40 @MBExp.py:227][0m Rewards obtained: [-4364.46195698231], Lows: [2130], Highs: [148], Total time: 78438.066464
[32m[0907 13-53-38 @MBExp.py:144][0m ####################################################################
[32m[0907 13-53-38 @MBExp.py:145][0m Starting training iteration 96.
[32m[0907 13-53-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33923, current rewards: 0.56300, mean: 0.05630
[32m[0907 13-53-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34847, current rewards: -53.65232, mean: -0.89421
[32m[0907 13-54-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34341, current rewards: -153.65232, mean: -1.39684
[32m[0907 13-54-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34294, current rewards: -253.65232, mean: -1.58533
[32m[0907 13-54-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33796, current rewards: -345.24254, mean: -1.64401
[32m[0907 13-55-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33524, current rewards: -414.08295, mean: -1.59263
[32m[0907 13-55-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33376, current rewards: -511.40445, mean: -1.64969
[32m[0907 13-55-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33170, current rewards: -562.12213, mean: -1.56145
[32m[0907 13-55-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33031, current rewards: -647.50152, mean: -1.57927
[32m[0907 13-56-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33182, current rewards: -691.91458, mean: -1.50416
[32m[0907 13-56-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33183, current rewards: -789.38634, mean: -1.54782
[32m[0907 13-56-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33063, current rewards: -889.38634, mean: -1.58819
[32m[0907 13-57-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33074, current rewards: -989.38634, mean: -1.62194
[32m[0907 13-57-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33115, current rewards: -1063.84487, mean: -1.61189
[32m[0907 13-57-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33347, current rewards: -1142.54855, mean: -1.60922
[32m[0907 13-57-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33410, current rewards: -1215.94108, mean: -1.59992
[32m[0907 13-58-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33412, current rewards: -1286.78110, mean: -1.58862
[32m[0907 13-58-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33333, current rewards: -1357.61321, mean: -1.57862
[32m[0907 13-58-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33412, current rewards: -1424.19936, mean: -1.56505
[32m[0907 13-58-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33376, current rewards: -1496.05545, mean: -1.55839
[32m[0907 13-59-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33471, current rewards: -1562.38077, mean: -1.54691
[32m[0907 13-59-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33567, current rewards: -1619.93583, mean: -1.52824
[32m[0907 13-59-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33473, current rewards: -1664.17361, mean: -1.49926
[32m[0907 14-00-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33388, current rewards: -1728.11176, mean: -1.48975
[32m[0907 14-00-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33315, current rewards: -1787.97220, mean: -1.47766
[32m[0907 14-00-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33226, current rewards: -1849.42566, mean: -1.46780
[32m[0907 14-00-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33141, current rewards: -1899.22017, mean: -1.44979
[32m[0907 14-01-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33083, current rewards: -1949.11239, mean: -1.43317
[32m[0907 14-01-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32999, current rewards: -2013.18087, mean: -1.42779
[32m[0907 14-01-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32924, current rewards: -2075.07090, mean: -1.42128
[32m[0907 14-01-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32852, current rewards: -2127.04496, mean: -1.40864
[32m[0907 14-02-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32805, current rewards: -2165.84046, mean: -1.38836
[32m[0907 14-02-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32792, current rewards: -2213.98504, mean: -1.37515
[32m[0907 14-02-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32768, current rewards: -2267.78621, mean: -1.36614
[32m[0907 14-02-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32733, current rewards: -2327.51886, mean: -1.36112
[32m[0907 14-03-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32713, current rewards: -2393.93143, mean: -1.36019
[32m[0907 14-03-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32678, current rewards: -2493.93143, mean: -1.37786
[32m[0907 14-03-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32678, current rewards: -2591.30281, mean: -1.39317
[32m[0907 14-04-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32643, current rewards: -2691.30281, mean: -1.40906
[32m[0907 14-04-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32654, current rewards: -2791.30281, mean: -1.42413
[32m[0907 14-04-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32661, current rewards: -2889.20979, mean: -1.43742
[32m[0907 14-04-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32640, current rewards: -2984.28402, mean: -1.44868
[32m[0907 14-05-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32630, current rewards: -3082.08814, mean: -1.46071
[32m[0907 14-05-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32599, current rewards: -3182.08814, mean: -1.47319
[32m[0907 14-05-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32547, current rewards: -3282.08814, mean: -1.48511
[32m[0907 14-05-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32516, current rewards: -3379.30191, mean: -1.49527
[32m[0907 14-06-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32489, current rewards: -3465.78174, mean: -1.50034
[32m[0907 14-06-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32446, current rewards: -3536.80457, mean: -1.49865
[32m[0907 14-06-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32396, current rewards: -3612.03607, mean: -1.49877
[32m[0907 14-06-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32356, current rewards: -3692.46698, mean: -1.50100
[32m[0907 14-07-07 @Agent.py:117][0m Average action selection time: 0.3231
[32m[0907 14-07-07 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-07-07 @MBExp.py:227][0m Rewards obtained: [-3759.2209040729554], Lows: [1841], Highs: [150], Total time: 79246.54560700001
[32m[0907 14-10-06 @MBExp.py:144][0m ####################################################################
[32m[0907 14-10-06 @MBExp.py:145][0m Starting training iteration 97.
[32m[0907 14-10-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33862, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-10-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31954, current rewards: -59.47397, mean: -0.99123
[32m[0907 14-10-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31763, current rewards: -117.18171, mean: -1.06529
[32m[0907 14-10-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31680, current rewards: -165.33585, mean: -1.03335
[32m[0907 14-11-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31632, current rewards: -198.38068, mean: -0.94467
[32m[0907 14-11-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31618, current rewards: -244.08357, mean: -0.93878
[32m[0907 14-11-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31611, current rewards: -290.58588, mean: -0.93737
[32m[0907 14-12-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31599, current rewards: -343.10295, mean: -0.95306
[32m[0907 14-12-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31589, current rewards: -393.35153, mean: -0.95939
[32m[0907 14-12-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31580, current rewards: -422.76429, mean: -0.91905
[32m[0907 14-12-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31686, current rewards: -477.79865, mean: -0.93686
[32m[0907 14-13-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31655, current rewards: -543.14450, mean: -0.96990
[32m[0907 14-13-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31636, current rewards: -638.87612, mean: -1.04734
[32m[0907 14-13-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31621, current rewards: -736.64908, mean: -1.11613
[32m[0907 14-13-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31601, current rewards: -836.64908, mean: -1.17838
[32m[0907 14-14-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31587, current rewards: -936.64908, mean: -1.23243
[32m[0907 14-14-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31575, current rewards: -1036.64908, mean: -1.27981
[32m[0907 14-14-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31564, current rewards: -1136.64908, mean: -1.32168
[32m[0907 14-14-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31554, current rewards: -1236.64908, mean: -1.35896
[32m[0907 14-15-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31550, current rewards: -1336.64908, mean: -1.39234
[32m[0907 14-15-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31545, current rewards: -1436.64908, mean: -1.42242
[32m[0907 14-15-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31540, current rewards: -1536.64908, mean: -1.44967
[32m[0907 14-15-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31530, current rewards: -1636.64908, mean: -1.47446
[32m[0907 14-16-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31524, current rewards: -1736.64908, mean: -1.49711
[32m[0907 14-16-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31508, current rewards: -1799.96168, mean: -1.48757
[32m[0907 14-16-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31476, current rewards: -1899.96168, mean: -1.50791
[32m[0907 14-16-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31448, current rewards: -1999.96168, mean: -1.52669
[32m[0907 14-17-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31419, current rewards: -2099.96168, mean: -1.54409
[32m[0907 14-17-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31393, current rewards: -2199.96168, mean: -1.56026
[32m[0907 14-17-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31369, current rewards: -2299.96168, mean: -1.57532
[32m[0907 14-18-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31348, current rewards: -2399.96168, mean: -1.58938
[32m[0907 14-18-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31325, current rewards: -2499.96168, mean: -1.60254
[32m[0907 14-18-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31305, current rewards: -2599.96168, mean: -1.61488
[32m[0907 14-18-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31289, current rewards: -2661.83418, mean: -1.60351
[32m[0907 14-19-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31272, current rewards: -2739.42684, mean: -1.60200
[32m[0907 14-19-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31258, current rewards: -2830.26119, mean: -1.60810
[32m[0907 14-19-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31251, current rewards: -2895.68320, mean: -1.59982
[32m[0907 14-19-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31256, current rewards: -2968.75306, mean: -1.59610
[32m[0907 14-20-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31262, current rewards: -3045.00844, mean: -1.59425
[32m[0907 14-20-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31266, current rewards: -3109.30548, mean: -1.58638
[32m[0907 14-20-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31268, current rewards: -3177.00398, mean: -1.58060
[32m[0907 14-20-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31272, current rewards: -3253.06168, mean: -1.57916
[32m[0907 14-21-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31313, current rewards: -3309.44111, mean: -1.56846
[32m[0907 14-21-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31304, current rewards: -3346.30995, mean: -1.54922
[32m[0907 14-21-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31285, current rewards: -3416.27260, mean: -1.54582
[32m[0907 14-21-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31291, current rewards: -3469.03567, mean: -1.53497
[32m[0907 14-22-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31311, current rewards: -3531.35883, mean: -1.52873
[32m[0907 14-22-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31313, current rewards: -3583.95145, mean: -1.51862
[32m[0907 14-22-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31282, current rewards: -3647.62873, mean: -1.51354
[32m[0907 14-22-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31244, current rewards: -3747.62873, mean: -1.52343
[32m[0907 14-23-07 @Agent.py:117][0m Average action selection time: 0.3121
[32m[0907 14-23-07 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-23-07 @MBExp.py:227][0m Rewards obtained: [-3827.6287290493356], Lows: [1935], Highs: [54], Total time: 80027.481545
[32m[0907 14-26-08 @MBExp.py:144][0m ####################################################################
[32m[0907 14-26-08 @MBExp.py:145][0m Starting training iteration 98.
[32m[0907 14-26-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31400, current rewards: 1.26261, mean: 0.12626
[32m[0907 14-26-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31693, current rewards: 5.73054, mean: 0.09551
[32m[0907 14-26-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31680, current rewards: 10.18928, mean: 0.09263
[32m[0907 14-26-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31654, current rewards: 14.64803, mean: 0.09155
[32m[0907 14-27-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31647, current rewards: 19.10677, mean: 0.09098
[32m[0907 14-27-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31614, current rewards: 23.56552, mean: 0.09064
[32m[0907 14-27-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31603, current rewards: 27.83227, mean: 0.08978
[32m[0907 14-28-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31589, current rewards: -16.90849, mean: -0.04697
[32m[0907 14-28-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31588, current rewards: -66.90849, mean: -0.16319
[32m[0907 14-28-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31583, current rewards: -116.90849, mean: -0.25415
[32m[0907 14-28-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31588, current rewards: -166.90849, mean: -0.32727
[32m[0907 14-29-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31585, current rewards: -216.90849, mean: -0.38734
[32m[0907 14-29-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31581, current rewards: -266.90849, mean: -0.43755
[32m[0907 14-29-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31572, current rewards: -316.90849, mean: -0.48016
[32m[0907 14-29-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31568, current rewards: -366.90849, mean: -0.51677
[32m[0907 14-30-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31569, current rewards: -416.90849, mean: -0.54856
[32m[0907 14-30-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31565, current rewards: -466.90849, mean: -0.57643
[32m[0907 14-30-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31563, current rewards: -516.90849, mean: -0.60106
[32m[0907 14-30-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31555, current rewards: -566.90849, mean: -0.62298
[32m[0907 14-31-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31551, current rewards: -616.90849, mean: -0.64261
[32m[0907 14-31-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31548, current rewards: -666.90849, mean: -0.66031
[32m[0907 14-31-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31543, current rewards: -716.90849, mean: -0.67633
[32m[0907 14-31-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31540, current rewards: -766.90849, mean: -0.69091
[32m[0907 14-32-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31534, current rewards: -816.90849, mean: -0.70423
[32m[0907 14-32-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31509, current rewards: -866.90849, mean: -0.71645
[32m[0907 14-32-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31480, current rewards: -916.90849, mean: -0.72771
[32m[0907 14-33-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31456, current rewards: -966.90849, mean: -0.73810
[32m[0907 14-33-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31434, current rewards: -1016.90849, mean: -0.74773
[32m[0907 14-33-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31412, current rewards: -1066.90849, mean: -0.75667
[32m[0907 14-33-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31388, current rewards: -1116.90849, mean: -0.76501
[32m[0907 14-34-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31367, current rewards: -1166.90849, mean: -0.77279
[32m[0907 14-34-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31349, current rewards: -1216.90849, mean: -0.78007
[32m[0907 14-34-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31332, current rewards: -1266.90849, mean: -0.78690
[32m[0907 14-34-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31314, current rewards: -1316.90849, mean: -0.79332
[32m[0907 14-35-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31298, current rewards: -1366.90849, mean: -0.79936
[32m[0907 14-35-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31284, current rewards: -1416.90849, mean: -0.80506
[32m[0907 14-35-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31283, current rewards: -1466.90849, mean: -0.81045
[32m[0907 14-35-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31289, current rewards: -1516.90849, mean: -0.81554
[32m[0907 14-36-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31295, current rewards: -1566.90849, mean: -0.82037
[32m[0907 14-36-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31298, current rewards: -1616.90849, mean: -0.82495
[32m[0907 14-36-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31300, current rewards: -1666.90849, mean: -0.82931
[32m[0907 14-36-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31306, current rewards: -1716.90849, mean: -0.83345
[32m[0907 14-37-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31310, current rewards: -1766.90849, mean: -0.83740
[32m[0907 14-37-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31288, current rewards: -1816.90849, mean: -0.84116
[32m[0907 14-37-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31257, current rewards: -1866.90849, mean: -0.84475
[32m[0907 14-37-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31228, current rewards: -1916.90849, mean: -0.84819
[32m[0907 14-38-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31201, current rewards: -1966.90849, mean: -0.85148
[32m[0907 14-38-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31173, current rewards: -2016.90849, mean: -0.85462
[32m[0907 14-38-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31147, current rewards: -2066.90849, mean: -0.85764
[32m[0907 14-38-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31114, current rewards: -2116.90849, mean: -0.86053
[32m[0907 14-39-05 @Agent.py:117][0m Average action selection time: 0.3108
[32m[0907 14-39-05 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-39-06 @MBExp.py:227][0m Rewards obtained: [-2156.908485957712], Lows: [0], Highs: [2185], Total time: 80805.22200000001
[32m[0907 14-42-09 @MBExp.py:144][0m ####################################################################
[32m[0907 14-42-09 @MBExp.py:145][0m Starting training iteration 99.
[32m[0907 14-42-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31753, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-42-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31666, current rewards: -100.00000, mean: -1.66667
[32m[0907 14-42-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31632, current rewards: -200.00000, mean: -1.81818
[32m[0907 14-42-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31596, current rewards: -300.00000, mean: -1.87500
[32m[0907 14-43-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31579, current rewards: -400.00000, mean: -1.90476
[32m[0907 14-43-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31560, current rewards: -500.00000, mean: -1.92308
[32m[0907 14-43-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31554, current rewards: -600.00000, mean: -1.93548
[32m[0907 14-44-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31562, current rewards: -700.00000, mean: -1.94444
[32m[0907 14-44-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31557, current rewards: -800.00000, mean: -1.95122
[32m[0907 14-44-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31560, current rewards: -900.00000, mean: -1.95652
[32m[0907 14-44-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31570, current rewards: -1000.00000, mean: -1.96078
[32m[0907 14-45-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31572, current rewards: -1100.00000, mean: -1.96429
[32m[0907 14-45-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31567, current rewards: -1200.00000, mean: -1.96721
[32m[0907 14-45-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31563, current rewards: -1300.00000, mean: -1.96970
[32m[0907 14-45-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31566, current rewards: -1400.00000, mean: -1.97183
[32m[0907 14-46-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31564, current rewards: -1500.00000, mean: -1.97368
[32m[0907 14-46-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31560, current rewards: -1600.00000, mean: -1.97531
[32m[0907 14-46-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31563, current rewards: -1700.00000, mean: -1.97674
[32m[0907 14-46-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31562, current rewards: -1800.00000, mean: -1.97802
[32m[0907 14-47-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31556, current rewards: -1900.00000, mean: -1.97917
[32m[0907 14-47-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31552, current rewards: -2000.00000, mean: -1.98020
[32m[0907 14-47-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31549, current rewards: -2100.00000, mean: -1.98113
[32m[0907 14-47-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31547, current rewards: -2200.00000, mean: -1.98198
[32m[0907 14-48-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31545, current rewards: -2300.00000, mean: -1.98276
[32m[0907 14-48-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31518, current rewards: -2400.00000, mean: -1.98347
[32m[0907 14-48-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31488, current rewards: -2500.00000, mean: -1.98413
[32m[0907 14-49-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31460, current rewards: -2600.00000, mean: -1.98473
[32m[0907 14-49-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31437, current rewards: -2700.00000, mean: -1.98529
[32m[0907 14-49-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31417, current rewards: -2800.00000, mean: -1.98582
[32m[0907 14-49-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31396, current rewards: -2900.00000, mean: -1.98630
[32m[0907 14-50-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31378, current rewards: -3000.00000, mean: -1.98675
[32m[0907 14-50-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31358, current rewards: -3100.00000, mean: -1.98718
[32m[0907 14-50-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31339, current rewards: -3200.00000, mean: -1.98758
[32m[0907 14-50-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31323, current rewards: -3300.00000, mean: -1.98795
[32m[0907 14-51-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31307, current rewards: -3396.00000, mean: -1.98596
[32m[0907 14-51-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31291, current rewards: -3492.92631, mean: -1.98462
[32m[0907 14-51-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31288, current rewards: -3581.76768, mean: -1.97888
[32m[0907 14-51-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31293, current rewards: -3679.76768, mean: -1.97837
[32m[0907 14-52-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31299, current rewards: -3773.61934, mean: -1.97572
[32m[0907 14-52-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31305, current rewards: -3868.50269, mean: -1.97373
[32m[0907 14-52-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31379, current rewards: -3950.32108, mean: -1.96533
[32m[0907 14-52-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31386, current rewards: -4050.32108, mean: -1.96618
[32m[0907 14-53-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31392, current rewards: -4150.32108, mean: -1.96698
[32m[0907 14-53-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31382, current rewards: -4250.32108, mean: -1.96774
[32m[0907 14-53-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31370, current rewards: -4350.32108, mean: -1.96847
[32m[0907 14-53-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31355, current rewards: -4450.32108, mean: -1.96917
[32m[0907 14-54-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31325, current rewards: -4550.32108, mean: -1.96984
[32m[0907 14-54-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31295, current rewards: -4650.32108, mean: -1.97048
[32m[0907 14-54-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31265, current rewards: -4750.32108, mean: -1.97109
[32m[0907 14-54-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31235, current rewards: -4848.32108, mean: -1.97086
[32m[0907 14-55-09 @Agent.py:117][0m Average action selection time: 0.3121
[32m[0907 14-55-09 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-55-10 @MBExp.py:227][0m Rewards obtained: [-4925.260324959677], Lows: [2446], Highs: [37], Total time: 81586.15552700001
[32m[0907 14-58-14 @MBExp.py:144][0m ####################################################################
[32m[0907 14-58-14 @MBExp.py:145][0m Starting training iteration 100.
[32m[0907 14-58-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31788, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-58-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37172, current rewards: -57.62863, mean: -0.96048
[32m[0907 14-58-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34641, current rewards: -94.40835, mean: -0.85826
[32m[0907 14-59-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33690, current rewards: -144.40835, mean: -0.90255
[32m[0907 14-59-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33198, current rewards: -194.40835, mean: -0.92575
[32m[0907 14-59-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32886, current rewards: -222.97305, mean: -0.85759
[32m[0907 14-59-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32691, current rewards: -217.17782, mean: -0.70057
[32m[0907 15-00-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32542, current rewards: -211.38259, mean: -0.58717
[32m[0907 15-00-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32421, current rewards: -205.58736, mean: -0.50143
[32m[0907 15-00-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32322, current rewards: -199.79213, mean: -0.43433
[32m[0907 15-00-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32254, current rewards: -193.99690, mean: -0.38039
[32m[0907 15-01-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32197, current rewards: -231.72195, mean: -0.41379
[32m[0907 15-01-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32142, current rewards: -281.72195, mean: -0.46184
[32m[0907 15-01-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32094, current rewards: -331.72195, mean: -0.50261
[32m[0907 15-02-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32048, current rewards: -381.72195, mean: -0.53764
[32m[0907 15-02-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32013, current rewards: -431.72195, mean: -0.56806
[32m[0907 15-02-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31980, current rewards: -481.72195, mean: -0.59472
[32m[0907 15-02-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31956, current rewards: -531.72195, mean: -0.61828
[32m[0907 15-03-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31943, current rewards: -581.72195, mean: -0.63925
[32m[0907 15-03-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31927, current rewards: -631.72195, mean: -0.65804
[32m[0907 15-03-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31905, current rewards: -681.72195, mean: -0.67497
[32m[0907 15-03-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31884, current rewards: -731.72195, mean: -0.69030
[32m[0907 15-04-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31864, current rewards: -781.72195, mean: -0.70425
[32m[0907 15-04-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31837, current rewards: -831.72195, mean: -0.71700
[32m[0907 15-04-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31791, current rewards: -881.72195, mean: -0.72870
[32m[0907 15-04-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31750, current rewards: -931.72195, mean: -0.73946
[32m[0907 15-05-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31712, current rewards: -981.72195, mean: -0.74941
[32m[0907 15-05-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31678, current rewards: -1031.72195, mean: -0.75862
[32m[0907 15-05-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31646, current rewards: -1081.72195, mean: -0.76718
[32m[0907 15-05-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31618, current rewards: -1131.72195, mean: -0.77515
[32m[0907 15-06-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31589, current rewards: -1181.72195, mean: -0.78260
[32m[0907 15-06-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31562, current rewards: -1231.72195, mean: -0.78957
[32m[0907 15-06-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31539, current rewards: -1281.72195, mean: -0.79610
[32m[0907 15-06-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31514, current rewards: -1331.72195, mean: -0.80224
[32m[0907 15-07-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31493, current rewards: -1381.72195, mean: -0.80802
[32m[0907 15-07-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31471, current rewards: -1431.72195, mean: -0.81348
[32m[0907 15-07-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31473, current rewards: -1481.72195, mean: -0.81863
[32m[0907 15-08-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31475, current rewards: -1531.72195, mean: -0.82351
[32m[0907 15-08-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31475, current rewards: -1581.72195, mean: -0.82813
[32m[0907 15-08-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31476, current rewards: -1631.72195, mean: -0.83251
[32m[0907 15-08-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31478, current rewards: -1681.72195, mean: -0.83668
[32m[0907 15-09-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31478, current rewards: -1731.72195, mean: -0.84064
[32m[0907 15-09-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31478, current rewards: -1781.72195, mean: -0.84442
[32m[0907 15-09-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31463, current rewards: -1831.72195, mean: -0.84802
[32m[0907 15-09-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31447, current rewards: -1881.72195, mean: -0.85146
[32m[0907 15-10-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31433, current rewards: -1931.72195, mean: -0.85474
[32m[0907 15-10-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31408, current rewards: -1981.72195, mean: -0.85789
[32m[0907 15-10-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31377, current rewards: -2031.72195, mean: -0.86090
[32m[0907 15-10-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31346, current rewards: -2081.72195, mean: -0.86379
[32m[0907 15-11-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31317, current rewards: -2131.72195, mean: -0.86655
[32m[0907 15-11-17 @Agent.py:117][0m Average action selection time: 0.3129
[32m[0907 15-11-17 @Agent.py:118][0m Rollout length: 2520
[32m[0907 15-11-17 @MBExp.py:227][0m Rewards obtained: [-2171.721949240972], Lows: [8], Highs: [2192], Total time: 82369.17262400001
[32m[0907 15-14-22 @MBExp.py:144][0m ####################################################################
[32m[0907 15-14-22 @MBExp.py:145][0m Starting training iteration 101.
[32m[0907 15-14-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31817, current rewards: -10.00000, mean: -1.00000
[32m[0907 15-14-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32352, current rewards: -86.00000, mean: -1.43333
[32m[0907 15-14-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32830, current rewards: -136.00000, mean: -1.23636
[32m[0907 15-15-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32449, current rewards: -206.54538, mean: -1.29091
[32m[0907 15-15-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32240, current rewards: -264.54538, mean: -1.25974
[32m[0907 15-15-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32141, current rewards: -352.49304, mean: -1.35574
[32m[0907 15-16-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32046, current rewards: -402.49304, mean: -1.29836
[32m[0907 15-16-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32005, current rewards: -474.49304, mean: -1.31804
[32m[0907 15-16-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31944, current rewards: -526.49304, mean: -1.28413
[32m[0907 15-16-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31898, current rewards: -576.49304, mean: -1.25325
[32m[0907 15-17-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31856, current rewards: -626.49304, mean: -1.22842
[32m[0907 15-17-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31827, current rewards: -676.49304, mean: -1.20802
[32m[0907 15-17-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31791, current rewards: -726.49304, mean: -1.19097
[32m[0907 15-17-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31773, current rewards: -776.49304, mean: -1.17650
[32m[0907 15-18-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31749, current rewards: -826.49304, mean: -1.16407
[32m[0907 15-18-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31738, current rewards: -876.49304, mean: -1.15328
[32m[0907 15-18-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31728, current rewards: -926.49304, mean: -1.14382
[32m[0907 15-18-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31707, current rewards: -976.49304, mean: -1.13546
[32m[0907 15-19-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31694, current rewards: -1026.49304, mean: -1.12801
[32m[0907 15-19-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31683, current rewards: -1076.49304, mean: -1.12135
[32m[0907 15-19-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31671, current rewards: -1126.49304, mean: -1.11534
[32m[0907 15-19-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31657, current rewards: -1176.49304, mean: -1.10990
[32m[0907 15-20-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31647, current rewards: -1226.49304, mean: -1.10495
[32m[0907 15-20-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31616, current rewards: -1276.49304, mean: -1.10043
[32m[0907 15-20-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31582, current rewards: -1326.49304, mean: -1.09628
[32m[0907 15-21-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31551, current rewards: -1376.49304, mean: -1.09245
[32m[0907 15-21-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31523, current rewards: -1426.49304, mean: -1.08893
[32m[0907 15-21-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31495, current rewards: -1476.49304, mean: -1.08566
[32m[0907 15-21-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31470, current rewards: -1526.49304, mean: -1.08262
[32m[0907 15-22-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31446, current rewards: -1576.49304, mean: -1.07979
[32m[0907 15-22-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31422, current rewards: -1626.49304, mean: -1.07715
[32m[0907 15-22-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31401, current rewards: -1676.49304, mean: -1.07468
[32m[0907 15-22-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31380, current rewards: -1726.49304, mean: -1.07236
[32m[0907 15-23-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31360, current rewards: -1776.49304, mean: -1.07018
[32m[0907 15-23-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31341, current rewards: -1826.49304, mean: -1.06812
[32m[0907 15-23-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31330, current rewards: -1876.49304, mean: -1.06619
[32m[0907 15-23-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31337, current rewards: -1926.49304, mean: -1.06436
[32m[0907 15-24-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31343, current rewards: -1976.49304, mean: -1.06263
[32m[0907 15-24-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31349, current rewards: -2026.49304, mean: -1.06099
[32m[0907 15-24-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31356, current rewards: -2076.49304, mean: -1.05944
[32m[0907 15-24-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31361, current rewards: -2126.49304, mean: -1.05796
[32m[0907 15-25-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31366, current rewards: -2176.49304, mean: -1.05655
[32m[0907 15-25-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31371, current rewards: -2226.49304, mean: -1.05521
[32m[0907 15-25-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31360, current rewards: -2276.49304, mean: -1.05393
[32m[0907 15-25-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31347, current rewards: -2326.49304, mean: -1.05271
[32m[0907 15-26-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31336, current rewards: -2376.49304, mean: -1.05155
[32m[0907 15-26-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31311, current rewards: -2426.49304, mean: -1.05043
[32m[0907 15-26-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31282, current rewards: -2476.49304, mean: -1.04936
[32m[0907 15-26-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31253, current rewards: -2526.49304, mean: -1.04834
[32m[0907 15-27-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31227, current rewards: -2576.49304, mean: -1.04735
[32m[0907 15-27-23 @Agent.py:117][0m Average action selection time: 0.3120
[32m[0907 15-27-23 @Agent.py:118][0m Rollout length: 2520
[32m[0907 15-27-23 @MBExp.py:227][0m Rewards obtained: [-2616.493036152032], Lows: [120], Highs: [2377], Total time: 83150.02339100001
[32m[0907 15-30-31 @MBExp.py:144][0m ####################################################################
[32m[0907 15-30-31 @MBExp.py:145][0m Starting training iteration 102.
[32m[0907 15-30-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31722, current rewards: -10.00000, mean: -1.00000
[32m[0907 15-30-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31827, current rewards: -100.00000, mean: -1.66667
[32m[0907 15-31-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32129, current rewards: -183.67869, mean: -1.66981
[32m[0907 15-31-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31968, current rewards: -283.67869, mean: -1.77299
[32m[0907 15-31-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31873, current rewards: -383.67869, mean: -1.82704
[32m[0907 15-31-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31800, current rewards: -483.67869, mean: -1.86030
[32m[0907 15-32-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31755, current rewards: -583.67869, mean: -1.88283
[32m[0907 15-32-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31711, current rewards: -683.67869, mean: -1.89911
[32m[0907 15-32-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31741, current rewards: -783.67869, mean: -1.91141
[32m[0907 15-32-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32134, current rewards: -883.67869, mean: -1.92104
[32m[0907 15-33-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32448, current rewards: -983.67869, mean: -1.92878
[32m[0907 15-33-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32700, current rewards: -1083.67869, mean: -1.93514
[32m[0907 15-33-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32904, current rewards: -1183.67869, mean: -1.94046
[32m[0907 15-34-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33078, current rewards: -1283.67869, mean: -1.94497
[32m[0907 15-34-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33225, current rewards: -1383.67869, mean: -1.94884
[32m[0907 15-34-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33366, current rewards: -1483.67869, mean: -1.95221
[32m[0907 15-35-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33484, current rewards: -1583.67869, mean: -1.95516
[32m[0907 15-35-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33606, current rewards: -1683.67869, mean: -1.95777
[32m[0907 15-35-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33749, current rewards: -1783.67869, mean: -1.96009
[32m[0907 15-35-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33829, current rewards: -1883.67869, mean: -1.96217
[32m[0907 15-36-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33909, current rewards: -1983.67869, mean: -1.96404
[32m[0907 15-36-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33978, current rewards: -2083.67869, mean: -1.96573
[32m[0907 15-36-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34032, current rewards: -2183.67869, mean: -1.96728
[32m[0907 15-37-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34055, current rewards: -2283.67869, mean: -1.96869
[32m[0907 15-37-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34071, current rewards: -2383.67869, mean: -1.96998
[32m[0907 15-37-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34084, current rewards: -2483.67869, mean: -1.97117
[32m[0907 15-37-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34097, current rewards: -2583.67869, mean: -1.97227
[32m[0907 15-38-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34110, current rewards: -2683.67869, mean: -1.97329
[32m[0907 15-38-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34124, current rewards: -2783.67869, mean: -1.97424
[32m[0907 15-38-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34136, current rewards: -2883.67869, mean: -1.97512
[32m[0907 15-39-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34148, current rewards: -2983.67869, mean: -1.97595
[32m[0907 15-39-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34159, current rewards: -3083.67869, mean: -1.97672
[32m[0907 15-39-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34171, current rewards: -3183.67869, mean: -1.97744
[32m[0907 15-39-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34179, current rewards: -3283.67869, mean: -1.97812
[32m[0907 15-40-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34189, current rewards: -3383.67869, mean: -1.97876
[32m[0907 15-40-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34204, current rewards: -3483.67869, mean: -1.97936
[32m[0907 15-40-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34233, current rewards: -3583.67869, mean: -1.97993
[32m[0907 15-41-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34264, current rewards: -3683.67869, mean: -1.98047
[32m[0907 15-41-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34292, current rewards: -3783.67869, mean: -1.98098
[32m[0907 15-41-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34315, current rewards: -3883.67869, mean: -1.98147
[32m[0907 15-42-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34341, current rewards: -3983.67869, mean: -1.98193
[32m[0907 15-42-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34364, current rewards: -4083.67869, mean: -1.98237
[32m[0907 15-42-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34384, current rewards: -4183.67869, mean: -1.98279
[32m[0907 15-42-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34385, current rewards: -4283.67869, mean: -1.98318
[32m[0907 15-43-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34386, current rewards: -4383.67869, mean: -1.98357
[32m[0907 15-43-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34385, current rewards: -4483.67869, mean: -1.98393
[32m[0907 15-43-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34388, current rewards: -4583.67869, mean: -1.98428
[32m[0907 15-44-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34401, current rewards: -4683.67869, mean: -1.98461
[32m[0907 15-44-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34417, current rewards: -4783.67869, mean: -1.98493
[32m[0907 15-44-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34419, current rewards: -4883.67869, mean: -1.98524
[32m[0907 15-44-52 @Agent.py:117][0m Average action selection time: 0.3441
[32m[0907 15-44-52 @Agent.py:118][0m Rollout length: 2520
[32m[0907 15-44-52 @MBExp.py:227][0m Rewards obtained: [-4963.678691181749], Lows: [2467], Highs: [30], Total time: 84011.16909200001
[32m[0907 15-48-36 @MBExp.py:144][0m ####################################################################
[32m[0907 15-48-36 @MBExp.py:145][0m Starting training iteration 103.
[32m[0907 15-48-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36159, current rewards: -10.00000, mean: -1.00000
[32m[0907 15-48-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36470, current rewards: -92.85679, mean: -1.54761
[32m[0907 15-49-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37048, current rewards: -190.78161, mean: -1.73438
[32m[0907 15-49-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37200, current rewards: -283.10732, mean: -1.76942
[32m[0907 15-49-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37443, current rewards: -378.98728, mean: -1.80470
[32m[0907 15-50-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37246, current rewards: -477.98728, mean: -1.83841
[32m[0907 15-50-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37250, current rewards: -574.81689, mean: -1.85425
[32m[0907 15-50-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37223, current rewards: -671.72159, mean: -1.86589
[32m[0907 15-51-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37191, current rewards: -770.72159, mean: -1.87981
[32m[0907 15-51-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37105, current rewards: -863.88259, mean: -1.87801
[32m[0907 15-51-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37107, current rewards: -962.88259, mean: -1.88801
[32m[0907 15-52-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37130, current rewards: -1060.08330, mean: -1.89301
[32m[0907 15-52-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37069, current rewards: -1160.08330, mean: -1.90178
[32m[0907 15-52-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37020, current rewards: -1260.08330, mean: -1.90922
[32m[0907 15-52-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36976, current rewards: -1360.08330, mean: -1.91561
[32m[0907 15-53-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36943, current rewards: -1460.08330, mean: -1.92116
[32m[0907 15-53-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36908, current rewards: -1560.08330, mean: -1.92603
[32m[0907 15-53-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36881, current rewards: -1660.08330, mean: -1.93033
[32m[0907 15-54-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36856, current rewards: -1760.08330, mean: -1.93416
[32m[0907 15-54-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36840, current rewards: -1860.08330, mean: -1.93759
[32m[0907 15-54-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36820, current rewards: -1960.08330, mean: -1.94068
[32m[0907 15-55-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36798, current rewards: -2060.08330, mean: -1.94347
[32m[0907 15-55-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36755, current rewards: -2160.08330, mean: -1.94602
[32m[0907 15-55-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36704, current rewards: -2260.08330, mean: -1.94835
[32m[0907 15-56-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36668, current rewards: -2355.37675, mean: -1.94659
[32m[0907 15-56-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36624, current rewards: -2455.37675, mean: -1.94871
[32m[0907 15-56-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36582, current rewards: -2555.37675, mean: -1.95067
[32m[0907 15-56-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36542, current rewards: -2655.37675, mean: -1.95248
[32m[0907 15-57-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36506, current rewards: -2755.37675, mean: -1.95417
[32m[0907 15-57-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36474, current rewards: -2855.37675, mean: -1.95574
[32m[0907 15-57-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36442, current rewards: -2955.37675, mean: -1.95720
[32m[0907 15-58-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36416, current rewards: -3055.37675, mean: -1.95857
[32m[0907 15-58-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36391, current rewards: -3155.37675, mean: -1.95986
[32m[0907 15-58-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36366, current rewards: -3255.37675, mean: -1.96107
[32m[0907 15-58-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36341, current rewards: -3355.37675, mean: -1.96221
[32m[0907 15-59-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36331, current rewards: -3455.37675, mean: -1.96328
[32m[0907 15-59-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36335, current rewards: -3555.37675, mean: -1.96430
[32m[0907 15-59-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36335, current rewards: -3655.37675, mean: -1.96526
[32m[0907 16-00-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36338, current rewards: -3755.37675, mean: -1.96617
[32m[0907 16-00-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36340, current rewards: -3855.37675, mean: -1.96703
[32m[0907 16-00-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36342, current rewards: -3955.37675, mean: -1.96785
[32m[0907 16-01-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36344, current rewards: -4055.37675, mean: -1.96863
[32m[0907 16-01-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36338, current rewards: -4155.37675, mean: -1.96937
[32m[0907 16-01-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36320, current rewards: -4255.37675, mean: -1.97008
[32m[0907 16-01-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36303, current rewards: -4355.37675, mean: -1.97076
[32m[0907 16-02-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36286, current rewards: -4455.37675, mean: -1.97141
[32m[0907 16-02-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36270, current rewards: -4555.37675, mean: -1.97202
[32m[0907 16-02-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36257, current rewards: -4655.37675, mean: -1.97262
[32m[0907 16-03-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36242, current rewards: -4755.37675, mean: -1.97319
[32m[0907 16-03-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36219, current rewards: -4855.37675, mean: -1.97373
[32m[0907 16-03-41 @Agent.py:117][0m Average action selection time: 0.3619
[32m[0907 16-03-41 @Agent.py:118][0m Rollout length: 2520
[32m[0907 16-03-41 @MBExp.py:227][0m Rewards obtained: [-4935.376752242507], Lows: [2455], Highs: [29], Total time: 84916.74839300002
[32m[0907 16-07-29 @MBExp.py:144][0m ####################################################################
[32m[0907 16-07-29 @MBExp.py:145][0m Starting training iteration 104.
[32m[0907 16-07-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36515, current rewards: -10.00000, mean: -1.00000
[32m[0907 16-07-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36453, current rewards: -96.00000, mean: -1.60000
[32m[0907 16-08-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36454, current rewards: -196.00000, mean: -1.78182
[32m[0907 16-08-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36447, current rewards: -296.00000, mean: -1.85000
[32m[0907 16-08-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36449, current rewards: -396.00000, mean: -1.88571
[32m[0907 16-09-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36454, current rewards: -496.00000, mean: -1.90769
[32m[0907 16-09-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36460, current rewards: -596.00000, mean: -1.92258
[32m[0907 16-09-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36458, current rewards: -696.00000, mean: -1.93333
[32m[0907 16-09-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36451, current rewards: -796.00000, mean: -1.94146
[32m[0907 16-10-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36445, current rewards: -896.00000, mean: -1.94783
[32m[0907 16-10-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36439, current rewards: -996.00000, mean: -1.95294
[32m[0907 16-10-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36444, current rewards: -1096.00000, mean: -1.95714
[32m[0907 16-11-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36443, current rewards: -1196.00000, mean: -1.96066
[32m[0907 16-11-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36433, current rewards: -1296.00000, mean: -1.96364
[32m[0907 16-11-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36426, current rewards: -1396.00000, mean: -1.96620
[32m[0907 16-12-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36427, current rewards: -1496.00000, mean: -1.96842
[32m[0907 16-12-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36425, current rewards: -1596.00000, mean: -1.97037
[32m[0907 16-12-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36423, current rewards: -1696.00000, mean: -1.97209
[32m[0907 16-13-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36418, current rewards: -1796.00000, mean: -1.97363
[32m[0907 16-13-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36415, current rewards: -1896.00000, mean: -1.97500
[32m[0907 16-13-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36404, current rewards: -1996.00000, mean: -1.97624
[32m[0907 16-13-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36398, current rewards: -2096.00000, mean: -1.97736
[32m[0907 16-14-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36366, current rewards: -2196.00000, mean: -1.97838
[32m[0907 16-14-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36337, current rewards: -2296.00000, mean: -1.97931
[32m[0907 16-14-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36305, current rewards: -2396.00000, mean: -1.98017
[32m[0907 16-15-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36274, current rewards: -2496.00000, mean: -1.98095
[32m[0907 16-15-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36247, current rewards: -2596.00000, mean: -1.98168
[32m[0907 16-15-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36224, current rewards: -2696.00000, mean: -1.98235
[32m[0907 16-16-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36201, current rewards: -2796.00000, mean: -1.98298
[32m[0907 16-16-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36182, current rewards: -2896.00000, mean: -1.98356
[32m[0907 16-16-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36161, current rewards: -2996.00000, mean: -1.98411
[32m[0907 16-16-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36144, current rewards: -3096.00000, mean: -1.98462
[32m[0907 16-17-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36125, current rewards: -3196.00000, mean: -1.98509
[32m[0907 16-17-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36107, current rewards: -3296.00000, mean: -1.98554
[32m[0907 16-17-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36092, current rewards: -3396.00000, mean: -1.98596
[32m[0907 16-18-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36098, current rewards: -3496.00000, mean: -1.98636
[32m[0907 16-18-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36110, current rewards: -3596.00000, mean: -1.98674
[32m[0907 16-18-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36118, current rewards: -3696.00000, mean: -1.98710
[32m[0907 16-19-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36127, current rewards: -3796.00000, mean: -1.98743
[32m[0907 16-19-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36134, current rewards: -3896.00000, mean: -1.98776
[32m[0907 16-19-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36143, current rewards: -3996.00000, mean: -1.98806
[32m[0907 16-19-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36148, current rewards: -4096.00000, mean: -1.98835
[32m[0907 16-20-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36152, current rewards: -4196.00000, mean: -1.98863
[32m[0907 16-20-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36153, current rewards: -4296.00000, mean: -1.98889
[32m[0907 16-20-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36156, current rewards: -4396.00000, mean: -1.98914
[32m[0907 16-21-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36157, current rewards: -4496.00000, mean: -1.98938
[32m[0907 16-21-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36159, current rewards: -4596.00000, mean: -1.98961
[32m[0907 16-21-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36161, current rewards: -4696.00000, mean: -1.98983
[32m[0907 16-22-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36161, current rewards: -4796.00000, mean: -1.99004
[32m[0907 16-22-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36149, current rewards: -4896.00000, mean: -1.99024
[32m[0907 16-22-33 @Agent.py:117][0m Average action selection time: 0.3613
[32m[0907 16-22-33 @Agent.py:118][0m Rollout length: 2520
[32m[0907 16-22-34 @MBExp.py:227][0m Rewards obtained: [-4976], Lows: [2476], Highs: [24], Total time: 85820.94553000001
[32m[0907 16-26-29 @MBExp.py:144][0m ####################################################################
[32m[0907 16-26-29 @MBExp.py:145][0m Starting training iteration 105.
[32m[0907 16-26-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.61788, current rewards: -10.00000, mean: -1.00000
[32m[0907 16-26-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.42549, current rewards: -60.00000, mean: -1.00000
[32m[0907 16-27-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.40110, current rewards: -110.00000, mean: -1.00000
[32m[0907 16-27-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.39181, current rewards: -160.00000, mean: -1.00000
[32m[0907 16-27-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.38704, current rewards: -210.00000, mean: -1.00000
[32m[0907 16-28-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.38396, current rewards: -260.00000, mean: -1.00000
[32m[0907 16-28-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.38184, current rewards: -310.00000, mean: -1.00000
[32m[0907 16-28-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.38043, current rewards: -360.00000, mean: -1.00000
[32m[0907 16-29-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37936, current rewards: -410.00000, mean: -1.00000
[32m[0907 16-29-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37853, current rewards: -460.00000, mean: -1.00000
[32m[0907 16-29-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37777, current rewards: -510.00000, mean: -1.00000
[32m[0907 16-30-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37715, current rewards: -560.00000, mean: -1.00000
[32m[0907 16-30-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37667, current rewards: -610.00000, mean: -1.00000
[32m[0907 16-30-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37621, current rewards: -660.00000, mean: -1.00000
[32m[0907 16-30-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37584, current rewards: -710.00000, mean: -1.00000
[32m[0907 16-31-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37547, current rewards: -760.00000, mean: -1.00000
[32m[0907 16-31-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37518, current rewards: -810.00000, mean: -1.00000
[32m[0907 16-31-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37486, current rewards: -860.00000, mean: -1.00000
[32m[0907 16-32-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37460, current rewards: -910.00000, mean: -1.00000
[32m[0907 16-32-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37429, current rewards: -960.00000, mean: -1.00000
[32m[0907 16-32-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37408, current rewards: -1010.00000, mean: -1.00000
[32m[0907 16-33-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37391, current rewards: -1060.00000, mean: -1.00000
[32m[0907 16-33-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37364, current rewards: -1110.00000, mean: -1.00000
[32m[0907 16-33-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37313, current rewards: -1160.00000, mean: -1.00000
[32m[0907 16-34-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37269, current rewards: -1210.00000, mean: -1.00000
[32m[0907 16-34-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37227, current rewards: -1260.00000, mean: -1.00000
[32m[0907 16-34-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37185, current rewards: -1310.00000, mean: -1.00000
[32m[0907 16-34-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37148, current rewards: -1360.00000, mean: -1.00000
[32m[0907 16-35-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.37116, current rewards: -1403.35834, mean: -0.99529
[32m[0907 16-35-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.37089, current rewards: -1398.01118, mean: -0.95754
[32m[0907 16-35-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.37062, current rewards: -1392.66402, mean: -0.92229
[32m[0907 16-36-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.37039, current rewards: -1387.31686, mean: -0.88931
[32m[0907 16-36-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.37018, current rewards: -1381.96970, mean: -0.85837
[32m[0907 16-36-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36993, current rewards: -1376.62254, mean: -0.82929
[32m[0907 16-37-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36970, current rewards: -1371.27538, mean: -0.80192
[32m[0907 16-37-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36950, current rewards: -1365.92822, mean: -0.77610
[32m[0907 16-37-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36955, current rewards: -1362.14804, mean: -0.75257
[32m[0907 16-37-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36960, current rewards: -1358.98831, mean: -0.73064
[32m[0907 16-38-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36964, current rewards: -1389.85080, mean: -0.72767
[32m[0907 16-38-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36968, current rewards: -1439.85080, mean: -0.73462
[32m[0907 16-38-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36969, current rewards: -1489.85080, mean: -0.74122
[32m[0907 16-39-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36972, current rewards: -1539.85080, mean: -0.74750
[32m[0907 16-39-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36957, current rewards: -1589.85080, mean: -0.75348
[32m[0907 16-39-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36939, current rewards: -1639.85080, mean: -0.75919
[32m[0907 16-40-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36921, current rewards: -1689.85080, mean: -0.76464
[32m[0907 16-40-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36904, current rewards: -1739.85080, mean: -0.76985
[32m[0907 16-40-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36889, current rewards: -1789.85080, mean: -0.77483
[32m[0907 16-41-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36877, current rewards: -1839.85080, mean: -0.77960
[32m[0907 16-41-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36862, current rewards: -1889.85080, mean: -0.78417
[32m[0907 16-41-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36846, current rewards: -1939.85080, mean: -0.78856
[32m[0907 16-41-50 @Agent.py:117][0m Average action selection time: 0.3682
[32m[0907 16-41-50 @Agent.py:118][0m Rollout length: 2520
[32m[0907 16-41-50 @MBExp.py:227][0m Rewards obtained: [-1979.8508029542982], Lows: [0], Highs: [2026], Total time: 86742.25658300001
[32m[0907 16-45-47 @MBExp.py:144][0m ####################################################################
[32m[0907 16-45-47 @MBExp.py:145][0m Starting training iteration 106.
[32m[0907 16-45-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36955, current rewards: 1.16794, mean: 0.11679
[32m[0907 16-46-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37022, current rewards: -77.74141, mean: -1.29569
[32m[0907 16-46-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37003, current rewards: -141.82402, mean: -1.28931
[32m[0907 16-46-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37025, current rewards: -224.74731, mean: -1.40467
[32m[0907 16-47-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37011, current rewards: -314.51664, mean: -1.49770
[32m[0907 16-47-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37015, current rewards: -403.29239, mean: -1.55112
[32m[0907 16-47-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37082, current rewards: -485.55402, mean: -1.56630
[32m[0907 16-48-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37071, current rewards: -585.55402, mean: -1.62654
[32m[0907 16-48-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37108, current rewards: -677.26620, mean: -1.65187
[32m[0907 16-48-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37077, current rewards: -766.39571, mean: -1.66608
[32m[0907 16-48-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37058, current rewards: -855.86532, mean: -1.67817
[32m[0907 16-49-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37050, current rewards: -955.86532, mean: -1.70690
[32m[0907 16-49-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37045, current rewards: -1055.86532, mean: -1.73093
[32m[0907 16-49-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37040, current rewards: -1155.86532, mean: -1.75131
[32m[0907 16-50-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37028, current rewards: -1255.86532, mean: -1.76882
[32m[0907 16-50-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37020, current rewards: -1355.86532, mean: -1.78403
[32m[0907 16-50-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37017, current rewards: -1455.86532, mean: -1.79736
[32m[0907 16-51-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37007, current rewards: -1555.86532, mean: -1.80915
[32m[0907 16-51-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37001, current rewards: -1655.86532, mean: -1.81963
[32m[0907 16-51-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36999, current rewards: -1755.86532, mean: -1.82903
[32m[0907 16-52-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37001, current rewards: -1855.86532, mean: -1.83749
[32m[0907 16-52-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37001, current rewards: -1955.86532, mean: -1.84516
[32m[0907 16-52-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36972, current rewards: -2055.86532, mean: -1.85213
[32m[0907 16-52-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36938, current rewards: -2155.86532, mean: -1.85850
[32m[0907 16-53-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36903, current rewards: -2255.86532, mean: -1.86435
[32m[0907 16-53-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36874, current rewards: -2355.86532, mean: -1.86973
[32m[0907 16-53-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36845, current rewards: -2455.86532, mean: -1.87471
[32m[0907 16-54-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36817, current rewards: -2555.86532, mean: -1.87931
[32m[0907 16-54-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36793, current rewards: -2655.86532, mean: -1.88359
[32m[0907 16-54-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36771, current rewards: -2755.86532, mean: -1.88758
[32m[0907 16-55-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36749, current rewards: -2855.86532, mean: -1.89130
[32m[0907 16-55-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36729, current rewards: -2955.86532, mean: -1.89479
[32m[0907 16-55-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36710, current rewards: -3055.86532, mean: -1.89805
[32m[0907 16-55-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36694, current rewards: -3155.86532, mean: -1.90112
[32m[0907 16-56-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36677, current rewards: -3255.86532, mean: -1.90401
[32m[0907 16-56-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36667, current rewards: -3355.86532, mean: -1.90674
[32m[0907 16-56-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36675, current rewards: -3455.86532, mean: -1.90932
[32m[0907 16-57-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36683, current rewards: -3555.86532, mean: -1.91176
[32m[0907 16-57-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36692, current rewards: -3655.86532, mean: -1.91407
[32m[0907 16-57-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36698, current rewards: -3755.86532, mean: -1.91626
[32m[0907 16-58-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36707, current rewards: -3855.86532, mean: -1.91834
[32m[0907 16-58-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36710, current rewards: -3955.86532, mean: -1.92032
[32m[0907 16-58-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36698, current rewards: -4055.86532, mean: -1.92221
[32m[0907 16-59-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36685, current rewards: -4155.86532, mean: -1.92401
[32m[0907 16-59-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36672, current rewards: -4255.86532, mean: -1.92573
[32m[0907 16-59-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36662, current rewards: -4355.86532, mean: -1.92737
[32m[0907 16-59-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36652, current rewards: -4455.86532, mean: -1.92895
[32m[0907 17-00-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36643, current rewards: -4555.86532, mean: -1.93045
[32m[0907 17-00-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36633, current rewards: -4655.86532, mean: -1.93189
[32m[0907 17-00-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36624, current rewards: -4755.86532, mean: -1.93328
[32m[0907 17-01-03 @Agent.py:117][0m Average action selection time: 0.3660
[32m[0907 17-01-03 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-01-03 @MBExp.py:227][0m Rewards obtained: [-4835.865317385673], Lows: [2404], Highs: [36], Total time: 87658.078445
[32m[0907 17-05-02 @MBExp.py:144][0m ####################################################################
[32m[0907 17-05-02 @MBExp.py:145][0m Starting training iteration 107.
[32m[0907 17-05-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.37172, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-05-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37141, current rewards: -58.68496, mean: -0.97808
[32m[0907 17-05-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37099, current rewards: -108.68496, mean: -0.98805
[32m[0907 17-06-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37158, current rewards: -158.68496, mean: -0.99178
[32m[0907 17-06-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37175, current rewards: -208.68496, mean: -0.99374
[32m[0907 17-06-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37168, current rewards: -258.68496, mean: -0.99494
[32m[0907 17-06-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37145, current rewards: -308.68496, mean: -0.99576
[32m[0907 17-07-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37116, current rewards: -358.68496, mean: -0.99635
[32m[0907 17-07-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37128, current rewards: -408.68496, mean: -0.99679
[32m[0907 17-07-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37130, current rewards: -408.92576, mean: -0.88897
[32m[0907 17-08-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37121, current rewards: -401.09984, mean: -0.78647
[32m[0907 17-08-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37125, current rewards: -427.39777, mean: -0.76321
[32m[0907 17-08-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37118, current rewards: -477.39777, mean: -0.78262
[32m[0907 17-09-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37116, current rewards: -527.39777, mean: -0.79909
[32m[0907 17-09-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37106, current rewards: -577.39777, mean: -0.81324
[32m[0907 17-09-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37109, current rewards: -627.39777, mean: -0.82552
[32m[0907 17-10-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37102, current rewards: -677.39777, mean: -0.83629
[32m[0907 17-10-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37097, current rewards: -727.39777, mean: -0.84581
[32m[0907 17-10-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37088, current rewards: -777.39777, mean: -0.85428
[32m[0907 17-10-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37081, current rewards: -827.39777, mean: -0.86187
[32m[0907 17-11-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37077, current rewards: -877.39777, mean: -0.86871
[32m[0907 17-11-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37072, current rewards: -927.39777, mean: -0.87490
[32m[0907 17-11-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37068, current rewards: -977.39777, mean: -0.88054
[32m[0907 17-12-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37067, current rewards: -1027.39777, mean: -0.88569
[32m[0907 17-12-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37061, current rewards: -1077.39777, mean: -0.89041
[32m[0907 17-12-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37054, current rewards: -1127.39777, mean: -0.89476
[32m[0907 17-13-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37049, current rewards: -1177.39777, mean: -0.89878
[32m[0907 17-13-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37047, current rewards: -1227.39777, mean: -0.90250
[32m[0907 17-13-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.37017, current rewards: -1277.39777, mean: -0.90596
[32m[0907 17-14-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36988, current rewards: -1327.39777, mean: -0.90918
[32m[0907 17-14-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36959, current rewards: -1377.39777, mean: -0.91218
[32m[0907 17-14-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36935, current rewards: -1427.39777, mean: -0.91500
[32m[0907 17-14-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36911, current rewards: -1477.39777, mean: -0.91764
[32m[0907 17-15-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36887, current rewards: -1527.39777, mean: -0.92012
[32m[0907 17-15-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36866, current rewards: -1577.39777, mean: -0.92245
[32m[0907 17-15-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36843, current rewards: -1627.39777, mean: -0.92466
[32m[0907 17-16-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36824, current rewards: -1677.39777, mean: -0.92674
[32m[0907 17-16-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36805, current rewards: -1727.39777, mean: -0.92871
[32m[0907 17-16-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36789, current rewards: -1777.39777, mean: -0.93057
[32m[0907 17-17-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36772, current rewards: -1827.39777, mean: -0.93235
[32m[0907 17-17-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36755, current rewards: -1877.39777, mean: -0.93403
[32m[0907 17-17-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36739, current rewards: -1927.39777, mean: -0.93563
[32m[0907 17-17-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36726, current rewards: -1977.39777, mean: -0.93716
[32m[0907 17-18-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36713, current rewards: -2027.39777, mean: -0.93861
[32m[0907 17-18-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36701, current rewards: -2077.39777, mean: -0.94000
[32m[0907 17-18-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36690, current rewards: -2127.39777, mean: -0.94133
[32m[0907 17-19-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36680, current rewards: -2177.39777, mean: -0.94260
[32m[0907 17-19-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36669, current rewards: -2227.39777, mean: -0.94381
[32m[0907 17-19-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36659, current rewards: -2277.39777, mean: -0.94498
[32m[0907 17-20-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36649, current rewards: -2327.39777, mean: -0.94610
[32m[0907 17-20-18 @Agent.py:117][0m Average action selection time: 0.3663
[32m[0907 17-20-18 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-20-19 @MBExp.py:227][0m Rewards obtained: [-2367.397767821101], Lows: [0], Highs: [2384], Total time: 88574.60196900001
[32m[0907 17-24-20 @MBExp.py:144][0m ####################################################################
[32m[0907 17-24-20 @MBExp.py:145][0m Starting training iteration 108.
[32m[0907 17-24-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.39303, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-24-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37526, current rewards: -96.82758, mean: -1.61379
[32m[0907 17-25-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37346, current rewards: -194.33246, mean: -1.76666
[32m[0907 17-25-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37288, current rewards: -289.87832, mean: -1.81174
[32m[0907 17-25-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37258, current rewards: -389.87832, mean: -1.85656
[32m[0907 17-25-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37223, current rewards: -489.87832, mean: -1.88415
[32m[0907 17-26-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37202, current rewards: -589.87832, mean: -1.90283
[32m[0907 17-26-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37159, current rewards: -689.87832, mean: -1.91633
[32m[0907 17-26-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37142, current rewards: -789.87832, mean: -1.92653
[32m[0907 17-27-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37142, current rewards: -889.87832, mean: -1.93452
[32m[0907 17-27-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37130, current rewards: -989.87832, mean: -1.94094
[32m[0907 17-27-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37137, current rewards: -1089.87832, mean: -1.94621
[32m[0907 17-28-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37130, current rewards: -1189.87832, mean: -1.95062
[32m[0907 17-28-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37126, current rewards: -1289.87832, mean: -1.95436
[32m[0907 17-28-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37124, current rewards: -1389.87832, mean: -1.95758
[32m[0907 17-29-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37118, current rewards: -1489.87832, mean: -1.96037
[32m[0907 17-29-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37111, current rewards: -1589.87832, mean: -1.96281
[32m[0907 17-29-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37109, current rewards: -1689.87832, mean: -1.96497
[32m[0907 17-29-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37102, current rewards: -1789.87832, mean: -1.96690
[32m[0907 17-30-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37101, current rewards: -1889.87832, mean: -1.96862
[32m[0907 17-30-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37097, current rewards: -1989.87832, mean: -1.97018
[32m[0907 17-30-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37096, current rewards: -2089.87832, mean: -1.97158
[32m[0907 17-31-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37094, current rewards: -2189.87832, mean: -1.97286
[32m[0907 17-31-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37095, current rewards: -2289.87832, mean: -1.97403
[32m[0907 17-31-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37093, current rewards: -2389.87832, mean: -1.97511
[32m[0907 17-32-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37097, current rewards: -2489.87832, mean: -1.97609
[32m[0907 17-32-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37091, current rewards: -2589.87832, mean: -1.97701
[32m[0907 17-32-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37089, current rewards: -2689.87832, mean: -1.97785
[32m[0907 17-33-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.37060, current rewards: -2789.87832, mean: -1.97864
[32m[0907 17-33-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.37030, current rewards: -2889.87832, mean: -1.97937
[32m[0907 17-33-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.37002, current rewards: -2989.87832, mean: -1.98005
[32m[0907 17-33-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36972, current rewards: -3089.87832, mean: -1.98069
[32m[0907 17-34-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36945, current rewards: -3189.87832, mean: -1.98129
[32m[0907 17-34-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36919, current rewards: -3289.87832, mean: -1.98185
[32m[0907 17-34-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36897, current rewards: -3389.87832, mean: -1.98238
[32m[0907 17-35-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36873, current rewards: -3489.87832, mean: -1.98289
[32m[0907 17-35-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36853, current rewards: -3589.87832, mean: -1.98336
[32m[0907 17-35-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36831, current rewards: -3689.87832, mean: -1.98381
[32m[0907 17-36-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36813, current rewards: -3789.87832, mean: -1.98423
[32m[0907 17-36-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36795, current rewards: -3889.87832, mean: -1.98463
[32m[0907 17-36-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36780, current rewards: -3989.87832, mean: -1.98501
[32m[0907 17-36-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36766, current rewards: -4089.87832, mean: -1.98538
[32m[0907 17-37-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36764, current rewards: -4189.87832, mean: -1.98572
[32m[0907 17-37-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36753, current rewards: -4289.87832, mean: -1.98605
[32m[0907 17-37-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36742, current rewards: -4389.87832, mean: -1.98637
[32m[0907 17-38-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36729, current rewards: -4489.87832, mean: -1.98667
[32m[0907 17-38-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36717, current rewards: -4589.87832, mean: -1.98696
[32m[0907 17-38-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36704, current rewards: -4689.87832, mean: -1.98724
[32m[0907 17-39-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36694, current rewards: -4789.87832, mean: -1.98750
[32m[0907 17-39-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36683, current rewards: -4889.87832, mean: -1.98776
[32m[0907 17-39-37 @Agent.py:117][0m Average action selection time: 0.3666
[32m[0907 17-39-37 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-39-37 @MBExp.py:227][0m Rewards obtained: [-4969.878321788234], Lows: [2475], Highs: [21], Total time: 89491.92878100001
[32m[0907 17-43-41 @MBExp.py:144][0m ####################################################################
[32m[0907 17-43-41 @MBExp.py:145][0m Starting training iteration 109.
[32m[0907 17-43-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.37227, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-44-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37158, current rewards: -56.16130, mean: -0.93602
[32m[0907 17-44-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37145, current rewards: -156.16130, mean: -1.41965
[32m[0907 17-44-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37149, current rewards: -256.16130, mean: -1.60101
[32m[0907 17-44-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37123, current rewards: -356.16130, mean: -1.69601
[32m[0907 17-45-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37130, current rewards: -456.16130, mean: -1.75447
[32m[0907 17-45-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37114, current rewards: -556.16130, mean: -1.79407
[32m[0907 17-45-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37109, current rewards: -656.16130, mean: -1.82267
[32m[0907 17-46-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37104, current rewards: -756.16130, mean: -1.84430
[32m[0907 17-46-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37104, current rewards: -856.16130, mean: -1.86122
[32m[0907 17-46-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37107, current rewards: -956.16130, mean: -1.87483
[32m[0907 17-47-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37106, current rewards: -1056.16130, mean: -1.88600
[32m[0907 17-47-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37103, current rewards: -1156.16130, mean: -1.89535
[32m[0907 17-47-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37100, current rewards: -1256.16130, mean: -1.90327
[32m[0907 17-48-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37093, current rewards: -1356.16130, mean: -1.91009
[32m[0907 17-48-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37091, current rewards: -1456.16130, mean: -1.91600
[32m[0907 17-48-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37086, current rewards: -1556.16130, mean: -1.92119
[32m[0907 17-49-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37080, current rewards: -1656.16130, mean: -1.92577
[32m[0907 17-49-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37076, current rewards: -1756.16130, mean: -1.92985
[32m[0907 17-49-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37075, current rewards: -1856.16130, mean: -1.93350
[32m[0907 17-49-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37075, current rewards: -1956.16130, mean: -1.93679
[32m[0907 17-50-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37071, current rewards: -2056.16130, mean: -1.93977
[32m[0907 17-50-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37069, current rewards: -2156.16130, mean: -1.94249
[32m[0907 17-50-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37067, current rewards: -2256.16130, mean: -1.94497
[32m[0907 17-51-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37061, current rewards: -2356.16130, mean: -1.94724
[32m[0907 17-51-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37058, current rewards: -2456.16130, mean: -1.94933
[32m[0907 17-51-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37057, current rewards: -2556.16130, mean: -1.95127
[32m[0907 17-52-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37053, current rewards: -2656.16130, mean: -1.95306
[32m[0907 17-52-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.37021, current rewards: -2756.16130, mean: -1.95472
[32m[0907 17-52-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36995, current rewards: -2856.16130, mean: -1.95627
[32m[0907 17-53-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36967, current rewards: -2956.16130, mean: -1.95772
[32m[0907 17-53-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36941, current rewards: -3056.16130, mean: -1.95908
[32m[0907 17-53-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36920, current rewards: -3156.16130, mean: -1.96035
[32m[0907 17-53-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36896, current rewards: -3256.16130, mean: -1.96154
[32m[0907 17-54-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36877, current rewards: -3356.16130, mean: -1.96267
[32m[0907 17-54-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36857, current rewards: -3456.16130, mean: -1.96373
[32m[0907 17-54-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36837, current rewards: -3556.16130, mean: -1.96473
[32m[0907 17-55-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36820, current rewards: -3656.16130, mean: -1.96568
[32m[0907 17-55-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36805, current rewards: -3756.16130, mean: -1.96658
[32m[0907 17-55-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36788, current rewards: -3856.16130, mean: -1.96743
[32m[0907 17-56-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36775, current rewards: -3956.16130, mean: -1.96824
[32m[0907 17-56-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36769, current rewards: -4056.16130, mean: -1.96901
[32m[0907 17-56-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36760, current rewards: -4156.16130, mean: -1.96974
[32m[0907 17-56-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36748, current rewards: -4256.16130, mean: -1.97045
[32m[0907 17-57-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36736, current rewards: -4356.16130, mean: -1.97111
[32m[0907 17-57-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36724, current rewards: -4456.16130, mean: -1.97175
[32m[0907 17-57-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36714, current rewards: -4556.16130, mean: -1.97236
[32m[0907 17-58-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36703, current rewards: -4656.16130, mean: -1.97295
[32m[0907 17-58-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36693, current rewards: -4756.16130, mean: -1.97351
[32m[0907 17-58-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36683, current rewards: -4856.16130, mean: -1.97405
[32m[0907 17-58-59 @Agent.py:117][0m Average action selection time: 0.3667
[32m[0907 17-58-59 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-58-59 @MBExp.py:227][0m Rewards obtained: [-4936.161302509825], Lows: [2449], Highs: [42], Total time: 90409.594962
[32m[0907 18-03-05 @MBExp.py:144][0m ####################################################################
[32m[0907 18-03-05 @MBExp.py:145][0m Starting training iteration 110.
[32m[0907 18-03-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35721, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-03-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36928, current rewards: -100.00000, mean: -1.66667
[32m[0907 18-03-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36964, current rewards: -200.00000, mean: -1.81818
[32m[0907 18-04-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36977, current rewards: -300.00000, mean: -1.87500
[32m[0907 18-04-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37010, current rewards: -400.00000, mean: -1.90476
[32m[0907 18-04-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37054, current rewards: -500.00000, mean: -1.92308
[32m[0907 18-05-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37087, current rewards: -596.48799, mean: -1.92415
[32m[0907 18-05-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37085, current rewards: -696.48799, mean: -1.93469
[32m[0907 18-05-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37087, current rewards: -796.48799, mean: -1.94265
[32m[0907 18-05-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37083, current rewards: -896.48799, mean: -1.94889
[32m[0907 18-06-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37076, current rewards: -996.48799, mean: -1.95390
[32m[0907 18-06-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37072, current rewards: -1096.48799, mean: -1.95801
[32m[0907 18-06-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37074, current rewards: -1196.48799, mean: -1.96146
[32m[0907 18-07-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37072, current rewards: -1296.48799, mean: -1.96438
[32m[0907 18-07-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37072, current rewards: -1396.48799, mean: -1.96688
[32m[0907 18-07-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37073, current rewards: -1496.48799, mean: -1.96906
[32m[0907 18-08-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37077, current rewards: -1596.48799, mean: -1.97097
[32m[0907 18-08-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37076, current rewards: -1696.48799, mean: -1.97266
[32m[0907 18-08-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37072, current rewards: -1796.48799, mean: -1.97416
[32m[0907 18-09-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37076, current rewards: -1896.48799, mean: -1.97551
[32m[0907 18-09-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37072, current rewards: -1996.48799, mean: -1.97672
[32m[0907 18-09-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37071, current rewards: -2096.48799, mean: -1.97782
[32m[0907 18-09-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37064, current rewards: -2196.48799, mean: -1.97882
[32m[0907 18-10-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37058, current rewards: -2296.48799, mean: -1.97973
[32m[0907 18-10-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37052, current rewards: -2396.48799, mean: -1.98057
[32m[0907 18-10-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37048, current rewards: -2496.48799, mean: -1.98134
[32m[0907 18-11-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37049, current rewards: -2596.48799, mean: -1.98205
[32m[0907 18-11-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37021, current rewards: -2696.48799, mean: -1.98271
[32m[0907 18-11-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36993, current rewards: -2796.48799, mean: -1.98332
[32m[0907 18-12-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36966, current rewards: -2896.48799, mean: -1.98390
[32m[0907 18-12-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36940, current rewards: -2996.48799, mean: -1.98443
[32m[0907 18-12-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36916, current rewards: -3096.48799, mean: -1.98493
[32m[0907 18-12-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36893, current rewards: -3196.48799, mean: -1.98540
[32m[0907 18-13-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36873, current rewards: -3296.48799, mean: -1.98584
[32m[0907 18-13-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36853, current rewards: -3396.48799, mean: -1.98625
[32m[0907 18-13-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36837, current rewards: -3496.48799, mean: -1.98664
[32m[0907 18-14-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36820, current rewards: -3596.48799, mean: -1.98701
[32m[0907 18-14-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36806, current rewards: -3696.48799, mean: -1.98736
[32m[0907 18-14-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36794, current rewards: -3796.48799, mean: -1.98769
[32m[0907 18-15-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36780, current rewards: -3896.48799, mean: -1.98800
[32m[0907 18-15-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36767, current rewards: -3996.48799, mean: -1.98830
[32m[0907 18-15-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36770, current rewards: -4096.48799, mean: -1.98859
[32m[0907 18-16-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36756, current rewards: -4196.48799, mean: -1.98886
[32m[0907 18-16-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36744, current rewards: -4296.48799, mean: -1.98911
[32m[0907 18-16-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36733, current rewards: -4396.48799, mean: -1.98936
[32m[0907 18-16-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36721, current rewards: -4496.48799, mean: -1.98960
[32m[0907 18-17-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36708, current rewards: -4596.48799, mean: -1.98982
[32m[0907 18-17-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36696, current rewards: -4696.48799, mean: -1.99004
[32m[0907 18-17-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36684, current rewards: -4796.48799, mean: -1.99024
[32m[0907 18-18-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36671, current rewards: -4896.48799, mean: -1.99044
[32m[0907 18-18-22 @Agent.py:117][0m Average action selection time: 0.3666
[32m[0907 18-18-22 @Agent.py:118][0m Rollout length: 2520
[32m[0907 18-18-22 @MBExp.py:227][0m Rewards obtained: [-4976.487993478084], Lows: [2478], Highs: [21], Total time: 91327.00187200001
[32m[0907 18-22-30 @MBExp.py:144][0m ####################################################################
[32m[0907 18-22-30 @MBExp.py:145][0m Starting training iteration 111.
[32m[0907 18-22-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35592, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-22-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36793, current rewards: -94.94369, mean: -1.58239
[32m[0907 18-23-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36888, current rewards: -194.94369, mean: -1.77222
[32m[0907 18-23-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36986, current rewards: -294.94369, mean: -1.84340
[32m[0907 18-23-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37021, current rewards: -394.94369, mean: -1.88068
[32m[0907 18-24-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37005, current rewards: -494.94369, mean: -1.90363
[32m[0907 18-24-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36999, current rewards: -594.94369, mean: -1.91917
[32m[0907 18-24-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36991, current rewards: -694.94369, mean: -1.93040
[32m[0907 18-25-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36988, current rewards: -794.94369, mean: -1.93889
[32m[0907 18-25-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36990, current rewards: -894.94369, mean: -1.94553
[32m[0907 18-25-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36988, current rewards: -994.94369, mean: -1.95087
[32m[0907 18-25-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36990, current rewards: -1094.94369, mean: -1.95526
[32m[0907 18-26-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36991, current rewards: -1194.94369, mean: -1.95892
[32m[0907 18-26-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36987, current rewards: -1294.94369, mean: -1.96204
[32m[0907 18-26-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36992, current rewards: -1394.94369, mean: -1.96471
[32m[0907 18-27-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36986, current rewards: -1494.94369, mean: -1.96703
[32m[0907 18-27-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36987, current rewards: -1594.94369, mean: -1.96907
[32m[0907 18-27-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36989, current rewards: -1694.94369, mean: -1.97086
[32m[0907 18-28-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36980, current rewards: -1794.94369, mean: -1.97247
[32m[0907 18-28-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36969, current rewards: -1894.94369, mean: -1.97390
[32m[0907 18-28-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36968, current rewards: -1994.94369, mean: -1.97519
[32m[0907 18-29-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36971, current rewards: -2094.94369, mean: -1.97636
[32m[0907 18-29-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36964, current rewards: -2194.94369, mean: -1.97743
[32m[0907 18-29-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36958, current rewards: -2294.94369, mean: -1.97840
[32m[0907 18-29-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36962, current rewards: -2394.94369, mean: -1.97929
[32m[0907 18-30-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36963, current rewards: -2494.94369, mean: -1.98011
[32m[0907 18-30-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36955, current rewards: -2594.94369, mean: -1.98087
[32m[0907 18-30-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36928, current rewards: -2694.94369, mean: -1.98158
[32m[0907 18-31-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36903, current rewards: -2794.94369, mean: -1.98223
[32m[0907 18-31-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36875, current rewards: -2894.94369, mean: -1.98284
[32m[0907 18-31-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36850, current rewards: -2994.94369, mean: -1.98341
[32m[0907 18-32-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36827, current rewards: -3094.94369, mean: -1.98394
[32m[0907 18-32-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36807, current rewards: -3194.94369, mean: -1.98444
[32m[0907 18-32-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36788, current rewards: -3294.94369, mean: -1.98491
[32m[0907 18-32-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36770, current rewards: -3394.94369, mean: -1.98535
[32m[0907 18-33-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36753, current rewards: -3494.94369, mean: -1.98576
[32m[0907 18-33-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36736, current rewards: -3594.94369, mean: -1.98616
[32m[0907 18-33-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36723, current rewards: -3694.94369, mean: -1.98653
[32m[0907 18-34-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36706, current rewards: -3794.94369, mean: -1.98688
[32m[0907 18-34-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36691, current rewards: -3894.94369, mean: -1.98722
[32m[0907 18-34-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36673, current rewards: -3994.94369, mean: -1.98753
[32m[0907 18-35-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36671, current rewards: -4094.94369, mean: -1.98784
[32m[0907 18-35-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36652, current rewards: -4194.94369, mean: -1.98812
[32m[0907 18-35-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36632, current rewards: -4294.94369, mean: -1.98840
[32m[0907 18-36-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36611, current rewards: -4394.94369, mean: -1.98866
[32m[0907 18-36-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36590, current rewards: -4494.94369, mean: -1.98891
[32m[0907 18-36-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36570, current rewards: -4594.94369, mean: -1.98915
[32m[0907 18-36-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36549, current rewards: -4694.94369, mean: -1.98938
[32m[0907 18-37-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36530, current rewards: -4794.94369, mean: -1.98960
[32m[0907 18-37-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36510, current rewards: -4894.94369, mean: -1.98981
[32m[0907 18-37-43 @Agent.py:117][0m Average action selection time: 0.3649
[32m[0907 18-37-43 @Agent.py:118][0m Rollout length: 2520
[32m[0907 18-37-43 @MBExp.py:227][0m Rewards obtained: [-4974.943691271455], Lows: [2476], Highs: [23], Total time: 92240.18979900001
[32m[0907 18-41-48 @MBExp.py:144][0m ####################################################################
[32m[0907 18-41-48 @MBExp.py:145][0m Starting training iteration 112.
[32m[0907 18-41-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34577, current rewards: 1.17349, mean: 0.11735
[32m[0907 18-42-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35969, current rewards: -77.40756, mean: -1.29013
[32m[0907 18-42-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36177, current rewards: -177.40756, mean: -1.61280
[32m[0907 18-42-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36198, current rewards: -277.40756, mean: -1.73380
[32m[0907 18-43-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36237, current rewards: -377.40756, mean: -1.79718
[32m[0907 18-43-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36257, current rewards: -477.40756, mean: -1.83618
[32m[0907 18-43-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36262, current rewards: -577.40756, mean: -1.86261
[32m[0907 18-43-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36260, current rewards: -677.40756, mean: -1.88169
[32m[0907 18-44-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36267, current rewards: -777.40756, mean: -1.89612
[32m[0907 18-44-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36254, current rewards: -877.40756, mean: -1.90741
[32m[0907 18-44-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36264, current rewards: -977.40756, mean: -1.91649
[32m[0907 18-45-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36264, current rewards: -1077.40756, mean: -1.92394
[32m[0907 18-45-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36267, current rewards: -1177.40756, mean: -1.93018
[32m[0907 18-45-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36265, current rewards: -1277.40756, mean: -1.93547
[32m[0907 18-46-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36267, current rewards: -1377.40756, mean: -1.94001
[32m[0907 18-46-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36260, current rewards: -1477.40756, mean: -1.94396
[32m[0907 18-46-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36255, current rewards: -1577.40756, mean: -1.94742
[32m[0907 18-47-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36251, current rewards: -1677.40756, mean: -1.95047
[32m[0907 18-47-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36251, current rewards: -1777.40756, mean: -1.95320
[32m[0907 18-47-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36251, current rewards: -1877.40756, mean: -1.95563
[32m[0907 18-47-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36248, current rewards: -1977.40756, mean: -1.95783
[32m[0907 18-48-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36243, current rewards: -2077.40756, mean: -1.95982
[32m[0907 18-48-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36244, current rewards: -2177.40756, mean: -1.96163
[32m[0907 18-48-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36242, current rewards: -2277.40756, mean: -1.96328
[32m[0907 18-49-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36241, current rewards: -2377.40756, mean: -1.96480
[32m[0907 18-49-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36241, current rewards: -2477.40756, mean: -1.96620
[32m[0907 18-49-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36223, current rewards: -2577.40756, mean: -1.96749
[32m[0907 18-50-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36198, current rewards: -2677.40756, mean: -1.96868
[32m[0907 18-50-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36173, current rewards: -2777.40756, mean: -1.96979
[32m[0907 18-50-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36150, current rewards: -2877.40756, mean: -1.97083
[32m[0907 18-50-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36126, current rewards: -2977.40756, mean: -1.97179
[32m[0907 18-51-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36107, current rewards: -3077.40756, mean: -1.97270
[32m[0907 18-51-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36086, current rewards: -3177.40756, mean: -1.97355
[32m[0907 18-51-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36066, current rewards: -3277.40756, mean: -1.97434
[32m[0907 18-52-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36047, current rewards: -3377.40756, mean: -1.97509
[32m[0907 18-52-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36029, current rewards: -3477.40756, mean: -1.97580
[32m[0907 18-52-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36014, current rewards: -3577.40756, mean: -1.97647
[32m[0907 18-52-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36001, current rewards: -3677.40756, mean: -1.97710
[32m[0907 18-53-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35990, current rewards: -3777.40756, mean: -1.97770
[32m[0907 18-53-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35977, current rewards: -3877.40756, mean: -1.97827
[32m[0907 18-53-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35975, current rewards: -3977.40756, mean: -1.97881
[32m[0907 18-54-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35971, current rewards: -4077.40756, mean: -1.97932
[32m[0907 18-54-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35959, current rewards: -4177.40756, mean: -1.97981
[32m[0907 18-54-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35950, current rewards: -4277.40756, mean: -1.98028
[32m[0907 18-55-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35939, current rewards: -4377.40756, mean: -1.98073
[32m[0907 18-55-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35929, current rewards: -4477.40756, mean: -1.98115
[32m[0907 18-55-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35918, current rewards: -4577.40756, mean: -1.98156
[32m[0907 18-55-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35909, current rewards: -4677.40756, mean: -1.98195
[32m[0907 18-56-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35901, current rewards: -4777.40756, mean: -1.98233
[32m[0907 18-56-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35893, current rewards: -4877.40756, mean: -1.98269
[32m[0907 18-56-46 @Agent.py:117][0m Average action selection time: 0.3589
[32m[0907 18-56-46 @Agent.py:118][0m Rollout length: 2520
[32m[0907 18-56-46 @MBExp.py:227][0m Rewards obtained: [-4957.407557814216], Lows: [2480], Highs: [0], Total time: 93138.20708000001
[32m[0907 19-00-54 @MBExp.py:144][0m ####################################################################
[32m[0907 19-00-54 @MBExp.py:145][0m Starting training iteration 113.
[32m[0907 19-00-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.57756, current rewards: 0.92163, mean: 0.09216
[32m[0907 19-01-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.43776, current rewards: -38.20008, mean: -0.63667
[32m[0907 19-01-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.40471, current rewards: -33.24287, mean: -0.30221
[32m[0907 19-01-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.39218, current rewards: -28.28566, mean: -0.17679
[32m[0907 19-02-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.38581, current rewards: -23.32845, mean: -0.11109
[32m[0907 19-02-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.38142, current rewards: -18.37124, mean: -0.07066
[32m[0907 19-02-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37862, current rewards: -13.41403, mean: -0.04327
[32m[0907 19-03-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37654, current rewards: -8.45682, mean: -0.02349
[32m[0907 19-03-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37494, current rewards: -2.22063, mean: -0.00542
[32m[0907 19-03-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37368, current rewards: 5.45808, mean: 0.01187
[32m[0907 19-04-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37258, current rewards: 7.85875, mean: 0.01541
[32m[0907 19-04-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37167, current rewards: 10.25943, mean: 0.01832
[32m[0907 19-04-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37100, current rewards: 12.66010, mean: 0.02075
[32m[0907 19-04-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37035, current rewards: 15.06078, mean: 0.02282
[32m[0907 19-05-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36983, current rewards: -13.97895, mean: -0.01969
[32m[0907 19-05-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36940, current rewards: -63.97895, mean: -0.08418
[32m[0907 19-05-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36903, current rewards: -113.97895, mean: -0.14071
[32m[0907 19-06-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36863, current rewards: -163.97895, mean: -0.19067
[32m[0907 19-06-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36835, current rewards: -213.97895, mean: -0.23514
[32m[0907 19-06-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36805, current rewards: -263.97895, mean: -0.27498
[32m[0907 19-07-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36781, current rewards: -313.97895, mean: -0.31087
[32m[0907 19-07-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36752, current rewards: -363.97895, mean: -0.34338
[32m[0907 19-07-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36728, current rewards: -413.97895, mean: -0.37295
[32m[0907 19-08-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36710, current rewards: -463.97895, mean: -0.39998
[32m[0907 19-08-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36693, current rewards: -513.97895, mean: -0.42478
[32m[0907 19-08-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36659, current rewards: -563.97895, mean: -0.44760
[32m[0907 19-08-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36614, current rewards: -613.97895, mean: -0.46869
[32m[0907 19-09-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36571, current rewards: -663.97895, mean: -0.48822
[32m[0907 19-09-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36532, current rewards: -713.97895, mean: -0.50637
[32m[0907 19-09-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36496, current rewards: -763.97895, mean: -0.52327
[32m[0907 19-10-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36464, current rewards: -813.97895, mean: -0.53906
[32m[0907 19-10-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36433, current rewards: -863.97895, mean: -0.55383
[32m[0907 19-10-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36404, current rewards: -913.97895, mean: -0.56769
[32m[0907 19-10-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36378, current rewards: -963.97895, mean: -0.58071
[32m[0907 19-11-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36353, current rewards: -1013.97895, mean: -0.59297
[32m[0907 19-11-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36328, current rewards: -1063.97895, mean: -0.60453
[32m[0907 19-11-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36305, current rewards: -1113.97895, mean: -0.61546
[32m[0907 19-12-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36283, current rewards: -1163.97895, mean: -0.62580
[32m[0907 19-12-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36261, current rewards: -1213.97895, mean: -0.63559
[32m[0907 19-12-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36244, current rewards: -1263.97895, mean: -0.64489
[32m[0907 19-13-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36251, current rewards: -1313.97895, mean: -0.65372
[32m[0907 19-13-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36244, current rewards: -1363.97895, mean: -0.66213
[32m[0907 19-13-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36219, current rewards: -1413.97895, mean: -0.67013
[32m[0907 19-13-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36196, current rewards: -1463.97895, mean: -0.67777
[32m[0907 19-14-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36169, current rewards: -1513.97895, mean: -0.68506
[32m[0907 19-14-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36129, current rewards: -1563.97895, mean: -0.69203
[32m[0907 19-14-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36091, current rewards: -1613.97895, mean: -0.69869
[32m[0907 19-15-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36056, current rewards: -1663.97895, mean: -0.70508
[32m[0907 19-15-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36021, current rewards: -1713.97895, mean: -0.71119
[32m[0907 19-15-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35988, current rewards: -1763.97895, mean: -0.71706
[32m[0907 19-15-53 @Agent.py:117][0m Average action selection time: 0.3596
[32m[0907 19-15-53 @Agent.py:118][0m Rollout length: 2520
[32m[0907 19-15-53 @MBExp.py:227][0m Rewards obtained: [-1803.9789499130889], Lows: [21], Highs: [1820], Total time: 94038.019358
[32m[0907 19-19-40 @MBExp.py:144][0m ####################################################################
[32m[0907 19-19-40 @MBExp.py:145][0m Starting training iteration 114.
[32m[0907 19-19-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34191, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-20-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35173, current rewards: -100.00000, mean: -1.66667
[32m[0907 19-20-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35261, current rewards: -200.00000, mean: -1.81818
[32m[0907 19-20-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35295, current rewards: -284.91258, mean: -1.78070
[32m[0907 19-20-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35282, current rewards: -334.91258, mean: -1.59482
[32m[0907 19-21-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35254, current rewards: -384.91258, mean: -1.48043
[32m[0907 19-21-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35247, current rewards: -434.91258, mean: -1.40294
[32m[0907 19-21-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35246, current rewards: -484.91258, mean: -1.34698
[32m[0907 19-22-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35217, current rewards: -534.91258, mean: -1.30466
[32m[0907 19-22-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35220, current rewards: -584.91258, mean: -1.27155
[32m[0907 19-22-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35231, current rewards: -634.91258, mean: -1.24493
[32m[0907 19-22-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35236, current rewards: -684.91258, mean: -1.22306
[32m[0907 19-23-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35236, current rewards: -734.91258, mean: -1.20477
[32m[0907 19-23-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35231, current rewards: -784.91258, mean: -1.18926
[32m[0907 19-23-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35235, current rewards: -834.91258, mean: -1.17593
[32m[0907 19-24-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35239, current rewards: -884.91258, mean: -1.16436
[32m[0907 19-24-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35240, current rewards: -934.91258, mean: -1.15421
[32m[0907 19-24-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35235, current rewards: -984.91258, mean: -1.14525
[32m[0907 19-25-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35226, current rewards: -1034.91258, mean: -1.13727
[32m[0907 19-25-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35221, current rewards: -1084.91258, mean: -1.13012
[32m[0907 19-25-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35218, current rewards: -1134.91258, mean: -1.12368
[32m[0907 19-25-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35217, current rewards: -1184.91258, mean: -1.11784
[32m[0907 19-26-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35215, current rewards: -1234.91258, mean: -1.11253
[32m[0907 19-26-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35213, current rewards: -1284.91258, mean: -1.10768
[32m[0907 19-26-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35211, current rewards: -1309.00749, mean: -1.08182
[32m[0907 19-27-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35200, current rewards: -1344.51616, mean: -1.06708
[32m[0907 19-27-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35168, current rewards: -1444.51616, mean: -1.10268
[32m[0907 19-27-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35140, current rewards: -1544.51616, mean: -1.13567
[32m[0907 19-27-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35112, current rewards: -1644.51616, mean: -1.16632
[32m[0907 19-28-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35086, current rewards: -1744.51616, mean: -1.19487
[32m[0907 19-28-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35062, current rewards: -1844.51616, mean: -1.22153
[32m[0907 19-28-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35042, current rewards: -1856.64968, mean: -1.19016
[32m[0907 19-29-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35023, current rewards: -1956.64968, mean: -1.21531
[32m[0907 19-29-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34998, current rewards: -2056.64968, mean: -1.23895
[32m[0907 19-29-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34878, current rewards: -2156.64968, mean: -1.26120
[32m[0907 19-29-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34761, current rewards: -2256.64968, mean: -1.28219
[32m[0907 19-30-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34653, current rewards: -2356.64968, mean: -1.30202
[32m[0907 19-30-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34547, current rewards: -2456.64968, mean: -1.32078
[32m[0907 19-30-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34447, current rewards: -2556.64968, mean: -1.33856
[32m[0907 19-30-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34358, current rewards: -2656.64968, mean: -1.35543
[32m[0907 19-31-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34292, current rewards: -2756.64968, mean: -1.37147
[32m[0907 19-31-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34224, current rewards: -2856.64968, mean: -1.38672
[32m[0907 19-31-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34159, current rewards: -2956.64968, mean: -1.40126
[32m[0907 19-31-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34094, current rewards: -3056.64968, mean: -1.41512
[32m[0907 19-32-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34036, current rewards: -3156.64968, mean: -1.42835
[32m[0907 19-32-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33966, current rewards: -3256.64968, mean: -1.44100
[32m[0907 19-32-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33896, current rewards: -3356.64968, mean: -1.45310
[32m[0907 19-32-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33829, current rewards: -3456.64968, mean: -1.46468
[32m[0907 19-33-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33764, current rewards: -3556.64968, mean: -1.47579
[32m[0907 19-33-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33703, current rewards: -3656.64968, mean: -1.48644
[32m[0907 19-33-42 @Agent.py:117][0m Average action selection time: 0.3366
[32m[0907 19-33-42 @Agent.py:118][0m Rollout length: 2520
[32m[0907 19-33-43 @MBExp.py:227][0m Rewards obtained: [-3736.649684089558], Lows: [1345], Highs: [1060], Total time: 94880.23410500001
[32m[0907 19-37-29 @MBExp.py:144][0m ####################################################################
[32m[0907 19-37-29 @MBExp.py:145][0m Starting training iteration 115.
[32m[0907 19-37-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.57044, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-37-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.43435, current rewards: -81.00000, mean: -1.35000
[32m[0907 19-38-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.39982, current rewards: -131.00000, mean: -1.19091
[32m[0907 19-38-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.38678, current rewards: -181.00000, mean: -1.13125
[32m[0907 19-38-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37992, current rewards: -231.00000, mean: -1.10000
[32m[0907 19-39-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37566, current rewards: -281.00000, mean: -1.08077
[32m[0907 19-39-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37271, current rewards: -331.00000, mean: -1.06774
[32m[0907 19-39-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37061, current rewards: -355.34175, mean: -0.98706
[32m[0907 19-40-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36902, current rewards: -351.36322, mean: -0.85698
[32m[0907 19-40-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36784, current rewards: -347.38470, mean: -0.75518
[32m[0907 19-40-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36668, current rewards: -343.40617, mean: -0.67335
[32m[0907 19-40-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36585, current rewards: -373.97390, mean: -0.66781
[32m[0907 19-41-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36521, current rewards: -423.97390, mean: -0.69504
[32m[0907 19-41-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36465, current rewards: -473.97390, mean: -0.71814
[32m[0907 19-41-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36416, current rewards: -523.97390, mean: -0.73799
[32m[0907 19-42-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36367, current rewards: -573.97390, mean: -0.75523
[32m[0907 19-42-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36334, current rewards: -623.97390, mean: -0.77034
[32m[0907 19-42-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36369, current rewards: -673.97390, mean: -0.78369
[32m[0907 19-43-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36394, current rewards: -723.97390, mean: -0.79558
[32m[0907 19-43-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36413, current rewards: -773.97390, mean: -0.80622
[32m[0907 19-43-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36405, current rewards: -823.97390, mean: -0.81582
[32m[0907 19-43-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36367, current rewards: -873.97390, mean: -0.82450
[32m[0907 19-44-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36338, current rewards: -923.97390, mean: -0.83241
[32m[0907 19-44-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36317, current rewards: -973.97390, mean: -0.83963
[32m[0907 19-44-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36294, current rewards: -1023.97390, mean: -0.84626
[32m[0907 19-45-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36239, current rewards: -1073.97390, mean: -0.85236
[32m[0907 19-45-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36190, current rewards: -1123.97390, mean: -0.85800
[32m[0907 19-45-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36143, current rewards: -1173.97390, mean: -0.86322
[32m[0907 19-45-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36099, current rewards: -1223.97390, mean: -0.86807
[32m[0907 19-46-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36058, current rewards: -1273.97390, mean: -0.87258
[32m[0907 19-46-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36018, current rewards: -1323.97390, mean: -0.87680
[32m[0907 19-46-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35982, current rewards: -1373.97390, mean: -0.88075
[32m[0907 19-47-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35949, current rewards: -1423.97390, mean: -0.88446
[32m[0907 19-47-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35916, current rewards: -1473.97390, mean: -0.88794
[32m[0907 19-47-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35887, current rewards: -1523.97390, mean: -0.89121
[32m[0907 19-48-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35859, current rewards: -1573.97390, mean: -0.89430
[32m[0907 19-48-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35831, current rewards: -1623.97390, mean: -0.89722
[32m[0907 19-48-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35805, current rewards: -1673.97390, mean: -0.89999
[32m[0907 19-48-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35780, current rewards: -1723.97390, mean: -0.90260
[32m[0907 19-49-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35774, current rewards: -1773.97390, mean: -0.90509
[32m[0907 19-49-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35772, current rewards: -1823.97390, mean: -0.90745
[32m[0907 19-49-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35772, current rewards: -1873.97390, mean: -0.90970
[32m[0907 19-50-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35772, current rewards: -1923.97390, mean: -0.91184
[32m[0907 19-50-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35769, current rewards: -1973.97390, mean: -0.91388
[32m[0907 19-50-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35767, current rewards: -2023.97390, mean: -0.91583
[32m[0907 19-50-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35746, current rewards: -2073.97390, mean: -0.91769
[32m[0907 19-51-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35726, current rewards: -2123.97390, mean: -0.91947
[32m[0907 19-51-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35709, current rewards: -2173.97390, mean: -0.92118
[32m[0907 19-51-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35692, current rewards: -2223.97390, mean: -0.92281
[32m[0907 19-52-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35676, current rewards: -2273.97390, mean: -0.92438
[32m[0907 19-52-21 @Agent.py:117][0m Average action selection time: 0.3566
[32m[0907 19-52-21 @Agent.py:118][0m Rollout length: 2520
[32m[0907 19-52-21 @MBExp.py:227][0m Rewards obtained: [-2313.973901590626], Lows: [21], Highs: [2287], Total time: 95772.534427
[32m[0907 19-56-22 @MBExp.py:144][0m ####################################################################
[32m[0907 19-56-22 @MBExp.py:145][0m Starting training iteration 116.
[32m[0907 19-56-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35119, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-56-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35569, current rewards: -95.12820, mean: -1.58547
[32m[0907 19-57-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35931, current rewards: -195.12820, mean: -1.77389
[32m[0907 19-57-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36045, current rewards: -295.12820, mean: -1.84455
[32m[0907 19-57-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36162, current rewards: -395.12820, mean: -1.88156
[32m[0907 19-57-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36201, current rewards: -495.12820, mean: -1.90434
[32m[0907 19-58-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36346, current rewards: -595.12820, mean: -1.91977
[32m[0907 19-58-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36430, current rewards: -695.12820, mean: -1.93091
[32m[0907 19-58-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36437, current rewards: -795.12820, mean: -1.93934
[32m[0907 19-59-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36468, current rewards: -895.12820, mean: -1.94593
[32m[0907 19-59-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36517, current rewards: -995.12820, mean: -1.95123
[32m[0907 19-59-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36542, current rewards: -1095.12820, mean: -1.95559
[32m[0907 20-00-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36564, current rewards: -1195.12820, mean: -1.95923
[32m[0907 20-00-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36579, current rewards: -1295.12820, mean: -1.96232
[32m[0907 20-00-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36541, current rewards: -1395.12820, mean: -1.96497
[32m[0907 20-01-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36507, current rewards: -1495.12820, mean: -1.96727
[32m[0907 20-01-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36477, current rewards: -1595.12820, mean: -1.96929
[32m[0907 20-01-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36443, current rewards: -1695.12820, mean: -1.97108
[32m[0907 20-01-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36405, current rewards: -1795.12820, mean: -1.97267
[32m[0907 20-02-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36371, current rewards: -1895.12820, mean: -1.97409
[32m[0907 20-02-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36334, current rewards: -1995.12820, mean: -1.97537
[32m[0907 20-02-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36306, current rewards: -2095.12820, mean: -1.97654
[32m[0907 20-03-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36279, current rewards: -2195.12820, mean: -1.97759
[32m[0907 20-03-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36257, current rewards: -2295.12820, mean: -1.97856
[32m[0907 20-03-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36208, current rewards: -2395.12820, mean: -1.97944
[32m[0907 20-03-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36154, current rewards: -2495.12820, mean: -1.98026
[32m[0907 20-04-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36118, current rewards: -2595.12820, mean: -1.98101
[32m[0907 20-04-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36084, current rewards: -2695.12820, mean: -1.98171
[32m[0907 20-04-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36052, current rewards: -2795.12820, mean: -1.98236
[32m[0907 20-05-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36015, current rewards: -2895.12820, mean: -1.98296
[32m[0907 20-05-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35970, current rewards: -2995.12820, mean: -1.98353
[32m[0907 20-05-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35930, current rewards: -3095.12820, mean: -1.98406
[32m[0907 20-06-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35892, current rewards: -3195.12820, mean: -1.98455
[32m[0907 20-06-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35856, current rewards: -3295.12820, mean: -1.98502
[32m[0907 20-06-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35824, current rewards: -3395.12820, mean: -1.98546
[32m[0907 20-06-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35792, current rewards: -3495.12820, mean: -1.98587
[32m[0907 20-07-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35760, current rewards: -3595.12820, mean: -1.98626
[32m[0907 20-07-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35732, current rewards: -3695.12820, mean: -1.98663
[32m[0907 20-07-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35709, current rewards: -3795.12820, mean: -1.98698
[32m[0907 20-08-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35711, current rewards: -3895.12820, mean: -1.98731
[32m[0907 20-08-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35711, current rewards: -3995.12820, mean: -1.98763
[32m[0907 20-08-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35707, current rewards: -4095.12820, mean: -1.98793
[32m[0907 20-08-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35704, current rewards: -4195.12820, mean: -1.98821
[32m[0907 20-09-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35705, current rewards: -4295.12820, mean: -1.98849
[32m[0907 20-09-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35701, current rewards: -4395.12820, mean: -1.98875
[32m[0907 20-09-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35678, current rewards: -4495.12820, mean: -1.98899
[32m[0907 20-10-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35658, current rewards: -4595.12820, mean: -1.98923
[32m[0907 20-10-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35640, current rewards: -4695.12820, mean: -1.98946
[32m[0907 20-10-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35620, current rewards: -4795.12820, mean: -1.98968
[32m[0907 20-10-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35602, current rewards: -4895.12820, mean: -1.98989
[32m[0907 20-11-12 @Agent.py:117][0m Average action selection time: 0.3558
[32m[0907 20-11-12 @Agent.py:118][0m Rollout length: 2520
[32m[0907 20-11-12 @MBExp.py:227][0m Rewards obtained: [-4975.128196229243], Lows: [2478], Highs: [20], Total time: 96662.905109
[32m[0907 20-15-18 @MBExp.py:144][0m ####################################################################
[32m[0907 20-15-18 @MBExp.py:145][0m Starting training iteration 117.
[32m[0907 20-15-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35910, current rewards: -10.00000, mean: -1.00000
[32m[0907 20-15-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35034, current rewards: -55.08580, mean: -0.91810
[32m[0907 20-15-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35174, current rewards: -155.08580, mean: -1.40987
[32m[0907 20-16-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35194, current rewards: -255.08580, mean: -1.59429
[32m[0907 20-16-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35064, current rewards: -355.08580, mean: -1.69088
[32m[0907 20-16-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34378, current rewards: -455.08580, mean: -1.75033
[32m[0907 20-17-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33937, current rewards: -555.08580, mean: -1.79060
[32m[0907 20-17-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33613, current rewards: -655.08580, mean: -1.81968
[32m[0907 20-17-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33374, current rewards: -755.08580, mean: -1.84167
[32m[0907 20-17-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33175, current rewards: -855.08580, mean: -1.85888
[32m[0907 20-18-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33006, current rewards: -955.08580, mean: -1.87272
[32m[0907 20-18-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32880, current rewards: -1055.08580, mean: -1.88408
[32m[0907 20-18-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32766, current rewards: -1155.08580, mean: -1.89358
[32m[0907 20-18-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32672, current rewards: -1255.08580, mean: -1.90165
[32m[0907 20-19-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32596, current rewards: -1355.08580, mean: -1.90857
[32m[0907 20-19-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32523, current rewards: -1455.08580, mean: -1.91459
[32m[0907 20-19-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32456, current rewards: -1555.08580, mean: -1.91986
[32m[0907 20-19-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32402, current rewards: -1655.08580, mean: -1.92452
[32m[0907 20-20-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32349, current rewards: -1755.08580, mean: -1.92867
[32m[0907 20-20-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32310, current rewards: -1855.08580, mean: -1.93238
[32m[0907 20-20-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32266, current rewards: -1955.08580, mean: -1.93573
[32m[0907 20-21-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32227, current rewards: -2055.08580, mean: -1.93876
[32m[0907 20-21-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32197, current rewards: -2155.08580, mean: -1.94152
[32m[0907 20-21-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32152, current rewards: -2255.08580, mean: -1.94404
[32m[0907 20-21-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32096, current rewards: -2355.08580, mean: -1.94635
[32m[0907 20-22-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32045, current rewards: -2455.08580, mean: -1.94848
[32m[0907 20-22-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32022, current rewards: -2555.08580, mean: -1.95045
[32m[0907 20-22-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32111, current rewards: -2655.08580, mean: -1.95227
[32m[0907 20-22-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32194, current rewards: -2755.08580, mean: -1.95396
[32m[0907 20-23-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32270, current rewards: -2855.08580, mean: -1.95554
[32m[0907 20-23-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32340, current rewards: -2955.08580, mean: -1.95701
[32m[0907 20-23-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32386, current rewards: -3055.08580, mean: -1.95839
[32m[0907 20-23-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32336, current rewards: -3155.08580, mean: -1.95968
[32m[0907 20-24-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32289, current rewards: -3255.08580, mean: -1.96090
[32m[0907 20-24-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32250, current rewards: -3355.08580, mean: -1.96204
[32m[0907 20-24-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32209, current rewards: -3455.08580, mean: -1.96312
[32m[0907 20-25-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32170, current rewards: -3555.08580, mean: -1.96414
[32m[0907 20-25-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32133, current rewards: -3655.08580, mean: -1.96510
[32m[0907 20-25-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32118, current rewards: -3755.08580, mean: -1.96601
[32m[0907 20-25-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32101, current rewards: -3855.08580, mean: -1.96688
[32m[0907 20-26-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32086, current rewards: -3955.08580, mean: -1.96770
[32m[0907 20-26-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32070, current rewards: -4055.08580, mean: -1.96849
[32m[0907 20-26-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32055, current rewards: -4155.08580, mean: -1.96923
[32m[0907 20-26-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32045, current rewards: -4255.08580, mean: -1.96995
[32m[0907 20-27-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32028, current rewards: -4355.08580, mean: -1.97063
[32m[0907 20-27-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32001, current rewards: -4455.08580, mean: -1.97128
[32m[0907 20-27-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31975, current rewards: -4555.08580, mean: -1.97190
[32m[0907 20-27-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31950, current rewards: -4655.08580, mean: -1.97249
[32m[0907 20-28-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31926, current rewards: -4755.08580, mean: -1.97306
[32m[0907 20-28-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31902, current rewards: -4855.08580, mean: -1.97361
[32m[0907 20-28-35 @Agent.py:117][0m Average action selection time: 0.3188
[32m[0907 20-28-35 @Agent.py:118][0m Rollout length: 2520
[32m[0907 20-28-36 @MBExp.py:227][0m Rewards obtained: [-4935.085798131262], Lows: [2456], Highs: [25], Total time: 97460.780285
[32m[0907 20-32-11 @MBExp.py:144][0m ####################################################################
[32m[0907 20-32-11 @MBExp.py:145][0m Starting training iteration 118.
[32m[0907 20-32-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29927, current rewards: -10.00000, mean: -1.00000
[32m[0907 20-32-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30415, current rewards: -60.00000, mean: -1.00000
[32m[0907 20-32-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30942, current rewards: -110.00000, mean: -1.00000
[32m[0907 20-33-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31147, current rewards: -160.00000, mean: -1.00000
[32m[0907 20-33-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31227, current rewards: -210.00000, mean: -1.00000
[32m[0907 20-33-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31626, current rewards: -260.00000, mean: -1.00000
[32m[0907 20-33-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32558, current rewards: -310.00000, mean: -1.00000
[32m[0907 20-34-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33134, current rewards: -360.00000, mean: -1.00000
[32m[0907 20-34-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33641, current rewards: -410.00000, mean: -1.00000
[32m[0907 20-34-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33843, current rewards: -460.00000, mean: -1.00000
[32m[0907 20-35-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33615, current rewards: -510.00000, mean: -1.00000
[32m[0907 20-35-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33424, current rewards: -560.00000, mean: -1.00000
[32m[0907 20-35-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33264, current rewards: -610.00000, mean: -1.00000
[32m[0907 20-35-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33126, current rewards: -660.00000, mean: -1.00000
[32m[0907 20-36-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33009, current rewards: -710.00000, mean: -1.00000
[32m[0907 20-36-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32907, current rewards: -760.00000, mean: -1.00000
[32m[0907 20-36-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32815, current rewards: -810.00000, mean: -1.00000
[32m[0907 20-36-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32740, current rewards: -860.00000, mean: -1.00000
[32m[0907 20-37-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32665, current rewards: -910.00000, mean: -1.00000
[32m[0907 20-37-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32600, current rewards: -960.00000, mean: -1.00000
[32m[0907 20-37-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32547, current rewards: -1010.00000, mean: -1.00000
[32m[0907 20-37-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32511, current rewards: -1060.00000, mean: -1.00000
[32m[0907 20-38-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32474, current rewards: -1110.00000, mean: -1.00000
[32m[0907 20-38-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32421, current rewards: -1160.00000, mean: -1.00000
[32m[0907 20-38-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32376, current rewards: -1210.00000, mean: -1.00000
[32m[0907 20-38-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32334, current rewards: -1260.00000, mean: -1.00000
[32m[0907 20-39-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32296, current rewards: -1310.00000, mean: -1.00000
[32m[0907 20-39-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32260, current rewards: -1360.00000, mean: -1.00000
[32m[0907 20-39-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32225, current rewards: -1410.00000, mean: -1.00000
[32m[0907 20-40-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32192, current rewards: -1446.21703, mean: -0.99056
[32m[0907 20-40-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32161, current rewards: -1496.21703, mean: -0.99087
[32m[0907 20-40-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32133, current rewards: -1546.21703, mean: -0.99116
[32m[0907 20-40-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32186, current rewards: -1596.21703, mean: -0.99144
[32m[0907 20-41-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32257, current rewards: -1646.21703, mean: -0.99170
[32m[0907 20-41-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32319, current rewards: -1696.21703, mean: -0.99194
[32m[0907 20-41-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32379, current rewards: -1746.21703, mean: -0.99217
[32m[0907 20-41-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32435, current rewards: -1796.21703, mean: -0.99239
[32m[0907 20-42-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32519, current rewards: -1840.96276, mean: -0.98976
[32m[0907 20-42-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32590, current rewards: -1838.31359, mean: -0.96247
[32m[0907 20-42-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32657, current rewards: -1835.66441, mean: -0.93656
[32m[0907 20-43-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32721, current rewards: -1859.33983, mean: -0.92504
[32m[0907 20-43-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32779, current rewards: -1909.33983, mean: -0.92686
[32m[0907 20-43-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32837, current rewards: -1959.33983, mean: -0.92860
[32m[0907 20-44-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32898, current rewards: -2009.33983, mean: -0.93025
[32m[0907 20-44-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32935, current rewards: -2059.33983, mean: -0.93183
[32m[0907 20-44-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32967, current rewards: -2109.33983, mean: -0.93334
[32m[0907 20-44-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32991, current rewards: -2159.33983, mean: -0.93478
[32m[0907 20-45-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33021, current rewards: -2209.33983, mean: -0.93616
[32m[0907 20-45-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33054, current rewards: -2259.33983, mean: -0.93749
[32m[0907 20-45-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33080, current rewards: -2309.33983, mean: -0.93876
[32m[0907 20-45-59 @Agent.py:117][0m Average action selection time: 0.3310
[32m[0907 20-45-59 @Agent.py:118][0m Rollout length: 2520
[32m[0907 20-45-59 @MBExp.py:227][0m Rewards obtained: [-2349.3398255669154], Lows: [0], Highs: [2357], Total time: 98289.046345
[32m[0907 20-49-59 @MBExp.py:144][0m ####################################################################
[32m[0907 20-49-59 @MBExp.py:145][0m Starting training iteration 119.
[32m[0907 20-50-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.37918, current rewards: -10.00000, mean: -1.00000
[32m[0907 20-50-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35125, current rewards: -58.89714, mean: -0.98162
[32m[0907 20-50-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35202, current rewards: -108.89714, mean: -0.98997
[32m[0907 20-50-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35269, current rewards: -158.89714, mean: -0.99311
[32m[0907 20-51-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35309, current rewards: -208.89714, mean: -0.99475
[32m[0907 20-51-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35337, current rewards: -258.89714, mean: -0.99576
[32m[0907 20-51-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35360, current rewards: -308.89714, mean: -0.99644
[32m[0907 20-52-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35380, current rewards: -358.89714, mean: -0.99694
[32m[0907 20-52-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35375, current rewards: -408.89714, mean: -0.99731
[32m[0907 20-52-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35382, current rewards: -458.89714, mean: -0.99760
[32m[0907 20-53-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35383, current rewards: -508.89714, mean: -0.99784
[32m[0907 20-53-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35396, current rewards: -558.89714, mean: -0.99803
[32m[0907 20-53-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35411, current rewards: -608.89714, mean: -0.99819
[32m[0907 20-53-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35420, current rewards: -658.89714, mean: -0.99833
[32m[0907 20-54-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35417, current rewards: -708.89714, mean: -0.99845
[32m[0907 20-54-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35419, current rewards: -758.89714, mean: -0.99855
[32m[0907 20-54-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35424, current rewards: -808.89714, mean: -0.99864
[32m[0907 20-55-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35423, current rewards: -858.89714, mean: -0.99872
[32m[0907 20-55-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35422, current rewards: -908.89714, mean: -0.99879
[32m[0907 20-55-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35428, current rewards: -958.89714, mean: -0.99885
[32m[0907 20-55-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35430, current rewards: -1008.89714, mean: -0.99891
[32m[0907 20-56-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35434, current rewards: -1058.89714, mean: -0.99896
[32m[0907 20-56-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35398, current rewards: -1108.89714, mean: -0.99901
[32m[0907 20-56-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35367, current rewards: -1158.89714, mean: -0.99905
[32m[0907 20-57-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35334, current rewards: -1208.89714, mean: -0.99909
[32m[0907 20-57-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35306, current rewards: -1258.89714, mean: -0.99912
[32m[0907 20-57-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35278, current rewards: -1308.89714, mean: -0.99916
[32m[0907 20-57-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35253, current rewards: -1358.89714, mean: -0.99919
[32m[0907 20-58-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35230, current rewards: -1408.89714, mean: -0.99922
[32m[0907 20-58-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35207, current rewards: -1458.89714, mean: -0.99924
[32m[0907 20-58-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35186, current rewards: -1508.89714, mean: -0.99927
[32m[0907 20-59-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35169, current rewards: -1513.79985, mean: -0.97038
[32m[0907 20-59-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35152, current rewards: -1510.11261, mean: -0.93796
[32m[0907 20-59-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35136, current rewards: -1506.42536, mean: -0.90749
[32m[0907 21-00-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35120, current rewards: -1502.73812, mean: -0.87879
[32m[0907 21-00-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35106, current rewards: -1499.05087, mean: -0.85173
[32m[0907 21-00-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35098, current rewards: -1495.36363, mean: -0.82617
[32m[0907 21-00-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35110, current rewards: -1529.42620, mean: -0.82227
[32m[0907 21-01-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35125, current rewards: -1579.42620, mean: -0.82692
[32m[0907 21-01-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35133, current rewards: -1629.42620, mean: -0.83134
[32m[0907 21-01-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35144, current rewards: -1679.42620, mean: -0.83554
[32m[0907 21-02-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35155, current rewards: -1729.42620, mean: -0.83953
[32m[0907 21-02-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35163, current rewards: -1779.42620, mean: -0.84333
[32m[0907 21-02-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35169, current rewards: -1829.42620, mean: -0.84696
[32m[0907 21-02-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35169, current rewards: -1879.42620, mean: -0.85042
[32m[0907 21-03-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35156, current rewards: -1929.42620, mean: -0.85373
[32m[0907 21-03-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35146, current rewards: -1979.42620, mean: -0.85689
[32m[0907 21-03-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35135, current rewards: -2029.42620, mean: -0.85993
[32m[0907 21-04-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35125, current rewards: -2079.42620, mean: -0.86283
[32m[0907 21-04-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35115, current rewards: -2129.42620, mean: -0.86562
[32m[0907 21-04-38 @Agent.py:117][0m Average action selection time: 0.3511
[32m[0907 21-04-38 @Agent.py:118][0m Rollout length: 2520
[32m[0907 21-04-38 @MBExp.py:227][0m Rewards obtained: [-2169.426195573078], Lows: [0], Highs: [2192], Total time: 99167.58213699999
[32m[0907 21-08-46 @MBExp.py:144][0m ####################################################################
[32m[0907 21-08-46 @MBExp.py:145][0m Starting training iteration 120.
[32m[0907 21-08-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33608, current rewards: -10.00000, mean: -1.00000
[32m[0907 21-09-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34413, current rewards: -95.92234, mean: -1.59871
[32m[0907 21-09-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34855, current rewards: -195.92234, mean: -1.78111
[32m[0907 21-09-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35060, current rewards: -295.92234, mean: -1.84951
[32m[0907 21-10-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35168, current rewards: -395.92234, mean: -1.88534
[32m[0907 21-10-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35240, current rewards: -495.92234, mean: -1.90739
[32m[0907 21-10-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35283, current rewards: -595.92234, mean: -1.92233
[32m[0907 21-10-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35308, current rewards: -695.92234, mean: -1.93312
[32m[0907 21-11-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35328, current rewards: -795.92234, mean: -1.94127
[32m[0907 21-11-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35346, current rewards: -895.92234, mean: -1.94766
[32m[0907 21-11-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35351, current rewards: -995.92234, mean: -1.95279
[32m[0907 21-12-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35353, current rewards: -1095.92234, mean: -1.95700
[32m[0907 21-12-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35358, current rewards: -1195.92234, mean: -1.96053
[32m[0907 21-12-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35360, current rewards: -1295.92234, mean: -1.96352
[32m[0907 21-12-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35368, current rewards: -1395.92234, mean: -1.96609
[32m[0907 21-13-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35370, current rewards: -1495.92234, mean: -1.96832
[32m[0907 21-13-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35372, current rewards: -1595.92234, mean: -1.97027
[32m[0907 21-13-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35375, current rewards: -1695.92234, mean: -1.97200
[32m[0907 21-14-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35370, current rewards: -1795.92234, mean: -1.97354
[32m[0907 21-14-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35375, current rewards: -1895.92234, mean: -1.97492
[32m[0907 21-14-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35381, current rewards: -1995.92234, mean: -1.97616
[32m[0907 21-15-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35279, current rewards: -2095.92234, mean: -1.97729
[32m[0907 21-15-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35130, current rewards: -2195.92234, mean: -1.97831
[32m[0907 21-15-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34995, current rewards: -2295.92234, mean: -1.97924
[32m[0907 21-15-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34869, current rewards: -2395.92234, mean: -1.98010
[32m[0907 21-16-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34755, current rewards: -2495.92234, mean: -1.98089
[32m[0907 21-16-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34647, current rewards: -2595.92234, mean: -1.98162
[32m[0907 21-16-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34546, current rewards: -2695.92234, mean: -1.98230
[32m[0907 21-16-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34456, current rewards: -2795.92234, mean: -1.98292
[32m[0907 21-17-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34372, current rewards: -2895.92234, mean: -1.98351
[32m[0907 21-17-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34293, current rewards: -2995.92234, mean: -1.98405
[32m[0907 21-17-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34218, current rewards: -3095.92234, mean: -1.98457
[32m[0907 21-17-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34151, current rewards: -3195.92234, mean: -1.98504
[32m[0907 21-18-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34083, current rewards: -3295.92234, mean: -1.98550
[32m[0907 21-18-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34022, current rewards: -3395.92234, mean: -1.98592
[32m[0907 21-18-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33965, current rewards: -3495.92234, mean: -1.98632
[32m[0907 21-19-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33910, current rewards: -3595.92234, mean: -1.98670
[32m[0907 21-19-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33857, current rewards: -3695.92234, mean: -1.98706
[32m[0907 21-19-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33808, current rewards: -3795.92234, mean: -1.98739
[32m[0907 21-19-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33761, current rewards: -3895.92234, mean: -1.98772
[32m[0907 21-20-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33717, current rewards: -3995.92234, mean: -1.98802
[32m[0907 21-20-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33674, current rewards: -4095.92234, mean: -1.98831
[32m[0907 21-20-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33635, current rewards: -4195.92234, mean: -1.98859
[32m[0907 21-20-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33597, current rewards: -4295.92234, mean: -1.98885
[32m[0907 21-21-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33522, current rewards: -4395.92234, mean: -1.98911
[32m[0907 21-21-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33394, current rewards: -4495.92234, mean: -1.98935
[32m[0907 21-21-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33272, current rewards: -4595.92234, mean: -1.98958
[32m[0907 21-21-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33156, current rewards: -4695.92234, mean: -1.98980
[32m[0907 21-22-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33045, current rewards: -4795.92234, mean: -1.99001
[32m[0907 21-22-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32938, current rewards: -4895.92234, mean: -1.99021
[32m[0907 21-22-28 @Agent.py:117][0m Average action selection time: 0.3286
[32m[0907 21-22-28 @Agent.py:118][0m Rollout length: 2520
[32m[0907 21-22-29 @MBExp.py:227][0m Rewards obtained: [-4975.922335745043], Lows: [2477], Highs: [22], Total time: 99989.794726
