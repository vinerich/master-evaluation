[32m[0906 13-39-16 @logger.py:99][0m Log file set to /app/logs/dats-delay-20/zinc-coating-v0_0/Tuesday_06_September_2022_01-39PM.log
[32m[0906 13-39-16 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00001, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00001, current rewards: -62.42621, mean: -1.04044
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00001, current rewards: -121.92712, mean: -1.10843
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00001, current rewards: -186.66326, mean: -1.16665
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00001, current rewards: -239.12895, mean: -1.13871
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00001, current rewards: -299.36130, mean: -1.15139
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00001, current rewards: -362.11887, mean: -1.16813
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00001, current rewards: -419.42326, mean: -1.16506
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00001, current rewards: -487.48969, mean: -1.18900
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00001, current rewards: -571.41837, mean: -1.24221
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00001, current rewards: -657.86378, mean: -1.28993
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00001, current rewards: -734.54111, mean: -1.31168
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00001, current rewards: -813.09557, mean: -1.33294
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00001, current rewards: -896.75827, mean: -1.35872
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00001, current rewards: -974.53649, mean: -1.37259
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00001, current rewards: -1065.64015, mean: -1.40216
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00001, current rewards: -1146.11329, mean: -1.41495
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00001, current rewards: -1222.18167, mean: -1.42114
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00001, current rewards: -1282.73582, mean: -1.40960
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00001, current rewards: -1330.18882, mean: -1.38561
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00001, current rewards: -1381.53529, mean: -1.36786
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00001, current rewards: -1427.99562, mean: -1.34717
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00001, current rewards: -1483.58526, mean: -1.33656
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00001, current rewards: -1535.98860, mean: -1.32413
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00001, current rewards: -1586.31878, mean: -1.31101
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00001, current rewards: -1639.48763, mean: -1.30118
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00001, current rewards: -1680.58272, mean: -1.28289
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00001, current rewards: -1733.57852, mean: -1.27469
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00001, current rewards: -1783.10508, mean: -1.26461
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00001, current rewards: -1831.71906, mean: -1.25460
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00001, current rewards: -1892.08292, mean: -1.25304
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00001, current rewards: -1952.63102, mean: -1.25169
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00001, current rewards: -2014.04057, mean: -1.25096
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00001, current rewards: -2072.67558, mean: -1.24860
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00001, current rewards: -2132.02888, mean: -1.24680
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00001, current rewards: -2196.06568, mean: -1.24776
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00001, current rewards: -2252.00351, mean: -1.24420
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00001, current rewards: -2315.26304, mean: -1.24477
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00001, current rewards: -2374.68848, mean: -1.24329
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00001, current rewards: -2425.48857, mean: -1.23749
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00001, current rewards: -2482.54946, mean: -1.23510
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00001, current rewards: -2534.74425, mean: -1.23046
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00001, current rewards: -2582.00970, mean: -1.22370
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00001, current rewards: -2631.80555, mean: -1.21843
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00001, current rewards: -2682.09547, mean: -1.21362
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00001, current rewards: -2736.28869, mean: -1.21075
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00001, current rewards: -2790.60503, mean: -1.20805
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00001, current rewards: -2835.87862, mean: -1.20164
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00001, current rewards: -2886.98455, mean: -1.19792
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00001, current rewards: -2947.62863, mean: -1.19822
[32m[0906 13-39-16 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-39-16 @Agent.py:118][0m Rollout length: 2520
[32m[0906 13-39-17 @MBExp.py:144][0m ####################################################################
[32m[0906 13-39-17 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-39-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20668, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-39-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19698, current rewards: -99.00000, mean: -1.65000
[32m[0906 13-39-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19683, current rewards: -199.00000, mean: -1.80909
[32m[0906 13-39-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19714, current rewards: -299.00000, mean: -1.86875
[32m[0906 13-40-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.20212, current rewards: -399.00000, mean: -1.90000
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.21086, current rewards: -499.00000, mean: -1.91923
[32m[0906 13-40-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.22257, current rewards: -599.00000, mean: -1.93226
[32m[0906 13-40-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.23446, current rewards: -699.00000, mean: -1.94167
[32m[0906 13-40-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.24622, current rewards: -799.00000, mean: -1.94878
[32m[0906 13-41-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.25534, current rewards: -899.00000, mean: -1.95435
[32m[0906 13-41-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.26436, current rewards: -999.00000, mean: -1.95882
[32m[0906 13-41-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.27390, current rewards: -1099.00000, mean: -1.96250
[32m[0906 13-42-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.28167, current rewards: -1199.00000, mean: -1.96557
[32m[0906 13-42-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.28818, current rewards: -1299.00000, mean: -1.96818
[32m[0906 13-42-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29389, current rewards: -1399.00000, mean: -1.97042
[32m[0906 13-43-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29872, current rewards: -1499.00000, mean: -1.97237
[32m[0906 13-43-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30266, current rewards: -1599.00000, mean: -1.97407
[32m[0906 13-43-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30615, current rewards: -1699.00000, mean: -1.97558
[32m[0906 13-43-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30932, current rewards: -1799.00000, mean: -1.97692
[32m[0906 13-44-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31225, current rewards: -1899.00000, mean: -1.97812
[32m[0906 13-44-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31492, current rewards: -1999.00000, mean: -1.97921
[32m[0906 13-44-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31733, current rewards: -2099.00000, mean: -1.98019
[32m[0906 13-45-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31950, current rewards: -2199.00000, mean: -1.98108
[32m[0906 13-45-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32143, current rewards: -2299.00000, mean: -1.98190
[32m[0906 13-45-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32322, current rewards: -2399.00000, mean: -1.98264
[32m[0906 13-46-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32489, current rewards: -2499.00000, mean: -1.98333
[32m[0906 13-46-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32649, current rewards: -2599.00000, mean: -1.98397
[32m[0906 13-46-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32798, current rewards: -2699.00000, mean: -1.98456
[32m[0906 13-47-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32915, current rewards: -2799.00000, mean: -1.98511
[32m[0906 13-47-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33015, current rewards: -2899.00000, mean: -1.98562
[32m[0906 13-47-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33115, current rewards: -2987.95762, mean: -1.97878
[32m[0906 13-47-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33213, current rewards: -3077.73951, mean: -1.97291
[32m[0906 13-48-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33307, current rewards: -3177.73951, mean: -1.97375
[32m[0906 13-48-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33400, current rewards: -3277.73951, mean: -1.97454
[32m[0906 13-48-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33488, current rewards: -3377.73951, mean: -1.97529
[32m[0906 13-49-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33566, current rewards: -3477.73951, mean: -1.97599
[32m[0906 13-49-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33638, current rewards: -3577.73951, mean: -1.97665
[32m[0906 13-49-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33719, current rewards: -3677.73951, mean: -1.97728
[32m[0906 13-50-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33792, current rewards: -3777.73951, mean: -1.97787
[32m[0906 13-50-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33864, current rewards: -3877.73951, mean: -1.97844
[32m[0906 13-50-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33928, current rewards: -3977.73951, mean: -1.97897
[32m[0906 13-50-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33988, current rewards: -4077.73951, mean: -1.97949
[32m[0906 13-51-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34045, current rewards: -4177.73951, mean: -1.97997
[32m[0906 13-51-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34097, current rewards: -4277.73951, mean: -1.98043
[32m[0906 13-51-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34147, current rewards: -4377.73951, mean: -1.98088
[32m[0906 13-52-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34196, current rewards: -4477.73951, mean: -1.98130
[32m[0906 13-52-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34249, current rewards: -4577.73951, mean: -1.98171
[32m[0906 13-52-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34294, current rewards: -4677.73951, mean: -1.98209
[32m[0906 13-53-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34327, current rewards: -4777.73951, mean: -1.98246
[32m[0906 13-53-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34357, current rewards: -4877.73951, mean: -1.98282
[32m[0906 13-53-38 @Agent.py:117][0m Average action selection time: 0.3438
[32m[0906 13-53-38 @Agent.py:118][0m Rollout length: 2520
[32m[0906 13-53-38 @MBExp.py:227][0m Rewards obtained: [-4957.739507182845], Lows: [2470], Highs: [21], Total time: 860.231743
[32m[0906 13-53-42 @MBExp.py:144][0m ####################################################################
[32m[0906 13-53-42 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-53-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36123, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-54-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35898, current rewards: -97.94719, mean: -1.63245
[32m[0906 13-54-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35807, current rewards: -197.94719, mean: -1.79952
[32m[0906 13-54-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35925, current rewards: -297.94719, mean: -1.86217
[32m[0906 13-54-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35960, current rewards: -397.94719, mean: -1.89499
[32m[0906 13-55-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35991, current rewards: -497.94719, mean: -1.91518
[32m[0906 13-55-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36052, current rewards: -597.94719, mean: -1.92886
[32m[0906 13-55-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36065, current rewards: -697.94719, mean: -1.93874
[32m[0906 13-56-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36092, current rewards: -797.94719, mean: -1.94621
[32m[0906 13-56-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36112, current rewards: -897.94719, mean: -1.95206
[32m[0906 13-56-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36054, current rewards: -997.94719, mean: -1.95676
[32m[0906 13-57-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36031, current rewards: -1097.94719, mean: -1.96062
[32m[0906 13-57-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36008, current rewards: -1197.94719, mean: -1.96385
[32m[0906 13-57-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35985, current rewards: -1297.94719, mean: -1.96659
[32m[0906 13-57-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35967, current rewards: -1397.94719, mean: -1.96894
[32m[0906 13-58-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35971, current rewards: -1497.94719, mean: -1.97098
[32m[0906 13-58-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35988, current rewards: -1597.94719, mean: -1.97277
[32m[0906 13-58-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36002, current rewards: -1697.94719, mean: -1.97436
[32m[0906 13-59-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36016, current rewards: -1797.94719, mean: -1.97577
[32m[0906 13-59-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36025, current rewards: -1897.94719, mean: -1.97703
[32m[0906 13-59-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36031, current rewards: -1997.94719, mean: -1.97817
[32m[0906 14-00-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36041, current rewards: -2097.94719, mean: -1.97920
[32m[0906 14-00-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36039, current rewards: -2197.94719, mean: -1.98013
[32m[0906 14-00-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36031, current rewards: -2297.94719, mean: -1.98099
[32m[0906 14-00-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36038, current rewards: -2397.94719, mean: -1.98177
[32m[0906 14-01-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36043, current rewards: -2497.94719, mean: -1.98250
[32m[0906 14-01-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36037, current rewards: -2597.94719, mean: -1.98317
[32m[0906 14-01-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36029, current rewards: -2695.71040, mean: -1.98214
[32m[0906 14-02-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36014, current rewards: -2795.71040, mean: -1.98277
[32m[0906 14-02-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36009, current rewards: -2895.71040, mean: -1.98336
[32m[0906 14-02-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35992, current rewards: -2995.71040, mean: -1.98391
[32m[0906 14-03-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35984, current rewards: -3095.71040, mean: -1.98443
[32m[0906 14-03-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35986, current rewards: -3195.71040, mean: -1.98491
[32m[0906 14-03-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35993, current rewards: -3295.71040, mean: -1.98537
[32m[0906 14-03-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36010, current rewards: -3395.71040, mean: -1.98580
[32m[0906 14-04-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36027, current rewards: -3495.71040, mean: -1.98620
[32m[0906 14-04-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36041, current rewards: -3595.71040, mean: -1.98658
[32m[0906 14-04-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36051, current rewards: -3695.71040, mean: -1.98694
[32m[0906 14-05-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36055, current rewards: -3720.79446, mean: -1.94806
[32m[0906 14-05-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36049, current rewards: -3747.74730, mean: -1.91212
[32m[0906 14-05-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36038, current rewards: -3807.29995, mean: -1.89418
[32m[0906 14-06-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36029, current rewards: -3907.29995, mean: -1.89675
[32m[0906 14-06-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36022, current rewards: -4007.29995, mean: -1.89919
[32m[0906 14-06-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36014, current rewards: -4107.29995, mean: -1.90153
[32m[0906 14-06-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36004, current rewards: -4207.29995, mean: -1.90376
[32m[0906 14-07-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36016, current rewards: -4307.29995, mean: -1.90588
[32m[0906 14-07-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36028, current rewards: -4387.29995, mean: -1.89926
[32m[0906 14-07-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36039, current rewards: -4487.29995, mean: -1.90140
[32m[0906 14-08-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36040, current rewards: -4587.29995, mean: -1.90344
[32m[0906 14-08-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36032, current rewards: -4687.29995, mean: -1.90541
[32m[0906 14-08-43 @Agent.py:117][0m Average action selection time: 0.3602
[32m[0906 14-08-43 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-08-43 @MBExp.py:227][0m Rewards obtained: [-4767.29994519131], Lows: [2384], Highs: [40], Total time: 1761.511533
[32m[0906 14-08-50 @MBExp.py:144][0m ####################################################################
[32m[0906 14-08-50 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 14-08-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36059, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-09-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35807, current rewards: -13.67765, mean: -0.22796
[32m[0906 14-09-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35775, current rewards: -5.42172, mean: -0.04929
[32m[0906 14-09-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35747, current rewards: 2.83155, mean: 0.01770
[32m[0906 14-10-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35781, current rewards: 11.07947, mean: 0.05276
[32m[0906 14-10-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35798, current rewards: 19.34382, mean: 0.07440
[32m[0906 14-10-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35884, current rewards: 26.12551, mean: 0.08428
[32m[0906 14-10-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35951, current rewards: 29.39031, mean: 0.08164
[32m[0906 14-11-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36044, current rewards: 32.21689, mean: 0.07858
[32m[0906 14-11-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36107, current rewards: 35.04445, mean: 0.07618
[32m[0906 14-11-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36121, current rewards: 37.87106, mean: 0.07426
[32m[0906 14-12-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36115, current rewards: 40.69766, mean: 0.07267
[32m[0906 14-12-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36113, current rewards: 25.97425, mean: 0.04258
[32m[0906 14-12-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36079, current rewards: 32.72561, mean: 0.04958
[32m[0906 14-13-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36070, current rewards: 39.48369, mean: 0.05561
[32m[0906 14-13-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36053, current rewards: 45.82025, mean: 0.06029
[32m[0906 14-13-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36032, current rewards: 51.11212, mean: 0.06310
[32m[0906 14-14-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36020, current rewards: 56.42741, mean: 0.06561
[32m[0906 14-14-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36002, current rewards: 61.73967, mean: 0.06785
[32m[0906 14-14-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35997, current rewards: 67.05712, mean: 0.06985
[32m[0906 14-14-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35989, current rewards: 72.37576, mean: 0.07166
[32m[0906 14-15-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35981, current rewards: 39.78100, mean: 0.03753
[32m[0906 14-15-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35969, current rewards: 51.60868, mean: 0.04649
[32m[0906 14-15-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35962, current rewards: 67.64088, mean: 0.05831
[32m[0906 14-16-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35953, current rewards: 77.24200, mean: 0.06384
[32m[0906 14-16-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35968, current rewards: 86.94838, mean: 0.06901
[32m[0906 14-16-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35977, current rewards: 96.65717, mean: 0.07378
[32m[0906 14-17-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35986, current rewards: 60.47709, mean: 0.04447
[32m[0906 14-17-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35992, current rewards: 63.44304, mean: 0.04500
[32m[0906 14-17-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36001, current rewards: 66.39977, mean: 0.04548
[32m[0906 14-17-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36006, current rewards: 69.35677, mean: 0.04593
[32m[0906 14-18-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36011, current rewards: 72.28272, mean: 0.04634
[32m[0906 14-18-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36011, current rewards: 22.28272, mean: 0.01384
[32m[0906 14-18-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36016, current rewards: -27.71728, mean: -0.01670
[32m[0906 14-19-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36010, current rewards: -77.71728, mean: -0.04545
[32m[0906 14-19-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35997, current rewards: -127.71728, mean: -0.07257
[32m[0906 14-19-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35984, current rewards: -177.71728, mean: -0.09819
[32m[0906 14-20-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35972, current rewards: -227.71728, mean: -0.12243
[32m[0906 14-20-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35962, current rewards: -277.71728, mean: -0.14540
[32m[0906 14-20-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35955, current rewards: -327.71728, mean: -0.16720
[32m[0906 14-20-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35944, current rewards: -397.12076, mean: -0.19757
[32m[0906 14-21-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35934, current rewards: -497.12076, mean: -0.24132
[32m[0906 14-21-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35924, current rewards: -597.12076, mean: -0.28300
[32m[0906 14-21-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35914, current rewards: -697.12076, mean: -0.32274
[32m[0906 14-22-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35908, current rewards: -797.12076, mean: -0.36069
[32m[0906 14-22-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35899, current rewards: -844.85502, mean: -0.37383
[32m[0906 14-22-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35894, current rewards: -834.91376, mean: -0.36143
[32m[0906 14-22-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35888, current rewards: -824.97378, mean: -0.34957
[32m[0906 14-23-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35879, current rewards: -815.41696, mean: -0.33835
[32m[0906 14-23-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35877, current rewards: -807.03080, mean: -0.32806
[32m[0906 14-23-48 @Agent.py:117][0m Average action selection time: 0.3588
[32m[0906 14-23-48 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-23-48 @MBExp.py:227][0m Rewards obtained: [-800.3057500680413], Lows: [298], Highs: [450], Total time: 2659.158474
[32m[0906 14-23-57 @MBExp.py:144][0m ####################################################################
[32m[0906 14-23-57 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 14-24-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36159, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-24-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35921, current rewards: -60.00000, mean: -1.00000
[32m[0906 14-24-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35923, current rewards: -110.00000, mean: -1.00000
[32m[0906 14-24-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35973, current rewards: -160.00000, mean: -1.00000
[32m[0906 14-25-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35900, current rewards: -210.00000, mean: -1.00000
[32m[0906 14-25-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35791, current rewards: -260.00000, mean: -1.00000
[32m[0906 14-25-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35750, current rewards: -304.75960, mean: -0.98310
[32m[0906 14-26-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35676, current rewards: -310.35737, mean: -0.86210
[32m[0906 14-26-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35651, current rewards: -320.08607, mean: -0.78070
[32m[0906 14-26-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35628, current rewards: -325.57842, mean: -0.70778
[32m[0906 14-26-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35601, current rewards: -331.07299, mean: -0.64916
[32m[0906 14-27-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35583, current rewards: -340.80348, mean: -0.60858
[32m[0906 14-27-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35582, current rewards: -346.29672, mean: -0.56770
[32m[0906 14-27-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35576, current rewards: -353.90911, mean: -0.53623
[32m[0906 14-28-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35570, current rewards: -361.49750, mean: -0.50915
[32m[0906 14-28-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35578, current rewards: -372.33874, mean: -0.48992
[32m[0906 14-28-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35583, current rewards: -388.53536, mean: -0.47967
[32m[0906 14-29-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35581, current rewards: -380.33622, mean: -0.44225
[32m[0906 14-29-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35583, current rewards: -372.14748, mean: -0.40895
[32m[0906 14-29-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35575, current rewards: -410.04012, mean: -0.42713
[32m[0906 14-29-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35585, current rewards: -400.70667, mean: -0.39674
[32m[0906 14-30-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35623, current rewards: -391.37323, mean: -0.36922
[32m[0906 14-30-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35628, current rewards: -387.66637, mean: -0.34925
[32m[0906 14-30-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35619, current rewards: -412.48135, mean: -0.35559
[32m[0906 14-31-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35614, current rewards: -462.48135, mean: -0.38222
[32m[0906 14-31-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35609, current rewards: -512.48135, mean: -0.40673
[32m[0906 14-31-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35601, current rewards: -562.48135, mean: -0.42938
[32m[0906 14-32-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35593, current rewards: -612.48135, mean: -0.45035
[32m[0906 14-32-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35587, current rewards: -662.48135, mean: -0.46984
[32m[0906 14-32-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35581, current rewards: -712.48135, mean: -0.48800
[32m[0906 14-32-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35576, current rewards: -762.48135, mean: -0.50495
[32m[0906 14-33-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35571, current rewards: -812.48135, mean: -0.52082
[32m[0906 14-33-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35565, current rewards: -862.48135, mean: -0.53570
[32m[0906 14-33-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35561, current rewards: -912.48135, mean: -0.54969
[32m[0906 14-34-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35556, current rewards: -962.48135, mean: -0.56285
[32m[0906 14-34-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35552, current rewards: -1012.48135, mean: -0.57527
[32m[0906 14-34-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35547, current rewards: -1062.48135, mean: -0.58701
[32m[0906 14-34-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35547, current rewards: -1112.48135, mean: -0.59811
[32m[0906 14-35-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35548, current rewards: -1162.48135, mean: -0.60863
[32m[0906 14-35-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35548, current rewards: -1212.48135, mean: -0.61861
[32m[0906 14-35-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35548, current rewards: -1262.48135, mean: -0.62810
[32m[0906 14-36-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35550, current rewards: -1312.48135, mean: -0.63713
[32m[0906 14-36-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35552, current rewards: -1362.48135, mean: -0.64573
[32m[0906 14-36-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35554, current rewards: -1412.48135, mean: -0.65393
[32m[0906 14-37-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35556, current rewards: -1462.48135, mean: -0.66176
[32m[0906 14-37-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35554, current rewards: -1512.48135, mean: -0.66924
[32m[0906 14-37-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35553, current rewards: -1562.48135, mean: -0.67640
[32m[0906 14-37-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35551, current rewards: -1612.48135, mean: -0.68325
[32m[0906 14-38-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35548, current rewards: -1662.48135, mean: -0.68983
[32m[0906 14-38-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35547, current rewards: -1712.48135, mean: -0.69613
[32m[0906 14-38-46 @Agent.py:117][0m Average action selection time: 0.3555
[32m[0906 14-38-46 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-38-46 @MBExp.py:227][0m Rewards obtained: [-1752.4813459198926], Lows: [43], Highs: [1747], Total time: 3548.477653
[32m[0906 14-38-57 @MBExp.py:144][0m ####################################################################
[32m[0906 14-38-57 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 14-39-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35903, current rewards: 0.80728, mean: 0.08073
[32m[0906 14-39-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35611, current rewards: 4.55612, mean: 0.07594
[32m[0906 14-39-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35738, current rewards: 8.29866, mean: 0.07544
[32m[0906 14-39-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35790, current rewards: 12.04119, mean: 0.07526
[32m[0906 14-40-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35717, current rewards: 15.78373, mean: 0.07516
[32m[0906 14-40-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35662, current rewards: 19.52626, mean: 0.07510
[32m[0906 14-40-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35705, current rewards: 18.79679, mean: 0.06063
[32m[0906 14-41-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35613, current rewards: -31.20321, mean: -0.08668
[32m[0906 14-41-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35615, current rewards: -81.20321, mean: -0.19806
[32m[0906 14-41-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35590, current rewards: -131.20321, mean: -0.28522
[32m[0906 14-41-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35566, current rewards: -181.20321, mean: -0.35530
[32m[0906 14-42-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35548, current rewards: -231.20321, mean: -0.41286
[32m[0906 14-42-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35536, current rewards: -281.20321, mean: -0.46099
[32m[0906 14-42-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35518, current rewards: -331.20321, mean: -0.50182
[32m[0906 14-43-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35508, current rewards: -381.20321, mean: -0.53691
[32m[0906 14-43-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35504, current rewards: -431.20321, mean: -0.56737
[32m[0906 14-43-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35490, current rewards: -481.20321, mean: -0.59408
[32m[0906 14-44-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35477, current rewards: -531.20321, mean: -0.61768
[32m[0906 14-44-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35470, current rewards: -581.20321, mean: -0.63868
[32m[0906 14-44-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35466, current rewards: -631.20321, mean: -0.65750
[32m[0906 14-44-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35466, current rewards: -681.20321, mean: -0.67446
[32m[0906 14-45-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35479, current rewards: -731.20321, mean: -0.68981
[32m[0906 14-45-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35487, current rewards: -781.20321, mean: -0.70379
[32m[0906 14-45-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35487, current rewards: -831.20321, mean: -0.71655
[32m[0906 14-46-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35498, current rewards: -881.20321, mean: -0.72827
[32m[0906 14-46-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35519, current rewards: -931.20321, mean: -0.73905
[32m[0906 14-46-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35531, current rewards: -981.20321, mean: -0.74901
[32m[0906 14-47-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35564, current rewards: -1031.20321, mean: -0.75824
[32m[0906 14-47-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35588, current rewards: -1081.20321, mean: -0.76681
[32m[0906 14-47-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35603, current rewards: -1131.20321, mean: -0.77480
[32m[0906 14-47-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35611, current rewards: -1181.20321, mean: -0.78225
[32m[0906 14-48-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35622, current rewards: -1231.20321, mean: -0.78923
[32m[0906 14-48-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35632, current rewards: -1281.20321, mean: -0.79578
[32m[0906 14-48-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35639, current rewards: -1309.03177, mean: -0.78857
[32m[0906 14-49-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35653, current rewards: -1359.03177, mean: -0.79476
[32m[0906 14-49-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35668, current rewards: -1409.03177, mean: -0.80059
[32m[0906 14-49-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35688, current rewards: -1459.03177, mean: -0.80609
[32m[0906 14-50-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35711, current rewards: -1509.03177, mean: -0.81131
[32m[0906 14-50-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35732, current rewards: -1559.03177, mean: -0.81625
[32m[0906 14-50-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35754, current rewards: -1609.03177, mean: -0.82093
[32m[0906 14-50-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35776, current rewards: -1659.03177, mean: -0.82539
[32m[0906 14-51-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35796, current rewards: -1709.03177, mean: -0.82963
[32m[0906 14-51-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35804, current rewards: -1759.03177, mean: -0.83366
[32m[0906 14-51-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35808, current rewards: -1809.03177, mean: -0.83751
[32m[0906 14-52-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35812, current rewards: -1859.03177, mean: -0.84119
[32m[0906 14-52-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35805, current rewards: -1909.03177, mean: -0.84470
[32m[0906 14-52-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35794, current rewards: -1959.03177, mean: -0.84807
[32m[0906 14-53-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35783, current rewards: -2009.03177, mean: -0.85128
[32m[0906 14-53-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35775, current rewards: -2059.03177, mean: -0.85437
[32m[0906 14-53-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35768, current rewards: -2109.03177, mean: -0.85733
[32m[0906 14-53-52 @Agent.py:117][0m Average action selection time: 0.3577
[32m[0906 14-53-52 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-53-52 @MBExp.py:227][0m Rewards obtained: [-2149.03176530047], Lows: [0], Highs: [2173], Total time: 4443.318394
[32m[0906 14-54-05 @MBExp.py:144][0m ####################################################################
[32m[0906 14-54-05 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 14-54-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35854, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-54-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35805, current rewards: -54.96862, mean: -0.91614
[32m[0906 14-54-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35826, current rewards: -88.10571, mean: -0.80096
[32m[0906 14-55-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35815, current rewards: -113.87335, mean: -0.71171
[32m[0906 14-55-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35563, current rewards: -140.25157, mean: -0.66786
[32m[0906 14-55-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35449, current rewards: -186.17459, mean: -0.71606
[32m[0906 14-55-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35487, current rewards: -237.49184, mean: -0.76610
[32m[0906 14-56-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35464, current rewards: -246.03131, mean: -0.68342
[32m[0906 14-56-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35527, current rewards: -239.44751, mean: -0.58402
[32m[0906 14-56-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35568, current rewards: -232.86500, mean: -0.50623
[32m[0906 14-57-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35570, current rewards: -226.28578, mean: -0.44370
[32m[0906 14-57-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35578, current rewards: -219.70044, mean: -0.39232
[32m[0906 14-57-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35671, current rewards: -213.11842, mean: -0.34937
[32m[0906 14-58-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35719, current rewards: -206.54164, mean: -0.31294
[32m[0906 14-58-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35702, current rewards: -199.97110, mean: -0.28165
[32m[0906 14-58-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35686, current rewards: -193.38905, mean: -0.25446
[32m[0906 14-58-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35676, current rewards: -263.62314, mean: -0.32546
[32m[0906 14-59-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35673, current rewards: -309.70413, mean: -0.36012
[32m[0906 14-59-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35674, current rewards: -355.50397, mean: -0.39066
[32m[0906 14-59-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35680, current rewards: -401.86646, mean: -0.41861
[32m[0906 15-00-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35686, current rewards: -448.16893, mean: -0.44373
[32m[0906 15-00-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35713, current rewards: -494.51006, mean: -0.46652
[32m[0906 15-00-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35731, current rewards: -544.75467, mean: -0.49077
[32m[0906 15-01-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35748, current rewards: -618.67374, mean: -0.53334
[32m[0906 15-01-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35773, current rewards: -704.36503, mean: -0.58212
[32m[0906 15-01-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35783, current rewards: -788.22283, mean: -0.62557
[32m[0906 15-01-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35777, current rewards: -826.45512, mean: -0.63088
[32m[0906 15-02-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35769, current rewards: -867.34647, mean: -0.63775
[32m[0906 15-02-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35767, current rewards: -922.87846, mean: -0.65452
[32m[0906 15-02-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35762, current rewards: -978.40578, mean: -0.67014
[32m[0906 15-03-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35759, current rewards: -1025.23302, mean: -0.67896
[32m[0906 15-03-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35755, current rewards: -1063.86885, mean: -0.68197
[32m[0906 15-03-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35751, current rewards: -1102.75176, mean: -0.68494
[32m[0906 15-03-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35765, current rewards: -1160.64803, mean: -0.69919
[32m[0906 15-04-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35795, current rewards: -1200.16059, mean: -0.70185
[32m[0906 15-04-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35820, current rewards: -1239.72103, mean: -0.70439
[32m[0906 15-04-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35845, current rewards: -1289.69820, mean: -0.71254
[32m[0906 15-05-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35867, current rewards: -1345.90338, mean: -0.72360
[32m[0906 15-05-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35882, current rewards: -1402.10441, mean: -0.73409
[32m[0906 15-05-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35877, current rewards: -1451.13643, mean: -0.74038
[32m[0906 15-06-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35877, current rewards: -1504.92368, mean: -0.74872
[32m[0906 15-06-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35880, current rewards: -1558.19629, mean: -0.75641
[32m[0906 15-06-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35871, current rewards: -1611.58707, mean: -0.76379
[32m[0906 15-07-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35861, current rewards: -1664.97620, mean: -0.77082
[32m[0906 15-07-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35856, current rewards: -1718.38796, mean: -0.77755
[32m[0906 15-07-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35855, current rewards: -1771.77851, mean: -0.78397
[32m[0906 15-07-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35857, current rewards: -1825.60632, mean: -0.79031
[32m[0906 15-08-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35857, current rewards: -1872.65647, mean: -0.79350
[32m[0906 15-08-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35861, current rewards: -1928.07138, mean: -0.80003
[32m[0906 15-08-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35868, current rewards: -1967.64339, mean: -0.79986
[32m[0906 15-09-02 @Agent.py:117][0m Average action selection time: 0.3587
[32m[0906 15-09-02 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-09-02 @MBExp.py:227][0m Rewards obtained: [-1996.5751812369845], Lows: [1136], Highs: [46], Total time: 5340.708839
[32m[0906 15-09-18 @MBExp.py:144][0m ####################################################################
[32m[0906 15-09-18 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 15-09-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36340, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-09-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36025, current rewards: -39.72100, mean: -0.66202
[32m[0906 15-09-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35958, current rewards: -34.40732, mean: -0.31279
[32m[0906 15-10-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35881, current rewards: -29.20760, mean: -0.18255
[32m[0906 15-10-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35698, current rewards: -22.73738, mean: -0.10827
[32m[0906 15-10-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35712, current rewards: -17.26297, mean: -0.06640
[32m[0906 15-11-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35716, current rewards: -11.92620, mean: -0.03847
[32m[0906 15-11-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35663, current rewards: -6.58516, mean: -0.01829
[32m[0906 15-11-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35709, current rewards: -1.24819, mean: -0.00304
[32m[0906 15-12-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35731, current rewards: 4.08815, mean: 0.00889
[32m[0906 15-12-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35740, current rewards: -42.34796, mean: -0.08304
[32m[0906 15-12-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35734, current rewards: -32.12763, mean: -0.05737
[32m[0906 15-12-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35746, current rewards: -22.02645, mean: -0.03611
[32m[0906 15-13-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35762, current rewards: -12.41901, mean: -0.01882
[32m[0906 15-13-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35785, current rewards: -2.41276, mean: -0.00340
[32m[0906 15-13-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35792, current rewards: 7.60459, mean: 0.01001
[32m[0906 15-14-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35794, current rewards: 17.60754, mean: 0.02174
[32m[0906 15-14-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35796, current rewards: 27.62183, mean: 0.03212
[32m[0906 15-14-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35790, current rewards: 37.63724, mean: 0.04136
[32m[0906 15-15-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35783, current rewards: 27.25323, mean: 0.02839
[32m[0906 15-15-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35775, current rewards: 33.67549, mean: 0.03334
[32m[0906 15-15-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35778, current rewards: 41.00557, mean: 0.03868
[32m[0906 15-15-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35793, current rewards: 47.48403, mean: 0.04278
[32m[0906 15-16-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35817, current rewards: 53.96409, mean: 0.04652
[32m[0906 15-16-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35842, current rewards: 60.44408, mean: 0.04995
[32m[0906 15-16-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35865, current rewards: 24.27696, mean: 0.01927
[32m[0906 15-17-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35898, current rewards: 0.54124, mean: 0.00041
[32m[0906 15-17-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35909, current rewards: 6.34454, mean: 0.00467
[32m[0906 15-17-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35912, current rewards: 12.10794, mean: 0.00859
[32m[0906 15-18-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35915, current rewards: 11.55132, mean: 0.00791
[32m[0906 15-18-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35924, current rewards: 17.70139, mean: 0.01172
[32m[0906 15-18-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35933, current rewards: 23.85695, mean: 0.01529
[32m[0906 15-18-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35928, current rewards: 30.00909, mean: 0.01864
[32m[0906 15-19-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35917, current rewards: 36.16490, mean: 0.02179
[32m[0906 15-19-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35908, current rewards: 42.31606, mean: 0.02475
[32m[0906 15-19-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35900, current rewards: 48.46509, mean: 0.02754
[32m[0906 15-20-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35899, current rewards: 54.61908, mean: 0.03018
[32m[0906 15-20-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35894, current rewards: 35.57253, mean: 0.01913
[32m[0906 15-20-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35894, current rewards: 24.65630, mean: 0.01291
[32m[0906 15-21-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35890, current rewards: 28.32327, mean: 0.01445
[32m[0906 15-21-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35881, current rewards: -25.78656, mean: -0.01283
[32m[0906 15-21-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35877, current rewards: -15.82848, mean: -0.00768
[32m[0906 15-21-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35872, current rewards: -8.48098, mean: -0.00402
[32m[0906 15-22-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35868, current rewards: -1.14935, mean: -0.00053
[32m[0906 15-22-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35864, current rewards: 5.01242, mean: 0.00227
[32m[0906 15-22-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35862, current rewards: 8.67136, mean: 0.00384
[32m[0906 15-23-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35861, current rewards: -20.58563, mean: -0.00891
[32m[0906 15-23-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35858, current rewards: -23.66501, mean: -0.01003
[32m[0906 15-23-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35857, current rewards: -19.96440, mean: -0.00828
[32m[0906 15-24-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35853, current rewards: -16.26594, mean: -0.00661
[32m[0906 15-24-15 @Agent.py:117][0m Average action selection time: 0.3585
[32m[0906 15-24-15 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-24-15 @MBExp.py:227][0m Rewards obtained: [-13.308884867971917], Lows: [127], Highs: [85], Total time: 6237.620989999999
[32m[0906 15-24-32 @MBExp.py:144][0m ####################################################################
[32m[0906 15-24-32 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 15-24-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35918, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-24-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35699, current rewards: -97.78125, mean: -1.62969
[32m[0906 15-25-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35697, current rewards: -197.78125, mean: -1.79801
[32m[0906 15-25-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35630, current rewards: -297.78125, mean: -1.86113
[32m[0906 15-25-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35454, current rewards: -397.78125, mean: -1.89420
[32m[0906 15-26-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35443, current rewards: -449.38849, mean: -1.72842
[32m[0906 15-26-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35455, current rewards: -496.05808, mean: -1.60019
[32m[0906 15-26-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35445, current rewards: -543.51385, mean: -1.50976
[32m[0906 15-26-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35504, current rewards: -590.54283, mean: -1.44035
[32m[0906 15-27-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35556, current rewards: -643.33561, mean: -1.39856
[32m[0906 15-27-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35562, current rewards: -690.91485, mean: -1.35474
[32m[0906 15-27-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35540, current rewards: -755.33392, mean: -1.34881
[32m[0906 15-28-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35570, current rewards: -793.56088, mean: -1.30092
[32m[0906 15-28-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35612, current rewards: -829.15167, mean: -1.25629
[32m[0906 15-28-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35640, current rewards: -866.25908, mean: -1.22008
[32m[0906 15-29-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35659, current rewards: -903.51309, mean: -1.18883
[32m[0906 15-29-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35672, current rewards: -953.72253, mean: -1.17744
[32m[0906 15-29-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35683, current rewards: -1008.24967, mean: -1.17238
[32m[0906 15-29-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35696, current rewards: -1060.57685, mean: -1.16547
[32m[0906 15-30-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35707, current rewards: -1097.68080, mean: -1.14342
[32m[0906 15-30-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35709, current rewards: -1134.92247, mean: -1.12369
[32m[0906 15-30-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35708, current rewards: -1173.25026, mean: -1.10684
[32m[0906 15-31-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35716, current rewards: -1256.29427, mean: -1.13180
[32m[0906 15-31-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35730, current rewards: -1356.29427, mean: -1.16922
[32m[0906 15-31-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35747, current rewards: -1456.29427, mean: -1.20355
[32m[0906 15-32-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35759, current rewards: -1556.29427, mean: -1.23515
[32m[0906 15-32-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35783, current rewards: -1656.29427, mean: -1.26435
[32m[0906 15-32-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35803, current rewards: -1756.29427, mean: -1.29139
[32m[0906 15-32-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35825, current rewards: -1856.29427, mean: -1.31652
[32m[0906 15-33-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35839, current rewards: -1956.29427, mean: -1.33993
[32m[0906 15-33-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35854, current rewards: -2056.29427, mean: -1.36178
[32m[0906 15-33-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35867, current rewards: -2156.29427, mean: -1.38224
[32m[0906 15-34-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35866, current rewards: -2256.29427, mean: -1.40143
[32m[0906 15-34-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35860, current rewards: -2315.65242, mean: -1.39497
[32m[0906 15-34-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35861, current rewards: -2386.78905, mean: -1.39578
[32m[0906 15-35-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35864, current rewards: -2459.19184, mean: -1.39727
[32m[0906 15-35-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35853, current rewards: -2504.88626, mean: -1.38392
[32m[0906 15-35-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35849, current rewards: -2601.93388, mean: -1.39889
[32m[0906 15-35-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35843, current rewards: -2649.48691, mean: -1.38717
[32m[0906 15-36-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35838, current rewards: -2707.43509, mean: -1.38134
[32m[0906 15-36-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35834, current rewards: -2752.58351, mean: -1.36944
[32m[0906 15-36-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35831, current rewards: -2783.58124, mean: -1.35125
[32m[0906 15-37-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35827, current rewards: -2814.46610, mean: -1.33387
[32m[0906 15-37-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35825, current rewards: -2907.18356, mean: -1.34592
[32m[0906 15-37-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35827, current rewards: -2960.85038, mean: -1.33975
[32m[0906 15-38-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35821, current rewards: -3003.09714, mean: -1.32880
[32m[0906 15-38-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35807, current rewards: -3041.94024, mean: -1.31686
[32m[0906 15-38-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35793, current rewards: -3083.25927, mean: -1.30647
[32m[0906 15-38-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35752, current rewards: -3135.60533, mean: -1.30108
[32m[0906 15-39-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35663, current rewards: -3190.55002, mean: -1.29697
[32m[0906 15-39-22 @Agent.py:117][0m Average action selection time: 0.3560
[32m[0906 15-39-22 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-39-22 @MBExp.py:227][0m Rewards obtained: [-3225.265132958692], Lows: [1695], Highs: [38], Total time: 7128.197165
[32m[0906 15-39-40 @MBExp.py:144][0m ####################################################################
[32m[0906 15-39-40 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 15-39-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31735, current rewards: 1.33336, mean: 0.13334
[32m[0906 15-39-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31643, current rewards: 10.20561, mean: 0.17009
[32m[0906 15-40-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31600, current rewards: 17.91982, mean: 0.16291
[32m[0906 15-40-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31473, current rewards: 23.86297, mean: 0.14914
[32m[0906 15-40-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31259, current rewards: 33.39592, mean: 0.15903
[32m[0906 15-41-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31278, current rewards: 46.23327, mean: 0.17782
[32m[0906 15-41-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31263, current rewards: 54.65525, mean: 0.17631
[32m[0906 15-41-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31301, current rewards: 63.10757, mean: 0.17530
[32m[0906 15-41-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31356, current rewards: 71.41490, mean: 0.17418
[32m[0906 15-42-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31379, current rewards: 79.71297, mean: 0.17329
[32m[0906 15-42-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31386, current rewards: 88.00870, mean: 0.17257
[32m[0906 15-42-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31365, current rewards: 96.30934, mean: 0.17198
[32m[0906 15-42-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31398, current rewards: 77.95782, mean: 0.12780
[32m[0906 15-43-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31428, current rewards: 107.02105, mean: 0.16215
[32m[0906 15-43-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31440, current rewards: 145.60031, mean: 0.20507
[32m[0906 15-43-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31463, current rewards: 184.35750, mean: 0.24258
[32m[0906 15-43-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31477, current rewards: 222.93572, mean: 0.27523
[32m[0906 15-44-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31494, current rewards: 261.29295, mean: 0.30383
[32m[0906 15-44-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31503, current rewards: 300.18295, mean: 0.32987
[32m[0906 15-44-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31512, current rewards: 338.92790, mean: 0.35305
[32m[0906 15-44-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31523, current rewards: 318.69339, mean: 0.31554
[32m[0906 15-45-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31530, current rewards: 303.07203, mean: 0.28592
[32m[0906 15-45-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31535, current rewards: 307.42666, mean: 0.27696
[32m[0906 15-45-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31544, current rewards: 312.42512, mean: 0.26933
[32m[0906 15-46-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31552, current rewards: 317.42807, mean: 0.26234
[32m[0906 15-46-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31556, current rewards: 322.42709, mean: 0.25589
[32m[0906 15-46-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31559, current rewards: 327.42671, mean: 0.24994
[32m[0906 15-46-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31563, current rewards: 332.42125, mean: 0.24443
[32m[0906 15-47-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31565, current rewards: 346.67037, mean: 0.24587
[32m[0906 15-47-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31568, current rewards: 353.38553, mean: 0.24204
[32m[0906 15-47-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31570, current rewards: 360.47076, mean: 0.23872
[32m[0906 15-47-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31578, current rewards: 367.54795, mean: 0.23561
[32m[0906 15-48-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31578, current rewards: 374.62995, mean: 0.23269
[32m[0906 15-48-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31582, current rewards: 381.71016, mean: 0.22995
[32m[0906 15-48-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31583, current rewards: 388.80226, mean: 0.22737
[32m[0906 15-48-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31584, current rewards: 395.89181, mean: 0.22494
[32m[0906 15-49-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31585, current rewards: 402.97732, mean: 0.22264
[32m[0906 15-49-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31583, current rewards: 385.38874, mean: 0.20720
[32m[0906 15-49-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31579, current rewards: 393.96342, mean: 0.20626
[32m[0906 15-49-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31577, current rewards: 403.53131, mean: 0.20588
[32m[0906 15-50-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31578, current rewards: 413.07843, mean: 0.20551
[32m[0906 15-50-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31585, current rewards: 422.61849, mean: 0.20515
[32m[0906 15-50-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31586, current rewards: 385.36168, mean: 0.18264
[32m[0906 15-51-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31586, current rewards: 392.24345, mean: 0.18159
[32m[0906 15-51-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31586, current rewards: 399.15657, mean: 0.18061
[32m[0906 15-51-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31585, current rewards: 407.37553, mean: 0.18025
[32m[0906 15-51-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31586, current rewards: 418.74549, mean: 0.18128
[32m[0906 15-52-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31587, current rewards: 412.93299, mean: 0.17497
[32m[0906 15-52-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31588, current rewards: 411.49754, mean: 0.17075
[32m[0906 15-52-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31589, current rewards: 417.83745, mean: 0.16985
[32m[0906 15-52-50 @Agent.py:117][0m Average action selection time: 0.3159
[32m[0906 15-52-50 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-52-50 @MBExp.py:227][0m Rewards obtained: [422.93896163568644], Lows: [52], Highs: [65], Total time: 7918.472368
[32m[0906 15-53-09 @MBExp.py:144][0m ####################################################################
[32m[0906 15-53-09 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 15-53-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31770, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-53-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31675, current rewards: -12.85433, mean: -0.21424
[32m[0906 15-53-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31589, current rewards: -7.69930, mean: -0.06999
[32m[0906 15-53-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31441, current rewards: -1.05155, mean: -0.00657
[32m[0906 15-54-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31200, current rewards: 4.45660, mean: 0.02122
[32m[0906 15-54-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31246, current rewards: 9.95154, mean: 0.03828
[32m[0906 15-54-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31224, current rewards: -20.42147, mean: -0.06588
[32m[0906 15-55-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31253, current rewards: -15.00178, mean: -0.04167
[32m[0906 15-55-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31290, current rewards: -6.46386, mean: -0.01577
[32m[0906 15-55-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31313, current rewards: 2.07406, mean: 0.00451
[32m[0906 15-55-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31341, current rewards: 10.61198, mean: 0.02081
[32m[0906 15-56-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31319, current rewards: 16.43018, mean: 0.02934
[32m[0906 15-56-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31355, current rewards: 19.54826, mean: 0.03205
[32m[0906 15-56-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31380, current rewards: 22.66633, mean: 0.03434
[32m[0906 15-56-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31408, current rewards: 25.78440, mean: 0.03632
[32m[0906 15-57-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31435, current rewards: 23.59067, mean: 0.03104
[32m[0906 15-57-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31455, current rewards: -26.40933, mean: -0.03260
[32m[0906 15-57-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31470, current rewards: -76.40933, mean: -0.08885
[32m[0906 15-57-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31483, current rewards: -126.40933, mean: -0.13891
[32m[0906 15-58-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31497, current rewards: -176.40933, mean: -0.18376
[32m[0906 15-58-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31498, current rewards: -226.40933, mean: -0.22417
[32m[0906 15-58-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31501, current rewards: -276.40933, mean: -0.26076
[32m[0906 15-58-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31504, current rewards: -326.40933, mean: -0.29406
[32m[0906 15-59-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31504, current rewards: -376.40933, mean: -0.32449
[32m[0906 15-59-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31506, current rewards: -426.40933, mean: -0.35240
[32m[0906 15-59-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31503, current rewards: -476.40933, mean: -0.37810
[32m[0906 16-00-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31502, current rewards: -526.40933, mean: -0.40184
[32m[0906 16-00-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31503, current rewards: -576.40933, mean: -0.42383
[32m[0906 16-00-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31502, current rewards: -626.40933, mean: -0.44426
[32m[0906 16-00-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31500, current rewards: -676.40933, mean: -0.46329
[32m[0906 16-01-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31499, current rewards: -726.40933, mean: -0.48107
[32m[0906 16-01-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31493, current rewards: -776.40933, mean: -0.49770
[32m[0906 16-01-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31493, current rewards: -826.40933, mean: -0.51330
[32m[0906 16-01-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31491, current rewards: -876.40933, mean: -0.52796
[32m[0906 16-02-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31494, current rewards: -926.40933, mean: -0.54176
[32m[0906 16-02-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31501, current rewards: -976.40933, mean: -0.55478
[32m[0906 16-02-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31500, current rewards: -1026.40933, mean: -0.56708
[32m[0906 16-02-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31499, current rewards: -1076.40933, mean: -0.57871
[32m[0906 16-03-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31501, current rewards: -1126.40933, mean: -0.58974
[32m[0906 16-03-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31498, current rewards: -1176.40933, mean: -0.60021
[32m[0906 16-03-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31497, current rewards: -1226.40933, mean: -0.61015
[32m[0906 16-03-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31496, current rewards: -1276.40933, mean: -0.61962
[32m[0906 16-04-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31493, current rewards: -1326.40933, mean: -0.62863
[32m[0906 16-04-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31491, current rewards: -1376.40933, mean: -0.63723
[32m[0906 16-04-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31492, current rewards: -1426.40933, mean: -0.64543
[32m[0906 16-05-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31490, current rewards: -1476.40933, mean: -0.65328
[32m[0906 16-05-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31489, current rewards: -1526.40933, mean: -0.66078
[32m[0906 16-05-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31492, current rewards: -1576.40933, mean: -0.66797
[32m[0906 16-05-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31492, current rewards: -1626.40933, mean: -0.67486
[32m[0906 16-06-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31490, current rewards: -1674.25503, mean: -0.68059
[32m[0906 16-06-17 @Agent.py:117][0m Average action selection time: 0.3149
[32m[0906 16-06-17 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-06-17 @MBExp.py:227][0m Rewards obtained: [-1671.1690753822406], Lows: [21], Highs: [1723], Total time: 8706.306106
[32m[0906 16-06-38 @MBExp.py:144][0m ####################################################################
[32m[0906 16-06-38 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 16-06-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31757, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-06-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31611, current rewards: -20.39625, mean: -0.33994
[32m[0906 16-07-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31648, current rewards: -10.45518, mean: -0.09505
[32m[0906 16-07-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31393, current rewards: -0.36411, mean: -0.00228
[32m[0906 16-07-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31137, current rewards: 8.17096, mean: 0.03891
[32m[0906 16-07-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31221, current rewards: 16.69210, mean: 0.06420
[32m[0906 16-08-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31177, current rewards: 25.24218, mean: 0.08143
[32m[0906 16-08-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31216, current rewards: -6.50993, mean: -0.01808
[32m[0906 16-08-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31280, current rewards: -22.43673, mean: -0.05472
[32m[0906 16-09-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31323, current rewards: -28.08605, mean: -0.06106
[32m[0906 16-09-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31329, current rewards: -52.21594, mean: -0.10238
[32m[0906 16-09-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31302, current rewards: -65.89177, mean: -0.11766
[32m[0906 16-09-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31343, current rewards: -60.72951, mean: -0.09956
[32m[0906 16-10-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31373, current rewards: -47.14315, mean: -0.07143
[32m[0906 16-10-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31397, current rewards: -33.87438, mean: -0.04771
[32m[0906 16-10-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31411, current rewards: -20.63348, mean: -0.02715
[32m[0906 16-10-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31423, current rewards: -7.37490, mean: -0.00910
[32m[0906 16-11-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31434, current rewards: 5.82896, mean: 0.00678
[32m[0906 16-11-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31445, current rewards: -30.01279, mean: -0.03298
[32m[0906 16-11-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31464, current rewards: -35.82646, mean: -0.03732
[32m[0906 16-11-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31474, current rewards: -29.64877, mean: -0.02936
[32m[0906 16-12-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31481, current rewards: -23.47109, mean: -0.02214
[32m[0906 16-12-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31485, current rewards: -17.29341, mean: -0.01558
[32m[0906 16-12-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31488, current rewards: -11.11573, mean: -0.00958
[32m[0906 16-12-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31492, current rewards: -4.93805, mean: -0.00408
[32m[0906 16-13-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31491, current rewards: 1.23963, mean: 0.00098
[32m[0906 16-13-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31495, current rewards: 7.41731, mean: 0.00566
[32m[0906 16-13-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31496, current rewards: 12.79231, mean: 0.00941
[32m[0906 16-14-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31497, current rewards: -26.23419, mean: -0.01861
[32m[0906 16-14-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31501, current rewards: -76.23419, mean: -0.05222
[32m[0906 16-14-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31500, current rewards: -126.23419, mean: -0.08360
[32m[0906 16-14-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31502, current rewards: -176.23419, mean: -0.11297
[32m[0906 16-15-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31501, current rewards: -226.23419, mean: -0.14052
[32m[0906 16-15-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31501, current rewards: -276.23419, mean: -0.16641
[32m[0906 16-15-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31500, current rewards: -326.23419, mean: -0.19078
[32m[0906 16-15-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31507, current rewards: -376.23419, mean: -0.21377
[32m[0906 16-16-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31511, current rewards: -426.23419, mean: -0.23549
[32m[0906 16-16-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31513, current rewards: -476.23419, mean: -0.25604
[32m[0906 16-16-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31511, current rewards: -524.08886, mean: -0.27439
[32m[0906 16-16-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31511, current rewards: -520.45553, mean: -0.26554
[32m[0906 16-17-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31510, current rewards: -516.82220, mean: -0.25713
[32m[0906 16-17-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31509, current rewards: -513.18887, mean: -0.24912
[32m[0906 16-17-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31510, current rewards: -509.55553, mean: -0.24150
[32m[0906 16-17-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31510, current rewards: -506.19331, mean: -0.23435
[32m[0906 16-18-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31511, current rewards: -503.23314, mean: -0.22771
[32m[0906 16-18-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31515, current rewards: -500.27297, mean: -0.22136
[32m[0906 16-18-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31515, current rewards: -497.31280, mean: -0.21529
[32m[0906 16-19-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31514, current rewards: -494.35264, mean: -0.20947
[32m[0906 16-19-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31514, current rewards: -491.39247, mean: -0.20390
[32m[0906 16-19-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31511, current rewards: -488.43230, mean: -0.19855
[32m[0906 16-19-46 @Agent.py:117][0m Average action selection time: 0.3151
[32m[0906 16-19-46 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-19-46 @MBExp.py:227][0m Rewards obtained: [-486.06416581793025], Lows: [42], Highs: [650], Total time: 9494.694242
[32m[0906 16-20-09 @MBExp.py:144][0m ####################################################################
[32m[0906 16-20-09 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 16-20-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31656, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-20-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31575, current rewards: -13.76680, mean: -0.22945
[32m[0906 16-20-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31536, current rewards: -0.01762, mean: -0.00016
[32m[0906 16-20-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31223, current rewards: 8.87395, mean: 0.05546
[32m[0906 16-21-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30998, current rewards: 17.78100, mean: 0.08467
[32m[0906 16-21-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31093, current rewards: 26.66749, mean: 0.10257
[32m[0906 16-21-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31042, current rewards: 35.53104, mean: 0.11462
[32m[0906 16-22-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31078, current rewards: -17.04866, mean: -0.04736
[32m[0906 16-22-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31147, current rewards: -117.04866, mean: -0.28548
[32m[0906 16-22-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31199, current rewards: -217.04866, mean: -0.47184
[32m[0906 16-22-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31209, current rewards: -317.04866, mean: -0.62166
[32m[0906 16-23-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31184, current rewards: -357.47033, mean: -0.63834
[32m[0906 16-23-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31233, current rewards: -395.78978, mean: -0.64884
[32m[0906 16-23-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31266, current rewards: -434.30003, mean: -0.65803
[32m[0906 16-23-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31304, current rewards: -487.59438, mean: -0.68675
[32m[0906 16-24-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31323, current rewards: -542.99200, mean: -0.71446
[32m[0906 16-24-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31342, current rewards: -590.65514, mean: -0.72920
[32m[0906 16-24-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31355, current rewards: -620.36269, mean: -0.72135
[32m[0906 16-24-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31369, current rewards: -663.86103, mean: -0.72952
[32m[0906 16-25-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31381, current rewards: -710.86736, mean: -0.74049
[32m[0906 16-25-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31389, current rewards: -747.49902, mean: -0.74010
[32m[0906 16-25-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31399, current rewards: -784.01675, mean: -0.73964
[32m[0906 16-25-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31403, current rewards: -833.73816, mean: -0.75112
[32m[0906 16-26-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31406, current rewards: -861.65736, mean: -0.74281
[32m[0906 16-26-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31406, current rewards: -854.05212, mean: -0.70583
[32m[0906 16-26-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31416, current rewards: -846.92490, mean: -0.67216
[32m[0906 16-27-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31426, current rewards: -841.80610, mean: -0.64260
[32m[0906 16-27-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31431, current rewards: -836.74117, mean: -0.61525
[32m[0906 16-27-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31434, current rewards: -831.82155, mean: -0.58994
[32m[0906 16-27-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31437, current rewards: -854.18454, mean: -0.58506
[32m[0906 16-28-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31440, current rewards: -891.65268, mean: -0.59050
[32m[0906 16-28-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31437, current rewards: -861.90619, mean: -0.55250
[32m[0906 16-28-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31442, current rewards: -834.04252, mean: -0.51804
[32m[0906 16-28-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31440, current rewards: -806.16507, mean: -0.48564
[32m[0906 16-29-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31440, current rewards: -816.37063, mean: -0.47741
[32m[0906 16-29-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31440, current rewards: -869.68039, mean: -0.49414
[32m[0906 16-29-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31442, current rewards: -910.71363, mean: -0.50316
[32m[0906 16-29-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31442, current rewards: -947.36675, mean: -0.50934
[32m[0906 16-30-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31440, current rewards: -986.29357, mean: -0.51638
[32m[0906 16-30-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31441, current rewards: -1037.45185, mean: -0.52931
[32m[0906 16-30-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31441, current rewards: -1052.27012, mean: -0.52352
[32m[0906 16-30-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31442, current rewards: -1044.12209, mean: -0.50686
[32m[0906 16-31-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31442, current rewards: -1035.90842, mean: -0.49095
[32m[0906 16-31-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31443, current rewards: -1021.29887, mean: -0.47282
[32m[0906 16-31-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31448, current rewards: -1010.62599, mean: -0.45730
[32m[0906 16-32-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31447, current rewards: -1000.02809, mean: -0.44249
[32m[0906 16-32-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31444, current rewards: -991.64303, mean: -0.42928
[32m[0906 16-32-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31443, current rewards: -1044.65804, mean: -0.44265
[32m[0906 16-32-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31443, current rewards: -1084.03406, mean: -0.44981
[32m[0906 16-33-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31445, current rewards: -1120.72637, mean: -0.45558
[32m[0906 16-33-15 @Agent.py:117][0m Average action selection time: 0.3145
[32m[0906 16-33-15 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-33-15 @MBExp.py:227][0m Rewards obtained: [-1140.4330287290531], Lows: [742], Highs: [62], Total time: 10281.423609
[32m[0906 16-33-40 @MBExp.py:144][0m ####################################################################
[32m[0906 16-33-40 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 16-33-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31852, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-33-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31685, current rewards: -12.71580, mean: -0.21193
[32m[0906 16-34-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31616, current rewards: -9.08901, mean: -0.08263
[32m[0906 16-34-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31281, current rewards: -5.26390, mean: -0.03290
[32m[0906 16-34-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31066, current rewards: -1.43786, mean: -0.00685
[32m[0906 16-35-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31153, current rewards: 2.38800, mean: 0.00918
[32m[0906 16-35-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31115, current rewards: -15.23246, mean: -0.04914
[32m[0906 16-35-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31166, current rewards: -11.87684, mean: -0.03299
[32m[0906 16-35-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31231, current rewards: -8.44324, mean: -0.02059
[32m[0906 16-36-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31284, current rewards: -5.04293, mean: -0.01096
[32m[0906 16-36-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31279, current rewards: -33.48909, mean: -0.06566
[32m[0906 16-36-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31248, current rewards: -28.47629, mean: -0.05085
[32m[0906 16-36-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31285, current rewards: -24.40052, mean: -0.04000
[32m[0906 16-37-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31327, current rewards: -20.29895, mean: -0.03076
[32m[0906 16-37-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31355, current rewards: -16.20122, mean: -0.02282
[32m[0906 16-37-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31389, current rewards: -12.10560, mean: -0.01593
[32m[0906 16-37-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31403, current rewards: -8.00489, mean: -0.00988
[32m[0906 16-38-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31414, current rewards: -58.53108, mean: -0.06806
[32m[0906 16-38-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31424, current rewards: -85.69739, mean: -0.09417
[32m[0906 16-38-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31431, current rewards: -104.98346, mean: -0.10936
[32m[0906 16-38-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31445, current rewards: -123.14389, mean: -0.12192
[32m[0906 16-39-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31455, current rewards: -143.49070, mean: -0.13537
[32m[0906 16-39-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31465, current rewards: -170.43923, mean: -0.15355
[32m[0906 16-39-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31476, current rewards: -221.29611, mean: -0.19077
[32m[0906 16-40-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31486, current rewards: -218.69722, mean: -0.18074
[32m[0906 16-40-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31491, current rewards: -216.28400, mean: -0.17165
[32m[0906 16-40-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31495, current rewards: -212.18522, mean: -0.16197
[32m[0906 16-40-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31496, current rewards: -207.13534, mean: -0.15231
[32m[0906 16-41-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31508, current rewards: -202.08546, mean: -0.14332
[32m[0906 16-41-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31512, current rewards: -197.03559, mean: -0.13496
[32m[0906 16-41-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31516, current rewards: -191.98571, mean: -0.12714
[32m[0906 16-41-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31518, current rewards: -186.93584, mean: -0.11983
[32m[0906 16-42-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31517, current rewards: -202.80491, mean: -0.12597
[32m[0906 16-42-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31518, current rewards: -252.80491, mean: -0.15229
[32m[0906 16-42-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31515, current rewards: -302.80491, mean: -0.17708
[32m[0906 16-42-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31513, current rewards: -352.80491, mean: -0.20046
[32m[0906 16-43-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31511, current rewards: -402.80491, mean: -0.22254
[32m[0906 16-43-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31510, current rewards: -452.80491, mean: -0.24344
[32m[0906 16-43-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31511, current rewards: -502.80491, mean: -0.26325
[32m[0906 16-43-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31509, current rewards: -552.80491, mean: -0.28204
[32m[0906 16-44-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31507, current rewards: -602.80491, mean: -0.29990
[32m[0906 16-44-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31505, current rewards: -652.80491, mean: -0.31690
[32m[0906 16-44-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31504, current rewards: -702.80491, mean: -0.33308
[32m[0906 16-45-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31503, current rewards: -727.09062, mean: -0.33662
[32m[0906 16-45-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31500, current rewards: -721.04535, mean: -0.32626
[32m[0906 16-45-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31501, current rewards: -715.00009, mean: -0.31637
[32m[0906 16-45-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31501, current rewards: -708.95482, mean: -0.30691
[32m[0906 16-46-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31500, current rewards: -702.90956, mean: -0.29784
[32m[0906 16-46-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31499, current rewards: -705.83153, mean: -0.29288
[32m[0906 16-46-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31498, current rewards: -755.83153, mean: -0.30725
[32m[0906 16-46-48 @Agent.py:117][0m Average action selection time: 0.3150
[32m[0906 16-46-48 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-46-48 @MBExp.py:227][0m Rewards obtained: [-795.8315323800108], Lows: [40], Highs: [863], Total time: 11069.428807
[32m[0906 16-47-15 @MBExp.py:144][0m ####################################################################
[32m[0906 16-47-15 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 16-47-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31618, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-47-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31624, current rewards: -16.49160, mean: -0.27486
[32m[0906 16-47-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31563, current rewards: -6.59599, mean: -0.05996
[32m[0906 16-48-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31168, current rewards: 4.84299, mean: 0.03027
[32m[0906 16-48-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30990, current rewards: 16.29781, mean: 0.07761
[32m[0906 16-48-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31069, current rewards: 27.75367, mean: 0.10674
[32m[0906 16-48-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31046, current rewards: 39.19088, mean: 0.12642
[32m[0906 16-49-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31117, current rewards: 50.62147, mean: 0.14062
[32m[0906 16-49-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31196, current rewards: 62.06273, mean: 0.15137
[32m[0906 16-49-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31253, current rewards: 73.51125, mean: 0.15981
[32m[0906 16-49-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31255, current rewards: 82.01817, mean: 0.16082
[32m[0906 16-50-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31232, current rewards: 91.95997, mean: 0.16421
[32m[0906 16-50-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31267, current rewards: 101.93056, mean: 0.16710
[32m[0906 16-50-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31294, current rewards: 103.08182, mean: 0.15618
[32m[0906 16-50-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31326, current rewards: 75.44880, mean: 0.10627
[32m[0906 16-51-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31350, current rewards: 81.02762, mean: 0.10662
[32m[0906 16-51-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31368, current rewards: 86.56561, mean: 0.10687
[32m[0906 16-51-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31384, current rewards: 92.10109, mean: 0.10709
[32m[0906 16-52-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31401, current rewards: 71.72576, mean: 0.07882
[32m[0906 16-52-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31413, current rewards: 65.00802, mean: 0.06772
[32m[0906 16-52-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31427, current rewards: 69.84522, mean: 0.06915
[32m[0906 16-52-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31440, current rewards: 74.40458, mean: 0.07019
[32m[0906 16-53-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31448, current rewards: 78.97368, mean: 0.07115
[32m[0906 16-53-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31454, current rewards: 83.54448, mean: 0.07202
[32m[0906 16-53-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31458, current rewards: 88.11503, mean: 0.07282
[32m[0906 16-53-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31458, current rewards: 92.68533, mean: 0.07356
[32m[0906 16-54-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31464, current rewards: 97.01898, mean: 0.07406
[32m[0906 16-54-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31465, current rewards: 57.71289, mean: 0.04244
[32m[0906 16-54-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31467, current rewards: 26.44268, mean: 0.01875
[32m[0906 16-54-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31467, current rewards: -0.22294, mean: -0.00015
[32m[0906 16-55-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31467, current rewards: -48.70025, mean: -0.03225
[32m[0906 16-55-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31462, current rewards: -97.15442, mean: -0.06228
[32m[0906 16-55-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31463, current rewards: -138.93771, mean: -0.08630
[32m[0906 16-55-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31463, current rewards: -168.95606, mean: -0.10178
[32m[0906 16-56-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31464, current rewards: -196.71175, mean: -0.11504
[32m[0906 16-56-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31464, current rewards: -239.60813, mean: -0.13614
[32m[0906 16-56-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31466, current rewards: -288.13014, mean: -0.15919
[32m[0906 16-57-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31463, current rewards: -334.47849, mean: -0.17983
[32m[0906 16-57-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31463, current rewards: -348.43747, mean: -0.18243
[32m[0906 16-57-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31462, current rewards: -343.23080, mean: -0.17512
[32m[0906 16-57-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31463, current rewards: -338.22121, mean: -0.16827
[32m[0906 16-58-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31463, current rewards: -333.21209, mean: -0.16175
[32m[0906 16-58-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31461, current rewards: -328.20291, mean: -0.15555
[32m[0906 16-58-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31461, current rewards: -322.06978, mean: -0.14911
[32m[0906 16-58-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31460, current rewards: -316.77664, mean: -0.14334
[32m[0906 16-59-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31461, current rewards: -311.46817, mean: -0.13782
[32m[0906 16-59-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31461, current rewards: -306.16093, mean: -0.13254
[32m[0906 16-59-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31460, current rewards: -300.85374, mean: -0.12748
[32m[0906 16-59-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31457, current rewards: -295.54552, mean: -0.12263
[32m[0906 17-00-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31457, current rewards: -331.04834, mean: -0.13457
[32m[0906 17-00-21 @Agent.py:117][0m Average action selection time: 0.3146
[32m[0906 17-00-21 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-00-22 @MBExp.py:227][0m Rewards obtained: [-322.71584446005016], Lows: [339], Highs: [40], Total time: 11856.428677
[32m[0906 17-00-50 @MBExp.py:144][0m ####################################################################
[32m[0906 17-00-50 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 17-00-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31687, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-01-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31597, current rewards: -31.34615, mean: -0.52244
[32m[0906 17-01-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31424, current rewards: -27.57840, mean: -0.25071
[32m[0906 17-01-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30962, current rewards: -23.60612, mean: -0.14754
[32m[0906 17-01-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30848, current rewards: -19.61523, mean: -0.09341
[32m[0906 17-02-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30909, current rewards: -15.62222, mean: -0.06009
[32m[0906 17-02-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30900, current rewards: -24.10206, mean: -0.07775
[32m[0906 17-02-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30984, current rewards: -47.16811, mean: -0.13102
[32m[0906 17-02-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31069, current rewards: -39.67109, mean: -0.09676
[32m[0906 17-03-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31129, current rewards: -49.79055, mean: -0.10824
[32m[0906 17-03-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31138, current rewards: -42.17422, mean: -0.08269
[32m[0906 17-03-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31115, current rewards: -34.27480, mean: -0.06121
[32m[0906 17-04-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31143, current rewards: -26.39488, mean: -0.04327
[32m[0906 17-04-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31173, current rewards: -18.51702, mean: -0.02806
[32m[0906 17-04-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31206, current rewards: -10.63643, mean: -0.01498
[32m[0906 17-04-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31232, current rewards: -2.75124, mean: -0.00362
[32m[0906 17-05-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31255, current rewards: -18.90865, mean: -0.02334
[32m[0906 17-05-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31278, current rewards: -13.31915, mean: -0.01549
[32m[0906 17-05-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31295, current rewards: -7.46824, mean: -0.00821
[32m[0906 17-05-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31309, current rewards: -2.33174, mean: -0.00243
[32m[0906 17-06-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31316, current rewards: 2.80247, mean: 0.00277
[32m[0906 17-06-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31328, current rewards: 7.93505, mean: 0.00749
[32m[0906 17-06-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31340, current rewards: 13.06689, mean: 0.01177
[32m[0906 17-06-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31344, current rewards: 18.20045, mean: 0.01569
[32m[0906 17-07-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31356, current rewards: -22.92610, mean: -0.01895
[32m[0906 17-07-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31365, current rewards: -55.61655, mean: -0.04414
[32m[0906 17-07-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31374, current rewards: -48.75372, mean: -0.03722
[32m[0906 17-07-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31379, current rewards: -41.91663, mean: -0.03082
[32m[0906 17-08-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31385, current rewards: -35.08014, mean: -0.02488
[32m[0906 17-08-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31389, current rewards: -28.24989, mean: -0.01935
[32m[0906 17-08-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31390, current rewards: -21.41446, mean: -0.01418
[32m[0906 17-09-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31392, current rewards: -55.63317, mean: -0.03566
[32m[0906 17-09-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31397, current rewards: -46.29972, mean: -0.02876
[32m[0906 17-09-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31399, current rewards: -37.01167, mean: -0.02230
[32m[0906 17-09-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31399, current rewards: -33.67815, mean: -0.01969
[32m[0906 17-10-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31398, current rewards: -28.61559, mean: -0.01626
[32m[0906 17-10-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31396, current rewards: -22.98764, mean: -0.01270
[32m[0906 17-10-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31398, current rewards: -17.34758, mean: -0.00933
[32m[0906 17-10-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31396, current rewards: -11.70713, mean: -0.00613
[32m[0906 17-11-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31397, current rewards: -6.06880, mean: -0.00310
[32m[0906 17-11-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31396, current rewards: -0.42443, mean: -0.00021
[32m[0906 17-11-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31398, current rewards: 5.21526, mean: 0.00253
[32m[0906 17-11-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31399, current rewards: 14.11229, mean: 0.00669
[32m[0906 17-12-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31403, current rewards: -2.63802, mean: -0.00122
[32m[0906 17-12-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31403, current rewards: 1.79364, mean: 0.00081
[32m[0906 17-12-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31400, current rewards: 7.53005, mean: 0.00333
[32m[0906 17-12-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31399, current rewards: 13.27117, mean: 0.00575
[32m[0906 17-13-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31399, current rewards: 19.01581, mean: 0.00806
[32m[0906 17-13-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31401, current rewards: 24.76171, mean: 0.01027
[32m[0906 17-13-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31402, current rewards: 30.50656, mean: 0.01240
[32m[0906 17-13-55 @Agent.py:117][0m Average action selection time: 0.3140
[32m[0906 17-13-55 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-13-55 @MBExp.py:227][0m Rewards obtained: [34.962703770849416], Lows: [91], Highs: [74], Total time: 12642.078941
[32m[0906 17-14-26 @MBExp.py:144][0m ####################################################################
[32m[0906 17-14-26 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 17-14-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31683, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-14-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31546, current rewards: -15.68172, mean: -0.26136
[32m[0906 17-15-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31250, current rewards: -11.02392, mean: -0.10022
[32m[0906 17-15-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30846, current rewards: -6.39763, mean: -0.03999
[32m[0906 17-15-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30773, current rewards: -24.04127, mean: -0.11448
[32m[0906 17-15-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30845, current rewards: -20.45133, mean: -0.07866
[32m[0906 17-16-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30844, current rewards: -16.93096, mean: -0.05462
[32m[0906 17-16-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30938, current rewards: -13.39623, mean: -0.03721
[32m[0906 17-16-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31026, current rewards: -9.86180, mean: -0.02405
[32m[0906 17-16-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31089, current rewards: -6.36785, mean: -0.01384
[32m[0906 17-17-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31089, current rewards: -2.83582, mean: -0.00556
[32m[0906 17-17-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31070, current rewards: 0.71137, mean: 0.00127
[32m[0906 17-17-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31103, current rewards: 4.25505, mean: 0.00698
[32m[0906 17-17-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31152, current rewards: -35.61511, mean: -0.05396
[32m[0906 17-18-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31182, current rewards: -29.19105, mean: -0.04111
[32m[0906 17-18-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31217, current rewards: -23.14579, mean: -0.03045
[32m[0906 17-18-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31243, current rewards: -17.10052, mean: -0.02111
[32m[0906 17-18-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31265, current rewards: -12.69508, mean: -0.01476
[32m[0906 17-19-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31279, current rewards: -10.16751, mean: -0.01117
[32m[0906 17-19-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31297, current rewards: -7.63995, mean: -0.00796
[32m[0906 17-19-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31308, current rewards: -5.11238, mean: -0.00506
[32m[0906 17-19-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31323, current rewards: -2.58481, mean: -0.00244
[32m[0906 17-20-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31336, current rewards: -0.05725, mean: -0.00005
[32m[0906 17-20-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31346, current rewards: 2.47032, mean: 0.00213
[32m[0906 17-20-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31357, current rewards: -38.07472, mean: -0.03147
[32m[0906 17-21-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31365, current rewards: -88.07472, mean: -0.06990
[32m[0906 17-21-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31368, current rewards: -138.07472, mean: -0.10540
[32m[0906 17-21-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31373, current rewards: -188.07472, mean: -0.13829
[32m[0906 17-21-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31378, current rewards: -238.07472, mean: -0.16885
[32m[0906 17-22-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31381, current rewards: -288.07472, mean: -0.19731
[32m[0906 17-22-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31383, current rewards: -338.07472, mean: -0.22389
[32m[0906 17-22-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31386, current rewards: -388.07472, mean: -0.24877
[32m[0906 17-22-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31390, current rewards: -438.07472, mean: -0.27210
[32m[0906 17-23-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31392, current rewards: -488.07472, mean: -0.29402
[32m[0906 17-23-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31394, current rewards: -538.07472, mean: -0.31466
[32m[0906 17-23-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31396, current rewards: -588.07472, mean: -0.33413
[32m[0906 17-23-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31396, current rewards: -638.07472, mean: -0.35253
[32m[0906 17-24-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31398, current rewards: -688.07472, mean: -0.36993
[32m[0906 17-24-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31399, current rewards: -738.07472, mean: -0.38643
[32m[0906 17-24-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31402, current rewards: -788.07472, mean: -0.40208
[32m[0906 17-24-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31402, current rewards: -838.07472, mean: -0.41695
[32m[0906 17-25-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31403, current rewards: -888.07472, mean: -0.43110
[32m[0906 17-25-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31406, current rewards: -938.07472, mean: -0.44459
[32m[0906 17-25-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31407, current rewards: -988.07472, mean: -0.45744
[32m[0906 17-26-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31408, current rewards: -1038.07472, mean: -0.46972
[32m[0906 17-26-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31409, current rewards: -1088.07472, mean: -0.48145
[32m[0906 17-26-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31410, current rewards: -1138.07472, mean: -0.49267
[32m[0906 17-26-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31411, current rewards: -1188.07472, mean: -0.50342
[32m[0906 17-27-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31412, current rewards: -1238.07472, mean: -0.51372
[32m[0906 17-27-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31413, current rewards: -1288.07472, mean: -0.52361
[32m[0906 17-27-31 @Agent.py:117][0m Average action selection time: 0.3141
[32m[0906 17-27-31 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-27-31 @MBExp.py:227][0m Rewards obtained: [-1328.074720549359], Lows: [24], Highs: [1371], Total time: 13427.979725
[32m[0906 17-28-04 @MBExp.py:144][0m ####################################################################
[32m[0906 17-28-04 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 17-28-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31599, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-28-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31500, current rewards: -15.42682, mean: -0.25711
[32m[0906 17-28-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31151, current rewards: -9.94770, mean: -0.09043
[32m[0906 17-28-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30751, current rewards: -4.71947, mean: -0.02950
[32m[0906 17-29-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30708, current rewards: 0.50157, mean: 0.00239
[32m[0906 17-29-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30757, current rewards: 5.72028, mean: 0.02200
[32m[0906 17-29-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30781, current rewards: 10.94267, mean: 0.03530
[32m[0906 17-29-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30869, current rewards: 16.16827, mean: 0.04491
[32m[0906 17-30-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30943, current rewards: 21.39602, mean: 0.05219
[32m[0906 17-30-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31010, current rewards: 23.16467, mean: 0.05036
[32m[0906 17-30-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31022, current rewards: 24.37141, mean: 0.04779
[32m[0906 17-30-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31015, current rewards: 7.29285, mean: 0.01302
[32m[0906 17-31-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31049, current rewards: 0.49933, mean: 0.00082
[32m[0906 17-31-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31099, current rewards: -10.59152, mean: -0.01605
[32m[0906 17-31-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31138, current rewards: -10.53002, mean: -0.01483
[32m[0906 17-32-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31169, current rewards: -16.20602, mean: -0.02132
[32m[0906 17-32-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31194, current rewards: -23.00902, mean: -0.02841
[32m[0906 17-32-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31219, current rewards: -41.95019, mean: -0.04878
[32m[0906 17-32-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31235, current rewards: -90.62874, mean: -0.09959
[32m[0906 17-33-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31251, current rewards: -131.84875, mean: -0.13734
[32m[0906 17-33-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31265, current rewards: -189.79341, mean: -0.18791
[32m[0906 17-33-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31277, current rewards: -252.00793, mean: -0.23774
[32m[0906 17-33-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31288, current rewards: -314.24515, mean: -0.28310
[32m[0906 17-34-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31301, current rewards: -376.51313, mean: -0.32458
[32m[0906 17-34-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31307, current rewards: -438.83283, mean: -0.36267
[32m[0906 17-34-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31314, current rewards: -501.25162, mean: -0.39782
[32m[0906 17-34-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31322, current rewards: -557.08387, mean: -0.42525
[32m[0906 17-35-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31333, current rewards: -617.44317, mean: -0.45400
[32m[0906 17-35-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31341, current rewards: -677.78681, mean: -0.48070
[32m[0906 17-35-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31348, current rewards: -686.99004, mean: -0.47054
[32m[0906 17-35-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31355, current rewards: -683.13948, mean: -0.45241
[32m[0906 17-36-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31359, current rewards: -679.43777, mean: -0.43554
[32m[0906 17-36-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31364, current rewards: -675.22631, mean: -0.41940
[32m[0906 17-36-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31367, current rewards: -659.57238, mean: -0.39733
[32m[0906 17-37-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31373, current rewards: -652.92277, mean: -0.38183
[32m[0906 17-37-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31376, current rewards: -647.54384, mean: -0.36792
[32m[0906 17-37-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31378, current rewards: -642.31139, mean: -0.35487
[32m[0906 17-37-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31379, current rewards: -656.60434, mean: -0.35301
[32m[0906 17-38-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31381, current rewards: -699.20028, mean: -0.36607
[32m[0906 17-38-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31384, current rewards: -701.93776, mean: -0.35813
[32m[0906 17-38-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31385, current rewards: -725.31171, mean: -0.36085
[32m[0906 17-38-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31390, current rewards: -763.47009, mean: -0.37062
[32m[0906 17-39-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31393, current rewards: -814.72938, mean: -0.38613
[32m[0906 17-39-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31395, current rewards: -822.93125, mean: -0.38099
[32m[0906 17-39-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31397, current rewards: -838.35818, mean: -0.37935
[32m[0906 17-39-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31399, current rewards: -880.17275, mean: -0.38946
[32m[0906 17-40-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31400, current rewards: -909.99908, mean: -0.39394
[32m[0906 17-40-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31402, current rewards: -942.83984, mean: -0.39951
[32m[0906 17-40-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31402, current rewards: -1002.95413, mean: -0.41616
[32m[0906 17-40-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31404, current rewards: -1063.00554, mean: -0.43212
[32m[0906 17-41-09 @Agent.py:117][0m Average action selection time: 0.3140
[32m[0906 17-41-09 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-41-09 @MBExp.py:227][0m Rewards obtained: [-1122.005541627459], Lows: [430], Highs: [473], Total time: 14213.685839
[32m[0906 17-41-43 @MBExp.py:144][0m ####################################################################
[32m[0906 17-41-43 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 17-41-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31874, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-42-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31635, current rewards: -33.84252, mean: -0.56404
[32m[0906 17-42-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31103, current rewards: -29.00343, mean: -0.26367
[32m[0906 17-42-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30699, current rewards: -24.38903, mean: -0.15243
[32m[0906 17-42-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30687, current rewards: -19.77614, mean: -0.09417
[32m[0906 17-43-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30723, current rewards: -15.16896, mean: -0.05834
[32m[0906 17-43-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30733, current rewards: -10.55856, mean: -0.03406
[32m[0906 17-43-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30834, current rewards: -5.94305, mean: -0.01651
[32m[0906 17-43-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30915, current rewards: -1.32323, mean: -0.00323
[32m[0906 17-44-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30981, current rewards: 3.28491, mean: 0.00714
[32m[0906 17-44-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30989, current rewards: -35.19942, mean: -0.06902
[32m[0906 17-44-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30983, current rewards: -127.17876, mean: -0.22710
[32m[0906 17-44-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31000, current rewards: -227.17876, mean: -0.37242
[32m[0906 17-45-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31042, current rewards: -327.17876, mean: -0.49573
[32m[0906 17-45-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31080, current rewards: -427.17876, mean: -0.60166
[32m[0906 17-45-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31117, current rewards: -527.17876, mean: -0.69366
[32m[0906 17-45-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31148, current rewards: -619.31729, mean: -0.76459
[32m[0906 17-46-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31174, current rewards: -610.23000, mean: -0.70957
[32m[0906 17-46-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31198, current rewards: -600.49606, mean: -0.65989
[32m[0906 17-46-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31222, current rewards: -593.79007, mean: -0.61853
[32m[0906 17-46-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31244, current rewards: -587.47046, mean: -0.58165
[32m[0906 17-47-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31257, current rewards: -580.98352, mean: -0.54810
[32m[0906 17-47-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31276, current rewards: -574.49509, mean: -0.51756
[32m[0906 17-47-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31289, current rewards: -568.00628, mean: -0.48966
[32m[0906 17-48-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31298, current rewards: -561.51261, mean: -0.46406
[32m[0906 17-48-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31309, current rewards: -557.00537, mean: -0.44207
[32m[0906 17-48-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31315, current rewards: -550.87451, mean: -0.42051
[32m[0906 17-48-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31322, current rewards: -544.70924, mean: -0.40052
[32m[0906 17-49-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31330, current rewards: -538.54561, mean: -0.38195
[32m[0906 17-49-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31338, current rewards: -532.39951, mean: -0.36466
[32m[0906 17-49-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31344, current rewards: -526.22728, mean: -0.34849
[32m[0906 17-49-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31349, current rewards: -520.06420, mean: -0.33337
[32m[0906 17-50-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31350, current rewards: -513.90470, mean: -0.31920
[32m[0906 17-50-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31351, current rewards: -524.03105, mean: -0.31568
[32m[0906 17-50-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31355, current rewards: -556.61136, mean: -0.32550
[32m[0906 17-50-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31359, current rewards: -638.56701, mean: -0.36282
[32m[0906 17-51-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31360, current rewards: -729.09671, mean: -0.40282
[32m[0906 17-51-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31361, current rewards: -819.60796, mean: -0.44065
[32m[0906 17-51-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31360, current rewards: -905.39094, mean: -0.47403
[32m[0906 17-51-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31364, current rewards: -995.92212, mean: -0.50812
[32m[0906 17-52-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31364, current rewards: -1066.45050, mean: -0.53057
[32m[0906 17-52-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31366, current rewards: -1057.75234, mean: -0.51347
[32m[0906 17-52-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31367, current rewards: -1052.84350, mean: -0.49898
[32m[0906 17-53-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31370, current rewards: -1043.94408, mean: -0.48331
[32m[0906 17-53-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31371, current rewards: -1035.53669, mean: -0.46857
[32m[0906 17-53-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31372, current rewards: -1027.12775, mean: -0.45448
[32m[0906 17-53-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31373, current rewards: -1018.72378, mean: -0.44101
[32m[0906 17-54-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31374, current rewards: -1047.52650, mean: -0.44387
[32m[0906 17-54-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31376, current rewards: -1040.85009, mean: -0.43189
[32m[0906 17-54-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31378, current rewards: -1033.93079, mean: -0.42030
[32m[0906 17-54-48 @Agent.py:117][0m Average action selection time: 0.3138
[32m[0906 17-54-48 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-54-48 @MBExp.py:227][0m Rewards obtained: [-1028.5008946426258], Lows: [624], Highs: [41], Total time: 14998.790981
[32m[0906 17-55-24 @MBExp.py:144][0m ####################################################################
[32m[0906 17-55-24 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 17-55-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31780, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-55-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31642, current rewards: -17.14770, mean: -0.28579
[32m[0906 17-55-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31050, current rewards: -11.26399, mean: -0.10240
[32m[0906 17-56-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30676, current rewards: -5.37379, mean: -0.03359
[32m[0906 17-56-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30645, current rewards: 0.51954, mean: 0.00247
[32m[0906 17-56-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30668, current rewards: 6.40382, mean: 0.02463
[32m[0906 17-56-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30697, current rewards: 12.29659, mean: 0.03967
[32m[0906 17-57-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30800, current rewards: 18.18046, mean: 0.05050
[32m[0906 17-57-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30892, current rewards: 23.84949, mean: 0.05817
[32m[0906 17-57-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30967, current rewards: 29.08450, mean: 0.06323
[32m[0906 17-58-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30971, current rewards: 34.61002, mean: 0.06786
[32m[0906 17-58-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30954, current rewards: 41.71906, mean: 0.07450
[32m[0906 17-58-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30964, current rewards: 50.44572, mean: 0.08270
[32m[0906 17-58-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31006, current rewards: 59.20446, mean: 0.08970
[32m[0906 17-59-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31028, current rewards: 67.94667, mean: 0.09570
[32m[0906 17-59-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31060, current rewards: 76.69999, mean: 0.10092
[32m[0906 17-59-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31082, current rewards: 68.04186, mean: 0.08400
[32m[0906 17-59-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31105, current rewards: 47.17346, mean: 0.05485
[32m[0906 18-00-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31122, current rewards: 50.86071, mean: 0.05589
[32m[0906 18-00-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31139, current rewards: 54.54796, mean: 0.05682
[32m[0906 18-00-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31153, current rewards: 58.23520, mean: 0.05766
[32m[0906 18-00-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31162, current rewards: 28.63635, mean: 0.02702
[32m[0906 18-01-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31176, current rewards: -21.36365, mean: -0.01925
[32m[0906 18-01-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31187, current rewards: -71.36365, mean: -0.06152
[32m[0906 18-01-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31200, current rewards: -121.36365, mean: -0.10030
[32m[0906 18-01-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31211, current rewards: -171.36365, mean: -0.13600
[32m[0906 18-02-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31223, current rewards: -221.36365, mean: -0.16898
[32m[0906 18-02-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31230, current rewards: -271.36365, mean: -0.19953
[32m[0906 18-02-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31239, current rewards: -321.36365, mean: -0.22792
[32m[0906 18-03-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31246, current rewards: -371.36365, mean: -0.25436
[32m[0906 18-03-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31253, current rewards: -370.76188, mean: -0.24554
[32m[0906 18-03-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31258, current rewards: -406.39179, mean: -0.26051
[32m[0906 18-03-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31263, current rewards: -398.18017, mean: -0.24732
[32m[0906 18-04-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31266, current rewards: -376.25485, mean: -0.22666
[32m[0906 18-04-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31268, current rewards: -352.58679, mean: -0.20619
[32m[0906 18-04-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31272, current rewards: -328.77407, mean: -0.18680
[32m[0906 18-04-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31274, current rewards: -305.10409, mean: -0.16857
[32m[0906 18-05-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31277, current rewards: -281.46558, mean: -0.15133
[32m[0906 18-05-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31278, current rewards: -257.79279, mean: -0.13497
[32m[0906 18-05-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31282, current rewards: -268.98998, mean: -0.13724
[32m[0906 18-05-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31286, current rewards: -263.59942, mean: -0.13114
[32m[0906 18-06-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31290, current rewards: -258.38666, mean: -0.12543
[32m[0906 18-06-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31294, current rewards: -253.03599, mean: -0.11992
[32m[0906 18-06-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31296, current rewards: -247.68911, mean: -0.11467
[32m[0906 18-06-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31299, current rewards: -242.34136, mean: -0.10966
[32m[0906 18-07-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31297, current rewards: -236.99096, mean: -0.10486
[32m[0906 18-07-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31298, current rewards: -231.64956, mean: -0.10028
[32m[0906 18-07-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31301, current rewards: -268.36106, mean: -0.11371
[32m[0906 18-07-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31303, current rewards: -261.59280, mean: -0.10854
[32m[0906 18-08-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31303, current rewards: -256.78935, mean: -0.10439
[32m[0906 18-08-27 @Agent.py:117][0m Average action selection time: 0.3130
[32m[0906 18-08-27 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-08-27 @MBExp.py:227][0m Rewards obtained: [-252.71952394827625], Lows: [60], Highs: [477], Total time: 15782.020088
[32m[0906 18-09-05 @MBExp.py:144][0m ####################################################################
[32m[0906 18-09-05 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 18-09-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31701, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-09-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31722, current rewards: -52.30088, mean: -0.87168
[32m[0906 18-09-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30992, current rewards: -41.43982, mean: -0.37673
[32m[0906 18-09-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30659, current rewards: -27.61995, mean: -0.17262
[32m[0906 18-10-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30622, current rewards: -11.55093, mean: -0.05500
[32m[0906 18-10-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30674, current rewards: -16.54730, mean: -0.06364
[32m[0906 18-10-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30703, current rewards: -54.30899, mean: -0.17519
[32m[0906 18-10-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30811, current rewards: -102.21354, mean: -0.28393
[32m[0906 18-11-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30904, current rewards: -138.78236, mean: -0.33849
[32m[0906 18-11-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30985, current rewards: -142.82857, mean: -0.31050
[32m[0906 18-11-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30989, current rewards: -139.79017, mean: -0.27410
[32m[0906 18-11-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30975, current rewards: -135.63164, mean: -0.24220
[32m[0906 18-12-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30981, current rewards: -131.45556, mean: -0.21550
[32m[0906 18-12-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31035, current rewards: -132.01280, mean: -0.20002
[32m[0906 18-12-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31341, current rewards: -132.09768, mean: -0.18605
[32m[0906 18-13-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31610, current rewards: -128.32952, mean: -0.16885
[32m[0906 18-13-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31846, current rewards: -124.57569, mean: -0.15380
[32m[0906 18-13-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32069, current rewards: -120.86198, mean: -0.14054
[32m[0906 18-13-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32277, current rewards: -117.14936, mean: -0.12874
[32m[0906 18-14-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32465, current rewards: -113.43473, mean: -0.11816
[32m[0906 18-14-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32631, current rewards: -109.72298, mean: -0.10864
[32m[0906 18-14-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32781, current rewards: -106.00904, mean: -0.10001
[32m[0906 18-15-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32916, current rewards: -110.59317, mean: -0.09963
[32m[0906 18-15-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33042, current rewards: -139.37693, mean: -0.12015
[32m[0906 18-15-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33158, current rewards: -132.98888, mean: -0.10991
[32m[0906 18-16-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33261, current rewards: -123.78350, mean: -0.09824
[32m[0906 18-16-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33361, current rewards: -143.05857, mean: -0.10921
[32m[0906 18-16-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33473, current rewards: -136.49426, mean: -0.10036
[32m[0906 18-16-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33581, current rewards: -127.00596, mean: -0.09008
[32m[0906 18-17-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33678, current rewards: -217.64989, mean: -0.14908
[32m[0906 18-17-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33753, current rewards: -317.64989, mean: -0.21036
[32m[0906 18-17-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33808, current rewards: -417.64989, mean: -0.26772
[32m[0906 18-18-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33858, current rewards: -490.40848, mean: -0.30460
[32m[0906 18-18-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33903, current rewards: -573.72188, mean: -0.34562
[32m[0906 18-18-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33947, current rewards: -667.44756, mean: -0.39032
[32m[0906 18-19-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33990, current rewards: -706.95949, mean: -0.40168
[32m[0906 18-19-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34032, current rewards: -701.95986, mean: -0.38782
[32m[0906 18-19-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34070, current rewards: -698.57884, mean: -0.37558
[32m[0906 18-19-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34105, current rewards: -695.19664, mean: -0.36398
[32m[0906 18-20-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34140, current rewards: -691.81509, mean: -0.35297
[32m[0906 18-20-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34172, current rewards: -688.62108, mean: -0.34260
[32m[0906 18-20-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34203, current rewards: -685.31927, mean: -0.33268
[32m[0906 18-21-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34232, current rewards: -682.01623, mean: -0.32323
[32m[0906 18-21-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34264, current rewards: -678.71447, mean: -0.31422
[32m[0906 18-21-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34299, current rewards: -675.41145, mean: -0.30562
[32m[0906 18-22-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34332, current rewards: -672.11104, mean: -0.29739
[32m[0906 18-22-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34365, current rewards: -668.80691, mean: -0.28953
[32m[0906 18-22-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34392, current rewards: -665.50526, mean: -0.28199
[32m[0906 18-22-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34420, current rewards: -661.94115, mean: -0.27466
[32m[0906 18-23-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34448, current rewards: -658.54996, mean: -0.26770
[32m[0906 18-23-27 @Agent.py:117][0m Average action selection time: 0.3447
[32m[0906 18-23-27 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-23-28 @MBExp.py:227][0m Rewards obtained: [-697.1751755027988], Lows: [440], Highs: [66], Total time: 16644.426606
[32m[0906 18-24-13 @MBExp.py:144][0m ####################################################################
[32m[0906 18-24-13 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 18-24-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35800, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-24-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35694, current rewards: -12.75011, mean: -0.21250
[32m[0906 18-24-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34859, current rewards: -8.28665, mean: -0.07533
[32m[0906 18-25-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34546, current rewards: -3.82505, mean: -0.02391
[32m[0906 18-25-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34495, current rewards: 0.63767, mean: 0.00304
[32m[0906 18-25-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34595, current rewards: 5.09733, mean: 0.01961
[32m[0906 18-26-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34756, current rewards: 9.48463, mean: 0.03060
[32m[0906 18-26-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34941, current rewards: 13.43840, mean: 0.03733
[32m[0906 18-26-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34993, current rewards: 18.06726, mean: 0.04407
[32m[0906 18-26-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35042, current rewards: 22.70223, mean: 0.04935
[32m[0906 18-27-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35017, current rewards: 27.33291, mean: 0.05359
[32m[0906 18-27-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34983, current rewards: 31.96307, mean: 0.05708
[32m[0906 18-27-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34965, current rewards: 36.59066, mean: 0.05998
[32m[0906 18-28-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35011, current rewards: 41.00139, mean: 0.06212
[32m[0906 18-28-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35040, current rewards: 44.96521, mean: 0.06333
[32m[0906 18-28-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35084, current rewards: 52.41010, mean: 0.06896
[32m[0906 18-28-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35141, current rewards: 56.57457, mean: 0.06985
[32m[0906 18-29-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35184, current rewards: 60.75911, mean: 0.07065
[32m[0906 18-29-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35215, current rewards: 64.93769, mean: 0.07136
[32m[0906 18-29-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35249, current rewards: 69.12114, mean: 0.07200
[32m[0906 18-30-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35262, current rewards: 73.30443, mean: 0.07258
[32m[0906 18-30-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35263, current rewards: 77.48654, mean: 0.07310
[32m[0906 18-30-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35264, current rewards: 81.66981, mean: 0.07358
[32m[0906 18-31-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35270, current rewards: 86.15012, mean: 0.07427
[32m[0906 18-31-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35273, current rewards: 69.05017, mean: 0.05707
[32m[0906 18-31-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35274, current rewards: 73.37500, mean: 0.05823
[32m[0906 18-31-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35279, current rewards: 77.72077, mean: 0.05933
[32m[0906 18-32-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35223, current rewards: 82.06746, mean: 0.06034
[32m[0906 18-32-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35090, current rewards: 86.41013, mean: 0.06128
[32m[0906 18-32-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34970, current rewards: 90.75382, mean: 0.06216
[32m[0906 18-32-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34863, current rewards: 54.26734, mean: 0.03594
[32m[0906 18-33-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34757, current rewards: 46.50392, mean: 0.02981
[32m[0906 18-33-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34655, current rewards: 39.10315, mean: 0.02429
[32m[0906 18-33-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34562, current rewards: 44.28029, mean: 0.02667
[32m[0906 18-34-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34475, current rewards: 49.48574, mean: 0.02894
[32m[0906 18-34-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34391, current rewards: 54.69129, mean: 0.03107
[32m[0906 18-34-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34314, current rewards: 59.89542, mean: 0.03309
[32m[0906 18-34-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34243, current rewards: 65.10448, mean: 0.03500
[32m[0906 18-35-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34171, current rewards: 70.31134, mean: 0.03681
[32m[0906 18-35-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34102, current rewards: 75.51884, mean: 0.03853
[32m[0906 18-35-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34036, current rewards: 60.78206, mean: 0.03024
[32m[0906 18-35-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33971, current rewards: 66.77697, mean: 0.03242
[32m[0906 18-36-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33911, current rewards: 71.11088, mean: 0.03370
[32m[0906 18-36-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33853, current rewards: 53.67979, mean: 0.02485
[32m[0906 18-36-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33797, current rewards: 58.35321, mean: 0.02640
[32m[0906 18-36-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33746, current rewards: 62.89980, mean: 0.02783
[32m[0906 18-37-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33698, current rewards: 67.44173, mean: 0.02920
[32m[0906 18-37-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33651, current rewards: 71.98777, mean: 0.03050
[32m[0906 18-37-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33606, current rewards: 35.06148, mean: 0.01455
[32m[0906 18-37-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33560, current rewards: 43.29871, mean: 0.01760
[32m[0906 18-38-11 @Agent.py:117][0m Average action selection time: 0.3353
[32m[0906 18-38-11 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-38-12 @MBExp.py:227][0m Rewards obtained: [49.39813340287507], Lows: [60], Highs: [73], Total time: 17483.329624
[32m[0906 18-38-53 @MBExp.py:144][0m ####################################################################
[32m[0906 18-38-53 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 18-38-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31668, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-39-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31356, current rewards: -28.33457, mean: -0.47224
[32m[0906 18-39-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30686, current rewards: -24.76255, mean: -0.22511
[32m[0906 18-39-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30441, current rewards: -21.16540, mean: -0.13228
[32m[0906 18-39-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30407, current rewards: -17.56755, mean: -0.08366
[32m[0906 18-40-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30494, current rewards: -13.97056, mean: -0.05373
[32m[0906 18-40-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30550, current rewards: -10.37421, mean: -0.03347
[32m[0906 18-40-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30668, current rewards: -6.77532, mean: -0.01882
[32m[0906 18-40-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30779, current rewards: -3.17591, mean: -0.00775
[32m[0906 18-41-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30862, current rewards: 0.42276, mean: 0.00092
[32m[0906 18-41-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30877, current rewards: 4.02127, mean: 0.00788
[32m[0906 18-41-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30876, current rewards: 7.61687, mean: 0.01360
[32m[0906 18-42-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30878, current rewards: -9.50541, mean: -0.01558
[32m[0906 18-42-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30936, current rewards: -23.98158, mean: -0.03634
[32m[0906 18-42-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30978, current rewards: -17.30942, mean: -0.02438
[32m[0906 18-42-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31015, current rewards: -48.92791, mean: -0.06438
[32m[0906 18-43-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31051, current rewards: -46.46374, mean: -0.05736
[32m[0906 18-43-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31075, current rewards: -40.76223, mean: -0.04740
[32m[0906 18-43-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31106, current rewards: -35.11056, mean: -0.03858
[32m[0906 18-43-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31132, current rewards: -29.46445, mean: -0.03069
[32m[0906 18-44-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31150, current rewards: -61.85842, mean: -0.06125
[32m[0906 18-44-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31169, current rewards: -58.68347, mean: -0.05536
[32m[0906 18-44-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31183, current rewards: -47.80860, mean: -0.04307
[32m[0906 18-44-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31195, current rewards: -36.80470, mean: -0.03173
[32m[0906 18-45-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31208, current rewards: -26.99784, mean: -0.02231
[32m[0906 18-45-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31219, current rewards: -22.31365, mean: -0.01771
[32m[0906 18-45-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31231, current rewards: -16.93570, mean: -0.01293
[32m[0906 18-45-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31242, current rewards: -11.55439, mean: -0.00850
[32m[0906 18-46-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31252, current rewards: -6.17425, mean: -0.00438
[32m[0906 18-46-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31261, current rewards: -0.79506, mean: -0.00054
[32m[0906 18-46-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31269, current rewards: 4.58349, mean: 0.00304
[32m[0906 18-47-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31277, current rewards: 9.96249, mean: 0.00639
[32m[0906 18-47-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31287, current rewards: -6.07107, mean: -0.00377
[32m[0906 18-47-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31295, current rewards: 3.15749, mean: 0.00190
[32m[0906 18-47-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31301, current rewards: 12.63463, mean: 0.00739
[32m[0906 18-48-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31305, current rewards: 22.10320, mean: 0.01256
[32m[0906 18-48-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31311, current rewards: 31.58242, mean: 0.01745
[32m[0906 18-48-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31316, current rewards: 41.05465, mean: 0.02207
[32m[0906 18-48-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31319, current rewards: 50.53498, mean: 0.02646
[32m[0906 18-49-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31321, current rewards: 59.86987, mean: 0.03055
[32m[0906 18-49-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31324, current rewards: 68.99800, mean: 0.03433
[32m[0906 18-49-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31327, current rewards: 56.95699, mean: 0.02765
[32m[0906 18-49-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31330, current rewards: 60.33082, mean: 0.02859
[32m[0906 18-50-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31332, current rewards: 66.04433, mean: 0.03058
[32m[0906 18-50-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31335, current rewards: 71.74892, mean: 0.03247
[32m[0906 18-50-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31337, current rewards: 77.45954, mean: 0.03427
[32m[0906 18-50-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31341, current rewards: 83.16775, mean: 0.03600
[32m[0906 18-51-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31342, current rewards: 78.27692, mean: 0.03317
[32m[0906 18-51-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31344, current rewards: 53.24804, mean: 0.02209
[32m[0906 18-51-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31345, current rewards: 61.52788, mean: 0.02501
[32m[0906 18-51-57 @Agent.py:117][0m Average action selection time: 0.3135
[32m[0906 18-51-57 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-51-57 @MBExp.py:227][0m Rewards obtained: [68.15100911824206], Lows: [86], Highs: [71], Total time: 18267.563494
[32m[0906 18-52-40 @MBExp.py:144][0m ####################################################################
[32m[0906 18-52-40 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 18-52-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31565, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-52-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31181, current rewards: -17.79615, mean: -0.29660
[32m[0906 18-53-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30619, current rewards: -13.01433, mean: -0.11831
[32m[0906 18-53-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30398, current rewards: -8.18096, mean: -0.05113
[32m[0906 18-53-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30347, current rewards: -3.35095, mean: -0.01596
[32m[0906 18-54-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30444, current rewards: 1.47785, mean: 0.00568
[32m[0906 18-54-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30502, current rewards: 7.52526, mean: 0.02428
[32m[0906 18-54-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30625, current rewards: 11.97187, mean: 0.03326
[32m[0906 18-54-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30741, current rewards: 16.29850, mean: 0.03975
[32m[0906 18-55-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30824, current rewards: 20.17112, mean: 0.04385
[32m[0906 18-55-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30838, current rewards: 23.93830, mean: 0.04694
[32m[0906 18-55-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30833, current rewards: 27.83284, mean: 0.04970
[32m[0906 18-55-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30833, current rewards: 7.33555, mean: 0.01203
[32m[0906 18-56-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30890, current rewards: 14.61085, mean: 0.02214
[32m[0906 18-56-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30950, current rewards: 20.43613, mean: 0.02878
[32m[0906 18-56-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30987, current rewards: 27.43259, mean: 0.03610
[32m[0906 18-56-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31026, current rewards: 34.87707, mean: 0.04306
[32m[0906 18-57-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31057, current rewards: 28.53563, mean: 0.03318
[32m[0906 18-57-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31086, current rewards: 24.58233, mean: 0.02701
[32m[0906 18-57-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31105, current rewards: 29.34931, mean: 0.03057
[32m[0906 18-57-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31123, current rewards: 34.11839, mean: 0.03378
[32m[0906 18-58-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31144, current rewards: 38.89540, mean: 0.03669
[32m[0906 18-58-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31160, current rewards: 44.06945, mean: 0.03970
[32m[0906 18-58-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31178, current rewards: 52.56796, mean: 0.04532
[32m[0906 18-58-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31193, current rewards: 57.85711, mean: 0.04782
[32m[0906 18-59-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31204, current rewards: 63.16122, mean: 0.05013
[32m[0906 18-59-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31216, current rewards: 46.26730, mean: 0.03532
[32m[0906 18-59-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31226, current rewards: 50.21179, mean: 0.03692
[32m[0906 19-00-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31231, current rewards: 54.54225, mean: 0.03868
[32m[0906 19-00-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31243, current rewards: 58.86508, mean: 0.04032
[32m[0906 19-00-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31251, current rewards: 63.19440, mean: 0.04185
[32m[0906 19-00-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31260, current rewards: 68.59361, mean: 0.04397
[32m[0906 19-01-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31263, current rewards: 76.24486, mean: 0.04736
[32m[0906 19-01-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31267, current rewards: 82.07683, mean: 0.04944
[32m[0906 19-01-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31270, current rewards: 87.91148, mean: 0.05141
[32m[0906 19-01-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31273, current rewards: 93.74623, mean: 0.05326
[32m[0906 19-02-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31275, current rewards: 99.58595, mean: 0.05502
[32m[0906 19-02-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31279, current rewards: 105.42544, mean: 0.05668
[32m[0906 19-02-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31285, current rewards: 111.26322, mean: 0.05825
[32m[0906 19-02-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31287, current rewards: 118.88800, mean: 0.06066
[32m[0906 19-03-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31292, current rewards: 124.95499, mean: 0.06217
[32m[0906 19-03-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31291, current rewards: 131.02074, mean: 0.06360
[32m[0906 19-03-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31292, current rewards: 137.09368, mean: 0.06497
[32m[0906 19-03-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31293, current rewards: 128.31598, mean: 0.05941
[32m[0906 19-04-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31296, current rewards: 105.39469, mean: 0.04769
[32m[0906 19-04-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31299, current rewards: 111.48828, mean: 0.04933
[32m[0906 19-04-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31300, current rewards: 117.73542, mean: 0.05097
[32m[0906 19-05-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31302, current rewards: 122.32557, mean: 0.05183
[32m[0906 19-05-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31304, current rewards: 126.94458, mean: 0.05267
[32m[0906 19-05-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31305, current rewards: 121.20947, mean: 0.04927
[32m[0906 19-05-44 @Agent.py:117][0m Average action selection time: 0.3131
[32m[0906 19-05-44 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-05-44 @MBExp.py:227][0m Rewards obtained: [113.79017203065844], Lows: [34], Highs: [81], Total time: 19050.828443000002
[32m[0906 19-06-29 @MBExp.py:144][0m ####################################################################
[32m[0906 19-06-29 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 19-06-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31771, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-06-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31020, current rewards: -18.38019, mean: -0.30634
[32m[0906 19-07-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30536, current rewards: -12.89227, mean: -0.11720
[32m[0906 19-07-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30358, current rewards: -7.07092, mean: -0.04419
[32m[0906 19-07-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30321, current rewards: -1.23795, mean: -0.00589
[32m[0906 19-07-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30428, current rewards: 4.76761, mean: 0.01834
[32m[0906 19-08-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30498, current rewards: 10.89984, mean: 0.03516
[32m[0906 19-08-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30635, current rewards: 16.76119, mean: 0.04656
[32m[0906 19-08-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30739, current rewards: 22.62468, mean: 0.05518
[32m[0906 19-08-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30832, current rewards: 28.48580, mean: 0.06193
[32m[0906 19-09-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30856, current rewards: 34.35494, mean: 0.06736
[32m[0906 19-09-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30857, current rewards: 17.24678, mean: 0.03080
[32m[0906 19-09-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30855, current rewards: 21.78429, mean: 0.03571
[32m[0906 19-09-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30911, current rewards: 26.28486, mean: 0.03983
[32m[0906 19-10-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30966, current rewards: 32.32662, mean: 0.04553
[32m[0906 19-10-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31008, current rewards: 37.12438, mean: 0.04885
[32m[0906 19-10-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31049, current rewards: 41.92498, mean: 0.05176
[32m[0906 19-10-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31082, current rewards: 46.71653, mean: 0.05432
[32m[0906 19-11-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31113, current rewards: 51.51151, mean: 0.05661
[32m[0906 19-11-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31141, current rewards: 56.31206, mean: 0.05866
[32m[0906 19-11-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31164, current rewards: 61.10690, mean: 0.06050
[32m[0906 19-11-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31184, current rewards: 65.89880, mean: 0.06217
[32m[0906 19-12-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31201, current rewards: 76.26637, mean: 0.06871
[32m[0906 19-12-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31218, current rewards: 81.82136, mean: 0.07054
[32m[0906 19-12-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31230, current rewards: 76.71758, mean: 0.06340
[32m[0906 19-13-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31242, current rewards: 54.87961, mean: 0.04356
[32m[0906 19-13-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31254, current rewards: 63.73491, mean: 0.04865
[32m[0906 19-13-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31265, current rewards: 72.60277, mean: 0.05338
[32m[0906 19-13-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31277, current rewards: 81.45164, mean: 0.05777
[32m[0906 19-14-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31285, current rewards: 90.32028, mean: 0.06186
[32m[0906 19-14-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31294, current rewards: 89.41461, mean: 0.05921
[32m[0906 19-14-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31300, current rewards: 96.37014, mean: 0.06178
[32m[0906 19-14-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31304, current rewards: 102.38121, mean: 0.06359
[32m[0906 19-15-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31312, current rewards: 108.40647, mean: 0.06531
[32m[0906 19-15-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31318, current rewards: 114.42829, mean: 0.06692
[32m[0906 19-15-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31322, current rewards: 120.45073, mean: 0.06844
[32m[0906 19-15-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31330, current rewards: 126.47325, mean: 0.06987
[32m[0906 19-16-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31334, current rewards: 132.49164, mean: 0.07123
[32m[0906 19-16-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31338, current rewards: 116.13767, mean: 0.06081
[32m[0906 19-16-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31341, current rewards: 120.82481, mean: 0.06165
[32m[0906 19-16-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31344, current rewards: 125.49831, mean: 0.06244
[32m[0906 19-17-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31347, current rewards: 130.16972, mean: 0.06319
[32m[0906 19-17-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31350, current rewards: 134.84355, mean: 0.06391
[32m[0906 19-17-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31355, current rewards: 139.51497, mean: 0.06459
[32m[0906 19-18-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31359, current rewards: 144.18138, mean: 0.06524
[32m[0906 19-18-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31363, current rewards: 148.85559, mean: 0.06587
[32m[0906 19-18-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31365, current rewards: 153.52900, mean: 0.06646
[32m[0906 19-18-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31369, current rewards: 115.85219, mean: 0.04909
[32m[0906 19-19-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31372, current rewards: 122.07494, mean: 0.05065
[32m[0906 19-19-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31375, current rewards: 128.27185, mean: 0.05214
[32m[0906 19-19-34 @Agent.py:117][0m Average action selection time: 0.3138
[32m[0906 19-19-34 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-19-34 @MBExp.py:227][0m Rewards obtained: [133.22775855599434], Lows: [46], Highs: [61], Total time: 19835.840276000003
[32m[0906 19-20-21 @MBExp.py:144][0m ####################################################################
[32m[0906 19-20-21 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 19-20-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31751, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-20-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30906, current rewards: -13.55984, mean: -0.22600
[32m[0906 19-20-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30459, current rewards: -9.97742, mean: -0.09070
[32m[0906 19-21-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30279, current rewards: -6.39886, mean: -0.03999
[32m[0906 19-21-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30235, current rewards: -2.81950, mean: -0.01343
[32m[0906 19-21-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30364, current rewards: 0.73417, mean: 0.00282
[32m[0906 19-21-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30453, current rewards: 4.16287, mean: 0.01343
[32m[0906 19-22-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30603, current rewards: 7.83743, mean: 0.02177
[32m[0906 19-22-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30735, current rewards: 11.51081, mean: 0.02808
[32m[0906 19-22-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30835, current rewards: 15.18279, mean: 0.03301
[32m[0906 19-22-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30852, current rewards: -2.42567, mean: -0.00476
[32m[0906 19-23-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30851, current rewards: 1.17606, mean: 0.00210
[32m[0906 19-23-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30852, current rewards: 4.76951, mean: 0.00782
[32m[0906 19-23-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30903, current rewards: 8.36299, mean: 0.01267
[32m[0906 19-24-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30955, current rewards: -28.94591, mean: -0.04077
[32m[0906 19-24-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30996, current rewards: -24.68987, mean: -0.03249
[32m[0906 19-24-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31033, current rewards: -20.36201, mean: -0.02514
[32m[0906 19-24-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31066, current rewards: -34.79410, mean: -0.04046
[32m[0906 19-25-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31098, current rewards: -53.13274, mean: -0.05839
[32m[0906 19-25-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31121, current rewards: -48.56666, mean: -0.05059
[32m[0906 19-25-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31142, current rewards: -43.93920, mean: -0.04350
[32m[0906 19-25-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31160, current rewards: -39.28511, mean: -0.03706
[32m[0906 19-26-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31176, current rewards: -34.79560, mean: -0.03135
[32m[0906 19-26-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31193, current rewards: -30.34096, mean: -0.02616
[32m[0906 19-26-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31204, current rewards: -25.91327, mean: -0.02142
[32m[0906 19-26-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31218, current rewards: -52.64639, mean: -0.04178
[32m[0906 19-27-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31231, current rewards: -44.78685, mean: -0.03419
[32m[0906 19-27-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31246, current rewards: -36.92732, mean: -0.02715
[32m[0906 19-27-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31259, current rewards: -29.06778, mean: -0.02062
[32m[0906 19-27-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31264, current rewards: -21.20824, mean: -0.01453
[32m[0906 19-28-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31274, current rewards: -15.91609, mean: -0.01054
[32m[0906 19-28-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31281, current rewards: -11.45734, mean: -0.00734
[32m[0906 19-28-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31287, current rewards: -6.99860, mean: -0.00435
[32m[0906 19-29-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31297, current rewards: -2.53985, mean: -0.00153
[32m[0906 19-29-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31306, current rewards: -14.41873, mean: -0.00843
[32m[0906 19-29-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31316, current rewards: -64.41873, mean: -0.03660
[32m[0906 19-29-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31348, current rewards: -114.41873, mean: -0.06321
[32m[0906 19-30-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31452, current rewards: -164.41873, mean: -0.08840
[32m[0906 19-30-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31552, current rewards: -214.41873, mean: -0.11226
[32m[0906 19-30-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31644, current rewards: -264.41873, mean: -0.13491
[32m[0906 19-30-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31727, current rewards: -314.41873, mean: -0.15643
[32m[0906 19-31-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31812, current rewards: -364.41873, mean: -0.17690
[32m[0906 19-31-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31892, current rewards: -414.41873, mean: -0.19641
[32m[0906 19-31-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31967, current rewards: -464.41873, mean: -0.21501
[32m[0906 19-32-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32038, current rewards: -514.41873, mean: -0.23277
[32m[0906 19-32-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32104, current rewards: -564.41873, mean: -0.24974
[32m[0906 19-32-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32169, current rewards: -614.41873, mean: -0.26598
[32m[0906 19-33-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32233, current rewards: -664.41873, mean: -0.28153
[32m[0906 19-33-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32293, current rewards: -714.41873, mean: -0.29644
[32m[0906 19-33-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32352, current rewards: -764.41873, mean: -0.31074
[32m[0906 19-33-51 @Agent.py:117][0m Average action selection time: 0.3240
[32m[0906 19-33-51 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-33-51 @MBExp.py:227][0m Rewards obtained: [-804.4187304571672], Lows: [58], Highs: [846], Total time: 20646.400127
[32m[0906 19-34-46 @MBExp.py:144][0m ####################################################################
[32m[0906 19-34-46 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 19-34-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35402, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-35-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34272, current rewards: -15.81557, mean: -0.26359
[32m[0906 19-35-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33839, current rewards: -11.10005, mean: -0.10091
[32m[0906 19-35-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33691, current rewards: -6.38589, mean: -0.03991
[32m[0906 19-35-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33594, current rewards: -1.67301, mean: -0.00797
[32m[0906 19-36-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33757, current rewards: 3.04300, mean: 0.01170
[32m[0906 19-36-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33871, current rewards: 7.76316, mean: 0.02504
[32m[0906 19-36-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34049, current rewards: 12.47922, mean: 0.03466
[32m[0906 19-37-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34215, current rewards: 17.19506, mean: 0.04194
[32m[0906 19-37-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34342, current rewards: 21.91374, mean: 0.04764
[32m[0906 19-37-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34375, current rewards: 26.63130, mean: 0.05222
[32m[0906 19-37-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34378, current rewards: 31.34821, mean: 0.05598
[32m[0906 19-38-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34385, current rewards: 27.68611, mean: 0.04539
[32m[0906 19-38-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34434, current rewards: -0.59455, mean: -0.00090
[32m[0906 19-38-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34499, current rewards: 5.15713, mean: 0.00726
[32m[0906 19-39-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34548, current rewards: 10.91333, mean: 0.01436
[32m[0906 19-39-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34596, current rewards: 16.66535, mean: 0.02057
[32m[0906 19-39-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34637, current rewards: 22.41875, mean: 0.02607
[32m[0906 19-40-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34676, current rewards: 28.17431, mean: 0.03096
[32m[0906 19-40-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34709, current rewards: 33.92258, mean: 0.03534
[32m[0906 19-40-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34743, current rewards: 17.50745, mean: 0.01733
[32m[0906 19-40-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34771, current rewards: 25.97683, mean: 0.02451
[32m[0906 19-41-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34787, current rewards: 31.00478, mean: 0.02793
[32m[0906 19-41-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34812, current rewards: 36.01610, mean: 0.03105
[32m[0906 19-41-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34826, current rewards: 41.02371, mean: 0.03390
[32m[0906 19-42-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34842, current rewards: 46.03854, mean: 0.03654
[32m[0906 19-42-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34857, current rewards: 51.05203, mean: 0.03897
[32m[0906 19-42-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34869, current rewards: 56.05947, mean: 0.04122
[32m[0906 19-42-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34877, current rewards: 52.66871, mean: 0.03735
[32m[0906 19-43-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34889, current rewards: 25.62593, mean: 0.01755
[32m[0906 19-43-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34898, current rewards: 30.67577, mean: 0.02032
[32m[0906 19-43-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34909, current rewards: 35.65801, mean: 0.02286
[32m[0906 19-44-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34915, current rewards: 40.63647, mean: 0.02524
[32m[0906 19-44-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34916, current rewards: 45.61833, mean: 0.02748
[32m[0906 19-44-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34822, current rewards: 50.59781, mean: 0.02959
[32m[0906 19-44-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34728, current rewards: 55.58018, mean: 0.03158
[32m[0906 19-45-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34636, current rewards: 38.34038, mean: 0.02118
[32m[0906 19-45-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34551, current rewards: 42.84706, mean: 0.02304
[32m[0906 19-45-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34473, current rewards: 48.33251, mean: 0.02530
[32m[0906 19-46-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34398, current rewards: 53.82458, mean: 0.02746
[32m[0906 19-46-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34324, current rewards: 59.30910, mean: 0.02951
[32m[0906 19-46-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34253, current rewards: 64.79337, mean: 0.03145
[32m[0906 19-46-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34189, current rewards: 70.27835, mean: 0.03331
[32m[0906 19-47-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34126, current rewards: 75.76365, mean: 0.03508
[32m[0906 19-47-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34066, current rewards: 81.24374, mean: 0.03676
[32m[0906 19-47-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34009, current rewards: 86.24683, mean: 0.03816
[32m[0906 19-47-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33954, current rewards: 90.94883, mean: 0.03937
[32m[0906 19-48-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33902, current rewards: 95.70669, mean: 0.04055
[32m[0906 19-48-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33853, current rewards: 100.46732, mean: 0.04169
[32m[0906 19-48-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33806, current rewards: 105.23046, mean: 0.04278
[32m[0906 19-48-51 @Agent.py:117][0m Average action selection time: 0.3377
[32m[0906 19-48-51 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-48-51 @MBExp.py:227][0m Rewards obtained: [109.03449964099805], Lows: [45], Highs: [60], Total time: 21491.286602
[32m[0906 19-49-41 @MBExp.py:144][0m ####################################################################
[32m[0906 19-49-41 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 19-49-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31726, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-50-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30475, current rewards: -15.07542, mean: -0.25126
[32m[0906 19-50-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30209, current rewards: -9.51338, mean: -0.08649
[32m[0906 19-50-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30112, current rewards: -3.95005, mean: -0.02469
[32m[0906 19-50-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30058, current rewards: 1.61093, mean: 0.00767
[32m[0906 19-51-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30199, current rewards: 7.17300, mean: 0.02759
[32m[0906 19-51-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30299, current rewards: 2.73191, mean: 0.00881
[32m[0906 19-51-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30465, current rewards: -7.20016, mean: -0.02000
[32m[0906 19-51-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30616, current rewards: -7.23928, mean: -0.01766
[32m[0906 19-52-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30721, current rewards: -5.34825, mean: -0.01163
[32m[0906 19-52-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30747, current rewards: -3.42006, mean: -0.00671
[32m[0906 19-52-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30759, current rewards: -3.64163, mean: -0.00650
[32m[0906 19-52-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30765, current rewards: -1.80074, mean: -0.00295
[32m[0906 19-53-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30807, current rewards: 4.19348, mean: 0.00635
[32m[0906 19-53-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30875, current rewards: 9.30008, mean: 0.01310
[32m[0906 19-53-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30920, current rewards: -23.43222, mean: -0.03083
[32m[0906 19-53-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30964, current rewards: -22.41491, mean: -0.02767
[32m[0906 19-54-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31001, current rewards: -17.32920, mean: -0.02015
[32m[0906 19-54-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31032, current rewards: -12.24635, mean: -0.01346
[32m[0906 19-54-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31059, current rewards: -7.52987, mean: -0.00784
[32m[0906 19-54-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31079, current rewards: -14.65103, mean: -0.01451
[32m[0906 19-55-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31097, current rewards: -10.80119, mean: -0.01019
[32m[0906 19-55-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31111, current rewards: -6.80809, mean: -0.00613
[32m[0906 19-55-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31127, current rewards: -2.93701, mean: -0.00253
[32m[0906 19-55-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31143, current rewards: 0.98032, mean: 0.00081
[32m[0906 19-56-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31155, current rewards: 4.87255, mean: 0.00387
[32m[0906 19-56-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31172, current rewards: 8.77402, mean: 0.00670
[32m[0906 19-56-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31185, current rewards: 12.67165, mean: 0.00932
[32m[0906 19-57-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31194, current rewards: 16.57071, mean: 0.01175
[32m[0906 19-57-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31204, current rewards: 20.46970, mean: 0.01402
[32m[0906 19-57-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31213, current rewards: 2.79867, mean: 0.00185
[32m[0906 19-57-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31222, current rewards: 7.28132, mean: 0.00467
[32m[0906 19-58-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31230, current rewards: 11.94993, mean: 0.00742
[32m[0906 19-58-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31237, current rewards: 16.61596, mean: 0.01001
[32m[0906 19-58-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31245, current rewards: 21.28006, mean: 0.01244
[32m[0906 19-58-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31251, current rewards: 25.94602, mean: 0.01474
[32m[0906 19-59-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31257, current rewards: 25.92513, mean: 0.01432
[32m[0906 19-59-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31263, current rewards: 20.98099, mean: 0.01128
[32m[0906 19-59-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31269, current rewards: 3.65101, mean: 0.00191
[32m[0906 19-59-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31273, current rewards: -6.34924, mean: -0.00324
[32m[0906 20-00-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31276, current rewards: -16.47046, mean: -0.00819
[32m[0906 20-00-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31281, current rewards: -37.27621, mean: -0.01810
[32m[0906 20-00-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31282, current rewards: -52.62962, mean: -0.02494
[32m[0906 20-00-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31286, current rewards: -62.48575, mean: -0.02893
[32m[0906 20-01-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31288, current rewards: -73.53988, mean: -0.03328
[32m[0906 20-01-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31290, current rewards: -99.09162, mean: -0.04385
[32m[0906 20-01-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31295, current rewards: -109.99934, mean: -0.04762
[32m[0906 20-02-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31299, current rewards: -121.23525, mean: -0.05137
[32m[0906 20-02-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31302, current rewards: -116.87416, mean: -0.04850
[32m[0906 20-02-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31305, current rewards: -112.89887, mean: -0.04589
[32m[0906 20-02-45 @Agent.py:117][0m Average action selection time: 0.3131
[32m[0906 20-02-45 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-02-45 @MBExp.py:227][0m Rewards obtained: [-109.71760732114167], Lows: [46], Highs: [240], Total time: 22274.607125
[32m[0906 20-03-37 @MBExp.py:144][0m ####################################################################
[32m[0906 20-03-37 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 20-03-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31010, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-03-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30278, current rewards: -13.83549, mean: -0.23059
[32m[0906 20-04-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30140, current rewards: -8.98547, mean: -0.08169
[32m[0906 20-04-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30016, current rewards: -4.78576, mean: -0.02991
[32m[0906 20-04-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30004, current rewards: 0.09451, mean: 0.00045
[32m[0906 20-04-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30174, current rewards: 5.11832, mean: 0.01969
[32m[0906 20-05-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30302, current rewards: 10.13987, mean: 0.03271
[32m[0906 20-05-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30479, current rewards: 15.16197, mean: 0.04212
[32m[0906 20-05-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30649, current rewards: 20.18799, mean: 0.04924
[32m[0906 20-05-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30756, current rewards: 5.40284, mean: 0.01175
[32m[0906 20-06-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30774, current rewards: 8.40491, mean: 0.01648
[32m[0906 20-06-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30783, current rewards: 14.17256, mean: 0.02531
[32m[0906 20-06-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30790, current rewards: 19.87782, mean: 0.03259
[32m[0906 20-07-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30829, current rewards: 24.97259, mean: 0.03784
[32m[0906 20-07-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30885, current rewards: -22.20344, mean: -0.03127
[32m[0906 20-07-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30937, current rewards: -46.71609, mean: -0.06147
[32m[0906 20-07-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30988, current rewards: -40.25727, mean: -0.04970
[32m[0906 20-08-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31025, current rewards: -33.79844, mean: -0.03930
[32m[0906 20-08-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31055, current rewards: -27.33962, mean: -0.03004
[32m[0906 20-08-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31083, current rewards: -21.02714, mean: -0.02190
[32m[0906 20-08-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31110, current rewards: -17.54659, mean: -0.01737
[32m[0906 20-09-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31128, current rewards: -31.21389, mean: -0.02945
[32m[0906 20-09-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31145, current rewards: -81.21389, mean: -0.07317
[32m[0906 20-09-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31165, current rewards: -131.21389, mean: -0.11312
[32m[0906 20-09-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31183, current rewards: -181.21389, mean: -0.14976
[32m[0906 20-10-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31200, current rewards: -231.21389, mean: -0.18350
[32m[0906 20-10-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31216, current rewards: -281.21389, mean: -0.21467
[32m[0906 20-10-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31229, current rewards: -331.21389, mean: -0.24354
[32m[0906 20-10-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31243, current rewards: -381.21389, mean: -0.27036
[32m[0906 20-11-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31251, current rewards: -431.21389, mean: -0.29535
[32m[0906 20-11-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31257, current rewards: -481.21389, mean: -0.31868
[32m[0906 20-11-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31265, current rewards: -531.21389, mean: -0.34052
[32m[0906 20-12-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31272, current rewards: -581.21389, mean: -0.36100
[32m[0906 20-12-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31279, current rewards: -631.21389, mean: -0.38025
[32m[0906 20-12-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31286, current rewards: -681.21389, mean: -0.39837
[32m[0906 20-12-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31290, current rewards: -731.21389, mean: -0.41546
[32m[0906 20-13-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31295, current rewards: -781.21389, mean: -0.43161
[32m[0906 20-13-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31297, current rewards: -831.21389, mean: -0.44689
[32m[0906 20-13-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31365, current rewards: -881.21389, mean: -0.46137
[32m[0906 20-13-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31462, current rewards: -931.21389, mean: -0.47511
[32m[0906 20-14-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31555, current rewards: -981.21389, mean: -0.48817
[32m[0906 20-14-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31645, current rewards: -1031.21389, mean: -0.50059
[32m[0906 20-14-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31733, current rewards: -1081.21389, mean: -0.51242
[32m[0906 20-15-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31814, current rewards: -1131.21389, mean: -0.52371
[32m[0906 20-15-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31891, current rewards: -1181.21389, mean: -0.53449
[32m[0906 20-15-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31962, current rewards: -1231.21389, mean: -0.54478
[32m[0906 20-15-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32031, current rewards: -1281.21389, mean: -0.55464
[32m[0906 20-16-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32097, current rewards: -1331.21389, mean: -0.56407
[32m[0906 20-16-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32161, current rewards: -1381.21389, mean: -0.57312
[32m[0906 20-16-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32222, current rewards: -1431.21389, mean: -0.58179
[32m[0906 20-17-05 @Agent.py:117][0m Average action selection time: 0.3227
[32m[0906 20-17-05 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-17-05 @MBExp.py:227][0m Rewards obtained: [-1471.2138930665299], Lows: [40], Highs: [1496], Total time: 23081.964434999998
[32m[0906 20-18-05 @MBExp.py:144][0m ####################################################################
[32m[0906 20-18-05 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 20-18-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34233, current rewards: 0.67787, mean: 0.06779
[32m[0906 20-18-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33616, current rewards: 5.22816, mean: 0.08714
[32m[0906 20-18-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33466, current rewards: 13.36492, mean: 0.12150
[32m[0906 20-18-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33334, current rewards: 20.47868, mean: 0.12799
[32m[0906 20-19-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33329, current rewards: 27.40534, mean: 0.13050
[32m[0906 20-19-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33527, current rewards: 34.33200, mean: 0.13205
[32m[0906 20-19-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33664, current rewards: 41.25866, mean: 0.13309
[32m[0906 20-20-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33859, current rewards: 48.18532, mean: 0.13385
[32m[0906 20-20-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34052, current rewards: 55.11197, mean: 0.13442
[32m[0906 20-20-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34195, current rewards: 62.03863, mean: 0.13487
[32m[0906 20-21-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34235, current rewards: 59.77346, mean: 0.11720
[32m[0906 20-21-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34245, current rewards: 9.77346, mean: 0.01745
[32m[0906 20-21-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34256, current rewards: -40.22654, mean: -0.06595
[32m[0906 20-21-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34296, current rewards: -90.22654, mean: -0.13671
[32m[0906 20-22-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34361, current rewards: -140.22654, mean: -0.19750
[32m[0906 20-22-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34414, current rewards: -190.22654, mean: -0.25030
[32m[0906 20-22-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34471, current rewards: -240.22654, mean: -0.29658
[32m[0906 20-23-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34519, current rewards: -290.22654, mean: -0.33747
[32m[0906 20-23-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34557, current rewards: -340.22654, mean: -0.37388
[32m[0906 20-23-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34597, current rewards: -390.22654, mean: -0.40649
[32m[0906 20-23-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34625, current rewards: -440.22654, mean: -0.43587
[32m[0906 20-24-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34650, current rewards: -490.22654, mean: -0.46248
[32m[0906 20-24-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34678, current rewards: -540.22654, mean: -0.48669
[32m[0906 20-24-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34697, current rewards: -590.22654, mean: -0.50882
[32m[0906 20-25-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34717, current rewards: -598.28733, mean: -0.49445
[32m[0906 20-25-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34735, current rewards: -595.86332, mean: -0.47291
[32m[0906 20-25-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34755, current rewards: -593.43931, mean: -0.45301
[32m[0906 20-25-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34771, current rewards: -598.35466, mean: -0.43997
[32m[0906 20-26-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34785, current rewards: -648.35466, mean: -0.45983
[32m[0906 20-26-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34798, current rewards: -698.35466, mean: -0.47833
[32m[0906 20-26-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34809, current rewards: -748.35466, mean: -0.49560
[32m[0906 20-27-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34816, current rewards: -798.35466, mean: -0.51177
[32m[0906 20-27-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34824, current rewards: -848.35466, mean: -0.52693
[32m[0906 20-27-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34833, current rewards: -898.35466, mean: -0.54118
[32m[0906 20-28-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34844, current rewards: -948.35466, mean: -0.55459
[32m[0906 20-28-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34851, current rewards: -998.35466, mean: -0.56725
[32m[0906 20-28-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34859, current rewards: -1048.35466, mean: -0.57920
[32m[0906 20-28-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34865, current rewards: -1098.35466, mean: -0.59051
[32m[0906 20-29-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34873, current rewards: -1148.35466, mean: -0.60123
[32m[0906 20-29-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34882, current rewards: -1198.35466, mean: -0.61141
[32m[0906 20-29-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34888, current rewards: -1248.35466, mean: -0.62107
[32m[0906 20-30-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34895, current rewards: -1298.35466, mean: -0.63027
[32m[0906 20-30-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34902, current rewards: -1348.35466, mean: -0.63903
[32m[0906 20-30-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34907, current rewards: -1398.35466, mean: -0.64739
[32m[0906 20-30-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34910, current rewards: -1448.35466, mean: -0.65536
[32m[0906 20-31-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34912, current rewards: -1498.35466, mean: -0.66299
[32m[0906 20-31-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34916, current rewards: -1498.18192, mean: -0.64856
[32m[0906 20-31-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34920, current rewards: -1493.64633, mean: -0.63290
[32m[0906 20-32-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34924, current rewards: -1489.11075, mean: -0.61789
[32m[0906 20-32-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34926, current rewards: -1484.57516, mean: -0.60349
[32m[0906 20-32-39 @Agent.py:117][0m Average action selection time: 0.3493
[32m[0906 20-32-39 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-32-39 @MBExp.py:227][0m Rewards obtained: [-1480.9466853173542], Lows: [0], Highs: [1579], Total time: 23955.816056999996
[32m[0906 20-33-42 @MBExp.py:144][0m ####################################################################
[32m[0906 20-33-42 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 20-33-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34197, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-34-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33484, current rewards: -16.46141, mean: -0.27436
[32m[0906 20-34-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33404, current rewards: -11.10908, mean: -0.10099
[32m[0906 20-34-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33233, current rewards: -3.98508, mean: -0.02491
[32m[0906 20-34-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33239, current rewards: 1.36023, mean: 0.00648
[32m[0906 20-35-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33465, current rewards: 6.71144, mean: 0.02581
[32m[0906 20-35-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33617, current rewards: 12.06012, mean: 0.03890
[32m[0906 20-35-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33824, current rewards: -16.30463, mean: -0.04529
[32m[0906 20-36-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34002, current rewards: -17.74892, mean: -0.04329
[32m[0906 20-36-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34145, current rewards: -11.66638, mean: -0.02536
[32m[0906 20-36-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34181, current rewards: -5.59605, mean: -0.01097
[32m[0906 20-36-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34464, current rewards: -0.81981, mean: -0.00146
[32m[0906 20-37-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34456, current rewards: 5.58626, mean: 0.00916
[32m[0906 20-37-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34475, current rewards: 11.96777, mean: 0.01813
[32m[0906 20-37-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34543, current rewards: 18.35350, mean: 0.02585
[32m[0906 20-38-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34594, current rewards: 24.57259, mean: 0.03233
[32m[0906 20-38-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34636, current rewards: 28.58740, mean: 0.03529
[32m[0906 20-38-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34675, current rewards: 33.61122, mean: 0.03908
[32m[0906 20-38-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34710, current rewards: 38.63626, mean: 0.04246
[32m[0906 20-39-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34735, current rewards: 46.07570, mean: 0.04800
[32m[0906 20-39-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34757, current rewards: 51.14715, mean: 0.05064
[32m[0906 20-39-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34775, current rewards: 55.91862, mean: 0.05275
[32m[0906 20-40-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34794, current rewards: 60.68480, mean: 0.05467
[32m[0906 20-40-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34818, current rewards: 65.45195, mean: 0.05642
[32m[0906 20-40-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34832, current rewards: 70.21729, mean: 0.05803
[32m[0906 20-41-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34841, current rewards: 33.20309, mean: 0.02635
[32m[0906 20-41-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34852, current rewards: 42.16990, mean: 0.03219
[32m[0906 20-41-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34861, current rewards: 48.57679, mean: 0.03572
[32m[0906 20-41-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34871, current rewards: 51.57798, mean: 0.03658
[32m[0906 20-42-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34878, current rewards: 57.35267, mean: 0.03928
[32m[0906 20-42-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34886, current rewards: 43.38934, mean: 0.02873
[32m[0906 20-42-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34897, current rewards: 43.41863, mean: 0.02783
[32m[0906 20-43-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34908, current rewards: 50.22686, mean: 0.03120
[32m[0906 20-43-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34919, current rewards: 57.04121, mean: 0.03436
[32m[0906 20-43-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34922, current rewards: 63.84683, mean: 0.03734
[32m[0906 20-43-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34928, current rewards: 70.65425, mean: 0.04014
[32m[0906 20-44-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34935, current rewards: 76.59788, mean: 0.04232
[32m[0906 20-44-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34943, current rewards: 83.17215, mean: 0.04472
[32m[0906 20-44-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34982, current rewards: 89.78546, mean: 0.04701
[32m[0906 20-45-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35043, current rewards: 96.40176, mean: 0.04918
[32m[0906 20-45-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35105, current rewards: 103.01106, mean: 0.05125
[32m[0906 20-45-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35160, current rewards: 109.62447, mean: 0.05322
[32m[0906 20-46-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35215, current rewards: 116.22786, mean: 0.05508
[32m[0906 20-46-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35267, current rewards: 122.83144, mean: 0.05687
[32m[0906 20-46-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35317, current rewards: 117.18171, mean: 0.05302
[32m[0906 20-47-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35368, current rewards: 122.27773, mean: 0.05411
[32m[0906 20-47-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35417, current rewards: 127.77428, mean: 0.05531
[32m[0906 20-47-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35462, current rewards: 132.79195, mean: 0.05627
[32m[0906 20-47-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35504, current rewards: 137.80912, mean: 0.05718
[32m[0906 20-48-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35503, current rewards: 142.82611, mean: 0.05806
[32m[0906 20-48-30 @Agent.py:117][0m Average action selection time: 0.3550
[32m[0906 20-48-30 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-48-30 @MBExp.py:227][0m Rewards obtained: [146.83685360641707], Lows: [51], Highs: [40], Total time: 24843.937059999997
[32m[0906 20-49-35 @MBExp.py:144][0m ####################################################################
[32m[0906 20-49-35 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 20-49-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34472, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-49-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33447, current rewards: -16.26794, mean: -0.27113
[32m[0906 20-50-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33351, current rewards: -11.32156, mean: -0.10292
[32m[0906 20-50-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33177, current rewards: -6.25308, mean: -0.03908
[32m[0906 20-50-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33186, current rewards: -1.18319, mean: -0.00563
[32m[0906 20-51-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33448, current rewards: 3.89290, mean: 0.01497
[32m[0906 20-51-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33613, current rewards: 8.96678, mean: 0.02893
[32m[0906 20-51-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33810, current rewards: 14.03683, mean: 0.03899
[32m[0906 20-51-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33982, current rewards: 19.11061, mean: 0.04661
[32m[0906 20-52-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34122, current rewards: 24.18524, mean: 0.05258
[32m[0906 20-52-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34164, current rewards: 30.93498, mean: 0.06066
[32m[0906 20-52-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34190, current rewards: 36.44490, mean: 0.06508
[32m[0906 20-53-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34204, current rewards: 41.32196, mean: 0.06774
[32m[0906 20-53-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34228, current rewards: 4.27994, mean: 0.00648
[32m[0906 20-53-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34300, current rewards: 8.87630, mean: 0.01250
[32m[0906 20-53-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34358, current rewards: 14.18277, mean: 0.01866
[32m[0906 20-54-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34412, current rewards: 19.51354, mean: 0.02409
[32m[0906 20-54-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34459, current rewards: 24.83111, mean: 0.02887
[32m[0906 20-54-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34494, current rewards: 30.02453, mean: 0.03299
[32m[0906 20-55-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34532, current rewards: 33.99615, mean: 0.03541
[32m[0906 20-55-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34566, current rewards: 39.82108, mean: 0.03943
[32m[0906 20-55-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34596, current rewards: 45.63249, mean: 0.04305
[32m[0906 20-55-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34626, current rewards: 51.43537, mean: 0.04634
[32m[0906 20-56-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34651, current rewards: 57.23626, mean: 0.04934
[32m[0906 20-56-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34675, current rewards: 63.04069, mean: 0.05210
[32m[0906 20-56-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34696, current rewards: 68.85548, mean: 0.05465
[32m[0906 20-57-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34710, current rewards: 74.65695, mean: 0.05699
[32m[0906 20-57-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34729, current rewards: 58.33885, mean: 0.04290
[32m[0906 20-57-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34748, current rewards: 63.65637, mean: 0.04515
[32m[0906 20-58-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34760, current rewards: 69.07843, mean: 0.04731
[32m[0906 20-58-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34773, current rewards: 74.49906, mean: 0.04934
[32m[0906 20-58-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34786, current rewards: 79.91247, mean: 0.05123
[32m[0906 20-58-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34799, current rewards: 85.32916, mean: 0.05300
[32m[0906 20-59-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34810, current rewards: 90.74086, mean: 0.05466
[32m[0906 20-59-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34820, current rewards: 95.04859, mean: 0.05558
[32m[0906 20-59-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34830, current rewards: 101.58362, mean: 0.05772
[32m[0906 21-00-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34838, current rewards: 106.03976, mean: 0.05859
[32m[0906 21-00-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34846, current rewards: 110.54256, mean: 0.05943
[32m[0906 21-00-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34853, current rewards: 115.04604, mean: 0.06023
[32m[0906 21-00-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34862, current rewards: 119.55420, mean: 0.06100
[32m[0906 21-01-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34868, current rewards: 124.05928, mean: 0.06172
[32m[0906 21-01-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34871, current rewards: 86.95444, mean: 0.04221
[32m[0906 21-01-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34875, current rewards: 92.06568, mean: 0.04363
[32m[0906 21-02-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34881, current rewards: 96.45539, mean: 0.04466
[32m[0906 21-02-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34887, current rewards: 100.88451, mean: 0.04565
[32m[0906 21-02-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34896, current rewards: 105.61148, mean: 0.04673
[32m[0906 21-03-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34902, current rewards: 110.34304, mean: 0.04777
[32m[0906 21-03-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34906, current rewards: 115.06796, mean: 0.04876
[32m[0906 21-03-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34912, current rewards: 119.79640, mean: 0.04971
[32m[0906 21-03-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34914, current rewards: 88.91541, mean: 0.03614
[32m[0906 21-04-08 @Agent.py:117][0m Average action selection time: 0.3492
[32m[0906 21-04-08 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-04-08 @MBExp.py:227][0m Rewards obtained: [87.4953347195859], Lows: [60], Highs: [41], Total time: 25717.581451
[32m[0906 21-05-15 @MBExp.py:144][0m ####################################################################
[32m[0906 21-05-15 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 21-05-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33759, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-05-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33351, current rewards: -21.55638, mean: -0.35927
[32m[0906 21-05-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33311, current rewards: -13.73913, mean: -0.12490
[32m[0906 21-06-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33108, current rewards: -8.63987, mean: -0.05400
[32m[0906 21-06-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33119, current rewards: -3.51875, mean: -0.01676
[32m[0906 21-06-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33373, current rewards: 1.60005, mean: 0.00615
[32m[0906 21-06-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33537, current rewards: 6.72188, mean: 0.02168
[32m[0906 21-07-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33746, current rewards: 11.84101, mean: 0.03289
[32m[0906 21-07-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33957, current rewards: 16.95992, mean: 0.04137
[32m[0906 21-07-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34090, current rewards: 22.07749, mean: 0.04799
[32m[0906 21-08-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34122, current rewards: -15.21890, mean: -0.02984
[32m[0906 21-08-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34149, current rewards: -9.95369, mean: -0.01777
[32m[0906 21-08-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34172, current rewards: -4.65791, mean: -0.00764
[32m[0906 21-09-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34194, current rewards: 0.63394, mean: 0.00096
[32m[0906 21-09-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34274, current rewards: 5.92597, mean: 0.00835
[32m[0906 21-09-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34347, current rewards: 11.21854, mean: 0.01476
[32m[0906 21-09-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34405, current rewards: 16.51252, mean: 0.02039
[32m[0906 21-10-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34456, current rewards: 21.80007, mean: 0.02535
[32m[0906 21-10-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34500, current rewards: 30.00362, mean: 0.03297
[32m[0906 21-10-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34535, current rewards: 35.20560, mean: 0.03667
[32m[0906 21-11-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34569, current rewards: 40.50101, mean: 0.04010
[32m[0906 21-11-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34600, current rewards: 45.79537, mean: 0.04320
[32m[0906 21-11-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34630, current rewards: 50.74309, mean: 0.04571
[32m[0906 21-11-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34657, current rewards: 30.63466, mean: 0.02641
[32m[0906 21-12-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34678, current rewards: 37.00893, mean: 0.03059
[32m[0906 21-12-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34698, current rewards: 43.46956, mean: 0.03450
[32m[0906 21-12-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34720, current rewards: 49.36288, mean: 0.03768
[32m[0906 21-13-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34736, current rewards: 12.48028, mean: 0.00918
[32m[0906 21-13-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34751, current rewards: 18.23313, mean: 0.01293
[32m[0906 21-13-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34765, current rewards: 23.98441, mean: 0.01643
[32m[0906 21-14-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34778, current rewards: 29.73938, mean: 0.01969
[32m[0906 21-14-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34792, current rewards: 35.48999, mean: 0.02275
[32m[0906 21-14-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34804, current rewards: 41.24518, mean: 0.02562
[32m[0906 21-14-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34813, current rewards: 46.99328, mean: 0.02831
[32m[0906 21-15-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34825, current rewards: 52.57474, mean: 0.03075
[32m[0906 21-15-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34836, current rewards: 58.16842, mean: 0.03305
[32m[0906 21-15-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34846, current rewards: 63.96463, mean: 0.03534
[32m[0906 21-16-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34854, current rewards: 69.76688, mean: 0.03751
[32m[0906 21-16-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34862, current rewards: 33.25776, mean: 0.01741
[32m[0906 21-16-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34871, current rewards: 40.75876, mean: 0.02080
[32m[0906 21-16-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34879, current rewards: 47.94374, mean: 0.02385
[32m[0906 21-17-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34888, current rewards: 55.12463, mean: 0.02676
[32m[0906 21-17-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34898, current rewards: 62.65870, mean: 0.02970
[32m[0906 21-17-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34901, current rewards: 70.77043, mean: 0.03276
[32m[0906 21-18-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34908, current rewards: 77.58345, mean: 0.03511
[32m[0906 21-18-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34911, current rewards: 84.38502, mean: 0.03734
[32m[0906 21-18-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34917, current rewards: 91.18602, mean: 0.03947
[32m[0906 21-19-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34921, current rewards: 97.99117, mean: 0.04152
[32m[0906 21-19-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34924, current rewards: 104.79071, mean: 0.04348
[32m[0906 21-19-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34929, current rewards: 111.58665, mean: 0.04536
[32m[0906 21-19-49 @Agent.py:117][0m Average action selection time: 0.3493
[32m[0906 21-19-49 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-19-49 @MBExp.py:227][0m Rewards obtained: [114.75452482902492], Lows: [78], Highs: [22], Total time: 26591.543360999996
[32m[0906 21-20-58 @MBExp.py:144][0m ####################################################################
[32m[0906 21-20-58 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 21-21-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33485, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-21-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33343, current rewards: -15.29507, mean: -0.25492
[32m[0906 21-21-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33596, current rewards: -15.72304, mean: -0.14294
[32m[0906 21-21-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33238, current rewards: -13.63079, mean: -0.08519
[32m[0906 21-22-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33234, current rewards: -14.26828, mean: -0.06794
[32m[0906 21-22-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33475, current rewards: -12.81243, mean: -0.04928
[32m[0906 21-22-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33625, current rewards: -11.42054, mean: -0.03684
[32m[0906 21-23-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33844, current rewards: -12.10403, mean: -0.03362
[32m[0906 21-23-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34024, current rewards: -10.66853, mean: -0.02602
[32m[0906 21-23-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34173, current rewards: -9.55713, mean: -0.02078
[32m[0906 21-23-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34197, current rewards: -10.55623, mean: -0.02070
[32m[0906 21-24-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34212, current rewards: -9.45981, mean: -0.01689
[32m[0906 21-24-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34235, current rewards: -10.46081, mean: -0.01715
[32m[0906 21-24-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34247, current rewards: -28.15061, mean: -0.04265
[32m[0906 21-25-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34319, current rewards: -40.37587, mean: -0.05687
[32m[0906 21-25-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34386, current rewards: -52.17545, mean: -0.06865
[32m[0906 21-25-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34441, current rewards: -68.24892, mean: -0.08426
[32m[0906 21-25-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34491, current rewards: -78.71353, mean: -0.09153
[32m[0906 21-26-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34532, current rewards: -78.37175, mean: -0.08612
[32m[0906 21-26-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34575, current rewards: -69.42581, mean: -0.07232
[32m[0906 21-26-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34606, current rewards: -127.41400, mean: -0.12615
[32m[0906 21-27-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34641, current rewards: -116.07701, mean: -0.10951
[32m[0906 21-27-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34667, current rewards: -142.48228, mean: -0.12836
[32m[0906 21-27-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34693, current rewards: -183.11265, mean: -0.15786
[32m[0906 21-27-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34716, current rewards: -204.30129, mean: -0.16884
[32m[0906 21-28-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34737, current rewards: -203.93221, mean: -0.16185
[32m[0906 21-28-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34754, current rewards: -195.41847, mean: -0.14917
[32m[0906 21-28-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34778, current rewards: -184.84948, mean: -0.13592
[32m[0906 21-29-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34794, current rewards: -174.35411, mean: -0.12366
[32m[0906 21-29-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34811, current rewards: -163.54853, mean: -0.11202
[32m[0906 21-29-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34827, current rewards: -152.18859, mean: -0.10079
[32m[0906 21-30-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34841, current rewards: -143.40186, mean: -0.09192
[32m[0906 21-30-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34856, current rewards: -137.93464, mean: -0.08567
[32m[0906 21-30-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34870, current rewards: -131.01614, mean: -0.07893
[32m[0906 21-30-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34881, current rewards: -123.61012, mean: -0.07229
[32m[0906 21-31-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34889, current rewards: -121.02614, mean: -0.06876
[32m[0906 21-31-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34899, current rewards: -191.99760, mean: -0.10608
[32m[0906 21-31-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34903, current rewards: -252.70716, mean: -0.13586
[32m[0906 21-32-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34911, current rewards: -303.28973, mean: -0.15879
[32m[0906 21-32-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34916, current rewards: -368.60088, mean: -0.18806
[32m[0906 21-32-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34922, current rewards: -419.71110, mean: -0.20881
[32m[0906 21-32-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34928, current rewards: -468.09378, mean: -0.22723
[32m[0906 21-33-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34934, current rewards: -550.51930, mean: -0.26091
[32m[0906 21-33-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34940, current rewards: -622.71623, mean: -0.28829
[32m[0906 21-33-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34948, current rewards: -688.04237, mean: -0.31133
[32m[0906 21-34-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34952, current rewards: -740.85972, mean: -0.32781
[32m[0906 21-34-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34957, current rewards: -807.60500, mean: -0.34961
[32m[0906 21-34-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34962, current rewards: -858.82707, mean: -0.36391
[32m[0906 21-35-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34967, current rewards: -916.96229, mean: -0.38048
[32m[0906 21-35-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34975, current rewards: -973.20033, mean: -0.39561
[32m[0906 21-35-33 @Agent.py:117][0m Average action selection time: 0.3498
[32m[0906 21-35-33 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-35-33 @MBExp.py:227][0m Rewards obtained: [-1041.7271408908828], Lows: [675], Highs: [59], Total time: 27466.685838999998
[32m[0906 21-36-44 @MBExp.py:144][0m ####################################################################
[32m[0906 21-36-44 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 21-36-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33193, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-37-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33294, current rewards: -21.48208, mean: -0.35803
[32m[0906 21-37-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33290, current rewards: -14.75177, mean: -0.13411
[32m[0906 21-37-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32986, current rewards: -8.09105, mean: -0.05057
[32m[0906 21-37-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33040, current rewards: -1.42844, mean: -0.00680
[32m[0906 21-38-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33300, current rewards: -16.82999, mean: -0.06473
[32m[0906 21-38-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33475, current rewards: -11.52528, mean: -0.03718
[32m[0906 21-38-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33700, current rewards: -6.18743, mean: -0.01719
[32m[0906 21-39-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33886, current rewards: 0.32383, mean: 0.00079
[32m[0906 21-39-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34027, current rewards: -2.87330, mean: -0.00625
[32m[0906 21-39-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34061, current rewards: -30.88925, mean: -0.06057
[32m[0906 21-39-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34095, current rewards: -24.86007, mean: -0.04439
[32m[0906 21-40-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34119, current rewards: -19.32334, mean: -0.03168
[32m[0906 21-40-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34142, current rewards: -13.81788, mean: -0.02094
[32m[0906 21-40-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34218, current rewards: -8.31821, mean: -0.01172
[32m[0906 21-41-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34293, current rewards: -22.02356, mean: -0.02898
[32m[0906 21-41-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34358, current rewards: -15.82573, mean: -0.01954
[32m[0906 21-41-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34410, current rewards: -9.42363, mean: -0.01096
[32m[0906 21-41-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34452, current rewards: -2.91864, mean: -0.00321
[32m[0906 21-42-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34498, current rewards: -39.24508, mean: -0.04088
[32m[0906 21-42-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34537, current rewards: -32.45507, mean: -0.03213
[32m[0906 21-42-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34577, current rewards: -25.31244, mean: -0.02388
[32m[0906 21-43-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34612, current rewards: -18.16253, mean: -0.01636
[32m[0906 21-43-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34639, current rewards: -11.02001, mean: -0.00950
[32m[0906 21-43-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34662, current rewards: -3.90409, mean: -0.00323
[32m[0906 21-44-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34689, current rewards: 3.08016, mean: 0.00244
[32m[0906 21-44-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34709, current rewards: 10.24257, mean: 0.00782
[32m[0906 21-44-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34727, current rewards: 17.41490, mean: 0.01281
[32m[0906 21-44-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34746, current rewards: -18.87984, mean: -0.01339
[32m[0906 21-45-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34762, current rewards: -13.64614, mean: -0.00935
[32m[0906 21-45-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34780, current rewards: -8.38559, mean: -0.00555
[32m[0906 21-45-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34793, current rewards: -3.08882, mean: -0.00198
[32m[0906 21-46-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34809, current rewards: 2.19632, mean: 0.00136
[32m[0906 21-46-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34826, current rewards: -13.72355, mean: -0.00827
[32m[0906 21-46-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34840, current rewards: -66.60787, mean: -0.03895
[32m[0906 21-46-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34853, current rewards: -91.44842, mean: -0.05196
[32m[0906 21-47-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34860, current rewards: -128.37238, mean: -0.07092
[32m[0906 21-47-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34869, current rewards: -148.98136, mean: -0.08010
[32m[0906 21-47-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34878, current rewards: -159.16992, mean: -0.08334
[32m[0906 21-48-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34886, current rewards: -173.38759, mean: -0.08846
[32m[0906 21-48-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34893, current rewards: -173.99256, mean: -0.08656
[32m[0906 21-48-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34903, current rewards: -213.81519, mean: -0.10379
[32m[0906 21-49-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34911, current rewards: -236.45270, mean: -0.11206
[32m[0906 21-49-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34917, current rewards: -273.82793, mean: -0.12677
[32m[0906 21-49-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34922, current rewards: -302.96687, mean: -0.13709
[32m[0906 21-49-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34930, current rewards: -329.39986, mean: -0.14575
[32m[0906 21-50-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34932, current rewards: -369.52465, mean: -0.15997
[32m[0906 21-50-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34937, current rewards: -394.11639, mean: -0.16700
[32m[0906 21-50-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34944, current rewards: -427.21062, mean: -0.17727
[32m[0906 21-51-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34952, current rewards: -472.04866, mean: -0.19189
[32m[0906 21-51-18 @Agent.py:117][0m Average action selection time: 0.3496
[32m[0906 21-51-18 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-51-18 @MBExp.py:227][0m Rewards obtained: [-468.0920403880189], Lows: [352], Highs: [84], Total time: 28341.242631999998
[32m[0906 21-52-31 @MBExp.py:144][0m ####################################################################
[32m[0906 21-52-31 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 21-52-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33347, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-52-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33290, current rewards: -53.62444, mean: -0.89374
[32m[0906 21-53-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33280, current rewards: -103.62444, mean: -0.94204
[32m[0906 21-53-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32949, current rewards: -153.62444, mean: -0.96015
[32m[0906 21-53-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32987, current rewards: -203.62444, mean: -0.96964
[32m[0906 21-53-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33267, current rewards: -253.62444, mean: -0.97548
[32m[0906 21-54-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33444, current rewards: -303.62444, mean: -0.97943
[32m[0906 21-54-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33667, current rewards: -353.62444, mean: -0.98229
[32m[0906 21-54-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33867, current rewards: -403.62444, mean: -0.98445
[32m[0906 21-55-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34000, current rewards: -453.62444, mean: -0.98614
[32m[0906 21-55-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34045, current rewards: -503.62444, mean: -0.98750
[32m[0906 21-55-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34086, current rewards: -517.27308, mean: -0.92370
[32m[0906 21-55-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34111, current rewards: -512.53760, mean: -0.84023
[32m[0906 21-56-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34128, current rewards: -507.75678, mean: -0.76933
[32m[0906 21-56-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34204, current rewards: -502.97850, mean: -0.70842
[32m[0906 21-56-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34284, current rewards: -498.19600, mean: -0.65552
[32m[0906 21-57-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34351, current rewards: -530.10100, mean: -0.65445
[32m[0906 21-57-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34407, current rewards: -570.39818, mean: -0.66325
[32m[0906 21-57-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34453, current rewards: -595.23930, mean: -0.65411
[32m[0906 21-58-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34495, current rewards: -618.38610, mean: -0.64415
[32m[0906 21-58-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34534, current rewards: -644.60047, mean: -0.63822
[32m[0906 21-58-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34571, current rewards: -666.77289, mean: -0.62903
[32m[0906 21-58-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34599, current rewards: -705.14404, mean: -0.63526
[32m[0906 21-59-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34629, current rewards: -714.15907, mean: -0.61565
[32m[0906 21-59-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34653, current rewards: -739.01316, mean: -0.61075
[32m[0906 21-59-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34676, current rewards: -780.93372, mean: -0.61979
[32m[0906 22-00-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34698, current rewards: -801.15996, mean: -0.61157
[32m[0906 22-00-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34710, current rewards: -828.72584, mean: -0.60936
[32m[0906 22-00-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34723, current rewards: -860.45074, mean: -0.61025
[32m[0906 22-00-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34738, current rewards: -895.26237, mean: -0.61319
[32m[0906 22-01-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34753, current rewards: -925.70224, mean: -0.61305
[32m[0906 22-01-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34766, current rewards: -962.61505, mean: -0.61706
[32m[0906 22-01-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34782, current rewards: -993.46406, mean: -0.61706
[32m[0906 22-02-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34794, current rewards: -1022.92684, mean: -0.61622
[32m[0906 22-02-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34801, current rewards: -1057.68426, mean: -0.61853
[32m[0906 22-02-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34808, current rewards: -1086.96890, mean: -0.61760
[32m[0906 22-03-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34816, current rewards: -1119.58682, mean: -0.61856
[32m[0906 22-03-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34823, current rewards: -1162.15538, mean: -0.62481
[32m[0906 22-03-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34835, current rewards: -1212.15538, mean: -0.63464
[32m[0906 22-03-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34845, current rewards: -1262.15538, mean: -0.64396
[32m[0906 22-04-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34850, current rewards: -1312.15538, mean: -0.65281
[32m[0906 22-04-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34856, current rewards: -1362.15538, mean: -0.66124
[32m[0906 22-04-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34862, current rewards: -1403.60435, mean: -0.66522
[32m[0906 22-05-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34867, current rewards: -1448.07295, mean: -0.67040
[32m[0906 22-05-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34875, current rewards: -1478.89845, mean: -0.66918
[32m[0906 22-05-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34881, current rewards: -1525.70096, mean: -0.67509
[32m[0906 22-05-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34886, current rewards: -1557.64946, mean: -0.67431
[32m[0906 22-06-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34891, current rewards: -1600.16876, mean: -0.67804
[32m[0906 22-06-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34897, current rewards: -1650.09705, mean: -0.68469
[32m[0906 22-06-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34900, current rewards: -1693.59024, mean: -0.68845
[32m[0906 22-07-04 @Agent.py:117][0m Average action selection time: 0.3490
[32m[0906 22-07-04 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-07-04 @MBExp.py:227][0m Rewards obtained: [-1729.3233586995207], Lows: [30], Highs: [1736], Total time: 29214.499753999997
[32m[0906 22-08-19 @MBExp.py:144][0m ####################################################################
[32m[0906 22-08-19 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 22-08-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33261, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-08-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33258, current rewards: -21.54205, mean: -0.35903
[32m[0906 22-08-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33190, current rewards: -14.14803, mean: -0.12862
[32m[0906 22-09-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32871, current rewards: -6.86276, mean: -0.04289
[32m[0906 22-09-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32906, current rewards: 0.42015, mean: 0.00200
[32m[0906 22-09-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33194, current rewards: 7.70331, mean: 0.02963
[32m[0906 22-10-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33404, current rewards: 14.98890, mean: 0.04835
[32m[0906 22-10-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33628, current rewards: 22.26957, mean: 0.06186
[32m[0906 22-10-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33828, current rewards: 29.14126, mean: 0.07108
[32m[0906 22-10-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33971, current rewards: 36.47130, mean: 0.07929
[32m[0906 22-11-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34021, current rewards: 43.77356, mean: 0.08583
[32m[0906 22-11-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34059, current rewards: 51.06295, mean: 0.09118
[32m[0906 22-11-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34089, current rewards: 58.35920, mean: 0.09567
[32m[0906 22-12-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34105, current rewards: 65.65570, mean: 0.09948
[32m[0906 22-12-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34174, current rewards: 72.95670, mean: 0.10276
[32m[0906 22-12-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34243, current rewards: 80.25213, mean: 0.10559
[32m[0906 22-12-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34307, current rewards: 68.37527, mean: 0.08441
[32m[0906 22-13-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34364, current rewards: 75.20320, mean: 0.08745
[32m[0906 22-13-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34411, current rewards: 59.41611, mean: 0.06529
[32m[0906 22-13-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34453, current rewards: 66.32747, mean: 0.06909
[32m[0906 22-14-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34496, current rewards: 73.36383, mean: 0.07264
[32m[0906 22-14-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34534, current rewards: 80.40248, mean: 0.07585
[32m[0906 22-14-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34568, current rewards: 87.43901, mean: 0.07877
[32m[0906 22-15-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34595, current rewards: 94.47682, mean: 0.08145
[32m[0906 22-15-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34621, current rewards: 101.50682, mean: 0.08389
[32m[0906 22-15-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34644, current rewards: 108.55240, mean: 0.08615
[32m[0906 22-15-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34665, current rewards: 115.58740, mean: 0.08823
[32m[0906 22-16-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34682, current rewards: 81.50975, mean: 0.05993
[32m[0906 22-16-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34698, current rewards: 88.01753, mean: 0.06242
[32m[0906 22-16-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34716, current rewards: 94.37846, mean: 0.06464
[32m[0906 22-17-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34729, current rewards: 100.74656, mean: 0.06672
[32m[0906 22-17-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34745, current rewards: 107.11483, mean: 0.06866
[32m[0906 22-17-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34756, current rewards: 116.34318, mean: 0.07226
[32m[0906 22-17-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34769, current rewards: 129.03534, mean: 0.07773
[32m[0906 22-18-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34784, current rewards: 99.55413, mean: 0.05822
[32m[0906 22-18-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34797, current rewards: 102.32154, mean: 0.05814
[32m[0906 22-18-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34809, current rewards: 109.47030, mean: 0.06048
[32m[0906 22-19-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34816, current rewards: 116.58717, mean: 0.06268
[32m[0906 22-19-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34824, current rewards: 123.70453, mean: 0.06477
[32m[0906 22-19-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34834, current rewards: 130.82121, mean: 0.06675
[32m[0906 22-20-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34841, current rewards: 137.93867, mean: 0.06863
[32m[0906 22-20-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34852, current rewards: 138.45921, mean: 0.06721
[32m[0906 22-20-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34857, current rewards: 124.40787, mean: 0.05896
[32m[0906 22-20-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34862, current rewards: 131.16102, mean: 0.06072
[32m[0906 22-21-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34868, current rewards: 137.93865, mean: 0.06242
[32m[0906 22-21-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34875, current rewards: 144.71393, mean: 0.06403
[32m[0906 22-21-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34881, current rewards: 151.48959, mean: 0.06558
[32m[0906 22-22-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34887, current rewards: 158.26437, mean: 0.06706
[32m[0906 22-22-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34892, current rewards: 165.04048, mean: 0.06848
[32m[0906 22-22-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34897, current rewards: 173.89509, mean: 0.07069
[32m[0906 22-22-52 @Agent.py:117][0m Average action selection time: 0.3490
[32m[0906 22-22-52 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-22-52 @MBExp.py:227][0m Rewards obtained: [179.17429128113005], Lows: [51], Highs: [66], Total time: 30087.678089999998
[32m[0906 22-24-09 @MBExp.py:144][0m ####################################################################
[32m[0906 22-24-09 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 22-24-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33386, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-24-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33343, current rewards: -14.94952, mean: -0.24916
[32m[0906 22-24-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33179, current rewards: -8.80180, mean: -0.08002
[32m[0906 22-25-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32876, current rewards: -2.09108, mean: -0.01307
[32m[0906 22-25-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32907, current rewards: 3.62780, mean: 0.01728
[32m[0906 22-25-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33192, current rewards: 10.16100, mean: 0.03908
[32m[0906 22-25-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33394, current rewards: 15.99820, mean: 0.05161
[32m[0906 22-26-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33624, current rewards: 22.23120, mean: 0.06175
[32m[0906 22-26-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33835, current rewards: -37.30514, mean: -0.09099
[32m[0906 22-26-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33977, current rewards: -44.24242, mean: -0.09618
[32m[0906 22-27-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34020, current rewards: -36.58734, mean: -0.07174
[32m[0906 22-27-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34057, current rewards: -28.93225, mean: -0.05166
[32m[0906 22-27-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34088, current rewards: -21.27717, mean: -0.03488
[32m[0906 22-27-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34117, current rewards: -21.69380, mean: -0.03287
[32m[0906 22-28-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34185, current rewards: -71.69380, mean: -0.10098
[32m[0906 22-28-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34264, current rewards: -121.69380, mean: -0.16012
[32m[0906 22-28-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34325, current rewards: -171.69380, mean: -0.21197
[32m[0906 22-29-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34382, current rewards: -221.69380, mean: -0.25778
[32m[0906 22-29-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34435, current rewards: -271.69380, mean: -0.29856
[32m[0906 22-29-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34481, current rewards: -321.69380, mean: -0.33510
[32m[0906 22-29-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34523, current rewards: -371.69380, mean: -0.36801
[32m[0906 22-30-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34561, current rewards: -421.69380, mean: -0.39782
[32m[0906 22-30-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34591, current rewards: -471.69380, mean: -0.42495
[32m[0906 22-30-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34618, current rewards: -521.69380, mean: -0.44974
[32m[0906 22-31-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34643, current rewards: -571.69380, mean: -0.47247
[32m[0906 22-31-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34665, current rewards: -621.69380, mean: -0.49341
[32m[0906 22-31-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34687, current rewards: -671.69380, mean: -0.51274
[32m[0906 22-32-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34707, current rewards: -721.69380, mean: -0.53066
[32m[0906 22-32-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34732, current rewards: -771.69380, mean: -0.54730
[32m[0906 22-32-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34750, current rewards: -821.69380, mean: -0.56280
[32m[0906 22-32-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34766, current rewards: -871.69380, mean: -0.57728
[32m[0906 22-33-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34782, current rewards: -921.69380, mean: -0.59083
[32m[0906 22-33-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34798, current rewards: -971.69380, mean: -0.60354
[32m[0906 22-33-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34809, current rewards: -1021.69380, mean: -0.61548
[32m[0906 22-34-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34823, current rewards: -1071.69380, mean: -0.62672
[32m[0906 22-34-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34835, current rewards: -1121.69380, mean: -0.63733
[32m[0906 22-34-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34844, current rewards: -1171.69380, mean: -0.64734
[32m[0906 22-34-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34853, current rewards: -1221.69380, mean: -0.65682
[32m[0906 22-35-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34863, current rewards: -1271.69380, mean: -0.66581
[32m[0906 22-35-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34871, current rewards: -1321.69380, mean: -0.67433
[32m[0906 22-35-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34881, current rewards: -1371.69380, mean: -0.68243
[32m[0906 22-36-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34889, current rewards: -1421.69380, mean: -0.69014
[32m[0906 22-36-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34897, current rewards: -1471.69380, mean: -0.69749
[32m[0906 22-36-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34903, current rewards: -1521.69380, mean: -0.70449
[32m[0906 22-37-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34911, current rewards: -1571.69380, mean: -0.71117
[32m[0906 22-37-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34917, current rewards: -1621.69380, mean: -0.71756
[32m[0906 22-37-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34923, current rewards: -1671.69380, mean: -0.72368
[32m[0906 22-37-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34929, current rewards: -1721.69380, mean: -0.72953
[32m[0906 22-38-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34932, current rewards: -1771.69380, mean: -0.73514
[32m[0906 22-38-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34936, current rewards: -1821.69380, mean: -0.74053
[32m[0906 22-38-43 @Agent.py:117][0m Average action selection time: 0.3494
[32m[0906 22-38-43 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-38-43 @MBExp.py:227][0m Rewards obtained: [-1861.693803479659], Lows: [39], Highs: [1868], Total time: 30961.826973999996
[32m[0906 22-40-01 @MBExp.py:144][0m ####################################################################
[32m[0906 22-40-01 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 22-40-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33383, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-40-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33409, current rewards: -16.27065, mean: -0.27118
[32m[0906 22-40-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33148, current rewards: -8.54671, mean: -0.07770
[32m[0906 22-40-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32877, current rewards: -0.85734, mean: -0.00536
[32m[0906 22-41-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32911, current rewards: 6.83310, mean: 0.03254
[32m[0906 22-41-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33197, current rewards: 14.51647, mean: 0.05583
[32m[0906 22-41-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33390, current rewards: 22.20591, mean: 0.07163
[32m[0906 22-42-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33651, current rewards: 29.90087, mean: 0.08306
[32m[0906 22-42-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33844, current rewards: 37.59259, mean: 0.09169
[32m[0906 22-42-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33975, current rewards: 45.28119, mean: 0.09844
[32m[0906 22-42-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34023, current rewards: 44.89269, mean: 0.08802
[32m[0906 22-43-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34055, current rewards: 16.24444, mean: 0.02901
[32m[0906 22-43-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34081, current rewards: 23.10628, mean: 0.03788
[32m[0906 22-43-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34104, current rewards: 29.68364, mean: 0.04498
[32m[0906 22-44-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34159, current rewards: 36.23514, mean: 0.05104
[32m[0906 22-44-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34231, current rewards: 43.19344, mean: 0.05683
[32m[0906 22-44-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34302, current rewards: 55.35851, mean: 0.06834
[32m[0906 22-44-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34361, current rewards: 61.54585, mean: 0.07156
[32m[0906 22-45-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34399, current rewards: 67.74829, mean: 0.07445
[32m[0906 22-45-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34432, current rewards: 73.94120, mean: 0.07702
[32m[0906 22-45-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34468, current rewards: 80.13094, mean: 0.07934
[32m[0906 22-46-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34500, current rewards: 86.33345, mean: 0.08145
[32m[0906 22-46-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34529, current rewards: 50.57972, mean: 0.04557
[32m[0906 22-46-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34554, current rewards: 55.89157, mean: 0.04818
[32m[0906 22-47-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34578, current rewards: 61.43316, mean: 0.05077
[32m[0906 22-47-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34603, current rewards: 66.59391, mean: 0.05285
[32m[0906 22-47-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34624, current rewards: 71.74853, mean: 0.05477
[32m[0906 22-47-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34641, current rewards: 76.90742, mean: 0.05655
[32m[0906 22-48-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34659, current rewards: 82.06117, mean: 0.05820
[32m[0906 22-48-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34675, current rewards: 87.21726, mean: 0.05974
[32m[0906 22-48-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34691, current rewards: 62.92927, mean: 0.04168
[32m[0906 22-49-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34706, current rewards: 56.74723, mean: 0.03638
[32m[0906 22-49-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34719, current rewards: 61.80979, mean: 0.03839
[32m[0906 22-49-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34734, current rewards: 70.10764, mean: 0.04223
[32m[0906 22-49-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34745, current rewards: 80.54736, mean: 0.04710
[32m[0906 22-50-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34757, current rewards: 90.98857, mean: 0.05170
[32m[0906 22-50-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34768, current rewards: 101.42589, mean: 0.05604
[32m[0906 22-50-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34779, current rewards: 111.85730, mean: 0.06014
[32m[0906 22-51-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34787, current rewards: 122.30545, mean: 0.06403
[32m[0906 22-51-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34795, current rewards: 132.73550, mean: 0.06772
[32m[0906 22-51-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34805, current rewards: 108.01999, mean: 0.05374
[32m[0906 22-51-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34812, current rewards: 114.56926, mean: 0.05562
[32m[0906 22-52-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34819, current rewards: 80.88442, mean: 0.03833
[32m[0906 22-52-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34827, current rewards: 84.49637, mean: 0.03912
[32m[0906 22-52-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34836, current rewards: 91.55865, mean: 0.04143
[32m[0906 22-53-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34844, current rewards: 98.61164, mean: 0.04363
[32m[0906 22-53-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34854, current rewards: 105.65550, mean: 0.04574
[32m[0906 22-53-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34859, current rewards: 112.69952, mean: 0.04775
[32m[0906 22-54-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34864, current rewards: 118.80494, mean: 0.04930
[32m[0906 22-54-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34871, current rewards: 124.53500, mean: 0.05062
[32m[0906 22-54-34 @Agent.py:117][0m Average action selection time: 0.3488
[32m[0906 22-54-34 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-54-34 @MBExp.py:227][0m Rewards obtained: [130.7989843535366], Lows: [90], Highs: [41], Total time: 31834.423964999994
[32m[0906 22-55-55 @MBExp.py:144][0m ####################################################################
[32m[0906 22-55-55 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 22-55-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33366, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-56-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33363, current rewards: -16.32628, mean: -0.27210
[32m[0906 22-56-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33076, current rewards: -12.44305, mean: -0.11312
[32m[0906 22-56-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32816, current rewards: -8.61070, mean: -0.05382
[32m[0906 22-57-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32877, current rewards: -4.79261, mean: -0.02282
[32m[0906 22-57-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33145, current rewards: -0.97337, mean: -0.00374
[32m[0906 22-57-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33355, current rewards: 2.84909, mean: 0.00919
[32m[0906 22-57-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33610, current rewards: 8.57190, mean: 0.02381
[32m[0906 22-58-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33804, current rewards: 15.05582, mean: 0.03672
[32m[0906 22-58-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33934, current rewards: 20.00614, mean: 0.04349
[32m[0906 22-58-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33983, current rewards: 24.97497, mean: 0.04897
[32m[0906 22-59-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34017, current rewards: 29.94007, mean: 0.05346
[32m[0906 22-59-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34049, current rewards: 34.90438, mean: 0.05722
[32m[0906 22-59-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34073, current rewards: 39.86833, mean: 0.06041
[32m[0906 22-59-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34124, current rewards: 38.53878, mean: 0.05428
[32m[0906 23-00-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34202, current rewards: 8.43479, mean: 0.01110
[32m[0906 23-00-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34270, current rewards: 14.03410, mean: 0.01733
[32m[0906 23-00-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34330, current rewards: 19.60857, mean: 0.02280
[32m[0906 23-01-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34376, current rewards: 25.18407, mean: 0.02767
[32m[0906 23-01-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34424, current rewards: -11.21205, mean: -0.01168
[32m[0906 23-01-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34459, current rewards: -2.77538, mean: -0.00275
[32m[0906 23-02-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34494, current rewards: 5.08416, mean: 0.00480
[32m[0906 23-02-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34533, current rewards: 12.94370, mean: 0.01166
[32m[0906 23-02-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34558, current rewards: 19.16793, mean: 0.01652
[32m[0906 23-02-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34585, current rewards: -25.52027, mean: -0.02109
[32m[0906 23-03-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34610, current rewards: -75.52027, mean: -0.05994
[32m[0906 23-03-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34633, current rewards: -125.52027, mean: -0.09582
[32m[0906 23-03-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34654, current rewards: -175.52027, mean: -0.12906
[32m[0906 23-04-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34680, current rewards: -225.52027, mean: -0.15994
[32m[0906 23-04-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34701, current rewards: -275.52027, mean: -0.18871
[32m[0906 23-04-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34717, current rewards: -325.52027, mean: -0.21558
[32m[0906 23-04-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34734, current rewards: -375.52027, mean: -0.24072
[32m[0906 23-05-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34753, current rewards: -384.64774, mean: -0.23891
[32m[0906 23-05-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34768, current rewards: -382.24707, mean: -0.23027
[32m[0906 23-05-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34778, current rewards: -379.84639, mean: -0.22213
[32m[0906 23-06-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34791, current rewards: -377.44571, mean: -0.21446
[32m[0906 23-06-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34800, current rewards: -375.04504, mean: -0.20721
[32m[0906 23-06-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34810, current rewards: -372.64436, mean: -0.20035
[32m[0906 23-07-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34820, current rewards: -370.24369, mean: -0.19384
[32m[0906 23-07-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34828, current rewards: -369.93904, mean: -0.18874
[32m[0906 23-07-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34839, current rewards: -419.93904, mean: -0.20892
[32m[0906 23-07-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34846, current rewards: -469.93904, mean: -0.22813
[32m[0906 23-08-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34852, current rewards: -519.93904, mean: -0.24642
[32m[0906 23-08-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34860, current rewards: -569.93904, mean: -0.26386
[32m[0906 23-08-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34865, current rewards: -619.93904, mean: -0.28052
[32m[0906 23-09-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34871, current rewards: -669.93904, mean: -0.29643
[32m[0906 23-09-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34879, current rewards: -719.93904, mean: -0.31166
[32m[0906 23-09-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34885, current rewards: -769.93904, mean: -0.32625
[32m[0906 23-09-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34888, current rewards: -819.93904, mean: -0.34022
[32m[0906 23-10-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34893, current rewards: -832.75639, mean: -0.33852
[32m[0906 23-10-28 @Agent.py:117][0m Average action selection time: 0.3490
[32m[0906 23-10-28 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-10-28 @MBExp.py:227][0m Rewards obtained: [-830.261930717794], Lows: [40], Highs: [893], Total time: 32707.526388999995
[32m[0906 23-11-51 @MBExp.py:144][0m ####################################################################
[32m[0906 23-11-51 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 23-11-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33207, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-12-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33248, current rewards: -17.79318, mean: -0.29655
[32m[0906 23-12-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32977, current rewards: -12.73816, mean: -0.11580
[32m[0906 23-12-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32721, current rewards: -7.69140, mean: -0.04807
[32m[0906 23-13-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32774, current rewards: -2.64124, mean: -0.01258
[32m[0906 23-13-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33049, current rewards: -40.55209, mean: -0.15597
[32m[0906 23-13-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33273, current rewards: -34.44296, mean: -0.11111
[32m[0906 23-13-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33528, current rewards: -30.26721, mean: -0.08408
[32m[0906 23-14-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33747, current rewards: -24.70629, mean: -0.06026
[32m[0906 23-14-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33891, current rewards: -19.14766, mean: -0.04163
[32m[0906 23-14-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33946, current rewards: -13.58989, mean: -0.02665
[32m[0906 23-15-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33984, current rewards: -8.02945, mean: -0.01434
[32m[0906 23-15-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34019, current rewards: -2.46832, mean: -0.00405
[32m[0906 23-15-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34045, current rewards: 3.08732, mean: 0.00468
[32m[0906 23-15-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34091, current rewards: 5.31719, mean: 0.00749
[32m[0906 23-16-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34171, current rewards: -6.98701, mean: -0.00919
[32m[0906 23-16-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34240, current rewards: -1.65244, mean: -0.00204
[32m[0906 23-16-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34302, current rewards: 3.64661, mean: 0.00424
[32m[0906 23-17-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34356, current rewards: 8.93546, mean: 0.00982
[32m[0906 23-17-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34403, current rewards: 14.22495, mean: 0.01482
[32m[0906 23-17-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34444, current rewards: 19.52604, mean: 0.01933
[32m[0906 23-17-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34485, current rewards: 24.81966, mean: 0.02341
[32m[0906 23-18-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34520, current rewards: 7.88390, mean: 0.00710
[32m[0906 23-18-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34554, current rewards: -1.59705, mean: -0.00138
[32m[0906 23-18-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34579, current rewards: -0.68308, mean: -0.00056
[32m[0906 23-19-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34604, current rewards: 3.95037, mean: 0.00314
[32m[0906 23-19-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34621, current rewards: 8.59875, mean: 0.00656
[32m[0906 23-19-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34640, current rewards: 13.26044, mean: 0.00975
[32m[0906 23-20-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34664, current rewards: 17.92491, mean: 0.01271
[32m[0906 23-20-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34683, current rewards: 22.58764, mean: 0.01547
[32m[0906 23-20-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34704, current rewards: 27.23866, mean: 0.01804
[32m[0906 23-20-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34723, current rewards: 31.89775, mean: 0.02045
[32m[0906 23-21-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34738, current rewards: 36.62596, mean: 0.02275
[32m[0906 23-21-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34755, current rewards: 41.23695, mean: 0.02484
[32m[0906 23-21-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34766, current rewards: 39.57853, mean: 0.02315
[32m[0906 23-22-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34780, current rewards: 7.97042, mean: 0.00453
[32m[0906 23-22-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34792, current rewards: 12.03352, mean: 0.00665
[32m[0906 23-22-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34799, current rewards: 16.11621, mean: 0.00866
[32m[0906 23-22-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34810, current rewards: 20.19956, mean: 0.01058
[32m[0906 23-23-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34821, current rewards: 24.28083, mean: 0.01239
[32m[0906 23-23-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34830, current rewards: 31.85270, mean: 0.01585
[32m[0906 23-23-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34835, current rewards: 36.44280, mean: 0.01769
[32m[0906 23-24-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34842, current rewards: 41.03117, mean: 0.01945
[32m[0906 23-24-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34850, current rewards: 45.61970, mean: 0.02112
[32m[0906 23-24-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34857, current rewards: 50.20564, mean: 0.02272
[32m[0906 23-24-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34861, current rewards: 54.79161, mean: 0.02424
[32m[0906 23-25-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34868, current rewards: 59.37893, mean: 0.02571
[32m[0906 23-25-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34874, current rewards: 21.21921, mean: 0.00899
[32m[0906 23-25-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34879, current rewards: 26.37283, mean: 0.01094
[32m[0906 23-26-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34886, current rewards: 33.00492, mean: 0.01342
[32m[0906 23-26-24 @Agent.py:117][0m Average action selection time: 0.3489
[32m[0906 23-26-24 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-26-24 @MBExp.py:227][0m Rewards obtained: [38.33136333303521], Lows: [71], Highs: [65], Total time: 33580.520121999994
[32m[0906 23-27-49 @MBExp.py:144][0m ####################################################################
[32m[0906 23-27-49 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 23-27-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33072, current rewards: -1.56603, mean: -0.15660
[32m[0906 23-28-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33312, current rewards: 4.94517, mean: 0.08242
[32m[0906 23-28-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32931, current rewards: 11.64791, mean: 0.10589
[32m[0906 23-28-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32704, current rewards: 18.33242, mean: 0.11458
[32m[0906 23-28-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32751, current rewards: 25.02190, mean: 0.11915
[32m[0906 23-29-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33002, current rewards: 31.70590, mean: 0.12195
[32m[0906 23-29-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33231, current rewards: 37.71909, mean: 0.12167
[32m[0906 23-29-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33485, current rewards: 43.51700, mean: 0.12088
[32m[0906 23-30-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33708, current rewards: 49.87806, mean: 0.12165
[32m[0906 23-30-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33861, current rewards: 56.23624, mean: 0.12225
[32m[0906 23-30-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33908, current rewards: 49.06752, mean: 0.09621
[32m[0906 23-30-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33950, current rewards: 42.86339, mean: 0.07654
[32m[0906 23-31-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33988, current rewards: 44.36625, mean: 0.07273
[32m[0906 23-31-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34020, current rewards: 46.98084, mean: 0.07118
[32m[0906 23-31-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34072, current rewards: 48.55864, mean: 0.06839
[32m[0906 23-32-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34158, current rewards: 55.48931, mean: 0.07301
[32m[0906 23-32-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34234, current rewards: 61.47156, mean: 0.07589
[32m[0906 23-32-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34297, current rewards: 67.42782, mean: 0.07840
[32m[0906 23-33-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34348, current rewards: 73.38916, mean: 0.08065
[32m[0906 23-33-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34397, current rewards: 79.32512, mean: 0.08263
[32m[0906 23-33-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34445, current rewards: 42.89571, mean: 0.04247
[32m[0906 23-33-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34481, current rewards: 45.83574, mean: 0.04324
[32m[0906 23-34-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34518, current rewards: 51.26661, mean: 0.04619
[32m[0906 23-34-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34550, current rewards: 55.32021, mean: 0.04769
[32m[0906 23-34-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34576, current rewards: 59.74287, mean: 0.04937
[32m[0906 23-35-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34605, current rewards: 64.18053, mean: 0.05094
[32m[0906 23-35-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34628, current rewards: 68.61659, mean: 0.05238
[32m[0906 23-35-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34651, current rewards: 73.05273, mean: 0.05372
[32m[0906 23-35-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34671, current rewards: 41.97910, mean: 0.02977
[32m[0906 23-36-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34686, current rewards: 40.00654, mean: 0.02740
[32m[0906 23-36-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34700, current rewards: 45.38982, mean: 0.03006
[32m[0906 23-36-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34718, current rewards: 50.50050, mean: 0.03237
[32m[0906 23-37-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34733, current rewards: 55.78424, mean: 0.03465
[32m[0906 23-37-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34746, current rewards: 61.05286, mean: 0.03678
[32m[0906 23-37-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34764, current rewards: 66.32526, mean: 0.03879
[32m[0906 23-38-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34775, current rewards: 71.59858, mean: 0.04068
[32m[0906 23-38-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34787, current rewards: 76.86529, mean: 0.04247
[32m[0906 23-38-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34802, current rewards: 82.13550, mean: 0.04416
[32m[0906 23-38-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34813, current rewards: 87.40360, mean: 0.04576
[32m[0906 23-39-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34823, current rewards: 97.17017, mean: 0.04958
[32m[0906 23-39-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34833, current rewards: 102.97934, mean: 0.05123
[32m[0906 23-39-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34842, current rewards: 108.93002, mean: 0.05288
[32m[0906 23-40-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34850, current rewards: 102.56702, mean: 0.04861
[32m[0906 23-40-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34857, current rewards: 83.48922, mean: 0.03865
[32m[0906 23-40-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34866, current rewards: 61.97280, mean: 0.02804
[32m[0906 23-40-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34871, current rewards: 57.93059, mean: 0.02563
[32m[0906 23-41-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34880, current rewards: 57.20413, mean: 0.02476
[32m[0906 23-41-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34894, current rewards: 46.66268, mean: 0.01977
[32m[0906 23-41-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34899, current rewards: 45.22574, mean: 0.01877
[32m[0906 23-42-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34904, current rewards: 35.03523, mean: 0.01424
[32m[0906 23-42-22 @Agent.py:117][0m Average action selection time: 0.3491
[32m[0906 23-42-22 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-42-22 @MBExp.py:227][0m Rewards obtained: [26.367867164632695], Lows: [40], Highs: [148], Total time: 34453.92224299999
[32m[0906 23-43-49 @MBExp.py:144][0m ####################################################################
[32m[0906 23-43-49 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 23-43-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33280, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-44-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33277, current rewards: -14.21621, mean: -0.23694
[32m[0906 23-44-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32866, current rewards: -8.41263, mean: -0.07648
[32m[0906 23-44-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32655, current rewards: -2.61307, mean: -0.01633
[32m[0906 23-44-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32708, current rewards: 3.18552, mean: 0.01517
[32m[0906 23-45-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32961, current rewards: 8.77303, mean: 0.03374
[32m[0906 23-45-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33185, current rewards: 13.66655, mean: 0.04409
[32m[0906 23-45-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33447, current rewards: 19.20146, mean: 0.05334
[32m[0906 23-46-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33674, current rewards: 24.73489, mean: 0.06033
[32m[0906 23-46-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33816, current rewards: 30.27112, mean: 0.06581
[32m[0906 23-46-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33874, current rewards: -6.62823, mean: -0.01300
[32m[0906 23-46-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33923, current rewards: -1.53765, mean: -0.00275
[32m[0906 23-47-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33960, current rewards: 2.93361, mean: 0.00481
[32m[0906 23-47-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33999, current rewards: 7.40559, mean: 0.01122
[32m[0906 23-47-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34037, current rewards: 13.43659, mean: 0.01892
[32m[0906 23-48-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34124, current rewards: 17.92395, mean: 0.02358
[32m[0906 23-48-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34203, current rewards: 22.49598, mean: 0.02777
[32m[0906 23-48-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34267, current rewards: 27.07005, mean: 0.03148
[32m[0906 23-49-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34324, current rewards: 31.64425, mean: 0.03477
[32m[0906 23-49-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34375, current rewards: 36.21675, mean: 0.03773
[32m[0906 23-49-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34426, current rewards: 40.79146, mean: 0.04039
[32m[0906 23-49-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34473, current rewards: 45.36732, mean: 0.04280
[32m[0906 23-50-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34513, current rewards: 6.39292, mean: 0.00576
[32m[0906 23-50-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34549, current rewards: 14.23514, mean: 0.01227
[32m[0906 23-50-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34579, current rewards: 19.57559, mean: 0.01618
[32m[0906 23-51-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34606, current rewards: 24.86281, mean: 0.01973
[32m[0906 23-51-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34631, current rewards: 30.15166, mean: 0.02302
[32m[0906 23-51-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34653, current rewards: 35.44320, mean: 0.02606
[32m[0906 23-51-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34677, current rewards: 40.73356, mean: 0.02889
[32m[0906 23-52-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34695, current rewards: 46.02147, mean: 0.03152
[32m[0906 23-52-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34712, current rewards: 43.79007, mean: 0.02900
[32m[0906 23-52-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34730, current rewards: 52.28892, mean: 0.03352
[32m[0906 23-53-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34745, current rewards: 34.44149, mean: 0.02139
[32m[0906 23-53-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34761, current rewards: 40.55168, mean: 0.02443
[32m[0906 23-53-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34775, current rewards: 44.28626, mean: 0.02590
[32m[0906 23-54-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34789, current rewards: 47.94853, mean: 0.02724
[32m[0906 23-54-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34798, current rewards: 51.60463, mean: 0.02851
[32m[0906 23-54-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34807, current rewards: 55.26089, mean: 0.02971
[32m[0906 23-54-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34818, current rewards: 58.79557, mean: 0.03078
[32m[0906 23-55-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34828, current rewards: 62.26718, mean: 0.03177
[32m[0906 23-55-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34838, current rewards: 65.85422, mean: 0.03276
[32m[0906 23-55-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34847, current rewards: 69.43988, mean: 0.03371
[32m[0906 23-56-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34854, current rewards: 73.02710, mean: 0.03461
[32m[0906 23-56-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34863, current rewards: 76.61239, mean: 0.03547
[32m[0906 23-56-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34871, current rewards: 40.67787, mean: 0.01841
[32m[0906 23-56-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34880, current rewards: 46.22339, mean: 0.02045
[32m[0906 23-57-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34885, current rewards: 51.44391, mean: 0.02227
[32m[0906 23-57-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34892, current rewards: 56.37642, mean: 0.02389
[32m[0906 23-57-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34899, current rewards: 62.17586, mean: 0.02580
[32m[0906 23-58-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34906, current rewards: 67.97497, mean: 0.02763
[32m[0906 23-58-22 @Agent.py:117][0m Average action selection time: 0.3491
[32m[0906 23-58-22 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-58-23 @MBExp.py:227][0m Rewards obtained: [72.6123997263197], Lows: [67], Highs: [41], Total time: 35327.36749799999
[32m[0906 23-59-51 @MBExp.py:144][0m ####################################################################
[32m[0906 23-59-51 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 23-59-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33071, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-00-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33246, current rewards: -25.36288, mean: -0.42271
[32m[0907 00-00-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32762, current rewards: -21.43284, mean: -0.19484
[32m[0907 00-00-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32589, current rewards: -17.50389, mean: -0.10940
[32m[0907 00-01-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32665, current rewards: -13.57632, mean: -0.06465
[32m[0907 00-01-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32939, current rewards: -10.24204, mean: -0.03939
[32m[0907 00-01-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33175, current rewards: -5.47159, mean: -0.01765
[32m[0907 00-01-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33443, current rewards: 3.37498, mean: 0.00937
[32m[0907 00-02-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33672, current rewards: 8.11074, mean: 0.01978
[32m[0907 00-02-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33802, current rewards: 12.39613, mean: 0.02695
[32m[0907 00-02-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33869, current rewards: 17.16591, mean: 0.03366
[32m[0907 00-03-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33916, current rewards: 22.00630, mean: 0.03930
[32m[0907 00-03-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33956, current rewards: 26.43708, mean: 0.04334
[32m[0907 00-03-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33986, current rewards: 32.78938, mean: 0.04968
[32m[0907 00-03-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34025, current rewards: 37.73778, mean: 0.05315
[32m[0907 00-04-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34111, current rewards: 42.08776, mean: 0.05538
[32m[0907 00-04-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34179, current rewards: 46.37652, mean: 0.05725
[32m[0907 00-04-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34241, current rewards: 50.68154, mean: 0.05893
[32m[0907 00-05-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34296, current rewards: 54.98867, mean: 0.06043
[32m[0907 00-05-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34346, current rewards: 59.29443, mean: 0.06177
[32m[0907 00-05-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34389, current rewards: 63.60123, mean: 0.06297
[32m[0907 00-05-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34431, current rewards: 67.88439, mean: 0.06404
[32m[0907 00-06-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34469, current rewards: 74.57209, mean: 0.06718
[32m[0907 00-06-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34495, current rewards: 80.70261, mean: 0.06957
[32m[0907 00-06-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34522, current rewards: 86.59996, mean: 0.07157
[32m[0907 00-07-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34549, current rewards: 92.49885, mean: 0.07341
[32m[0907 00-07-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34574, current rewards: 98.39851, mean: 0.07511
[32m[0907 00-07-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34602, current rewards: 104.29523, mean: 0.07669
[32m[0907 00-08-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34622, current rewards: 110.18958, mean: 0.07815
[32m[0907 00-08-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34645, current rewards: 116.08058, mean: 0.07951
[32m[0907 00-08-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34662, current rewards: 110.94218, mean: 0.07347
[32m[0907 00-08-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34678, current rewards: 118.12375, mean: 0.07572
[32m[0907 00-09-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34694, current rewards: 83.20436, mean: 0.05168
[32m[0907 00-09-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34709, current rewards: 89.01780, mean: 0.05363
[32m[0907 00-09-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34725, current rewards: 94.80523, mean: 0.05544
[32m[0907 00-10-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34740, current rewards: 100.60548, mean: 0.05716
[32m[0907 00-10-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34751, current rewards: 106.41055, mean: 0.05879
[32m[0907 00-10-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34761, current rewards: 112.21517, mean: 0.06033
[32m[0907 00-10-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34773, current rewards: 121.00668, mean: 0.06335
[32m[0907 00-11-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34782, current rewards: 127.02501, mean: 0.06481
[32m[0907 00-11-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34794, current rewards: 133.03980, mean: 0.06619
[32m[0907 00-11-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34803, current rewards: 139.06505, mean: 0.06751
[32m[0907 00-12-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34811, current rewards: 145.09090, mean: 0.06876
[32m[0907 00-12-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34830, current rewards: 114.38034, mean: 0.05295
[32m[0907 00-12-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34860, current rewards: 102.22220, mean: 0.04625
[32m[0907 00-13-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34868, current rewards: 106.71965, mean: 0.04722
[32m[0907 00-13-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34875, current rewards: 110.89521, mean: 0.04801
[32m[0907 00-13-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34880, current rewards: 114.26604, mean: 0.04842
[32m[0907 00-13-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34886, current rewards: 117.88756, mean: 0.04892
[32m[0907 00-14-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34892, current rewards: 121.51071, mean: 0.04939
[32m[0907 00-14-24 @Agent.py:117][0m Average action selection time: 0.3490
[32m[0907 00-14-24 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-14-24 @MBExp.py:227][0m Rewards obtained: [124.40804816991178], Lows: [46], Highs: [46], Total time: 36200.50799499999
[32m[0907 00-15-56 @MBExp.py:144][0m ####################################################################
[32m[0907 00-15-56 @MBExp.py:145][0m Starting training iteration 44.
[32m[0907 00-15-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35699, current rewards: 0.58300, mean: 0.05830
[32m[0907 00-16-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33628, current rewards: 6.90622, mean: 0.11510
[32m[0907 00-16-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33018, current rewards: 19.40213, mean: 0.17638
[32m[0907 00-16-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32777, current rewards: 32.45724, mean: 0.20286
[32m[0907 00-17-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32819, current rewards: 45.56664, mean: 0.21698
[32m[0907 00-17-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33071, current rewards: 11.82381, mean: 0.04548
[32m[0907 00-17-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33298, current rewards: 10.82118, mean: 0.03491
[32m[0907 00-17-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33566, current rewards: -6.57354, mean: -0.01826
[32m[0907 00-18-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33787, current rewards: -46.36050, mean: -0.11307
[32m[0907 00-18-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33904, current rewards: -54.77413, mean: -0.11907
[32m[0907 00-18-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33957, current rewards: -50.55282, mean: -0.09912
[32m[0907 00-19-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34000, current rewards: -46.34514, mean: -0.08276
[32m[0907 00-19-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34036, current rewards: -65.85514, mean: -0.10796
[32m[0907 00-19-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34066, current rewards: -62.61402, mean: -0.09487
[32m[0907 00-19-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34103, current rewards: -55.47423, mean: -0.07813
[32m[0907 00-20-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34190, current rewards: -46.07391, mean: -0.06062
[32m[0907 00-20-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34263, current rewards: -73.17144, mean: -0.09034
[32m[0907 00-20-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34322, current rewards: -65.20327, mean: -0.07582
[32m[0907 00-21-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34377, current rewards: -99.91047, mean: -0.10979
[32m[0907 00-21-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34425, current rewards: -94.76081, mean: -0.09871
[32m[0907 00-21-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34473, current rewards: -89.58819, mean: -0.08870
[32m[0907 00-22-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34512, current rewards: -84.10189, mean: -0.07934
[32m[0907 00-22-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34543, current rewards: -75.97987, mean: -0.06845
[32m[0907 00-22-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34574, current rewards: -70.69423, mean: -0.06094
[32m[0907 00-22-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34603, current rewards: -65.41759, mean: -0.05406
[32m[0907 00-23-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34629, current rewards: -60.13736, mean: -0.04773
[32m[0907 00-23-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34662, current rewards: -72.55046, mean: -0.05538
[32m[0907 00-23-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34681, current rewards: -74.87530, mean: -0.05506
[32m[0907 00-24-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34700, current rewards: -70.73453, mean: -0.05017
[32m[0907 00-24-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34719, current rewards: -66.59705, mean: -0.04561
[32m[0907 00-24-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34736, current rewards: -62.56147, mean: -0.04143
[32m[0907 00-24-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34751, current rewards: -58.38956, mean: -0.03743
[32m[0907 00-25-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34768, current rewards: -54.21642, mean: -0.03367
[32m[0907 00-25-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34779, current rewards: -50.04441, mean: -0.03015
[32m[0907 00-25-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34793, current rewards: -45.87124, mean: -0.02683
[32m[0907 00-26-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34805, current rewards: -41.69332, mean: -0.02369
[32m[0907 00-26-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34816, current rewards: -35.51002, mean: -0.01962
[32m[0907 00-26-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34826, current rewards: -26.86007, mean: -0.01444
[32m[0907 00-27-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34838, current rewards: -22.27249, mean: -0.01166
[32m[0907 00-27-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34847, current rewards: -17.32401, mean: -0.00884
[32m[0907 00-27-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34858, current rewards: -12.37056, mean: -0.00615
[32m[0907 00-27-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34865, current rewards: -7.41632, mean: -0.00360
[32m[0907 00-28-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34874, current rewards: -2.47423, mean: -0.00117
[32m[0907 00-28-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34880, current rewards: 2.46847, mean: 0.00114
[32m[0907 00-28-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34889, current rewards: 7.41463, mean: 0.00336
[32m[0907 00-29-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34895, current rewards: -29.20946, mean: -0.01292
[32m[0907 00-29-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34902, current rewards: -23.49835, mean: -0.01017
[32m[0907 00-29-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34909, current rewards: -18.28307, mean: -0.00775
[32m[0907 00-29-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34917, current rewards: -13.06228, mean: -0.00542
[32m[0907 00-30-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34925, current rewards: -7.84745, mean: -0.00319
[32m[0907 00-30-29 @Agent.py:117][0m Average action selection time: 0.3493
[32m[0907 00-30-29 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-30-30 @MBExp.py:227][0m Rewards obtained: [-3.6741172084332794], Lows: [127], Highs: [60], Total time: 37074.45873399999
[32m[0907 00-32-03 @MBExp.py:144][0m ####################################################################
[32m[0907 00-32-03 @MBExp.py:145][0m Starting training iteration 45.
[32m[0907 00-32-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33332, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-32-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33033, current rewards: -14.65170, mean: -0.24419
[32m[0907 00-32-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32635, current rewards: -9.44574, mean: -0.08587
[32m[0907 00-32-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32505, current rewards: -4.25654, mean: -0.02660
[32m[0907 00-33-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32476, current rewards: 0.15743, mean: 0.00075
[32m[0907 00-33-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32780, current rewards: 5.58140, mean: 0.02147
[32m[0907 00-33-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33045, current rewards: 10.91956, mean: 0.03522
[32m[0907 00-34-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33349, current rewards: 16.26109, mean: 0.04517
[32m[0907 00-34-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33592, current rewards: 15.27435, mean: 0.03725
[32m[0907 00-34-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33718, current rewards: -13.68264, mean: -0.02974
[32m[0907 00-34-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33791, current rewards: -7.77977, mean: -0.01525
[32m[0907 00-35-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33846, current rewards: -1.89026, mean: -0.00338
[32m[0907 00-35-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33898, current rewards: 6.64294, mean: 0.01089
[32m[0907 00-35-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33938, current rewards: 13.50712, mean: 0.02047
[32m[0907 00-36-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33977, current rewards: 19.31251, mean: 0.02720
[32m[0907 00-36-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34068, current rewards: 25.11108, mean: 0.03304
[32m[0907 00-36-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34151, current rewards: 30.90953, mean: 0.03816
[32m[0907 00-36-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34210, current rewards: 36.70419, mean: 0.04268
[32m[0907 00-37-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34275, current rewards: 42.50532, mean: 0.04671
[32m[0907 00-37-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34331, current rewards: 8.46488, mean: 0.00882
[32m[0907 00-37-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34386, current rewards: 20.65307, mean: 0.02045
[32m[0907 00-38-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34427, current rewards: 30.55208, mean: 0.02882
[32m[0907 00-38-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34466, current rewards: 38.85220, mean: 0.03500
[32m[0907 00-38-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34497, current rewards: 34.32630, mean: 0.02959
[32m[0907 00-39-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34528, current rewards: -15.67370, mean: -0.01295
[32m[0907 00-39-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34556, current rewards: -65.67370, mean: -0.05212
[32m[0907 00-39-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34582, current rewards: -115.67370, mean: -0.08830
[32m[0907 00-39-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34602, current rewards: -165.67370, mean: -0.12182
[32m[0907 00-40-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34623, current rewards: -215.67370, mean: -0.15296
[32m[0907 00-40-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34643, current rewards: -265.67370, mean: -0.18197
[32m[0907 00-40-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34664, current rewards: -315.67370, mean: -0.20906
[32m[0907 00-41-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34677, current rewards: -365.67370, mean: -0.23441
[32m[0907 00-41-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34691, current rewards: -415.67370, mean: -0.25818
[32m[0907 00-41-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34709, current rewards: -465.67370, mean: -0.28053
[32m[0907 00-41-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34720, current rewards: -515.67370, mean: -0.30156
[32m[0907 00-42-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34733, current rewards: -565.67370, mean: -0.32141
[32m[0907 00-42-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34749, current rewards: -615.67370, mean: -0.34015
[32m[0907 00-42-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34760, current rewards: -665.67370, mean: -0.35789
[32m[0907 00-43-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34771, current rewards: -715.67370, mean: -0.37470
[32m[0907 00-43-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34783, current rewards: -765.67370, mean: -0.39065
[32m[0907 00-43-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34791, current rewards: -815.67370, mean: -0.40581
[32m[0907 00-44-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34803, current rewards: -865.67370, mean: -0.42023
[32m[0907 00-44-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34813, current rewards: -915.67370, mean: -0.43397
[32m[0907 00-44-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34820, current rewards: -965.67370, mean: -0.44707
[32m[0907 00-44-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34829, current rewards: -1015.67370, mean: -0.45958
[32m[0907 00-45-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34834, current rewards: -1065.67370, mean: -0.47154
[32m[0907 00-45-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34842, current rewards: -1115.67370, mean: -0.48298
[32m[0907 00-45-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34847, current rewards: -1165.67370, mean: -0.49393
[32m[0907 00-46-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34853, current rewards: -1215.67370, mean: -0.50443
[32m[0907 00-46-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34861, current rewards: -1265.67370, mean: -0.51450
[32m[0907 00-46-35 @Agent.py:117][0m Average action selection time: 0.3486
[32m[0907 00-46-35 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-46-35 @MBExp.py:227][0m Rewards obtained: [-1305.6737042529912], Lows: [41], Highs: [1371], Total time: 37946.758562999996
[32m[0907 00-48-10 @MBExp.py:144][0m ####################################################################
[32m[0907 00-48-10 @MBExp.py:145][0m Starting training iteration 46.
[32m[0907 00-48-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33246, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-48-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32933, current rewards: -19.68627, mean: -0.32810
[32m[0907 00-48-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32644, current rewards: -11.97298, mean: -0.10885
[32m[0907 00-49-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32526, current rewards: -5.00300, mean: -0.03127
[32m[0907 00-49-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32498, current rewards: -14.80874, mean: -0.07052
[32m[0907 00-49-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32772, current rewards: -34.43239, mean: -0.13243
[32m[0907 00-49-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33043, current rewards: -25.32616, mean: -0.08170
[32m[0907 00-50-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33345, current rewards: -16.09111, mean: -0.04470
[32m[0907 00-50-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33583, current rewards: -6.85940, mean: -0.01673
[32m[0907 00-50-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33705, current rewards: 2.37286, mean: 0.00516
[32m[0907 00-51-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33783, current rewards: 11.60739, mean: 0.02276
[32m[0907 00-51-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33963, current rewards: -1.20999, mean: -0.00216
[32m[0907 00-51-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34002, current rewards: 6.07286, mean: 0.00996
[32m[0907 00-51-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34033, current rewards: 15.14477, mean: 0.02295
[32m[0907 00-52-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34064, current rewards: 23.80175, mean: 0.03352
[32m[0907 00-52-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34139, current rewards: 32.48542, mean: 0.04274
[32m[0907 00-52-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34207, current rewards: 41.04292, mean: 0.05067
[32m[0907 00-53-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34267, current rewards: 49.39760, mean: 0.05744
[32m[0907 00-53-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34291, current rewards: 57.72853, mean: 0.06344
[32m[0907 00-53-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34159, current rewards: 66.19090, mean: 0.06895
[32m[0907 00-53-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34027, current rewards: 79.91299, mean: 0.07912
[32m[0907 00-54-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33911, current rewards: 88.42503, mean: 0.08342
[32m[0907 00-54-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33801, current rewards: 97.00901, mean: 0.08740
[32m[0907 00-54-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33701, current rewards: 105.69970, mean: 0.09112
[32m[0907 00-54-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33611, current rewards: 114.35172, mean: 0.09451
[32m[0907 00-55-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33528, current rewards: 122.96899, mean: 0.09759
[32m[0907 00-55-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33447, current rewards: 131.59801, mean: 0.10046
[32m[0907 00-55-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33376, current rewards: 114.68300, mean: 0.08433
[32m[0907 00-56-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33308, current rewards: 123.16133, mean: 0.08735
[32m[0907 00-56-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33245, current rewards: 130.69920, mean: 0.08952
[32m[0907 00-56-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33185, current rewards: 138.22271, mean: 0.09154
[32m[0907 00-56-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33131, current rewards: 145.75318, mean: 0.09343
[32m[0907 00-57-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33079, current rewards: 153.28662, mean: 0.09521
[32m[0907 00-57-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33030, current rewards: 160.81570, mean: 0.09688
[32m[0907 00-57-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32983, current rewards: 168.34673, mean: 0.09845
[32m[0907 00-57-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32937, current rewards: 175.87119, mean: 0.09993
[32m[0907 00-58-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32897, current rewards: 182.89852, mean: 0.10105
[32m[0907 00-58-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32856, current rewards: 189.96282, mean: 0.10213
[32m[0907 00-58-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32819, current rewards: 197.55487, mean: 0.10343
[32m[0907 00-58-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32785, current rewards: 205.10592, mean: 0.10465
[32m[0907 00-59-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32752, current rewards: 212.66439, mean: 0.10580
[32m[0907 00-59-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32721, current rewards: 220.21410, mean: 0.10690
[32m[0907 00-59-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32691, current rewards: 226.84127, mean: 0.10751
[32m[0907 00-59-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32662, current rewards: 231.55941, mean: 0.10720
[32m[0907 01-00-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32636, current rewards: 236.17307, mean: 0.10687
[32m[0907 01-00-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32608, current rewards: 240.68422, mean: 0.10650
[32m[0907 01-00-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32582, current rewards: 245.23610, mean: 0.10616
[32m[0907 01-00-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32557, current rewards: 249.76705, mean: 0.10583
[32m[0907 01-01-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32535, current rewards: 254.31012, mean: 0.10552
[32m[0907 01-01-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32513, current rewards: 258.84694, mean: 0.10522
[32m[0907 01-01-43 @Agent.py:117][0m Average action selection time: 0.3250
[32m[0907 01-01-43 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-01-43 @MBExp.py:227][0m Rewards obtained: [262.4824837915784], Lows: [32], Highs: [42], Total time: 38759.863666
[32m[0907 01-03-10 @MBExp.py:144][0m ####################################################################
[32m[0907 01-03-10 @MBExp.py:145][0m Starting training iteration 47.
[32m[0907 01-03-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32725, current rewards: 1.70758, mean: 0.17076
[32m[0907 01-03-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29967, current rewards: -74.14901, mean: -1.23582
[32m[0907 01-03-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29537, current rewards: -69.09274, mean: -0.62812
[32m[0907 01-03-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29386, current rewards: -65.57368, mean: -0.40984
[32m[0907 01-04-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29334, current rewards: -58.13355, mean: -0.27683
[32m[0907 01-04-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29523, current rewards: -52.25580, mean: -0.20098
[32m[0907 01-04-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29728, current rewards: -46.38062, mean: -0.14961
[32m[0907 01-04-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29963, current rewards: -40.50658, mean: -0.11252
[32m[0907 01-05-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30144, current rewards: -34.63165, mean: -0.08447
[32m[0907 01-05-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30237, current rewards: -28.75805, mean: -0.06252
[32m[0907 01-05-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30295, current rewards: -22.88774, mean: -0.04488
[32m[0907 01-06-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30344, current rewards: -17.76203, mean: -0.03172
[32m[0907 01-06-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30379, current rewards: -11.78817, mean: -0.01932
[32m[0907 01-06-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30409, current rewards: -16.00453, mean: -0.02425
[32m[0907 01-06-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30440, current rewards: -23.22570, mean: -0.03271
[32m[0907 01-07-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30517, current rewards: -18.68607, mean: -0.02459
[32m[0907 01-07-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30585, current rewards: -14.12990, mean: -0.01744
[32m[0907 01-07-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30645, current rewards: -9.57245, mean: -0.01113
[32m[0907 01-07-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30698, current rewards: -5.01436, mean: -0.00551
[32m[0907 01-08-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30745, current rewards: -0.45336, mean: -0.00047
[32m[0907 01-08-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30788, current rewards: 4.10538, mean: 0.00406
[32m[0907 01-08-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30822, current rewards: 8.66384, mean: 0.00817
[32m[0907 01-08-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30851, current rewards: 13.21405, mean: 0.01190
[32m[0907 01-09-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30876, current rewards: 17.77252, mean: 0.01532
[32m[0907 01-09-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30902, current rewards: 22.33208, mean: 0.01846
[32m[0907 01-09-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30928, current rewards: 24.70383, mean: 0.01961
[32m[0907 01-09-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30950, current rewards: -35.61728, mean: -0.02719
[32m[0907 01-10-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30971, current rewards: -39.74278, mean: -0.02922
[32m[0907 01-10-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30989, current rewards: -42.70177, mean: -0.03028
[32m[0907 01-10-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31006, current rewards: -42.65169, mean: -0.02921
[32m[0907 01-10-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31020, current rewards: -42.34682, mean: -0.02804
[32m[0907 01-11-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31035, current rewards: -40.90316, mean: -0.02622
[32m[0907 01-11-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31046, current rewards: -39.58959, mean: -0.02459
[32m[0907 01-11-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31059, current rewards: -39.37237, mean: -0.02372
[32m[0907 01-12-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31069, current rewards: -38.03388, mean: -0.02224
[32m[0907 01-12-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31082, current rewards: -36.72645, mean: -0.02087
[32m[0907 01-12-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31090, current rewards: -56.85554, mean: -0.03141
[32m[0907 01-12-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31100, current rewards: -53.23043, mean: -0.02862
[32m[0907 01-13-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31110, current rewards: -91.32756, mean: -0.04782
[32m[0907 01-13-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31117, current rewards: -84.40000, mean: -0.04306
[32m[0907 01-13-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31123, current rewards: -79.76213, mean: -0.03968
[32m[0907 01-13-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31132, current rewards: -75.07181, mean: -0.03644
[32m[0907 01-14-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31138, current rewards: -70.13708, mean: -0.03324
[32m[0907 01-14-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31142, current rewards: -65.45545, mean: -0.03030
[32m[0907 01-14-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31147, current rewards: -60.48252, mean: -0.02737
[32m[0907 01-14-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31152, current rewards: -55.61460, mean: -0.02461
[32m[0907 01-15-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31157, current rewards: -50.71224, mean: -0.02195
[32m[0907 01-15-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31162, current rewards: -46.07103, mean: -0.01952
[32m[0907 01-15-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31168, current rewards: -41.18232, mean: -0.01709
[32m[0907 01-15-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31172, current rewards: -36.23932, mean: -0.01473
[32m[0907 01-16-10 @Agent.py:117][0m Average action selection time: 0.3117
[32m[0907 01-16-10 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-16-10 @MBExp.py:227][0m Rewards obtained: [-32.518772949918855], Lows: [85], Highs: [90], Total time: 39539.880937999995
[32m[0907 01-17-40 @MBExp.py:144][0m ####################################################################
[32m[0907 01-17-40 @MBExp.py:145][0m Starting training iteration 48.
[32m[0907 01-17-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29679, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-17-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29412, current rewards: -15.77150, mean: -0.26286
[32m[0907 01-18-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29238, current rewards: -10.60776, mean: -0.09643
[32m[0907 01-18-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29171, current rewards: -5.43359, mean: -0.03396
[32m[0907 01-18-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29135, current rewards: -0.26203, mean: -0.00125
[32m[0907 01-18-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29352, current rewards: 4.90822, mean: 0.01888
[32m[0907 01-19-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29598, current rewards: 10.08615, mean: 0.03254
[32m[0907 01-19-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29842, current rewards: 15.25841, mean: 0.04238
[32m[0907 01-19-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30053, current rewards: 20.42770, mean: 0.04982
[32m[0907 01-19-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30163, current rewards: -12.26085, mean: -0.02665
[32m[0907 01-20-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30242, current rewards: -28.42888, mean: -0.05574
[32m[0907 01-20-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30304, current rewards: -21.50222, mean: -0.03840
[32m[0907 01-20-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30342, current rewards: -14.57556, mean: -0.02389
[32m[0907 01-21-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30382, current rewards: -7.64890, mean: -0.01159
[32m[0907 01-21-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30412, current rewards: -42.84797, mean: -0.06035
[32m[0907 01-21-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30489, current rewards: -92.84797, mean: -0.12217
[32m[0907 01-21-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30563, current rewards: -142.84797, mean: -0.17636
[32m[0907 01-22-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30619, current rewards: -192.84797, mean: -0.22424
[32m[0907 01-22-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30669, current rewards: -242.84797, mean: -0.26687
[32m[0907 01-22-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30714, current rewards: -292.84797, mean: -0.30505
[32m[0907 01-22-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30761, current rewards: -342.84797, mean: -0.33945
[32m[0907 01-23-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30799, current rewards: -392.84797, mean: -0.37061
[32m[0907 01-23-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30836, current rewards: -442.84797, mean: -0.39896
[32m[0907 01-23-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30868, current rewards: -492.84797, mean: -0.42487
[32m[0907 01-23-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30899, current rewards: -542.84797, mean: -0.44863
[32m[0907 01-24-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30923, current rewards: -592.84797, mean: -0.47051
[32m[0907 01-24-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30946, current rewards: -642.84797, mean: -0.49072
[32m[0907 01-24-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30968, current rewards: -692.84797, mean: -0.50945
[32m[0907 01-24-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30989, current rewards: -742.84797, mean: -0.52684
[32m[0907 01-25-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31010, current rewards: -792.84797, mean: -0.54305
[32m[0907 01-25-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31026, current rewards: -842.84797, mean: -0.55818
[32m[0907 01-25-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31042, current rewards: -892.84797, mean: -0.57234
[32m[0907 01-26-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31057, current rewards: -942.84797, mean: -0.58562
[32m[0907 01-26-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31070, current rewards: -992.84797, mean: -0.59810
[32m[0907 01-26-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31083, current rewards: -1042.84797, mean: -0.60985
[32m[0907 01-26-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31094, current rewards: -1092.84797, mean: -0.62094
[32m[0907 01-27-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31103, current rewards: -1142.84797, mean: -0.63141
[32m[0907 01-27-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31112, current rewards: -1192.84797, mean: -0.64132
[32m[0907 01-27-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31119, current rewards: -1242.84797, mean: -0.65071
[32m[0907 01-27-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31126, current rewards: -1292.84797, mean: -0.65962
[32m[0907 01-28-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31133, current rewards: -1342.84797, mean: -0.66808
[32m[0907 01-28-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31140, current rewards: -1392.84797, mean: -0.67614
[32m[0907 01-28-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31150, current rewards: -1442.84797, mean: -0.68381
[32m[0907 01-28-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31160, current rewards: -1492.84797, mean: -0.69113
[32m[0907 01-29-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31166, current rewards: -1542.84797, mean: -0.69812
[32m[0907 01-29-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31173, current rewards: -1592.84797, mean: -0.70480
[32m[0907 01-29-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31179, current rewards: -1642.84797, mean: -0.71119
[32m[0907 01-29-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31183, current rewards: -1692.84797, mean: -0.71731
[32m[0907 01-30-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31187, current rewards: -1742.84797, mean: -0.72317
[32m[0907 01-30-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31190, current rewards: -1792.84797, mean: -0.72880
[32m[0907 01-30-40 @Agent.py:117][0m Average action selection time: 0.3119
[32m[0907 01-30-40 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-30-40 @MBExp.py:227][0m Rewards obtained: [-1832.8479681101237], Lows: [31], Highs: [1848], Total time: 40320.384482999994
[32m[0907 01-32-11 @MBExp.py:144][0m ####################################################################
[32m[0907 01-32-11 @MBExp.py:145][0m Starting training iteration 49.
[32m[0907 01-32-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29876, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-32-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29440, current rewards: -17.52217, mean: -0.29204
[32m[0907 01-32-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29255, current rewards: -12.91113, mean: -0.11737
[32m[0907 01-32-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29204, current rewards: -7.88901, mean: -0.04931
[32m[0907 01-33-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29161, current rewards: -2.85417, mean: -0.01359
[32m[0907 01-33-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29362, current rewards: 2.18184, mean: 0.00839
[32m[0907 01-33-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29612, current rewards: 7.21807, mean: 0.02328
[32m[0907 01-33-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29866, current rewards: 12.25421, mean: 0.03404
[32m[0907 01-34-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30078, current rewards: 17.28970, mean: 0.04217
[32m[0907 01-34-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30172, current rewards: 22.32594, mean: 0.04853
[32m[0907 01-34-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30241, current rewards: 27.36336, mean: 0.05365
[32m[0907 01-35-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30294, current rewards: 32.40115, mean: 0.05786
[32m[0907 01-35-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30333, current rewards: 37.43856, mean: 0.06137
[32m[0907 01-35-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30368, current rewards: 42.47409, mean: 0.06435
[32m[0907 01-35-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30393, current rewards: 47.50912, mean: 0.06691
[32m[0907 01-36-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30459, current rewards: 52.54524, mean: 0.06914
[32m[0907 01-36-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30523, current rewards: 57.58264, mean: 0.07109
[32m[0907 01-36-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30584, current rewards: 62.61753, mean: 0.07281
[32m[0907 01-36-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30637, current rewards: 72.13373, mean: 0.07927
[32m[0907 01-37-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30680, current rewards: 77.46790, mean: 0.08070
[32m[0907 01-37-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30720, current rewards: 25.08382, mean: 0.02484
[32m[0907 01-37-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30760, current rewards: -74.91618, mean: -0.07068
[32m[0907 01-37-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30797, current rewards: -174.91618, mean: -0.15758
[32m[0907 01-38-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30825, current rewards: -274.91618, mean: -0.23700
[32m[0907 01-38-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30852, current rewards: -374.91618, mean: -0.30985
[32m[0907 01-38-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30878, current rewards: -474.91618, mean: -0.37692
[32m[0907 01-38-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30904, current rewards: -574.91618, mean: -0.43887
[32m[0907 01-39-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30930, current rewards: -674.91618, mean: -0.49626
[32m[0907 01-39-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30951, current rewards: -774.91618, mean: -0.54959
[32m[0907 01-39-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30969, current rewards: -874.91618, mean: -0.59926
[32m[0907 01-39-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30984, current rewards: -974.91618, mean: -0.64564
[32m[0907 01-40-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30998, current rewards: -1074.91618, mean: -0.68905
[32m[0907 01-40-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31016, current rewards: -1174.91618, mean: -0.72976
[32m[0907 01-40-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31031, current rewards: -1274.91618, mean: -0.76802
[32m[0907 01-41-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31042, current rewards: -1374.91618, mean: -0.80404
[32m[0907 01-41-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31058, current rewards: -1474.91618, mean: -0.83802
[32m[0907 01-41-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31070, current rewards: -1574.91618, mean: -0.87012
[32m[0907 01-41-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31082, current rewards: -1674.91618, mean: -0.90049
[32m[0907 01-42-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31092, current rewards: -1774.91618, mean: -0.92928
[32m[0907 01-42-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31101, current rewards: -1874.91618, mean: -0.95659
[32m[0907 01-42-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31108, current rewards: -1974.91618, mean: -0.98255
[32m[0907 01-42-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31114, current rewards: -2074.91618, mean: -1.00724
[32m[0907 01-43-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31118, current rewards: -2174.91618, mean: -1.03077
[32m[0907 01-43-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31124, current rewards: -2274.91618, mean: -1.05320
[32m[0907 01-43-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31131, current rewards: -2374.91618, mean: -1.07462
[32m[0907 01-43-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31137, current rewards: -2474.91618, mean: -1.09510
[32m[0907 01-44-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31143, current rewards: -2574.91618, mean: -1.11468
[32m[0907 01-44-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31146, current rewards: -2674.91618, mean: -1.13344
[32m[0907 01-44-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31151, current rewards: -2774.91618, mean: -1.15142
[32m[0907 01-44-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31154, current rewards: -2874.91618, mean: -1.16867
[32m[0907 01-45-11 @Agent.py:117][0m Average action selection time: 0.3116
[32m[0907 01-45-11 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-45-11 @MBExp.py:227][0m Rewards obtained: [-2954.9161776409765], Lows: [1507], Highs: [41], Total time: 41099.99688099999
[32m[0907 01-46-44 @MBExp.py:144][0m ####################################################################
[32m[0907 01-46-44 @MBExp.py:145][0m Starting training iteration 50.
[32m[0907 01-46-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29669, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-47-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29327, current rewards: -16.85732, mean: -0.28096
[32m[0907 01-47-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29185, current rewards: -12.80286, mean: -0.11639
[32m[0907 01-47-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29138, current rewards: -8.75822, mean: -0.05474
[32m[0907 01-47-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29119, current rewards: -4.71702, mean: -0.02246
[32m[0907 01-48-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29298, current rewards: -0.67234, mean: -0.00259
[32m[0907 01-48-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29548, current rewards: 3.37567, mean: 0.01089
[32m[0907 01-48-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29786, current rewards: 7.41895, mean: 0.02061
[32m[0907 01-48-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30001, current rewards: 11.46892, mean: 0.02797
[32m[0907 01-49-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30102, current rewards: 8.01123, mean: 0.01742
[32m[0907 01-49-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30175, current rewards: -19.57925, mean: -0.03839
[32m[0907 01-49-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30232, current rewards: -14.85897, mean: -0.02653
[32m[0907 01-49-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30282, current rewards: -10.15143, mean: -0.01664
[32m[0907 01-50-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30321, current rewards: -5.44099, mean: -0.00824
[32m[0907 01-50-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30354, current rewards: -0.73125, mean: -0.00103
[32m[0907 01-50-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30425, current rewards: 3.97587, mean: 0.00523
[32m[0907 01-50-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30498, current rewards: 8.68348, mean: 0.01072
[32m[0907 01-51-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30559, current rewards: 17.94848, mean: 0.02087
[32m[0907 01-51-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30610, current rewards: 24.33574, mean: 0.02674
[32m[0907 01-51-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30657, current rewards: 29.48144, mean: 0.03071
[32m[0907 01-51-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30700, current rewards: 34.62709, mean: 0.03428
[32m[0907 01-52-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30738, current rewards: 39.77274, mean: 0.03752
[32m[0907 01-52-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30771, current rewards: 20.65431, mean: 0.01861
[32m[0907 01-52-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30803, current rewards: 9.02726, mean: 0.00778
[32m[0907 01-52-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30826, current rewards: 13.53185, mean: 0.01118
[32m[0907 01-53-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30850, current rewards: 17.95067, mean: 0.01425
[32m[0907 01-53-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30875, current rewards: 21.83578, mean: 0.01667
[32m[0907 01-53-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30900, current rewards: 26.26761, mean: 0.01931
[32m[0907 01-54-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30924, current rewards: 8.87790, mean: 0.00630
[32m[0907 01-54-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30947, current rewards: 9.49932, mean: 0.00651
[32m[0907 01-54-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30964, current rewards: 13.96771, mean: 0.00925
[32m[0907 01-54-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30985, current rewards: 18.45304, mean: 0.01183
[32m[0907 01-55-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31001, current rewards: 22.93946, mean: 0.01425
[32m[0907 01-55-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31015, current rewards: 27.41866, mean: 0.01652
[32m[0907 01-55-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31030, current rewards: 31.71539, mean: 0.01855
[32m[0907 01-55-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31044, current rewards: -5.33630, mean: -0.00303
[32m[0907 01-56-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31056, current rewards: -1.58930, mean: -0.00088
[32m[0907 01-56-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31067, current rewards: 2.12159, mean: 0.00114
[32m[0907 01-56-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31079, current rewards: 5.83215, mean: 0.00305
[32m[0907 01-56-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31089, current rewards: 9.54479, mean: 0.00487
[32m[0907 01-57-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31096, current rewards: 13.25754, mean: 0.00660
[32m[0907 01-57-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31105, current rewards: 16.96861, mean: 0.00824
[32m[0907 01-57-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31114, current rewards: 23.56898, mean: 0.01117
[32m[0907 01-57-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31124, current rewards: 27.78884, mean: 0.01287
[32m[0907 01-58-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31131, current rewards: 32.01397, mean: 0.01449
[32m[0907 01-58-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31140, current rewards: 14.27066, mean: 0.00631
[32m[0907 01-58-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31151, current rewards: 18.82038, mean: 0.00815
[32m[0907 01-59-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31159, current rewards: 23.41548, mean: 0.00992
[32m[0907 01-59-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31168, current rewards: 28.00861, mean: 0.01162
[32m[0907 01-59-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31175, current rewards: 32.60371, mean: 0.01325
[32m[0907 01-59-44 @Agent.py:117][0m Average action selection time: 0.3118
[32m[0907 01-59-44 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-59-44 @MBExp.py:227][0m Rewards obtained: [36.33430473888779], Lows: [40], Highs: [99], Total time: 41880.12909999999
[32m[0907 02-01-19 @MBExp.py:144][0m ####################################################################
[32m[0907 02-01-19 @MBExp.py:145][0m Starting training iteration 51.
[32m[0907 02-01-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29867, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-01-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29323, current rewards: -17.37533, mean: -0.28959
[32m[0907 02-01-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29238, current rewards: -11.76067, mean: -0.10692
[32m[0907 02-02-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29187, current rewards: -6.16665, mean: -0.03854
[32m[0907 02-02-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29151, current rewards: -0.57475, mean: -0.00274
[32m[0907 02-02-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29296, current rewards: 5.01538, mean: 0.01929
[32m[0907 02-02-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29531, current rewards: 10.61304, mean: 0.03424
[32m[0907 02-03-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29766, current rewards: 16.20707, mean: 0.04502
[32m[0907 02-03-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29989, current rewards: -20.61122, mean: -0.05027
[32m[0907 02-03-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30096, current rewards: -15.63782, mean: -0.03400
[32m[0907 02-03-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30173, current rewards: -10.74426, mean: -0.02107
[32m[0907 02-04-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30228, current rewards: -5.85015, mean: -0.01045
[32m[0907 02-04-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30282, current rewards: -0.95683, mean: -0.00157
[32m[0907 02-04-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30326, current rewards: -8.13830, mean: -0.01233
[32m[0907 02-04-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30362, current rewards: -11.50989, mean: -0.01621
[32m[0907 02-05-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30429, current rewards: -6.13926, mean: -0.00808
[32m[0907 02-05-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30501, current rewards: -1.20744, mean: -0.00149
[32m[0907 02-05-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30563, current rewards: 4.16483, mean: 0.00484
[32m[0907 02-05-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30619, current rewards: 9.66255, mean: 0.01062
[32m[0907 02-06-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30671, current rewards: -3.83082, mean: -0.00399
[32m[0907 02-06-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30719, current rewards: -22.17251, mean: -0.02195
[32m[0907 02-06-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30758, current rewards: -16.67062, mean: -0.01573
[32m[0907 02-07-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30796, current rewards: -11.17522, mean: -0.01007
[32m[0907 02-07-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30827, current rewards: -5.68436, mean: -0.00490
[32m[0907 02-07-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30857, current rewards: -0.18817, mean: -0.00016
[32m[0907 02-07-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30884, current rewards: 6.35990, mean: 0.00505
[32m[0907 02-08-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30910, current rewards: 11.88116, mean: 0.00907
[32m[0907 02-08-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30935, current rewards: 17.40923, mean: 0.01280
[32m[0907 02-08-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30957, current rewards: 22.93209, mean: 0.01626
[32m[0907 02-08-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30975, current rewards: 28.44906, mean: 0.01949
[32m[0907 02-09-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30994, current rewards: 33.97020, mean: 0.02250
[32m[0907 02-09-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31010, current rewards: 39.49071, mean: 0.02531
[32m[0907 02-09-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31023, current rewards: 45.00778, mean: 0.02796
[32m[0907 02-09-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31041, current rewards: 50.24499, mean: 0.03027
[32m[0907 02-10-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31054, current rewards: 55.75032, mean: 0.03260
[32m[0907 02-10-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31067, current rewards: 56.81383, mean: 0.03228
[32m[0907 02-10-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31079, current rewards: 44.37832, mean: 0.02452
[32m[0907 02-10-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31090, current rewards: 49.66360, mean: 0.02670
[32m[0907 02-11-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31104, current rewards: 54.93068, mean: 0.02876
[32m[0907 02-11-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31116, current rewards: 60.19919, mean: 0.03071
[32m[0907 02-11-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31125, current rewards: 65.46436, mean: 0.03257
[32m[0907 02-12-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31135, current rewards: 75.49304, mean: 0.03665
[32m[0907 02-12-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31146, current rewards: 80.70934, mean: 0.03825
[32m[0907 02-12-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31154, current rewards: 85.92293, mean: 0.03978
[32m[0907 02-12-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31162, current rewards: 91.13602, mean: 0.04124
[32m[0907 02-13-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31166, current rewards: 96.34858, mean: 0.04263
[32m[0907 02-13-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31172, current rewards: 101.56306, mean: 0.04397
[32m[0907 02-13-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31176, current rewards: 64.88489, mean: 0.02749
[32m[0907 02-13-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31182, current rewards: 70.54009, mean: 0.02927
[32m[0907 02-14-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31188, current rewards: 74.73664, mean: 0.03038
[32m[0907 02-14-19 @Agent.py:117][0m Average action selection time: 0.3119
[32m[0907 02-14-19 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-14-19 @MBExp.py:227][0m Rewards obtained: [78.4608290550221], Lows: [61], Highs: [61], Total time: 42660.66592299999
[32m[0907 02-15-56 @MBExp.py:144][0m ####################################################################
[32m[0907 02-15-56 @MBExp.py:145][0m Starting training iteration 52.
[32m[0907 02-15-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29773, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-16-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29213, current rewards: -19.26963, mean: -0.32116
[32m[0907 02-16-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29135, current rewards: -15.27397, mean: -0.13885
[32m[0907 02-16-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29105, current rewards: -11.15907, mean: -0.06974
[32m[0907 02-16-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29092, current rewards: -7.04061, mean: -0.03353
[32m[0907 02-17-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29237, current rewards: -44.48580, mean: -0.17110
[32m[0907 02-17-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29503, current rewards: -39.97100, mean: -0.12894
[32m[0907 02-17-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29744, current rewards: -34.66367, mean: -0.09629
[32m[0907 02-17-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29960, current rewards: -29.35604, mean: -0.07160
[32m[0907 02-18-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30052, current rewards: -24.04730, mean: -0.05228
[32m[0907 02-18-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30411, current rewards: -61.44744, mean: -0.12049
[32m[0907 02-18-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30444, current rewards: -55.63045, mean: -0.09934
[32m[0907 02-19-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30470, current rewards: -49.54317, mean: -0.08122
[32m[0907 02-19-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30492, current rewards: -60.43144, mean: -0.09156
[32m[0907 02-19-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30511, current rewards: -80.38623, mean: -0.11322
[32m[0907 02-19-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30559, current rewards: -72.82602, mean: -0.09582
[32m[0907 02-20-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30625, current rewards: -68.14872, mean: -0.08413
[32m[0907 02-20-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30673, current rewards: -63.06785, mean: -0.07333
[32m[0907 02-20-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30715, current rewards: -57.98630, mean: -0.06372
[32m[0907 02-20-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30756, current rewards: -52.90537, mean: -0.05511
[32m[0907 02-21-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30797, current rewards: -70.18701, mean: -0.06949
[32m[0907 02-21-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30831, current rewards: -65.15532, mean: -0.06147
[32m[0907 02-21-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30861, current rewards: -59.84205, mean: -0.05391
[32m[0907 02-21-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30884, current rewards: -54.52657, mean: -0.04701
[32m[0907 02-22-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30907, current rewards: -49.63195, mean: -0.04102
[32m[0907 02-22-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30928, current rewards: -44.43638, mean: -0.03527
[32m[0907 02-22-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30952, current rewards: -39.23933, mean: -0.02995
[32m[0907 02-22-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30972, current rewards: -34.04449, mean: -0.02503
[32m[0907 02-23-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30992, current rewards: -28.85198, mean: -0.02046
[32m[0907 02-23-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31007, current rewards: -23.65899, mean: -0.01620
[32m[0907 02-23-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31024, current rewards: -18.46868, mean: -0.01223
[32m[0907 02-24-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31038, current rewards: -35.17915, mean: -0.02255
[32m[0907 02-24-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31057, current rewards: -26.33771, mean: -0.01636
[32m[0907 02-24-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31071, current rewards: -21.26349, mean: -0.01281
[32m[0907 02-24-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31084, current rewards: -16.13011, mean: -0.00943
[32m[0907 02-25-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31096, current rewards: -10.98325, mean: -0.00624
[32m[0907 02-25-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31107, current rewards: -5.84451, mean: -0.00323
[32m[0907 02-25-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31116, current rewards: -0.70660, mean: -0.00038
[32m[0907 02-25-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31126, current rewards: 4.44072, mean: 0.00232
[32m[0907 02-26-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31136, current rewards: 8.60256, mean: 0.00439
[32m[0907 02-26-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31143, current rewards: 12.70011, mean: 0.00632
[32m[0907 02-26-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31150, current rewards: 17.28093, mean: 0.00839
[32m[0907 02-26-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31158, current rewards: 21.69790, mean: 0.01028
[32m[0907 02-27-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31166, current rewards: 25.95222, mean: 0.01201
[32m[0907 02-27-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31174, current rewards: 30.19506, mean: 0.01366
[32m[0907 02-27-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31182, current rewards: 34.41785, mean: 0.01523
[32m[0907 02-27-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31190, current rewards: 42.24263, mean: 0.01829
[32m[0907 02-28-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31197, current rewards: 47.15815, mean: 0.01998
[32m[0907 02-28-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31203, current rewards: 52.10057, mean: 0.02162
[32m[0907 02-28-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31208, current rewards: 56.99887, mean: 0.02317
[32m[0907 02-28-57 @Agent.py:117][0m Average action selection time: 0.3121
[32m[0907 02-28-57 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-28-57 @MBExp.py:227][0m Rewards obtained: [61.011541978897206], Lows: [61], Highs: [62], Total time: 43441.60434399999
[32m[0907 02-30-36 @MBExp.py:144][0m ####################################################################
[32m[0907 02-30-36 @MBExp.py:145][0m Starting training iteration 53.
[32m[0907 02-30-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29499, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-30-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29164, current rewards: -59.37425, mean: -0.98957
[32m[0907 02-31-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29105, current rewards: -54.22412, mean: -0.49295
[32m[0907 02-31-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29124, current rewards: -49.08839, mean: -0.30680
[32m[0907 02-31-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29156, current rewards: -43.96355, mean: -0.20935
[32m[0907 02-31-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29269, current rewards: -38.83548, mean: -0.14937
[32m[0907 02-32-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29537, current rewards: -33.60812, mean: -0.10841
[32m[0907 02-32-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29776, current rewards: -61.99916, mean: -0.17222
[32m[0907 02-32-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29991, current rewards: -56.08529, mean: -0.13679
[32m[0907 02-32-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30085, current rewards: -50.72848, mean: -0.11028
[32m[0907 02-33-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30161, current rewards: -45.36801, mean: -0.08896
[32m[0907 02-33-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30224, current rewards: -40.01520, mean: -0.07146
[32m[0907 02-33-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30278, current rewards: -77.11952, mean: -0.12643
[32m[0907 02-33-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30327, current rewards: -65.67765, mean: -0.09951
[32m[0907 02-34-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30362, current rewards: -54.19349, mean: -0.07633
[32m[0907 02-34-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30435, current rewards: -42.16556, mean: -0.05548
[32m[0907 02-34-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30507, current rewards: -30.77770, mean: -0.03800
[32m[0907 02-34-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30564, current rewards: -19.32861, mean: -0.02248
[32m[0907 02-35-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30621, current rewards: -7.85383, mean: -0.00863
[32m[0907 02-35-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30671, current rewards: 3.60955, mean: 0.00376
[32m[0907 02-35-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30713, current rewards: 15.09551, mean: 0.01495
[32m[0907 02-36-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30756, current rewards: 22.55944, mean: 0.02128
[32m[0907 02-36-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30793, current rewards: 27.74625, mean: 0.02500
[32m[0907 02-36-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30824, current rewards: 33.41194, mean: 0.02880
[32m[0907 02-36-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30852, current rewards: 38.66049, mean: 0.03195
[32m[0907 02-37-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30881, current rewards: 42.83145, mean: 0.03399
[32m[0907 02-37-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30909, current rewards: 47.59567, mean: 0.03633
[32m[0907 02-37-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30934, current rewards: 52.76897, mean: 0.03880
[32m[0907 02-37-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30953, current rewards: 57.94504, mean: 0.04110
[32m[0907 02-38-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30970, current rewards: 63.12779, mean: 0.04324
[32m[0907 02-38-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30988, current rewards: 68.30266, mean: 0.04523
[32m[0907 02-38-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31005, current rewards: 72.86990, mean: 0.04671
[32m[0907 02-38-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31021, current rewards: 77.44031, mean: 0.04810
[32m[0907 02-39-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31036, current rewards: 82.57837, mean: 0.04975
[32m[0907 02-39-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31048, current rewards: 65.54440, mean: 0.03833
[32m[0907 02-39-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31062, current rewards: 70.45006, mean: 0.04003
[32m[0907 02-39-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31072, current rewards: 75.42131, mean: 0.04167
[32m[0907 02-40-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31084, current rewards: 80.39683, mean: 0.04322
[32m[0907 02-40-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31093, current rewards: 85.36923, mean: 0.04470
[32m[0907 02-40-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31105, current rewards: 58.85468, mean: 0.03003
[32m[0907 02-41-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31114, current rewards: 53.24471, mean: 0.02649
[32m[0907 02-41-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31124, current rewards: 59.17339, mean: 0.02872
[32m[0907 02-41-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31134, current rewards: 65.13674, mean: 0.03087
[32m[0907 02-41-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31143, current rewards: 71.10158, mean: 0.03292
[32m[0907 02-42-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31150, current rewards: 77.07113, mean: 0.03487
[32m[0907 02-42-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31156, current rewards: 83.04299, mean: 0.03674
[32m[0907 02-42-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31164, current rewards: 89.01153, mean: 0.03853
[32m[0907 02-42-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31171, current rewards: 94.97568, mean: 0.04024
[32m[0907 02-43-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31177, current rewards: 100.93945, mean: 0.04188
[32m[0907 02-43-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31182, current rewards: 106.91282, mean: 0.04346
[32m[0907 02-43-36 @Agent.py:117][0m Average action selection time: 0.3119
[32m[0907 02-43-36 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-43-36 @MBExp.py:227][0m Rewards obtained: [111.68084668444918], Lows: [81], Highs: [41], Total time: 44221.90753299999
[32m[0907 02-45-17 @MBExp.py:144][0m ####################################################################
[32m[0907 02-45-17 @MBExp.py:145][0m Starting training iteration 54.
[32m[0907 02-45-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29249, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-45-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29093, current rewards: -37.84100, mean: -0.63068
[32m[0907 02-45-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29261, current rewards: -72.57463, mean: -0.65977
[32m[0907 02-46-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29183, current rewards: -109.88800, mean: -0.68680
[32m[0907 02-46-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29155, current rewards: -150.91680, mean: -0.71865
[32m[0907 02-46-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29243, current rewards: -163.53654, mean: -0.62899
[32m[0907 02-46-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29487, current rewards: -196.41094, mean: -0.63358
[32m[0907 02-47-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29733, current rewards: -194.06370, mean: -0.53907
[32m[0907 02-47-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29942, current rewards: -188.44244, mean: -0.45962
[32m[0907 02-47-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30037, current rewards: -182.79096, mean: -0.39737
[32m[0907 02-47-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30115, current rewards: -177.13622, mean: -0.34733
[32m[0907 02-48-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30179, current rewards: -171.48168, mean: -0.30622
[32m[0907 02-48-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30235, current rewards: -165.83156, mean: -0.27186
[32m[0907 02-48-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30282, current rewards: -160.17650, mean: -0.24269
[32m[0907 02-48-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30322, current rewards: -155.56343, mean: -0.21910
[32m[0907 02-49-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30386, current rewards: -163.05768, mean: -0.21455
[32m[0907 02-49-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30456, current rewards: -197.83287, mean: -0.24424
[32m[0907 02-49-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30539, current rewards: -226.58077, mean: -0.26347
[32m[0907 02-49-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30592, current rewards: -238.95405, mean: -0.26259
[32m[0907 02-50-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30659, current rewards: -259.76401, mean: -0.27059
[32m[0907 02-50-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30704, current rewards: -306.82785, mean: -0.30379
[32m[0907 02-50-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30740, current rewards: -336.80169, mean: -0.31774
[32m[0907 02-50-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30776, current rewards: -331.56548, mean: -0.29871
[32m[0907 02-51-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30810, current rewards: -324.21713, mean: -0.27950
[32m[0907 02-51-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30842, current rewards: -316.74138, mean: -0.26177
[32m[0907 02-51-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30871, current rewards: -309.25879, mean: -0.24544
[32m[0907 02-52-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30895, current rewards: -301.77528, mean: -0.23036
[32m[0907 02-52-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30917, current rewards: -294.28991, mean: -0.21639
[32m[0907 02-52-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30939, current rewards: -331.26858, mean: -0.23494
[32m[0907 02-52-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30960, current rewards: -324.64516, mean: -0.22236
[32m[0907 02-53-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30975, current rewards: -318.74166, mean: -0.21109
[32m[0907 02-53-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30994, current rewards: -312.22832, mean: -0.20015
[32m[0907 02-53-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31009, current rewards: -306.00446, mean: -0.19006
[32m[0907 02-53-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31025, current rewards: -316.65054, mean: -0.19075
[32m[0907 02-54-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31041, current rewards: -336.60028, mean: -0.19684
[32m[0907 02-54-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31054, current rewards: -382.30974, mean: -0.21722
[32m[0907 02-54-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31066, current rewards: -393.58219, mean: -0.21745
[32m[0907 02-54-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31078, current rewards: -418.73072, mean: -0.22512
[32m[0907 02-55-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31088, current rewards: -487.47596, mean: -0.25522
[32m[0907 02-55-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31098, current rewards: -522.93593, mean: -0.26680
[32m[0907 02-55-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31109, current rewards: -569.97302, mean: -0.28357
[32m[0907 02-55-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31118, current rewards: -605.44340, mean: -0.29390
[32m[0907 02-56-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31126, current rewards: -653.63998, mean: -0.30978
[32m[0907 02-56-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31136, current rewards: -685.32474, mean: -0.31728
[32m[0907 02-56-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31144, current rewards: -727.01368, mean: -0.32897
[32m[0907 02-57-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31152, current rewards: -767.93489, mean: -0.33979
[32m[0907 02-57-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31159, current rewards: -817.93489, mean: -0.35408
[32m[0907 02-57-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31163, current rewards: -867.93489, mean: -0.36777
[32m[0907 02-57-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31170, current rewards: -917.93489, mean: -0.38089
[32m[0907 02-58-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31177, current rewards: -967.93489, mean: -0.39347
[32m[0907 02-58-17 @Agent.py:117][0m Average action selection time: 0.3118
[32m[0907 02-58-17 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-58-17 @MBExp.py:227][0m Rewards obtained: [-1007.9348873320799], Lows: [381], Highs: [493], Total time: 45002.10256099999
[32m[0907 02-59-59 @MBExp.py:144][0m ####################################################################
[32m[0907 02-59-59 @MBExp.py:145][0m Starting training iteration 55.
[32m[0907 03-00-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28789, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-00-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29075, current rewards: -56.65127, mean: -0.94419
[32m[0907 03-00-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29073, current rewards: -53.63515, mean: -0.48759
[32m[0907 03-00-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29071, current rewards: -50.59996, mean: -0.31625
[32m[0907 03-01-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29066, current rewards: -47.57026, mean: -0.22653
[32m[0907 03-01-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29171, current rewards: -44.63419, mean: -0.17167
[32m[0907 03-01-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29377, current rewards: -41.60015, mean: -0.13419
[32m[0907 03-01-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29642, current rewards: -38.56205, mean: -0.10712
[32m[0907 03-02-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29862, current rewards: -35.51731, mean: -0.08663
[32m[0907 03-02-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29979, current rewards: -32.47605, mean: -0.07060
[32m[0907 03-02-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30062, current rewards: -29.43681, mean: -0.05772
[32m[0907 03-02-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30135, current rewards: -26.39428, mean: -0.04713
[32m[0907 03-03-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30193, current rewards: -23.35076, mean: -0.03828
[32m[0907 03-03-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30237, current rewards: -19.31220, mean: -0.02926
[32m[0907 03-03-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30285, current rewards: -16.19471, mean: -0.02281
[32m[0907 03-03-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30355, current rewards: -13.17914, mean: -0.01734
[32m[0907 03-04-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30432, current rewards: -50.08333, mean: -0.06183
[32m[0907 03-04-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30505, current rewards: -44.66664, mean: -0.05194
[32m[0907 03-04-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30570, current rewards: -39.27299, mean: -0.04316
[32m[0907 03-04-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30623, current rewards: -33.88114, mean: -0.03529
[32m[0907 03-05-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30668, current rewards: -28.48766, mean: -0.02821
[32m[0907 03-05-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30712, current rewards: -41.52092, mean: -0.03917
[32m[0907 03-05-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30751, current rewards: -65.98810, mean: -0.05945
[32m[0907 03-05-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30793, current rewards: -115.98810, mean: -0.09999
[32m[0907 03-06-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30828, current rewards: -165.98810, mean: -0.13718
[32m[0907 03-06-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30857, current rewards: -215.98810, mean: -0.17142
[32m[0907 03-06-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30883, current rewards: -265.98810, mean: -0.20304
[32m[0907 03-07-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30908, current rewards: -315.98810, mean: -0.23234
[32m[0907 03-07-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30932, current rewards: -365.98810, mean: -0.25957
[32m[0907 03-07-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30953, current rewards: -415.98810, mean: -0.28492
[32m[0907 03-07-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30970, current rewards: -465.98810, mean: -0.30860
[32m[0907 03-08-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30989, current rewards: -515.98810, mean: -0.33076
[32m[0907 03-08-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31008, current rewards: -565.98810, mean: -0.35155
[32m[0907 03-08-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31025, current rewards: -615.98810, mean: -0.37108
[32m[0907 03-08-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31040, current rewards: -665.98810, mean: -0.38947
[32m[0907 03-09-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31056, current rewards: -715.98810, mean: -0.40681
[32m[0907 03-09-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31070, current rewards: -765.98810, mean: -0.42320
[32m[0907 03-09-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31080, current rewards: -815.98810, mean: -0.43870
[32m[0907 03-09-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31092, current rewards: -865.98810, mean: -0.45340
[32m[0907 03-10-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31102, current rewards: -915.98810, mean: -0.46734
[32m[0907 03-10-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31110, current rewards: -965.98810, mean: -0.48059
[32m[0907 03-10-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31123, current rewards: -1015.98810, mean: -0.49320
[32m[0907 03-10-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31131, current rewards: -1065.98810, mean: -0.50521
[32m[0907 03-11-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31140, current rewards: -1115.98810, mean: -0.51666
[32m[0907 03-11-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31150, current rewards: -1165.98810, mean: -0.52760
[32m[0907 03-11-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31158, current rewards: -1215.98810, mean: -0.53805
[32m[0907 03-12-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31165, current rewards: -1265.98810, mean: -0.54805
[32m[0907 03-12-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31171, current rewards: -1315.98810, mean: -0.55762
[32m[0907 03-12-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31180, current rewards: -1365.98810, mean: -0.56680
[32m[0907 03-12-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31189, current rewards: -1415.98810, mean: -0.57560
[32m[0907 03-13-00 @Agent.py:117][0m Average action selection time: 0.3119
[32m[0907 03-13-00 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-13-00 @MBExp.py:227][0m Rewards obtained: [-1455.9880963164142], Lows: [50], Highs: [1439], Total time: 45782.594764999994
[32m[0907 03-14-44 @MBExp.py:144][0m ####################################################################
[32m[0907 03-14-44 @MBExp.py:145][0m Starting training iteration 56.
[32m[0907 03-14-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28887, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-15-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.28990, current rewards: -15.78088, mean: -0.26301
[32m[0907 03-15-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29015, current rewards: -8.23026, mean: -0.07482
[32m[0907 03-15-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29034, current rewards: -0.46314, mean: -0.00289
[32m[0907 03-15-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29045, current rewards: 7.11397, mean: 0.03388
[32m[0907 03-16-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29146, current rewards: 12.95452, mean: 0.04983
[32m[0907 03-16-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29325, current rewards: 19.75424, mean: 0.06372
[32m[0907 03-16-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29573, current rewards: 26.22107, mean: 0.07284
[32m[0907 03-16-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29792, current rewards: 32.93604, mean: 0.08033
[32m[0907 03-17-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29908, current rewards: 39.57877, mean: 0.08604
[32m[0907 03-17-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29999, current rewards: 46.11905, mean: 0.09043
[32m[0907 03-17-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30076, current rewards: 51.96320, mean: 0.09279
[32m[0907 03-17-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30139, current rewards: 56.67703, mean: 0.09291
[32m[0907 03-18-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30188, current rewards: 65.75873, mean: 0.09963
[32m[0907 03-18-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30229, current rewards: 73.19670, mean: 0.10309
[32m[0907 03-18-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30296, current rewards: 81.00176, mean: 0.10658
[32m[0907 03-18-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30379, current rewards: 88.95107, mean: 0.10982
[32m[0907 03-19-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30449, current rewards: 96.92125, mean: 0.11270
[32m[0907 03-19-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30507, current rewards: 104.89613, mean: 0.11527
[32m[0907 03-19-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30565, current rewards: 112.85916, mean: 0.11756
[32m[0907 03-19-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30616, current rewards: 120.81028, mean: 0.11961
[32m[0907 03-20-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30658, current rewards: 130.65029, mean: 0.12325
[32m[0907 03-20-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30698, current rewards: 100.24708, mean: 0.09031
[32m[0907 03-20-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30734, current rewards: 100.84146, mean: 0.08693
[32m[0907 03-20-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30769, current rewards: 102.18439, mean: 0.08445
[32m[0907 03-21-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30797, current rewards: 100.49667, mean: 0.07976
[32m[0907 03-21-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30825, current rewards: 104.83135, mean: 0.08002
[32m[0907 03-21-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30851, current rewards: 93.52424, mean: 0.06877
[32m[0907 03-21-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30873, current rewards: 96.92263, mean: 0.06874
[32m[0907 03-22-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30892, current rewards: 92.31571, mean: 0.06323
[32m[0907 03-22-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30924, current rewards: 53.01772, mean: 0.03511
[32m[0907 03-22-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30940, current rewards: 38.79042, mean: 0.02487
[32m[0907 03-23-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30955, current rewards: 35.01847, mean: 0.02175
[32m[0907 03-23-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30969, current rewards: 39.54393, mean: 0.02382
[32m[0907 03-23-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30984, current rewards: 44.18630, mean: 0.02584
[32m[0907 03-23-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30998, current rewards: 48.83477, mean: 0.02775
[32m[0907 03-24-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31011, current rewards: 53.48255, mean: 0.02955
[32m[0907 03-24-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31023, current rewards: 58.13391, mean: 0.03125
[32m[0907 03-24-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31036, current rewards: 64.61603, mean: 0.03383
[32m[0907 03-24-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31047, current rewards: 53.76426, mean: 0.02743
[32m[0907 03-25-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31056, current rewards: 52.15437, mean: 0.02595
[32m[0907 03-25-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31067, current rewards: 58.38777, mean: 0.02834
[32m[0907 03-25-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31075, current rewards: 65.73543, mean: 0.03115
[32m[0907 03-25-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31085, current rewards: 73.18680, mean: 0.03388
[32m[0907 03-26-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31093, current rewards: 23.38062, mean: 0.01058
[32m[0907 03-26-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31102, current rewards: 18.53249, mean: 0.00820
[32m[0907 03-26-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31110, current rewards: 25.15108, mean: 0.01089
[32m[0907 03-26-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31117, current rewards: 31.86339, mean: 0.01350
[32m[0907 03-27-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31125, current rewards: 38.56289, mean: 0.01600
[32m[0907 03-27-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31131, current rewards: 45.26288, mean: 0.01840
[32m[0907 03-27-43 @Agent.py:117][0m Average action selection time: 0.3114
[32m[0907 03-27-43 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-27-43 @MBExp.py:227][0m Rewards obtained: [50.62499049734501], Lows: [90], Highs: [79], Total time: 46561.679003
[32m[0907 03-29-29 @MBExp.py:144][0m ####################################################################
[32m[0907 03-29-29 @MBExp.py:145][0m Starting training iteration 57.
[32m[0907 03-29-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28922, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-29-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29024, current rewards: -37.16971, mean: -0.61950
[32m[0907 03-30-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29063, current rewards: -48.40781, mean: -0.44007
[32m[0907 03-30-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29087, current rewards: -64.79171, mean: -0.40495
[32m[0907 03-30-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29081, current rewards: -79.34033, mean: -0.37781
[32m[0907 03-30-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29182, current rewards: -109.13730, mean: -0.41976
[32m[0907 03-31-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29325, current rewards: -123.40442, mean: -0.39808
[32m[0907 03-31-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29573, current rewards: -138.52209, mean: -0.38478
[32m[0907 03-31-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29773, current rewards: -152.11257, mean: -0.37101
[32m[0907 03-31-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29892, current rewards: -162.69068, mean: -0.35368
[32m[0907 03-32-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29981, current rewards: -195.62938, mean: -0.38359
[32m[0907 03-32-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30052, current rewards: -208.55135, mean: -0.37241
[32m[0907 03-32-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30112, current rewards: -222.45542, mean: -0.36468
[32m[0907 03-32-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30164, current rewards: -237.82473, mean: -0.36034
[32m[0907 03-33-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30206, current rewards: -249.56971, mean: -0.35151
[32m[0907 03-33-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30265, current rewards: -275.80323, mean: -0.36290
[32m[0907 03-33-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30348, current rewards: -304.04624, mean: -0.37537
[32m[0907 03-33-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30418, current rewards: -315.20807, mean: -0.36652
[32m[0907 03-34-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30483, current rewards: -331.73853, mean: -0.36455
[32m[0907 03-34-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30537, current rewards: -344.90789, mean: -0.35928
[32m[0907 03-34-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30589, current rewards: -361.01778, mean: -0.35744
[32m[0907 03-34-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30635, current rewards: -396.50790, mean: -0.37406
[32m[0907 03-35-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30680, current rewards: -401.50928, mean: -0.36172
[32m[0907 03-35-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30716, current rewards: -411.17150, mean: -0.35446
[32m[0907 03-35-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30753, current rewards: -419.80902, mean: -0.34695
[32m[0907 03-35-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30784, current rewards: -448.51814, mean: -0.35597
[32m[0907 03-36-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30812, current rewards: -435.52556, mean: -0.33246
[32m[0907 03-36-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30836, current rewards: -422.79311, mean: -0.31088
[32m[0907 03-36-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30857, current rewards: -410.16751, mean: -0.29090
[32m[0907 03-37-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30881, current rewards: -398.84064, mean: -0.27318
[32m[0907 03-37-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30905, current rewards: -386.50277, mean: -0.25596
[32m[0907 03-37-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30928, current rewards: -373.25197, mean: -0.23926
[32m[0907 03-37-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30948, current rewards: -410.60055, mean: -0.25503
[32m[0907 03-38-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30967, current rewards: -400.71683, mean: -0.24140
[32m[0907 03-38-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30983, current rewards: -389.76675, mean: -0.22793
[32m[0907 03-38-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30998, current rewards: -378.71955, mean: -0.21518
[32m[0907 03-38-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31011, current rewards: -367.68775, mean: -0.20314
[32m[0907 03-39-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31027, current rewards: -358.21510, mean: -0.19259
[32m[0907 03-39-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31041, current rewards: -353.39827, mean: -0.18503
[32m[0907 03-39-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31052, current rewards: -348.39377, mean: -0.17775
[32m[0907 03-39-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31063, current rewards: -343.66317, mean: -0.17098
[32m[0907 03-40-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31075, current rewards: -338.93631, mean: -0.16453
[32m[0907 03-40-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31086, current rewards: -334.20493, mean: -0.15839
[32m[0907 03-40-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31098, current rewards: -329.47111, mean: -0.15253
[32m[0907 03-40-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31109, current rewards: -324.74063, mean: -0.14694
[32m[0907 03-41-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31118, current rewards: -319.98962, mean: -0.14159
[32m[0907 03-41-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31127, current rewards: -315.14729, mean: -0.13643
[32m[0907 03-41-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31133, current rewards: -310.36365, mean: -0.13151
[32m[0907 03-42-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31140, current rewards: -305.57802, mean: -0.12680
[32m[0907 03-42-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31148, current rewards: -300.79167, mean: -0.12227
[32m[0907 03-42-29 @Agent.py:117][0m Average action selection time: 0.3116
[32m[0907 03-42-29 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-42-29 @MBExp.py:227][0m Rewards obtained: [-296.96157908114145], Lows: [311], Highs: [67], Total time: 47341.223705
[32m[0907 03-44-17 @MBExp.py:144][0m ####################################################################
[32m[0907 03-44-17 @MBExp.py:145][0m Starting training iteration 58.
[32m[0907 03-44-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30041, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-44-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29869, current rewards: -57.65912, mean: -0.96099
[32m[0907 03-44-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30322, current rewards: -88.73601, mean: -0.80669
[32m[0907 03-45-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30164, current rewards: -121.91878, mean: -0.76199
[32m[0907 03-45-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30231, current rewards: -142.80611, mean: -0.68003
[32m[0907 03-45-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30229, current rewards: -141.95895, mean: -0.54600
[32m[0907 03-45-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30415, current rewards: -158.78083, mean: -0.51220
[32m[0907 03-46-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30530, current rewards: -183.58513, mean: -0.50996
[32m[0907 03-46-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30701, current rewards: -184.94435, mean: -0.45108
[32m[0907 03-46-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30877, current rewards: -207.99448, mean: -0.45216
[32m[0907 03-46-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31039, current rewards: -259.50990, mean: -0.50884
[32m[0907 03-47-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31155, current rewards: -316.97225, mean: -0.56602
[32m[0907 03-47-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31381, current rewards: -374.47678, mean: -0.61390
[32m[0907 03-47-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31519, current rewards: -412.77666, mean: -0.62542
[32m[0907 03-48-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31532, current rewards: -446.13042, mean: -0.62835
[32m[0907 03-48-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31702, current rewards: -505.00379, mean: -0.66448
[32m[0907 03-48-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31821, current rewards: -535.86999, mean: -0.66157
[32m[0907 03-48-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31861, current rewards: -557.26272, mean: -0.64798
[32m[0907 03-49-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31953, current rewards: -568.39690, mean: -0.62461
[32m[0907 03-49-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31988, current rewards: -598.23986, mean: -0.62317
[32m[0907 03-49-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32024, current rewards: -681.23986, mean: -0.67449
[32m[0907 03-49-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32004, current rewards: -781.23986, mean: -0.73702
[32m[0907 03-50-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31981, current rewards: -881.23986, mean: -0.79391
[32m[0907 03-50-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31964, current rewards: -981.23986, mean: -0.84590
[32m[0907 03-50-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31948, current rewards: -1081.23986, mean: -0.89359
[32m[0907 03-51-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31933, current rewards: -1181.23986, mean: -0.93749
[32m[0907 03-51-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31922, current rewards: -1281.23986, mean: -0.97805
[32m[0907 03-51-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31910, current rewards: -1381.23986, mean: -1.01562
[32m[0907 03-51-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31899, current rewards: -1481.23986, mean: -1.05052
[32m[0907 03-52-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31884, current rewards: -1581.23986, mean: -1.08304
[32m[0907 03-52-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31873, current rewards: -1681.23986, mean: -1.11340
[32m[0907 03-52-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31864, current rewards: -1781.23986, mean: -1.14182
[32m[0907 03-52-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31850, current rewards: -1881.23986, mean: -1.16847
[32m[0907 03-53-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31836, current rewards: -1981.23986, mean: -1.19352
[32m[0907 03-53-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31828, current rewards: -2081.23986, mean: -1.21710
[32m[0907 03-53-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31820, current rewards: -2181.23986, mean: -1.23934
[32m[0907 03-53-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31812, current rewards: -2281.23986, mean: -1.26035
[32m[0907 03-54-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31804, current rewards: -2381.23986, mean: -1.28024
[32m[0907 03-54-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31794, current rewards: -2481.23986, mean: -1.29908
[32m[0907 03-54-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31785, current rewards: -2581.23986, mean: -1.31696
[32m[0907 03-54-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31778, current rewards: -2681.23986, mean: -1.33395
[32m[0907 03-55-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31770, current rewards: -2781.23986, mean: -1.35012
[32m[0907 03-55-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31761, current rewards: -2881.23986, mean: -1.36552
[32m[0907 03-55-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31752, current rewards: -2981.23986, mean: -1.38020
[32m[0907 03-55-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31746, current rewards: -3081.23986, mean: -1.39423
[32m[0907 03-56-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31740, current rewards: -3181.23986, mean: -1.40763
[32m[0907 03-56-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31732, current rewards: -3281.23986, mean: -1.42045
[32m[0907 03-56-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31726, current rewards: -3381.23986, mean: -1.43273
[32m[0907 03-57-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31720, current rewards: -3481.23986, mean: -1.44450
[32m[0907 03-57-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31715, current rewards: -3581.23986, mean: -1.45579
[32m[0907 03-57-30 @Agent.py:117][0m Average action selection time: 0.3171
[32m[0907 03-57-30 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-57-30 @MBExp.py:227][0m Rewards obtained: [-3661.2398599005637], Lows: [1774], Highs: [196], Total time: 48134.677349
[32m[0907 03-59-20 @MBExp.py:144][0m ####################################################################
[32m[0907 03-59-20 @MBExp.py:145][0m Starting training iteration 59.
[32m[0907 03-59-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31071, current rewards: -7.90061, mean: -0.79006
[32m[0907 03-59-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29640, current rewards: -75.53200, mean: -1.25887
[32m[0907 03-59-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29383, current rewards: -74.63022, mean: -0.67846
[32m[0907 04-00-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29261, current rewards: -106.97285, mean: -0.66858
[32m[0907 04-00-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29279, current rewards: -100.42693, mean: -0.47822
[32m[0907 04-00-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29412, current rewards: -137.70133, mean: -0.52962
[32m[0907 04-00-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29606, current rewards: -187.70133, mean: -0.60549
[32m[0907 04-01-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29848, current rewards: -237.70133, mean: -0.66028
[32m[0907 04-01-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29971, current rewards: -287.70133, mean: -0.70171
[32m[0907 04-01-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30070, current rewards: -337.70133, mean: -0.73413
[32m[0907 04-01-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30155, current rewards: -387.70133, mean: -0.76020
[32m[0907 04-02-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30224, current rewards: -437.70133, mean: -0.78161
[32m[0907 04-02-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30278, current rewards: -487.70133, mean: -0.79951
[32m[0907 04-02-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30323, current rewards: -537.70133, mean: -0.81470
[32m[0907 04-02-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30370, current rewards: -587.70133, mean: -0.82775
[32m[0907 04-03-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30455, current rewards: -637.70133, mean: -0.83908
[32m[0907 04-03-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30530, current rewards: -687.70133, mean: -0.84901
[32m[0907 04-03-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30593, current rewards: -737.70133, mean: -0.85779
[32m[0907 04-03-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30647, current rewards: -787.70133, mean: -0.86561
[32m[0907 04-04-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30700, current rewards: -837.70133, mean: -0.87261
[32m[0907 04-04-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30746, current rewards: -887.70133, mean: -0.87891
[32m[0907 04-04-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30787, current rewards: -937.70133, mean: -0.88462
[32m[0907 04-05-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30825, current rewards: -987.70133, mean: -0.88982
[32m[0907 04-05-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30853, current rewards: -1037.70133, mean: -0.89457
[32m[0907 04-05-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30883, current rewards: -1087.70133, mean: -0.89893
[32m[0907 04-05-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30911, current rewards: -1137.70133, mean: -0.90294
[32m[0907 04-06-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30937, current rewards: -1187.70133, mean: -0.90664
[32m[0907 04-06-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30955, current rewards: -1237.70133, mean: -0.91007
[32m[0907 04-06-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30978, current rewards: -1287.70133, mean: -0.91326
[32m[0907 04-06-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30996, current rewards: -1337.70133, mean: -0.91623
[32m[0907 04-07-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31018, current rewards: -1387.70133, mean: -0.91901
[32m[0907 04-07-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31034, current rewards: -1437.70133, mean: -0.92160
[32m[0907 04-07-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31050, current rewards: -1487.70133, mean: -0.92404
[32m[0907 04-07-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31064, current rewards: -1537.70133, mean: -0.92633
[32m[0907 04-08-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31079, current rewards: -1587.70133, mean: -0.92848
[32m[0907 04-08-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31093, current rewards: -1637.70133, mean: -0.93051
[32m[0907 04-08-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31107, current rewards: -1687.70133, mean: -0.93243
[32m[0907 04-08-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31118, current rewards: -1737.70133, mean: -0.93425
[32m[0907 04-09-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31128, current rewards: -1787.70133, mean: -0.93597
[32m[0907 04-09-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31138, current rewards: -1837.70133, mean: -0.93760
[32m[0907 04-09-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31146, current rewards: -1887.70133, mean: -0.93915
[32m[0907 04-10-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31154, current rewards: -1937.70133, mean: -0.94063
[32m[0907 04-10-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31163, current rewards: -1987.70133, mean: -0.94204
[32m[0907 04-10-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31171, current rewards: -2037.70133, mean: -0.94338
[32m[0907 04-10-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31177, current rewards: -2087.70133, mean: -0.94466
[32m[0907 04-11-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31184, current rewards: -2137.70133, mean: -0.94589
[32m[0907 04-11-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31189, current rewards: -2187.70133, mean: -0.94706
[32m[0907 04-11-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31197, current rewards: -2237.70133, mean: -0.94818
[32m[0907 04-11-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31205, current rewards: -2287.70133, mean: -0.94925
[32m[0907 04-12-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31212, current rewards: -2337.70133, mean: -0.95029
[32m[0907 04-12-21 @Agent.py:117][0m Average action selection time: 0.3122
[32m[0907 04-12-21 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-12-21 @MBExp.py:227][0m Rewards obtained: [-2377.7013310368748], Lows: [59], Highs: [2286], Total time: 48915.757917999996
[32m[0907 04-14-12 @MBExp.py:144][0m ####################################################################
[32m[0907 04-14-12 @MBExp.py:145][0m Starting training iteration 60.
[32m[0907 04-14-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28931, current rewards: -3.67922, mean: -0.36792
[32m[0907 04-14-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29040, current rewards: -11.38557, mean: -0.18976
[32m[0907 04-14-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29058, current rewards: -6.44653, mean: -0.05860
[32m[0907 04-14-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29052, current rewards: -1.63890, mean: -0.01024
[32m[0907 04-15-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29104, current rewards: 11.65162, mean: 0.05548
[32m[0907 04-15-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29273, current rewards: 17.42564, mean: 0.06702
[32m[0907 04-15-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29487, current rewards: 23.10271, mean: 0.07452
[32m[0907 04-16-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29740, current rewards: 28.77978, mean: 0.07994
[32m[0907 04-16-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29878, current rewards: -20.10668, mean: -0.04904
[32m[0907 04-16-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29990, current rewards: -70.10668, mean: -0.15241
[32m[0907 04-16-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30082, current rewards: -120.10668, mean: -0.23550
[32m[0907 04-17-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30158, current rewards: -170.10668, mean: -0.30376
[32m[0907 04-17-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30216, current rewards: -220.10668, mean: -0.36083
[32m[0907 04-17-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30264, current rewards: -270.10668, mean: -0.40925
[32m[0907 04-17-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30316, current rewards: -320.10668, mean: -0.45085
[32m[0907 04-18-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30416, current rewards: -370.10668, mean: -0.48698
[32m[0907 04-18-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30501, current rewards: -420.10668, mean: -0.51865
[32m[0907 04-18-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30570, current rewards: -470.10668, mean: -0.54664
[32m[0907 04-18-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30635, current rewards: -520.10668, mean: -0.57155
[32m[0907 04-19-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30694, current rewards: -570.10668, mean: -0.59386
[32m[0907 04-19-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30745, current rewards: -620.10668, mean: -0.61397
[32m[0907 04-19-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30789, current rewards: -670.10668, mean: -0.63218
[32m[0907 04-19-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30824, current rewards: -720.10668, mean: -0.64874
[32m[0907 04-20-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30860, current rewards: -770.10668, mean: -0.66389
[32m[0907 04-20-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30893, current rewards: -820.10668, mean: -0.67777
[32m[0907 04-20-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30922, current rewards: -870.10668, mean: -0.69056
[32m[0907 04-20-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30948, current rewards: -920.10668, mean: -0.70237
[32m[0907 04-21-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30969, current rewards: -970.10668, mean: -0.71331
[32m[0907 04-21-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30990, current rewards: -1020.10668, mean: -0.72348
[32m[0907 04-21-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31011, current rewards: -1070.10668, mean: -0.73295
[32m[0907 04-22-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31028, current rewards: -1120.10668, mean: -0.74179
[32m[0907 04-22-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31044, current rewards: -1170.10668, mean: -0.75007
[32m[0907 04-22-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31059, current rewards: -1220.10668, mean: -0.75783
[32m[0907 04-22-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31073, current rewards: -1270.10668, mean: -0.76512
[32m[0907 04-23-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31086, current rewards: -1320.10668, mean: -0.77199
[32m[0907 04-23-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31097, current rewards: -1370.10668, mean: -0.77847
[32m[0907 04-23-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31109, current rewards: -1420.10668, mean: -0.78459
[32m[0907 04-23-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31122, current rewards: -1470.10668, mean: -0.79038
[32m[0907 04-24-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31132, current rewards: -1520.10668, mean: -0.79587
[32m[0907 04-24-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31140, current rewards: -1570.10668, mean: -0.80107
[32m[0907 04-24-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31148, current rewards: -1620.10668, mean: -0.80602
[32m[0907 04-24-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31155, current rewards: -1670.10668, mean: -0.81073
[32m[0907 04-25-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31163, current rewards: -1720.10668, mean: -0.81522
[32m[0907 04-25-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31170, current rewards: -1770.10668, mean: -0.81949
[32m[0907 04-25-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31178, current rewards: -1820.10668, mean: -0.82358
[32m[0907 04-25-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31182, current rewards: -1870.10668, mean: -0.82748
[32m[0907 04-26-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31188, current rewards: -1920.10668, mean: -0.83122
[32m[0907 04-26-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31195, current rewards: -1970.10668, mean: -0.83479
[32m[0907 04-26-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31201, current rewards: -2020.10668, mean: -0.83822
[32m[0907 04-27-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31208, current rewards: -2070.10668, mean: -0.84151
[32m[0907 04-27-13 @Agent.py:117][0m Average action selection time: 0.3121
[32m[0907 04-27-13 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-27-13 @MBExp.py:227][0m Rewards obtained: [-2110.1066821570453], Lows: [0], Highs: [2154], Total time: 49696.738810999996
[32m[0907 04-29-07 @MBExp.py:144][0m ####################################################################
[32m[0907 04-29-07 @MBExp.py:145][0m Starting training iteration 61.
[32m[0907 04-29-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28879, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-29-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29036, current rewards: -82.40461, mean: -1.37341
[32m[0907 04-29-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29043, current rewards: -182.40461, mean: -1.65822
[32m[0907 04-29-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29037, current rewards: -282.40461, mean: -1.76503
[32m[0907 04-30-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29062, current rewards: -382.40461, mean: -1.82097
[32m[0907 04-30-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29220, current rewards: -482.40461, mean: -1.85540
[32m[0907 04-30-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29414, current rewards: -582.40461, mean: -1.87872
[32m[0907 04-30-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29651, current rewards: -682.40461, mean: -1.89557
[32m[0907 04-31-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29802, current rewards: -782.40461, mean: -1.90830
[32m[0907 04-31-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29924, current rewards: -882.40461, mean: -1.91827
[32m[0907 04-31-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30015, current rewards: -982.40461, mean: -1.92628
[32m[0907 04-31-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30089, current rewards: -1082.40461, mean: -1.93287
[32m[0907 04-32-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30148, current rewards: -1182.40461, mean: -1.93837
[32m[0907 04-32-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30201, current rewards: -1282.40461, mean: -1.94304
[32m[0907 04-32-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30257, current rewards: -1382.40461, mean: -1.94705
[32m[0907 04-32-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30342, current rewards: -1482.40461, mean: -1.95053
[32m[0907 04-33-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30425, current rewards: -1582.40461, mean: -1.95359
[32m[0907 04-33-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30496, current rewards: -1682.40461, mean: -1.95628
[32m[0907 04-33-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30561, current rewards: -1782.40461, mean: -1.95869
[32m[0907 04-34-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30614, current rewards: -1882.40461, mean: -1.96084
[32m[0907 04-34-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30665, current rewards: -1982.40461, mean: -1.96278
[32m[0907 04-34-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30713, current rewards: -2082.40461, mean: -1.96453
[32m[0907 04-34-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30753, current rewards: -2182.40461, mean: -1.96613
[32m[0907 04-35-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30793, current rewards: -2282.40461, mean: -1.96759
[32m[0907 04-35-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30827, current rewards: -2382.40461, mean: -1.96893
[32m[0907 04-35-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30851, current rewards: -2482.40461, mean: -1.97016
[32m[0907 04-35-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30875, current rewards: -2582.40461, mean: -1.97130
[32m[0907 04-36-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30899, current rewards: -2682.40461, mean: -1.97236
[32m[0907 04-36-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30921, current rewards: -2782.40461, mean: -1.97334
[32m[0907 04-36-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30942, current rewards: -2882.40461, mean: -1.97425
[32m[0907 04-36-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30959, current rewards: -2982.40461, mean: -1.97510
[32m[0907 04-37-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30976, current rewards: -3082.40461, mean: -1.97590
[32m[0907 04-37-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30991, current rewards: -3182.40461, mean: -1.97665
[32m[0907 04-37-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31003, current rewards: -3282.40461, mean: -1.97735
[32m[0907 04-37-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31015, current rewards: -3382.40461, mean: -1.97801
[32m[0907 04-38-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31026, current rewards: -3482.40461, mean: -1.97864
[32m[0907 04-38-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31038, current rewards: -3582.40461, mean: -1.97923
[32m[0907 04-38-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31048, current rewards: -3682.40461, mean: -1.97979
[32m[0907 04-39-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31058, current rewards: -3782.40461, mean: -1.98032
[32m[0907 04-39-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31067, current rewards: -3882.40461, mean: -1.98082
[32m[0907 04-39-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31077, current rewards: -3982.40461, mean: -1.98130
[32m[0907 04-39-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31087, current rewards: -4082.40461, mean: -1.98175
[32m[0907 04-40-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31096, current rewards: -4182.40461, mean: -1.98218
[32m[0907 04-40-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31103, current rewards: -4282.40461, mean: -1.98259
[32m[0907 04-40-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31108, current rewards: -4382.40461, mean: -1.98299
[32m[0907 04-40-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31115, current rewards: -4482.40461, mean: -1.98336
[32m[0907 04-41-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31120, current rewards: -4582.40461, mean: -1.98372
[32m[0907 04-41-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31128, current rewards: -4682.40461, mean: -1.98407
[32m[0907 04-41-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31133, current rewards: -4782.40461, mean: -1.98440
[32m[0907 04-41-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31136, current rewards: -4882.40461, mean: -1.98472
[32m[0907 04-42-06 @Agent.py:117][0m Average action selection time: 0.3114
[32m[0907 04-42-06 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-42-06 @MBExp.py:227][0m Rewards obtained: [-4962.404609068035], Lows: [2472], Highs: [20], Total time: 50475.926551
[32m[0907 04-44-01 @MBExp.py:144][0m ####################################################################
[32m[0907 04-44-01 @MBExp.py:145][0m Starting training iteration 62.
[32m[0907 04-44-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29038, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-44-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30170, current rewards: -77.66987, mean: -1.29450
[32m[0907 04-44-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29666, current rewards: -73.94570, mean: -0.67223
[32m[0907 04-44-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29486, current rewards: -67.28657, mean: -0.42054
[32m[0907 04-45-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29390, current rewards: -53.81701, mean: -0.25627
[32m[0907 04-45-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29552, current rewards: -93.33788, mean: -0.35899
[32m[0907 04-45-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29617, current rewards: -89.20972, mean: -0.28777
[32m[0907 04-45-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29681, current rewards: -83.73547, mean: -0.23260
[32m[0907 04-46-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29797, current rewards: -78.25308, mean: -0.19086
[32m[0907 04-46-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29913, current rewards: -72.77066, mean: -0.15820
[32m[0907 04-46-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30006, current rewards: -89.77160, mean: -0.17602
[32m[0907 04-46-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30092, current rewards: -84.14237, mean: -0.15025
[32m[0907 04-47-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30159, current rewards: -78.87746, mean: -0.12931
[32m[0907 04-47-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30212, current rewards: -73.42341, mean: -0.11125
[32m[0907 04-47-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30264, current rewards: -67.96515, mean: -0.09573
[32m[0907 04-47-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30360, current rewards: -62.50723, mean: -0.08225
[32m[0907 04-48-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30624, current rewards: -78.74662, mean: -0.09722
[32m[0907 04-48-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30764, current rewards: -137.70802, mean: -0.16013
[32m[0907 04-48-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30859, current rewards: -225.23716, mean: -0.24751
[32m[0907 04-48-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30923, current rewards: -304.39495, mean: -0.31708
[32m[0907 04-49-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30955, current rewards: -404.39495, mean: -0.40039
[32m[0907 04-49-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30981, current rewards: -504.39495, mean: -0.47584
[32m[0907 04-49-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31006, current rewards: -604.39495, mean: -0.54450
[32m[0907 04-50-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31028, current rewards: -704.39495, mean: -0.60724
[32m[0907 04-50-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31052, current rewards: -804.39495, mean: -0.66479
[32m[0907 04-50-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31072, current rewards: -904.39495, mean: -0.71777
[32m[0907 04-50-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31089, current rewards: -1004.39495, mean: -0.76671
[32m[0907 04-51-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31105, current rewards: -1104.39495, mean: -0.81206
[32m[0907 04-51-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31123, current rewards: -1204.39495, mean: -0.85418
[32m[0907 04-51-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31135, current rewards: -1304.39495, mean: -0.89342
[32m[0907 04-51-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31150, current rewards: -1404.39495, mean: -0.93006
[32m[0907 04-52-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31163, current rewards: -1504.39495, mean: -0.96436
[32m[0907 04-52-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31173, current rewards: -1604.39495, mean: -0.99652
[32m[0907 04-52-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31184, current rewards: -1704.39495, mean: -1.02674
[32m[0907 04-52-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31190, current rewards: -1804.39495, mean: -1.05520
[32m[0907 04-53-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31200, current rewards: -1904.39495, mean: -1.08204
[32m[0907 04-53-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31210, current rewards: -2004.39495, mean: -1.10740
[32m[0907 04-53-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31219, current rewards: -2104.39495, mean: -1.13140
[32m[0907 04-53-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31228, current rewards: -2204.39495, mean: -1.15413
[32m[0907 04-54-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31235, current rewards: -2304.39495, mean: -1.17571
[32m[0907 04-54-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31241, current rewards: -2404.39495, mean: -1.19622
[32m[0907 04-54-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31245, current rewards: -2504.39495, mean: -1.21573
[32m[0907 04-55-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31252, current rewards: -2604.39495, mean: -1.23431
[32m[0907 04-55-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31258, current rewards: -2704.39495, mean: -1.25203
[32m[0907 04-55-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31263, current rewards: -2804.39495, mean: -1.26896
[32m[0907 04-55-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31268, current rewards: -2904.39495, mean: -1.28513
[32m[0907 04-56-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31270, current rewards: -3004.39495, mean: -1.30060
[32m[0907 04-56-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31272, current rewards: -3104.39495, mean: -1.31542
[32m[0907 04-56-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31275, current rewards: -3204.39495, mean: -1.32962
[32m[0907 04-56-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31281, current rewards: -3304.39495, mean: -1.34325
[32m[0907 04-57-03 @Agent.py:117][0m Average action selection time: 0.3128
[32m[0907 04-57-03 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-57-04 @MBExp.py:227][0m Rewards obtained: [-3384.394946440905], Lows: [1720], Highs: [41], Total time: 51258.700065
[32m[0907 04-59-00 @MBExp.py:144][0m ####################################################################
[32m[0907 04-59-00 @MBExp.py:145][0m Starting training iteration 63.
[32m[0907 04-59-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.48410, current rewards: -5.80418, mean: -0.58042
[32m[0907 04-59-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34272, current rewards: -26.60377, mean: -0.44340
[32m[0907 04-59-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31901, current rewards: -30.37211, mean: -0.27611
[32m[0907 04-59-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30984, current rewards: -35.17241, mean: -0.21983
[32m[0907 05-00-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30598, current rewards: -31.03754, mean: -0.14780
[32m[0907 05-00-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30458, current rewards: -26.52236, mean: -0.10201
[32m[0907 05-00-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30360, current rewards: -22.00589, mean: -0.07099
[32m[0907 05-00-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30296, current rewards: -17.49076, mean: -0.04859
[32m[0907 05-01-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30350, current rewards: -12.97403, mean: -0.03164
[32m[0907 05-01-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30399, current rewards: -8.45609, mean: -0.01838
[32m[0907 05-01-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30439, current rewards: -3.94047, mean: -0.00773
[32m[0907 05-01-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30476, current rewards: 0.95323, mean: 0.00170
[32m[0907 05-02-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30505, current rewards: -14.10674, mean: -0.02313
[32m[0907 05-02-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30528, current rewards: -8.91065, mean: -0.01350
[32m[0907 05-02-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30578, current rewards: -3.86159, mean: -0.00544
[32m[0907 05-02-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30661, current rewards: 1.17945, mean: 0.00155
[32m[0907 05-03-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30719, current rewards: 6.21944, mean: 0.00768
[32m[0907 05-03-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30768, current rewards: 7.06431, mean: 0.00821
[32m[0907 05-03-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30807, current rewards: -25.88138, mean: -0.02844
[32m[0907 05-03-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30846, current rewards: -20.75106, mean: -0.02162
[32m[0907 05-04-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30884, current rewards: -14.98720, mean: -0.01484
[32m[0907 05-04-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30921, current rewards: -9.84610, mean: -0.00929
[32m[0907 05-04-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30953, current rewards: -4.70167, mean: -0.00424
[32m[0907 05-05-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30982, current rewards: 0.44170, mean: 0.00038
[32m[0907 05-05-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31007, current rewards: 5.59088, mean: 0.00462
[32m[0907 05-05-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31027, current rewards: 9.96172, mean: 0.00791
[32m[0907 05-05-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31046, current rewards: 14.16525, mean: 0.01081
[32m[0907 05-06-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31065, current rewards: 18.78783, mean: 0.01381
[32m[0907 05-06-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31080, current rewards: 21.23739, mean: 0.01506
[32m[0907 05-06-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31098, current rewards: 25.76586, mean: 0.01765
[32m[0907 05-06-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31115, current rewards: 30.32093, mean: 0.02008
[32m[0907 05-07-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31130, current rewards: 34.87117, mean: 0.02235
[32m[0907 05-07-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31144, current rewards: 1.61105, mean: 0.00100
[32m[0907 05-07-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31160, current rewards: 6.04480, mean: 0.00364
[32m[0907 05-07-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31173, current rewards: 10.27599, mean: 0.00601
[32m[0907 05-08-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31185, current rewards: 14.50144, mean: 0.00824
[32m[0907 05-08-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31196, current rewards: 22.01032, mean: 0.01216
[32m[0907 05-08-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31204, current rewards: -6.27311, mean: -0.00337
[32m[0907 05-08-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31211, current rewards: -56.27311, mean: -0.02946
[32m[0907 05-09-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31221, current rewards: -106.27311, mean: -0.05422
[32m[0907 05-09-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31229, current rewards: -156.27311, mean: -0.07775
[32m[0907 05-09-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31234, current rewards: -206.27311, mean: -0.10013
[32m[0907 05-10-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31240, current rewards: -256.27311, mean: -0.12146
[32m[0907 05-10-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31246, current rewards: -306.27311, mean: -0.14179
[32m[0907 05-10-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31251, current rewards: -356.27311, mean: -0.16121
[32m[0907 05-10-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31259, current rewards: -406.27311, mean: -0.17977
[32m[0907 05-11-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31263, current rewards: -456.27311, mean: -0.19752
[32m[0907 05-11-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31270, current rewards: -506.27311, mean: -0.21452
[32m[0907 05-11-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31275, current rewards: -556.27311, mean: -0.23082
[32m[0907 05-11-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31280, current rewards: -606.27311, mean: -0.24645
[32m[0907 05-12-03 @Agent.py:117][0m Average action selection time: 0.3128
[32m[0907 05-12-03 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-12-03 @MBExp.py:227][0m Rewards obtained: [-646.2731124568221], Lows: [60], Highs: [705], Total time: 52041.461371
[32m[0907 05-14-02 @MBExp.py:144][0m ####################################################################
[32m[0907 05-14-02 @MBExp.py:145][0m Starting training iteration 64.
[32m[0907 05-14-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29862, current rewards: 1.75773, mean: 0.17577
[32m[0907 05-14-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29608, current rewards: 10.57410, mean: 0.17624
[32m[0907 05-14-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29356, current rewards: 19.36277, mean: 0.17603
[32m[0907 05-14-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29277, current rewards: 28.15143, mean: 0.17595
[32m[0907 05-15-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29238, current rewards: 36.94009, mean: 0.17591
[32m[0907 05-15-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29371, current rewards: 45.72876, mean: 0.17588
[32m[0907 05-15-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29437, current rewards: 16.89267, mean: 0.05449
[32m[0907 05-15-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29507, current rewards: -33.10733, mean: -0.09196
[32m[0907 05-16-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29560, current rewards: -83.10733, mean: -0.20270
[32m[0907 05-16-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29639, current rewards: -133.10733, mean: -0.28936
[32m[0907 05-16-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29758, current rewards: -183.10733, mean: -0.35903
[32m[0907 05-16-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29855, current rewards: -233.10733, mean: -0.41626
[32m[0907 05-17-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29940, current rewards: -283.10733, mean: -0.46411
[32m[0907 05-17-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30010, current rewards: -333.10733, mean: -0.50471
[32m[0907 05-17-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30094, current rewards: -383.10733, mean: -0.53959
[32m[0907 05-17-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30191, current rewards: -433.10733, mean: -0.56988
[32m[0907 05-18-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30278, current rewards: -483.10733, mean: -0.59643
[32m[0907 05-18-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30358, current rewards: -533.10733, mean: -0.61989
[32m[0907 05-18-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30434, current rewards: -583.10733, mean: -0.64078
[32m[0907 05-18-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30503, current rewards: -633.10733, mean: -0.65949
[32m[0907 05-19-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30559, current rewards: -683.10733, mean: -0.67634
[32m[0907 05-19-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30609, current rewards: -733.10733, mean: -0.69161
[32m[0907 05-19-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30656, current rewards: -783.10733, mean: -0.70550
[32m[0907 05-19-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30701, current rewards: -833.10733, mean: -0.71820
[32m[0907 05-20-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30736, current rewards: -883.10733, mean: -0.72984
[32m[0907 05-20-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30770, current rewards: -933.10733, mean: -0.74056
[32m[0907 05-20-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30799, current rewards: -983.10733, mean: -0.75046
[32m[0907 05-21-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30829, current rewards: -1033.10733, mean: -0.75964
[32m[0907 05-21-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30857, current rewards: -1083.10733, mean: -0.76816
[32m[0907 05-21-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30885, current rewards: -1133.10733, mean: -0.77610
[32m[0907 05-21-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30903, current rewards: -1183.10733, mean: -0.78351
[32m[0907 05-22-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30923, current rewards: -1233.10733, mean: -0.79045
[32m[0907 05-22-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30941, current rewards: -1258.20627, mean: -0.78149
[32m[0907 05-22-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30958, current rewards: -1253.37539, mean: -0.75505
[32m[0907 05-22-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30972, current rewards: -1248.52021, mean: -0.73013
[32m[0907 05-23-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30987, current rewards: -1243.66904, mean: -0.70663
[32m[0907 05-23-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31028, current rewards: -1275.37466, mean: -0.70463
[32m[0907 05-23-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31040, current rewards: -1270.49271, mean: -0.68306
[32m[0907 05-23-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31053, current rewards: -1265.52491, mean: -0.66258
[32m[0907 05-24-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31061, current rewards: -1260.40956, mean: -0.64307
[32m[0907 05-24-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31072, current rewards: -1255.28908, mean: -0.62452
[32m[0907 05-24-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31080, current rewards: -1273.58017, mean: -0.61824
[32m[0907 05-24-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31091, current rewards: -1268.15681, mean: -0.60102
[32m[0907 05-25-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31100, current rewards: -1262.71743, mean: -0.58459
[32m[0907 05-25-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31106, current rewards: -1257.42740, mean: -0.56897
[32m[0907 05-25-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31113, current rewards: -1253.63087, mean: -0.55470
[32m[0907 05-26-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31119, current rewards: -1248.37109, mean: -0.54042
[32m[0907 05-26-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31128, current rewards: -1243.14355, mean: -0.52676
[32m[0907 05-26-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31143, current rewards: -1274.44388, mean: -0.52881
[32m[0907 05-26-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31174, current rewards: -1334.67858, mean: -0.54255
[32m[0907 05-27-02 @Agent.py:117][0m Average action selection time: 0.3118
[32m[0907 05-27-02 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-27-02 @MBExp.py:227][0m Rewards obtained: [-1409.583984941113], Lows: [95], Highs: [1353], Total time: 52821.603974
[32m[0907 05-29-02 @MBExp.py:144][0m ####################################################################
[32m[0907 05-29-02 @MBExp.py:145][0m Starting training iteration 65.
[32m[0907 05-29-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32816, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-29-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30892, current rewards: -36.83373, mean: -0.61390
[32m[0907 05-29-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30245, current rewards: -48.66403, mean: -0.44240
[32m[0907 05-29-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29870, current rewards: -45.37682, mean: -0.28361
[32m[0907 05-30-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29776, current rewards: -48.00284, mean: -0.22858
[32m[0907 05-30-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29793, current rewards: -51.12052, mean: -0.19662
[32m[0907 05-30-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29765, current rewards: -43.47452, mean: -0.14024
[32m[0907 05-30-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29788, current rewards: -35.96086, mean: -0.09989
[32m[0907 05-31-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29790, current rewards: -29.86113, mean: -0.07283
[32m[0907 05-31-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29804, current rewards: -23.11179, mean: -0.05024
[32m[0907 05-31-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29900, current rewards: -16.06166, mean: -0.03149
[32m[0907 05-31-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29980, current rewards: -9.59749, mean: -0.01714
[32m[0907 05-32-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30049, current rewards: -3.09650, mean: -0.00508
[32m[0907 05-32-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30103, current rewards: 3.06066, mean: 0.00464
[32m[0907 05-32-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30215, current rewards: -24.95384, mean: -0.03515
[32m[0907 05-32-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30332, current rewards: -41.88884, mean: -0.05512
[32m[0907 05-33-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30416, current rewards: -41.03726, mean: -0.05066
[32m[0907 05-33-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30488, current rewards: -36.38620, mean: -0.04231
[32m[0907 05-33-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30545, current rewards: -31.73780, mean: -0.03488
[32m[0907 05-33-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30600, current rewards: -25.66494, mean: -0.02673
[32m[0907 05-34-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30645, current rewards: -19.59198, mean: -0.01940
[32m[0907 05-34-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30692, current rewards: -14.88717, mean: -0.01404
[32m[0907 05-34-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30735, current rewards: -10.18088, mean: -0.00917
[32m[0907 05-35-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30771, current rewards: -5.47613, mean: -0.00472
[32m[0907 05-35-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30804, current rewards: -0.76442, mean: -0.00063
[32m[0907 05-35-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30836, current rewards: 3.94412, mean: 0.00313
[32m[0907 05-35-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30860, current rewards: 8.65047, mean: 0.00660
[32m[0907 05-36-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30880, current rewards: 13.33270, mean: 0.00980
[32m[0907 05-36-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30905, current rewards: -3.99504, mean: -0.00283
[32m[0907 05-36-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30926, current rewards: 1.38767, mean: 0.00095
[32m[0907 05-36-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30943, current rewards: 6.69367, mean: 0.00443
[32m[0907 05-37-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30958, current rewards: 12.00229, mean: 0.00769
[32m[0907 05-37-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30974, current rewards: 17.30643, mean: 0.01075
[32m[0907 05-37-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30990, current rewards: 22.61539, mean: 0.01362
[32m[0907 05-37-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31003, current rewards: 27.91775, mean: 0.01633
[32m[0907 05-38-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31020, current rewards: 33.22602, mean: 0.01888
[32m[0907 05-38-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31036, current rewards: 43.42627, mean: 0.02399
[32m[0907 05-38-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31049, current rewards: 49.05947, mean: 0.02638
[32m[0907 05-38-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31060, current rewards: 35.64739, mean: 0.01866
[32m[0907 05-39-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31070, current rewards: -15.58588, mean: -0.00795
[32m[0907 05-39-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31080, current rewards: -9.49608, mean: -0.00472
[32m[0907 05-39-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31088, current rewards: -3.45081, mean: -0.00168
[32m[0907 05-39-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31101, current rewards: 2.59445, mean: 0.00123
[32m[0907 05-40-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31110, current rewards: -40.68011, mean: -0.01883
[32m[0907 05-40-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31117, current rewards: -90.68011, mean: -0.04103
[32m[0907 05-40-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31125, current rewards: -140.68011, mean: -0.06225
[32m[0907 05-41-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31132, current rewards: -190.68011, mean: -0.08255
[32m[0907 05-41-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31140, current rewards: -219.15257, mean: -0.09286
[32m[0907 05-41-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31147, current rewards: -212.57928, mean: -0.08821
[32m[0907 05-41-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31155, current rewards: -206.24683, mean: -0.08384
[32m[0907 05-42-02 @Agent.py:117][0m Average action selection time: 0.3116
[32m[0907 05-42-02 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-42-02 @MBExp.py:227][0m Rewards obtained: [-201.1882211593838], Lows: [123], Highs: [245], Total time: 53601.289485
[32m[0907 05-44-05 @MBExp.py:144][0m ####################################################################
[32m[0907 05-44-05 @MBExp.py:145][0m Starting training iteration 66.
[32m[0907 05-44-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49836, current rewards: 0.65059, mean: 0.06506
[32m[0907 05-44-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36722, current rewards: -38.71137, mean: -0.64519
[32m[0907 05-44-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33215, current rewards: -38.71918, mean: -0.35199
[32m[0907 05-44-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31910, current rewards: -33.81498, mean: -0.21134
[32m[0907 05-45-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31254, current rewards: -28.60030, mean: -0.13619
[32m[0907 05-45-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30983, current rewards: -23.52092, mean: -0.09047
[32m[0907 05-45-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30744, current rewards: -18.67648, mean: -0.06025
[32m[0907 05-45-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30623, current rewards: -13.51922, mean: -0.03755
[32m[0907 05-46-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30527, current rewards: -8.36289, mean: -0.02040
[32m[0907 05-46-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30455, current rewards: -3.48669, mean: -0.00758
[32m[0907 05-46-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30482, current rewards: 1.52431, mean: 0.00299
[32m[0907 05-46-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30510, current rewards: 6.41462, mean: 0.01145
[32m[0907 05-47-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30532, current rewards: 11.50190, mean: 0.01886
[32m[0907 05-47-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30545, current rewards: 16.56599, mean: 0.02510
[32m[0907 05-47-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30608, current rewards: 21.62949, mean: 0.03046
[32m[0907 05-47-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30675, current rewards: 26.68645, mean: 0.03511
[32m[0907 05-48-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30734, current rewards: 28.50054, mean: 0.03519
[32m[0907 05-48-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30782, current rewards: 15.30843, mean: 0.01780
[32m[0907 05-48-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30825, current rewards: 21.68719, mean: 0.02383
[32m[0907 05-49-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30866, current rewards: -9.45663, mean: -0.00985
[32m[0907 05-49-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30897, current rewards: -4.76249, mean: -0.00472
[32m[0907 05-49-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30927, current rewards: 0.79573, mean: 0.00075
[32m[0907 05-49-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30956, current rewards: 6.45777, mean: 0.00582
[32m[0907 05-50-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30982, current rewards: 12.12183, mean: 0.01045
[32m[0907 05-50-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31003, current rewards: 17.78891, mean: 0.01470
[32m[0907 05-50-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31023, current rewards: 23.46068, mean: 0.01862
[32m[0907 05-50-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31043, current rewards: 28.05801, mean: 0.02142
[32m[0907 05-51-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31063, current rewards: 31.58798, mean: 0.02323
[32m[0907 05-51-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31082, current rewards: 35.82809, mean: 0.02541
[32m[0907 05-51-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31098, current rewards: 40.23424, mean: 0.02756
[32m[0907 05-51-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31110, current rewards: 44.64880, mean: 0.02957
[32m[0907 05-52-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31123, current rewards: 49.05862, mean: 0.03145
[32m[0907 05-52-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31136, current rewards: 53.47264, mean: 0.03321
[32m[0907 05-52-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31148, current rewards: 57.88067, mean: 0.03487
[32m[0907 05-52-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31160, current rewards: 62.28777, mean: 0.03643
[32m[0907 05-53-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31170, current rewards: 66.83836, mean: 0.03798
[32m[0907 05-53-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31178, current rewards: 71.51999, mean: 0.03951
[32m[0907 05-53-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31187, current rewards: 75.91967, mean: 0.04082
[32m[0907 05-54-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31195, current rewards: 80.32003, mean: 0.04205
[32m[0907 05-54-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31203, current rewards: 84.71503, mean: 0.04322
[32m[0907 05-54-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31275, current rewards: 43.63766, mean: 0.02171
[32m[0907 05-54-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31415, current rewards: -26.72362, mean: -0.01297
[32m[0907 05-55-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31594, current rewards: -79.54606, mean: -0.03770
[32m[0907 05-55-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31865, current rewards: -143.57026, mean: -0.06647
[32m[0907 05-55-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31863, current rewards: -151.81217, mean: -0.06869
[32m[0907 05-56-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31852, current rewards: -167.62067, mean: -0.07417
[32m[0907 05-56-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31842, current rewards: -178.23650, mean: -0.07716
[32m[0907 05-56-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31833, current rewards: -188.83628, mean: -0.08002
[32m[0907 05-56-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31843, current rewards: -209.38214, mean: -0.08688
[32m[0907 05-57-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31849, current rewards: -219.21269, mean: -0.08911
[32m[0907 05-57-22 @Agent.py:117][0m Average action selection time: 0.3185
[32m[0907 05-57-22 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-57-22 @MBExp.py:227][0m Rewards obtained: [-230.677725950386], Lows: [168], Highs: [124], Total time: 54398.322949
[32m[0907 05-59-25 @MBExp.py:144][0m ####################################################################
[32m[0907 05-59-25 @MBExp.py:145][0m Starting training iteration 67.
[32m[0907 05-59-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.44458, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-59-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36463, current rewards: -65.30514, mean: -1.08842
[32m[0907 06-00-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33273, current rewards: -121.64896, mean: -1.10590
[32m[0907 06-00-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31954, current rewards: -133.81372, mean: -0.83634
[32m[0907 06-00-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31385, current rewards: -129.06868, mean: -0.61461
[32m[0907 06-00-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31074, current rewards: -124.31048, mean: -0.47812
[32m[0907 06-01-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30888, current rewards: -119.55464, mean: -0.38566
[32m[0907 06-01-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30768, current rewards: -114.79203, mean: -0.31887
[32m[0907 06-01-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30681, current rewards: -110.03664, mean: -0.26838
[32m[0907 06-01-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30704, current rewards: -105.62777, mean: -0.22963
[32m[0907 06-02-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30723, current rewards: -99.85234, mean: -0.19579
[32m[0907 06-02-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30735, current rewards: -94.82051, mean: -0.16932
[32m[0907 06-02-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30743, current rewards: -89.78869, mean: -0.14719
[32m[0907 06-02-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30805, current rewards: -84.76583, mean: -0.12843
[32m[0907 06-03-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30860, current rewards: -79.73594, mean: -0.11230
[32m[0907 06-03-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30940, current rewards: -125.38376, mean: -0.16498
[32m[0907 06-03-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30983, current rewards: -185.25768, mean: -0.22871
[32m[0907 06-03-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31025, current rewards: -179.81572, mean: -0.20909
[32m[0907 06-04-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31056, current rewards: -174.79276, mean: -0.19208
[32m[0907 06-04-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31090, current rewards: -169.94168, mean: -0.17702
[32m[0907 06-04-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31119, current rewards: -164.54966, mean: -0.16292
[32m[0907 06-04-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31148, current rewards: -159.15432, mean: -0.15015
[32m[0907 06-05-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31167, current rewards: -153.75647, mean: -0.13852
[32m[0907 06-05-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31186, current rewards: -148.35836, mean: -0.12790
[32m[0907 06-05-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31206, current rewards: -142.96318, mean: -0.11815
[32m[0907 06-05-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31221, current rewards: -137.56967, mean: -0.10918
[32m[0907 06-06-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31233, current rewards: -132.16554, mean: -0.10089
[32m[0907 06-06-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31247, current rewards: -131.73591, mean: -0.09686
[32m[0907 06-06-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31255, current rewards: -190.61720, mean: -0.13519
[32m[0907 06-07-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31277, current rewards: -230.90571, mean: -0.15815
[32m[0907 06-07-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31282, current rewards: -284.05849, mean: -0.18812
[32m[0907 06-07-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31290, current rewards: -334.26470, mean: -0.21427
[32m[0907 06-07-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31296, current rewards: -405.15970, mean: -0.25165
[32m[0907 06-08-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31302, current rewards: -446.95227, mean: -0.26925
[32m[0907 06-08-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31306, current rewards: -513.62943, mean: -0.30037
[32m[0907 06-08-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31325, current rewards: -535.12752, mean: -0.30405
[32m[0907 06-08-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31344, current rewards: -580.64833, mean: -0.32080
[32m[0907 06-09-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31351, current rewards: -579.27127, mean: -0.31144
[32m[0907 06-09-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31357, current rewards: -575.20285, mean: -0.30115
[32m[0907 06-09-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31360, current rewards: -571.11345, mean: -0.29138
[32m[0907 06-09-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31366, current rewards: -567.02309, mean: -0.28210
[32m[0907 06-10-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31367, current rewards: -562.93140, mean: -0.27327
[32m[0907 06-10-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31370, current rewards: -558.84148, mean: -0.26485
[32m[0907 06-10-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31375, current rewards: -554.23291, mean: -0.25659
[32m[0907 06-11-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31474, current rewards: -591.80325, mean: -0.26778
[32m[0907 06-11-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31474, current rewards: -586.79902, mean: -0.25965
[32m[0907 06-11-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31473, current rewards: -582.16008, mean: -0.25202
[32m[0907 06-11-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31472, current rewards: -577.52679, mean: -0.24471
[32m[0907 06-12-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31471, current rewards: -572.89416, mean: -0.23772
[32m[0907 06-12-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31470, current rewards: -568.26048, mean: -0.23100
[32m[0907 06-12-33 @Agent.py:117][0m Average action selection time: 0.3147
[32m[0907 06-12-33 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-12-33 @MBExp.py:227][0m Rewards obtained: [-564.5553370325732], Lows: [361], Highs: [62], Total time: 55185.753264
[32m[0907 06-14-38 @MBExp.py:144][0m ####################################################################
[32m[0907 06-14-38 @MBExp.py:145][0m Starting training iteration 68.
[32m[0907 06-14-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.40830, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-14-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34620, current rewards: -65.77730, mean: -1.09629
[32m[0907 06-15-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32080, current rewards: -165.77730, mean: -1.50707
[32m[0907 06-15-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31115, current rewards: -265.77730, mean: -1.66111
[32m[0907 06-15-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30552, current rewards: -365.77730, mean: -1.74180
[32m[0907 06-15-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30326, current rewards: -465.77730, mean: -1.79145
[32m[0907 06-16-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30262, current rewards: -565.77730, mean: -1.82509
[32m[0907 06-16-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30222, current rewards: -665.77730, mean: -1.84938
[32m[0907 06-16-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30194, current rewards: -765.77730, mean: -1.86775
[32m[0907 06-16-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30229, current rewards: -865.77730, mean: -1.88212
[32m[0907 06-17-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30292, current rewards: -965.77730, mean: -1.89368
[32m[0907 06-17-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30344, current rewards: -1065.77730, mean: -1.90317
[32m[0907 06-17-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30406, current rewards: -1165.77730, mean: -1.91111
[32m[0907 06-18-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30493, current rewards: -1265.77730, mean: -1.91784
[32m[0907 06-18-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30575, current rewards: -1365.77730, mean: -1.92363
[32m[0907 06-18-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30640, current rewards: -1465.77730, mean: -1.92865
[32m[0907 06-18-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30690, current rewards: -1565.77730, mean: -1.93306
[32m[0907 06-19-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30736, current rewards: -1665.77730, mean: -1.93695
[32m[0907 06-19-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30777, current rewards: -1765.77730, mean: -1.94041
[32m[0907 06-19-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30815, current rewards: -1865.77730, mean: -1.94352
[32m[0907 06-19-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30852, current rewards: -1965.77730, mean: -1.94631
[32m[0907 06-20-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30879, current rewards: -2065.77730, mean: -1.94885
[32m[0907 06-20-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30903, current rewards: -2165.77730, mean: -1.95115
[32m[0907 06-20-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30928, current rewards: -2265.77730, mean: -1.95326
[32m[0907 06-20-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30948, current rewards: -2365.77730, mean: -1.95519
[32m[0907 06-21-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30964, current rewards: -2465.77730, mean: -1.95697
[32m[0907 06-21-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30978, current rewards: -2565.77730, mean: -1.95861
[32m[0907 06-21-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30992, current rewards: -2665.77730, mean: -1.96013
[32m[0907 06-21-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31013, current rewards: -2765.77730, mean: -1.96154
[32m[0907 06-22-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31030, current rewards: -2865.77730, mean: -1.96286
[32m[0907 06-22-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31045, current rewards: -2965.77730, mean: -1.96409
[32m[0907 06-22-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31060, current rewards: -3065.77730, mean: -1.96524
[32m[0907 06-23-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31170, current rewards: -3165.77730, mean: -1.96632
[32m[0907 06-23-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31294, current rewards: -3265.77730, mean: -1.96734
[32m[0907 06-23-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31411, current rewards: -3365.77730, mean: -1.96829
[32m[0907 06-23-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31548, current rewards: -3465.77730, mean: -1.96919
[32m[0907 06-24-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31684, current rewards: -3565.77730, mean: -1.97004
[32m[0907 06-24-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31781, current rewards: -3665.77730, mean: -1.97085
[32m[0907 06-24-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31871, current rewards: -3765.77730, mean: -1.97161
[32m[0907 06-25-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31948, current rewards: -3865.77730, mean: -1.97234
[32m[0907 06-25-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31940, current rewards: -3965.77730, mean: -1.97302
[32m[0907 06-25-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31929, current rewards: -4065.77730, mean: -1.97368
[32m[0907 06-25-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31916, current rewards: -4165.77730, mean: -1.97430
[32m[0907 06-26-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31906, current rewards: -4265.77730, mean: -1.97490
[32m[0907 06-26-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31896, current rewards: -4365.77730, mean: -1.97546
[32m[0907 06-26-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31888, current rewards: -4465.77730, mean: -1.97601
[32m[0907 06-26-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31879, current rewards: -4565.77730, mean: -1.97653
[32m[0907 06-27-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31872, current rewards: -4665.77730, mean: -1.97702
[32m[0907 06-27-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31863, current rewards: -4765.77730, mean: -1.97750
[32m[0907 06-27-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31854, current rewards: -4865.77730, mean: -1.97796
[32m[0907 06-27-55 @Agent.py:117][0m Average action selection time: 0.3185
[32m[0907 06-27-55 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-27-55 @MBExp.py:227][0m Rewards obtained: [-4945.7772972209395], Lows: [2464], Highs: [20], Total time: 55982.689785
[32m[0907 06-30-03 @MBExp.py:144][0m ####################################################################
[32m[0907 06-30-03 @MBExp.py:145][0m Starting training iteration 69.
[32m[0907 06-30-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.46691, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-30-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36282, current rewards: -71.93712, mean: -1.19895
[32m[0907 06-30-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32985, current rewards: -128.97653, mean: -1.17251
[32m[0907 06-30-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31793, current rewards: -143.10759, mean: -0.89442
[32m[0907 06-31-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31061, current rewards: -194.78521, mean: -0.92755
[32m[0907 06-31-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30676, current rewards: -188.99444, mean: -0.72690
[32m[0907 06-31-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30504, current rewards: -183.24358, mean: -0.59111
[32m[0907 06-31-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30423, current rewards: -177.49177, mean: -0.49303
[32m[0907 06-32-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30369, current rewards: -212.70507, mean: -0.51879
[32m[0907 06-32-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30398, current rewards: -200.68460, mean: -0.43627
[32m[0907 06-32-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30444, current rewards: -194.40636, mean: -0.38119
[32m[0907 06-32-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30477, current rewards: -182.66668, mean: -0.32619
[32m[0907 06-33-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30536, current rewards: -164.14822, mean: -0.26910
[32m[0907 06-33-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30615, current rewards: -137.70724, mean: -0.20865
[32m[0907 06-33-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30689, current rewards: -106.39268, mean: -0.14985
[32m[0907 06-33-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30751, current rewards: -73.33323, mean: -0.09649
[32m[0907 06-34-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30805, current rewards: -40.18943, mean: -0.04962
[32m[0907 06-34-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30848, current rewards: -6.87769, mean: -0.00800
[32m[0907 06-34-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30894, current rewards: -82.62209, mean: -0.09079
[32m[0907 06-35-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30930, current rewards: -68.37097, mean: -0.07122
[32m[0907 06-35-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31023, current rewards: -94.67604, mean: -0.09374
[32m[0907 06-35-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31049, current rewards: -137.77951, mean: -0.12998
[32m[0907 06-35-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31075, current rewards: -132.23559, mean: -0.11913
[32m[0907 06-36-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31095, current rewards: -126.69262, mean: -0.10922
[32m[0907 06-36-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31109, current rewards: -121.14514, mean: -0.10012
[32m[0907 06-36-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31126, current rewards: -115.60375, mean: -0.09175
[32m[0907 06-36-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31142, current rewards: -110.17798, mean: -0.08411
[32m[0907 06-37-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31156, current rewards: -104.74788, mean: -0.07702
[32m[0907 06-37-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31167, current rewards: -99.20704, mean: -0.07036
[32m[0907 06-37-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31179, current rewards: -93.66797, mean: -0.06416
[32m[0907 06-37-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31204, current rewards: -171.31533, mean: -0.11345
[32m[0907 06-38-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31214, current rewards: -163.87476, mean: -0.10505
[32m[0907 06-38-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31222, current rewards: -158.20088, mean: -0.09826
[32m[0907 06-38-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31230, current rewards: -152.45321, mean: -0.09184
[32m[0907 06-38-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31240, current rewards: -146.89752, mean: -0.08590
[32m[0907 06-39-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31246, current rewards: -141.30050, mean: -0.08028
[32m[0907 06-39-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31274, current rewards: -187.45821, mean: -0.10357
[32m[0907 06-39-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31444, current rewards: -255.60221, mean: -0.13742
[32m[0907 06-40-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31563, current rewards: -318.34620, mean: -0.16667
[32m[0907 06-40-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31631, current rewards: -377.94131, mean: -0.19283
[32m[0907 06-40-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31901, current rewards: -437.54879, mean: -0.21769
[32m[0907 06-41-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32019, current rewards: -498.02039, mean: -0.24176
[32m[0907 06-41-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32110, current rewards: -576.58055, mean: -0.27326
[32m[0907 06-41-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32233, current rewards: -648.18755, mean: -0.30009
[32m[0907 06-41-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32286, current rewards: -710.79584, mean: -0.32163
[32m[0907 06-42-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32309, current rewards: -764.70882, mean: -0.33837
[32m[0907 06-42-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32291, current rewards: -864.70882, mean: -0.37433
[32m[0907 06-42-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32273, current rewards: -964.70882, mean: -0.40877
[32m[0907 06-43-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32256, current rewards: -1064.70882, mean: -0.44179
[32m[0907 06-43-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32241, current rewards: -1164.70882, mean: -0.47346
[32m[0907 06-43-29 @Agent.py:117][0m Average action selection time: 0.3223
[32m[0907 06-43-29 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-43-29 @MBExp.py:227][0m Rewards obtained: [-1244.708820518058], Lows: [731], Highs: [152], Total time: 56789.122758000005
[32m[0907 06-45-38 @MBExp.py:144][0m ####################################################################
[32m[0907 06-45-38 @MBExp.py:145][0m Starting training iteration 70.
[32m[0907 06-45-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.46314, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-46-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37042, current rewards: -49.72122, mean: -0.82869
[32m[0907 06-46-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34029, current rewards: -120.66021, mean: -1.09691
[32m[0907 06-46-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33260, current rewards: -192.59758, mean: -1.20373
[32m[0907 06-46-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34056, current rewards: -225.83577, mean: -1.07541
[32m[0907 06-47-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33820, current rewards: -292.71681, mean: -1.12583
[32m[0907 06-47-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33827, current rewards: -337.30628, mean: -1.08808
[32m[0907 06-47-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33440, current rewards: -377.25821, mean: -1.04794
[32m[0907 06-47-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33122, current rewards: -369.18000, mean: -0.90044
[32m[0907 06-48-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32877, current rewards: -362.21404, mean: -0.78742
[32m[0907 06-48-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32753, current rewards: -411.16520, mean: -0.80621
[32m[0907 06-48-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32655, current rewards: -461.16520, mean: -0.82351
[32m[0907 06-48-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32575, current rewards: -511.16520, mean: -0.83798
[32m[0907 06-49-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32497, current rewards: -561.16520, mean: -0.85025
[32m[0907 06-49-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32430, current rewards: -611.16520, mean: -0.86080
[32m[0907 06-49-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32374, current rewards: -661.16520, mean: -0.86995
[32m[0907 06-50-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32331, current rewards: -711.16520, mean: -0.87798
[32m[0907 06-50-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32290, current rewards: -761.16520, mean: -0.88508
[32m[0907 06-50-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32246, current rewards: -811.16520, mean: -0.89139
[32m[0907 06-50-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32205, current rewards: -861.16520, mean: -0.89705
[32m[0907 06-51-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32171, current rewards: -911.16520, mean: -0.90214
[32m[0907 06-51-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32138, current rewards: -961.16520, mean: -0.90676
[32m[0907 06-51-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32110, current rewards: -1011.16520, mean: -0.91096
[32m[0907 06-51-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32084, current rewards: -1061.16520, mean: -0.91480
[32m[0907 06-52-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32057, current rewards: -1103.31861, mean: -0.91183
[32m[0907 06-52-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32032, current rewards: -1129.22114, mean: -0.89621
[32m[0907 06-52-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32027, current rewards: -1140.96483, mean: -0.87097
[32m[0907 06-52-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32013, current rewards: -1214.95871, mean: -0.89335
[32m[0907 06-53-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31995, current rewards: -1276.62250, mean: -0.90541
[32m[0907 06-53-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31974, current rewards: -1334.54134, mean: -0.91407
[32m[0907 06-53-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31959, current rewards: -1396.59400, mean: -0.92490
[32m[0907 06-53-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31947, current rewards: -1459.40419, mean: -0.93552
[32m[0907 06-54-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31933, current rewards: -1517.28289, mean: -0.94241
[32m[0907 06-54-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31919, current rewards: -1591.60755, mean: -0.95880
[32m[0907 06-54-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31905, current rewards: -1670.78497, mean: -0.97707
[32m[0907 06-55-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31929, current rewards: -1703.08787, mean: -0.96766
[32m[0907 06-55-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31915, current rewards: -1717.89744, mean: -0.94911
[32m[0907 06-55-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31900, current rewards: -1731.01684, mean: -0.93065
[32m[0907 06-55-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31889, current rewards: -1738.07986, mean: -0.90999
[32m[0907 06-56-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31876, current rewards: -1748.12377, mean: -0.89190
[32m[0907 06-56-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31868, current rewards: -1758.63865, mean: -0.87494
[32m[0907 06-56-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31856, current rewards: -1766.73521, mean: -0.85764
[32m[0907 06-56-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31958, current rewards: -1803.00418, mean: -0.85450
[32m[0907 06-57-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31945, current rewards: -1843.52512, mean: -0.85348
[32m[0907 06-57-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31943, current rewards: -1889.39268, mean: -0.85493
[32m[0907 06-57-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31932, current rewards: -1932.02237, mean: -0.85488
[32m[0907 06-57-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31929, current rewards: -1971.30189, mean: -0.85338
[32m[0907 06-58-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32089, current rewards: -1981.68415, mean: -0.83970
[32m[0907 06-58-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32260, current rewards: -1988.48215, mean: -0.82510
[32m[0907 06-58-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32244, current rewards: -1986.49680, mean: -0.80752
[32m[0907 06-59-04 @Agent.py:117][0m Average action selection time: 0.3223
[32m[0907 06-59-04 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-59-04 @MBExp.py:227][0m Rewards obtained: [-1982.315922216383], Lows: [668], Highs: [853], Total time: 57595.61664100001
[32m[0907 07-01-14 @MBExp.py:144][0m ####################################################################
[32m[0907 07-01-14 @MBExp.py:145][0m Starting training iteration 71.
[32m[0907 07-01-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.45781, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-01-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36313, current rewards: -54.15690, mean: -0.90261
[32m[0907 07-01-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36064, current rewards: -93.34496, mean: -0.84859
[32m[0907 07-02-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34164, current rewards: -174.38542, mean: -1.08991
[32m[0907 07-02-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34681, current rewards: -220.14978, mean: -1.04833
[32m[0907 07-02-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34557, current rewards: -287.97886, mean: -1.10761
[32m[0907 07-03-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34681, current rewards: -334.49409, mean: -1.07901
[32m[0907 07-03-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34547, current rewards: -409.17260, mean: -1.13659
[32m[0907 07-03-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34768, current rewards: -500.94677, mean: -1.22182
[32m[0907 07-03-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34516, current rewards: -553.94677, mean: -1.20423
[32m[0907 07-04-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34420, current rewards: -570.45561, mean: -1.11854
[32m[0907 07-04-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34336, current rewards: -565.44821, mean: -1.00973
[32m[0907 07-04-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34111, current rewards: -559.63322, mean: -0.91743
[32m[0907 07-04-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33913, current rewards: -553.82470, mean: -0.83913
[32m[0907 07-05-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33750, current rewards: -548.01050, mean: -0.77185
[32m[0907 07-05-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33611, current rewards: -542.19314, mean: -0.71341
[32m[0907 07-05-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33486, current rewards: -536.38299, mean: -0.66220
[32m[0907 07-06-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33369, current rewards: -530.85380, mean: -0.61727
[32m[0907 07-06-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33268, current rewards: -525.70711, mean: -0.57770
[32m[0907 07-06-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33207, current rewards: -585.10922, mean: -0.60949
[32m[0907 07-06-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33128, current rewards: -678.79166, mean: -0.67207
[32m[0907 07-07-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33089, current rewards: -766.86520, mean: -0.72346
[32m[0907 07-07-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33025, current rewards: -848.41656, mean: -0.76434
[32m[0907 07-07-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33019, current rewards: -924.58112, mean: -0.79705
[32m[0907 07-07-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33116, current rewards: -1022.32288, mean: -0.84489
[32m[0907 07-08-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33215, current rewards: -1104.94331, mean: -0.87694
[32m[0907 07-08-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33298, current rewards: -1204.94331, mean: -0.91980
[32m[0907 07-08-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33390, current rewards: -1304.94331, mean: -0.95952
[32m[0907 07-09-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33457, current rewards: -1404.94331, mean: -0.99641
[32m[0907 07-09-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33694, current rewards: -1482.01068, mean: -1.01508
[32m[0907 07-09-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33807, current rewards: -1536.70304, mean: -1.01768
[32m[0907 07-10-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33909, current rewards: -1586.70304, mean: -1.01712
[32m[0907 07-10-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34125, current rewards: -1650.48762, mean: -1.02515
[32m[0907 07-10-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34442, current rewards: -1704.62126, mean: -1.02688
[32m[0907 07-11-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34467, current rewards: -1755.03997, mean: -1.02634
[32m[0907 07-11-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34655, current rewards: -1827.28819, mean: -1.03823
[32m[0907 07-11-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34996, current rewards: -1857.48211, mean: -1.02623
[32m[0907 07-12-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35009, current rewards: -1910.59100, mean: -1.02720
[32m[0907 07-12-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35014, current rewards: -1989.90843, mean: -1.04184
[32m[0907 07-12-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35019, current rewards: -2054.66361, mean: -1.04830
[32m[0907 07-13-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35189, current rewards: -2109.31804, mean: -1.04941
[32m[0907 07-13-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35330, current rewards: -2161.59442, mean: -1.04932
[32m[0907 07-13-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35399, current rewards: -2224.78861, mean: -1.05440
[32m[0907 07-13-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35405, current rewards: -2306.38851, mean: -1.06777
[32m[0907 07-14-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35484, current rewards: -2354.25662, mean: -1.06527
[32m[0907 07-14-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35599, current rewards: -2379.37145, mean: -1.05282
[32m[0907 07-14-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35516, current rewards: -2424.57584, mean: -1.04960
[32m[0907 07-15-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35455, current rewards: -2510.34962, mean: -1.06371
[32m[0907 07-15-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35379, current rewards: -2590.76753, mean: -1.07501
[32m[0907 07-15-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35348, current rewards: -2652.93487, mean: -1.07843
[32m[0907 07-15-57 @Agent.py:117][0m Average action selection time: 0.3531
[32m[0907 07-15-57 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-15-58 @MBExp.py:227][0m Rewards obtained: [-2667.3445273576135], Lows: [1113], Highs: [562], Total time: 58479.13199000001
[32m[0907 07-18-08 @MBExp.py:144][0m ####################################################################
[32m[0907 07-18-08 @MBExp.py:145][0m Starting training iteration 72.
[32m[0907 07-18-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.48392, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-18-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.40625, current rewards: -78.25755, mean: -1.30429
[32m[0907 07-18-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37296, current rewards: -129.56987, mean: -1.17791
[32m[0907 07-19-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36311, current rewards: -201.77443, mean: -1.26109
[32m[0907 07-19-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35901, current rewards: -272.98462, mean: -1.29993
[32m[0907 07-19-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35813, current rewards: -347.54010, mean: -1.33669
[32m[0907 07-19-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35380, current rewards: -428.38272, mean: -1.38188
[32m[0907 07-20-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35432, current rewards: -497.09799, mean: -1.38083
[32m[0907 07-20-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35175, current rewards: -564.05471, mean: -1.37574
[32m[0907 07-20-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35225, current rewards: -639.81327, mean: -1.39090
[32m[0907 07-21-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34889, current rewards: -711.58795, mean: -1.39527
[32m[0907 07-21-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34730, current rewards: -791.50678, mean: -1.41340
[32m[0907 07-21-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34536, current rewards: -891.50678, mean: -1.46149
[32m[0907 07-21-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34314, current rewards: -991.50678, mean: -1.50228
[32m[0907 07-22-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34125, current rewards: -1091.50678, mean: -1.53733
[32m[0907 07-22-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33961, current rewards: -1191.50678, mean: -1.56777
[32m[0907 07-22-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33819, current rewards: -1291.50678, mean: -1.59445
[32m[0907 07-22-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33688, current rewards: -1391.50678, mean: -1.61803
[32m[0907 07-23-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33578, current rewards: -1491.50678, mean: -1.63902
[32m[0907 07-23-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33471, current rewards: -1591.50678, mean: -1.65782
[32m[0907 07-23-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33429, current rewards: -1682.75718, mean: -1.66610
[32m[0907 07-24-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33563, current rewards: -1754.19033, mean: -1.65490
[32m[0907 07-24-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33604, current rewards: -1832.84767, mean: -1.65121
[32m[0907 07-24-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33543, current rewards: -1889.26694, mean: -1.62868
[32m[0907 07-24-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33462, current rewards: -1980.57385, mean: -1.63684
[32m[0907 07-25-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33389, current rewards: -2080.57385, mean: -1.65125
[32m[0907 07-25-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33320, current rewards: -2180.57385, mean: -1.66456
[32m[0907 07-25-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33255, current rewards: -2280.57385, mean: -1.67689
[32m[0907 07-25-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33191, current rewards: -2380.57385, mean: -1.68835
[32m[0907 07-26-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33139, current rewards: -2480.57385, mean: -1.69902
[32m[0907 07-26-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33090, current rewards: -2580.57385, mean: -1.70899
[32m[0907 07-26-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33039, current rewards: -2680.57385, mean: -1.71832
[32m[0907 07-27-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32989, current rewards: -2780.57385, mean: -1.72706
[32m[0907 07-27-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32945, current rewards: -2880.57385, mean: -1.73529
[32m[0907 07-27-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32903, current rewards: -2980.57385, mean: -1.74303
[32m[0907 07-27-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32864, current rewards: -3080.57385, mean: -1.75033
[32m[0907 07-28-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32828, current rewards: -3180.57385, mean: -1.75722
[32m[0907 07-28-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32792, current rewards: -3280.57385, mean: -1.76375
[32m[0907 07-28-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32757, current rewards: -3380.57385, mean: -1.76993
[32m[0907 07-28-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32726, current rewards: -3480.57385, mean: -1.77580
[32m[0907 07-29-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32696, current rewards: -3580.57385, mean: -1.78138
[32m[0907 07-29-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32665, current rewards: -3680.57385, mean: -1.78669
[32m[0907 07-29-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32639, current rewards: -3780.57385, mean: -1.79174
[32m[0907 07-29-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32614, current rewards: -3880.57385, mean: -1.79656
[32m[0907 07-30-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32591, current rewards: -3980.57385, mean: -1.80116
[32m[0907 07-30-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32565, current rewards: -4080.57385, mean: -1.80556
[32m[0907 07-30-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32527, current rewards: -4180.57385, mean: -1.80977
[32m[0907 07-30-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32490, current rewards: -4280.57385, mean: -1.81380
[32m[0907 07-31-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32454, current rewards: -4380.57385, mean: -1.81767
[32m[0907 07-31-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32419, current rewards: -4480.57385, mean: -1.82137
[32m[0907 07-31-39 @Agent.py:117][0m Average action selection time: 0.3238
[32m[0907 07-31-39 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-31-39 @MBExp.py:227][0m Rewards obtained: [-4560.573854878503], Lows: [2286], Highs: [21], Total time: 59289.40292500001
[32m[0907 07-33-51 @MBExp.py:144][0m ####################################################################
[32m[0907 07-33-51 @MBExp.py:145][0m Starting training iteration 73.
[32m[0907 07-33-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49520, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-34-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36891, current rewards: -100.00000, mean: -1.66667
[32m[0907 07-34-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33908, current rewards: -191.16784, mean: -1.73789
[32m[0907 07-34-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33734, current rewards: -275.66191, mean: -1.72289
[32m[0907 07-35-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33995, current rewards: -362.84525, mean: -1.72783
[32m[0907 07-35-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34070, current rewards: -441.44710, mean: -1.69787
[32m[0907 07-35-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33990, current rewards: -507.80806, mean: -1.63809
[32m[0907 07-35-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34181, current rewards: -548.79222, mean: -1.52442
[32m[0907 07-36-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34327, current rewards: -617.14754, mean: -1.50524
[32m[0907 07-36-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34429, current rewards: -694.82784, mean: -1.51050
[32m[0907 07-36-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34540, current rewards: -777.53591, mean: -1.52458
[32m[0907 07-37-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34436, current rewards: -862.09883, mean: -1.53946
[32m[0907 07-37-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34287, current rewards: -926.86451, mean: -1.51945
[32m[0907 07-37-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34080, current rewards: -1000.78676, mean: -1.51634
[32m[0907 07-37-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33920, current rewards: -1060.59351, mean: -1.49379
[32m[0907 07-38-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33774, current rewards: -1118.95258, mean: -1.47231
[32m[0907 07-38-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33626, current rewards: -1188.17277, mean: -1.46688
[32m[0907 07-38-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33499, current rewards: -1282.07523, mean: -1.49079
[32m[0907 07-38-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33393, current rewards: -1382.07523, mean: -1.51876
[32m[0907 07-39-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33294, current rewards: -1482.07523, mean: -1.54383
[32m[0907 07-39-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33207, current rewards: -1582.07523, mean: -1.56641
[32m[0907 07-39-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33129, current rewards: -1682.07523, mean: -1.58686
[32m[0907 07-39-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33058, current rewards: -1782.07523, mean: -1.60547
[32m[0907 07-40-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32991, current rewards: -1882.07523, mean: -1.62248
[32m[0907 07-40-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32928, current rewards: -1982.07523, mean: -1.63808
[32m[0907 07-40-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32873, current rewards: -2082.07523, mean: -1.65244
[32m[0907 07-41-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32824, current rewards: -2182.07523, mean: -1.66571
[32m[0907 07-41-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32778, current rewards: -2282.07523, mean: -1.67800
[32m[0907 07-41-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32730, current rewards: -2382.07523, mean: -1.68942
[32m[0907 07-41-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32690, current rewards: -2482.07523, mean: -1.70005
[32m[0907 07-42-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32649, current rewards: -2582.07523, mean: -1.70998
[32m[0907 07-42-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32615, current rewards: -2682.07523, mean: -1.71928
[32m[0907 07-42-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32578, current rewards: -2782.07523, mean: -1.72800
[32m[0907 07-42-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32545, current rewards: -2882.07523, mean: -1.73619
[32m[0907 07-43-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32516, current rewards: -2982.07523, mean: -1.74390
[32m[0907 07-43-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32489, current rewards: -3082.07523, mean: -1.75118
[32m[0907 07-43-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32462, current rewards: -3182.07523, mean: -1.75805
[32m[0907 07-43-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32437, current rewards: -3282.07523, mean: -1.76456
[32m[0907 07-44-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32412, current rewards: -3382.07523, mean: -1.77072
[32m[0907 07-44-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32389, current rewards: -3482.07523, mean: -1.77657
[32m[0907 07-44-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32366, current rewards: -3582.07523, mean: -1.78213
[32m[0907 07-44-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32344, current rewards: -3682.07523, mean: -1.78742
[32m[0907 07-45-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32322, current rewards: -3782.07523, mean: -1.79245
[32m[0907 07-45-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32302, current rewards: -3882.07523, mean: -1.79726
[32m[0907 07-45-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32284, current rewards: -3982.07523, mean: -1.80184
[32m[0907 07-46-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32252, current rewards: -4082.07523, mean: -1.80623
[32m[0907 07-46-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32220, current rewards: -4182.07523, mean: -1.81042
[32m[0907 07-46-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32189, current rewards: -4282.07523, mean: -1.81444
[32m[0907 07-46-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32161, current rewards: -4382.07523, mean: -1.81829
[32m[0907 07-47-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32133, current rewards: -4482.07523, mean: -1.82198
[32m[0907 07-47-14 @Agent.py:117][0m Average action selection time: 0.3211
[32m[0907 07-47-14 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-47-15 @MBExp.py:227][0m Rewards obtained: [-4562.075227299475], Lows: [2280], Highs: [41], Total time: 60092.89470000001
[32m[0907 07-49-29 @MBExp.py:144][0m ####################################################################
[32m[0907 07-49-29 @MBExp.py:145][0m Starting training iteration 74.
[32m[0907 07-49-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.48456, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-49-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36468, current rewards: -20.51186, mean: -0.34186
[32m[0907 07-50-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33579, current rewards: -16.53893, mean: -0.15035
[32m[0907 07-50-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32777, current rewards: -11.23232, mean: -0.07020
[32m[0907 07-50-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32519, current rewards: -5.97955, mean: -0.02847
[32m[0907 07-50-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32356, current rewards: -0.73206, mean: -0.00282
[32m[0907 07-51-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32243, current rewards: 4.51462, mean: 0.01456
[32m[0907 07-51-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32154, current rewards: 9.76419, mean: 0.02712
[32m[0907 07-51-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32077, current rewards: 15.02185, mean: 0.03664
[32m[0907 07-51-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32029, current rewards: 20.27285, mean: 0.04407
[32m[0907 07-52-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31974, current rewards: 25.40792, mean: 0.04982
[32m[0907 07-52-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32384, current rewards: -26.15503, mean: -0.04671
[32m[0907 07-52-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32348, current rewards: -22.61103, mean: -0.03707
[32m[0907 07-53-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32286, current rewards: -16.71651, mean: -0.02533
[32m[0907 07-53-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32232, current rewards: -10.77158, mean: -0.01517
[32m[0907 07-53-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32184, current rewards: -4.82907, mean: -0.00635
[32m[0907 07-53-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32145, current rewards: 1.12165, mean: 0.00138
[32m[0907 07-54-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32114, current rewards: 7.06896, mean: 0.00822
[32m[0907 07-54-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32082, current rewards: 14.95195, mean: 0.01643
[32m[0907 07-54-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32048, current rewards: 20.70853, mean: 0.02157
[32m[0907 07-54-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32026, current rewards: 26.47108, mean: 0.02621
[32m[0907 07-55-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32004, current rewards: 32.24511, mean: 0.03042
[32m[0907 07-55-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31979, current rewards: 38.00078, mean: 0.03423
[32m[0907 07-55-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31963, current rewards: 43.76742, mean: 0.03773
[32m[0907 07-55-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31948, current rewards: -6.61431, mean: -0.00547
[32m[0907 07-56-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32014, current rewards: -42.91124, mean: -0.03406
[32m[0907 07-56-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31992, current rewards: -33.51836, mean: -0.02559
[32m[0907 07-56-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31972, current rewards: -28.07680, mean: -0.02064
[32m[0907 07-57-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31953, current rewards: -22.45865, mean: -0.01593
[32m[0907 07-57-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31938, current rewards: -16.83769, mean: -0.01153
[32m[0907 07-57-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32044, current rewards: -11.21621, mean: -0.00743
[32m[0907 07-57-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32149, current rewards: -5.59977, mean: -0.00359
[32m[0907 07-58-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32245, current rewards: 0.02430, mean: 0.00002
[32m[0907 07-58-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32386, current rewards: 5.63248, mean: 0.00339
[32m[0907 07-58-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32495, current rewards: -16.26198, mean: -0.00951
[32m[0907 07-59-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32580, current rewards: -45.45446, mean: -0.02583
[32m[0907 07-59-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32650, current rewards: -40.27267, mean: -0.02225
[32m[0907 07-59-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32718, current rewards: -35.16270, mean: -0.01890
[32m[0907 07-59-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32721, current rewards: -30.10045, mean: -0.01576
[32m[0907 08-00-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32687, current rewards: -25.05678, mean: -0.01278
[32m[0907 08-00-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32661, current rewards: -20.02403, mean: -0.00996
[32m[0907 08-00-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32632, current rewards: -15.00039, mean: -0.00728
[32m[0907 08-00-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32605, current rewards: -10.30569, mean: -0.00488
[32m[0907 08-01-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32581, current rewards: -6.11091, mean: -0.00283
[32m[0907 08-01-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32543, current rewards: -1.16445, mean: -0.00053
[32m[0907 08-01-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32504, current rewards: 1.63850, mean: 0.00072
[32m[0907 08-02-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32466, current rewards: -14.82894, mean: -0.00642
[32m[0907 08-02-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32429, current rewards: -9.47519, mean: -0.00401
[32m[0907 08-02-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32395, current rewards: -4.15075, mean: -0.00172
[32m[0907 08-02-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32361, current rewards: 1.17020, mean: 0.00048
[32m[0907 08-02-58 @Agent.py:117][0m Average action selection time: 0.3233
[32m[0907 08-02-58 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-02-58 @MBExp.py:227][0m Rewards obtained: [5.42726576404933], Lows: [79], Highs: [95], Total time: 60901.98047100001
[32m[0907 08-05-15 @MBExp.py:144][0m ####################################################################
[32m[0907 08-05-15 @MBExp.py:145][0m Starting training iteration 75.
[32m[0907 08-05-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30908, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-05-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29357, current rewards: -31.42599, mean: -0.52377
[32m[0907 08-05-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31146, current rewards: -108.88495, mean: -0.98986
[32m[0907 08-06-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30983, current rewards: -163.05689, mean: -1.01911
[32m[0907 08-06-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30982, current rewards: -223.95430, mean: -1.06645
[32m[0907 08-06-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31064, current rewards: -273.43440, mean: -1.05167
[32m[0907 08-06-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31230, current rewards: -335.72915, mean: -1.08300
[32m[0907 08-07-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31287, current rewards: -390.47021, mean: -1.08464
[32m[0907 08-07-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31322, current rewards: -390.45012, mean: -0.95232
[32m[0907 08-07-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31356, current rewards: -413.93399, mean: -0.89986
[32m[0907 08-07-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31384, current rewards: -413.84503, mean: -0.81146
[32m[0907 08-08-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31411, current rewards: -409.95608, mean: -0.73206
[32m[0907 08-08-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31431, current rewards: -406.20850, mean: -0.66592
[32m[0907 08-08-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31452, current rewards: -402.51327, mean: -0.60987
[32m[0907 08-08-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31464, current rewards: -398.86047, mean: -0.56178
[32m[0907 08-09-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31579, current rewards: -448.77601, mean: -0.59049
[32m[0907 08-09-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31581, current rewards: -533.11737, mean: -0.65817
[32m[0907 08-09-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31581, current rewards: -633.11737, mean: -0.73618
[32m[0907 08-10-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31582, current rewards: -733.11737, mean: -0.80562
[32m[0907 08-10-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31584, current rewards: -833.11737, mean: -0.86783
[32m[0907 08-10-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31581, current rewards: -933.11737, mean: -0.92388
[32m[0907 08-10-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31582, current rewards: -1033.11737, mean: -0.97464
[32m[0907 08-11-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31578, current rewards: -1133.11737, mean: -1.02083
[32m[0907 08-11-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31574, current rewards: -1233.11737, mean: -1.06303
[32m[0907 08-11-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31570, current rewards: -1333.11737, mean: -1.10175
[32m[0907 08-11-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31566, current rewards: -1433.11737, mean: -1.13739
[32m[0907 08-12-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31563, current rewards: -1533.11737, mean: -1.17032
[32m[0907 08-12-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31561, current rewards: -1633.11737, mean: -1.20082
[32m[0907 08-12-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31560, current rewards: -1733.11737, mean: -1.22916
[32m[0907 08-12-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31558, current rewards: -1833.11737, mean: -1.25556
[32m[0907 08-13-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31554, current rewards: -1933.11737, mean: -1.28021
[32m[0907 08-13-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31551, current rewards: -2033.11737, mean: -1.30328
[32m[0907 08-13-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31549, current rewards: -2133.11737, mean: -1.32492
[32m[0907 08-13-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31548, current rewards: -2233.11737, mean: -1.34525
[32m[0907 08-14-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31547, current rewards: -2333.11737, mean: -1.36440
[32m[0907 08-14-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31550, current rewards: -2433.11737, mean: -1.38245
[32m[0907 08-14-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31548, current rewards: -2533.11737, mean: -1.39951
[32m[0907 08-15-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31543, current rewards: -2633.11737, mean: -1.41565
[32m[0907 08-15-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31542, current rewards: -2733.11737, mean: -1.43095
[32m[0907 08-15-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31540, current rewards: -2833.11737, mean: -1.44547
[32m[0907 08-15-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31538, current rewards: -2933.11737, mean: -1.45926
[32m[0907 08-16-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31536, current rewards: -3033.11737, mean: -1.47239
[32m[0907 08-16-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31535, current rewards: -3133.11737, mean: -1.48489
[32m[0907 08-16-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31529, current rewards: -3233.11737, mean: -1.49681
[32m[0907 08-16-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31514, current rewards: -3333.11737, mean: -1.50820
[32m[0907 08-17-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31496, current rewards: -3433.11737, mean: -1.51908
[32m[0907 08-17-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31481, current rewards: -3533.11737, mean: -1.52949
[32m[0907 08-17-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31466, current rewards: -3633.11737, mean: -1.53946
[32m[0907 08-17-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31453, current rewards: -3733.11737, mean: -1.54901
[32m[0907 08-18-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31440, current rewards: -3833.11737, mean: -1.55818
[32m[0907 08-18-21 @Agent.py:117][0m Average action selection time: 0.3143
[32m[0907 08-18-21 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-18-21 @MBExp.py:227][0m Rewards obtained: [-3913.1173739855544], Lows: [1965], Highs: [51], Total time: 61688.40691400001
[32m[0907 08-20-40 @MBExp.py:144][0m ####################################################################
[32m[0907 08-20-40 @MBExp.py:145][0m Starting training iteration 76.
[32m[0907 08-20-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.40596, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-20-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31301, current rewards: -61.72183, mean: -1.02870
[32m[0907 08-21-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32315, current rewards: -122.76987, mean: -1.11609
[32m[0907 08-21-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31852, current rewards: -177.10997, mean: -1.10694
[32m[0907 08-21-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31638, current rewards: -249.59824, mean: -1.18856
[32m[0907 08-22-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31634, current rewards: -314.73817, mean: -1.21053
[32m[0907 08-22-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31641, current rewards: -375.11339, mean: -1.21004
[32m[0907 08-22-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31664, current rewards: -431.67595, mean: -1.19910
[32m[0907 08-22-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31658, current rewards: -493.43551, mean: -1.20350
[32m[0907 08-23-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31756, current rewards: -547.88473, mean: -1.19105
[32m[0907 08-23-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31747, current rewards: -589.07602, mean: -1.15505
[32m[0907 08-23-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31732, current rewards: -662.39598, mean: -1.18285
[32m[0907 08-23-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31721, current rewards: -732.89478, mean: -1.20147
[32m[0907 08-24-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31710, current rewards: -791.41081, mean: -1.19911
[32m[0907 08-24-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31734, current rewards: -847.36120, mean: -1.19347
[32m[0907 08-24-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31820, current rewards: -899.37216, mean: -1.18338
[32m[0907 08-24-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31804, current rewards: -963.58985, mean: -1.18962
[32m[0907 08-25-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31842, current rewards: -1029.33686, mean: -1.19690
[32m[0907 08-25-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31937, current rewards: -1089.76181, mean: -1.19754
[32m[0907 08-25-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31985, current rewards: -1146.61336, mean: -1.19439
[32m[0907 08-26-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31972, current rewards: -1203.73688, mean: -1.19182
[32m[0907 08-26-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32007, current rewards: -1268.03324, mean: -1.19626
[32m[0907 08-26-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31978, current rewards: -1332.78652, mean: -1.20071
[32m[0907 08-26-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32026, current rewards: -1384.09749, mean: -1.19319
[32m[0907 08-27-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32152, current rewards: -1388.69295, mean: -1.14768
[32m[0907 08-27-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32410, current rewards: -1385.80804, mean: -1.09985
[32m[0907 08-27-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32420, current rewards: -1380.27935, mean: -1.05365
[32m[0907 08-28-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32387, current rewards: -1374.93219, mean: -1.01098
[32m[0907 08-28-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32355, current rewards: -1369.58502, mean: -0.97134
[32m[0907 08-28-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32325, current rewards: -1364.23786, mean: -0.93441
[32m[0907 08-28-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32296, current rewards: -1358.89070, mean: -0.89993
[32m[0907 08-29-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32269, current rewards: -1353.54354, mean: -0.86766
[32m[0907 08-29-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32245, current rewards: -1348.19638, mean: -0.83739
[32m[0907 08-29-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32221, current rewards: -1342.84922, mean: -0.80895
[32m[0907 08-29-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32200, current rewards: -1360.74787, mean: -0.79576
[32m[0907 08-30-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32179, current rewards: -1410.74787, mean: -0.80156
[32m[0907 08-30-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32159, current rewards: -1460.74787, mean: -0.80704
[32m[0907 08-30-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32140, current rewards: -1510.74787, mean: -0.81223
[32m[0907 08-30-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32122, current rewards: -1560.74787, mean: -0.81715
[32m[0907 08-31-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32107, current rewards: -1610.74787, mean: -0.82181
[32m[0907 08-31-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32092, current rewards: -1660.74787, mean: -0.82624
[32m[0907 08-31-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32075, current rewards: -1710.74787, mean: -0.83046
[32m[0907 08-31-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32057, current rewards: -1760.74787, mean: -0.83448
[32m[0907 08-32-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32030, current rewards: -1810.74787, mean: -0.83831
[32m[0907 08-32-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32002, current rewards: -1860.74787, mean: -0.84197
[32m[0907 08-32-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31978, current rewards: -1910.74787, mean: -0.84546
[32m[0907 08-32-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31952, current rewards: -1960.74787, mean: -0.84881
[32m[0907 08-33-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31927, current rewards: -2010.74787, mean: -0.85201
[32m[0907 08-33-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31904, current rewards: -2060.74787, mean: -0.85508
[32m[0907 08-33-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31882, current rewards: -2110.74787, mean: -0.85803
[32m[0907 08-33-57 @Agent.py:117][0m Average action selection time: 0.3187
[32m[0907 08-33-57 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-33-57 @MBExp.py:227][0m Rewards obtained: [-2150.7478718400753], Lows: [676], Highs: [927], Total time: 62485.75453500001
[32m[0907 08-36-18 @MBExp.py:144][0m ####################################################################
[32m[0907 08-36-18 @MBExp.py:145][0m Starting training iteration 77.
[32m[0907 08-36-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29010, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-36-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33214, current rewards: -61.33686, mean: -1.02228
[32m[0907 08-36-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33309, current rewards: -108.89416, mean: -0.98995
[32m[0907 08-37-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33249, current rewards: -135.24274, mean: -0.84527
[32m[0907 08-37-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33138, current rewards: -141.10979, mean: -0.67195
[32m[0907 08-37-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32910, current rewards: -139.48676, mean: -0.53649
[32m[0907 08-38-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33075, current rewards: -158.27843, mean: -0.51058
[32m[0907 08-38-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33594, current rewards: -231.89385, mean: -0.64415
[32m[0907 08-38-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33632, current rewards: -266.87115, mean: -0.65091
[32m[0907 08-38-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33670, current rewards: -330.23953, mean: -0.71791
[32m[0907 08-39-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33658, current rewards: -375.57491, mean: -0.73642
[32m[0907 08-39-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33877, current rewards: -425.83252, mean: -0.76042
[32m[0907 08-39-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34271, current rewards: -490.17065, mean: -0.80356
[32m[0907 08-40-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34640, current rewards: -540.18859, mean: -0.81847
[32m[0907 08-40-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35006, current rewards: -591.44346, mean: -0.83302
[32m[0907 08-40-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35179, current rewards: -649.53407, mean: -0.85465
[32m[0907 08-41-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35350, current rewards: -717.32730, mean: -0.88559
[32m[0907 08-41-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35516, current rewards: -769.40624, mean: -0.89466
[32m[0907 08-41-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35620, current rewards: -826.60660, mean: -0.90836
[32m[0907 08-41-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35418, current rewards: -824.43981, mean: -0.85879
[32m[0907 08-42-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35220, current rewards: -816.38404, mean: -0.80830
[32m[0907 08-42-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35045, current rewards: -811.00213, mean: -0.76510
[32m[0907 08-42-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34991, current rewards: -853.18014, mean: -0.76863
[32m[0907 08-43-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34844, current rewards: -874.34745, mean: -0.75375
[32m[0907 08-43-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34707, current rewards: -869.00680, mean: -0.71819
[32m[0907 08-43-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34578, current rewards: -863.38296, mean: -0.68522
[32m[0907 08-43-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34462, current rewards: -857.75822, mean: -0.65478
[32m[0907 08-44-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34350, current rewards: -852.13184, mean: -0.62657
[32m[0907 08-44-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34300, current rewards: -865.41887, mean: -0.61377
[32m[0907 08-44-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34229, current rewards: -883.75711, mean: -0.60531
[32m[0907 08-44-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34143, current rewards: -877.51901, mean: -0.58114
[32m[0907 08-45-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34060, current rewards: -871.16540, mean: -0.55844
[32m[0907 08-45-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33984, current rewards: -864.98211, mean: -0.53726
[32m[0907 08-45-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33908, current rewards: -858.56110, mean: -0.51721
[32m[0907 08-45-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33837, current rewards: -853.00788, mean: -0.49884
[32m[0907 08-46-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33773, current rewards: -846.81185, mean: -0.48114
[32m[0907 08-46-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33707, current rewards: -840.91060, mean: -0.46459
[32m[0907 08-46-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33647, current rewards: -834.88377, mean: -0.44886
[32m[0907 08-47-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33590, current rewards: -828.73500, mean: -0.43389
[32m[0907 08-47-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33537, current rewards: -822.88498, mean: -0.41984
[32m[0907 08-47-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33540, current rewards: -857.93136, mean: -0.42683
[32m[0907 08-47-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33473, current rewards: -852.92253, mean: -0.41404
[32m[0907 08-48-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33408, current rewards: -847.87273, mean: -0.40184
[32m[0907 08-48-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33347, current rewards: -842.82311, mean: -0.39020
[32m[0907 08-48-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33287, current rewards: -837.77022, mean: -0.37908
[32m[0907 08-48-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33231, current rewards: -832.71790, mean: -0.36846
[32m[0907 08-49-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33177, current rewards: -827.66906, mean: -0.35830
[32m[0907 08-49-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33125, current rewards: -822.61693, mean: -0.34857
[32m[0907 08-49-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33082, current rewards: -828.57300, mean: -0.34381
[32m[0907 08-49-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33027, current rewards: -888.11971, mean: -0.36102
[32m[0907 08-50-04 @Agent.py:117][0m Average action selection time: 0.3303
[32m[0907 08-50-04 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-50-04 @MBExp.py:227][0m Rewards obtained: [-931.9737106112381], Lows: [543], Highs: [98], Total time: 63312.28838300001
[32m[0907 08-52-27 @MBExp.py:144][0m ####################################################################
[32m[0907 08-52-27 @MBExp.py:145][0m Starting training iteration 78.
[32m[0907 08-52-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.38928, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-52-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32459, current rewards: -88.63365, mean: -1.47723
[32m[0907 08-53-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31321, current rewards: -182.34548, mean: -1.65769
[32m[0907 08-53-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30916, current rewards: -272.15066, mean: -1.70094
[32m[0907 08-53-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30937, current rewards: -360.53594, mean: -1.71684
[32m[0907 08-53-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31225, current rewards: -447.44711, mean: -1.72095
[32m[0907 08-54-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31427, current rewards: -540.91807, mean: -1.74490
[32m[0907 08-54-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31463, current rewards: -636.30974, mean: -1.76753
[32m[0907 08-54-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31485, current rewards: -732.05371, mean: -1.78550
[32m[0907 08-54-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31518, current rewards: -827.54245, mean: -1.79901
[32m[0907 08-55-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31753, current rewards: -893.40621, mean: -1.75178
[32m[0907 08-55-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31794, current rewards: -991.16218, mean: -1.76993
[32m[0907 08-55-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31842, current rewards: -1083.73100, mean: -1.77661
[32m[0907 08-56-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32210, current rewards: -1176.94327, mean: -1.78325
[32m[0907 08-56-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32528, current rewards: -1272.27274, mean: -1.79193
[32m[0907 08-56-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32757, current rewards: -1365.60025, mean: -1.79684
[32m[0907 08-56-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32959, current rewards: -1460.46613, mean: -1.80304
[32m[0907 08-57-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33182, current rewards: -1560.46613, mean: -1.81450
[32m[0907 08-57-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33398, current rewards: -1655.61447, mean: -1.81936
[32m[0907 08-57-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33639, current rewards: -1746.01916, mean: -1.81877
[32m[0907 08-58-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33710, current rewards: -1841.74209, mean: -1.82351
[32m[0907 08-58-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33789, current rewards: -1939.56003, mean: -1.82977
[32m[0907 08-58-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33859, current rewards: -2034.11122, mean: -1.83253
[32m[0907 08-59-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33929, current rewards: -2124.07885, mean: -1.83110
[32m[0907 08-59-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33980, current rewards: -2221.90321, mean: -1.83628
[32m[0907 08-59-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34031, current rewards: -2319.60554, mean: -1.84096
[32m[0907 08-59-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34079, current rewards: -2419.60554, mean: -1.84703
[32m[0907 09-00-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34122, current rewards: -2519.60554, mean: -1.85265
[32m[0907 09-00-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34159, current rewards: -2619.60554, mean: -1.85788
[32m[0907 09-00-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34196, current rewards: -2719.60554, mean: -1.86274
[32m[0907 09-01-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34226, current rewards: -2819.60554, mean: -1.86729
[32m[0907 09-01-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34260, current rewards: -2919.60554, mean: -1.87154
[32m[0907 09-01-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34295, current rewards: -3019.60554, mean: -1.87553
[32m[0907 09-01-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34325, current rewards: -3119.60554, mean: -1.87928
[32m[0907 09-02-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34350, current rewards: -3219.60554, mean: -1.88281
[32m[0907 09-02-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34375, current rewards: -3319.60554, mean: -1.88614
[32m[0907 09-02-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34405, current rewards: -3419.60554, mean: -1.88928
[32m[0907 09-03-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34430, current rewards: -3519.60554, mean: -1.89226
[32m[0907 09-03-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34449, current rewards: -3619.60554, mean: -1.89508
[32m[0907 09-03-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34447, current rewards: -3719.60554, mean: -1.89776
[32m[0907 09-04-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34444, current rewards: -3819.60554, mean: -1.90030
[32m[0907 09-04-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34442, current rewards: -3919.60554, mean: -1.90272
[32m[0907 09-04-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34440, current rewards: -4019.60554, mean: -1.90503
[32m[0907 09-04-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34439, current rewards: -4119.60554, mean: -1.90722
[32m[0907 09-05-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34437, current rewards: -4219.60554, mean: -1.90932
[32m[0907 09-05-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34436, current rewards: -4319.60554, mean: -1.91133
[32m[0907 09-05-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34434, current rewards: -4419.60554, mean: -1.91325
[32m[0907 09-06-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34434, current rewards: -4519.60554, mean: -1.91509
[32m[0907 09-06-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34422, current rewards: -4619.60554, mean: -1.91685
[32m[0907 09-06-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34422, current rewards: -4719.60554, mean: -1.91854
[32m[0907 09-06-48 @Agent.py:117][0m Average action selection time: 0.3442
[32m[0907 09-06-48 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-06-48 @MBExp.py:227][0m Rewards obtained: [-4799.605540880419], Lows: [2399], Highs: [23], Total time: 64173.59179600001
[32m[0907 09-09-27 @MBExp.py:144][0m ####################################################################
[32m[0907 09-09-27 @MBExp.py:145][0m Starting training iteration 79.
[32m[0907 09-09-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.42050, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-09-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.38666, current rewards: -93.63865, mean: -1.56064
[32m[0907 09-10-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36470, current rewards: -147.72853, mean: -1.34299
[32m[0907 09-10-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35515, current rewards: -225.90174, mean: -1.41189
[32m[0907 09-10-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35264, current rewards: -275.46653, mean: -1.31175
[32m[0907 09-11-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35588, current rewards: -352.21731, mean: -1.35468
[32m[0907 09-11-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36175, current rewards: -417.52583, mean: -1.34686
[32m[0907 09-11-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36590, current rewards: -502.13976, mean: -1.39483
[32m[0907 09-11-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36678, current rewards: -535.50265, mean: -1.30610
[32m[0907 09-12-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36744, current rewards: -585.54513, mean: -1.27292
[32m[0907 09-12-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36936, current rewards: -650.07065, mean: -1.27465
[32m[0907 09-12-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37050, current rewards: -724.28967, mean: -1.29337
[32m[0907 09-13-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37089, current rewards: -774.74634, mean: -1.27008
[32m[0907 09-13-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37125, current rewards: -835.72865, mean: -1.26626
[32m[0907 09-13-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37448, current rewards: -893.58020, mean: -1.25856
[32m[0907 09-14-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37599, current rewards: -978.66423, mean: -1.28772
[32m[0907 09-14-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37548, current rewards: -1030.01967, mean: -1.27163
[32m[0907 09-14-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37476, current rewards: -1069.50592, mean: -1.24361
[32m[0907 09-15-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37681, current rewards: -1098.97252, mean: -1.20766
[32m[0907 09-15-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37655, current rewards: -1122.59911, mean: -1.16937
[32m[0907 09-15-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37757, current rewards: -1161.75192, mean: -1.15025
[32m[0907 09-16-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37686, current rewards: -1174.06945, mean: -1.10761
[32m[0907 09-16-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37709, current rewards: -1218.01054, mean: -1.09731
[32m[0907 09-16-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37740, current rewards: -1244.39848, mean: -1.07276
[32m[0907 09-17-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37760, current rewards: -1297.52950, mean: -1.07234
[32m[0907 09-17-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37797, current rewards: -1333.03801, mean: -1.05797
[32m[0907 09-17-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37759, current rewards: -1381.94060, mean: -1.05492
[32m[0907 09-18-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37714, current rewards: -1421.92619, mean: -1.04553
[32m[0907 09-18-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.37727, current rewards: -1438.00657, mean: -1.01986
[32m[0907 09-18-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.37769, current rewards: -1487.40360, mean: -1.01877
[32m[0907 09-18-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.37763, current rewards: -1531.77824, mean: -1.01442
[32m[0907 09-19-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.37715, current rewards: -1597.23368, mean: -1.02387
[32m[0907 09-19-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.37747, current rewards: -1657.75290, mean: -1.02966
[32m[0907 09-19-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.37687, current rewards: -1666.52648, mean: -1.00393
[32m[0907 09-20-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.37628, current rewards: -1661.39710, mean: -0.97158
[32m[0907 09-20-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.37575, current rewards: -1654.97148, mean: -0.94032
[32m[0907 09-20-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.37513, current rewards: -1648.46431, mean: -0.91075
[32m[0907 09-21-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.37442, current rewards: -1641.95531, mean: -0.88277
[32m[0907 09-21-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.37373, current rewards: -1635.44594, mean: -0.85625
[32m[0907 09-21-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.37308, current rewards: -1628.93624, mean: -0.83109
[32m[0907 09-21-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.37244, current rewards: -1622.42320, mean: -0.80718
[32m[0907 09-22-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.37196, current rewards: -1658.84635, mean: -0.80527
[32m[0907 09-22-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.37139, current rewards: -1691.11554, mean: -0.80148
[32m[0907 09-22-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.37108, current rewards: -1734.88296, mean: -0.80319
[32m[0907 09-23-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.37085, current rewards: -1774.06897, mean: -0.80275
[32m[0907 09-23-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.37039, current rewards: -1823.94368, mean: -0.80705
[32m[0907 09-23-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.37065, current rewards: -1918.94745, mean: -0.83071
[32m[0907 09-24-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.37023, current rewards: -1977.62482, mean: -0.83798
[32m[0907 09-24-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.37050, current rewards: -2044.90255, mean: -0.84851
[32m[0907 09-24-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.37057, current rewards: -2082.55683, mean: -0.84657
[32m[0907 09-24-54 @Agent.py:117][0m Average action selection time: 0.3702
[32m[0907 09-24-54 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-24-54 @MBExp.py:227][0m Rewards obtained: [-2086.144761188188], Lows: [1076], Highs: [150], Total time: 65099.95988400001
[32m[0907 09-27-34 @MBExp.py:144][0m ####################################################################
[32m[0907 09-27-34 @MBExp.py:145][0m Starting training iteration 80.
[32m[0907 09-27-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.38838, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-27-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34272, current rewards: -85.87536, mean: -1.43126
[32m[0907 09-28-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34047, current rewards: -163.74544, mean: -1.48859
[32m[0907 09-28-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34530, current rewards: -235.90987, mean: -1.47444
[32m[0907 09-28-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34735, current rewards: -313.73596, mean: -1.49398
[32m[0907 09-29-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34902, current rewards: -391.07056, mean: -1.50412
[32m[0907 09-29-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34978, current rewards: -478.93273, mean: -1.54494
[32m[0907 09-29-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35038, current rewards: -574.11092, mean: -1.59475
[32m[0907 09-30-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35799, current rewards: -660.50633, mean: -1.61099
[32m[0907 09-30-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36078, current rewards: -754.08861, mean: -1.63932
[32m[0907 09-30-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36453, current rewards: -849.65771, mean: -1.66600
[32m[0907 09-30-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36351, current rewards: -854.04429, mean: -1.52508
[32m[0907 09-31-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36268, current rewards: -850.84178, mean: -1.39482
[32m[0907 09-31-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36201, current rewards: -847.63930, mean: -1.28430
[32m[0907 09-31-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36142, current rewards: -844.43670, mean: -1.18935
[32m[0907 09-32-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36089, current rewards: -841.23408, mean: -1.10689
[32m[0907 09-32-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36038, current rewards: -862.58305, mean: -1.06492
[32m[0907 09-32-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35998, current rewards: -912.58305, mean: -1.06114
[32m[0907 09-33-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35960, current rewards: -962.58305, mean: -1.05778
[32m[0907 09-33-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35925, current rewards: -1012.58305, mean: -1.05477
[32m[0907 09-33-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35895, current rewards: -1062.58305, mean: -1.05206
[32m[0907 09-33-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35875, current rewards: -1112.58305, mean: -1.04961
[32m[0907 09-34-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35845, current rewards: -1162.58305, mean: -1.04737
[32m[0907 09-34-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35818, current rewards: -1212.58305, mean: -1.04533
[32m[0907 09-34-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35793, current rewards: -1262.58305, mean: -1.04346
[32m[0907 09-35-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35766, current rewards: -1312.58305, mean: -1.04173
[32m[0907 09-35-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35743, current rewards: -1362.58305, mean: -1.04014
[32m[0907 09-35-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35722, current rewards: -1412.58305, mean: -1.03866
[32m[0907 09-35-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35704, current rewards: -1462.58305, mean: -1.03729
[32m[0907 09-36-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35686, current rewards: -1512.58305, mean: -1.03602
[32m[0907 09-36-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35665, current rewards: -1562.58305, mean: -1.03482
[32m[0907 09-36-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35649, current rewards: -1612.58305, mean: -1.03371
[32m[0907 09-37-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35636, current rewards: -1662.58305, mean: -1.03266
[32m[0907 09-37-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35626, current rewards: -1712.58305, mean: -1.03168
[32m[0907 09-37-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35614, current rewards: -1762.58305, mean: -1.03075
[32m[0907 09-38-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35603, current rewards: -1812.58305, mean: -1.02988
[32m[0907 09-38-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35572, current rewards: -1862.58305, mean: -1.02905
[32m[0907 09-38-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35540, current rewards: -1912.58305, mean: -1.02827
[32m[0907 09-38-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35518, current rewards: -1962.58305, mean: -1.02753
[32m[0907 09-39-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35498, current rewards: -2012.58305, mean: -1.02683
[32m[0907 09-39-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35479, current rewards: -2062.58305, mean: -1.02616
[32m[0907 09-39-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35459, current rewards: -2112.58305, mean: -1.02553
[32m[0907 09-40-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35442, current rewards: -2162.58305, mean: -1.02492
[32m[0907 09-40-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35426, current rewards: -2212.58305, mean: -1.02434
[32m[0907 09-40-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35410, current rewards: -2262.58305, mean: -1.02379
[32m[0907 09-40-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35373, current rewards: -2312.58305, mean: -1.02327
[32m[0907 09-41-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35359, current rewards: -2362.58305, mean: -1.02276
[32m[0907 09-41-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35346, current rewards: -2412.58305, mean: -1.02228
[32m[0907 09-41-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35335, current rewards: -2462.58305, mean: -1.02182
[32m[0907 09-42-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35324, current rewards: -2512.58305, mean: -1.02138
[32m[0907 09-42-18 @Agent.py:117][0m Average action selection time: 0.3532
[32m[0907 09-42-18 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-42-18 @MBExp.py:227][0m Rewards obtained: [-2552.5830481168964], Lows: [432], Highs: [1733], Total time: 65983.63961200001
[32m[0907 09-45-05 @MBExp.py:144][0m ####################################################################
[32m[0907 09-45-05 @MBExp.py:145][0m Starting training iteration 81.
[32m[0907 09-45-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.38002, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-45-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36479, current rewards: -71.53002, mean: -1.19217
[32m[0907 09-45-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36840, current rewards: -143.98897, mean: -1.30899
[32m[0907 09-46-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37065, current rewards: -205.36808, mean: -1.28355
[32m[0907 09-46-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36859, current rewards: -279.69105, mean: -1.33186
[32m[0907 09-46-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36643, current rewards: -379.69105, mean: -1.46035
[32m[0907 09-46-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36471, current rewards: -479.69105, mean: -1.54739
[32m[0907 09-47-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36371, current rewards: -579.69105, mean: -1.61025
[32m[0907 09-47-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36279, current rewards: -679.69105, mean: -1.65778
[32m[0907 09-47-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36210, current rewards: -779.69105, mean: -1.69498
[32m[0907 09-48-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36162, current rewards: -879.69105, mean: -1.72488
[32m[0907 09-48-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36115, current rewards: -979.69105, mean: -1.74945
[32m[0907 09-48-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36070, current rewards: -1079.69105, mean: -1.76999
[32m[0907 09-49-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36037, current rewards: -1179.69105, mean: -1.78741
[32m[0907 09-49-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36014, current rewards: -1279.69105, mean: -1.80238
[32m[0907 09-49-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35984, current rewards: -1379.69105, mean: -1.81538
[32m[0907 09-49-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35959, current rewards: -1479.69105, mean: -1.82678
[32m[0907 09-50-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35937, current rewards: -1579.69105, mean: -1.83685
[32m[0907 09-50-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35922, current rewards: -1679.69105, mean: -1.84581
[32m[0907 09-50-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35906, current rewards: -1779.69105, mean: -1.85384
[32m[0907 09-51-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35887, current rewards: -1879.69105, mean: -1.86108
[32m[0907 09-51-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35882, current rewards: -1979.69105, mean: -1.86763
[32m[0907 09-51-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35868, current rewards: -2079.69105, mean: -1.87360
[32m[0907 09-52-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35858, current rewards: -2179.69105, mean: -1.87904
[32m[0907 09-52-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35848, current rewards: -2279.69105, mean: -1.88404
[32m[0907 09-52-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35839, current rewards: -2379.69105, mean: -1.88864
[32m[0907 09-52-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35836, current rewards: -2479.69105, mean: -1.89289
[32m[0907 09-53-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35829, current rewards: -2579.69105, mean: -1.89683
[32m[0907 09-53-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35822, current rewards: -2679.69105, mean: -1.90049
[32m[0907 09-53-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35815, current rewards: -2779.69105, mean: -1.90390
[32m[0907 09-54-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35809, current rewards: -2879.69105, mean: -1.90708
[32m[0907 09-54-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35807, current rewards: -2979.69105, mean: -1.91006
[32m[0907 09-54-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35806, current rewards: -3079.69105, mean: -1.91285
[32m[0907 09-55-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35808, current rewards: -3179.69105, mean: -1.91548
[32m[0907 09-55-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35806, current rewards: -3279.69105, mean: -1.91795
[32m[0907 09-55-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35803, current rewards: -3379.69105, mean: -1.92028
[32m[0907 09-55-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35788, current rewards: -3479.69105, mean: -1.92248
[32m[0907 09-56-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35773, current rewards: -3579.69105, mean: -1.92457
[32m[0907 09-56-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35756, current rewards: -3679.69105, mean: -1.92654
[32m[0907 09-56-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35737, current rewards: -3779.69105, mean: -1.92841
[32m[0907 09-57-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35721, current rewards: -3879.69105, mean: -1.93019
[32m[0907 09-57-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35708, current rewards: -3979.69105, mean: -1.93189
[32m[0907 09-57-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35692, current rewards: -4079.69105, mean: -1.93350
[32m[0907 09-57-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35680, current rewards: -4179.69105, mean: -1.93504
[32m[0907 09-58-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35666, current rewards: -4279.69105, mean: -1.93651
[32m[0907 09-58-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35639, current rewards: -4379.69105, mean: -1.93792
[32m[0907 09-58-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35630, current rewards: -4479.69105, mean: -1.93926
[32m[0907 09-59-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35614, current rewards: -4579.69105, mean: -1.94055
[32m[0907 09-59-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35592, current rewards: -4679.69105, mean: -1.94178
[32m[0907 09-59-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35568, current rewards: -4779.69105, mean: -1.94296
[32m[0907 09-59-54 @Agent.py:117][0m Average action selection time: 0.3555
[32m[0907 09-59-54 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-59-54 @MBExp.py:227][0m Rewards obtained: [-4859.691053407834], Lows: [2416], Highs: [40], Total time: 66873.15821300002
[32m[0907 10-02-42 @MBExp.py:144][0m ####################################################################
[32m[0907 10-02-42 @MBExp.py:145][0m Starting training iteration 82.
[32m[0907 10-02-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33645, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-03-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33683, current rewards: -96.93819, mean: -1.61564
[32m[0907 10-03-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34034, current rewards: -196.93819, mean: -1.79035
[32m[0907 10-03-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34478, current rewards: -296.93819, mean: -1.85586
[32m[0907 10-03-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34775, current rewards: -396.93819, mean: -1.89018
[32m[0907 10-04-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34923, current rewards: -496.93819, mean: -1.91130
[32m[0907 10-04-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35016, current rewards: -596.93819, mean: -1.92561
[32m[0907 10-04-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35100, current rewards: -696.93819, mean: -1.93594
[32m[0907 10-05-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35151, current rewards: -796.93819, mean: -1.94375
[32m[0907 10-05-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35234, current rewards: -896.93819, mean: -1.94987
[32m[0907 10-05-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35307, current rewards: -996.93819, mean: -1.95478
[32m[0907 10-06-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35419, current rewards: -1096.93819, mean: -1.95882
[32m[0907 10-06-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35463, current rewards: -1196.93819, mean: -1.96219
[32m[0907 10-06-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35509, current rewards: -1296.93819, mean: -1.96506
[32m[0907 10-06-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35533, current rewards: -1396.93819, mean: -1.96752
[32m[0907 10-07-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35562, current rewards: -1496.93819, mean: -1.96966
[32m[0907 10-07-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35578, current rewards: -1596.93819, mean: -1.97153
[32m[0907 10-07-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35610, current rewards: -1696.93819, mean: -1.97318
[32m[0907 10-08-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35628, current rewards: -1796.93819, mean: -1.97466
[32m[0907 10-08-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35651, current rewards: -1896.93819, mean: -1.97598
[32m[0907 10-08-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35669, current rewards: -1996.93819, mean: -1.97717
[32m[0907 10-09-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35691, current rewards: -2096.93819, mean: -1.97824
[32m[0907 10-09-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35710, current rewards: -2196.93819, mean: -1.97922
[32m[0907 10-09-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35724, current rewards: -2296.93819, mean: -1.98012
[32m[0907 10-09-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35736, current rewards: -2396.93819, mean: -1.98094
[32m[0907 10-10-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35741, current rewards: -2496.93819, mean: -1.98170
[32m[0907 10-10-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35750, current rewards: -2596.93819, mean: -1.98240
[32m[0907 10-10-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35735, current rewards: -2696.93819, mean: -1.98304
[32m[0907 10-11-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35718, current rewards: -2796.93819, mean: -1.98364
[32m[0907 10-11-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35697, current rewards: -2896.93819, mean: -1.98420
[32m[0907 10-11-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35676, current rewards: -2996.93819, mean: -1.98473
[32m[0907 10-11-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35661, current rewards: -3096.93819, mean: -1.98522
[32m[0907 10-12-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35647, current rewards: -3196.93819, mean: -1.98568
[32m[0907 10-12-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35635, current rewards: -3296.93819, mean: -1.98611
[32m[0907 10-12-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35619, current rewards: -3396.93819, mean: -1.98651
[32m[0907 10-13-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35599, current rewards: -3496.93819, mean: -1.98690
[32m[0907 10-13-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35564, current rewards: -3596.93819, mean: -1.98726
[32m[0907 10-13-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35533, current rewards: -3696.93819, mean: -1.98760
[32m[0907 10-14-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35504, current rewards: -3796.93819, mean: -1.98793
[32m[0907 10-14-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35474, current rewards: -3896.93819, mean: -1.98823
[32m[0907 10-14-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35448, current rewards: -3996.93819, mean: -1.98853
[32m[0907 10-14-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35421, current rewards: -4096.93819, mean: -1.98880
[32m[0907 10-15-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35395, current rewards: -4196.93819, mean: -1.98907
[32m[0907 10-15-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35371, current rewards: -4296.93819, mean: -1.98932
[32m[0907 10-15-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35349, current rewards: -4396.93819, mean: -1.98956
[32m[0907 10-16-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35324, current rewards: -4496.93819, mean: -1.98980
[32m[0907 10-16-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35305, current rewards: -4596.93819, mean: -1.99002
[32m[0907 10-16-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35285, current rewards: -4696.93819, mean: -1.99023
[32m[0907 10-16-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35266, current rewards: -4796.93819, mean: -1.99043
[32m[0907 10-17-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35180, current rewards: -4896.93819, mean: -1.99063
[32m[0907 10-17-21 @Agent.py:117][0m Average action selection time: 0.3511
[32m[0907 10-17-21 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-17-21 @MBExp.py:227][0m Rewards obtained: [-4976.938191826963], Lows: [2478], Highs: [21], Total time: 67751.69434000002
[32m[0907 10-19-52 @MBExp.py:144][0m ####################################################################
[32m[0907 10-19-52 @MBExp.py:145][0m Starting training iteration 83.
[32m[0907 10-19-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49787, current rewards: 0.90574, mean: 0.09057
[32m[0907 10-20-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36111, current rewards: -38.57819, mean: -0.64297
[32m[0907 10-20-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33441, current rewards: -32.61505, mean: -0.29650
[32m[0907 10-20-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32878, current rewards: -26.01629, mean: -0.16260
[32m[0907 10-21-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32590, current rewards: -19.41256, mean: -0.09244
[32m[0907 10-21-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32392, current rewards: -12.81030, mean: -0.04927
[32m[0907 10-21-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32269, current rewards: -5.16116, mean: -0.01665
[32m[0907 10-21-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32177, current rewards: 1.59564, mean: 0.00443
[32m[0907 10-22-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32116, current rewards: 8.16987, mean: 0.01993
[32m[0907 10-22-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32050, current rewards: 14.74071, mean: 0.03205
[32m[0907 10-22-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32009, current rewards: 20.18032, mean: 0.03957
[32m[0907 10-22-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31962, current rewards: -25.56473, mean: -0.04565
[32m[0907 10-23-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31918, current rewards: -72.34452, mean: -0.11860
[32m[0907 10-23-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31882, current rewards: -119.13939, mean: -0.18051
[32m[0907 10-23-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31849, current rewards: -169.13939, mean: -0.23822
[32m[0907 10-23-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31825, current rewards: -219.13939, mean: -0.28834
[32m[0907 10-24-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31801, current rewards: -269.13939, mean: -0.33227
[32m[0907 10-24-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31780, current rewards: -319.13939, mean: -0.37109
[32m[0907 10-24-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31764, current rewards: -369.13939, mean: -0.40565
[32m[0907 10-24-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31746, current rewards: -419.13939, mean: -0.43660
[32m[0907 10-25-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31735, current rewards: -469.13939, mean: -0.46449
[32m[0907 10-25-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31735, current rewards: -519.13939, mean: -0.48975
[32m[0907 10-25-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31731, current rewards: -552.94344, mean: -0.49815
[32m[0907 10-26-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31754, current rewards: -602.94344, mean: -0.51978
[32m[0907 10-26-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31816, current rewards: -645.98156, mean: -0.53387
[32m[0907 10-26-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31893, current rewards: -694.73836, mean: -0.55138
[32m[0907 10-26-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31923, current rewards: -751.44435, mean: -0.57362
[32m[0907 10-27-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32058, current rewards: -824.76231, mean: -0.60644
[32m[0907 10-27-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32221, current rewards: -861.36096, mean: -0.61089
[32m[0907 10-27-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32339, current rewards: -899.36164, mean: -0.61600
[32m[0907 10-28-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32391, current rewards: -940.27279, mean: -0.62270
[32m[0907 10-28-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32417, current rewards: -993.53462, mean: -0.63688
[32m[0907 10-28-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32477, current rewards: -1010.41150, mean: -0.62758
[32m[0907 10-28-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32446, current rewards: -1060.41150, mean: -0.63880
[32m[0907 10-29-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32400, current rewards: -1110.41150, mean: -0.64936
[32m[0907 10-29-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32352, current rewards: -1160.41150, mean: -0.65932
[32m[0907 10-29-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32308, current rewards: -1210.41150, mean: -0.66874
[32m[0907 10-29-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32265, current rewards: -1260.41150, mean: -0.67764
[32m[0907 10-30-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32228, current rewards: -1310.41150, mean: -0.68608
[32m[0907 10-30-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32193, current rewards: -1360.41150, mean: -0.69409
[32m[0907 10-30-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32156, current rewards: -1410.41150, mean: -0.70170
[32m[0907 10-30-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32122, current rewards: -1460.41150, mean: -0.70894
[32m[0907 10-31-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32089, current rewards: -1510.41150, mean: -0.71583
[32m[0907 10-31-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32060, current rewards: -1560.41150, mean: -0.72241
[32m[0907 10-31-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32037, current rewards: -1610.41150, mean: -0.72869
[32m[0907 10-31-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32009, current rewards: -1660.41150, mean: -0.73470
[32m[0907 10-32-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31981, current rewards: -1710.41150, mean: -0.74044
[32m[0907 10-32-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31957, current rewards: -1760.41150, mean: -0.74594
[32m[0907 10-32-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31934, current rewards: -1810.41150, mean: -0.75121
[32m[0907 10-32-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31910, current rewards: -1860.41150, mean: -0.75626
[32m[0907 10-33-10 @Agent.py:117][0m Average action selection time: 0.3189
[32m[0907 10-33-10 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-33-10 @MBExp.py:227][0m Rewards obtained: [-1900.4115000838087], Lows: [150], Highs: [1691], Total time: 68549.74813800001
[32m[0907 10-35-43 @MBExp.py:144][0m ####################################################################
[32m[0907 10-35-43 @MBExp.py:145][0m Starting training iteration 84.
[32m[0907 10-35-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29977, current rewards: 1.17068, mean: 0.11707
[32m[0907 10-36-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31712, current rewards: -70.51072, mean: -1.17518
[32m[0907 10-36-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32931, current rewards: -170.51072, mean: -1.55010
[32m[0907 10-36-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33273, current rewards: -270.51072, mean: -1.69069
[32m[0907 10-36-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33195, current rewards: -370.51072, mean: -1.76434
[32m[0907 10-37-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33106, current rewards: -470.51072, mean: -1.80966
[32m[0907 10-37-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33145, current rewards: -570.51072, mean: -1.84036
[32m[0907 10-37-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33127, current rewards: -667.61132, mean: -1.85448
[32m[0907 10-37-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32999, current rewards: -767.61132, mean: -1.87222
[32m[0907 10-38-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32954, current rewards: -862.04646, mean: -1.87401
[32m[0907 10-38-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32814, current rewards: -948.89294, mean: -1.86057
[32m[0907 10-38-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32700, current rewards: -1044.67653, mean: -1.86549
[32m[0907 10-39-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32606, current rewards: -1142.54602, mean: -1.87303
[32m[0907 10-39-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32520, current rewards: -1236.21918, mean: -1.87306
[32m[0907 10-39-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32666, current rewards: -1331.88467, mean: -1.87589
[32m[0907 10-39-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32836, current rewards: -1402.75037, mean: -1.84572
[32m[0907 10-40-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32986, current rewards: -1478.21062, mean: -1.82495
[32m[0907 10-40-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33149, current rewards: -1555.97567, mean: -1.80927
[32m[0907 10-40-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33506, current rewards: -1631.62195, mean: -1.79299
[32m[0907 10-41-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33841, current rewards: -1706.85073, mean: -1.77797
[32m[0907 10-41-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34180, current rewards: -1804.56544, mean: -1.78670
[32m[0907 10-41-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34468, current rewards: -1897.93856, mean: -1.79051
[32m[0907 10-42-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34768, current rewards: -1915.03410, mean: -1.72526
[32m[0907 10-42-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35029, current rewards: -2007.71724, mean: -1.73079
[32m[0907 10-42-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35199, current rewards: -2098.52877, mean: -1.73432
[32m[0907 10-43-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35233, current rewards: -2187.19451, mean: -1.73587
[32m[0907 10-43-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35235, current rewards: -2278.20734, mean: -1.73909
[32m[0907 10-43-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35237, current rewards: -2367.00517, mean: -1.74044
[32m[0907 10-44-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35241, current rewards: -2458.05487, mean: -1.74330
[32m[0907 10-44-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35243, current rewards: -2546.89285, mean: -1.74445
[32m[0907 10-44-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35239, current rewards: -2611.67512, mean: -1.72959
[32m[0907 10-44-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35285, current rewards: -2687.14062, mean: -1.72253
[32m[0907 10-45-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35308, current rewards: -2768.30889, mean: -1.71945
[32m[0907 10-45-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35297, current rewards: -2828.72893, mean: -1.70405
[32m[0907 10-45-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35356, current rewards: -2886.76303, mean: -1.68817
[32m[0907 10-46-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35512, current rewards: -2961.59675, mean: -1.68273
[32m[0907 10-46-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35634, current rewards: -3014.12151, mean: -1.66526
[32m[0907 10-46-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35791, current rewards: -3079.19238, mean: -1.65548
[32m[0907 10-47-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35884, current rewards: -3137.48919, mean: -1.64266
[32m[0907 10-47-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35971, current rewards: -3188.45760, mean: -1.62676
[32m[0907 10-47-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36054, current rewards: -3250.72992, mean: -1.61728
[32m[0907 10-48-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36134, current rewards: -3302.24976, mean: -1.60303
[32m[0907 10-48-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36209, current rewards: -3360.42462, mean: -1.59262
[32m[0907 10-48-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36217, current rewards: -3422.58784, mean: -1.58453
[32m[0907 10-49-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36249, current rewards: -3470.59632, mean: -1.57041
[32m[0907 10-49-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36300, current rewards: -3520.01123, mean: -1.55753
[32m[0907 10-49-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36389, current rewards: -3558.31691, mean: -1.54040
[32m[0907 10-50-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36477, current rewards: -3650.79468, mean: -1.54695
[32m[0907 10-50-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36531, current rewards: -3745.86975, mean: -1.55430
[32m[0907 10-50-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36491, current rewards: -3838.43578, mean: -1.56034
[32m[0907 10-50-56 @Agent.py:117][0m Average action selection time: 0.3646
[32m[0907 10-50-56 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-50-56 @MBExp.py:227][0m Rewards obtained: [-3909.0389473730374], Lows: [2015], Highs: [14], Total time: 69462.13731800001
[32m[0907 10-53-45 @MBExp.py:144][0m ####################################################################
[32m[0907 10-53-45 @MBExp.py:145][0m Starting training iteration 85.
[32m[0907 10-53-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29962, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-54-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30313, current rewards: -34.20623, mean: -0.57010
[32m[0907 10-54-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30751, current rewards: -28.33907, mean: -0.25763
[32m[0907 10-54-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31035, current rewards: -22.43570, mean: -0.14022
[32m[0907 10-54-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31181, current rewards: -16.52559, mean: -0.07869
[32m[0907 10-55-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31275, current rewards: -11.28400, mean: -0.04340
[32m[0907 10-55-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31333, current rewards: -5.68692, mean: -0.01834
[32m[0907 10-55-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31370, current rewards: 0.18912, mean: 0.00053
[32m[0907 10-55-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31400, current rewards: 6.05810, mean: 0.01478
[32m[0907 10-56-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31423, current rewards: 11.93230, mean: 0.02594
[32m[0907 10-56-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31435, current rewards: 17.80643, mean: 0.03491
[32m[0907 10-56-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31462, current rewards: 23.67878, mean: 0.04228
[32m[0907 10-56-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31476, current rewards: 29.55426, mean: 0.04845
[32m[0907 10-57-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31489, current rewards: 35.85238, mean: 0.05432
[32m[0907 10-57-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31523, current rewards: 1.08897, mean: 0.00153
[32m[0907 10-57-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31514, current rewards: 8.99316, mean: 0.01183
[32m[0907 10-58-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31520, current rewards: 16.58981, mean: 0.02048
[32m[0907 10-58-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31519, current rewards: 24.17270, mean: 0.02811
[32m[0907 10-58-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31527, current rewards: 31.76380, mean: 0.03491
[32m[0907 10-58-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31532, current rewards: 39.35936, mean: 0.04100
[32m[0907 10-59-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31531, current rewards: 46.94826, mean: 0.04648
[32m[0907 10-59-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31534, current rewards: 54.54254, mean: 0.05146
[32m[0907 10-59-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31553, current rewards: 36.98189, mean: 0.03332
[32m[0907 10-59-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31551, current rewards: 42.67113, mean: 0.03679
[32m[0907 11-00-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31560, current rewards: 48.35755, mean: 0.03996
[32m[0907 11-00-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31557, current rewards: 54.05610, mean: 0.04290
[32m[0907 11-00-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31555, current rewards: 59.75253, mean: 0.04561
[32m[0907 11-00-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31557, current rewards: 65.44763, mean: 0.04812
[32m[0907 11-01-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31558, current rewards: 71.14324, mean: 0.05046
[32m[0907 11-01-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31556, current rewards: 76.83306, mean: 0.05263
[32m[0907 11-01-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31555, current rewards: 83.88473, mean: 0.05555
[32m[0907 11-01-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31551, current rewards: 89.66500, mean: 0.05748
[32m[0907 11-02-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31549, current rewards: 95.41293, mean: 0.05926
[32m[0907 11-02-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31537, current rewards: 84.22690, mean: 0.05074
[32m[0907 11-02-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31556, current rewards: 26.21929, mean: 0.01533
[32m[0907 11-03-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31533, current rewards: 34.66321, mean: 0.01970
[32m[0907 11-03-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31512, current rewards: 50.55336, mean: 0.02793
[32m[0907 11-03-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31492, current rewards: 68.88190, mean: 0.03703
[32m[0907 11-03-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31471, current rewards: 81.42893, mean: 0.04263
[32m[0907 11-04-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31453, current rewards: 78.96552, mean: 0.04029
[32m[0907 11-04-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31435, current rewards: 78.82335, mean: 0.03922
[32m[0907 11-04-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31418, current rewards: 84.63419, mean: 0.04108
[32m[0907 11-04-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31404, current rewards: 90.44144, mean: 0.04286
[32m[0907 11-05-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31388, current rewards: 96.24312, mean: 0.04456
[32m[0907 11-05-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31393, current rewards: 102.05769, mean: 0.04618
[32m[0907 11-05-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31395, current rewards: 107.87059, mean: 0.04773
[32m[0907 11-05-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31397, current rewards: 116.57710, mean: 0.05047
[32m[0907 11-06-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31398, current rewards: 122.42501, mean: 0.05188
[32m[0907 11-06-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31384, current rewards: 128.29283, mean: 0.05323
[32m[0907 11-06-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31372, current rewards: 134.15983, mean: 0.05454
[32m[0907 11-06-50 @Agent.py:117][0m Average action selection time: 0.3136
[32m[0907 11-06-50 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-06-50 @MBExp.py:227][0m Rewards obtained: [138.84833715528455], Lows: [57], Highs: [82], Total time: 70246.92445300001
[32m[0907 11-09-27 @MBExp.py:144][0m ####################################################################
[32m[0907 11-09-27 @MBExp.py:145][0m Starting training iteration 86.
[32m[0907 11-09-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29779, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-09-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30609, current rewards: -92.60521, mean: -1.54342
[32m[0907 11-10-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30315, current rewards: -181.45073, mean: -1.64955
[32m[0907 11-10-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30328, current rewards: -267.99694, mean: -1.67498
[32m[0907 11-10-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30459, current rewards: -356.52128, mean: -1.69772
[32m[0907 11-10-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30650, current rewards: -440.37201, mean: -1.69374
[32m[0907 11-11-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30806, current rewards: -533.94683, mean: -1.72241
[32m[0907 11-11-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30934, current rewards: -633.94683, mean: -1.76096
[32m[0907 11-11-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31027, current rewards: -733.94683, mean: -1.79011
[32m[0907 11-11-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31090, current rewards: -833.94683, mean: -1.81293
[32m[0907 11-12-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31138, current rewards: -933.94683, mean: -1.83127
[32m[0907 11-12-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31178, current rewards: -1033.94683, mean: -1.84633
[32m[0907 11-12-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31214, current rewards: -1133.94683, mean: -1.85893
[32m[0907 11-12-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31245, current rewards: -1233.94683, mean: -1.86962
[32m[0907 11-13-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31268, current rewards: -1333.94683, mean: -1.87880
[32m[0907 11-13-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31289, current rewards: -1433.94683, mean: -1.88677
[32m[0907 11-13-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31308, current rewards: -1533.94683, mean: -1.89376
[32m[0907 11-13-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31323, current rewards: -1633.94683, mean: -1.89994
[32m[0907 11-14-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31345, current rewards: -1733.94683, mean: -1.90544
[32m[0907 11-14-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31354, current rewards: -1833.94683, mean: -1.91036
[32m[0907 11-14-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31364, current rewards: -1933.94683, mean: -1.91480
[32m[0907 11-15-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31371, current rewards: -2033.94683, mean: -1.91882
[32m[0907 11-15-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31383, current rewards: -2133.94683, mean: -1.92247
[32m[0907 11-15-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31387, current rewards: -2233.94683, mean: -1.92582
[32m[0907 11-15-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31395, current rewards: -2333.94683, mean: -1.92888
[32m[0907 11-16-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31403, current rewards: -2433.94683, mean: -1.93170
[32m[0907 11-16-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31408, current rewards: -2533.94683, mean: -1.93431
[32m[0907 11-16-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31413, current rewards: -2633.94683, mean: -1.93673
[32m[0907 11-16-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31416, current rewards: -2733.94683, mean: -1.93897
[32m[0907 11-17-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31421, current rewards: -2833.94683, mean: -1.94106
[32m[0907 11-17-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31424, current rewards: -2933.94683, mean: -1.94301
[32m[0907 11-17-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31428, current rewards: -3033.94683, mean: -1.94484
[32m[0907 11-17-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31432, current rewards: -3133.94683, mean: -1.94655
[32m[0907 11-18-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31437, current rewards: -3233.94683, mean: -1.94816
[32m[0907 11-18-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31427, current rewards: -3333.94683, mean: -1.94968
[32m[0907 11-18-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31408, current rewards: -3433.94683, mean: -1.95111
[32m[0907 11-18-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31390, current rewards: -3533.94683, mean: -1.95246
[32m[0907 11-19-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31374, current rewards: -3633.94683, mean: -1.95373
[32m[0907 11-19-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31360, current rewards: -3733.94683, mean: -1.95495
[32m[0907 11-19-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31346, current rewards: -3833.94683, mean: -1.95610
[32m[0907 11-19-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31332, current rewards: -3933.94683, mean: -1.95719
[32m[0907 11-20-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31320, current rewards: -4033.94683, mean: -1.95823
[32m[0907 11-20-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31307, current rewards: -4133.94683, mean: -1.95922
[32m[0907 11-20-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31297, current rewards: -4233.94683, mean: -1.96016
[32m[0907 11-20-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31286, current rewards: -4333.94683, mean: -1.96106
[32m[0907 11-21-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31289, current rewards: -4433.94683, mean: -1.96192
[32m[0907 11-21-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31292, current rewards: -4533.94683, mean: -1.96275
[32m[0907 11-21-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31301, current rewards: -4633.94683, mean: -1.96354
[32m[0907 11-22-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31307, current rewards: -4733.94683, mean: -1.96429
[32m[0907 11-22-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31310, current rewards: -4833.94683, mean: -1.96502
[32m[0907 11-22-30 @Agent.py:117][0m Average action selection time: 0.3132
[32m[0907 11-22-30 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-22-31 @MBExp.py:227][0m Rewards obtained: [-4913.946826303412], Lows: [2450], Highs: [21], Total time: 71030.55110400001
[32m[0907 11-25-11 @MBExp.py:144][0m ####################################################################
[32m[0907 11-25-11 @MBExp.py:145][0m Starting training iteration 87.
[32m[0907 11-25-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.48580, current rewards: -4.74076, mean: -0.47408
[32m[0907 11-25-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36644, current rewards: -62.64839, mean: -1.04414
[32m[0907 11-25-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35918, current rewards: -92.36330, mean: -0.83967
[32m[0907 11-26-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35107, current rewards: -98.50976, mean: -0.61569
[32m[0907 11-26-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34351, current rewards: -111.98859, mean: -0.53328
[32m[0907 11-26-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34393, current rewards: -124.05130, mean: -0.47712
[32m[0907 11-26-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34604, current rewards: -177.82922, mean: -0.57364
[32m[0907 11-27-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34541, current rewards: -237.10408, mean: -0.65862
[32m[0907 11-27-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34339, current rewards: -259.83403, mean: -0.63374
[32m[0907 11-27-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34102, current rewards: -265.19153, mean: -0.57650
[32m[0907 11-28-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33861, current rewards: -271.63519, mean: -0.53262
[32m[0907 11-28-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33670, current rewards: -269.14940, mean: -0.48062
[32m[0907 11-28-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33741, current rewards: -301.90062, mean: -0.49492
[32m[0907 11-28-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33572, current rewards: -298.77097, mean: -0.45268
[32m[0907 11-29-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33432, current rewards: -291.98311, mean: -0.41124
[32m[0907 11-29-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33308, current rewards: -285.10920, mean: -0.37514
[32m[0907 11-29-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33198, current rewards: -278.22828, mean: -0.34349
[32m[0907 11-29-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33100, current rewards: -271.33087, mean: -0.31550
[32m[0907 11-30-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33010, current rewards: -264.44779, mean: -0.29060
[32m[0907 11-30-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32937, current rewards: -257.56309, mean: -0.26829
[32m[0907 11-30-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32869, current rewards: -299.29655, mean: -0.29633
[32m[0907 11-30-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32811, current rewards: -355.56419, mean: -0.33544
[32m[0907 11-31-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32757, current rewards: -351.07023, mean: -0.31628
[32m[0907 11-31-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32702, current rewards: -346.97328, mean: -0.29911
[32m[0907 11-31-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32655, current rewards: -368.97756, mean: -0.30494
[32m[0907 11-32-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32609, current rewards: -398.45398, mean: -0.31623
[32m[0907 11-32-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32568, current rewards: -389.53624, mean: -0.29736
[32m[0907 11-32-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32529, current rewards: -383.78295, mean: -0.28219
[32m[0907 11-32-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32493, current rewards: -378.40539, mean: -0.26837
[32m[0907 11-33-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32458, current rewards: -373.03317, mean: -0.25550
[32m[0907 11-33-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32425, current rewards: -367.66105, mean: -0.24348
[32m[0907 11-33-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32398, current rewards: -363.00760, mean: -0.23270
[32m[0907 11-33-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32384, current rewards: -434.95281, mean: -0.27016
[32m[0907 11-34-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32360, current rewards: -519.50381, mean: -0.31295
[32m[0907 11-34-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32372, current rewards: -610.80159, mean: -0.35719
[32m[0907 11-34-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32326, current rewards: -691.33583, mean: -0.39280
[32m[0907 11-34-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32283, current rewards: -768.03377, mean: -0.42433
[32m[0907 11-35-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32243, current rewards: -848.79420, mean: -0.45634
[32m[0907 11-35-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32206, current rewards: -904.20903, mean: -0.47341
[32m[0907 11-35-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32168, current rewards: -944.79718, mean: -0.48204
[32m[0907 11-35-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32132, current rewards: -966.52157, mean: -0.48086
[32m[0907 11-36-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32098, current rewards: -977.37900, mean: -0.47446
[32m[0907 11-36-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32066, current rewards: -1063.58285, mean: -0.50407
[32m[0907 11-36-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32039, current rewards: -1104.80154, mean: -0.51148
[32m[0907 11-36-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32029, current rewards: -1096.44000, mean: -0.49613
[32m[0907 11-37-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32017, current rewards: -1088.58046, mean: -0.48167
[32m[0907 11-37-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32005, current rewards: -1080.72093, mean: -0.46784
[32m[0907 11-37-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31994, current rewards: -1087.90487, mean: -0.46098
[32m[0907 11-38-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31983, current rewards: -1137.90487, mean: -0.47216
[32m[0907 11-38-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31974, current rewards: -1187.90487, mean: -0.48289
[32m[0907 11-38-31 @Agent.py:117][0m Average action selection time: 0.3197
[32m[0907 11-38-31 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-38-31 @MBExp.py:227][0m Rewards obtained: [-1227.9048665509774], Lows: [612], Highs: [255], Total time: 71830.46130100002
[32m[0907 11-41-12 @MBExp.py:144][0m ####################################################################
[32m[0907 11-41-12 @MBExp.py:145][0m Starting training iteration 88.
[32m[0907 11-41-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29950, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-41-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29229, current rewards: -27.87758, mean: -0.46463
[32m[0907 11-41-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29159, current rewards: -48.16145, mean: -0.43783
[32m[0907 11-42-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29495, current rewards: -68.34190, mean: -0.42714
[32m[0907 11-42-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29790, current rewards: -88.05360, mean: -0.41930
[32m[0907 11-42-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30228, current rewards: -125.17117, mean: -0.48143
[32m[0907 11-42-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30468, current rewards: -165.84770, mean: -0.53499
[32m[0907 11-43-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30617, current rewards: -212.99216, mean: -0.59164
[32m[0907 11-43-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30796, current rewards: -273.18174, mean: -0.66630
[32m[0907 11-43-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31287, current rewards: -267.93226, mean: -0.58246
[32m[0907 11-43-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31685, current rewards: -262.48649, mean: -0.51468
[32m[0907 11-44-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32014, current rewards: -252.98977, mean: -0.45177
[32m[0907 11-44-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32271, current rewards: -247.39108, mean: -0.40556
[32m[0907 11-44-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32501, current rewards: -241.86285, mean: -0.36646
[32m[0907 11-45-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32698, current rewards: -236.33278, mean: -0.33286
[32m[0907 11-45-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32874, current rewards: -230.80526, mean: -0.30369
[32m[0907 11-45-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33082, current rewards: -225.27762, mean: -0.27812
[32m[0907 11-45-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33266, current rewards: -221.39822, mean: -0.25744
[32m[0907 11-46-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33428, current rewards: -215.14974, mean: -0.23643
[32m[0907 11-46-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33577, current rewards: -210.02548, mean: -0.21878
[32m[0907 11-46-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33701, current rewards: -204.22834, mean: -0.20221
[32m[0907 11-47-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33800, current rewards: -198.06717, mean: -0.18686
[32m[0907 11-47-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33914, current rewards: -191.81861, mean: -0.17281
[32m[0907 11-47-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34038, current rewards: -185.58085, mean: -0.15998
[32m[0907 11-48-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34133, current rewards: -179.30627, mean: -0.14819
[32m[0907 11-48-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34205, current rewards: -173.05532, mean: -0.13735
[32m[0907 11-48-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34260, current rewards: -166.81891, mean: -0.12734
[32m[0907 11-48-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34315, current rewards: -160.58755, mean: -0.11808
[32m[0907 11-49-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34358, current rewards: -154.48467, mean: -0.10956
[32m[0907 11-49-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34392, current rewards: -149.36099, mean: -0.10230
[32m[0907 11-49-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34418, current rewards: -144.22811, mean: -0.09552
[32m[0907 11-50-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34441, current rewards: -139.07987, mean: -0.08915
[32m[0907 11-50-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34458, current rewards: -133.91930, mean: -0.08318
[32m[0907 11-50-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34457, current rewards: -128.75817, mean: -0.07757
[32m[0907 11-51-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34456, current rewards: -123.59452, mean: -0.07228
[32m[0907 11-51-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34454, current rewards: -118.51811, mean: -0.06734
[32m[0907 11-51-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34465, current rewards: -157.41373, mean: -0.08697
[32m[0907 11-51-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34462, current rewards: -152.21659, mean: -0.08184
[32m[0907 11-52-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34459, current rewards: -146.88766, mean: -0.07690
[32m[0907 11-52-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34457, current rewards: -141.55741, mean: -0.07222
[32m[0907 11-52-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34455, current rewards: -136.22665, mean: -0.06777
[32m[0907 11-53-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34455, current rewards: -130.89925, mean: -0.06354
[32m[0907 11-53-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34454, current rewards: -125.57051, mean: -0.05951
[32m[0907 11-53-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34463, current rewards: -120.15679, mean: -0.05563
[32m[0907 11-53-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34482, current rewards: -114.12159, mean: -0.05164
[32m[0907 11-54-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34502, current rewards: -108.69829, mean: -0.04810
[32m[0907 11-54-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34519, current rewards: -103.28003, mean: -0.04471
[32m[0907 11-54-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34535, current rewards: -97.85461, mean: -0.04146
[32m[0907 11-55-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34551, current rewards: -92.43039, mean: -0.03835
[32m[0907 11-55-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34566, current rewards: -87.00702, mean: -0.03537
[32m[0907 11-55-37 @Agent.py:117][0m Average action selection time: 0.3458
[32m[0907 11-55-37 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-55-38 @MBExp.py:227][0m Rewards obtained: [-82.66814788937612], Lows: [161], Highs: [29], Total time: 72695.68306000001
[32m[0907 11-58-36 @MBExp.py:144][0m ####################################################################
[32m[0907 11-58-36 @MBExp.py:145][0m Starting training iteration 89.
[32m[0907 11-58-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32059, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-58-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32174, current rewards: -18.85057, mean: -0.31418
[32m[0907 11-59-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32173, current rewards: -15.78790, mean: -0.14353
[32m[0907 11-59-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32437, current rewards: -9.94932, mean: -0.06218
[32m[0907 11-59-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32836, current rewards: -4.36660, mean: -0.02079
[32m[0907 12-00-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33247, current rewards: 1.20860, mean: 0.00465
[32m[0907 12-00-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33642, current rewards: -36.88297, mean: -0.11898
[32m[0907 12-00-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34038, current rewards: -57.35136, mean: -0.15931
[32m[0907 12-00-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34346, current rewards: -73.73377, mean: -0.17984
[32m[0907 12-01-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34611, current rewards: -92.88774, mean: -0.20193
[32m[0907 12-01-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34713, current rewards: -136.87896, mean: -0.26839
[32m[0907 12-01-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34871, current rewards: -182.78038, mean: -0.32639
[32m[0907 12-02-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34953, current rewards: -217.05534, mean: -0.35583
[32m[0907 12-02-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34977, current rewards: -282.54173, mean: -0.42809
[32m[0907 12-02-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35006, current rewards: -290.41915, mean: -0.40904
[32m[0907 12-03-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35030, current rewards: -282.13432, mean: -0.37123
[32m[0907 12-03-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35047, current rewards: -275.28835, mean: -0.33986
[32m[0907 12-03-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35064, current rewards: -268.55980, mean: -0.31228
[32m[0907 12-03-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35080, current rewards: -257.03604, mean: -0.28246
[32m[0907 12-04-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34952, current rewards: -245.09677, mean: -0.25531
[32m[0907 12-04-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34791, current rewards: -238.17487, mean: -0.23582
[32m[0907 12-04-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34638, current rewards: -231.41438, mean: -0.21832
[32m[0907 12-04-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34499, current rewards: -224.66563, mean: -0.20240
[32m[0907 12-05-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34374, current rewards: -217.91644, mean: -0.18786
[32m[0907 12-05-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34256, current rewards: -235.09192, mean: -0.19429
[32m[0907 12-05-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34147, current rewards: -283.63601, mean: -0.22511
[32m[0907 12-06-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34054, current rewards: -342.36413, mean: -0.26135
[32m[0907 12-06-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33975, current rewards: -392.47220, mean: -0.28858
[32m[0907 12-06-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33887, current rewards: -444.09308, mean: -0.31496
[32m[0907 12-06-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33821, current rewards: -486.15683, mean: -0.33298
[32m[0907 12-07-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33744, current rewards: -534.89351, mean: -0.35423
[32m[0907 12-07-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33689, current rewards: -594.07416, mean: -0.38082
[32m[0907 12-07-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33617, current rewards: -622.04169, mean: -0.38636
[32m[0907 12-07-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33535, current rewards: -617.52478, mean: -0.37200
[32m[0907 12-08-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33457, current rewards: -613.24806, mean: -0.35862
[32m[0907 12-08-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33381, current rewards: -606.32152, mean: -0.34450
[32m[0907 12-08-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33310, current rewards: -601.89819, mean: -0.33254
[32m[0907 12-08-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33241, current rewards: -597.49399, mean: -0.32123
[32m[0907 12-09-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33175, current rewards: -632.76212, mean: -0.33129
[32m[0907 12-09-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33114, current rewards: -627.30793, mean: -0.32006
[32m[0907 12-09-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33055, current rewards: -620.01449, mean: -0.30846
[32m[0907 12-09-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33000, current rewards: -621.27318, mean: -0.30159
[32m[0907 12-10-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32977, current rewards: -645.93502, mean: -0.30613
[32m[0907 12-10-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32926, current rewards: -641.17333, mean: -0.29684
[32m[0907 12-10-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32895, current rewards: -635.53757, mean: -0.28757
[32m[0907 12-10-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32866, current rewards: -629.88057, mean: -0.27871
[32m[0907 12-11-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32839, current rewards: -624.22582, mean: -0.27023
[32m[0907 12-11-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32810, current rewards: -618.56830, mean: -0.26211
[32m[0907 12-11-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32781, current rewards: -666.88339, mean: -0.27672
[32m[0907 12-12-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32754, current rewards: -678.71729, mean: -0.27590
[32m[0907 12-12-15 @Agent.py:117][0m Average action selection time: 0.3273
[32m[0907 12-12-15 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-12-15 @MBExp.py:227][0m Rewards obtained: [-673.8352751779053], Lows: [459], Highs: [74], Total time: 73514.78663700001
[32m[0907 12-15-01 @MBExp.py:144][0m ####################################################################
[32m[0907 12-15-01 @MBExp.py:145][0m Starting training iteration 90.
[32m[0907 12-15-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30956, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-15-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29423, current rewards: -79.22518, mean: -1.32042
[32m[0907 12-15-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29258, current rewards: -144.72382, mean: -1.31567
[32m[0907 12-15-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29191, current rewards: -213.60661, mean: -1.33504
[32m[0907 12-16-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29437, current rewards: -267.11172, mean: -1.27196
[32m[0907 12-16-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29842, current rewards: -336.10180, mean: -1.29270
[32m[0907 12-16-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30147, current rewards: -398.44710, mean: -1.28531
[32m[0907 12-16-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30357, current rewards: -458.27856, mean: -1.27300
[32m[0907 12-17-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30520, current rewards: -527.04781, mean: -1.28548
[32m[0907 12-17-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30638, current rewards: -608.81357, mean: -1.32351
[32m[0907 12-17-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30748, current rewards: -603.82674, mean: -1.18397
[32m[0907 12-17-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30829, current rewards: -649.63094, mean: -1.16006
[32m[0907 12-18-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30915, current rewards: -667.23100, mean: -1.09382
[32m[0907 12-18-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30968, current rewards: -693.86914, mean: -1.05132
[32m[0907 12-18-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31136, current rewards: -743.86914, mean: -1.04770
[32m[0907 12-18-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31276, current rewards: -748.06262, mean: -0.98429
[32m[0907 12-19-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31289, current rewards: -747.76966, mean: -0.92317
[32m[0907 12-19-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31307, current rewards: -749.45039, mean: -0.87145
[32m[0907 12-19-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31321, current rewards: -794.55831, mean: -0.87314
[32m[0907 12-20-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31332, current rewards: -800.82610, mean: -0.83419
[32m[0907 12-20-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31340, current rewards: -806.05894, mean: -0.79808
[32m[0907 12-20-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31350, current rewards: -811.13756, mean: -0.76522
[32m[0907 12-20-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31355, current rewards: -814.05445, mean: -0.73338
[32m[0907 12-21-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31365, current rewards: -819.15514, mean: -0.70617
[32m[0907 12-21-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31376, current rewards: -824.23423, mean: -0.68119
[32m[0907 12-21-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31383, current rewards: -830.47986, mean: -0.65911
[32m[0907 12-21-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31403, current rewards: -882.47986, mean: -0.67365
[32m[0907 12-22-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31406, current rewards: -937.45672, mean: -0.68931
[32m[0907 12-22-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31410, current rewards: -972.31212, mean: -0.68958
[32m[0907 12-22-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31414, current rewards: -1003.01405, mean: -0.68700
[32m[0907 12-22-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31418, current rewards: -1038.87029, mean: -0.68799
[32m[0907 12-23-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31418, current rewards: -1091.79577, mean: -0.69987
[32m[0907 12-23-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31421, current rewards: -1137.54148, mean: -0.70655
[32m[0907 12-23-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31426, current rewards: -1168.66415, mean: -0.70401
[32m[0907 12-23-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31420, current rewards: -1232.13911, mean: -0.72055
[32m[0907 12-24-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31402, current rewards: -1323.75906, mean: -0.75214
[32m[0907 12-24-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31386, current rewards: -1404.61871, mean: -0.77603
[32m[0907 12-24-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31371, current rewards: -1432.60939, mean: -0.77022
[32m[0907 12-25-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31357, current rewards: -1451.34602, mean: -0.75987
[32m[0907 12-25-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31343, current rewards: -1482.03182, mean: -0.75614
[32m[0907 12-25-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31330, current rewards: -1478.61660, mean: -0.73563
[32m[0907 12-25-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31318, current rewards: -1473.43355, mean: -0.71526
[32m[0907 12-26-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31306, current rewards: -1468.28250, mean: -0.69587
[32m[0907 12-26-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31294, current rewards: -1463.66904, mean: -0.67762
[32m[0907 12-26-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31283, current rewards: -1458.55740, mean: -0.65998
[32m[0907 12-26-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31293, current rewards: -1451.70155, mean: -0.64235
[32m[0907 12-27-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31301, current rewards: -1456.76346, mean: -0.63063
[32m[0907 12-27-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31310, current rewards: -1508.26402, mean: -0.63909
[32m[0907 12-27-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31316, current rewards: -1586.91904, mean: -0.65847
[32m[0907 12-27-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31321, current rewards: -1680.22468, mean: -0.68302
[32m[0907 12-28-04 @Agent.py:117][0m Average action selection time: 0.3133
[32m[0907 12-28-04 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-28-05 @MBExp.py:227][0m Rewards obtained: [-1753.0456583220002], Lows: [851], Highs: [263], Total time: 74298.67340700001
[32m[0907 12-30-53 @MBExp.py:144][0m ####################################################################
[32m[0907 12-30-53 @MBExp.py:145][0m Starting training iteration 91.
[32m[0907 12-30-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.39486, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-31-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37470, current rewards: -57.67022, mean: -0.96117
[32m[0907 12-31-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34505, current rewards: -117.26378, mean: -1.06603
[32m[0907 12-31-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32872, current rewards: -217.26378, mean: -1.35790
[32m[0907 12-32-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32215, current rewards: -317.26378, mean: -1.51078
[32m[0907 12-32-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32111, current rewards: -417.26378, mean: -1.60486
[32m[0907 12-32-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32034, current rewards: -517.26378, mean: -1.66859
[32m[0907 12-32-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31978, current rewards: -617.26378, mean: -1.71462
[32m[0907 12-33-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31947, current rewards: -717.26378, mean: -1.74942
[32m[0907 12-33-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31908, current rewards: -817.26378, mean: -1.77666
[32m[0907 12-33-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31871, current rewards: -917.26378, mean: -1.79856
[32m[0907 12-33-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31845, current rewards: -1017.26378, mean: -1.81654
[32m[0907 12-34-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31818, current rewards: -1117.26378, mean: -1.83158
[32m[0907 12-34-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31799, current rewards: -1217.26378, mean: -1.84434
[32m[0907 12-34-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31786, current rewards: -1317.26378, mean: -1.85530
[32m[0907 12-34-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31771, current rewards: -1417.26378, mean: -1.86482
[32m[0907 12-35-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31760, current rewards: -1517.26378, mean: -1.87317
[32m[0907 12-35-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31748, current rewards: -1617.26378, mean: -1.88054
[32m[0907 12-35-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31740, current rewards: -1717.26378, mean: -1.88710
[32m[0907 12-35-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31729, current rewards: -1817.26378, mean: -1.89298
[32m[0907 12-36-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31721, current rewards: -1917.26378, mean: -1.89828
[32m[0907 12-36-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31717, current rewards: -2017.26378, mean: -1.90308
[32m[0907 12-36-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31712, current rewards: -2117.26378, mean: -1.90744
[32m[0907 12-37-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31700, current rewards: -2217.26378, mean: -1.91143
[32m[0907 12-37-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31693, current rewards: -2317.26378, mean: -1.91509
[32m[0907 12-37-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31679, current rewards: -2417.26378, mean: -1.91846
[32m[0907 12-37-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31678, current rewards: -2517.26378, mean: -1.92158
[32m[0907 12-38-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31673, current rewards: -2617.26378, mean: -1.92446
[32m[0907 12-38-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31668, current rewards: -2717.26378, mean: -1.92714
[32m[0907 12-38-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31661, current rewards: -2817.26378, mean: -1.92963
[32m[0907 12-38-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31655, current rewards: -2917.26378, mean: -1.93196
[32m[0907 12-39-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31652, current rewards: -3017.26378, mean: -1.93414
[32m[0907 12-39-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31649, current rewards: -3117.26378, mean: -1.93619
[32m[0907 12-39-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31630, current rewards: -3217.26378, mean: -1.93811
[32m[0907 12-39-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31603, current rewards: -3317.26378, mean: -1.93992
[32m[0907 12-40-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31580, current rewards: -3417.26378, mean: -1.94163
[32m[0907 12-40-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31557, current rewards: -3517.26378, mean: -1.94324
[32m[0907 12-40-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31537, current rewards: -3617.26378, mean: -1.94477
[32m[0907 12-40-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31519, current rewards: -3717.26378, mean: -1.94621
[32m[0907 12-41-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31500, current rewards: -3817.26378, mean: -1.94758
[32m[0907 12-41-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31483, current rewards: -3917.26378, mean: -1.94889
[32m[0907 12-41-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31468, current rewards: -4017.26378, mean: -1.95013
[32m[0907 12-41-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31452, current rewards: -4117.26378, mean: -1.95131
[32m[0907 12-42-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31435, current rewards: -4217.26378, mean: -1.95244
[32m[0907 12-42-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31429, current rewards: -4317.26378, mean: -1.95351
[32m[0907 12-42-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31432, current rewards: -4417.26378, mean: -1.95454
[32m[0907 12-42-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31434, current rewards: -4517.26378, mean: -1.95553
[32m[0907 12-43-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31441, current rewards: -4617.26378, mean: -1.95647
[32m[0907 12-43-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31443, current rewards: -4717.26378, mean: -1.95737
[32m[0907 12-43-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31443, current rewards: -4817.26378, mean: -1.95824
[32m[0907 12-43-59 @Agent.py:117][0m Average action selection time: 0.3144
[32m[0907 12-43-59 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-43-59 @MBExp.py:227][0m Rewards obtained: [-4897.263783471154], Lows: [2441], Highs: [20], Total time: 75085.47924000002
[32m[0907 12-46-48 @MBExp.py:144][0m ####################################################################
[32m[0907 12-46-48 @MBExp.py:145][0m Starting training iteration 92.
[32m[0907 12-46-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29158, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-47-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29079, current rewards: -100.00000, mean: -1.66667
[32m[0907 12-47-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29074, current rewards: -200.00000, mean: -1.81818
[32m[0907 12-47-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29080, current rewards: -300.00000, mean: -1.87500
[32m[0907 12-47-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29295, current rewards: -400.00000, mean: -1.90476
[32m[0907 12-48-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29536, current rewards: -500.00000, mean: -1.92308
[32m[0907 12-48-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29806, current rewards: -600.00000, mean: -1.93548
[32m[0907 12-48-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30070, current rewards: -700.00000, mean: -1.94444
[32m[0907 12-48-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30256, current rewards: -800.00000, mean: -1.95122
[32m[0907 12-49-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30418, current rewards: -900.00000, mean: -1.95652
[32m[0907 12-49-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30539, current rewards: -1000.00000, mean: -1.96078
[32m[0907 12-49-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30629, current rewards: -1100.00000, mean: -1.96429
[32m[0907 12-49-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30702, current rewards: -1200.00000, mean: -1.96721
[32m[0907 12-50-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30768, current rewards: -1300.00000, mean: -1.96970
[32m[0907 12-50-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30820, current rewards: -1400.00000, mean: -1.97183
[32m[0907 12-50-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30870, current rewards: -1500.00000, mean: -1.97368
[32m[0907 12-50-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30916, current rewards: -1600.00000, mean: -1.97531
[32m[0907 12-51-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30951, current rewards: -1700.00000, mean: -1.97674
[32m[0907 12-51-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30985, current rewards: -1800.00000, mean: -1.97802
[32m[0907 12-51-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31017, current rewards: -1900.00000, mean: -1.97917
[32m[0907 12-52-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31041, current rewards: -2000.00000, mean: -1.98020
[32m[0907 12-52-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31064, current rewards: -2100.00000, mean: -1.98113
[32m[0907 12-52-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31081, current rewards: -2200.00000, mean: -1.98198
[32m[0907 12-52-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31101, current rewards: -2300.00000, mean: -1.98276
[32m[0907 12-53-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31121, current rewards: -2400.00000, mean: -1.98347
[32m[0907 12-53-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31142, current rewards: -2500.00000, mean: -1.98413
[32m[0907 12-53-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31155, current rewards: -2600.00000, mean: -1.98473
[32m[0907 12-53-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31166, current rewards: -2700.00000, mean: -1.98529
[32m[0907 12-54-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31174, current rewards: -2800.00000, mean: -1.98582
[32m[0907 12-54-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31186, current rewards: -2900.00000, mean: -1.98630
[32m[0907 12-54-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31194, current rewards: -3000.00000, mean: -1.98675
[32m[0907 12-54-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31205, current rewards: -3100.00000, mean: -1.98718
[32m[0907 12-55-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31214, current rewards: -3200.00000, mean: -1.98758
[32m[0907 12-55-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31222, current rewards: -3300.00000, mean: -1.98795
[32m[0907 12-55-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31209, current rewards: -3400.00000, mean: -1.98830
[32m[0907 12-55-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31195, current rewards: -3500.00000, mean: -1.98864
[32m[0907 12-56-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31184, current rewards: -3600.00000, mean: -1.98895
[32m[0907 12-56-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31172, current rewards: -3700.00000, mean: -1.98925
[32m[0907 12-56-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31161, current rewards: -3800.00000, mean: -1.98953
[32m[0907 12-56-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31152, current rewards: -3900.00000, mean: -1.98980
[32m[0907 12-57-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31142, current rewards: -4000.00000, mean: -1.99005
[32m[0907 12-57-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31136, current rewards: -4100.00000, mean: -1.99029
[32m[0907 12-57-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31127, current rewards: -4200.00000, mean: -1.99052
[32m[0907 12-58-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31119, current rewards: -4300.00000, mean: -1.99074
[32m[0907 12-58-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31111, current rewards: -4400.00000, mean: -1.99095
[32m[0907 12-58-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31116, current rewards: -4500.00000, mean: -1.99115
[32m[0907 12-58-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31122, current rewards: -4600.00000, mean: -1.99134
[32m[0907 12-59-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31130, current rewards: -4700.00000, mean: -1.99153
[32m[0907 12-59-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31139, current rewards: -4800.00000, mean: -1.99170
[32m[0907 12-59-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31148, current rewards: -4900.00000, mean: -1.99187
[32m[0907 12-59-48 @Agent.py:117][0m Average action selection time: 0.3115
[32m[0907 12-59-48 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-59-48 @MBExp.py:227][0m Rewards obtained: [-4980], Lows: [2480], Highs: [20], Total time: 75865.03344200001
[32m[0907 13-02-39 @MBExp.py:144][0m ####################################################################
[32m[0907 13-02-39 @MBExp.py:145][0m Starting training iteration 93.
[32m[0907 13-02-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.38346, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-02-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32842, current rewards: -46.07184, mean: -0.76786
[32m[0907 13-03-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32454, current rewards: -75.37071, mean: -0.68519
[32m[0907 13-03-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32163, current rewards: -87.46902, mean: -0.54668
[32m[0907 13-03-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32920, current rewards: -113.03246, mean: -0.53825
[32m[0907 13-04-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33250, current rewards: -147.00789, mean: -0.56541
[32m[0907 13-04-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33364, current rewards: -171.72592, mean: -0.55395
[32m[0907 13-04-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33241, current rewards: -195.86912, mean: -0.54408
[32m[0907 13-04-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33314, current rewards: -228.33012, mean: -0.55690
[32m[0907 13-05-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33662, current rewards: -256.51620, mean: -0.55764
[32m[0907 13-05-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33765, current rewards: -286.80107, mean: -0.56236
[32m[0907 13-05-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34375, current rewards: -305.93517, mean: -0.54631
[32m[0907 13-06-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34461, current rewards: -348.49039, mean: -0.57130
[32m[0907 13-06-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35079, current rewards: -373.04099, mean: -0.56521
[32m[0907 13-06-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35276, current rewards: -415.15871, mean: -0.58473
[32m[0907 13-07-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35401, current rewards: -447.80057, mean: -0.58921
[32m[0907 13-07-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35236, current rewards: -448.68211, mean: -0.55393
[32m[0907 13-07-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35233, current rewards: -441.43567, mean: -0.51330
[32m[0907 13-08-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35237, current rewards: -437.31427, mean: -0.48057
[32m[0907 13-08-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35239, current rewards: -433.17324, mean: -0.45122
[32m[0907 13-08-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35245, current rewards: -429.03259, mean: -0.42478
[32m[0907 13-08-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35265, current rewards: -424.88959, mean: -0.40084
[32m[0907 13-09-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35279, current rewards: -420.74482, mean: -0.37905
[32m[0907 13-09-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35288, current rewards: -416.60233, mean: -0.35914
[32m[0907 13-09-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35305, current rewards: -412.45620, mean: -0.34087
[32m[0907 13-10-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35343, current rewards: -411.92531, mean: -0.32692
[32m[0907 13-10-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35388, current rewards: -409.74852, mean: -0.31279
[32m[0907 13-10-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35487, current rewards: -425.75133, mean: -0.31305
[32m[0907 13-11-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35679, current rewards: -459.12921, mean: -0.32562
[32m[0907 13-11-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35817, current rewards: -497.24452, mean: -0.34058
[32m[0907 13-11-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35978, current rewards: -536.05469, mean: -0.35500
[32m[0907 13-12-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36023, current rewards: -568.98879, mean: -0.36474
[32m[0907 13-12-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36037, current rewards: -603.35542, mean: -0.37475
[32m[0907 13-12-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36060, current rewards: -637.92937, mean: -0.38429
[32m[0907 13-12-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36030, current rewards: -672.36513, mean: -0.39320
[32m[0907 13-13-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36025, current rewards: -703.86784, mean: -0.39992
[32m[0907 13-13-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36143, current rewards: -741.71507, mean: -0.40979
[32m[0907 13-13-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36126, current rewards: -784.06243, mean: -0.42154
[32m[0907 13-14-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36147, current rewards: -819.33248, mean: -0.42897
[32m[0907 13-14-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36073, current rewards: -855.44147, mean: -0.43645
[32m[0907 13-14-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35955, current rewards: -901.22157, mean: -0.44837
[32m[0907 13-14-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35831, current rewards: -945.94062, mean: -0.45919
[32m[0907 13-15-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35736, current rewards: -985.37196, mean: -0.46700
[32m[0907 13-15-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35652, current rewards: -1031.11898, mean: -0.47737
[32m[0907 13-15-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35570, current rewards: -1075.78750, mean: -0.48678
[32m[0907 13-16-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35480, current rewards: -1119.44113, mean: -0.49533
[32m[0907 13-16-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35400, current rewards: -1154.18377, mean: -0.49965
[32m[0907 13-16-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35322, current rewards: -1201.01037, mean: -0.50890
[32m[0907 13-16-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35261, current rewards: -1250.75265, mean: -0.51898
[32m[0907 13-17-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35220, current rewards: -1281.02115, mean: -0.52074
[32m[0907 13-17-19 @Agent.py:117][0m Average action selection time: 0.3516
[32m[0907 13-17-19 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-17-19 @MBExp.py:227][0m Rewards obtained: [-1277.5718013653752], Lows: [59], Highs: [1267], Total time: 76744.87525300002
[32m[0907 13-20-11 @MBExp.py:144][0m ####################################################################
[32m[0907 13-20-11 @MBExp.py:145][0m Starting training iteration 94.
[32m[0907 13-20-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29031, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-20-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29810, current rewards: -96.94081, mean: -1.61568
[32m[0907 13-20-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30228, current rewards: -196.94081, mean: -1.79037
[32m[0907 13-20-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30444, current rewards: -296.94081, mean: -1.85588
[32m[0907 13-21-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30669, current rewards: -396.94081, mean: -1.89019
[32m[0907 13-21-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30853, current rewards: -496.94081, mean: -1.91131
[32m[0907 13-21-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30975, current rewards: -596.94081, mean: -1.92562
[32m[0907 13-22-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31077, current rewards: -696.94081, mean: -1.93595
[32m[0907 13-22-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31133, current rewards: -796.94081, mean: -1.94376
[32m[0907 13-22-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31177, current rewards: -896.94081, mean: -1.94987
[32m[0907 13-22-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31224, current rewards: -996.94081, mean: -1.95479
[32m[0907 13-23-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31259, current rewards: -1096.94081, mean: -1.95882
[32m[0907 13-23-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31281, current rewards: -1196.94081, mean: -1.96220
[32m[0907 13-23-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31294, current rewards: -1296.94081, mean: -1.96506
[32m[0907 13-23-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31315, current rewards: -1396.94081, mean: -1.96752
[32m[0907 13-24-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31335, current rewards: -1496.94081, mean: -1.96966
[32m[0907 13-24-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31351, current rewards: -1596.94081, mean: -1.97153
[32m[0907 13-24-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31366, current rewards: -1696.94081, mean: -1.97319
[32m[0907 13-24-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31375, current rewards: -1796.94081, mean: -1.97466
[32m[0907 13-25-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31386, current rewards: -1896.94081, mean: -1.97598
[32m[0907 13-25-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31394, current rewards: -1996.94081, mean: -1.97717
[32m[0907 13-25-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31407, current rewards: -2096.94081, mean: -1.97825
[32m[0907 13-26-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31416, current rewards: -2196.94081, mean: -1.97923
[32m[0907 13-26-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31418, current rewards: -2296.94081, mean: -1.98012
[32m[0907 13-26-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31425, current rewards: -2396.94081, mean: -1.98094
[32m[0907 13-26-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31426, current rewards: -2496.94081, mean: -1.98170
[32m[0907 13-27-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31429, current rewards: -2596.94081, mean: -1.98240
[32m[0907 13-27-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31431, current rewards: -2696.94081, mean: -1.98304
[32m[0907 13-27-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31433, current rewards: -2796.94081, mean: -1.98365
[32m[0907 13-27-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31435, current rewards: -2896.94081, mean: -1.98421
[32m[0907 13-28-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31437, current rewards: -2996.94081, mean: -1.98473
[32m[0907 13-28-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31440, current rewards: -3096.94081, mean: -1.98522
[32m[0907 13-28-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31432, current rewards: -3196.94081, mean: -1.98568
[32m[0907 13-28-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31415, current rewards: -3296.94081, mean: -1.98611
[32m[0907 13-29-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31396, current rewards: -3396.94081, mean: -1.98652
[32m[0907 13-29-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31377, current rewards: -3496.94081, mean: -1.98690
[32m[0907 13-29-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31362, current rewards: -3596.94081, mean: -1.98726
[32m[0907 13-29-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31346, current rewards: -3696.94081, mean: -1.98760
[32m[0907 13-30-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31331, current rewards: -3796.94081, mean: -1.98793
[32m[0907 13-30-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31315, current rewards: -3896.94081, mean: -1.98824
[32m[0907 13-30-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31299, current rewards: -3996.94081, mean: -1.98853
[32m[0907 13-30-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31284, current rewards: -4096.94081, mean: -1.98881
[32m[0907 13-31-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31270, current rewards: -4196.94081, mean: -1.98907
[32m[0907 13-31-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31258, current rewards: -4296.94081, mean: -1.98932
[32m[0907 13-31-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31260, current rewards: -4396.94081, mean: -1.98957
[32m[0907 13-31-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31265, current rewards: -4496.94081, mean: -1.98980
[32m[0907 13-32-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31270, current rewards: -4596.94081, mean: -1.99002
[32m[0907 13-32-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31273, current rewards: -4696.94081, mean: -1.99023
[32m[0907 13-32-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31276, current rewards: -4796.94081, mean: -1.99043
[32m[0907 13-33-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31281, current rewards: -4896.94081, mean: -1.99063
[32m[0907 13-33-13 @Agent.py:117][0m Average action selection time: 0.3128
[32m[0907 13-33-13 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-33-13 @MBExp.py:227][0m Rewards obtained: [-4976.940810692733], Lows: [2478], Highs: [21], Total time: 77527.67536200002
[32m[0907 13-36-07 @MBExp.py:144][0m ####################################################################
[32m[0907 13-36-07 @MBExp.py:145][0m Starting training iteration 95.
[32m[0907 13-36-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.48321, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-36-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36537, current rewards: -60.95651, mean: -1.01594
[32m[0907 13-36-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33932, current rewards: -144.47665, mean: -1.31342
[32m[0907 13-37-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33108, current rewards: -244.47665, mean: -1.52798
[32m[0907 13-37-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32854, current rewards: -342.08675, mean: -1.62898
[32m[0907 13-37-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32648, current rewards: -442.08675, mean: -1.70033
[32m[0907 13-37-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32544, current rewards: -542.08675, mean: -1.74867
[32m[0907 13-38-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32406, current rewards: -642.08675, mean: -1.78357
[32m[0907 13-38-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32326, current rewards: -714.21731, mean: -1.74199
[32m[0907 13-38-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32341, current rewards: -780.43671, mean: -1.69660
[32m[0907 13-38-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32473, current rewards: -855.65381, mean: -1.67775
[32m[0907 13-39-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32420, current rewards: -920.16561, mean: -1.64315
[32m[0907 13-39-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32577, current rewards: -1002.02443, mean: -1.64266
[32m[0907 13-39-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32545, current rewards: -1085.00841, mean: -1.64395
[32m[0907 13-39-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32558, current rewards: -1175.33521, mean: -1.65540
[32m[0907 13-40-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32484, current rewards: -1275.33521, mean: -1.67807
[32m[0907 13-40-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32421, current rewards: -1375.33521, mean: -1.69794
[32m[0907 13-40-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32367, current rewards: -1475.33521, mean: -1.71551
[32m[0907 13-41-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32320, current rewards: -1575.33521, mean: -1.73114
[32m[0907 13-41-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32278, current rewards: -1675.33521, mean: -1.74514
[32m[0907 13-41-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32239, current rewards: -1775.33521, mean: -1.75776
[32m[0907 13-41-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32204, current rewards: -1875.33521, mean: -1.76918
[32m[0907 13-42-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32171, current rewards: -1975.33521, mean: -1.77958
[32m[0907 13-42-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32142, current rewards: -2075.33521, mean: -1.78908
[32m[0907 13-42-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32113, current rewards: -2175.33521, mean: -1.79780
[32m[0907 13-42-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32087, current rewards: -2275.33521, mean: -1.80582
[32m[0907 13-43-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32062, current rewards: -2375.33521, mean: -1.81323
[32m[0907 13-43-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32038, current rewards: -2475.33521, mean: -1.82010
[32m[0907 13-43-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32020, current rewards: -2575.33521, mean: -1.82648
[32m[0907 13-43-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32003, current rewards: -2675.33521, mean: -1.83242
[32m[0907 13-44-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31986, current rewards: -2775.33521, mean: -1.83797
[32m[0907 13-44-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31973, current rewards: -2875.33521, mean: -1.84316
[32m[0907 13-44-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31947, current rewards: -2975.33521, mean: -1.84803
[32m[0907 13-44-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31912, current rewards: -3075.33521, mean: -1.85261
[32m[0907 13-45-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31878, current rewards: -3175.33521, mean: -1.85692
[32m[0907 13-45-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31847, current rewards: -3275.33521, mean: -1.86099
[32m[0907 13-45-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31818, current rewards: -3375.33521, mean: -1.86483
[32m[0907 13-45-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31787, current rewards: -3475.33521, mean: -1.86846
[32m[0907 13-46-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31761, current rewards: -3575.33521, mean: -1.87190
[32m[0907 13-46-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31734, current rewards: -3675.33521, mean: -1.87517
[32m[0907 13-46-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31709, current rewards: -3775.33521, mean: -1.87828
[32m[0907 13-47-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31684, current rewards: -3875.33521, mean: -1.88123
[32m[0907 13-47-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31662, current rewards: -3975.33521, mean: -1.88405
[32m[0907 13-47-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31641, current rewards: -4075.33521, mean: -1.88673
[32m[0907 13-47-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31634, current rewards: -4175.33521, mean: -1.88929
[32m[0907 13-48-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31629, current rewards: -4275.33521, mean: -1.89174
[32m[0907 13-48-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31626, current rewards: -4375.33521, mean: -1.89408
[32m[0907 13-48-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31624, current rewards: -4475.33521, mean: -1.89633
[32m[0907 13-48-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31620, current rewards: -4575.33521, mean: -1.89848
[32m[0907 13-49-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31616, current rewards: -4675.33521, mean: -1.90054
[32m[0907 13-49-18 @Agent.py:117][0m Average action selection time: 0.3161
[32m[0907 13-49-18 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-49-18 @MBExp.py:227][0m Rewards obtained: [-4755.335207269636], Lows: [2367], Highs: [49], Total time: 78318.79350700002
[32m[0907 13-52-13 @MBExp.py:144][0m ####################################################################
[32m[0907 13-52-13 @MBExp.py:145][0m Starting training iteration 96.
[32m[0907 13-52-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33637, current rewards: 0.56473, mean: 0.05647
[32m[0907 13-52-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30701, current rewards: -1.76343, mean: -0.02939
[32m[0907 13-52-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30800, current rewards: 2.03582, mean: 0.01851
[32m[0907 13-53-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30812, current rewards: 5.83507, mean: 0.03647
[32m[0907 13-53-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30828, current rewards: 9.63432, mean: 0.04588
[32m[0907 13-53-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30842, current rewards: -8.08613, mean: -0.03110
[32m[0907 13-53-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30938, current rewards: -58.08613, mean: -0.18737
[32m[0907 13-54-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31046, current rewards: -108.08613, mean: -0.30024
[32m[0907 13-54-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31135, current rewards: -158.08613, mean: -0.38558
[32m[0907 13-54-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31188, current rewards: -208.08613, mean: -0.45236
[32m[0907 13-54-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31224, current rewards: -258.08613, mean: -0.50605
[32m[0907 13-55-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31252, current rewards: -308.08613, mean: -0.55015
[32m[0907 13-55-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31281, current rewards: -358.08613, mean: -0.58703
[32m[0907 13-55-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31300, current rewards: -408.08613, mean: -0.61831
[32m[0907 13-55-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31324, current rewards: -458.08613, mean: -0.64519
[32m[0907 13-56-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31341, current rewards: -508.08613, mean: -0.66853
[32m[0907 13-56-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31355, current rewards: -558.08613, mean: -0.68900
[32m[0907 13-56-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31372, current rewards: -608.08613, mean: -0.70708
[32m[0907 13-56-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31387, current rewards: -658.08613, mean: -0.72317
[32m[0907 13-57-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31393, current rewards: -708.08613, mean: -0.73759
[32m[0907 13-57-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31399, current rewards: -758.08613, mean: -0.75058
[32m[0907 13-57-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31413, current rewards: -808.08613, mean: -0.76235
[32m[0907 13-58-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31421, current rewards: -858.08613, mean: -0.77305
[32m[0907 13-58-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31422, current rewards: -908.08613, mean: -0.78283
[32m[0907 13-58-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31430, current rewards: -958.08613, mean: -0.79181
[32m[0907 13-58-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31435, current rewards: -1008.08613, mean: -0.80007
[32m[0907 13-59-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31435, current rewards: -1058.08613, mean: -0.80770
[32m[0907 13-59-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31438, current rewards: -1108.08613, mean: -0.81477
[32m[0907 13-59-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31439, current rewards: -1158.08613, mean: -0.82134
[32m[0907 13-59-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31441, current rewards: -1208.08613, mean: -0.82746
[32m[0907 14-00-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31440, current rewards: -1258.08613, mean: -0.83317
[32m[0907 14-00-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31441, current rewards: -1308.08613, mean: -0.83852
[32m[0907 14-00-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31426, current rewards: -1358.08613, mean: -0.84353
[32m[0907 14-00-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31407, current rewards: -1408.08613, mean: -0.84824
[32m[0907 14-01-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31388, current rewards: -1458.08613, mean: -0.85268
[32m[0907 14-01-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31371, current rewards: -1508.08613, mean: -0.85687
[32m[0907 14-01-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31353, current rewards: -1558.08613, mean: -0.86082
[32m[0907 14-01-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31339, current rewards: -1608.08613, mean: -0.86456
[32m[0907 14-02-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31322, current rewards: -1658.08613, mean: -0.86811
[32m[0907 14-02-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31307, current rewards: -1708.08613, mean: -0.87147
[32m[0907 14-02-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31294, current rewards: -1758.08613, mean: -0.87467
[32m[0907 14-02-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31282, current rewards: -1808.08613, mean: -0.87771
[32m[0907 14-03-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31270, current rewards: -1858.08613, mean: -0.88061
[32m[0907 14-03-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31258, current rewards: -1908.08613, mean: -0.88337
[32m[0907 14-03-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31262, current rewards: -1958.08613, mean: -0.88601
[32m[0907 14-04-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31269, current rewards: -2008.08613, mean: -0.88853
[32m[0907 14-04-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31274, current rewards: -2058.08613, mean: -0.89095
[32m[0907 14-04-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31279, current rewards: -2108.08613, mean: -0.89326
[32m[0907 14-04-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31284, current rewards: -2158.08613, mean: -0.89547
[32m[0907 14-05-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31287, current rewards: -2208.08613, mean: -0.89760
[32m[0907 14-05-15 @Agent.py:117][0m Average action selection time: 0.3129
[32m[0907 14-05-15 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-05-16 @MBExp.py:227][0m Rewards obtained: [-2248.0861281360985], Lows: [3], Highs: [2260], Total time: 79101.76868700002
[32m[0907 14-08-13 @MBExp.py:144][0m ####################################################################
[32m[0907 14-08-13 @MBExp.py:145][0m Starting training iteration 97.
[32m[0907 14-08-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29216, current rewards: 0.79571, mean: 0.07957
[32m[0907 14-08-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29911, current rewards: -78.40859, mean: -1.30681
[32m[0907 14-08-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29919, current rewards: -86.25538, mean: -0.78414
[32m[0907 14-09-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29909, current rewards: -82.27685, mean: -0.51423
[32m[0907 14-09-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29907, current rewards: -78.29833, mean: -0.37285
[32m[0907 14-09-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29905, current rewards: -74.31980, mean: -0.28585
[32m[0907 14-09-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29913, current rewards: -70.34127, mean: -0.22691
[32m[0907 14-10-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30033, current rewards: -66.55274, mean: -0.18487
[32m[0907 14-10-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30184, current rewards: -62.91941, mean: -0.15346
[32m[0907 14-10-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30327, current rewards: -100.04741, mean: -0.21749
[32m[0907 14-10-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30442, current rewards: -150.04741, mean: -0.29421
[32m[0907 14-11-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30544, current rewards: -200.04741, mean: -0.35723
[32m[0907 14-11-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30626, current rewards: -250.04741, mean: -0.40991
[32m[0907 14-11-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30695, current rewards: -300.04741, mean: -0.45462
[32m[0907 14-11-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30758, current rewards: -350.04741, mean: -0.49302
[32m[0907 14-12-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30808, current rewards: -400.04741, mean: -0.52638
[32m[0907 14-12-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30853, current rewards: -450.04741, mean: -0.55561
[32m[0907 14-12-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30888, current rewards: -500.04741, mean: -0.58145
[32m[0907 14-12-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30918, current rewards: -550.04741, mean: -0.60445
[32m[0907 14-13-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30943, current rewards: -600.04741, mean: -0.62505
[32m[0907 14-13-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30965, current rewards: -650.04741, mean: -0.64361
[32m[0907 14-13-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30987, current rewards: -700.04741, mean: -0.66042
[32m[0907 14-13-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31006, current rewards: -750.04741, mean: -0.67572
[32m[0907 14-14-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31022, current rewards: -800.04741, mean: -0.68970
[32m[0907 14-14-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31038, current rewards: -850.04741, mean: -0.70252
[32m[0907 14-14-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31053, current rewards: -900.04741, mean: -0.71432
[32m[0907 14-15-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31071, current rewards: -950.04741, mean: -0.72523
[32m[0907 14-15-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31089, current rewards: -1000.04741, mean: -0.73533
[32m[0907 14-15-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31102, current rewards: -1050.04741, mean: -0.74471
[32m[0907 14-15-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31114, current rewards: -1100.04741, mean: -0.75346
[32m[0907 14-16-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31124, current rewards: -1150.04741, mean: -0.76162
[32m[0907 14-16-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31134, current rewards: -1200.04741, mean: -0.76926
[32m[0907 14-16-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31129, current rewards: -1250.04741, mean: -0.77643
[32m[0907 14-16-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31117, current rewards: -1300.04741, mean: -0.78316
[32m[0907 14-17-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31105, current rewards: -1350.04741, mean: -0.78950
[32m[0907 14-17-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31094, current rewards: -1400.04741, mean: -0.79548
[32m[0907 14-17-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31084, current rewards: -1450.04741, mean: -0.80113
[32m[0907 14-17-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31075, current rewards: -1500.04741, mean: -0.80648
[32m[0907 14-18-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31065, current rewards: -1550.04741, mean: -0.81154
[32m[0907 14-18-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31058, current rewards: -1600.04741, mean: -0.81635
[32m[0907 14-18-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31049, current rewards: -1650.04741, mean: -0.82092
[32m[0907 14-18-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31041, current rewards: -1700.04741, mean: -0.82527
[32m[0907 14-19-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31034, current rewards: -1750.04741, mean: -0.82941
[32m[0907 14-19-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31029, current rewards: -1800.04741, mean: -0.83336
[32m[0907 14-19-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31038, current rewards: -1850.04741, mean: -0.83713
[32m[0907 14-19-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31049, current rewards: -1900.04741, mean: -0.84073
[32m[0907 14-20-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31059, current rewards: -1950.04741, mean: -0.84418
[32m[0907 14-20-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31069, current rewards: -2000.04741, mean: -0.84748
[32m[0907 14-20-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31077, current rewards: -2050.04741, mean: -0.85064
[32m[0907 14-20-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31081, current rewards: -2100.04741, mean: -0.85368
[32m[0907 14-21-10 @Agent.py:117][0m Average action selection time: 0.3109
[32m[0907 14-21-10 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-21-11 @MBExp.py:227][0m Rewards obtained: [-2140.047407081851], Lows: [47], Highs: [2078], Total time: 79879.68031800001
[32m[0907 14-24-10 @MBExp.py:144][0m ####################################################################
[32m[0907 14-24-10 @MBExp.py:145][0m Starting training iteration 98.
[32m[0907 14-24-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28972, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-24-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29749, current rewards: -15.02943, mean: -0.25049
[32m[0907 14-24-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29859, current rewards: -10.23496, mean: -0.09305
[32m[0907 14-24-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29900, current rewards: -5.39901, mean: -0.03374
[32m[0907 14-25-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29893, current rewards: -0.55585, mean: -0.00265
[32m[0907 14-25-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29892, current rewards: 4.28257, mean: 0.01647
[32m[0907 14-25-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29895, current rewards: 9.83781, mean: 0.03173
[32m[0907 14-25-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29963, current rewards: 14.38454, mean: 0.03996
[32m[0907 14-26-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30239, current rewards: 12.23898, mean: 0.02985
[32m[0907 14-26-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30423, current rewards: -33.19031, mean: -0.07215
[32m[0907 14-26-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30722, current rewards: -71.59109, mean: -0.14037
[32m[0907 14-27-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30835, current rewards: -143.38692, mean: -0.25605
[32m[0907 14-27-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30902, current rewards: -243.38692, mean: -0.39899
[32m[0907 14-27-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31162, current rewards: -343.38692, mean: -0.52028
[32m[0907 14-27-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31269, current rewards: -412.20306, mean: -0.58057
[32m[0907 14-28-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31486, current rewards: -427.22930, mean: -0.56214
[32m[0907 14-28-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31582, current rewards: -469.61878, mean: -0.57978
[32m[0907 14-28-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31617, current rewards: -516.49565, mean: -0.60058
[32m[0907 14-28-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31618, current rewards: -594.42595, mean: -0.65322
[32m[0907 14-29-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31612, current rewards: -694.42595, mean: -0.72336
[32m[0907 14-29-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31611, current rewards: -794.42595, mean: -0.78656
[32m[0907 14-29-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31609, current rewards: -894.42595, mean: -0.84380
[32m[0907 14-30-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31606, current rewards: -994.42595, mean: -0.89588
[32m[0907 14-30-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31606, current rewards: -1094.42595, mean: -0.94347
[32m[0907 14-30-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31605, current rewards: -1194.42595, mean: -0.98713
[32m[0907 14-30-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31604, current rewards: -1294.42595, mean: -1.02732
[32m[0907 14-31-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31597, current rewards: -1394.42595, mean: -1.06445
[32m[0907 14-31-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31593, current rewards: -1494.42595, mean: -1.09884
[32m[0907 14-31-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31588, current rewards: -1594.42595, mean: -1.13080
[32m[0907 14-31-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31585, current rewards: -1694.42595, mean: -1.16057
[32m[0907 14-32-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31580, current rewards: -1794.42595, mean: -1.18836
[32m[0907 14-32-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31573, current rewards: -1894.42595, mean: -1.21438
[32m[0907 14-32-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31549, current rewards: -1994.42595, mean: -1.23877
[32m[0907 14-32-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31527, current rewards: -2094.42595, mean: -1.26170
[32m[0907 14-33-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31508, current rewards: -2194.42595, mean: -1.28329
[32m[0907 14-33-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31489, current rewards: -2294.42595, mean: -1.30365
[32m[0907 14-33-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31469, current rewards: -2394.42595, mean: -1.32289
[32m[0907 14-33-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31451, current rewards: -2494.42595, mean: -1.34109
[32m[0907 14-34-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31435, current rewards: -2594.42595, mean: -1.35834
[32m[0907 14-34-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31417, current rewards: -2694.42595, mean: -1.37471
[32m[0907 14-34-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31402, current rewards: -2794.42595, mean: -1.39026
[32m[0907 14-34-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31388, current rewards: -2894.42595, mean: -1.40506
[32m[0907 14-35-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31375, current rewards: -2994.42595, mean: -1.41916
[32m[0907 14-35-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31362, current rewards: -3094.42595, mean: -1.43260
[32m[0907 14-35-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31367, current rewards: -3194.42595, mean: -1.44544
[32m[0907 14-35-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31370, current rewards: -3294.42595, mean: -1.45771
[32m[0907 14-36-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31375, current rewards: -3394.42595, mean: -1.46945
[32m[0907 14-36-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31380, current rewards: -3494.42595, mean: -1.48069
[32m[0907 14-36-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31382, current rewards: -3594.42595, mean: -1.49146
[32m[0907 14-37-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31387, current rewards: -3694.42595, mean: -1.50180
[32m[0907 14-37-15 @Agent.py:117][0m Average action selection time: 0.3139
[32m[0907 14-37-15 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-37-15 @MBExp.py:227][0m Rewards obtained: [-3774.425949491589], Lows: [1868], Highs: [113], Total time: 80665.09839600002
[32m[0907 14-40-16 @MBExp.py:144][0m ####################################################################
[32m[0907 14-40-16 @MBExp.py:145][0m Starting training iteration 99.
[32m[0907 14-40-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.45735, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-40-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35131, current rewards: -65.03067, mean: -1.08384
[32m[0907 14-40-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33696, current rewards: -130.09050, mean: -1.18264
[32m[0907 14-41-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32600, current rewards: -187.94201, mean: -1.17464
[32m[0907 14-41-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32021, current rewards: -234.91206, mean: -1.11863
[32m[0907 14-41-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31787, current rewards: -289.87463, mean: -1.11490
[32m[0907 14-41-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31674, current rewards: -341.22202, mean: -1.10072
[32m[0907 14-42-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31973, current rewards: -383.15625, mean: -1.06432
[32m[0907 14-42-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32222, current rewards: -425.75104, mean: -1.03842
[32m[0907 14-42-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32626, current rewards: -498.59614, mean: -1.08390
[32m[0907 14-43-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33284, current rewards: -548.48596, mean: -1.07546
[32m[0907 14-43-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33941, current rewards: -590.14979, mean: -1.05384
[32m[0907 14-43-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34246, current rewards: -653.20445, mean: -1.07083
[32m[0907 14-44-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34488, current rewards: -691.80699, mean: -1.04819
[32m[0907 14-44-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34756, current rewards: -739.23164, mean: -1.04117
[32m[0907 14-44-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34897, current rewards: -781.07230, mean: -1.02773
[32m[0907 14-45-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35103, current rewards: -823.26412, mean: -1.01638
[32m[0907 14-45-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35555, current rewards: -873.18660, mean: -1.01533
[32m[0907 14-45-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35566, current rewards: -912.47980, mean: -1.00273
[32m[0907 14-45-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35356, current rewards: -962.47980, mean: -1.00258
[32m[0907 14-46-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35165, current rewards: -1012.47980, mean: -1.00246
[32m[0907 14-46-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34994, current rewards: -1062.47980, mean: -1.00234
[32m[0907 14-46-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34835, current rewards: -1112.47980, mean: -1.00223
[32m[0907 14-46-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34691, current rewards: -1162.47980, mean: -1.00214
[32m[0907 14-47-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34558, current rewards: -1212.47980, mean: -1.00205
[32m[0907 14-47-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34439, current rewards: -1262.47980, mean: -1.00197
[32m[0907 14-47-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34327, current rewards: -1312.47980, mean: -1.00189
[32m[0907 14-48-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34224, current rewards: -1362.47980, mean: -1.00182
[32m[0907 14-48-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34128, current rewards: -1412.47980, mean: -1.00176
[32m[0907 14-48-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34014, current rewards: -1462.47980, mean: -1.00170
[32m[0907 14-48-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33908, current rewards: -1512.47980, mean: -1.00164
[32m[0907 14-49-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33806, current rewards: -1562.47980, mean: -1.00159
[32m[0907 14-49-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33713, current rewards: -1612.47980, mean: -1.00154
[32m[0907 14-49-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33623, current rewards: -1662.47980, mean: -1.00149
[32m[0907 14-49-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33542, current rewards: -1712.47980, mean: -1.00145
[32m[0907 14-50-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33464, current rewards: -1737.64968, mean: -0.98730
[32m[0907 14-50-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33390, current rewards: -1733.67115, mean: -0.95783
[32m[0907 14-50-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33320, current rewards: -1729.69262, mean: -0.92994
[32m[0907 14-50-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33253, current rewards: -1725.71410, mean: -0.90352
[32m[0907 14-51-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33190, current rewards: -1722.36000, mean: -0.87876
[32m[0907 14-51-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33130, current rewards: -1719.02397, mean: -0.85524
[32m[0907 14-51-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33088, current rewards: -1715.68795, mean: -0.83286
[32m[0907 14-51-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33052, current rewards: -1712.35193, mean: -0.81154
[32m[0907 14-52-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33020, current rewards: -1726.08343, mean: -0.79911
[32m[0907 14-52-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32987, current rewards: -1776.08343, mean: -0.80366
[32m[0907 14-52-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32957, current rewards: -1826.08343, mean: -0.80800
[32m[0907 14-52-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32928, current rewards: -1876.08343, mean: -0.81216
[32m[0907 14-53-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32900, current rewards: -1926.08343, mean: -0.81614
[32m[0907 14-53-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32860, current rewards: -1976.08343, mean: -0.81995
[32m[0907 14-53-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32818, current rewards: -2026.08343, mean: -0.82361
[32m[0907 14-53-56 @Agent.py:117][0m Average action selection time: 0.3279
[32m[0907 14-53-56 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-53-57 @MBExp.py:227][0m Rewards obtained: [-2066.083432488106], Lows: [303], Highs: [1536], Total time: 81485.53290700002
[32m[0907 14-56-59 @MBExp.py:144][0m ####################################################################
[32m[0907 14-56-59 @MBExp.py:145][0m Starting training iteration 100.
[32m[0907 14-57-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31782, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-57-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.40033, current rewards: -52.60364, mean: -0.87673
[32m[0907 14-57-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36012, current rewards: -48.27569, mean: -0.43887
[32m[0907 14-57-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34423, current rewards: -48.52447, mean: -0.30328
[32m[0907 14-58-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34605, current rewards: -60.73762, mean: -0.28923
[32m[0907 14-58-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34260, current rewards: -54.50704, mean: -0.20964
[32m[0907 14-58-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34275, current rewards: -61.38242, mean: -0.19801
[32m[0907 14-59-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33921, current rewards: -63.13235, mean: -0.17537
[32m[0907 14-59-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33642, current rewards: -56.03579, mean: -0.13667
[32m[0907 14-59-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33414, current rewards: -48.93923, mean: -0.10639
[32m[0907 14-59-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33238, current rewards: -41.84268, mean: -0.08204
[32m[0907 15-00-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33097, current rewards: -34.74613, mean: -0.06205
[32m[0907 15-00-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32977, current rewards: -27.64958, mean: -0.04533
[32m[0907 15-00-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32872, current rewards: -67.37220, mean: -0.10208
[32m[0907 15-00-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32781, current rewards: -117.37220, mean: -0.16531
[32m[0907 15-01-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32707, current rewards: -167.37220, mean: -0.22023
[32m[0907 15-01-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32637, current rewards: -217.37220, mean: -0.26836
[32m[0907 15-01-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32572, current rewards: -267.37220, mean: -0.31090
[32m[0907 15-01-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32517, current rewards: -317.37220, mean: -0.34876
[32m[0907 15-02-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32464, current rewards: -367.37220, mean: -0.38268
[32m[0907 15-02-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32420, current rewards: -417.37220, mean: -0.41324
[32m[0907 15-02-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32378, current rewards: -467.37220, mean: -0.44092
[32m[0907 15-02-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32341, current rewards: -517.37220, mean: -0.46610
[32m[0907 15-03-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32312, current rewards: -567.37220, mean: -0.48911
[32m[0907 15-03-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32278, current rewards: -617.37220, mean: -0.51022
[32m[0907 15-03-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32248, current rewards: -667.37220, mean: -0.52966
[32m[0907 15-04-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32223, current rewards: -717.37220, mean: -0.54761
[32m[0907 15-04-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32199, current rewards: -767.37220, mean: -0.56424
[32m[0907 15-04-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32147, current rewards: -817.37220, mean: -0.57970
[32m[0907 15-04-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32101, current rewards: -867.37220, mean: -0.59409
[32m[0907 15-05-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32058, current rewards: -917.37220, mean: -0.60753
[32m[0907 15-05-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32018, current rewards: -967.37220, mean: -0.62011
[32m[0907 15-05-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31980, current rewards: -1017.37220, mean: -0.63191
[32m[0907 15-05-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31945, current rewards: -1067.37220, mean: -0.64300
[32m[0907 15-06-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31911, current rewards: -1117.37220, mean: -0.65343
[32m[0907 15-06-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31880, current rewards: -1167.37220, mean: -0.66328
[32m[0907 15-06-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31850, current rewards: -1217.37220, mean: -0.67258
[32m[0907 15-06-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31821, current rewards: -1267.37220, mean: -0.68138
[32m[0907 15-07-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31794, current rewards: -1317.37220, mean: -0.68972
[32m[0907 15-07-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31768, current rewards: -1367.37220, mean: -0.69764
[32m[0907 15-07-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31760, current rewards: -1417.37220, mean: -0.70516
[32m[0907 15-07-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31754, current rewards: -1467.37220, mean: -0.71232
[32m[0907 15-08-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31748, current rewards: -1517.37220, mean: -0.71913
[32m[0907 15-08-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31743, current rewards: -1567.37220, mean: -0.72564
[32m[0907 15-08-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31737, current rewards: -1617.37220, mean: -0.73184
[32m[0907 15-08-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31733, current rewards: -1667.37220, mean: -0.73778
[32m[0907 15-09-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31729, current rewards: -1717.37220, mean: -0.74345
[32m[0907 15-09-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31717, current rewards: -1767.37220, mean: -0.74889
[32m[0907 15-09-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31697, current rewards: -1817.37220, mean: -0.75410
[32m[0907 15-09-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31678, current rewards: -1867.37220, mean: -0.75909
[32m[0907 15-10-11 @Agent.py:117][0m Average action selection time: 0.3166
[32m[0907 15-10-11 @Agent.py:118][0m Rollout length: 2520
[32m[0907 15-10-11 @MBExp.py:227][0m Rewards obtained: [-1907.372197191204], Lows: [11], Highs: [1954], Total time: 82277.87364900002
[32m[0907 15-13-16 @MBExp.py:144][0m ####################################################################
[32m[0907 15-13-16 @MBExp.py:145][0m Starting training iteration 101.
[32m[0907 15-13-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29889, current rewards: -10.00000, mean: -1.00000
[32m[0907 15-13-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29911, current rewards: -10.32155, mean: -0.17203
[32m[0907 15-13-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29918, current rewards: -6.28002, mean: -0.05709
[32m[0907 15-14-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29928, current rewards: -2.23848, mean: -0.01399
[32m[0907 15-14-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29923, current rewards: 1.58963, mean: 0.00757
[32m[0907 15-14-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30177, current rewards: 4.37013, mean: 0.01681
[32m[0907 15-14-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30403, current rewards: 7.15062, mean: 0.02307
[32m[0907 15-15-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30563, current rewards: 9.93112, mean: 0.02759
[32m[0907 15-15-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30689, current rewards: 12.71162, mean: 0.03100
[32m[0907 15-15-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30790, current rewards: 15.49212, mean: 0.03368
[32m[0907 15-15-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30874, current rewards: 18.27262, mean: 0.03583
[32m[0907 15-16-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30940, current rewards: 21.05312, mean: 0.03759
[32m[0907 15-16-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30990, current rewards: 14.33313, mean: 0.02350
[32m[0907 15-16-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31038, current rewards: -35.66687, mean: -0.05404
[32m[0907 15-16-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31077, current rewards: -85.66687, mean: -0.12066
[32m[0907 15-17-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31105, current rewards: -135.66687, mean: -0.17851
[32m[0907 15-17-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31123, current rewards: -185.66687, mean: -0.22922
[32m[0907 15-17-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31146, current rewards: -235.66687, mean: -0.27403
[32m[0907 15-18-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31164, current rewards: -285.66687, mean: -0.31392
[32m[0907 15-18-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31179, current rewards: -335.66687, mean: -0.34965
[32m[0907 15-18-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31189, current rewards: -385.66687, mean: -0.38185
[32m[0907 15-18-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31198, current rewards: -435.66687, mean: -0.41101
[32m[0907 15-19-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31215, current rewards: -485.66687, mean: -0.43754
[32m[0907 15-19-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31227, current rewards: -535.66687, mean: -0.46178
[32m[0907 15-19-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31235, current rewards: -585.66687, mean: -0.48402
[32m[0907 15-19-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31244, current rewards: -635.66687, mean: -0.50450
[32m[0907 15-20-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31255, current rewards: -685.66687, mean: -0.52341
[32m[0907 15-20-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31256, current rewards: -735.66687, mean: -0.54093
[32m[0907 15-20-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31240, current rewards: -785.66687, mean: -0.55721
[32m[0907 15-20-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31223, current rewards: -835.66687, mean: -0.57237
[32m[0907 15-21-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31209, current rewards: -885.66687, mean: -0.58653
[32m[0907 15-21-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31197, current rewards: -935.66687, mean: -0.59979
[32m[0907 15-21-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31184, current rewards: -985.66687, mean: -0.61222
[32m[0907 15-21-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31171, current rewards: -1035.66687, mean: -0.62390
[32m[0907 15-22-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31160, current rewards: -1085.66687, mean: -0.63489
[32m[0907 15-22-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31146, current rewards: -1135.66687, mean: -0.64527
[32m[0907 15-22-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31134, current rewards: -1185.66687, mean: -0.65506
[32m[0907 15-22-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31124, current rewards: -1235.66687, mean: -0.66434
[32m[0907 15-23-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31113, current rewards: -1285.66687, mean: -0.67312
[32m[0907 15-23-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31102, current rewards: -1335.66687, mean: -0.68146
[32m[0907 15-23-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31109, current rewards: -1385.66687, mean: -0.68939
[32m[0907 15-23-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31121, current rewards: -1435.66687, mean: -0.69693
[32m[0907 15-24-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31132, current rewards: -1485.66687, mean: -0.70411
[32m[0907 15-24-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31141, current rewards: -1535.66687, mean: -0.71096
[32m[0907 15-24-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31152, current rewards: -1585.66687, mean: -0.71750
[32m[0907 15-25-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31160, current rewards: -1635.66687, mean: -0.72375
[32m[0907 15-25-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31168, current rewards: -1685.66687, mean: -0.72973
[32m[0907 15-25-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31171, current rewards: -1735.66687, mean: -0.73545
[32m[0907 15-25-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31164, current rewards: -1785.66687, mean: -0.74094
[32m[0907 15-26-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31156, current rewards: -1835.66687, mean: -0.74621
[32m[0907 15-26-15 @Agent.py:117][0m Average action selection time: 0.3115
[32m[0907 15-26-15 @Agent.py:118][0m Rollout length: 2520
[32m[0907 15-26-15 @MBExp.py:227][0m Rewards obtained: [-1875.6668726628034], Lows: [2], Highs: [1909], Total time: 83057.38410600001
[32m[0907 15-29-22 @MBExp.py:144][0m ####################################################################
[32m[0907 15-29-22 @MBExp.py:145][0m Starting training iteration 102.
[32m[0907 15-29-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29922, current rewards: -10.00000, mean: -1.00000
[32m[0907 15-29-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32963, current rewards: -81.43837, mean: -1.35731
[32m[0907 15-29-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33485, current rewards: -160.37015, mean: -1.45791
[32m[0907 15-30-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33511, current rewards: -245.20931, mean: -1.53256
[32m[0907 15-30-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33517, current rewards: -332.25064, mean: -1.58215
[32m[0907 15-30-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33361, current rewards: -432.25064, mean: -1.66250
[32m[0907 15-31-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33350, current rewards: -532.25064, mean: -1.71694
[32m[0907 15-31-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33351, current rewards: -632.25064, mean: -1.75625
[32m[0907 15-31-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33217, current rewards: -732.25064, mean: -1.78598
[32m[0907 15-31-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33247, current rewards: -832.25064, mean: -1.80924
[32m[0907 15-32-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33642, current rewards: -910.46656, mean: -1.78523
[32m[0907 15-32-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33749, current rewards: -994.91274, mean: -1.77663
[32m[0907 15-32-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33839, current rewards: -1094.91274, mean: -1.79494
[32m[0907 15-33-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34193, current rewards: -1183.45231, mean: -1.79311
[32m[0907 15-33-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34598, current rewards: -1275.06652, mean: -1.79587
[32m[0907 15-33-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34841, current rewards: -1357.96652, mean: -1.78680
[32m[0907 15-34-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35013, current rewards: -1451.33851, mean: -1.79178
[32m[0907 15-34-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35107, current rewards: -1500.14394, mean: -1.74435
[32m[0907 15-34-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35179, current rewards: -1554.33574, mean: -1.70806
[32m[0907 15-35-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35342, current rewards: -1591.85549, mean: -1.65818
[32m[0907 15-35-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35424, current rewards: -1653.62946, mean: -1.63726
[32m[0907 15-35-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35722, current rewards: -1731.35076, mean: -1.63335
[32m[0907 15-36-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35840, current rewards: -1807.80954, mean: -1.62866
[32m[0907 15-36-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36150, current rewards: -1899.26933, mean: -1.63730
[32m[0907 15-36-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36185, current rewards: -1971.12364, mean: -1.62903
[32m[0907 15-37-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36309, current rewards: -2052.52341, mean: -1.62899
[32m[0907 15-37-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36412, current rewards: -2117.41288, mean: -1.61635
[32m[0907 15-37-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36640, current rewards: -2210.70179, mean: -1.62552
[32m[0907 15-38-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36814, current rewards: -2299.45447, mean: -1.63082
[32m[0907 15-38-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36764, current rewards: -2392.95400, mean: -1.63901
[32m[0907 15-38-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36922, current rewards: -2460.06977, mean: -1.62919
[32m[0907 15-38-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36885, current rewards: -2541.44227, mean: -1.62913
[32m[0907 15-39-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36912, current rewards: -2618.05788, mean: -1.62612
[32m[0907 15-39-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36906, current rewards: -2695.98706, mean: -1.62409
[32m[0907 15-39-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36833, current rewards: -2795.98706, mean: -1.63508
[32m[0907 15-40-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36763, current rewards: -2895.98706, mean: -1.64545
[32m[0907 15-40-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36696, current rewards: -2995.98706, mean: -1.65524
[32m[0907 15-40-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36658, current rewards: -3095.98706, mean: -1.66451
[32m[0907 15-41-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36622, current rewards: -3195.98706, mean: -1.67329
[32m[0907 15-41-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36585, current rewards: -3295.98706, mean: -1.68163
[32m[0907 15-41-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36553, current rewards: -3395.98706, mean: -1.68955
[32m[0907 15-41-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36524, current rewards: -3495.98706, mean: -1.69708
[32m[0907 15-42-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36496, current rewards: -3595.98706, mean: -1.70426
[32m[0907 15-42-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36469, current rewards: -3695.98706, mean: -1.71111
[32m[0907 15-42-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36428, current rewards: -3795.98706, mean: -1.71764
[32m[0907 15-43-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36381, current rewards: -3895.98706, mean: -1.72389
[32m[0907 15-43-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36337, current rewards: -3995.98706, mean: -1.72986
[32m[0907 15-43-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36296, current rewards: -4095.98706, mean: -1.73559
[32m[0907 15-43-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36263, current rewards: -4195.98706, mean: -1.74107
[32m[0907 15-44-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36238, current rewards: -4295.98706, mean: -1.74634
[32m[0907 15-44-28 @Agent.py:117][0m Average action selection time: 0.3622
[32m[0907 15-44-28 @Agent.py:118][0m Rollout length: 2520
[32m[0907 15-44-29 @MBExp.py:227][0m Rewards obtained: [-4375.987061856382], Lows: [2172], Highs: [86], Total time: 83963.742473
[32m[0907 15-48-12 @MBExp.py:144][0m ####################################################################
[32m[0907 15-48-12 @MBExp.py:145][0m Starting training iteration 103.
[32m[0907 15-48-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.53020, current rewards: -10.00000, mean: -1.00000
[32m[0907 15-48-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.41118, current rewards: -100.00000, mean: -1.66667
[32m[0907 15-48-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.39058, current rewards: -195.76533, mean: -1.77968
[32m[0907 15-49-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.38263, current rewards: -295.76533, mean: -1.84853
[32m[0907 15-49-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37842, current rewards: -390.69591, mean: -1.86046
[32m[0907 15-49-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37587, current rewards: -490.69591, mean: -1.88729
[32m[0907 15-50-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37406, current rewards: -588.39454, mean: -1.89805
[32m[0907 15-50-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37272, current rewards: -684.12401, mean: -1.90034
[32m[0907 15-50-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37183, current rewards: -784.12401, mean: -1.91250
[32m[0907 15-51-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37093, current rewards: -879.76507, mean: -1.91253
[32m[0907 15-51-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37027, current rewards: -979.76507, mean: -1.92111
[32m[0907 15-51-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36971, current rewards: -1077.65611, mean: -1.92439
[32m[0907 15-51-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36930, current rewards: -1175.52126, mean: -1.92708
[32m[0907 15-52-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36893, current rewards: -1273.25084, mean: -1.92917
[32m[0907 15-52-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36861, current rewards: -1368.26998, mean: -1.92714
[32m[0907 15-52-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36834, current rewards: -1465.17879, mean: -1.92787
[32m[0907 15-53-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36812, current rewards: -1564.17879, mean: -1.93108
[32m[0907 15-53-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36793, current rewards: -1659.07504, mean: -1.92916
[32m[0907 15-53-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36765, current rewards: -1757.07504, mean: -1.93085
[32m[0907 15-54-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36750, current rewards: -1856.07504, mean: -1.93341
[32m[0907 15-54-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36804, current rewards: -1954.01451, mean: -1.93467
[32m[0907 15-54-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36790, current rewards: -2051.86127, mean: -1.93572
[32m[0907 15-55-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36771, current rewards: -2151.86127, mean: -1.93861
[32m[0907 15-55-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36742, current rewards: -2251.86127, mean: -1.94126
[32m[0907 15-55-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36697, current rewards: -2347.39304, mean: -1.93999
[32m[0907 15-55-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36658, current rewards: -2447.39304, mean: -1.94238
[32m[0907 15-56-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36619, current rewards: -2547.39304, mean: -1.94457
[32m[0907 15-56-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36582, current rewards: -2647.39304, mean: -1.94661
[32m[0907 15-56-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36548, current rewards: -2747.39304, mean: -1.94851
[32m[0907 15-57-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36516, current rewards: -2847.39304, mean: -1.95027
[32m[0907 15-57-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36483, current rewards: -2947.39304, mean: -1.95192
[32m[0907 15-57-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36453, current rewards: -3047.39304, mean: -1.95346
[32m[0907 15-57-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36425, current rewards: -3147.39304, mean: -1.95490
[32m[0907 15-58-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36400, current rewards: -3247.39304, mean: -1.95626
[32m[0907 15-58-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36382, current rewards: -3345.20935, mean: -1.95626
[32m[0907 15-58-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36356, current rewards: -3433.88821, mean: -1.95107
[32m[0907 15-59-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36340, current rewards: -3533.88821, mean: -1.95242
[32m[0907 15-59-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36341, current rewards: -3633.88821, mean: -1.95370
[32m[0907 15-59-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36345, current rewards: -3733.88821, mean: -1.95492
[32m[0907 16-00-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36351, current rewards: -3833.88821, mean: -1.95607
[32m[0907 16-00-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36355, current rewards: -3933.88821, mean: -1.95716
[32m[0907 16-00-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36353, current rewards: -4033.88821, mean: -1.95820
[32m[0907 16-01-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36356, current rewards: -4133.88821, mean: -1.95919
[32m[0907 16-01-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36356, current rewards: -4233.88821, mean: -1.96013
[32m[0907 16-01-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36339, current rewards: -4333.88821, mean: -1.96104
[32m[0907 16-01-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36322, current rewards: -4433.88821, mean: -1.96190
[32m[0907 16-02-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36305, current rewards: -4533.88821, mean: -1.96272
[32m[0907 16-02-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36289, current rewards: -4633.88821, mean: -1.96351
[32m[0907 16-02-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36275, current rewards: -4733.88821, mean: -1.96427
[32m[0907 16-03-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36262, current rewards: -4833.88821, mean: -1.96500
[32m[0907 16-03-19 @Agent.py:117][0m Average action selection time: 0.3625
[32m[0907 16-03-19 @Agent.py:118][0m Rollout length: 2520
[32m[0907 16-03-19 @MBExp.py:227][0m Rewards obtained: [-4913.888208616818], Lows: [2448], Highs: [25], Total time: 84870.885571
[32m[0907 16-07-07 @MBExp.py:144][0m ####################################################################
[32m[0907 16-07-07 @MBExp.py:145][0m Starting training iteration 104.
[32m[0907 16-07-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36176, current rewards: -10.00000, mean: -1.00000
[32m[0907 16-07-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34939, current rewards: -100.00000, mean: -1.66667
[32m[0907 16-07-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35705, current rewards: -200.00000, mean: -1.81818
[32m[0907 16-08-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35934, current rewards: -300.00000, mean: -1.87500
[32m[0907 16-08-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36080, current rewards: -400.00000, mean: -1.90476
[32m[0907 16-08-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36162, current rewards: -500.00000, mean: -1.92308
[32m[0907 16-08-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36199, current rewards: -600.00000, mean: -1.93548
[32m[0907 16-09-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36237, current rewards: -700.00000, mean: -1.94444
[32m[0907 16-09-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36279, current rewards: -800.00000, mean: -1.95122
[32m[0907 16-09-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36306, current rewards: -900.00000, mean: -1.95652
[32m[0907 16-10-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36306, current rewards: -1000.00000, mean: -1.96078
[32m[0907 16-10-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36319, current rewards: -1100.00000, mean: -1.96429
[32m[0907 16-10-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36321, current rewards: -1200.00000, mean: -1.96721
[32m[0907 16-11-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36327, current rewards: -1300.00000, mean: -1.96970
[32m[0907 16-11-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36337, current rewards: -1400.00000, mean: -1.97183
[32m[0907 16-11-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36341, current rewards: -1500.00000, mean: -1.97368
[32m[0907 16-12-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36347, current rewards: -1600.00000, mean: -1.97531
[32m[0907 16-12-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36340, current rewards: -1700.00000, mean: -1.97674
[32m[0907 16-12-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36340, current rewards: -1800.00000, mean: -1.97802
[32m[0907 16-12-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36337, current rewards: -1900.00000, mean: -1.97917
[32m[0907 16-13-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36342, current rewards: -2000.00000, mean: -1.98020
[32m[0907 16-13-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36344, current rewards: -2100.00000, mean: -1.98113
[32m[0907 16-13-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36342, current rewards: -2200.00000, mean: -1.98198
[32m[0907 16-14-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36312, current rewards: -2300.00000, mean: -1.98276
[32m[0907 16-14-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36284, current rewards: -2400.00000, mean: -1.98347
[32m[0907 16-14-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36255, current rewards: -2500.00000, mean: -1.98413
[32m[0907 16-15-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36226, current rewards: -2600.00000, mean: -1.98473
[32m[0907 16-15-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36202, current rewards: -2700.00000, mean: -1.98529
[32m[0907 16-15-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36179, current rewards: -2800.00000, mean: -1.98582
[32m[0907 16-15-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36157, current rewards: -2900.00000, mean: -1.98630
[32m[0907 16-16-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36139, current rewards: -3000.00000, mean: -1.98675
[32m[0907 16-16-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36119, current rewards: -3100.00000, mean: -1.98718
[32m[0907 16-16-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36104, current rewards: -3200.00000, mean: -1.98758
[32m[0907 16-17-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36085, current rewards: -3300.00000, mean: -1.98795
[32m[0907 16-17-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36069, current rewards: -3400.00000, mean: -1.98830
[32m[0907 16-17-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36053, current rewards: -3500.00000, mean: -1.98864
[32m[0907 16-18-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36061, current rewards: -3600.00000, mean: -1.98895
[32m[0907 16-18-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36068, current rewards: -3700.00000, mean: -1.98925
[32m[0907 16-18-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36078, current rewards: -3800.00000, mean: -1.98953
[32m[0907 16-18-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36086, current rewards: -3900.00000, mean: -1.98980
[32m[0907 16-19-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36093, current rewards: -4000.00000, mean: -1.99005
[32m[0907 16-19-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36100, current rewards: -4100.00000, mean: -1.99029
[32m[0907 16-19-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36111, current rewards: -4200.00000, mean: -1.99052
[32m[0907 16-20-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36119, current rewards: -4300.00000, mean: -1.99074
[32m[0907 16-20-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36121, current rewards: -4400.00000, mean: -1.99095
[32m[0907 16-20-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36122, current rewards: -4500.00000, mean: -1.99115
[32m[0907 16-21-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36124, current rewards: -4600.00000, mean: -1.99134
[32m[0907 16-21-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36127, current rewards: -4700.00000, mean: -1.99153
[32m[0907 16-21-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36129, current rewards: -4800.00000, mean: -1.99170
[32m[0907 16-21-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36128, current rewards: -4900.00000, mean: -1.99187
[32m[0907 16-22-11 @Agent.py:117][0m Average action selection time: 0.3613
[32m[0907 16-22-11 @Agent.py:118][0m Rollout length: 2520
[32m[0907 16-22-11 @MBExp.py:227][0m Rewards obtained: [-4980], Lows: [2480], Highs: [20], Total time: 85774.955357
[32m[0907 16-26-06 @MBExp.py:144][0m ####################################################################
[32m[0907 16-26-06 @MBExp.py:145][0m Starting training iteration 105.
[32m[0907 16-26-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36315, current rewards: -10.00000, mean: -1.00000
[32m[0907 16-26-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37241, current rewards: -70.24906, mean: -1.17082
[32m[0907 16-26-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.40038, current rewards: -139.65492, mean: -1.26959
[32m[0907 16-27-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.40170, current rewards: -214.97134, mean: -1.34357
[32m[0907 16-27-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.40936, current rewards: -284.86824, mean: -1.35652
[32m[0907 16-27-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.41259, current rewards: -353.58765, mean: -1.35995
[32m[0907 16-28-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.41273, current rewards: -430.27956, mean: -1.38800
[32m[0907 16-28-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.41278, current rewards: -488.02724, mean: -1.35563
[32m[0907 16-28-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.40771, current rewards: -574.95503, mean: -1.40233
[32m[0907 16-29-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.40379, current rewards: -674.95503, mean: -1.46729
[32m[0907 16-29-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.40058, current rewards: -774.95503, mean: -1.51952
[32m[0907 16-29-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.39796, current rewards: -874.95503, mean: -1.56242
[32m[0907 16-30-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.39568, current rewards: -974.95503, mean: -1.59829
[32m[0907 16-30-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.39376, current rewards: -1074.95503, mean: -1.62872
[32m[0907 16-30-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.39204, current rewards: -1174.95503, mean: -1.65487
[32m[0907 16-31-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.39075, current rewards: -1274.95503, mean: -1.67757
[32m[0907 16-31-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.38953, current rewards: -1374.95503, mean: -1.69748
[32m[0907 16-31-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.38839, current rewards: -1474.95503, mean: -1.71506
[32m[0907 16-31-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.38736, current rewards: -1574.95503, mean: -1.73072
[32m[0907 16-32-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.38643, current rewards: -1674.95503, mean: -1.74474
[32m[0907 16-32-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.38555, current rewards: -1774.95503, mean: -1.75738
[32m[0907 16-32-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.38488, current rewards: -1874.95503, mean: -1.76883
[32m[0907 16-33-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.38426, current rewards: -1974.95503, mean: -1.77924
[32m[0907 16-33-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.38337, current rewards: -2074.95503, mean: -1.78875
[32m[0907 16-33-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.38247, current rewards: -2174.95503, mean: -1.79748
[32m[0907 16-34-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.38165, current rewards: -2274.95503, mean: -1.80552
[32m[0907 16-34-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.38090, current rewards: -2374.95503, mean: -1.81294
[32m[0907 16-34-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.38021, current rewards: -2474.95503, mean: -1.81982
[32m[0907 16-35-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.37954, current rewards: -2574.95503, mean: -1.82621
[32m[0907 16-35-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.37892, current rewards: -2674.95503, mean: -1.83216
[32m[0907 16-35-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.37838, current rewards: -2774.95503, mean: -1.83772
[32m[0907 16-35-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.37787, current rewards: -2874.95503, mean: -1.84292
[32m[0907 16-36-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.37744, current rewards: -2974.95503, mean: -1.84780
[32m[0907 16-36-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.37699, current rewards: -3074.95503, mean: -1.85238
[32m[0907 16-36-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.37656, current rewards: -3174.95503, mean: -1.85670
[32m[0907 16-37-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.37616, current rewards: -3274.95503, mean: -1.86077
[32m[0907 16-37-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.37586, current rewards: -3374.95503, mean: -1.86462
[32m[0907 16-37-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.37575, current rewards: -3474.95503, mean: -1.86826
[32m[0907 16-38-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.37559, current rewards: -3574.95503, mean: -1.87170
[32m[0907 16-38-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.37546, current rewards: -3674.95503, mean: -1.87498
[32m[0907 16-38-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.37534, current rewards: -3774.95503, mean: -1.87809
[32m[0907 16-39-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.37524, current rewards: -3874.95503, mean: -1.88105
[32m[0907 16-39-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.37507, current rewards: -3974.95503, mean: -1.88386
[32m[0907 16-39-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.37479, current rewards: -4074.95503, mean: -1.88655
[32m[0907 16-39-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.37451, current rewards: -4174.95503, mean: -1.88912
[32m[0907 16-40-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.37421, current rewards: -4274.95503, mean: -1.89157
[32m[0907 16-40-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.37393, current rewards: -4374.95503, mean: -1.89392
[32m[0907 16-40-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.37369, current rewards: -4474.95503, mean: -1.89617
[32m[0907 16-41-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.37344, current rewards: -4574.95503, mean: -1.89832
[32m[0907 16-41-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.37321, current rewards: -4674.95503, mean: -1.90039
[32m[0907 16-41-39 @Agent.py:117][0m Average action selection time: 0.3730
[32m[0907 16-41-39 @Agent.py:118][0m Rollout length: 2520
[32m[0907 16-41-39 @MBExp.py:227][0m Rewards obtained: [-4754.955025408146], Lows: [2310], Highs: [143], Total time: 86708.431824
[32m[0907 16-45-36 @MBExp.py:144][0m ####################################################################
[32m[0907 16-45-36 @MBExp.py:145][0m Starting training iteration 106.
[32m[0907 16-45-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35267, current rewards: -10.00000, mean: -1.00000
[32m[0907 16-45-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36238, current rewards: -62.59525, mean: -1.04325
[32m[0907 16-46-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36727, current rewards: -122.99806, mean: -1.11816
[32m[0907 16-46-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36817, current rewards: -189.77835, mean: -1.18611
[32m[0907 16-46-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36879, current rewards: -256.66015, mean: -1.22219
[32m[0907 16-47-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36914, current rewards: -331.71621, mean: -1.27583
[32m[0907 16-47-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36925, current rewards: -408.05941, mean: -1.31632
[32m[0907 16-47-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36932, current rewards: -482.29059, mean: -1.33970
[32m[0907 16-48-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37023, current rewards: -554.80819, mean: -1.35319
[32m[0907 16-48-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37100, current rewards: -629.40275, mean: -1.36827
[32m[0907 16-48-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37092, current rewards: -726.35092, mean: -1.42422
[32m[0907 16-49-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37077, current rewards: -826.35092, mean: -1.47563
[32m[0907 16-49-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37072, current rewards: -926.35092, mean: -1.51861
[32m[0907 16-49-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37070, current rewards: -1026.35092, mean: -1.55508
[32m[0907 16-50-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37066, current rewards: -1126.35092, mean: -1.58641
[32m[0907 16-50-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37055, current rewards: -1226.35092, mean: -1.61362
[32m[0907 16-50-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37044, current rewards: -1326.35092, mean: -1.63747
[32m[0907 16-50-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37036, current rewards: -1426.35092, mean: -1.65855
[32m[0907 16-51-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37027, current rewards: -1526.35092, mean: -1.67731
[32m[0907 16-51-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37022, current rewards: -1626.35092, mean: -1.69412
[32m[0907 16-51-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37019, current rewards: -1726.35092, mean: -1.70926
[32m[0907 16-52-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37017, current rewards: -1826.35092, mean: -1.72297
[32m[0907 16-52-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37003, current rewards: -1926.35092, mean: -1.73545
[32m[0907 16-52-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36965, current rewards: -2026.35092, mean: -1.74685
[32m[0907 16-53-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36933, current rewards: -2126.35092, mean: -1.75731
[32m[0907 16-53-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36901, current rewards: -2226.35092, mean: -1.76695
[32m[0907 16-53-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36871, current rewards: -2326.35092, mean: -1.77584
[32m[0907 16-53-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36844, current rewards: -2426.35092, mean: -1.78408
[32m[0907 16-54-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36820, current rewards: -2526.35092, mean: -1.79174
[32m[0907 16-54-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36799, current rewards: -2626.35092, mean: -1.79887
[32m[0907 16-54-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36777, current rewards: -2726.35092, mean: -1.80553
[32m[0907 16-55-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36753, current rewards: -2826.35092, mean: -1.81176
[32m[0907 16-55-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36735, current rewards: -2926.35092, mean: -1.81761
[32m[0907 16-55-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36717, current rewards: -3026.35092, mean: -1.82310
[32m[0907 16-56-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36701, current rewards: -3126.35092, mean: -1.82828
[32m[0907 16-56-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36683, current rewards: -3226.35092, mean: -1.83315
[32m[0907 16-56-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36687, current rewards: -3326.35092, mean: -1.83776
[32m[0907 16-56-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36694, current rewards: -3426.35092, mean: -1.84212
[32m[0907 16-57-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36702, current rewards: -3526.35092, mean: -1.84626
[32m[0907 16-57-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36710, current rewards: -3626.35092, mean: -1.85018
[32m[0907 16-57-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36717, current rewards: -3726.35092, mean: -1.85391
[32m[0907 16-58-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36724, current rewards: -3826.35092, mean: -1.85745
[32m[0907 16-58-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36721, current rewards: -3926.35092, mean: -1.86083
[32m[0907 16-58-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36708, current rewards: -4026.35092, mean: -1.86405
[32m[0907 16-59-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36694, current rewards: -4126.35092, mean: -1.86713
[32m[0907 16-59-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36683, current rewards: -4226.35092, mean: -1.87007
[32m[0907 16-59-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36671, current rewards: -4326.35092, mean: -1.87288
[32m[0907 17-00-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36660, current rewards: -4426.35092, mean: -1.87557
[32m[0907 17-00-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36650, current rewards: -4526.35092, mean: -1.87815
[32m[0907 17-00-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36638, current rewards: -4626.35092, mean: -1.88063
[32m[0907 17-00-53 @Agent.py:117][0m Average action selection time: 0.3663
[32m[0907 17-00-53 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-00-53 @MBExp.py:227][0m Rewards obtained: [-4706.350916847346], Lows: [2270], Highs: [172], Total time: 87625.045466
[32m[0907 17-04-52 @MBExp.py:144][0m ####################################################################
[32m[0907 17-04-52 @MBExp.py:145][0m Starting training iteration 107.
[32m[0907 17-04-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35189, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-05-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36316, current rewards: -99.00000, mean: -1.65000
[32m[0907 17-05-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36738, current rewards: -199.00000, mean: -1.80909
[32m[0907 17-05-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36846, current rewards: -299.00000, mean: -1.86875
[32m[0907 17-06-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36932, current rewards: -399.00000, mean: -1.90000
[32m[0907 17-06-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36967, current rewards: -499.00000, mean: -1.91923
[32m[0907 17-06-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37008, current rewards: -599.00000, mean: -1.93226
[32m[0907 17-07-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37008, current rewards: -699.00000, mean: -1.94167
[32m[0907 17-07-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37007, current rewards: -799.00000, mean: -1.94878
[32m[0907 17-07-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37016, current rewards: -899.00000, mean: -1.95435
[32m[0907 17-08-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37027, current rewards: -999.00000, mean: -1.95882
[32m[0907 17-08-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37033, current rewards: -1099.00000, mean: -1.96250
[32m[0907 17-08-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37042, current rewards: -1199.00000, mean: -1.96557
[32m[0907 17-08-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37049, current rewards: -1299.00000, mean: -1.96818
[32m[0907 17-09-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37052, current rewards: -1399.00000, mean: -1.97042
[32m[0907 17-09-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37053, current rewards: -1499.00000, mean: -1.97237
[32m[0907 17-09-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37049, current rewards: -1599.00000, mean: -1.97407
[32m[0907 17-10-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37052, current rewards: -1699.00000, mean: -1.97558
[32m[0907 17-10-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37050, current rewards: -1799.00000, mean: -1.97692
[32m[0907 17-10-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37044, current rewards: -1899.00000, mean: -1.97812
[32m[0907 17-11-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37032, current rewards: -1999.00000, mean: -1.97921
[32m[0907 17-11-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37034, current rewards: -2099.00000, mean: -1.98019
[32m[0907 17-11-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37034, current rewards: -2199.00000, mean: -1.98108
[32m[0907 17-12-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37035, current rewards: -2299.00000, mean: -1.98190
[32m[0907 17-12-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37032, current rewards: -2399.00000, mean: -1.98264
[32m[0907 17-12-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37028, current rewards: -2499.00000, mean: -1.98333
[32m[0907 17-12-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37022, current rewards: -2599.00000, mean: -1.98397
[32m[0907 17-13-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37022, current rewards: -2699.00000, mean: -1.98456
[32m[0907 17-13-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.37004, current rewards: -2799.00000, mean: -1.98511
[32m[0907 17-13-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36975, current rewards: -2899.00000, mean: -1.98562
[32m[0907 17-14-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36949, current rewards: -2999.00000, mean: -1.98609
[32m[0907 17-14-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36922, current rewards: -3099.00000, mean: -1.98654
[32m[0907 17-14-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36899, current rewards: -3199.00000, mean: -1.98696
[32m[0907 17-15-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36874, current rewards: -3299.00000, mean: -1.98735
[32m[0907 17-15-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36851, current rewards: -3399.00000, mean: -1.98772
[32m[0907 17-15-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36833, current rewards: -3499.00000, mean: -1.98807
[32m[0907 17-15-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36810, current rewards: -3599.00000, mean: -1.98840
[32m[0907 17-16-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36792, current rewards: -3699.00000, mean: -1.98871
[32m[0907 17-16-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36775, current rewards: -3799.00000, mean: -1.98901
[32m[0907 17-16-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36757, current rewards: -3899.00000, mean: -1.98929
[32m[0907 17-17-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36740, current rewards: -3999.00000, mean: -1.98955
[32m[0907 17-17-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36725, current rewards: -4099.00000, mean: -1.98981
[32m[0907 17-17-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36710, current rewards: -4199.00000, mean: -1.99005
[32m[0907 17-18-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36700, current rewards: -4299.00000, mean: -1.99028
[32m[0907 17-18-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36689, current rewards: -4399.00000, mean: -1.99050
[32m[0907 17-18-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36678, current rewards: -4499.00000, mean: -1.99071
[32m[0907 17-18-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36666, current rewards: -4599.00000, mean: -1.99091
[32m[0907 17-19-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36658, current rewards: -4699.00000, mean: -1.99110
[32m[0907 17-19-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36647, current rewards: -4799.00000, mean: -1.99129
[32m[0907 17-19-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36639, current rewards: -4899.00000, mean: -1.99146
[32m[0907 17-20-08 @Agent.py:117][0m Average action selection time: 0.3663
[32m[0907 17-20-08 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-20-09 @MBExp.py:227][0m Rewards obtained: [-4979], Lows: [2479], Highs: [21], Total time: 88541.740813
[32m[0907 17-24-10 @MBExp.py:144][0m ####################################################################
[32m[0907 17-24-10 @MBExp.py:145][0m Starting training iteration 108.
[32m[0907 17-24-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.37462, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-24-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36709, current rewards: -99.00000, mean: -1.65000
[32m[0907 17-24-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36896, current rewards: -199.00000, mean: -1.80909
[32m[0907 17-25-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36927, current rewards: -299.00000, mean: -1.86875
[32m[0907 17-25-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36972, current rewards: -399.00000, mean: -1.90000
[32m[0907 17-25-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37013, current rewards: -499.00000, mean: -1.91923
[32m[0907 17-26-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37042, current rewards: -599.00000, mean: -1.93226
[32m[0907 17-26-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37062, current rewards: -699.00000, mean: -1.94167
[32m[0907 17-26-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37044, current rewards: -799.00000, mean: -1.94878
[32m[0907 17-27-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37041, current rewards: -899.00000, mean: -1.95435
[32m[0907 17-27-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37034, current rewards: -999.00000, mean: -1.95882
[32m[0907 17-27-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37029, current rewards: -1099.00000, mean: -1.96250
[32m[0907 17-27-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37021, current rewards: -1199.00000, mean: -1.96557
[32m[0907 17-28-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37027, current rewards: -1299.00000, mean: -1.96818
[32m[0907 17-28-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37026, current rewards: -1399.00000, mean: -1.97042
[32m[0907 17-28-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37027, current rewards: -1499.00000, mean: -1.97237
[32m[0907 17-29-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37030, current rewards: -1599.00000, mean: -1.97407
[32m[0907 17-29-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37025, current rewards: -1699.00000, mean: -1.97558
[32m[0907 17-29-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37027, current rewards: -1799.00000, mean: -1.97692
[32m[0907 17-30-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37024, current rewards: -1899.00000, mean: -1.97812
[32m[0907 17-30-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37019, current rewards: -1999.00000, mean: -1.97921
[32m[0907 17-30-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37018, current rewards: -2099.00000, mean: -1.98019
[32m[0907 17-31-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37015, current rewards: -2199.00000, mean: -1.98108
[32m[0907 17-31-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37015, current rewards: -2299.00000, mean: -1.98190
[32m[0907 17-31-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37016, current rewards: -2399.00000, mean: -1.98264
[32m[0907 17-31-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37021, current rewards: -2499.00000, mean: -1.98333
[32m[0907 17-32-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37021, current rewards: -2599.00000, mean: -1.98397
[32m[0907 17-32-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37029, current rewards: -2699.00000, mean: -1.98456
[32m[0907 17-32-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.37015, current rewards: -2799.00000, mean: -1.98511
[32m[0907 17-33-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36983, current rewards: -2899.00000, mean: -1.98562
[32m[0907 17-33-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36956, current rewards: -2999.00000, mean: -1.98609
[32m[0907 17-33-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36930, current rewards: -3099.00000, mean: -1.98654
[32m[0907 17-34-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36905, current rewards: -3199.00000, mean: -1.98696
[32m[0907 17-34-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36880, current rewards: -3299.00000, mean: -1.98735
[32m[0907 17-34-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36857, current rewards: -3399.00000, mean: -1.98772
[32m[0907 17-34-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36835, current rewards: -3499.00000, mean: -1.98807
[32m[0907 17-35-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36814, current rewards: -3599.00000, mean: -1.98840
[32m[0907 17-35-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36793, current rewards: -3699.00000, mean: -1.98871
[32m[0907 17-35-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36775, current rewards: -3799.00000, mean: -1.98901
[32m[0907 17-36-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36759, current rewards: -3899.00000, mean: -1.98929
[32m[0907 17-36-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36743, current rewards: -3999.00000, mean: -1.98955
[32m[0907 17-36-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36729, current rewards: -4099.00000, mean: -1.98981
[32m[0907 17-37-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36728, current rewards: -4199.00000, mean: -1.99005
[32m[0907 17-37-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36716, current rewards: -4299.00000, mean: -1.99028
[32m[0907 17-37-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36704, current rewards: -4399.00000, mean: -1.99050
[32m[0907 17-38-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36691, current rewards: -4499.00000, mean: -1.99071
[32m[0907 17-38-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36680, current rewards: -4599.00000, mean: -1.99091
[32m[0907 17-38-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36669, current rewards: -4699.00000, mean: -1.99110
[32m[0907 17-38-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36658, current rewards: -4799.00000, mean: -1.99129
[32m[0907 17-39-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36649, current rewards: -4899.00000, mean: -1.99146
[32m[0907 17-39-27 @Agent.py:117][0m Average action selection time: 0.3664
[32m[0907 17-39-27 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-39-27 @MBExp.py:227][0m Rewards obtained: [-4979], Lows: [2479], Highs: [21], Total time: 89458.65807399999
[32m[0907 17-43-30 @MBExp.py:144][0m ####################################################################
[32m[0907 17-43-30 @MBExp.py:145][0m Starting training iteration 109.
[32m[0907 17-43-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.38664, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-43-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.42443, current rewards: -85.87658, mean: -1.43128
[32m[0907 17-44-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.40490, current rewards: -149.01244, mean: -1.35466
[32m[0907 17-44-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.41391, current rewards: -231.19206, mean: -1.44495
[32m[0907 17-44-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.40539, current rewards: -316.57886, mean: -1.50752
[32m[0907 17-45-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.41620, current rewards: -396.05833, mean: -1.52330
[32m[0907 17-45-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.41198, current rewards: -469.11410, mean: -1.51327
[32m[0907 17-45-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.40725, current rewards: -538.49041, mean: -1.49581
[32m[0907 17-46-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.40280, current rewards: -588.49041, mean: -1.43534
[32m[0907 17-46-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.39919, current rewards: -638.49041, mean: -1.38802
[32m[0907 17-46-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.39647, current rewards: -688.49041, mean: -1.34998
[32m[0907 17-47-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.39413, current rewards: -738.49041, mean: -1.31873
[32m[0907 17-47-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.39222, current rewards: -788.49041, mean: -1.29261
[32m[0907 17-47-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.39060, current rewards: -838.49041, mean: -1.27044
[32m[0907 17-48-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.38920, current rewards: -888.49041, mean: -1.25139
[32m[0907 17-48-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.38797, current rewards: -938.49041, mean: -1.23486
[32m[0907 17-48-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.38684, current rewards: -988.49041, mean: -1.22036
[32m[0907 17-49-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.38588, current rewards: -1038.49041, mean: -1.20755
[32m[0907 17-49-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.38502, current rewards: -1088.49041, mean: -1.19614
[32m[0907 17-49-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.38422, current rewards: -1138.49041, mean: -1.18593
[32m[0907 17-49-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.38348, current rewards: -1188.49041, mean: -1.17672
[32m[0907 17-50-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.38289, current rewards: -1238.49041, mean: -1.16839
[32m[0907 17-50-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.38231, current rewards: -1288.49041, mean: -1.16080
[32m[0907 17-50-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.38173, current rewards: -1338.49041, mean: -1.15387
[32m[0907 17-51-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.38119, current rewards: -1388.49041, mean: -1.14751
[32m[0907 17-51-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.38079, current rewards: -1438.49041, mean: -1.14166
[32m[0907 17-51-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.38040, current rewards: -1488.49041, mean: -1.13625
[32m[0907 17-52-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37993, current rewards: -1538.49041, mean: -1.13124
[32m[0907 17-52-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.37929, current rewards: -1588.49041, mean: -1.12659
[32m[0907 17-52-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.37953, current rewards: -1660.27856, mean: -1.13718
[32m[0907 17-53-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.37913, current rewards: -1750.83228, mean: -1.15949
[32m[0907 17-53-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.37860, current rewards: -1850.83228, mean: -1.18643
[32m[0907 17-53-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.37809, current rewards: -1950.83228, mean: -1.21170
[32m[0907 17-53-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.37762, current rewards: -2050.83228, mean: -1.23544
[32m[0907 17-54-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.37719, current rewards: -2150.83228, mean: -1.25780
[32m[0907 17-54-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.37676, current rewards: -2250.83228, mean: -1.27888
[32m[0907 17-54-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.37636, current rewards: -2350.83228, mean: -1.29880
[32m[0907 17-55-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.37597, current rewards: -2450.83228, mean: -1.31765
[32m[0907 17-55-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.37560, current rewards: -2550.83228, mean: -1.33551
[32m[0907 17-55-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.37524, current rewards: -2650.83228, mean: -1.35247
[32m[0907 17-56-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.37492, current rewards: -2750.83228, mean: -1.36857
[32m[0907 17-56-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.37471, current rewards: -2850.83228, mean: -1.38390
[32m[0907 17-56-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.37441, current rewards: -2950.83228, mean: -1.39850
[32m[0907 17-56-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.37414, current rewards: -3050.83228, mean: -1.41242
[32m[0907 17-57-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.37387, current rewards: -3150.83228, mean: -1.42572
[32m[0907 17-57-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.37362, current rewards: -3250.83228, mean: -1.43842
[32m[0907 17-57-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.37338, current rewards: -3350.83228, mean: -1.45058
[32m[0907 17-58-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.37315, current rewards: -3450.83228, mean: -1.46222
[32m[0907 17-58-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.37292, current rewards: -3550.83228, mean: -1.47337
[32m[0907 17-58-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.37269, current rewards: -3650.83228, mean: -1.48408
[32m[0907 17-59-02 @Agent.py:117][0m Average action selection time: 0.3724
[32m[0907 17-59-02 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-59-02 @MBExp.py:227][0m Rewards obtained: [-3730.8322793391785], Lows: [1288], Highs: [1166], Total time: 90390.50135499999
[32m[0907 18-03-08 @MBExp.py:144][0m ####################################################################
[32m[0907 18-03-08 @MBExp.py:145][0m Starting training iteration 110.
[32m[0907 18-03-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.61730, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-03-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.45751, current rewards: -61.01152, mean: -1.01686
[32m[0907 18-03-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.41819, current rewards: -161.01152, mean: -1.46374
[32m[0907 18-04-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.40367, current rewards: -261.01152, mean: -1.63132
[32m[0907 18-04-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.39615, current rewards: -361.01152, mean: -1.71910
[32m[0907 18-04-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.39143, current rewards: -461.01152, mean: -1.77312
[32m[0907 18-05-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.38822, current rewards: -561.01152, mean: -1.80971
[32m[0907 18-05-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.38601, current rewards: -661.01152, mean: -1.83614
[32m[0907 18-05-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.38424, current rewards: -761.01152, mean: -1.85613
[32m[0907 18-06-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.38335, current rewards: -861.01152, mean: -1.87176
[32m[0907 18-06-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.38212, current rewards: -945.42117, mean: -1.85377
[32m[0907 18-06-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.38112, current rewards: -1033.62137, mean: -1.84575
[32m[0907 18-07-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.38017, current rewards: -1121.28551, mean: -1.83817
[32m[0907 18-07-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37945, current rewards: -1221.28551, mean: -1.85043
[32m[0907 18-07-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37882, current rewards: -1321.28551, mean: -1.86097
[32m[0907 18-07-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37832, current rewards: -1421.28551, mean: -1.87011
[32m[0907 18-08-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37784, current rewards: -1521.28551, mean: -1.87813
[32m[0907 18-08-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37741, current rewards: -1621.28551, mean: -1.88522
[32m[0907 18-08-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37703, current rewards: -1721.28551, mean: -1.89152
[32m[0907 18-09-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37674, current rewards: -1821.28551, mean: -1.89717
[32m[0907 18-09-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37637, current rewards: -1921.28551, mean: -1.90226
[32m[0907 18-09-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37606, current rewards: -2021.28551, mean: -1.90687
[32m[0907 18-10-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37584, current rewards: -2121.28551, mean: -1.91107
[32m[0907 18-10-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37557, current rewards: -2221.28551, mean: -1.91490
[32m[0907 18-10-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37535, current rewards: -2321.28551, mean: -1.91842
[32m[0907 18-11-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37511, current rewards: -2421.28551, mean: -1.92166
[32m[0907 18-11-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37482, current rewards: -2521.28551, mean: -1.92465
[32m[0907 18-11-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37437, current rewards: -2621.28551, mean: -1.92742
[32m[0907 18-11-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.37393, current rewards: -2721.28551, mean: -1.92999
[32m[0907 18-12-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.37352, current rewards: -2821.28551, mean: -1.93239
[32m[0907 18-12-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.37315, current rewards: -2921.28551, mean: -1.93463
[32m[0907 18-12-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.37281, current rewards: -3021.28551, mean: -1.93672
[32m[0907 18-13-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.37248, current rewards: -3121.28551, mean: -1.93869
[32m[0907 18-13-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.37216, current rewards: -3221.28551, mean: -1.94053
[32m[0907 18-13-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.37186, current rewards: -3321.28551, mean: -1.94227
[32m[0907 18-14-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.37160, current rewards: -3421.28551, mean: -1.94391
[32m[0907 18-14-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.37137, current rewards: -3521.28551, mean: -1.94546
[32m[0907 18-14-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.37116, current rewards: -3621.28551, mean: -1.94693
[32m[0907 18-14-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.37093, current rewards: -3721.28551, mean: -1.94832
[32m[0907 18-15-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.37070, current rewards: -3821.28551, mean: -1.94964
[32m[0907 18-15-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.37055, current rewards: -3921.28551, mean: -1.95089
[32m[0907 18-15-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.37045, current rewards: -4021.28551, mean: -1.95208
[32m[0907 18-16-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.37024, current rewards: -4121.28551, mean: -1.95322
[32m[0907 18-16-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.37006, current rewards: -4221.28551, mean: -1.95430
[32m[0907 18-16-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36987, current rewards: -4321.28551, mean: -1.95533
[32m[0907 18-17-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36968, current rewards: -4421.28551, mean: -1.95632
[32m[0907 18-17-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36951, current rewards: -4521.28551, mean: -1.95727
[32m[0907 18-17-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36932, current rewards: -4621.28551, mean: -1.95817
[32m[0907 18-17-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36917, current rewards: -4721.28551, mean: -1.95904
[32m[0907 18-18-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36901, current rewards: -4821.28551, mean: -1.95987
[32m[0907 18-18-30 @Agent.py:117][0m Average action selection time: 0.3687
[32m[0907 18-18-30 @Agent.py:118][0m Rollout length: 2520
[32m[0907 18-18-30 @MBExp.py:227][0m Rewards obtained: [-4901.285509410658], Lows: [2443], Highs: [24], Total time: 91313.09491899998
[32m[0907 18-22-39 @MBExp.py:144][0m ####################################################################
[32m[0907 18-22-39 @MBExp.py:145][0m Starting training iteration 111.
[32m[0907 18-22-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.39893, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-23-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37650, current rewards: -73.00000, mean: -1.21667
[32m[0907 18-23-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37332, current rewards: -173.00000, mean: -1.57273
[32m[0907 18-23-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37281, current rewards: -273.00000, mean: -1.70625
[32m[0907 18-23-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37236, current rewards: -373.00000, mean: -1.77619
[32m[0907 18-24-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37229, current rewards: -473.00000, mean: -1.81923
[32m[0907 18-24-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37229, current rewards: -573.00000, mean: -1.84839
[32m[0907 18-24-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37198, current rewards: -673.00000, mean: -1.86944
[32m[0907 18-25-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37171, current rewards: -773.00000, mean: -1.88537
[32m[0907 18-25-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37155, current rewards: -873.00000, mean: -1.89783
[32m[0907 18-25-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37141, current rewards: -973.00000, mean: -1.90784
[32m[0907 18-26-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37121, current rewards: -1073.00000, mean: -1.91607
[32m[0907 18-26-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37117, current rewards: -1173.00000, mean: -1.92295
[32m[0907 18-26-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37115, current rewards: -1273.00000, mean: -1.92879
[32m[0907 18-27-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37111, current rewards: -1373.00000, mean: -1.93380
[32m[0907 18-27-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37104, current rewards: -1473.00000, mean: -1.93816
[32m[0907 18-27-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37102, current rewards: -1573.00000, mean: -1.94198
[32m[0907 18-27-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37088, current rewards: -1673.00000, mean: -1.94535
[32m[0907 18-28-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37083, current rewards: -1773.00000, mean: -1.94835
[32m[0907 18-28-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37072, current rewards: -1873.00000, mean: -1.95104
[32m[0907 18-28-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37064, current rewards: -1973.00000, mean: -1.95347
[32m[0907 18-29-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37064, current rewards: -2073.00000, mean: -1.95566
[32m[0907 18-29-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37060, current rewards: -2173.00000, mean: -1.95766
[32m[0907 18-29-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37057, current rewards: -2273.00000, mean: -1.95948
[32m[0907 18-30-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37051, current rewards: -2373.00000, mean: -1.96116
[32m[0907 18-30-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37047, current rewards: -2473.00000, mean: -1.96270
[32m[0907 18-30-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37022, current rewards: -2573.00000, mean: -1.96412
[32m[0907 18-31-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36992, current rewards: -2673.00000, mean: -1.96544
[32m[0907 18-31-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36962, current rewards: -2773.00000, mean: -1.96667
[32m[0907 18-31-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36933, current rewards: -2873.00000, mean: -1.96781
[32m[0907 18-31-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36909, current rewards: -2973.00000, mean: -1.96887
[32m[0907 18-32-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36885, current rewards: -3073.00000, mean: -1.96987
[32m[0907 18-32-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36863, current rewards: -3173.00000, mean: -1.97081
[32m[0907 18-32-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36844, current rewards: -3273.00000, mean: -1.97169
[32m[0907 18-33-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36822, current rewards: -3373.00000, mean: -1.97251
[32m[0907 18-33-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36803, current rewards: -3473.00000, mean: -1.97330
[32m[0907 18-33-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36784, current rewards: -3573.00000, mean: -1.97403
[32m[0907 18-34-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36767, current rewards: -3673.00000, mean: -1.97473
[32m[0907 18-34-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36748, current rewards: -3773.00000, mean: -1.97539
[32m[0907 18-34-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36729, current rewards: -3873.00000, mean: -1.97602
[32m[0907 18-34-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36718, current rewards: -3973.00000, mean: -1.97662
[32m[0907 18-35-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36703, current rewards: -4073.00000, mean: -1.97718
[32m[0907 18-35-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36682, current rewards: -4173.00000, mean: -1.97773
[32m[0907 18-35-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36661, current rewards: -4273.00000, mean: -1.97824
[32m[0907 18-36-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36639, current rewards: -4373.00000, mean: -1.97873
[32m[0907 18-36-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36616, current rewards: -4473.00000, mean: -1.97920
[32m[0907 18-36-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36594, current rewards: -4573.00000, mean: -1.97965
[32m[0907 18-37-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36571, current rewards: -4673.00000, mean: -1.98008
[32m[0907 18-37-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36551, current rewards: -4773.00000, mean: -1.98050
[32m[0907 18-37-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36528, current rewards: -4873.00000, mean: -1.98089
[32m[0907 18-37-52 @Agent.py:117][0m Average action selection time: 0.3649
[32m[0907 18-37-52 @Agent.py:118][0m Rollout length: 2520
[32m[0907 18-37-52 @MBExp.py:227][0m Rewards obtained: [-4953], Lows: [2453], Highs: [47], Total time: 92226.31860999999
[32m[0907 18-41-56 @MBExp.py:144][0m ####################################################################
[32m[0907 18-41-56 @MBExp.py:145][0m Starting training iteration 112.
[32m[0907 18-42-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.53568, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-42-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.41109, current rewards: -66.00000, mean: -1.10000
[32m[0907 18-42-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.39076, current rewards: -114.89477, mean: -1.04450
[32m[0907 18-42-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.38173, current rewards: -163.84632, mean: -1.02404
[32m[0907 18-43-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37717, current rewards: -213.84632, mean: -1.01832
[32m[0907 18-43-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37462, current rewards: -262.75328, mean: -1.01059
[32m[0907 18-43-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37268, current rewards: -312.75328, mean: -1.00888
[32m[0907 18-44-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37131, current rewards: -362.75328, mean: -1.00765
[32m[0907 18-44-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37021, current rewards: -406.45956, mean: -0.99136
[32m[0907 18-44-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36940, current rewards: -404.01186, mean: -0.87829
[32m[0907 18-45-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36868, current rewards: -450.86500, mean: -0.88405
[32m[0907 18-45-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36818, current rewards: -500.86500, mean: -0.89440
[32m[0907 18-45-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36771, current rewards: -550.86500, mean: -0.90306
[32m[0907 18-45-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36731, current rewards: -600.86500, mean: -0.91040
[32m[0907 18-46-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36703, current rewards: -650.86500, mean: -0.91671
[32m[0907 18-46-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36670, current rewards: -700.86500, mean: -0.92219
[32m[0907 18-46-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36646, current rewards: -750.86500, mean: -0.92699
[32m[0907 18-47-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36621, current rewards: -800.86500, mean: -0.93124
[32m[0907 18-47-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36602, current rewards: -850.86500, mean: -0.93502
[32m[0907 18-47-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36581, current rewards: -900.86500, mean: -0.93840
[32m[0907 18-48-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36563, current rewards: -950.86500, mean: -0.94145
[32m[0907 18-48-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36542, current rewards: -1000.86500, mean: -0.94421
[32m[0907 18-48-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36525, current rewards: -1026.64986, mean: -0.92491
[32m[0907 18-49-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36509, current rewards: -1018.99478, mean: -0.87844
[32m[0907 18-49-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36494, current rewards: -1011.33970, mean: -0.83582
[32m[0907 18-49-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36473, current rewards: -1003.68462, mean: -0.79658
[32m[0907 18-49-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36440, current rewards: -996.02954, mean: -0.76033
[32m[0907 18-50-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36406, current rewards: -989.47763, mean: -0.72756
[32m[0907 18-50-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36371, current rewards: -1008.23230, mean: -0.71506
[32m[0907 18-50-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36342, current rewards: -1058.23230, mean: -0.72482
[32m[0907 18-51-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36313, current rewards: -1108.23230, mean: -0.73393
[32m[0907 18-51-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36286, current rewards: -1158.23230, mean: -0.74246
[32m[0907 18-51-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36261, current rewards: -1208.23230, mean: -0.75045
[32m[0907 18-51-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36238, current rewards: -1258.23230, mean: -0.75797
[32m[0907 18-52-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36216, current rewards: -1308.23230, mean: -0.76505
[32m[0907 18-52-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36195, current rewards: -1358.23230, mean: -0.77172
[32m[0907 18-52-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36174, current rewards: -1408.23230, mean: -0.77803
[32m[0907 18-53-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36157, current rewards: -1458.23230, mean: -0.78400
[32m[0907 18-53-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36142, current rewards: -1508.23230, mean: -0.78965
[32m[0907 18-53-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36128, current rewards: -1558.23230, mean: -0.79502
[32m[0907 18-54-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36136, current rewards: -1608.23230, mean: -0.80012
[32m[0907 18-54-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36119, current rewards: -1658.23230, mean: -0.80497
[32m[0907 18-54-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36104, current rewards: -1708.23230, mean: -0.80959
[32m[0907 18-54-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36090, current rewards: -1758.23230, mean: -0.81400
[32m[0907 18-55-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36076, current rewards: -1808.23230, mean: -0.81820
[32m[0907 18-55-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36063, current rewards: -1858.23230, mean: -0.82223
[32m[0907 18-55-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36049, current rewards: -1908.23230, mean: -0.82607
[32m[0907 18-56-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36036, current rewards: -1958.23230, mean: -0.82976
[32m[0907 18-56-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36025, current rewards: -2008.23230, mean: -0.83329
[32m[0907 18-56-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36015, current rewards: -2058.23230, mean: -0.83668
[32m[0907 18-56-56 @Agent.py:117][0m Average action selection time: 0.3599
[32m[0907 18-56-56 @Agent.py:118][0m Rollout length: 2520
[32m[0907 18-56-57 @MBExp.py:227][0m Rewards obtained: [-2098.232304924781], Lows: [6], Highs: [2133], Total time: 93126.83899699998
[32m[0907 19-01-03 @MBExp.py:144][0m ####################################################################
[32m[0907 19-01-03 @MBExp.py:145][0m Starting training iteration 113.
[32m[0907 19-01-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36471, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-01-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36479, current rewards: -100.00000, mean: -1.66667
[32m[0907 19-01-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36432, current rewards: -200.00000, mean: -1.81818
[32m[0907 19-02-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36458, current rewards: -300.00000, mean: -1.87500
[32m[0907 19-02-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36401, current rewards: -400.00000, mean: -1.90476
[32m[0907 19-02-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36406, current rewards: -500.00000, mean: -1.92308
[32m[0907 19-02-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36402, current rewards: -600.00000, mean: -1.93548
[32m[0907 19-03-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36379, current rewards: -700.00000, mean: -1.94444
[32m[0907 19-03-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36370, current rewards: -800.00000, mean: -1.95122
[32m[0907 19-03-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36357, current rewards: -900.00000, mean: -1.95652
[32m[0907 19-04-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36351, current rewards: -1000.00000, mean: -1.96078
[32m[0907 19-04-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36345, current rewards: -1100.00000, mean: -1.96429
[32m[0907 19-04-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36339, current rewards: -1200.00000, mean: -1.96721
[32m[0907 19-05-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36354, current rewards: -1300.00000, mean: -1.96970
[32m[0907 19-05-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36347, current rewards: -1400.00000, mean: -1.97183
[32m[0907 19-05-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36350, current rewards: -1500.00000, mean: -1.97368
[32m[0907 19-05-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36355, current rewards: -1600.00000, mean: -1.97531
[32m[0907 19-06-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36354, current rewards: -1700.00000, mean: -1.97674
[32m[0907 19-06-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36351, current rewards: -1800.00000, mean: -1.97802
[32m[0907 19-06-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36345, current rewards: -1900.00000, mean: -1.97917
[32m[0907 19-07-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36343, current rewards: -2000.00000, mean: -1.98020
[32m[0907 19-07-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36341, current rewards: -2100.00000, mean: -1.98113
[32m[0907 19-07-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36339, current rewards: -2200.00000, mean: -1.98198
[32m[0907 19-08-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36335, current rewards: -2300.00000, mean: -1.98276
[32m[0907 19-08-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36338, current rewards: -2400.00000, mean: -1.98347
[32m[0907 19-08-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36314, current rewards: -2500.00000, mean: -1.98413
[32m[0907 19-08-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36283, current rewards: -2600.00000, mean: -1.98473
[32m[0907 19-09-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36256, current rewards: -2700.00000, mean: -1.98529
[32m[0907 19-09-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36229, current rewards: -2800.00000, mean: -1.98582
[32m[0907 19-09-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36204, current rewards: -2900.00000, mean: -1.98630
[32m[0907 19-10-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36180, current rewards: -3000.00000, mean: -1.98675
[32m[0907 19-10-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36158, current rewards: -3100.00000, mean: -1.98718
[32m[0907 19-10-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36138, current rewards: -3200.00000, mean: -1.98758
[32m[0907 19-11-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36118, current rewards: -3300.00000, mean: -1.98795
[32m[0907 19-11-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36102, current rewards: -3400.00000, mean: -1.98830
[32m[0907 19-11-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36086, current rewards: -3500.00000, mean: -1.98864
[32m[0907 19-11-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36070, current rewards: -3600.00000, mean: -1.98895
[32m[0907 19-12-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36057, current rewards: -3700.00000, mean: -1.98925
[32m[0907 19-12-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36046, current rewards: -3800.00000, mean: -1.98953
[32m[0907 19-12-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36045, current rewards: -3900.00000, mean: -1.98980
[32m[0907 19-13-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36056, current rewards: -4000.00000, mean: -1.99005
[32m[0907 19-13-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36042, current rewards: -4100.00000, mean: -1.99029
[32m[0907 19-13-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36024, current rewards: -4200.00000, mean: -1.99052
[32m[0907 19-14-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36008, current rewards: -4300.00000, mean: -1.99074
[32m[0907 19-14-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35981, current rewards: -4400.00000, mean: -1.99095
[32m[0907 19-14-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35945, current rewards: -4500.00000, mean: -1.99115
[32m[0907 19-14-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35912, current rewards: -4600.00000, mean: -1.99134
[32m[0907 19-15-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35880, current rewards: -4700.00000, mean: -1.99153
[32m[0907 19-15-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35849, current rewards: -4800.00000, mean: -1.99170
[32m[0907 19-15-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35819, current rewards: -4900.00000, mean: -1.99187
[32m[0907 19-15-58 @Agent.py:117][0m Average action selection time: 0.3578
[32m[0907 19-15-58 @Agent.py:118][0m Rollout length: 2520
[32m[0907 19-15-58 @MBExp.py:227][0m Rewards obtained: [-4980], Lows: [2480], Highs: [20], Total time: 94022.10727499999
[32m[0907 19-19-45 @MBExp.py:144][0m ####################################################################
[32m[0907 19-19-45 @MBExp.py:145][0m Starting training iteration 114.
[32m[0907 19-19-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.58955, current rewards: -6.85170, mean: -0.68517
[32m[0907 19-20-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.43659, current rewards: -86.25830, mean: -1.43764
[32m[0907 19-20-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.39924, current rewards: -186.25830, mean: -1.69326
[32m[0907 19-20-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.38512, current rewards: -286.25830, mean: -1.78911
[32m[0907 19-21-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37731, current rewards: -386.25830, mean: -1.83933
[32m[0907 19-21-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37257, current rewards: -486.25830, mean: -1.87022
[32m[0907 19-21-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36955, current rewards: -586.25830, mean: -1.89116
[32m[0907 19-21-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36721, current rewards: -686.25830, mean: -1.90627
[32m[0907 19-22-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36542, current rewards: -786.25830, mean: -1.91770
[32m[0907 19-22-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36418, current rewards: -886.25830, mean: -1.92665
[32m[0907 19-22-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36298, current rewards: -986.25830, mean: -1.93384
[32m[0907 19-23-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36203, current rewards: -1086.25830, mean: -1.93975
[32m[0907 19-23-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36123, current rewards: -1186.25830, mean: -1.94469
[32m[0907 19-23-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36064, current rewards: -1286.25830, mean: -1.94888
[32m[0907 19-24-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36002, current rewards: -1386.25830, mean: -1.95248
[32m[0907 19-24-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35952, current rewards: -1486.25830, mean: -1.95560
[32m[0907 19-24-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35905, current rewards: -1586.25830, mean: -1.95834
[32m[0907 19-24-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35865, current rewards: -1686.25830, mean: -1.96077
[32m[0907 19-25-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35828, current rewards: -1786.25830, mean: -1.96292
[32m[0907 19-25-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35794, current rewards: -1886.25830, mean: -1.96485
[32m[0907 19-25-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35770, current rewards: -1986.25830, mean: -1.96659
[32m[0907 19-26-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35742, current rewards: -2086.25830, mean: -1.96817
[32m[0907 19-26-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35718, current rewards: -2186.25830, mean: -1.96960
[32m[0907 19-26-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35693, current rewards: -2286.25830, mean: -1.97091
[32m[0907 19-26-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35672, current rewards: -2386.25830, mean: -1.97211
[32m[0907 19-27-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35627, current rewards: -2486.25830, mean: -1.97322
[32m[0907 19-27-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35574, current rewards: -2586.25830, mean: -1.97424
[32m[0907 19-27-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35531, current rewards: -2686.25830, mean: -1.97519
[32m[0907 19-28-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35486, current rewards: -2786.25830, mean: -1.97607
[32m[0907 19-28-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35447, current rewards: -2886.25830, mean: -1.97689
[32m[0907 19-28-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35409, current rewards: -2986.25830, mean: -1.97765
[32m[0907 19-28-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35371, current rewards: -3086.25830, mean: -1.97837
[32m[0907 19-29-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35341, current rewards: -3186.25830, mean: -1.97904
[32m[0907 19-29-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35247, current rewards: -3286.25830, mean: -1.97967
[32m[0907 19-29-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35115, current rewards: -3386.25830, mean: -1.98027
[32m[0907 19-30-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34990, current rewards: -3486.25830, mean: -1.98083
[32m[0907 19-30-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34872, current rewards: -3586.25830, mean: -1.98136
[32m[0907 19-30-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34761, current rewards: -3686.25830, mean: -1.98186
[32m[0907 19-30-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34654, current rewards: -3786.25830, mean: -1.98233
[32m[0907 19-31-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34569, current rewards: -3886.25830, mean: -1.98278
[32m[0907 19-31-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34496, current rewards: -3986.25830, mean: -1.98321
[32m[0907 19-31-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34421, current rewards: -4086.25830, mean: -1.98362
[32m[0907 19-31-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34350, current rewards: -4186.25830, mean: -1.98401
[32m[0907 19-32-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34284, current rewards: -4286.25830, mean: -1.98438
[32m[0907 19-32-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34215, current rewards: -4386.25830, mean: -1.98473
[32m[0907 19-32-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34137, current rewards: -4486.25830, mean: -1.98507
[32m[0907 19-32-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34064, current rewards: -4586.25830, mean: -1.98539
[32m[0907 19-33-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33993, current rewards: -4686.25830, mean: -1.98570
[32m[0907 19-33-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33924, current rewards: -4786.25830, mean: -1.98600
[32m[0907 19-33-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33860, current rewards: -4886.25830, mean: -1.98628
[32m[0907 19-33-50 @Agent.py:117][0m Average action selection time: 0.3379
[32m[0907 19-33-50 @Agent.py:118][0m Rollout length: 2520
[32m[0907 19-33-51 @MBExp.py:227][0m Rewards obtained: [-4966.2583011011775], Lows: [2480], Highs: [7], Total time: 94867.61588099999
[32m[0907 19-37-37 @MBExp.py:144][0m ####################################################################
[32m[0907 19-37-37 @MBExp.py:145][0m Starting training iteration 115.
[32m[0907 19-37-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.59233, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-38-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.53095, current rewards: -64.40044, mean: -1.07334
[32m[0907 19-38-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.46433, current rewards: -145.88514, mean: -1.32623
[32m[0907 19-38-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.43131, current rewards: -245.88514, mean: -1.53678
[32m[0907 19-39-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.41397, current rewards: -345.88514, mean: -1.64707
[32m[0907 19-39-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.40320, current rewards: -445.88514, mean: -1.71494
[32m[0907 19-39-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.39584, current rewards: -545.88514, mean: -1.76092
[32m[0907 19-39-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.39065, current rewards: -645.88514, mean: -1.79413
[32m[0907 19-40-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.38659, current rewards: -745.88514, mean: -1.81923
[32m[0907 19-40-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.38342, current rewards: -845.88514, mean: -1.83888
[32m[0907 19-40-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.38098, current rewards: -945.88514, mean: -1.85468
[32m[0907 19-41-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37883, current rewards: -1045.88514, mean: -1.86765
[32m[0907 19-41-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.37709, current rewards: -1145.88514, mean: -1.87850
[32m[0907 19-41-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37565, current rewards: -1245.88514, mean: -1.88770
[32m[0907 19-42-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37415, current rewards: -1345.88514, mean: -1.89561
[32m[0907 19-42-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37306, current rewards: -1445.88514, mean: -1.90248
[32m[0907 19-42-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37287, current rewards: -1545.88514, mean: -1.90850
[32m[0907 19-42-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37248, current rewards: -1645.88514, mean: -1.91382
[32m[0907 19-43-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37221, current rewards: -1745.88514, mean: -1.91856
[32m[0907 19-43-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37169, current rewards: -1845.88514, mean: -1.92280
[32m[0907 19-43-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37090, current rewards: -1945.88514, mean: -1.92662
[32m[0907 19-44-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37025, current rewards: -2045.88514, mean: -1.93008
[32m[0907 19-44-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36963, current rewards: -2145.88514, mean: -1.93323
[32m[0907 19-44-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36911, current rewards: -2245.88514, mean: -1.93611
[32m[0907 19-45-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36829, current rewards: -2345.88514, mean: -1.93875
[32m[0907 19-45-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36757, current rewards: -2445.88514, mean: -1.94118
[32m[0907 19-45-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36687, current rewards: -2545.88514, mean: -1.94342
[32m[0907 19-45-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36623, current rewards: -2645.88514, mean: -1.94550
[32m[0907 19-46-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36561, current rewards: -2745.88514, mean: -1.94744
[32m[0907 19-46-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36503, current rewards: -2845.88514, mean: -1.94924
[32m[0907 19-46-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36450, current rewards: -2945.88514, mean: -1.95092
[32m[0907 19-47-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36397, current rewards: -3045.88514, mean: -1.95249
[32m[0907 19-47-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36349, current rewards: -3145.88514, mean: -1.95397
[32m[0907 19-47-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36304, current rewards: -3245.88514, mean: -1.95535
[32m[0907 19-47-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36264, current rewards: -3345.88514, mean: -1.95666
[32m[0907 19-48-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36222, current rewards: -3445.88514, mean: -1.95789
[32m[0907 19-48-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36185, current rewards: -3545.88514, mean: -1.95905
[32m[0907 19-48-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36150, current rewards: -3645.88514, mean: -1.96015
[32m[0907 19-49-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36130, current rewards: -3745.88514, mean: -1.96120
[32m[0907 19-49-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36124, current rewards: -3845.88514, mean: -1.96219
[32m[0907 19-49-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36113, current rewards: -3945.88514, mean: -1.96313
[32m[0907 19-50-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36106, current rewards: -4045.88514, mean: -1.96402
[32m[0907 19-50-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36096, current rewards: -4145.88514, mean: -1.96487
[32m[0907 19-50-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36086, current rewards: -4245.88514, mean: -1.96569
[32m[0907 19-50-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36060, current rewards: -4345.88514, mean: -1.96646
[32m[0907 19-51-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36034, current rewards: -4445.88514, mean: -1.96721
[32m[0907 19-51-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36008, current rewards: -4545.88514, mean: -1.96792
[32m[0907 19-51-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35985, current rewards: -4645.88514, mean: -1.96860
[32m[0907 19-52-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35962, current rewards: -4745.88514, mean: -1.96925
[32m[0907 19-52-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35928, current rewards: -4845.88514, mean: -1.96987
[32m[0907 19-52-35 @Agent.py:117][0m Average action selection time: 0.3588
[32m[0907 19-52-35 @Agent.py:118][0m Rollout length: 2520
[32m[0907 19-52-35 @MBExp.py:227][0m Rewards obtained: [-4925.885140997904], Lows: [2451], Highs: [27], Total time: 95765.44232799999
[32m[0907 19-56-36 @MBExp.py:144][0m ####################################################################
[32m[0907 19-56-36 @MBExp.py:145][0m Starting training iteration 116.
[32m[0907 19-56-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.60640, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-57-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.53229, current rewards: -60.72072, mean: -1.01201
[32m[0907 19-57-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.45616, current rewards: -160.72072, mean: -1.46110
[32m[0907 19-57-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.42779, current rewards: -260.72072, mean: -1.62950
[32m[0907 19-58-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.41449, current rewards: -360.72072, mean: -1.71772
[32m[0907 19-58-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.40582, current rewards: -460.72072, mean: -1.77200
[32m[0907 19-58-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.39917, current rewards: -560.72072, mean: -1.80878
[32m[0907 19-58-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.39483, current rewards: -660.72072, mean: -1.83534
[32m[0907 19-59-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.39128, current rewards: -760.72072, mean: -1.85542
[32m[0907 19-59-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.38882, current rewards: -860.72072, mean: -1.87113
[32m[0907 19-59-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.38650, current rewards: -960.72072, mean: -1.88377
[32m[0907 20-00-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.38472, current rewards: -1060.72072, mean: -1.89414
[32m[0907 20-00-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.38299, current rewards: -1160.72072, mean: -1.90282
[32m[0907 20-00-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.38122, current rewards: -1260.72072, mean: -1.91018
[32m[0907 20-01-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37979, current rewards: -1360.72072, mean: -1.91651
[32m[0907 20-01-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37859, current rewards: -1460.72072, mean: -1.92200
[32m[0907 20-01-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37734, current rewards: -1560.72072, mean: -1.92682
[32m[0907 20-02-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37621, current rewards: -1660.72072, mean: -1.93107
[32m[0907 20-02-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37515, current rewards: -1760.72072, mean: -1.93486
[32m[0907 20-02-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37420, current rewards: -1860.72072, mean: -1.93825
[32m[0907 20-02-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37334, current rewards: -1960.72072, mean: -1.94131
[32m[0907 20-03-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37260, current rewards: -2060.72072, mean: -1.94408
[32m[0907 20-03-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37181, current rewards: -2160.72072, mean: -1.94660
[32m[0907 20-03-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37079, current rewards: -2260.72072, mean: -1.94890
[32m[0907 20-04-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36993, current rewards: -2360.72072, mean: -1.95101
[32m[0907 20-04-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36923, current rewards: -2460.72072, mean: -1.95295
[32m[0907 20-04-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36860, current rewards: -2560.72072, mean: -1.95475
[32m[0907 20-04-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36798, current rewards: -2660.72072, mean: -1.95641
[32m[0907 20-05-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36724, current rewards: -2760.72072, mean: -1.95796
[32m[0907 20-05-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36652, current rewards: -2860.72072, mean: -1.95940
[32m[0907 20-05-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36588, current rewards: -2960.72072, mean: -1.96074
[32m[0907 20-06-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36526, current rewards: -3060.72072, mean: -1.96200
[32m[0907 20-06-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36470, current rewards: -3160.72072, mean: -1.96318
[32m[0907 20-06-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36417, current rewards: -3260.72072, mean: -1.96429
[32m[0907 20-06-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36366, current rewards: -3360.72072, mean: -1.96533
[32m[0907 20-07-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36319, current rewards: -3460.72072, mean: -1.96632
[32m[0907 20-07-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36273, current rewards: -3560.72072, mean: -1.96725
[32m[0907 20-07-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36248, current rewards: -3660.72072, mean: -1.96813
[32m[0907 20-08-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36234, current rewards: -3760.72072, mean: -1.96896
[32m[0907 20-08-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36222, current rewards: -3860.72072, mean: -1.96976
[32m[0907 20-08-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36208, current rewards: -3960.72072, mean: -1.97051
[32m[0907 20-09-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36196, current rewards: -4060.72072, mean: -1.97122
[32m[0907 20-09-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36181, current rewards: -4160.72072, mean: -1.97191
[32m[0907 20-09-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36157, current rewards: -4260.72072, mean: -1.97256
[32m[0907 20-09-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36126, current rewards: -4360.72072, mean: -1.97318
[32m[0907 20-10-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36095, current rewards: -4460.72072, mean: -1.97377
[32m[0907 20-10-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36066, current rewards: -4560.72072, mean: -1.97434
[32m[0907 20-10-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36039, current rewards: -4660.72072, mean: -1.97488
[32m[0907 20-11-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36011, current rewards: -4760.72072, mean: -1.97540
[32m[0907 20-11-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35955, current rewards: -4860.72072, mean: -1.97590
[32m[0907 20-11-34 @Agent.py:117][0m Average action selection time: 0.3590
[32m[0907 20-11-34 @Agent.py:118][0m Rollout length: 2520
[32m[0907 20-11-35 @MBExp.py:227][0m Rewards obtained: [-4940.720722767872], Lows: [2459], Highs: [25], Total time: 96663.79520099999
[32m[0907 20-15-41 @MBExp.py:144][0m ####################################################################
[32m[0907 20-15-41 @MBExp.py:145][0m Starting training iteration 117.
[32m[0907 20-15-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35438, current rewards: -10.00000, mean: -1.00000
[32m[0907 20-16-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35293, current rewards: -100.00000, mean: -1.66667
[32m[0907 20-16-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35296, current rewards: -200.00000, mean: -1.81818
[32m[0907 20-16-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34750, current rewards: -300.00000, mean: -1.87500
[32m[0907 20-16-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33976, current rewards: -400.00000, mean: -1.90476
[32m[0907 20-17-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33548, current rewards: -500.00000, mean: -1.92308
[32m[0907 20-17-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33224, current rewards: -600.00000, mean: -1.93548
[32m[0907 20-17-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33002, current rewards: -700.00000, mean: -1.94444
[32m[0907 20-17-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32825, current rewards: -800.00000, mean: -1.95122
[32m[0907 20-18-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32682, current rewards: -900.00000, mean: -1.95652
[32m[0907 20-18-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32578, current rewards: -1000.00000, mean: -1.96078
[32m[0907 20-18-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32487, current rewards: -1100.00000, mean: -1.96429
[32m[0907 20-18-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32409, current rewards: -1200.00000, mean: -1.96721
[32m[0907 20-19-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32349, current rewards: -1300.00000, mean: -1.96970
[32m[0907 20-19-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32295, current rewards: -1400.00000, mean: -1.97183
[32m[0907 20-19-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32241, current rewards: -1500.00000, mean: -1.97368
[32m[0907 20-20-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32199, current rewards: -1600.00000, mean: -1.97531
[32m[0907 20-20-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32163, current rewards: -1700.00000, mean: -1.97674
[32m[0907 20-20-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32126, current rewards: -1800.00000, mean: -1.97802
[32m[0907 20-20-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32094, current rewards: -1900.00000, mean: -1.97917
[32m[0907 20-21-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32063, current rewards: -2000.00000, mean: -1.98020
[32m[0907 20-21-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32039, current rewards: -2100.00000, mean: -1.98113
[32m[0907 20-21-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31991, current rewards: -2200.00000, mean: -1.98198
[32m[0907 20-21-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31935, current rewards: -2300.00000, mean: -1.98276
[32m[0907 20-22-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31885, current rewards: -2400.00000, mean: -1.98347
[32m[0907 20-22-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31913, current rewards: -2500.00000, mean: -1.98413
[32m[0907 20-22-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32007, current rewards: -2600.00000, mean: -1.98473
[32m[0907 20-22-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32096, current rewards: -2700.00000, mean: -1.98529
[32m[0907 20-23-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32176, current rewards: -2800.00000, mean: -1.98582
[32m[0907 20-23-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32251, current rewards: -2900.00000, mean: -1.98630
[32m[0907 20-23-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32262, current rewards: -3000.00000, mean: -1.98675
[32m[0907 20-24-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32215, current rewards: -3100.00000, mean: -1.98718
[32m[0907 20-24-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32170, current rewards: -3200.00000, mean: -1.98758
[32m[0907 20-24-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32132, current rewards: -3300.00000, mean: -1.98795
[32m[0907 20-24-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32093, current rewards: -3400.00000, mean: -1.98830
[32m[0907 20-25-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32056, current rewards: -3500.00000, mean: -1.98864
[32m[0907 20-25-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32025, current rewards: -3600.00000, mean: -1.98895
[32m[0907 20-25-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32014, current rewards: -3700.00000, mean: -1.98925
[32m[0907 20-25-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32001, current rewards: -3800.00000, mean: -1.98953
[32m[0907 20-26-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31990, current rewards: -3900.00000, mean: -1.98980
[32m[0907 20-26-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31977, current rewards: -4000.00000, mean: -1.99005
[32m[0907 20-26-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31967, current rewards: -4100.00000, mean: -1.99029
[32m[0907 20-26-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31957, current rewards: -4200.00000, mean: -1.99052
[32m[0907 20-27-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31936, current rewards: -4300.00000, mean: -1.99074
[32m[0907 20-27-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31910, current rewards: -4400.00000, mean: -1.99095
[32m[0907 20-27-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31885, current rewards: -4500.00000, mean: -1.99115
[32m[0907 20-27-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31862, current rewards: -4600.00000, mean: -1.99134
[32m[0907 20-28-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31839, current rewards: -4700.00000, mean: -1.99153
[32m[0907 20-28-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31817, current rewards: -4800.00000, mean: -1.99170
[32m[0907 20-28-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31783, current rewards: -4900.00000, mean: -1.99187
[32m[0907 20-28-55 @Agent.py:117][0m Average action selection time: 0.3174
[32m[0907 20-28-55 @Agent.py:118][0m Rollout length: 2520
[32m[0907 20-28-55 @MBExp.py:227][0m Rewards obtained: [-4980], Lows: [2480], Highs: [20], Total time: 97458.09319599999
[32m[0907 20-32-30 @MBExp.py:144][0m ####################################################################
[32m[0907 20-32-30 @MBExp.py:145][0m Starting training iteration 118.
[32m[0907 20-32-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.52982, current rewards: -10.00000, mean: -1.00000
[32m[0907 20-33-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.52576, current rewards: -50.43966, mean: -0.84066
[32m[0907 20-33-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.46130, current rewards: -100.43966, mean: -0.91309
[32m[0907 20-33-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.41567, current rewards: -150.43966, mean: -0.94025
[32m[0907 20-33-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.39166, current rewards: -200.43966, mean: -0.95447
[32m[0907 20-34-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37702, current rewards: -250.43966, mean: -0.96323
[32m[0907 20-34-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36713, current rewards: -300.43966, mean: -0.96916
[32m[0907 20-34-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35989, current rewards: -350.43966, mean: -0.97344
[32m[0907 20-34-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35444, current rewards: -400.43966, mean: -0.97668
[32m[0907 20-35-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35020, current rewards: -437.24993, mean: -0.95054
[32m[0907 20-35-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34670, current rewards: -432.29271, mean: -0.84763
[32m[0907 20-35-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34385, current rewards: -427.33550, mean: -0.76310
[32m[0907 20-35-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34146, current rewards: -422.37829, mean: -0.69242
[32m[0907 20-36-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33945, current rewards: -417.42108, mean: -0.63246
[32m[0907 20-36-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33772, current rewards: -412.46386, mean: -0.58094
[32m[0907 20-36-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33625, current rewards: -407.50665, mean: -0.53619
[32m[0907 20-37-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33497, current rewards: -403.65849, mean: -0.49834
[32m[0907 20-37-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33380, current rewards: -428.16182, mean: -0.49786
[32m[0907 20-37-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33275, current rewards: -478.16182, mean: -0.52545
[32m[0907 20-37-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33184, current rewards: -528.16182, mean: -0.55017
[32m[0907 20-38-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33124, current rewards: -578.16182, mean: -0.57244
[32m[0907 20-38-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33036, current rewards: -628.16182, mean: -0.59261
[32m[0907 20-38-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32954, current rewards: -678.16182, mean: -0.61096
[32m[0907 20-38-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32884, current rewards: -728.16182, mean: -0.62773
[32m[0907 20-39-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32818, current rewards: -778.16182, mean: -0.64311
[32m[0907 20-39-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32758, current rewards: -828.16182, mean: -0.65727
[32m[0907 20-39-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32701, current rewards: -878.16182, mean: -0.67035
[32m[0907 20-39-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32648, current rewards: -928.16182, mean: -0.68247
[32m[0907 20-40-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32596, current rewards: -978.16182, mean: -0.69373
[32m[0907 20-40-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32547, current rewards: -1028.16182, mean: -0.70422
[32m[0907 20-40-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32543, current rewards: -1078.16182, mean: -0.71401
[32m[0907 20-40-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32604, current rewards: -1128.16182, mean: -0.72318
[32m[0907 20-41-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32659, current rewards: -1170.82572, mean: -0.72722
[32m[0907 20-41-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32710, current rewards: -1168.42505, mean: -0.70387
[32m[0907 20-41-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32758, current rewards: -1166.02437, mean: -0.68189
[32m[0907 20-42-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32817, current rewards: -1209.73629, mean: -0.68735
[32m[0907 20-42-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32887, current rewards: -1259.73629, mean: -0.69599
[32m[0907 20-42-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32950, current rewards: -1309.73629, mean: -0.70416
[32m[0907 20-43-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33010, current rewards: -1359.73629, mean: -0.71190
[32m[0907 20-43-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33066, current rewards: -1409.73629, mean: -0.71925
[32m[0907 20-43-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33123, current rewards: -1459.73629, mean: -0.72624
[32m[0907 20-43-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33175, current rewards: -1509.73629, mean: -0.73288
[32m[0907 20-44-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33218, current rewards: -1559.73629, mean: -0.73921
[32m[0907 20-44-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33247, current rewards: -1609.73629, mean: -0.74525
[32m[0907 20-44-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33272, current rewards: -1659.73629, mean: -0.75101
[32m[0907 20-45-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33291, current rewards: -1709.73629, mean: -0.75652
[32m[0907 20-45-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33316, current rewards: -1759.73629, mean: -0.76179
[32m[0907 20-45-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33339, current rewards: -1809.73629, mean: -0.76684
[32m[0907 20-45-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33361, current rewards: -1859.73629, mean: -0.77167
[32m[0907 20-46-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33347, current rewards: -1909.73629, mean: -0.77632
[32m[0907 20-46-24 @Agent.py:117][0m Average action selection time: 0.3333
[32m[0907 20-46-24 @Agent.py:118][0m Rollout length: 2520
[32m[0907 20-46-24 @MBExp.py:227][0m Rewards obtained: [-1949.7362924220843], Lows: [0], Highs: [1992], Total time: 98292.16387699998
[32m[0907 20-50-25 @MBExp.py:144][0m ####################################################################
[32m[0907 20-50-25 @MBExp.py:145][0m Starting training iteration 119.
[32m[0907 20-50-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.38069, current rewards: -10.00000, mean: -1.00000
[32m[0907 20-50-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36065, current rewards: -57.88680, mean: -0.96478
[32m[0907 20-51-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35791, current rewards: -107.88680, mean: -0.98079
[32m[0907 20-51-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35673, current rewards: -157.88680, mean: -0.98679
[32m[0907 20-51-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35615, current rewards: -181.27141, mean: -0.86320
[32m[0907 20-51-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35583, current rewards: -173.41187, mean: -0.66697
[32m[0907 20-52-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35568, current rewards: -165.55233, mean: -0.53404
[32m[0907 20-52-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35545, current rewards: -160.07167, mean: -0.44464
[32m[0907 20-52-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35525, current rewards: -210.07167, mean: -0.51237
[32m[0907 20-53-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35518, current rewards: -260.07167, mean: -0.56537
[32m[0907 20-53-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35509, current rewards: -310.07167, mean: -0.60798
[32m[0907 20-53-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35521, current rewards: -360.07167, mean: -0.64299
[32m[0907 20-54-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35519, current rewards: -410.07167, mean: -0.67225
[32m[0907 20-54-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35516, current rewards: -460.07167, mean: -0.69708
[32m[0907 20-54-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35513, current rewards: -510.07167, mean: -0.71841
[32m[0907 20-54-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35508, current rewards: -560.07167, mean: -0.73694
[32m[0907 20-55-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35507, current rewards: -610.07167, mean: -0.75317
[32m[0907 20-55-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35499, current rewards: -660.07167, mean: -0.76753
[32m[0907 20-55-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35492, current rewards: -710.07167, mean: -0.78030
[32m[0907 20-56-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35496, current rewards: -760.07167, mean: -0.79174
[32m[0907 20-56-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35467, current rewards: -810.07167, mean: -0.80205
[32m[0907 20-56-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35426, current rewards: -860.07167, mean: -0.81139
[32m[0907 20-56-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35391, current rewards: -910.07167, mean: -0.81988
[32m[0907 20-57-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35356, current rewards: -960.07167, mean: -0.82765
[32m[0907 20-57-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35327, current rewards: -1010.07167, mean: -0.83477
[32m[0907 20-57-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35299, current rewards: -1060.07167, mean: -0.84133
[32m[0907 20-58-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35271, current rewards: -1110.07167, mean: -0.84738
[32m[0907 20-58-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35244, current rewards: -1160.07167, mean: -0.85299
[32m[0907 20-58-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35219, current rewards: -1210.07167, mean: -0.85821
[32m[0907 20-58-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35197, current rewards: -1260.07167, mean: -0.86306
[32m[0907 20-59-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35179, current rewards: -1310.07167, mean: -0.86760
[32m[0907 20-59-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35162, current rewards: -1360.07167, mean: -0.87184
[32m[0907 20-59-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35144, current rewards: -1410.07167, mean: -0.87582
[32m[0907 21-00-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35128, current rewards: -1460.07167, mean: -0.87956
[32m[0907 21-00-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35113, current rewards: -1510.07167, mean: -0.88308
[32m[0907 21-00-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35118, current rewards: -1560.07167, mean: -0.88640
[32m[0907 21-01-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35126, current rewards: -1610.07167, mean: -0.88954
[32m[0907 21-01-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35135, current rewards: -1660.07167, mean: -0.89251
[32m[0907 21-01-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35145, current rewards: -1710.07167, mean: -0.89533
[32m[0907 21-01-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35154, current rewards: -1760.07167, mean: -0.89800
[32m[0907 21-02-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35165, current rewards: -1810.07167, mean: -0.90053
[32m[0907 21-02-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35172, current rewards: -1860.07167, mean: -0.90295
[32m[0907 21-02-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35179, current rewards: -1910.07167, mean: -0.90525
[32m[0907 21-03-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35172, current rewards: -1960.07167, mean: -0.90744
[32m[0907 21-03-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35158, current rewards: -2010.07167, mean: -0.90953
[32m[0907 21-03-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35147, current rewards: -2060.07167, mean: -0.91154
[32m[0907 21-03-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35136, current rewards: -2110.07167, mean: -0.91345
[32m[0907 21-04-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35126, current rewards: -2160.07167, mean: -0.91528
[32m[0907 21-04-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35117, current rewards: -2210.07167, mean: -0.91704
[32m[0907 21-04-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35082, current rewards: -2260.07167, mean: -0.91873
[32m[0907 21-05-02 @Agent.py:117][0m Average action selection time: 0.3504
[32m[0907 21-05-02 @Agent.py:118][0m Rollout length: 2520
[32m[0907 21-05-02 @MBExp.py:227][0m Rewards obtained: [-2300.0716722975626], Lows: [12], Highs: [2306], Total time: 99169.10471999999
[32m[0907 21-09-11 @MBExp.py:144][0m ####################################################################
[32m[0907 21-09-11 @MBExp.py:145][0m Starting training iteration 120.
[32m[0907 21-09-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35652, current rewards: -10.00000, mean: -1.00000
[32m[0907 21-09-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35698, current rewards: -88.12173, mean: -1.46870
[32m[0907 21-09-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37543, current rewards: -178.37249, mean: -1.62157
[32m[0907 21-10-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36896, current rewards: -242.29872, mean: -1.51437
[32m[0907 21-10-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36548, current rewards: -292.29872, mean: -1.39190
[32m[0907 21-10-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36336, current rewards: -342.29872, mean: -1.31653
[32m[0907 21-11-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36179, current rewards: -392.29872, mean: -1.26548
[32m[0907 21-11-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36078, current rewards: -442.29872, mean: -1.22861
[32m[0907 21-11-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35997, current rewards: -492.29872, mean: -1.20073
[32m[0907 21-11-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35939, current rewards: -542.29872, mean: -1.17891
[32m[0907 21-12-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35888, current rewards: -592.29872, mean: -1.16137
[32m[0907 21-12-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35846, current rewards: -642.29872, mean: -1.14696
[32m[0907 21-12-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35814, current rewards: -692.29872, mean: -1.13492
[32m[0907 21-13-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35784, current rewards: -742.29872, mean: -1.12470
[32m[0907 21-13-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35756, current rewards: -756.89886, mean: -1.06605
[32m[0907 21-13-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35735, current rewards: -750.19766, mean: -0.98710
[32m[0907 21-14-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35714, current rewards: -747.36368, mean: -0.92267
[32m[0907 21-14-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35689, current rewards: -744.61698, mean: -0.86583
[32m[0907 21-14-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35674, current rewards: -741.87029, mean: -0.81524
[32m[0907 21-14-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35635, current rewards: -739.12359, mean: -0.76992
[32m[0907 21-15-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35449, current rewards: -736.37690, mean: -0.72909
[32m[0907 21-15-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35287, current rewards: -733.63020, mean: -0.69210
[32m[0907 21-15-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35131, current rewards: -730.88351, mean: -0.65845
[32m[0907 21-15-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34994, current rewards: -728.13682, mean: -0.62770
[32m[0907 21-16-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34869, current rewards: -724.36547, mean: -0.59865
[32m[0907 21-16-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34750, current rewards: -755.94670, mean: -0.59996
[32m[0907 21-16-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34641, current rewards: -805.94670, mean: -0.61523
[32m[0907 21-17-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34543, current rewards: -855.94670, mean: -0.62937
[32m[0907 21-17-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34451, current rewards: -905.94670, mean: -0.64252
[32m[0907 21-17-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34365, current rewards: -955.94670, mean: -0.65476
[32m[0907 21-17-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34285, current rewards: -1005.94670, mean: -0.66619
[32m[0907 21-18-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34210, current rewards: -1055.94670, mean: -0.67689
[32m[0907 21-18-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34138, current rewards: -1105.94670, mean: -0.68692
[32m[0907 21-18-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34071, current rewards: -1155.94670, mean: -0.69635
[32m[0907 21-18-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34007, current rewards: -1205.94670, mean: -0.70523
[32m[0907 21-19-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33948, current rewards: -1255.94670, mean: -0.71361
[32m[0907 21-19-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33892, current rewards: -1305.94670, mean: -0.72152
[32m[0907 21-19-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33840, current rewards: -1355.94670, mean: -0.72900
[32m[0907 21-19-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33789, current rewards: -1405.94670, mean: -0.73610
[32m[0907 21-20-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33742, current rewards: -1455.94670, mean: -0.74283
[32m[0907 21-20-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33698, current rewards: -1505.94670, mean: -0.74923
[32m[0907 21-20-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33656, current rewards: -1555.94670, mean: -0.75531
[32m[0907 21-21-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33614, current rewards: -1605.94670, mean: -0.76111
[32m[0907 21-21-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33490, current rewards: -1655.94670, mean: -0.76664
[32m[0907 21-21-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33361, current rewards: -1705.94670, mean: -0.77192
[32m[0907 21-21-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33236, current rewards: -1755.94670, mean: -0.77697
[32m[0907 21-21-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33116, current rewards: -1805.94670, mean: -0.78180
[32m[0907 21-22-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33003, current rewards: -1855.94670, mean: -0.78642
[32m[0907 21-22-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32895, current rewards: -1905.94670, mean: -0.79085
[32m[0907 21-22-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32703, current rewards: -1955.94670, mean: -0.79510
[32m[0907 21-22-43 @Agent.py:117][0m Average action selection time: 0.3249
[32m[0907 21-22-43 @Agent.py:118][0m Rollout length: 2520
[32m[0907 21-22-44 @MBExp.py:227][0m Rewards obtained: [-1995.9467034931304], Lows: [95], Highs: [1847], Total time: 99982.12898899999
