[32m[0906 13-40-34 @logger.py:99][0m Log file set to /app/logs/dats-delay-20/zinc-coating-v0_3/Tuesday_06_September_2022_01-40PM.log
[32m[0906 13-40-34 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00002, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -70.47621, mean: -1.17460
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -136.91755, mean: -1.24470
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -189.55429, mean: -1.18471
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -243.00146, mean: -1.15715
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -290.72675, mean: -1.11818
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -342.61218, mean: -1.10520
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -395.22214, mean: -1.09784
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -451.77363, mean: -1.10189
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -520.13706, mean: -1.13073
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -582.12767, mean: -1.14143
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -650.32848, mean: -1.16130
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -724.05750, mean: -1.18698
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -781.31326, mean: -1.18381
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -837.94658, mean: -1.18021
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -886.25680, mean: -1.16613
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -942.60108, mean: -1.16371
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -994.93684, mean: -1.15690
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -1044.23092, mean: -1.14751
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -1100.45409, mean: -1.14631
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1159.15522, mean: -1.14768
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1217.41083, mean: -1.14850
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1270.44898, mean: -1.14455
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1324.80094, mean: -1.14207
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1371.09531, mean: -1.13314
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1419.37023, mean: -1.12648
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1465.71116, mean: -1.11886
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1521.54786, mean: -1.11879
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1573.52878, mean: -1.11598
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1627.14283, mean: -1.11448
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1678.17535, mean: -1.11137
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -1720.01566, mean: -1.10257
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -1768.24604, mean: -1.09829
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -1815.35023, mean: -1.09358
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -1852.44193, mean: -1.08330
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -1901.51905, mean: -1.08041
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -1962.78053, mean: -1.08441
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2013.90419, mean: -1.08274
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2063.52934, mean: -1.08038
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2113.54072, mean: -1.07834
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2161.49013, mean: -1.07537
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2211.00627, mean: -1.07330
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2264.08743, mean: -1.07303
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2312.52132, mean: -1.07061
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2362.31090, mean: -1.06892
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2435.99369, mean: -1.07787
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2512.24455, mean: -1.08755
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2573.88670, mean: -1.09063
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2639.59661, mean: -1.09527
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2716.59852, mean: -1.10431
[32m[0906 13-40-34 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-40-34 @Agent.py:118][0m Rollout length: 2520
[32m[0906 13-40-37 @MBExp.py:144][0m ####################################################################
[32m[0906 13-40-37 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-40-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34832, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-40-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33527, current rewards: -62.57113, mean: -1.04285
[32m[0906 13-41-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33346, current rewards: -150.99200, mean: -1.37265
[32m[0906 13-41-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33745, current rewards: -250.99200, mean: -1.56870
[32m[0906 13-41-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34670, current rewards: -317.53843, mean: -1.51209
[32m[0906 13-42-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35156, current rewards: -314.74024, mean: -1.21054
[32m[0906 13-42-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35451, current rewards: -310.26066, mean: -1.00084
[32m[0906 13-42-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35664, current rewards: -305.78776, mean: -0.84941
[32m[0906 13-43-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35842, current rewards: -301.05568, mean: -0.73428
[32m[0906 13-43-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35913, current rewards: -295.14799, mean: -0.64163
[32m[0906 13-43-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35978, current rewards: -289.31528, mean: -0.56728
[32m[0906 13-43-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36020, current rewards: -283.49427, mean: -0.50624
[32m[0906 13-44-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36086, current rewards: -277.66798, mean: -0.45519
[32m[0906 13-44-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36148, current rewards: -280.29635, mean: -0.42469
[32m[0906 13-44-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36186, current rewards: -375.50415, mean: -0.52888
[32m[0906 13-45-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36216, current rewards: -473.33861, mean: -0.62281
[32m[0906 13-45-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36240, current rewards: -573.33861, mean: -0.70783
[32m[0906 13-45-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36263, current rewards: -667.58686, mean: -0.77626
[32m[0906 13-46-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36277, current rewards: -749.64031, mean: -0.82378
[32m[0906 13-46-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36296, current rewards: -820.91799, mean: -0.85512
[32m[0906 13-46-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36309, current rewards: -897.84642, mean: -0.88896
[32m[0906 13-47-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36290, current rewards: -984.22610, mean: -0.92852
[32m[0906 13-47-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36273, current rewards: -1032.09268, mean: -0.92981
[32m[0906 13-47-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36262, current rewards: -1082.09268, mean: -0.93284
[32m[0906 13-47-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36255, current rewards: -1132.09268, mean: -0.93561
[32m[0906 13-48-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36249, current rewards: -1182.09268, mean: -0.93817
[32m[0906 13-48-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36250, current rewards: -1232.09268, mean: -0.94053
[32m[0906 13-48-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36252, current rewards: -1282.09268, mean: -0.94272
[32m[0906 13-49-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36251, current rewards: -1332.09268, mean: -0.94475
[32m[0906 13-49-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36242, current rewards: -1382.09268, mean: -0.94664
[32m[0906 13-49-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36251, current rewards: -1432.09268, mean: -0.94841
[32m[0906 13-50-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36259, current rewards: -1482.09268, mean: -0.95006
[32m[0906 13-50-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36264, current rewards: -1532.09268, mean: -0.95161
[32m[0906 13-50-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36267, current rewards: -1582.09268, mean: -0.95307
[32m[0906 13-50-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36271, current rewards: -1610.93540, mean: -0.94207
[32m[0906 13-51-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36276, current rewards: -1605.25833, mean: -0.91208
[32m[0906 13-51-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36283, current rewards: -1599.58127, mean: -0.88375
[32m[0906 13-51-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36286, current rewards: -1593.90420, mean: -0.85694
[32m[0906 13-52-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36289, current rewards: -1588.22713, mean: -0.83153
[32m[0906 13-52-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36294, current rewards: -1582.55007, mean: -0.80742
[32m[0906 13-52-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36295, current rewards: -1590.23550, mean: -0.79116
[32m[0906 13-53-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36282, current rewards: -1640.23550, mean: -0.79623
[32m[0906 13-53-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36272, current rewards: -1690.23550, mean: -0.80106
[32m[0906 13-53-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36264, current rewards: -1740.23550, mean: -0.80566
[32m[0906 13-53-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36262, current rewards: -1790.23550, mean: -0.81006
[32m[0906 13-54-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36255, current rewards: -1840.23550, mean: -0.81426
[32m[0906 13-54-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36257, current rewards: -1890.23550, mean: -0.81828
[32m[0906 13-54-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36255, current rewards: -1940.23550, mean: -0.82213
[32m[0906 13-55-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36262, current rewards: -1990.23550, mean: -0.82582
[32m[0906 13-55-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36264, current rewards: -2040.23550, mean: -0.82936
[32m[0906 13-55-44 @Agent.py:117][0m Average action selection time: 0.3627
[32m[0906 13-55-44 @Agent.py:118][0m Rollout length: 2520
[32m[0906 13-55-44 @MBExp.py:227][0m Rewards obtained: [-2080.2354964770648], Lows: [510], Highs: [1157], Total time: 907.443799
[32m[0906 13-55-49 @MBExp.py:144][0m ####################################################################
[32m[0906 13-55-49 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-55-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36602, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-56-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36307, current rewards: -12.05188, mean: -0.20086
[32m[0906 13-56-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36252, current rewards: 3.47248, mean: 0.03157
[32m[0906 13-56-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35999, current rewards: 18.79354, mean: 0.11746
[32m[0906 13-57-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35942, current rewards: 34.09445, mean: 0.16235
[32m[0906 13-57-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35908, current rewards: 49.40404, mean: 0.19002
[32m[0906 13-57-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35876, current rewards: 64.71129, mean: 0.20875
[32m[0906 13-57-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35827, current rewards: 79.99797, mean: 0.22222
[32m[0906 13-58-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35849, current rewards: 66.46684, mean: 0.16211
[32m[0906 13-58-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35881, current rewards: 70.88144, mean: 0.15409
[32m[0906 13-58-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35918, current rewards: 73.46910, mean: 0.14406
[32m[0906 13-59-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35945, current rewards: 78.21413, mean: 0.13967
[32m[0906 13-59-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35967, current rewards: 82.62634, mean: 0.13545
[32m[0906 13-59-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35991, current rewards: 17.94206, mean: 0.02718
[32m[0906 14-00-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36002, current rewards: -82.05794, mean: -0.11557
[32m[0906 14-00-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35998, current rewards: -182.05794, mean: -0.23955
[32m[0906 14-00-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35993, current rewards: -282.05794, mean: -0.34822
[32m[0906 14-00-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36001, current rewards: -382.05794, mean: -0.44425
[32m[0906 14-01-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36007, current rewards: -482.05794, mean: -0.52973
[32m[0906 14-01-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35996, current rewards: -582.05794, mean: -0.60631
[32m[0906 14-01-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35977, current rewards: -682.05794, mean: -0.67530
[32m[0906 14-02-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35970, current rewards: -782.05794, mean: -0.73779
[32m[0906 14-02-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35963, current rewards: -882.05794, mean: -0.79465
[32m[0906 14-02-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35951, current rewards: -982.05794, mean: -0.84660
[32m[0906 14-03-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35940, current rewards: -1007.56392, mean: -0.83270
[32m[0906 14-03-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35949, current rewards: -1001.99991, mean: -0.79524
[32m[0906 14-03-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35959, current rewards: -996.19310, mean: -0.76045
[32m[0906 14-03-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35976, current rewards: -990.28024, mean: -0.72815
[32m[0906 14-04-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36006, current rewards: -984.36012, mean: -0.69813
[32m[0906 14-04-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36028, current rewards: -978.44057, mean: -0.67016
[32m[0906 14-04-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36033, current rewards: -972.51999, mean: -0.64405
[32m[0906 14-05-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36039, current rewards: -967.27677, mean: -0.62005
[32m[0906 14-05-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36032, current rewards: -960.41304, mean: -0.59653
[32m[0906 14-05-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36023, current rewards: -954.89193, mean: -0.57524
[32m[0906 14-06-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36011, current rewards: -950.59155, mean: -0.55590
[32m[0906 14-06-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35999, current rewards: -946.22707, mean: -0.53763
[32m[0906 14-06-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35990, current rewards: -941.87600, mean: -0.52037
[32m[0906 14-06-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35981, current rewards: -937.52314, mean: -0.50404
[32m[0906 14-07-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35990, current rewards: -933.16709, mean: -0.48857
[32m[0906 14-07-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36003, current rewards: -928.81087, mean: -0.47388
[32m[0906 14-07-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36016, current rewards: -924.45200, mean: -0.45993
[32m[0906 14-08-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36018, current rewards: -961.83781, mean: -0.46691
[32m[0906 14-08-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36011, current rewards: -961.96803, mean: -0.45591
[32m[0906 14-08-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35999, current rewards: -982.48826, mean: -0.45486
[32m[0906 14-09-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35994, current rewards: -1032.48826, mean: -0.46719
[32m[0906 14-09-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35989, current rewards: -1082.48826, mean: -0.47898
[32m[0906 14-09-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35981, current rewards: -1132.48826, mean: -0.49025
[32m[0906 14-09-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35977, current rewards: -1182.48826, mean: -0.50105
[32m[0906 14-10-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35982, current rewards: -1232.48826, mean: -0.51141
[32m[0906 14-10-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35981, current rewards: -1282.48826, mean: -0.52134
[32m[0906 14-10-49 @Agent.py:117][0m Average action selection time: 0.3599
[32m[0906 14-10-49 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-10-49 @MBExp.py:227][0m Rewards obtained: [-1322.488261402835], Lows: [577], Highs: [406], Total time: 1807.776342
[32m[0906 14-10-56 @MBExp.py:144][0m ####################################################################
[32m[0906 14-10-56 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 14-11-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36890, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-11-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36709, current rewards: -15.11179, mean: -0.25186
[32m[0906 14-11-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36663, current rewards: -9.16514, mean: -0.08332
[32m[0906 14-11-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36504, current rewards: -3.22508, mean: -0.02016
[32m[0906 14-12-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36403, current rewards: 2.71021, mean: 0.01291
[32m[0906 14-12-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36327, current rewards: 8.65430, mean: 0.03329
[32m[0906 14-12-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36189, current rewards: 14.59515, mean: 0.04708
[32m[0906 14-13-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36141, current rewards: 20.53217, mean: 0.05703
[32m[0906 14-13-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36088, current rewards: 24.84486, mean: 0.06060
[32m[0906 14-13-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36043, current rewards: 29.26751, mean: 0.06363
[32m[0906 14-14-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36004, current rewards: 33.69015, mean: 0.06606
[32m[0906 14-14-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35977, current rewards: -7.34506, mean: -0.01312
[32m[0906 14-14-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35947, current rewards: -3.63302, mean: -0.00596
[32m[0906 14-14-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35923, current rewards: 0.05566, mean: 0.00008
[32m[0906 14-15-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35903, current rewards: 3.74434, mean: 0.00527
[32m[0906 14-15-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35888, current rewards: 7.43362, mean: 0.00978
[32m[0906 14-15-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35880, current rewards: 10.61298, mean: 0.01310
[32m[0906 14-16-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35868, current rewards: 13.71782, mean: 0.01595
[32m[0906 14-16-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35882, current rewards: 16.82211, mean: 0.01849
[32m[0906 14-16-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35894, current rewards: 19.92796, mean: 0.02076
[32m[0906 14-16-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35903, current rewards: 23.03292, mean: 0.02280
[32m[0906 14-17-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35918, current rewards: 26.13847, mean: 0.02466
[32m[0906 14-17-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35928, current rewards: 8.97713, mean: 0.00809
[32m[0906 14-17-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35941, current rewards: 14.64640, mean: 0.01263
[32m[0906 14-18-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35948, current rewards: 21.21885, mean: 0.01754
[32m[0906 14-18-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35953, current rewards: 27.95834, mean: 0.02219
[32m[0906 14-18-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35964, current rewards: 34.70449, mean: 0.02649
[32m[0906 14-19-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35952, current rewards: 41.45012, mean: 0.03048
[32m[0906 14-19-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35940, current rewards: 48.19516, mean: 0.03418
[32m[0906 14-19-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35923, current rewards: 54.94210, mean: 0.03763
[32m[0906 14-19-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35913, current rewards: 61.68644, mean: 0.04085
[32m[0906 14-20-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35904, current rewards: 68.42631, mean: 0.04386
[32m[0906 14-20-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35890, current rewards: 61.62038, mean: 0.03827
[32m[0906 14-20-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35881, current rewards: 35.36011, mean: 0.02130
[32m[0906 14-21-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35872, current rewards: 6.58694, mean: 0.00385
[32m[0906 14-21-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35863, current rewards: 27.29281, mean: 0.01551
[32m[0906 14-21-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35858, current rewards: 44.85621, mean: 0.02478
[32m[0906 14-22-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35850, current rewards: 64.94824, mean: 0.03492
[32m[0906 14-22-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35844, current rewards: 85.08865, mean: 0.04455
[32m[0906 14-22-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35838, current rewards: 102.66412, mean: 0.05238
[32m[0906 14-22-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35831, current rewards: 95.75521, mean: 0.04764
[32m[0906 14-23-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35823, current rewards: -4.24479, mean: -0.00206
[32m[0906 14-23-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35824, current rewards: -104.24479, mean: -0.04941
[32m[0906 14-23-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35822, current rewards: -204.24479, mean: -0.09456
[32m[0906 14-24-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35823, current rewards: -304.24479, mean: -0.13767
[32m[0906 14-24-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35828, current rewards: -397.24241, mean: -0.17577
[32m[0906 14-24-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35832, current rewards: -492.38111, mean: -0.21315
[32m[0906 14-25-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35832, current rewards: -587.51557, mean: -0.24895
[32m[0906 14-25-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35832, current rewards: -680.22392, mean: -0.28225
[32m[0906 14-25-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35818, current rewards: -775.35693, mean: -0.31519
[32m[0906 14-25-52 @Agent.py:117][0m Average action selection time: 0.3581
[32m[0906 14-25-52 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-25-52 @MBExp.py:227][0m Rewards obtained: [-850.4892666886418], Lows: [568], Highs: [44], Total time: 2703.7525910000004
[32m[0906 14-26-01 @MBExp.py:144][0m ####################################################################
[32m[0906 14-26-01 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 14-26-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35702, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-26-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35552, current rewards: -17.29979, mean: -0.28833
[32m[0906 14-26-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35524, current rewards: -11.33603, mean: -0.10305
[32m[0906 14-26-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35454, current rewards: -5.38495, mean: -0.03366
[32m[0906 14-27-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35441, current rewards: 0.57158, mean: 0.00272
[32m[0906 14-27-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35483, current rewards: 6.52364, mean: 0.02509
[32m[0906 14-27-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35488, current rewards: 12.48259, mean: 0.04027
[32m[0906 14-28-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35486, current rewards: 18.88119, mean: 0.05245
[32m[0906 14-28-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35483, current rewards: 25.02226, mean: 0.06103
[32m[0906 14-28-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35481, current rewards: 31.16927, mean: 0.06776
[32m[0906 14-29-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35487, current rewards: 37.30721, mean: 0.07315
[32m[0906 14-29-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35485, current rewards: 43.45192, mean: 0.07759
[32m[0906 14-29-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35501, current rewards: 49.60350, mean: 0.08132
[32m[0906 14-29-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35521, current rewards: 55.74285, mean: 0.08446
[32m[0906 14-30-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35574, current rewards: 60.69949, mean: 0.08549
[32m[0906 14-30-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35590, current rewards: 56.65030, mean: 0.07454
[32m[0906 14-30-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35577, current rewards: 66.28609, mean: 0.08183
[32m[0906 14-31-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35568, current rewards: 75.12478, mean: 0.08735
[32m[0906 14-31-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35562, current rewards: 83.96516, mean: 0.09227
[32m[0906 14-31-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35557, current rewards: 92.80923, mean: 0.09668
[32m[0906 14-32-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35553, current rewards: 5.93384, mean: 0.00588
[32m[0906 14-32-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35544, current rewards: -89.35166, mean: -0.08429
[32m[0906 14-32-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35537, current rewards: -184.61199, mean: -0.16632
[32m[0906 14-32-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35529, current rewards: -277.44168, mean: -0.23917
[32m[0906 14-33-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35523, current rewards: -372.64387, mean: -0.30797
[32m[0906 14-33-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35523, current rewards: -465.45556, mean: -0.36941
[32m[0906 14-33-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35523, current rewards: -560.64173, mean: -0.42797
[32m[0906 14-34-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35517, current rewards: -655.84687, mean: -0.48224
[32m[0906 14-34-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35511, current rewards: -748.63894, mean: -0.53095
[32m[0906 14-34-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35508, current rewards: -830.25188, mean: -0.56867
[32m[0906 14-34-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35508, current rewards: -829.17653, mean: -0.54912
[32m[0906 14-35-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35512, current rewards: -824.15303, mean: -0.52830
[32m[0906 14-35-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35511, current rewards: -819.68753, mean: -0.50912
[32m[0906 14-35-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35511, current rewards: -814.96427, mean: -0.49094
[32m[0906 14-36-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35512, current rewards: -810.24085, mean: -0.47383
[32m[0906 14-36-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35513, current rewards: -805.51217, mean: -0.45768
[32m[0906 14-36-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35513, current rewards: -800.79016, mean: -0.44243
[32m[0906 14-37-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35516, current rewards: -796.06641, mean: -0.42799
[32m[0906 14-37-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35513, current rewards: -791.33638, mean: -0.41431
[32m[0906 14-37-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35513, current rewards: -786.70799, mean: -0.40138
[32m[0906 14-37-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35514, current rewards: -783.08885, mean: -0.38960
[32m[0906 14-38-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35512, current rewards: -814.42938, mean: -0.39535
[32m[0906 14-38-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35509, current rewards: -801.86692, mean: -0.38003
[32m[0906 14-38-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35505, current rewards: -789.56224, mean: -0.36554
[32m[0906 14-39-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35497, current rewards: -777.25352, mean: -0.35170
[32m[0906 14-39-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35500, current rewards: -764.96393, mean: -0.33848
[32m[0906 14-39-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35507, current rewards: -752.65754, mean: -0.32583
[32m[0906 14-39-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35512, current rewards: -740.36300, mean: -0.31371
[32m[0906 14-40-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35515, current rewards: -723.67012, mean: -0.30028
[32m[0906 14-40-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35516, current rewards: -755.06815, mean: -0.30694
[32m[0906 14-40-49 @Agent.py:117][0m Average action selection time: 0.3552
[32m[0906 14-40-49 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-40-49 @MBExp.py:227][0m Rewards obtained: [-747.4585856620475], Lows: [507], Highs: [41], Total time: 3592.4188140000006
[32m[0906 14-41-00 @MBExp.py:144][0m ####################################################################
[32m[0906 14-41-00 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 14-41-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35592, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-41-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35545, current rewards: -95.92750, mean: -1.59879
[32m[0906 14-41-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35447, current rewards: -195.92750, mean: -1.78116
[32m[0906 14-41-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35389, current rewards: -295.92750, mean: -1.84955
[32m[0906 14-42-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35353, current rewards: -395.92750, mean: -1.88537
[32m[0906 14-42-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35345, current rewards: -495.92750, mean: -1.90741
[32m[0906 14-42-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35332, current rewards: -595.92750, mean: -1.92235
[32m[0906 14-43-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35320, current rewards: -695.92750, mean: -1.93313
[32m[0906 14-43-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35315, current rewards: -795.92750, mean: -1.94129
[32m[0906 14-43-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35316, current rewards: -895.92750, mean: -1.94767
[32m[0906 14-44-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35308, current rewards: -995.92750, mean: -1.95280
[32m[0906 14-44-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35303, current rewards: -1095.92750, mean: -1.95701
[32m[0906 14-44-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35302, current rewards: -1195.92750, mean: -1.96054
[32m[0906 14-44-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35317, current rewards: -1295.92750, mean: -1.96353
[32m[0906 14-45-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35330, current rewards: -1351.77368, mean: -1.90391
[32m[0906 14-45-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35353, current rewards: -1451.77368, mean: -1.91023
[32m[0906 14-45-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35365, current rewards: -1551.77368, mean: -1.91577
[32m[0906 14-46-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35385, current rewards: -1651.77368, mean: -1.92067
[32m[0906 14-46-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35412, current rewards: -1751.77368, mean: -1.92503
[32m[0906 14-46-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35439, current rewards: -1851.77368, mean: -1.92893
[32m[0906 14-46-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35484, current rewards: -1951.77368, mean: -1.93245
[32m[0906 14-47-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35528, current rewards: -2051.77368, mean: -1.93564
[32m[0906 14-47-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35547, current rewards: -2151.77368, mean: -1.93853
[32m[0906 14-47-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35564, current rewards: -2251.77368, mean: -1.94118
[32m[0906 14-48-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35579, current rewards: -2351.77368, mean: -1.94361
[32m[0906 14-48-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35588, current rewards: -2451.77368, mean: -1.94585
[32m[0906 14-48-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35599, current rewards: -2551.77368, mean: -1.94792
[32m[0906 14-49-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35612, current rewards: -2651.77368, mean: -1.94983
[32m[0906 14-49-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35631, current rewards: -2751.77368, mean: -1.95161
[32m[0906 14-49-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35658, current rewards: -2851.77368, mean: -1.95327
[32m[0906 14-49-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35687, current rewards: -2951.77368, mean: -1.95482
[32m[0906 14-50-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35714, current rewards: -3051.77368, mean: -1.95627
[32m[0906 14-50-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35739, current rewards: -3151.77368, mean: -1.95762
[32m[0906 14-50-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35765, current rewards: -3251.77368, mean: -1.95890
[32m[0906 14-51-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35789, current rewards: -3351.77368, mean: -1.96010
[32m[0906 14-51-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35803, current rewards: -3451.77368, mean: -1.96124
[32m[0906 14-51-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35806, current rewards: -3551.77368, mean: -1.96231
[32m[0906 14-52-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35807, current rewards: -3651.77368, mean: -1.96332
[32m[0906 14-52-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35799, current rewards: -3751.77368, mean: -1.96428
[32m[0906 14-52-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35786, current rewards: -3851.77368, mean: -1.96519
[32m[0906 14-53-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35774, current rewards: -3951.77368, mean: -1.96606
[32m[0906 14-53-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35761, current rewards: -4051.77368, mean: -1.96688
[32m[0906 14-53-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35749, current rewards: -4151.77368, mean: -1.96767
[32m[0906 14-53-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35745, current rewards: -4251.77368, mean: -1.96841
[32m[0906 14-54-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35734, current rewards: -4351.77368, mean: -1.96913
[32m[0906 14-54-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35739, current rewards: -4451.77368, mean: -1.96981
[32m[0906 14-54-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35738, current rewards: -4551.77368, mean: -1.97046
[32m[0906 14-55-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35734, current rewards: -4651.77368, mean: -1.97109
[32m[0906 14-55-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35713, current rewards: -4751.77368, mean: -1.97169
[32m[0906 14-55-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35699, current rewards: -4851.77368, mean: -1.97227
[32m[0906 14-55-53 @Agent.py:117][0m Average action selection time: 0.3570
[32m[0906 14-55-53 @Agent.py:118][0m Rollout length: 2520
[32m[0906 14-55-53 @MBExp.py:227][0m Rewards obtained: [-4931.77367795105], Lows: [2457], Highs: [22], Total time: 4485.610396000001
[32m[0906 14-56-06 @MBExp.py:144][0m ####################################################################
[32m[0906 14-56-06 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 14-56-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36059, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-56-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35943, current rewards: -16.74184, mean: -0.27903
[32m[0906 14-56-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35820, current rewards: -10.34980, mean: -0.09409
[32m[0906 14-57-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35786, current rewards: -4.83284, mean: -0.03021
[32m[0906 14-57-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35716, current rewards: 0.00855, mean: 0.00004
[32m[0906 14-57-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35903, current rewards: 5.86661, mean: 0.02256
[32m[0906 14-57-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35953, current rewards: -31.96529, mean: -0.10311
[32m[0906 14-58-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35903, current rewards: -33.78717, mean: -0.09385
[32m[0906 14-58-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35858, current rewards: -27.80218, mean: -0.06781
[32m[0906 14-58-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35817, current rewards: -21.82423, mean: -0.04744
[32m[0906 14-59-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35772, current rewards: -15.85194, mean: -0.03108
[32m[0906 14-59-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35748, current rewards: -9.87751, mean: -0.01764
[32m[0906 14-59-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35751, current rewards: -3.90147, mean: -0.00640
[32m[0906 15-00-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35744, current rewards: -39.02945, mean: -0.05914
[32m[0906 15-00-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35775, current rewards: -51.94244, mean: -0.07316
[32m[0906 15-00-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35796, current rewards: -68.07630, mean: -0.08957
[32m[0906 15-00-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35814, current rewards: -65.48907, mean: -0.08085
[32m[0906 15-01-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35840, current rewards: -62.90185, mean: -0.07314
[32m[0906 15-01-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35857, current rewards: -60.31462, mean: -0.06628
[32m[0906 15-01-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35847, current rewards: -57.72740, mean: -0.06013
[32m[0906 15-02-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35834, current rewards: -55.14017, mean: -0.05459
[32m[0906 15-02-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35817, current rewards: -52.55295, mean: -0.04958
[32m[0906 15-02-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35811, current rewards: -80.46632, mean: -0.07249
[32m[0906 15-03-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35801, current rewards: -130.46632, mean: -0.11247
[32m[0906 15-03-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35792, current rewards: -180.46632, mean: -0.14915
[32m[0906 15-03-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35782, current rewards: -230.46632, mean: -0.18291
[32m[0906 15-03-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35789, current rewards: -280.46632, mean: -0.21410
[32m[0906 15-04-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35825, current rewards: -330.46632, mean: -0.24299
[32m[0906 15-04-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35851, current rewards: -380.46632, mean: -0.26983
[32m[0906 15-04-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35877, current rewards: -430.46632, mean: -0.29484
[32m[0906 15-05-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35901, current rewards: -480.46632, mean: -0.31819
[32m[0906 15-05-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35919, current rewards: -530.46632, mean: -0.34004
[32m[0906 15-05-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35911, current rewards: -580.46632, mean: -0.36054
[32m[0906 15-06-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35909, current rewards: -630.46632, mean: -0.37980
[32m[0906 15-06-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35911, current rewards: -680.46632, mean: -0.39793
[32m[0906 15-06-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35898, current rewards: -730.46632, mean: -0.41504
[32m[0906 15-06-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35884, current rewards: -780.46632, mean: -0.43120
[32m[0906 15-07-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35877, current rewards: -830.46632, mean: -0.44649
[32m[0906 15-07-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35873, current rewards: -880.46632, mean: -0.46098
[32m[0906 15-07-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35872, current rewards: -930.46632, mean: -0.47473
[32m[0906 15-08-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35869, current rewards: -980.46632, mean: -0.48779
[32m[0906 15-08-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35867, current rewards: -1030.46632, mean: -0.50023
[32m[0906 15-08-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35873, current rewards: -1046.55454, mean: -0.49600
[32m[0906 15-09-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35877, current rewards: -1041.85813, mean: -0.48234
[32m[0906 15-09-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35866, current rewards: -1037.16172, mean: -0.46930
[32m[0906 15-09-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35871, current rewards: -1032.46531, mean: -0.45684
[32m[0906 15-09-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35874, current rewards: -1027.76890, mean: -0.44492
[32m[0906 15-10-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35873, current rewards: -1023.07249, mean: -0.43351
[32m[0906 15-10-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35858, current rewards: -1052.06631, mean: -0.43654
[32m[0906 15-10-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35855, current rewards: -1049.66563, mean: -0.42669
[32m[0906 15-11-04 @Agent.py:117][0m Average action selection time: 0.3586
[32m[0906 15-11-04 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-11-04 @MBExp.py:227][0m Rewards obtained: [-1047.7450923719477], Lows: [70], Highs: [1050], Total time: 5382.838334000001
[32m[0906 15-11-19 @MBExp.py:144][0m ####################################################################
[32m[0906 15-11-19 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 15-11-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35889, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-11-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35899, current rewards: -53.47056, mean: -0.89118
[32m[0906 15-11-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35813, current rewards: -92.45055, mean: -0.84046
[32m[0906 15-12-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35855, current rewards: -133.63117, mean: -0.83519
[32m[0906 15-12-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35784, current rewards: -170.39880, mean: -0.81142
[32m[0906 15-12-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35805, current rewards: -211.57600, mean: -0.81375
[32m[0906 15-13-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35835, current rewards: -252.75861, mean: -0.81535
[32m[0906 15-13-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35902, current rewards: -275.96817, mean: -0.76658
[32m[0906 15-13-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35920, current rewards: -302.70146, mean: -0.73830
[32m[0906 15-14-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35882, current rewards: -321.72540, mean: -0.69940
[32m[0906 15-14-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35863, current rewards: -348.49456, mean: -0.68332
[32m[0906 15-14-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35848, current rewards: -371.85080, mean: -0.66402
[32m[0906 15-14-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35837, current rewards: -393.15924, mean: -0.64452
[32m[0906 15-15-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35828, current rewards: -421.02695, mean: -0.63792
[32m[0906 15-15-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35830, current rewards: -485.80579, mean: -0.68423
[32m[0906 15-15-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35838, current rewards: -585.80579, mean: -0.77080
[32m[0906 15-16-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35873, current rewards: -685.80579, mean: -0.84667
[32m[0906 15-16-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35900, current rewards: -785.80579, mean: -0.91373
[32m[0906 15-16-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35924, current rewards: -885.80579, mean: -0.97341
[32m[0906 15-17-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35967, current rewards: -985.80579, mean: -1.02688
[32m[0906 15-17-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35987, current rewards: -1085.80579, mean: -1.07506
[32m[0906 15-17-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35988, current rewards: -1185.80579, mean: -1.11868
[32m[0906 15-17-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35986, current rewards: -1285.80579, mean: -1.15838
[32m[0906 15-18-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35994, current rewards: -1385.80579, mean: -1.19466
[32m[0906 15-18-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35999, current rewards: -1485.80579, mean: -1.22794
[32m[0906 15-18-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35983, current rewards: -1585.80579, mean: -1.25858
[32m[0906 15-19-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35968, current rewards: -1685.80579, mean: -1.28687
[32m[0906 15-19-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35952, current rewards: -1785.80579, mean: -1.31309
[32m[0906 15-19-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35941, current rewards: -1885.80579, mean: -1.33745
[32m[0906 15-20-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35935, current rewards: -1985.80579, mean: -1.36014
[32m[0906 15-20-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35926, current rewards: -2085.80579, mean: -1.38133
[32m[0906 15-20-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35925, current rewards: -2129.19924, mean: -1.36487
[32m[0906 15-20-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35917, current rewards: -2172.89898, mean: -1.34963
[32m[0906 15-21-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35910, current rewards: -2222.89898, mean: -1.33910
[32m[0906 15-21-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35902, current rewards: -2272.89898, mean: -1.32918
[32m[0906 15-21-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35896, current rewards: -2322.89898, mean: -1.31983
[32m[0906 15-22-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35890, current rewards: -2372.89898, mean: -1.31099
[32m[0906 15-22-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35883, current rewards: -2422.89898, mean: -1.30263
[32m[0906 15-22-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35879, current rewards: -2472.89898, mean: -1.29471
[32m[0906 15-23-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35874, current rewards: -2522.89898, mean: -1.28719
[32m[0906 15-23-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35869, current rewards: -2529.77083, mean: -1.25859
[32m[0906 15-23-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35870, current rewards: -2568.90849, mean: -1.24704
[32m[0906 15-23-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35867, current rewards: -2618.90849, mean: -1.24119
[32m[0906 15-24-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35860, current rewards: -2668.90849, mean: -1.23561
[32m[0906 15-24-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35836, current rewards: -2718.90849, mean: -1.23028
[32m[0906 15-24-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35836, current rewards: -2768.90849, mean: -1.22518
[32m[0906 15-25-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35835, current rewards: -2818.90849, mean: -1.22031
[32m[0906 15-25-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35832, current rewards: -2868.90849, mean: -1.21564
[32m[0906 15-25-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35811, current rewards: -2918.90849, mean: -1.21117
[32m[0906 15-26-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35799, current rewards: -2968.90849, mean: -1.20687
[32m[0906 15-26-14 @Agent.py:117][0m Average action selection time: 0.3580
[32m[0906 15-26-14 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-26-14 @MBExp.py:227][0m Rewards obtained: [-3008.9084935054225], Lows: [850], Highs: [1340], Total time: 6278.480232000001
[32m[0906 15-26-32 @MBExp.py:144][0m ####################################################################
[32m[0906 15-26-32 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 15-26-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36104, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-26-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36021, current rewards: -99.00000, mean: -1.65000
[32m[0906 15-27-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35921, current rewards: -199.00000, mean: -1.80909
[32m[0906 15-27-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35894, current rewards: -299.00000, mean: -1.86875
[32m[0906 15-27-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35690, current rewards: -399.00000, mean: -1.90000
[32m[0906 15-28-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35725, current rewards: -499.00000, mean: -1.91923
[32m[0906 15-28-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35739, current rewards: -599.00000, mean: -1.93226
[32m[0906 15-28-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35786, current rewards: -696.91480, mean: -1.93587
[32m[0906 15-28-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35791, current rewards: -796.91480, mean: -1.94369
[32m[0906 15-29-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35793, current rewards: -896.91480, mean: -1.94981
[32m[0906 15-29-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35791, current rewards: -996.91480, mean: -1.95473
[32m[0906 15-29-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35797, current rewards: -1096.91480, mean: -1.95878
[32m[0906 15-30-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35814, current rewards: -1196.91480, mean: -1.96216
[32m[0906 15-30-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35810, current rewards: -1246.24551, mean: -1.88825
[32m[0906 15-30-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35798, current rewards: -1299.84319, mean: -1.83077
[32m[0906 15-31-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35800, current rewards: -1317.92738, mean: -1.73411
[32m[0906 15-31-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35811, current rewards: -1349.66731, mean: -1.66626
[32m[0906 15-31-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35833, current rewards: -1369.06992, mean: -1.59194
[32m[0906 15-31-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35841, current rewards: -1376.46396, mean: -1.51260
[32m[0906 15-32-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35863, current rewards: -1400.47206, mean: -1.45883
[32m[0906 15-32-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35885, current rewards: -1434.36918, mean: -1.42017
[32m[0906 15-32-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35906, current rewards: -1465.66475, mean: -1.38270
[32m[0906 15-33-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35923, current rewards: -1495.69680, mean: -1.34747
[32m[0906 15-33-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35936, current rewards: -1503.16206, mean: -1.29583
[32m[0906 15-33-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35950, current rewards: -1540.62684, mean: -1.27325
[32m[0906 15-34-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35946, current rewards: -1640.62684, mean: -1.30208
[32m[0906 15-34-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35938, current rewards: -1740.62684, mean: -1.32872
[32m[0906 15-34-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35933, current rewards: -1840.62684, mean: -1.35340
[32m[0906 15-34-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35937, current rewards: -1940.62684, mean: -1.37633
[32m[0906 15-35-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35919, current rewards: -2034.04861, mean: -1.39318
[32m[0906 15-35-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35911, current rewards: -2096.77694, mean: -1.38859
[32m[0906 15-35-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35901, current rewards: -2196.77694, mean: -1.40819
[32m[0906 15-36-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35895, current rewards: -2296.77694, mean: -1.42657
[32m[0906 15-36-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35888, current rewards: -2396.77694, mean: -1.44384
[32m[0906 15-36-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35883, current rewards: -2496.77694, mean: -1.46010
[32m[0906 15-37-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35876, current rewards: -2596.77694, mean: -1.47544
[32m[0906 15-37-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35870, current rewards: -2696.77694, mean: -1.48993
[32m[0906 15-37-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35865, current rewards: -2796.77694, mean: -1.50364
[32m[0906 15-37-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35866, current rewards: -2896.77694, mean: -1.51664
[32m[0906 15-38-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35847, current rewards: -2996.77694, mean: -1.52897
[32m[0906 15-38-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35824, current rewards: -3096.77694, mean: -1.54069
[32m[0906 15-38-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35800, current rewards: -3194.51436, mean: -1.55074
[32m[0906 15-39-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35697, current rewards: -3294.51436, mean: -1.56138
[32m[0906 15-39-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35598, current rewards: -3394.51436, mean: -1.57153
[32m[0906 15-39-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35494, current rewards: -3494.51436, mean: -1.58123
[32m[0906 15-39-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35406, current rewards: -3594.51436, mean: -1.59049
[32m[0906 15-40-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35323, current rewards: -3694.51436, mean: -1.59936
[32m[0906 15-40-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35241, current rewards: -3794.51436, mean: -1.60785
[32m[0906 15-40-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35144, current rewards: -3894.51436, mean: -1.61598
[32m[0906 15-40-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35060, current rewards: -3994.51436, mean: -1.62379
[32m[0906 15-41-08 @Agent.py:117][0m Average action selection time: 0.3501
[32m[0906 15-41-08 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-41-08 @MBExp.py:227][0m Rewards obtained: [-4074.514359811793], Lows: [2074], Highs: [41], Total time: 7154.270536000001
[32m[0906 15-41-25 @MBExp.py:144][0m ####################################################################
[32m[0906 15-41-25 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 15-41-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31879, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-41-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31721, current rewards: -53.66461, mean: -0.89441
[32m[0906 15-42-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31609, current rewards: -153.66461, mean: -1.39695
[32m[0906 15-42-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31551, current rewards: -253.66461, mean: -1.58540
[32m[0906 15-42-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31397, current rewards: -353.66461, mean: -1.68412
[32m[0906 15-42-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31454, current rewards: -406.09056, mean: -1.56189
[32m[0906 15-43-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31500, current rewards: -398.80437, mean: -1.28647
[32m[0906 15-43-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31529, current rewards: -391.38441, mean: -1.08718
[32m[0906 15-43-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31541, current rewards: -383.96812, mean: -0.93651
[32m[0906 15-43-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31550, current rewards: -376.54268, mean: -0.81857
[32m[0906 15-44-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31584, current rewards: -369.12863, mean: -0.72378
[32m[0906 15-44-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31591, current rewards: -361.69425, mean: -0.64588
[32m[0906 15-44-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31595, current rewards: -354.25134, mean: -0.58074
[32m[0906 15-44-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31596, current rewards: -346.82398, mean: -0.52549
[32m[0906 15-45-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31600, current rewards: -362.58574, mean: -0.51068
[32m[0906 15-45-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31596, current rewards: -363.67384, mean: -0.47852
[32m[0906 15-45-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31592, current rewards: -463.67384, mean: -0.57244
[32m[0906 15-45-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31598, current rewards: -563.67384, mean: -0.65543
[32m[0906 15-46-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31596, current rewards: -663.67384, mean: -0.72931
[32m[0906 15-46-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31595, current rewards: -763.67384, mean: -0.79549
[32m[0906 15-46-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31595, current rewards: -863.67384, mean: -0.85512
[32m[0906 15-47-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31591, current rewards: -963.67384, mean: -0.90913
[32m[0906 15-47-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31588, current rewards: -1063.67384, mean: -0.95826
[32m[0906 15-47-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31590, current rewards: -1163.67384, mean: -1.00317
[32m[0906 15-47-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31600, current rewards: -1263.67384, mean: -1.04436
[32m[0906 15-48-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31598, current rewards: -1363.67384, mean: -1.08228
[32m[0906 15-48-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31596, current rewards: -1463.67384, mean: -1.11731
[32m[0906 15-48-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31600, current rewards: -1563.67384, mean: -1.14976
[32m[0906 15-48-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31603, current rewards: -1663.67384, mean: -1.17991
[32m[0906 15-49-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31605, current rewards: -1731.27011, mean: -1.18580
[32m[0906 15-49-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31601, current rewards: -1756.59081, mean: -1.16331
[32m[0906 15-49-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31599, current rewards: -1845.81555, mean: -1.18322
[32m[0906 15-49-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31596, current rewards: -1945.81555, mean: -1.20858
[32m[0906 15-50-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31600, current rewards: -2045.81555, mean: -1.23242
[32m[0906 15-50-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31607, current rewards: -2145.81555, mean: -1.25486
[32m[0906 15-50-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31609, current rewards: -2245.81555, mean: -1.27603
[32m[0906 15-50-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31607, current rewards: -2345.81555, mean: -1.29603
[32m[0906 15-51-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31606, current rewards: -2445.81555, mean: -1.31495
[32m[0906 15-51-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31609, current rewards: -2545.81555, mean: -1.33289
[32m[0906 15-51-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31606, current rewards: -2645.81555, mean: -1.34991
[32m[0906 15-52-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31607, current rewards: -2745.81555, mean: -1.36608
[32m[0906 15-52-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31607, current rewards: -2797.82995, mean: -1.35817
[32m[0906 15-52-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31606, current rewards: -2775.52119, mean: -1.31541
[32m[0906 15-52-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31607, current rewards: -2755.29293, mean: -1.27560
[32m[0906 15-53-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31590, current rewards: -2737.57932, mean: -1.23872
[32m[0906 15-53-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31588, current rewards: -2760.73440, mean: -1.22156
[32m[0906 15-53-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31588, current rewards: -2860.73440, mean: -1.23841
[32m[0906 15-53-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31586, current rewards: -2960.73440, mean: -1.25455
[32m[0906 15-54-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31564, current rewards: -3060.73440, mean: -1.27001
[32m[0906 15-54-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31551, current rewards: -3160.73440, mean: -1.28485
[32m[0906 15-54-34 @Agent.py:117][0m Average action selection time: 0.3155
[32m[0906 15-54-34 @Agent.py:118][0m Rollout length: 2520
[32m[0906 15-54-34 @MBExp.py:227][0m Rewards obtained: [-3240.734403830234], Lows: [1692], Highs: [41], Total time: 7943.649171000001
[32m[0906 15-54-53 @MBExp.py:144][0m ####################################################################
[32m[0906 15-54-53 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 15-54-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31727, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-55-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31733, current rewards: -10.77772, mean: -0.17963
[32m[0906 15-55-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31672, current rewards: 7.95243, mean: 0.07229
[32m[0906 15-55-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31698, current rewards: 26.63905, mean: 0.16649
[32m[0906 15-56-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31531, current rewards: 45.10383, mean: 0.21478
[32m[0906 15-56-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31554, current rewards: 55.95649, mean: 0.21522
[32m[0906 15-56-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31572, current rewards: 70.36870, mean: 0.22700
[32m[0906 15-56-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31590, current rewards: 84.79329, mean: 0.23554
[32m[0906 15-57-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31604, current rewards: 99.23244, mean: 0.24203
[32m[0906 15-57-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31604, current rewards: 113.68485, mean: 0.24714
[32m[0906 15-57-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31608, current rewards: 128.12678, mean: 0.25123
[32m[0906 15-57-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31608, current rewards: 94.88863, mean: 0.16944
[32m[0906 15-58-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31601, current rewards: 112.43291, mean: 0.18432
[32m[0906 15-58-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31608, current rewards: 59.75910, mean: 0.09054
[32m[0906 15-58-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31607, current rewards: 77.98775, mean: 0.10984
[32m[0906 15-58-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31600, current rewards: 102.15909, mean: 0.13442
[32m[0906 15-59-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31594, current rewards: 126.28857, mean: 0.15591
[32m[0906 15-59-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31585, current rewards: 150.41547, mean: 0.17490
[32m[0906 15-59-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31578, current rewards: 174.55181, mean: 0.19182
[32m[0906 15-59-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31572, current rewards: 198.73478, mean: 0.20702
[32m[0906 16-00-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31567, current rewards: 222.93891, mean: 0.22073
[32m[0906 16-00-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31563, current rewards: 205.47919, mean: 0.19385
[32m[0906 16-00-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31557, current rewards: 170.26013, mean: 0.15339
[32m[0906 16-01-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31555, current rewards: 120.26013, mean: 0.10367
[32m[0906 16-01-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31552, current rewards: 70.26013, mean: 0.05807
[32m[0906 16-01-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31549, current rewards: 20.26013, mean: 0.01608
[32m[0906 16-01-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31542, current rewards: -29.73987, mean: -0.02270
[32m[0906 16-02-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31538, current rewards: -79.73987, mean: -0.05863
[32m[0906 16-02-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31544, current rewards: -129.73987, mean: -0.09201
[32m[0906 16-02-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31539, current rewards: -179.73987, mean: -0.12311
[32m[0906 16-02-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31538, current rewards: -229.73987, mean: -0.15215
[32m[0906 16-03-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31535, current rewards: -279.73987, mean: -0.17932
[32m[0906 16-03-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31533, current rewards: -329.73987, mean: -0.20481
[32m[0906 16-03-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31532, current rewards: -379.73987, mean: -0.22876
[32m[0906 16-03-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31527, current rewards: -429.73987, mean: -0.25131
[32m[0906 16-04-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31523, current rewards: -479.73987, mean: -0.27258
[32m[0906 16-04-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31521, current rewards: -529.73987, mean: -0.29267
[32m[0906 16-04-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31516, current rewards: -579.73987, mean: -0.31169
[32m[0906 16-04-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31513, current rewards: -629.73987, mean: -0.32971
[32m[0906 16-05-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31509, current rewards: -679.73987, mean: -0.34681
[32m[0906 16-05-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31513, current rewards: -729.73987, mean: -0.36305
[32m[0906 16-05-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31511, current rewards: -779.73987, mean: -0.37851
[32m[0906 16-05-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31511, current rewards: -829.73987, mean: -0.39324
[32m[0906 16-06-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31510, current rewards: -879.73987, mean: -0.40729
[32m[0906 16-06-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31497, current rewards: -878.62382, mean: -0.39757
[32m[0906 16-06-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31492, current rewards: -875.37793, mean: -0.38734
[32m[0906 16-07-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31493, current rewards: -908.41930, mean: -0.39326
[32m[0906 16-07-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31492, current rewards: -958.41930, mean: -0.40611
[32m[0906 16-07-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31470, current rewards: -1008.41930, mean: -0.41843
[32m[0906 16-07-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31455, current rewards: -1058.41930, mean: -0.43025
[32m[0906 16-08-01 @Agent.py:117][0m Average action selection time: 0.3146
[32m[0906 16-08-01 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-08-01 @MBExp.py:227][0m Rewards obtained: [-1098.4193018362128], Lows: [71], Highs: [1328], Total time: 8730.749397000001
[32m[0906 16-08-22 @MBExp.py:144][0m ####################################################################
[32m[0906 16-08-22 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 16-08-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31949, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-08-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31943, current rewards: -15.64414, mean: -0.26074
[32m[0906 16-08-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31812, current rewards: -7.98948, mean: -0.07263
[32m[0906 16-09-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31726, current rewards: -0.51469, mean: -0.00322
[32m[0906 16-09-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31552, current rewards: 6.74889, mean: 0.03214
[32m[0906 16-09-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31569, current rewards: 14.12294, mean: 0.05432
[32m[0906 16-09-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31579, current rewards: 21.51643, mean: 0.06941
[32m[0906 16-10-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31579, current rewards: 28.90799, mean: 0.08030
[32m[0906 16-10-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31589, current rewards: 36.28448, mean: 0.08850
[32m[0906 16-10-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31597, current rewards: 43.67460, mean: 0.09494
[32m[0906 16-11-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31601, current rewards: 51.06255, mean: 0.10012
[32m[0906 16-11-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31603, current rewards: 34.82576, mean: 0.06219
[32m[0906 16-11-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31615, current rewards: 21.05828, mean: 0.03452
[32m[0906 16-11-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31619, current rewards: 25.67154, mean: 0.03890
[32m[0906 16-12-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31620, current rewards: 30.43414, mean: 0.04286
[32m[0906 16-12-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31615, current rewards: 35.19929, mean: 0.04631
[32m[0906 16-12-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31611, current rewards: 39.96594, mean: 0.04934
[32m[0906 16-12-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31610, current rewards: 44.73059, mean: 0.05201
[32m[0906 16-13-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31603, current rewards: 49.49643, mean: 0.05439
[32m[0906 16-13-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31601, current rewards: 54.26537, mean: 0.05653
[32m[0906 16-13-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31590, current rewards: 59.33291, mean: 0.05875
[32m[0906 16-13-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31584, current rewards: 48.94670, mean: 0.04618
[32m[0906 16-14-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31581, current rewards: 54.80082, mean: 0.04937
[32m[0906 16-14-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31575, current rewards: 61.77505, mean: 0.05325
[32m[0906 16-14-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31574, current rewards: 44.74506, mean: 0.03698
[32m[0906 16-15-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31569, current rewards: 50.12382, mean: 0.03978
[32m[0906 16-15-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31563, current rewards: 56.02187, mean: 0.04276
[32m[0906 16-15-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31562, current rewards: 61.91555, mean: 0.04553
[32m[0906 16-15-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31562, current rewards: 67.80466, mean: 0.04809
[32m[0906 16-16-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31561, current rewards: 72.75611, mean: 0.04983
[32m[0906 16-16-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31559, current rewards: 78.38160, mean: 0.05191
[32m[0906 16-16-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31556, current rewards: 83.89117, mean: 0.05378
[32m[0906 16-16-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31553, current rewards: 89.39437, mean: 0.05552
[32m[0906 16-17-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31548, current rewards: 94.89895, mean: 0.05717
[32m[0906 16-17-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31547, current rewards: 100.40037, mean: 0.05871
[32m[0906 16-17-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31546, current rewards: 105.89917, mean: 0.06017
[32m[0906 16-17-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31544, current rewards: 111.40734, mean: 0.06155
[32m[0906 16-18-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31541, current rewards: 77.09857, mean: 0.04145
[32m[0906 16-18-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31543, current rewards: 83.83286, mean: 0.04389
[32m[0906 16-18-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31542, current rewards: 89.57714, mean: 0.04570
[32m[0906 16-18-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31539, current rewards: 95.32519, mean: 0.04743
[32m[0906 16-19-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31538, current rewards: 101.06585, mean: 0.04906
[32m[0906 16-19-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31538, current rewards: 64.67327, mean: 0.03065
[32m[0906 16-19-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31536, current rewards: 69.85314, mean: 0.03234
[32m[0906 16-19-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31521, current rewards: 74.75758, mean: 0.03383
[32m[0906 16-20-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31512, current rewards: 79.76895, mean: 0.03530
[32m[0906 16-20-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31514, current rewards: 84.57854, mean: 0.03661
[32m[0906 16-20-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31512, current rewards: 89.18581, mean: 0.03779
[32m[0906 16-21-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31491, current rewards: 93.78792, mean: 0.03892
[32m[0906 16-21-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31469, current rewards: 98.38992, mean: 0.04000
[32m[0906 16-21-29 @Agent.py:117][0m Average action selection time: 0.3147
[32m[0906 16-21-29 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-21-29 @MBExp.py:227][0m Rewards obtained: [102.0748204735896], Lows: [75], Highs: [42], Total time: 9518.209346000001
[32m[0906 16-21-52 @MBExp.py:144][0m ####################################################################
[32m[0906 16-21-52 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 16-21-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31685, current rewards: 0.67055, mean: 0.06705
[32m[0906 16-22-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31555, current rewards: 2.73625, mean: 0.04560
[32m[0906 16-22-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31540, current rewards: 9.05167, mean: 0.08229
[32m[0906 16-22-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31531, current rewards: 15.36710, mean: 0.09604
[32m[0906 16-22-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31369, current rewards: 20.63303, mean: 0.09825
[32m[0906 16-23-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31387, current rewards: 25.59024, mean: 0.09842
[32m[0906 16-23-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31405, current rewards: 30.54745, mean: 0.09854
[32m[0906 16-23-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31451, current rewards: 11.32349, mean: 0.03145
[32m[0906 16-24-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31467, current rewards: -38.67651, mean: -0.09433
[32m[0906 16-24-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31476, current rewards: -88.67651, mean: -0.19278
[32m[0906 16-24-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31477, current rewards: -138.67651, mean: -0.27191
[32m[0906 16-24-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31494, current rewards: -188.67651, mean: -0.33692
[32m[0906 16-25-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31496, current rewards: -238.67651, mean: -0.39127
[32m[0906 16-25-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31496, current rewards: -288.67651, mean: -0.43739
[32m[0906 16-25-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31499, current rewards: -338.67651, mean: -0.47701
[32m[0906 16-25-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31507, current rewards: -388.67651, mean: -0.51142
[32m[0906 16-26-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31508, current rewards: -438.67651, mean: -0.54158
[32m[0906 16-26-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31507, current rewards: -488.67651, mean: -0.56823
[32m[0906 16-26-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31511, current rewards: -538.67651, mean: -0.59195
[32m[0906 16-26-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31513, current rewards: -588.67651, mean: -0.61320
[32m[0906 16-27-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31513, current rewards: -638.67651, mean: -0.63235
[32m[0906 16-27-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31511, current rewards: -688.67651, mean: -0.64969
[32m[0906 16-27-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31508, current rewards: -738.67651, mean: -0.66547
[32m[0906 16-27-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31505, current rewards: -788.67651, mean: -0.67989
[32m[0906 16-28-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31505, current rewards: -838.67651, mean: -0.69312
[32m[0906 16-28-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31506, current rewards: -888.67651, mean: -0.70530
[32m[0906 16-28-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31502, current rewards: -938.67651, mean: -0.71655
[32m[0906 16-29-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31501, current rewards: -988.67651, mean: -0.72697
[32m[0906 16-29-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31503, current rewards: -1038.67651, mean: -0.73665
[32m[0906 16-29-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31499, current rewards: -1088.67651, mean: -0.74567
[32m[0906 16-29-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31495, current rewards: -1138.67651, mean: -0.75409
[32m[0906 16-30-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31493, current rewards: -1188.67651, mean: -0.76197
[32m[0906 16-30-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31488, current rewards: -1238.67651, mean: -0.76936
[32m[0906 16-30-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31482, current rewards: -1288.67651, mean: -0.77631
[32m[0906 16-30-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31478, current rewards: -1338.67651, mean: -0.78285
[32m[0906 16-31-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31475, current rewards: -1388.67651, mean: -0.78902
[32m[0906 16-31-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31472, current rewards: -1438.67651, mean: -0.79485
[32m[0906 16-31-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31472, current rewards: -1488.67651, mean: -0.80036
[32m[0906 16-31-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31475, current rewards: -1538.67651, mean: -0.80559
[32m[0906 16-32-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31474, current rewards: -1588.67651, mean: -0.81055
[32m[0906 16-32-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31474, current rewards: -1638.67651, mean: -0.81526
[32m[0906 16-32-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31471, current rewards: -1688.67651, mean: -0.81975
[32m[0906 16-32-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31470, current rewards: -1738.67651, mean: -0.82402
[32m[0906 16-33-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31468, current rewards: -1788.67651, mean: -0.82809
[32m[0906 16-33-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31456, current rewards: -1838.67651, mean: -0.83198
[32m[0906 16-33-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31446, current rewards: -1888.67651, mean: -0.83570
[32m[0906 16-33-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31448, current rewards: -1938.67651, mean: -0.83925
[32m[0906 16-34-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31448, current rewards: -1988.67651, mean: -0.84266
[32m[0906 16-34-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31430, current rewards: -2038.67651, mean: -0.84592
[32m[0906 16-34-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31409, current rewards: -2088.67651, mean: -0.84906
[32m[0906 16-34-58 @Agent.py:117][0m Average action selection time: 0.3141
[32m[0906 16-34-58 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-34-58 @MBExp.py:227][0m Rewards obtained: [-2128.6765134986927], Lows: [3], Highs: [2162], Total time: 10304.122503000002
[32m[0906 16-35-22 @MBExp.py:144][0m ####################################################################
[32m[0906 16-35-22 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 16-35-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31849, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-35-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31672, current rewards: -30.43915, mean: -0.50732
[32m[0906 16-35-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31640, current rewards: -27.95047, mean: -0.25410
[32m[0906 16-36-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31634, current rewards: -48.40661, mean: -0.30254
[32m[0906 16-36-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31482, current rewards: -54.21052, mean: -0.25815
[32m[0906 16-36-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31454, current rewards: -60.06182, mean: -0.23101
[32m[0906 16-37-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31498, current rewards: -64.89870, mean: -0.20935
[32m[0906 16-37-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31517, current rewards: -62.41728, mean: -0.17338
[32m[0906 16-37-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31554, current rewards: -59.96410, mean: -0.14625
[32m[0906 16-37-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31560, current rewards: -57.51082, mean: -0.12502
[32m[0906 16-38-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31569, current rewards: -54.32774, mean: -0.10652
[32m[0906 16-38-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31572, current rewards: -50.54693, mean: -0.09026
[32m[0906 16-38-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31572, current rewards: -46.90940, mean: -0.07690
[32m[0906 16-38-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31569, current rewards: -43.27781, mean: -0.06557
[32m[0906 16-39-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31565, current rewards: -39.64546, mean: -0.05584
[32m[0906 16-39-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31561, current rewards: -36.00942, mean: -0.04738
[32m[0906 16-39-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31558, current rewards: -32.37466, mean: -0.03997
[32m[0906 16-39-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31561, current rewards: -28.74108, mean: -0.03342
[32m[0906 16-40-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31560, current rewards: -25.10765, mean: -0.02759
[32m[0906 16-40-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31558, current rewards: -75.29528, mean: -0.07843
[32m[0906 16-40-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31556, current rewards: -93.17889, mean: -0.09226
[32m[0906 16-40-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31566, current rewards: -89.56972, mean: -0.08450
[32m[0906 16-41-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31566, current rewards: -86.26812, mean: -0.07772
[32m[0906 16-41-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31567, current rewards: -82.96889, mean: -0.07152
[32m[0906 16-41-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31565, current rewards: -100.53136, mean: -0.08308
[32m[0906 16-42-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31563, current rewards: -200.53136, mean: -0.15915
[32m[0906 16-42-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31564, current rewards: -300.53136, mean: -0.22941
[32m[0906 16-42-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31561, current rewards: -400.53136, mean: -0.29451
[32m[0906 16-42-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31558, current rewards: -500.53136, mean: -0.35499
[32m[0906 16-43-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31558, current rewards: -586.02273, mean: -0.40139
[32m[0906 16-43-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31553, current rewards: -584.30761, mean: -0.38696
[32m[0906 16-43-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31547, current rewards: -581.17908, mean: -0.37255
[32m[0906 16-43-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31539, current rewards: -578.10121, mean: -0.35907
[32m[0906 16-44-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31535, current rewards: -575.02784, mean: -0.34640
[32m[0906 16-44-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31531, current rewards: -594.35745, mean: -0.34758
[32m[0906 16-44-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31528, current rewards: -694.35745, mean: -0.39452
[32m[0906 16-44-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31527, current rewards: -794.35745, mean: -0.43887
[32m[0906 16-45-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31525, current rewards: -894.35745, mean: -0.48084
[32m[0906 16-45-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31529, current rewards: -994.35745, mean: -0.52061
[32m[0906 16-45-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31526, current rewards: -1094.35745, mean: -0.55835
[32m[0906 16-45-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31523, current rewards: -1194.35745, mean: -0.59421
[32m[0906 16-46-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31520, current rewards: -1294.35745, mean: -0.62833
[32m[0906 16-46-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31520, current rewards: -1394.35745, mean: -0.66083
[32m[0906 16-46-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31517, current rewards: -1494.35745, mean: -0.69183
[32m[0906 16-46-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31506, current rewards: -1594.35745, mean: -0.72143
[32m[0906 16-47-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31491, current rewards: -1694.35745, mean: -0.74972
[32m[0906 16-47-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31494, current rewards: -1794.35745, mean: -0.77678
[32m[0906 16-47-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31495, current rewards: -1894.35745, mean: -0.80269
[32m[0906 16-48-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31476, current rewards: -1994.35745, mean: -0.82753
[32m[0906 16-48-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31450, current rewards: -2065.97987, mean: -0.83983
[32m[0906 16-48-29 @Agent.py:117][0m Average action selection time: 0.3145
[32m[0906 16-48-29 @Agent.py:118][0m Rollout length: 2520
[32m[0906 16-48-29 @MBExp.py:227][0m Rewards obtained: [-2062.2219954967486], Lows: [1051], Highs: [77], Total time: 11090.996171000003
[32m[0906 16-48-56 @MBExp.py:144][0m ####################################################################
[32m[0906 16-48-56 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 16-48-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31932, current rewards: -4.73768, mean: -0.47377
[32m[0906 16-49-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31737, current rewards: -10.87066, mean: -0.18118
[32m[0906 16-49-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31691, current rewards: -3.07430, mean: -0.02795
[32m[0906 16-49-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31636, current rewards: 4.72446, mean: 0.02953
[32m[0906 16-50-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31476, current rewards: 12.53118, mean: 0.05967
[32m[0906 16-50-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31430, current rewards: 20.32932, mean: 0.07819
[32m[0906 16-50-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31475, current rewards: 28.12619, mean: 0.09073
[32m[0906 16-50-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31507, current rewards: 35.91963, mean: 0.09978
[32m[0906 16-51-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31527, current rewards: 43.70945, mean: 0.10661
[32m[0906 16-51-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31536, current rewards: 51.50242, mean: 0.11196
[32m[0906 16-51-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31545, current rewards: 50.34525, mean: 0.09872
[32m[0906 16-51-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31554, current rewards: 42.96912, mean: 0.07673
[32m[0906 16-52-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31559, current rewards: 48.44036, mean: 0.07941
[32m[0906 16-52-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31565, current rewards: 53.90281, mean: 0.08167
[32m[0906 16-52-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31562, current rewards: 59.36273, mean: 0.08361
[32m[0906 16-52-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31554, current rewards: 64.82691, mean: 0.08530
[32m[0906 16-53-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31555, current rewards: 70.28966, mean: 0.08678
[32m[0906 16-53-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31549, current rewards: 75.75183, mean: 0.08808
[32m[0906 16-53-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31547, current rewards: 82.67579, mean: 0.09085
[32m[0906 16-53-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31549, current rewards: 92.07918, mean: 0.09592
[32m[0906 16-54-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31548, current rewards: 99.58706, mean: 0.09860
[32m[0906 16-54-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31547, current rewards: 63.14899, mean: 0.05957
[32m[0906 16-54-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31542, current rewards: 68.86067, mean: 0.06204
[32m[0906 16-55-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31541, current rewards: 74.70241, mean: 0.06440
[32m[0906 16-55-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31536, current rewards: 80.55723, mean: 0.06658
[32m[0906 16-55-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31532, current rewards: 86.41514, mean: 0.06858
[32m[0906 16-55-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31529, current rewards: 92.26891, mean: 0.07043
[32m[0906 16-56-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31522, current rewards: 73.89393, mean: 0.05433
[32m[0906 16-56-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31520, current rewards: 76.89827, mean: 0.05454
[32m[0906 16-56-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31518, current rewards: 82.05088, mean: 0.05620
[32m[0906 16-56-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31513, current rewards: 85.01865, mean: 0.05630
[32m[0906 16-57-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31509, current rewards: 90.05757, mean: 0.05773
[32m[0906 16-57-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31507, current rewards: 95.29496, mean: 0.05919
[32m[0906 16-57-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31503, current rewards: 98.13334, mean: 0.05912
[32m[0906 16-57-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31499, current rewards: 103.23663, mean: 0.06037
[32m[0906 16-58-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31495, current rewards: 105.97537, mean: 0.06021
[32m[0906 16-58-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31491, current rewards: 110.76902, mean: 0.06120
[32m[0906 16-58-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31488, current rewards: 85.17264, mean: 0.04579
[32m[0906 16-58-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31487, current rewards: 84.01072, mean: 0.04398
[32m[0906 16-59-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31484, current rewards: 90.84960, mean: 0.04635
[32m[0906 16-59-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31484, current rewards: 97.68258, mean: 0.04860
[32m[0906 16-59-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31479, current rewards: 104.51321, mean: 0.05073
[32m[0906 17-00-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31475, current rewards: 111.34228, mean: 0.05277
[32m[0906 17-00-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31473, current rewards: 117.11484, mean: 0.05422
[32m[0906 17-00-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31459, current rewards: 106.53845, mean: 0.04821
[32m[0906 17-00-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31444, current rewards: 87.76915, mean: 0.03884
[32m[0906 17-01-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31445, current rewards: 93.04258, mean: 0.04028
[32m[0906 17-01-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31448, current rewards: 98.38046, mean: 0.04169
[32m[0906 17-01-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31423, current rewards: 103.72989, mean: 0.04304
[32m[0906 17-01-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31394, current rewards: 108.87506, mean: 0.04426
[32m[0906 17-02-01 @Agent.py:117][0m Average action selection time: 0.3139
[32m[0906 17-02-01 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-02-01 @MBExp.py:227][0m Rewards obtained: [71.13833371150842], Lows: [107], Highs: [56], Total time: 11876.456645000002
[32m[0906 17-02-30 @MBExp.py:144][0m ####################################################################
[32m[0906 17-02-30 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 17-02-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31941, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-02-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31718, current rewards: -16.70276, mean: -0.27838
[32m[0906 17-03-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31674, current rewards: -15.69648, mean: -0.14270
[32m[0906 17-03-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31627, current rewards: -13.29841, mean: -0.08312
[32m[0906 17-03-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31439, current rewards: -11.81468, mean: -0.05626
[32m[0906 17-03-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31370, current rewards: -26.05856, mean: -0.10023
[32m[0906 17-04-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31407, current rewards: -45.89923, mean: -0.14806
[32m[0906 17-04-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31441, current rewards: -41.40837, mean: -0.11502
[32m[0906 17-04-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31463, current rewards: -36.82033, mean: -0.08981
[32m[0906 17-04-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31471, current rewards: -32.56526, mean: -0.07079
[32m[0906 17-05-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31480, current rewards: -52.31340, mean: -0.10258
[32m[0906 17-05-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31485, current rewards: -46.92593, mean: -0.08380
[32m[0906 17-05-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31492, current rewards: -41.65926, mean: -0.06829
[32m[0906 17-05-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31499, current rewards: -36.39218, mean: -0.05514
[32m[0906 17-06-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31500, current rewards: -31.13536, mean: -0.04385
[32m[0906 17-06-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31499, current rewards: -25.86928, mean: -0.03404
[32m[0906 17-06-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31499, current rewards: -20.60723, mean: -0.02544
[32m[0906 17-07-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31499, current rewards: -14.90628, mean: -0.01733
[32m[0906 17-07-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31502, current rewards: -49.42782, mean: -0.05432
[32m[0906 17-07-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31498, current rewards: -44.90929, mean: -0.04678
[32m[0906 17-07-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31497, current rewards: -40.38033, mean: -0.03998
[32m[0906 17-08-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31496, current rewards: -35.85299, mean: -0.03382
[32m[0906 17-08-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31498, current rewards: -31.32591, mean: -0.02822
[32m[0906 17-08-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31495, current rewards: -26.79696, mean: -0.02310
[32m[0906 17-08-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31491, current rewards: -6.80131, mean: -0.00562
[32m[0906 17-09-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31484, current rewards: -3.50669, mean: -0.00278
[32m[0906 17-09-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31486, current rewards: 0.97469, mean: 0.00074
[32m[0906 17-09-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31482, current rewards: 5.45503, mean: 0.00401
[32m[0906 17-09-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31480, current rewards: 9.93396, mean: 0.00705
[32m[0906 17-10-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31479, current rewards: 14.41492, mean: 0.00987
[32m[0906 17-10-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31476, current rewards: 18.89562, mean: 0.01251
[32m[0906 17-10-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31474, current rewards: -20.58970, mean: -0.01320
[32m[0906 17-10-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31470, current rewards: -15.56237, mean: -0.00967
[32m[0906 17-11-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31466, current rewards: -11.51474, mean: -0.00694
[32m[0906 17-11-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31463, current rewards: -7.74599, mean: -0.00453
[32m[0906 17-11-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31463, current rewards: -3.52787, mean: -0.00200
[32m[0906 17-12-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31462, current rewards: 0.69124, mean: 0.00038
[32m[0906 17-12-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31460, current rewards: 4.91126, mean: 0.00264
[32m[0906 17-12-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31456, current rewards: 9.12909, mean: 0.00478
[32m[0906 17-12-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31453, current rewards: -9.79889, mean: -0.00500
[32m[0906 17-13-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31451, current rewards: -7.87710, mean: -0.00392
[32m[0906 17-13-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31451, current rewards: -6.60628, mean: -0.00321
[32m[0906 17-13-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31450, current rewards: -14.85181, mean: -0.00704
[32m[0906 17-13-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31450, current rewards: -10.78560, mean: -0.00499
[32m[0906 17-14-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31440, current rewards: -7.49632, mean: -0.00339
[32m[0906 17-14-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31425, current rewards: -4.19826, mean: -0.00186
[32m[0906 17-14-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31422, current rewards: -0.89757, mean: -0.00039
[32m[0906 17-14-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31424, current rewards: 2.39970, mean: 0.00102
[32m[0906 17-15-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31399, current rewards: 5.69613, mean: 0.00236
[32m[0906 17-15-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31369, current rewards: -32.82781, mean: -0.01334
[32m[0906 17-15-35 @Agent.py:117][0m Average action selection time: 0.3137
[32m[0906 17-15-35 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-15-35 @MBExp.py:227][0m Rewards obtained: [-28.25326872571803], Lows: [84], Highs: [92], Total time: 12661.283387000001
[32m[0906 17-16-05 @MBExp.py:144][0m ####################################################################
[32m[0906 17-16-05 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 17-16-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32034, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-16-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31730, current rewards: -17.72008, mean: -0.29533
[32m[0906 17-16-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31667, current rewards: -9.80843, mean: -0.08917
[32m[0906 17-16-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31621, current rewards: -1.95453, mean: -0.01222
[32m[0906 17-17-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31444, current rewards: 5.91712, mean: 0.02818
[32m[0906 17-17-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31375, current rewards: 13.78145, mean: 0.05301
[32m[0906 17-17-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31451, current rewards: 21.65608, mean: 0.06986
[32m[0906 17-17-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31473, current rewards: 29.51981, mean: 0.08200
[32m[0906 17-18-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31492, current rewards: 37.39312, mean: 0.09120
[32m[0906 17-18-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31501, current rewards: 48.98697, mean: 0.10649
[32m[0906 17-18-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31522, current rewards: 57.36825, mean: 0.11249
[32m[0906 17-19-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31529, current rewards: 65.96393, mean: 0.11779
[32m[0906 17-19-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31539, current rewards: 74.54274, mean: 0.12220
[32m[0906 17-19-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31543, current rewards: 83.13252, mean: 0.12596
[32m[0906 17-19-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31544, current rewards: 48.67751, mean: 0.06856
[32m[0906 17-20-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31542, current rewards: 10.42903, mean: 0.01372
[32m[0906 17-20-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31543, current rewards: -27.70158, mean: -0.03420
[32m[0906 17-20-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31545, current rewards: -83.34287, mean: -0.09691
[32m[0906 17-20-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31543, current rewards: -137.56267, mean: -0.15117
[32m[0906 17-21-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31538, current rewards: -185.72459, mean: -0.19346
[32m[0906 17-21-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31537, current rewards: -223.41311, mean: -0.22120
[32m[0906 17-21-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31531, current rewards: -261.25999, mean: -0.24647
[32m[0906 17-21-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31528, current rewards: -311.77856, mean: -0.28088
[32m[0906 17-22-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31527, current rewards: -366.61481, mean: -0.31605
[32m[0906 17-22-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31525, current rewards: -419.27845, mean: -0.34651
[32m[0906 17-22-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31524, current rewards: -456.74590, mean: -0.36250
[32m[0906 17-22-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31518, current rewards: -531.09391, mean: -0.40542
[32m[0906 17-23-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31515, current rewards: -631.09391, mean: -0.46404
[32m[0906 17-23-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31515, current rewards: -731.09391, mean: -0.51851
[32m[0906 17-23-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31514, current rewards: -831.09391, mean: -0.56924
[32m[0906 17-24-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31514, current rewards: -931.09391, mean: -0.61662
[32m[0906 17-24-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31513, current rewards: -1031.09391, mean: -0.66096
[32m[0906 17-24-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31515, current rewards: -1131.09391, mean: -0.70254
[32m[0906 17-24-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31514, current rewards: -1231.09391, mean: -0.74162
[32m[0906 17-25-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31514, current rewards: -1331.09391, mean: -0.77842
[32m[0906 17-25-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31511, current rewards: -1431.09391, mean: -0.81312
[32m[0906 17-25-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31509, current rewards: -1531.09391, mean: -0.84591
[32m[0906 17-25-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31506, current rewards: -1631.09391, mean: -0.87693
[32m[0906 17-26-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31505, current rewards: -1731.09391, mean: -0.90633
[32m[0906 17-26-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31500, current rewards: -1730.09794, mean: -0.88270
[32m[0906 17-26-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31498, current rewards: -1719.06254, mean: -0.85525
[32m[0906 17-26-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31497, current rewards: -1702.32211, mean: -0.82637
[32m[0906 17-27-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31497, current rewards: -1681.45622, mean: -0.79690
[32m[0906 17-27-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31495, current rewards: -1663.59835, mean: -0.77018
[32m[0906 17-27-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31484, current rewards: -1652.20242, mean: -0.74760
[32m[0906 17-27-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31468, current rewards: -1685.41491, mean: -0.74576
[32m[0906 17-28-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31464, current rewards: -1732.64111, mean: -0.75006
[32m[0906 17-28-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31467, current rewards: -1775.53238, mean: -0.75234
[32m[0906 17-28-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31441, current rewards: -1796.11808, mean: -0.74528
[32m[0906 17-28-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31411, current rewards: -1826.18326, mean: -0.74235
[32m[0906 17-29-11 @Agent.py:117][0m Average action selection time: 0.3141
[32m[0906 17-29-11 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-29-11 @MBExp.py:227][0m Rewards obtained: [-1854.4964996963251], Lows: [1056], Highs: [20], Total time: 13447.09653
[32m[0906 17-29-43 @MBExp.py:144][0m ####################################################################
[32m[0906 17-29-43 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 17-29-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31836, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-30-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31636, current rewards: -26.49896, mean: -0.44165
[32m[0906 17-30-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31600, current rewards: -19.56718, mean: -0.17788
[32m[0906 17-30-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31520, current rewards: -12.58736, mean: -0.07867
[32m[0906 17-30-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31381, current rewards: -5.61758, mean: -0.02675
[32m[0906 17-31-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31295, current rewards: 1.35357, mean: 0.00521
[32m[0906 17-31-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31371, current rewards: 8.33553, mean: 0.02689
[32m[0906 17-31-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31392, current rewards: 15.30719, mean: 0.04252
[32m[0906 17-31-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31417, current rewards: 23.91309, mean: 0.05832
[32m[0906 17-32-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31438, current rewards: 19.54277, mean: 0.04248
[32m[0906 17-32-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31449, current rewards: 13.21256, mean: 0.02591
[32m[0906 17-32-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31459, current rewards: 17.99907, mean: 0.03214
[32m[0906 17-32-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31462, current rewards: 22.78690, mean: 0.03736
[32m[0906 17-33-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31470, current rewards: 27.57578, mean: 0.04178
[32m[0906 17-33-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31475, current rewards: 32.36476, mean: 0.04558
[32m[0906 17-33-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31481, current rewards: 37.15233, mean: 0.04888
[32m[0906 17-33-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31478, current rewards: 41.36197, mean: 0.05106
[32m[0906 17-34-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31479, current rewards: 46.15971, mean: 0.05367
[32m[0906 17-34-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31478, current rewards: 50.82261, mean: 0.05585
[32m[0906 17-34-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31479, current rewards: 55.49186, mean: 0.05780
[32m[0906 17-35-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31485, current rewards: 60.15505, mean: 0.05956
[32m[0906 17-35-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31487, current rewards: 64.81657, mean: 0.06115
[32m[0906 17-35-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31485, current rewards: 74.81727, mean: 0.06740
[32m[0906 17-35-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31485, current rewards: 80.95917, mean: 0.06979
[32m[0906 17-36-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31484, current rewards: 87.41227, mean: 0.07224
[32m[0906 17-36-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31484, current rewards: 93.84210, mean: 0.07448
[32m[0906 17-36-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31482, current rewards: 100.26605, mean: 0.07654
[32m[0906 17-36-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31483, current rewards: 106.69396, mean: 0.07845
[32m[0906 17-37-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31485, current rewards: 113.11903, mean: 0.08023
[32m[0906 17-37-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31488, current rewards: 119.55419, mean: 0.08189
[32m[0906 17-37-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31489, current rewards: 125.98342, mean: 0.08343
[32m[0906 17-37-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31486, current rewards: 132.40733, mean: 0.08488
[32m[0906 17-38-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31485, current rewards: 128.93537, mean: 0.08008
[32m[0906 17-38-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31485, current rewards: 110.17852, mean: 0.06637
[32m[0906 17-38-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31483, current rewards: 120.49607, mean: 0.07047
[32m[0906 17-38-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31483, current rewards: 130.89367, mean: 0.07437
[32m[0906 17-39-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31482, current rewards: 95.53762, mean: 0.05278
[32m[0906 17-39-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31482, current rewards: 105.27231, mean: 0.05660
[32m[0906 17-39-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31482, current rewards: 111.49644, mean: 0.05838
[32m[0906 17-40-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31480, current rewards: 117.70346, mean: 0.06005
[32m[0906 17-40-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31480, current rewards: 123.91132, mean: 0.06165
[32m[0906 17-40-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31478, current rewards: 129.84905, mean: 0.06303
[32m[0906 17-40-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31477, current rewards: 56.85450, mean: 0.02695
[32m[0906 17-41-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31475, current rewards: -24.42887, mean: -0.01131
[32m[0906 17-41-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31463, current rewards: -106.25552, mean: -0.04808
[32m[0906 17-41-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31449, current rewards: -180.05762, mean: -0.07967
[32m[0906 17-41-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31444, current rewards: -186.68983, mean: -0.08082
[32m[0906 17-42-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31446, current rewards: -180.33751, mean: -0.07641
[32m[0906 17-42-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31419, current rewards: -173.99798, mean: -0.07220
[32m[0906 17-42-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31389, current rewards: -180.60641, mean: -0.07342
[32m[0906 17-42-48 @Agent.py:117][0m Average action selection time: 0.3138
[32m[0906 17-42-48 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-42-48 @MBExp.py:227][0m Rewards obtained: [-198.3905181525277], Lows: [221], Highs: [61], Total time: 14232.250255
[32m[0906 17-43-23 @MBExp.py:144][0m ####################################################################
[32m[0906 17-43-23 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 17-43-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31861, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-43-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31678, current rewards: -18.10365, mean: -0.30173
[32m[0906 17-43-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31669, current rewards: -13.53926, mean: -0.12308
[32m[0906 17-44-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31607, current rewards: -8.96669, mean: -0.05604
[32m[0906 17-44-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31426, current rewards: -4.39545, mean: -0.02093
[32m[0906 17-44-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31314, current rewards: 0.18112, mean: 0.00070
[32m[0906 17-45-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31360, current rewards: 4.75762, mean: 0.01535
[32m[0906 17-45-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31385, current rewards: 9.33271, mean: 0.02592
[32m[0906 17-45-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31416, current rewards: 17.94339, mean: 0.04376
[32m[0906 17-45-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31438, current rewards: -18.11377, mean: -0.03938
[32m[0906 17-46-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31455, current rewards: -13.44125, mean: -0.02636
[32m[0906 17-46-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31481, current rewards: -8.81181, mean: -0.01574
[32m[0906 17-46-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31483, current rewards: -4.18618, mean: -0.00686
[32m[0906 17-46-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31496, current rewards: 0.44201, mean: 0.00067
[32m[0906 17-47-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31501, current rewards: 5.06501, mean: 0.00713
[32m[0906 17-47-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31507, current rewards: 9.69058, mean: 0.01275
[32m[0906 17-47-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31513, current rewards: 19.84154, mean: 0.02450
[32m[0906 17-47-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31513, current rewards: 25.87823, mean: 0.03009
[32m[0906 17-48-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31511, current rewards: 8.80116, mean: 0.00967
[32m[0906 17-48-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31507, current rewards: 18.71636, mean: 0.01950
[32m[0906 17-48-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31509, current rewards: 29.97539, mean: 0.02968
[32m[0906 17-48-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31506, current rewards: 41.23266, mean: 0.03890
[32m[0906 17-49-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31506, current rewards: 4.22895, mean: 0.00381
[32m[0906 17-49-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31499, current rewards: 9.51557, mean: 0.00820
[32m[0906 17-49-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31494, current rewards: 14.37352, mean: 0.01188
[32m[0906 17-50-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31488, current rewards: 16.77963, mean: 0.01332
[32m[0906 17-50-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31483, current rewards: 21.40495, mean: 0.01634
[32m[0906 17-50-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31480, current rewards: 26.02598, mean: 0.01914
[32m[0906 17-50-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31479, current rewards: 30.64961, mean: 0.02174
[32m[0906 17-51-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31476, current rewards: 35.27620, mean: 0.02416
[32m[0906 17-51-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31475, current rewards: 39.89183, mean: 0.02642
[32m[0906 17-51-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31477, current rewards: 44.51871, mean: 0.02854
[32m[0906 17-51-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31471, current rewards: 49.14300, mean: 0.03052
[32m[0906 17-52-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31469, current rewards: 62.27277, mean: 0.03751
[32m[0906 17-52-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31466, current rewards: 66.69375, mean: 0.03900
[32m[0906 17-52-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31465, current rewards: 73.97217, mean: 0.04203
[32m[0906 17-52-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31461, current rewards: 81.61661, mean: 0.04509
[32m[0906 17-53-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31460, current rewards: 89.26477, mean: 0.04799
[32m[0906 17-53-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31459, current rewards: 96.90777, mean: 0.05074
[32m[0906 17-53-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31454, current rewards: 104.55110, mean: 0.05334
[32m[0906 17-53-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31452, current rewards: 112.20107, mean: 0.05582
[32m[0906 17-54-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31449, current rewards: 119.18277, mean: 0.05786
[32m[0906 17-54-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31451, current rewards: 124.21686, mean: 0.05887
[32m[0906 17-54-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31453, current rewards: 130.06999, mean: 0.06022
[32m[0906 17-54-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31444, current rewards: 91.45321, mean: 0.04138
[32m[0906 17-55-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31430, current rewards: 97.26571, mean: 0.04304
[32m[0906 17-55-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31425, current rewards: 102.65085, mean: 0.04444
[32m[0906 17-55-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31429, current rewards: 108.03159, mean: 0.04578
[32m[0906 17-56-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31404, current rewards: 113.40781, mean: 0.04706
[32m[0906 17-56-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31374, current rewards: 118.78414, mean: 0.04829
[32m[0906 17-56-27 @Agent.py:117][0m Average action selection time: 0.3136
[32m[0906 17-56-27 @Agent.py:118][0m Rollout length: 2520
[32m[0906 17-56-27 @MBExp.py:227][0m Rewards obtained: [123.87128199572811], Lows: [62], Highs: [42], Total time: 15016.926288
[32m[0906 17-57-03 @MBExp.py:144][0m ####################################################################
[32m[0906 17-57-03 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 17-57-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31939, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-57-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31720, current rewards: -19.22004, mean: -0.32033
[32m[0906 17-57-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31677, current rewards: -15.33471, mean: -0.13941
[32m[0906 17-57-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31610, current rewards: -11.44461, mean: -0.07153
[32m[0906 17-58-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31428, current rewards: -7.55882, mean: -0.03599
[32m[0906 17-58-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31320, current rewards: -3.67027, mean: -0.01412
[32m[0906 17-58-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31363, current rewards: 0.21150, mean: 0.00068
[32m[0906 17-58-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31389, current rewards: 4.10142, mean: 0.01139
[32m[0906 17-59-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31414, current rewards: 7.99207, mean: 0.01949
[32m[0906 17-59-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31415, current rewards: 11.87729, mean: 0.02582
[32m[0906 17-59-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31406, current rewards: 15.76248, mean: 0.03091
[32m[0906 17-59-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31415, current rewards: 19.65043, mean: 0.03509
[32m[0906 18-00-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31429, current rewards: 23.53718, mean: 0.03859
[32m[0906 18-00-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31442, current rewards: -9.97671, mean: -0.01512
[32m[0906 18-00-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31444, current rewards: -5.71478, mean: -0.00805
[32m[0906 18-01-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31448, current rewards: 3.70228, mean: 0.00487
[32m[0906 18-01-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31449, current rewards: -10.02603, mean: -0.01238
[32m[0906 18-01-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31450, current rewards: -3.21687, mean: -0.00374
[32m[0906 18-01-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31455, current rewards: 3.94007, mean: 0.00433
[32m[0906 18-02-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31455, current rewards: 11.05908, mean: 0.01152
[32m[0906 18-02-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31451, current rewards: 18.10004, mean: 0.01792
[32m[0906 18-02-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31452, current rewards: 25.15028, mean: 0.02373
[32m[0906 18-02-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31453, current rewards: 31.93732, mean: 0.02877
[32m[0906 18-03-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31453, current rewards: 35.02851, mean: 0.03020
[32m[0906 18-03-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31448, current rewards: 39.53522, mean: 0.03267
[32m[0906 18-03-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31448, current rewards: 43.16504, mean: 0.03426
[32m[0906 18-03-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31448, current rewards: 46.27186, mean: 0.03532
[32m[0906 18-04-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31447, current rewards: 49.33180, mean: 0.03627
[32m[0906 18-04-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31442, current rewards: 52.38502, mean: 0.03715
[32m[0906 18-04-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31444, current rewards: 55.43646, mean: 0.03797
[32m[0906 18-04-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31442, current rewards: 58.48781, mean: 0.03873
[32m[0906 18-05-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31440, current rewards: 41.37871, mean: 0.02652
[32m[0906 18-05-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31440, current rewards: 44.50543, mean: 0.02764
[32m[0906 18-05-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31438, current rewards: 48.18298, mean: 0.02903
[32m[0906 18-06-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31439, current rewards: 51.29698, mean: 0.03000
[32m[0906 18-06-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31439, current rewards: 54.40690, mean: 0.03091
[32m[0906 18-06-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31437, current rewards: 57.51660, mean: 0.03178
[32m[0906 18-06-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31436, current rewards: 62.41240, mean: 0.03356
[32m[0906 18-07-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31432, current rewards: 43.89967, mean: 0.02298
[32m[0906 18-07-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31431, current rewards: 46.18650, mean: 0.02356
[32m[0906 18-07-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31430, current rewards: 27.27189, mean: 0.01357
[32m[0906 18-07-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31427, current rewards: 18.76099, mean: 0.00911
[32m[0906 18-08-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31426, current rewards: 21.33820, mean: 0.01011
[32m[0906 18-08-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31425, current rewards: 23.80901, mean: 0.01102
[32m[0906 18-08-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31413, current rewards: 26.28076, mean: 0.01189
[32m[0906 18-08-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31401, current rewards: 28.75111, mean: 0.01272
[32m[0906 18-09-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31392, current rewards: -8.94290, mean: -0.00387
[32m[0906 18-09-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31396, current rewards: -5.07911, mean: -0.00215
[32m[0906 18-09-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31368, current rewards: -1.44578, mean: -0.00060
[32m[0906 18-09-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31339, current rewards: 2.50845, mean: 0.00102
[32m[0906 18-10-07 @Agent.py:117][0m Average action selection time: 0.3133
[32m[0906 18-10-07 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-10-07 @MBExp.py:227][0m Rewards obtained: [5.69126844863896], Lows: [52], Highs: [96], Total time: 15800.682242
[32m[0906 18-10-45 @MBExp.py:144][0m ####################################################################
[32m[0906 18-10-45 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 18-10-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31947, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-11-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31713, current rewards: -27.93078, mean: -0.46551
[32m[0906 18-11-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31701, current rewards: -24.54665, mean: -0.22315
[32m[0906 18-11-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31653, current rewards: -21.15201, mean: -0.13220
[32m[0906 18-11-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31459, current rewards: -17.75944, mean: -0.08457
[32m[0906 18-12-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31351, current rewards: -14.36618, mean: -0.05525
[32m[0906 18-12-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31377, current rewards: -10.97334, mean: -0.03540
[32m[0906 18-12-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31681, current rewards: -7.10058, mean: -0.01972
[32m[0906 18-12-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32136, current rewards: -3.30004, mean: -0.00805
[32m[0906 18-13-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32500, current rewards: 0.19976, mean: 0.00043
[32m[0906 18-13-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32803, current rewards: 3.69991, mean: 0.00725
[32m[0906 18-13-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33058, current rewards: 7.19949, mean: 0.01286
[32m[0906 18-14-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33283, current rewards: 10.69912, mean: 0.01754
[32m[0906 18-14-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33478, current rewards: 14.19950, mean: 0.02151
[32m[0906 18-14-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33642, current rewards: 17.69962, mean: 0.02493
[32m[0906 18-15-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33782, current rewards: 1.94018, mean: 0.00255
[32m[0906 18-15-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33908, current rewards: 5.20762, mean: 0.00643
[32m[0906 18-15-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34011, current rewards: 9.20713, mean: 0.01071
[32m[0906 18-15-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34106, current rewards: 13.20768, mean: 0.01451
[32m[0906 18-16-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34193, current rewards: 17.20882, mean: 0.01793
[32m[0906 18-16-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34274, current rewards: 8.24932, mean: 0.00817
[32m[0906 18-16-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34381, current rewards: 2.86848, mean: 0.00271
[32m[0906 18-17-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34474, current rewards: 6.23631, mean: 0.00562
[32m[0906 18-17-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34556, current rewards: 9.60569, mean: 0.00828
[32m[0906 18-17-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34594, current rewards: -16.01811, mean: -0.01324
[32m[0906 18-18-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34627, current rewards: -12.56074, mean: -0.00997
[32m[0906 18-18-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34664, current rewards: -8.99821, mean: -0.00687
[32m[0906 18-18-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34687, current rewards: -5.43463, mean: -0.00400
[32m[0906 18-18-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34714, current rewards: -1.86789, mean: -0.00132
[32m[0906 18-19-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34735, current rewards: 1.69469, mean: 0.00116
[32m[0906 18-19-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34759, current rewards: 5.25928, mean: 0.00348
[32m[0906 18-19-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34781, current rewards: 8.82329, mean: 0.00566
[32m[0906 18-20-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34800, current rewards: 16.00501, mean: 0.00994
[32m[0906 18-20-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34818, current rewards: 24.82944, mean: 0.01496
[32m[0906 18-20-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34835, current rewards: 28.67924, mean: 0.01677
[32m[0906 18-20-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34849, current rewards: 32.52694, mean: 0.01848
[32m[0906 18-21-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34865, current rewards: 36.37427, mean: 0.02010
[32m[0906 18-21-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34886, current rewards: 40.22025, mean: 0.02162
[32m[0906 18-21-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34908, current rewards: 6.68368, mean: 0.00350
[32m[0906 18-22-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34930, current rewards: 6.64560, mean: 0.00339
[32m[0906 18-22-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34950, current rewards: 10.12870, mean: 0.00504
[32m[0906 18-22-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34970, current rewards: 13.72284, mean: 0.00666
[32m[0906 18-23-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34988, current rewards: 17.29916, mean: 0.00820
[32m[0906 18-23-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35006, current rewards: 20.85326, mean: 0.00965
[32m[0906 18-23-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35011, current rewards: -12.87413, mean: -0.00583
[32m[0906 18-23-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35007, current rewards: -11.67270, mean: -0.00516
[32m[0906 18-24-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35001, current rewards: -4.01762, mean: -0.00174
[32m[0906 18-24-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35018, current rewards: 3.63746, mean: 0.00154
[32m[0906 18-24-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34997, current rewards: 11.29255, mean: 0.00469
[32m[0906 18-25-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34976, current rewards: -36.40125, mean: -0.01480
[32m[0906 18-25-20 @Agent.py:117][0m Average action selection time: 0.3496
[32m[0906 18-25-20 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-25-20 @MBExp.py:227][0m Rewards obtained: [-76.40125173182531], Lows: [41], Highs: [185], Total time: 16675.393833000002
[32m[0906 18-26-06 @MBExp.py:144][0m ####################################################################
[32m[0906 18-26-06 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 18-26-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36814, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-26-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35850, current rewards: -15.78579, mean: -0.26310
[32m[0906 18-26-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35672, current rewards: -9.00552, mean: -0.08187
[32m[0906 18-27-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35576, current rewards: -2.07832, mean: -0.01299
[32m[0906 18-27-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35359, current rewards: 4.86316, mean: 0.02316
[32m[0906 18-27-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35207, current rewards: 11.79399, mean: 0.04536
[32m[0906 18-27-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35227, current rewards: 16.85738, mean: 0.05438
[32m[0906 18-28-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35264, current rewards: 24.06814, mean: 0.06686
[32m[0906 18-28-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35292, current rewards: 32.65272, mean: 0.07964
[32m[0906 18-28-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35354, current rewards: 40.46144, mean: 0.08796
[32m[0906 18-29-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35406, current rewards: 48.25022, mean: 0.09461
[32m[0906 18-29-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35448, current rewards: 56.03636, mean: 0.10006
[32m[0906 18-29-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35477, current rewards: 63.83949, mean: 0.10465
[32m[0906 18-30-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35499, current rewards: 71.62696, mean: 0.10853
[32m[0906 18-30-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35495, current rewards: -26.21619, mean: -0.03692
[32m[0906 18-30-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35482, current rewards: -126.21619, mean: -0.16607
[32m[0906 18-30-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35478, current rewards: -226.21619, mean: -0.27928
[32m[0906 18-31-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35472, current rewards: -326.21619, mean: -0.37932
[32m[0906 18-31-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35464, current rewards: -422.10637, mean: -0.46385
[32m[0906 18-31-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35455, current rewards: -416.47016, mean: -0.43382
[32m[0906 18-32-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35451, current rewards: -406.11962, mean: -0.40210
[32m[0906 18-32-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35285, current rewards: -395.33650, mean: -0.37296
[32m[0906 18-32-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35115, current rewards: -384.54571, mean: -0.34644
[32m[0906 18-32-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34963, current rewards: -375.98933, mean: -0.32413
[32m[0906 18-33-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34834, current rewards: -419.78454, mean: -0.34693
[32m[0906 18-33-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34703, current rewards: -408.05198, mean: -0.32385
[32m[0906 18-33-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34585, current rewards: -399.36158, mean: -0.30486
[32m[0906 18-33-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34473, current rewards: -390.67726, mean: -0.28726
[32m[0906 18-34-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34370, current rewards: -381.98911, mean: -0.27091
[32m[0906 18-34-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34272, current rewards: -373.29993, mean: -0.25568
[32m[0906 18-34-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34178, current rewards: -364.61102, mean: -0.24146
[32m[0906 18-34-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34090, current rewards: -355.91970, mean: -0.22815
[32m[0906 18-35-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34006, current rewards: -349.60730, mean: -0.21715
[32m[0906 18-35-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33928, current rewards: -342.60164, mean: -0.20639
[32m[0906 18-35-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33855, current rewards: -358.72727, mean: -0.20978
[32m[0906 18-36-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33789, current rewards: -343.10414, mean: -0.19495
[32m[0906 18-36-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33725, current rewards: -311.14244, mean: -0.17190
[32m[0906 18-36-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33665, current rewards: -278.54418, mean: -0.14975
[32m[0906 18-36-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33609, current rewards: -245.87323, mean: -0.12873
[32m[0906 18-37-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33551, current rewards: -213.30782, mean: -0.10883
[32m[0906 18-37-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33498, current rewards: -246.84626, mean: -0.12281
[32m[0906 18-37-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33448, current rewards: -298.08066, mean: -0.14470
[32m[0906 18-37-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33400, current rewards: -339.08072, mean: -0.16070
[32m[0906 18-38-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33358, current rewards: -359.77813, mean: -0.16656
[32m[0906 18-38-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33304, current rewards: -353.76105, mean: -0.16007
[32m[0906 18-38-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33247, current rewards: -346.44898, mean: -0.15330
[32m[0906 18-38-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33193, current rewards: -338.96606, mean: -0.14674
[32m[0906 18-39-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33160, current rewards: -331.45114, mean: -0.14045
[32m[0906 18-39-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33094, current rewards: -323.78817, mean: -0.13435
[32m[0906 18-39-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33029, current rewards: -313.77848, mean: -0.12755
[32m[0906 18-39-51 @Agent.py:117][0m Average action selection time: 0.3298
[32m[0906 18-39-51 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-39-51 @MBExp.py:227][0m Rewards obtained: [-305.46753623275225], Lows: [361], Highs: [48], Total time: 17500.563155000003
[32m[0906 18-40-33 @MBExp.py:144][0m ####################################################################
[32m[0906 18-40-33 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 18-40-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31811, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-40-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31644, current rewards: -35.12375, mean: -0.58540
[32m[0906 18-41-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31605, current rewards: -80.58242, mean: -0.73257
[32m[0906 18-41-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31523, current rewards: -124.59615, mean: -0.77873
[32m[0906 18-41-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31367, current rewards: -160.33388, mean: -0.76349
[32m[0906 18-41-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31279, current rewards: -194.92496, mean: -0.74971
[32m[0906 18-42-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31305, current rewards: -229.45119, mean: -0.74017
[32m[0906 18-42-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31356, current rewards: -325.09060, mean: -0.90303
[32m[0906 18-42-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31381, current rewards: -370.84292, mean: -0.90449
[32m[0906 18-42-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31402, current rewards: -385.38718, mean: -0.83780
[32m[0906 18-43-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31417, current rewards: -375.96504, mean: -0.73719
[32m[0906 18-43-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31423, current rewards: -366.22864, mean: -0.65398
[32m[0906 18-43-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31426, current rewards: -356.48673, mean: -0.58440
[32m[0906 18-44-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31433, current rewards: -346.71740, mean: -0.52533
[32m[0906 18-44-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31433, current rewards: -336.97801, mean: -0.47462
[32m[0906 18-44-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31438, current rewards: -328.90958, mean: -0.43278
[32m[0906 18-44-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31440, current rewards: -321.60050, mean: -0.39704
[32m[0906 18-45-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31444, current rewards: -313.08461, mean: -0.36405
[32m[0906 18-45-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31449, current rewards: -304.57641, mean: -0.33470
[32m[0906 18-45-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31449, current rewards: -296.05619, mean: -0.30839
[32m[0906 18-45-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31446, current rewards: -307.08078, mean: -0.30404
[32m[0906 18-46-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31445, current rewards: -328.17069, mean: -0.30959
[32m[0906 18-46-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31445, current rewards: -318.11055, mean: -0.28659
[32m[0906 18-46-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31445, current rewards: -308.04073, mean: -0.26555
[32m[0906 18-46-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31446, current rewards: -332.95772, mean: -0.27517
[32m[0906 18-47-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31445, current rewards: -321.03413, mean: -0.25479
[32m[0906 18-47-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31443, current rewards: -310.27611, mean: -0.23685
[32m[0906 18-47-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31445, current rewards: -299.51333, mean: -0.22023
[32m[0906 18-47-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31446, current rewards: -296.05137, mean: -0.20997
[32m[0906 18-48-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31446, current rewards: -300.70710, mean: -0.20596
[32m[0906 18-48-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31445, current rewards: -284.57885, mean: -0.18846
[32m[0906 18-48-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31443, current rewards: -268.27095, mean: -0.17197
[32m[0906 18-48-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31443, current rewards: -297.88718, mean: -0.18502
[32m[0906 18-49-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31442, current rewards: -280.31010, mean: -0.16886
[32m[0906 18-49-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31444, current rewards: -262.85655, mean: -0.15372
[32m[0906 18-49-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31445, current rewards: -330.49570, mean: -0.18778
[32m[0906 18-50-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31441, current rewards: -319.04170, mean: -0.17627
[32m[0906 18-50-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31438, current rewards: -307.36706, mean: -0.16525
[32m[0906 18-50-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31438, current rewards: -295.67448, mean: -0.15480
[32m[0906 18-50-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31436, current rewards: -283.99502, mean: -0.14490
[32m[0906 18-51-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31438, current rewards: -273.11385, mean: -0.13588
[32m[0906 18-51-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31437, current rewards: -262.12135, mean: -0.12724
[32m[0906 18-51-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31438, current rewards: -254.20082, mean: -0.12047
[32m[0906 18-51-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31436, current rewards: -243.22699, mean: -0.11261
[32m[0906 18-52-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31425, current rewards: -232.22512, mean: -0.10508
[32m[0906 18-52-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31410, current rewards: -221.23366, mean: -0.09789
[32m[0906 18-52-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31395, current rewards: -210.26286, mean: -0.09102
[32m[0906 18-52-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31394, current rewards: -199.27000, mean: -0.08444
[32m[0906 18-53-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31365, current rewards: -190.50521, mean: -0.07905
[32m[0906 18-53-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31336, current rewards: -183.14448, mean: -0.07445
[32m[0906 18-53-36 @Agent.py:117][0m Average action selection time: 0.3131
[32m[0906 18-53-36 @Agent.py:118][0m Rollout length: 2520
[32m[0906 18-53-36 @MBExp.py:227][0m Rewards obtained: [-175.42604143398137], Lows: [303], Highs: [62], Total time: 18284.017467000005
[32m[0906 18-54-19 @MBExp.py:144][0m ####################################################################
[32m[0906 18-54-19 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 18-54-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31518, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-54-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31579, current rewards: -15.64200, mean: -0.26070
[32m[0906 18-54-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31564, current rewards: -10.47168, mean: -0.09520
[32m[0906 18-55-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31504, current rewards: -5.31048, mean: -0.03319
[32m[0906 18-55-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31361, current rewards: -0.14897, mean: -0.00071
[32m[0906 18-55-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31250, current rewards: 5.01210, mean: 0.01928
[32m[0906 18-55-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31250, current rewards: 10.17203, mean: 0.03281
[32m[0906 18-56-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31297, current rewards: 15.06690, mean: 0.04185
[32m[0906 18-56-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31339, current rewards: -3.39730, mean: -0.00829
[32m[0906 18-56-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31374, current rewards: -0.15858, mean: -0.00034
[32m[0906 18-57-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31390, current rewards: 3.32367, mean: 0.00652
[32m[0906 18-57-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31412, current rewards: 6.83958, mean: 0.01221
[32m[0906 18-57-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31424, current rewards: 10.34150, mean: 0.01695
[32m[0906 18-57-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31429, current rewards: 13.85394, mean: 0.02099
[32m[0906 18-58-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31431, current rewards: 17.35917, mean: 0.02445
[32m[0906 18-58-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31432, current rewards: 21.01382, mean: 0.02765
[32m[0906 18-58-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31445, current rewards: 24.55728, mean: 0.03032
[32m[0906 18-58-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31450, current rewards: 28.17384, mean: 0.03276
[32m[0906 18-59-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31449, current rewards: 31.76549, mean: 0.03491
[32m[0906 18-59-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31448, current rewards: -5.38812, mean: -0.00561
[32m[0906 18-59-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31448, current rewards: -2.28726, mean: -0.00226
[32m[0906 18-59-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31451, current rewards: 0.63548, mean: 0.00060
[32m[0906 19-00-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31449, current rewards: 3.55822, mean: 0.00321
[32m[0906 19-00-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31453, current rewards: 6.63508, mean: 0.00572
[32m[0906 19-00-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31458, current rewards: 9.92552, mean: 0.00820
[32m[0906 19-00-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31456, current rewards: 13.21595, mean: 0.01049
[32m[0906 19-01-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31451, current rewards: 16.50639, mean: 0.01260
[32m[0906 19-01-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31448, current rewards: 19.79683, mean: 0.01456
[32m[0906 19-01-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31445, current rewards: -30.20317, mean: -0.02142
[32m[0906 19-01-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31442, current rewards: -80.20317, mean: -0.05493
[32m[0906 19-02-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31443, current rewards: -130.20317, mean: -0.08623
[32m[0906 19-02-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31441, current rewards: -180.20317, mean: -0.11551
[32m[0906 19-02-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31438, current rewards: -230.20317, mean: -0.14298
[32m[0906 19-03-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31435, current rewards: -280.20317, mean: -0.16880
[32m[0906 19-03-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31437, current rewards: -330.20317, mean: -0.19310
[32m[0906 19-03-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31435, current rewards: -380.20317, mean: -0.21602
[32m[0906 19-03-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31433, current rewards: -430.20317, mean: -0.23768
[32m[0906 19-04-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31433, current rewards: -480.20317, mean: -0.25817
[32m[0906 19-04-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31430, current rewards: -530.20317, mean: -0.27759
[32m[0906 19-04-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31431, current rewards: -580.20317, mean: -0.29602
[32m[0906 19-04-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31431, current rewards: -630.20317, mean: -0.31353
[32m[0906 19-05-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31429, current rewards: -680.20317, mean: -0.33020
[32m[0906 19-05-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31428, current rewards: -730.20317, mean: -0.34607
[32m[0906 19-05-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31427, current rewards: -780.20317, mean: -0.36121
[32m[0906 19-05-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31415, current rewards: -830.20317, mean: -0.37566
[32m[0906 19-06-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31402, current rewards: -880.20317, mean: -0.38947
[32m[0906 19-06-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31388, current rewards: -930.20317, mean: -0.40269
[32m[0906 19-06-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31386, current rewards: -980.20317, mean: -0.41534
[32m[0906 19-06-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31357, current rewards: -1030.20317, mean: -0.42747
[32m[0906 19-07-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31329, current rewards: -1080.20317, mean: -0.43911
[32m[0906 19-07-23 @Agent.py:117][0m Average action selection time: 0.3131
[32m[0906 19-07-23 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-07-23 @MBExp.py:227][0m Rewards obtained: [-1120.203169234864], Lows: [20], Highs: [1182], Total time: 19067.321631000006
[32m[0906 19-08-08 @MBExp.py:144][0m ####################################################################
[32m[0906 19-08-08 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 19-08-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31831, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-08-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31654, current rewards: -16.24794, mean: -0.27080
[32m[0906 19-08-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31601, current rewards: -10.74203, mean: -0.09765
[32m[0906 19-08-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31510, current rewards: -5.23572, mean: -0.03272
[32m[0906 19-09-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31370, current rewards: 0.26778, mean: 0.00128
[32m[0906 19-09-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31266, current rewards: 5.76982, mean: 0.02219
[32m[0906 19-09-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31258, current rewards: 12.99869, mean: 0.04193
[32m[0906 19-10-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31319, current rewards: 17.83847, mean: 0.04955
[32m[0906 19-10-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31357, current rewards: 22.62839, mean: 0.05519
[32m[0906 19-10-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31384, current rewards: 27.41712, mean: 0.05960
[32m[0906 19-10-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31413, current rewards: 10.18502, mean: 0.01997
[32m[0906 19-11-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31435, current rewards: 14.66361, mean: 0.02619
[32m[0906 19-11-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31454, current rewards: 19.33676, mean: 0.03170
[32m[0906 19-11-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31472, current rewards: 24.00282, mean: 0.03637
[32m[0906 19-11-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31483, current rewards: 27.97073, mean: 0.03940
[32m[0906 19-12-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31490, current rewards: 32.51075, mean: 0.04278
[32m[0906 19-12-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31490, current rewards: 36.95031, mean: 0.04562
[32m[0906 19-12-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31491, current rewards: 41.38909, mean: 0.04813
[32m[0906 19-12-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31492, current rewards: 45.82687, mean: 0.05036
[32m[0906 19-13-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31491, current rewards: 50.26430, mean: 0.05236
[32m[0906 19-13-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31490, current rewards: 54.70193, mean: 0.05416
[32m[0906 19-13-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31493, current rewards: 59.13723, mean: 0.05579
[32m[0906 19-13-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31495, current rewards: 57.86305, mean: 0.05213
[32m[0906 19-14-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31502, current rewards: 27.80517, mean: 0.02397
[32m[0906 19-14-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31502, current rewards: 33.81479, mean: 0.02795
[32m[0906 19-14-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31503, current rewards: 39.83232, mean: 0.03161
[32m[0906 19-15-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31499, current rewards: 45.85209, mean: 0.03500
[32m[0906 19-15-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31496, current rewards: 51.87295, mean: 0.03814
[32m[0906 19-15-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31497, current rewards: 57.88731, mean: 0.04105
[32m[0906 19-15-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31495, current rewards: 63.89691, mean: 0.04377
[32m[0906 19-16-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31497, current rewards: 63.21836, mean: 0.04187
[32m[0906 19-16-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31493, current rewards: 65.95662, mean: 0.04228
[32m[0906 19-16-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31494, current rewards: 70.62558, mean: 0.04387
[32m[0906 19-16-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31496, current rewards: 75.29591, mean: 0.04536
[32m[0906 19-17-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31495, current rewards: 79.97154, mean: 0.04677
[32m[0906 19-17-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31491, current rewards: 84.64626, mean: 0.04809
[32m[0906 19-17-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31492, current rewards: 89.32362, mean: 0.04935
[32m[0906 19-17-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31490, current rewards: 93.99374, mean: 0.05053
[32m[0906 19-18-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31488, current rewards: 98.66562, mean: 0.05166
[32m[0906 19-18-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31487, current rewards: 112.26560, mean: 0.05728
[32m[0906 19-18-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31487, current rewards: 76.00896, mean: 0.03782
[32m[0906 19-18-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31486, current rewards: 84.53841, mean: 0.04104
[32m[0906 19-19-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31485, current rewards: 92.44602, mean: 0.04381
[32m[0906 19-19-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31482, current rewards: 100.34154, mean: 0.04645
[32m[0906 19-19-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31469, current rewards: 108.23807, mean: 0.04898
[32m[0906 19-19-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31454, current rewards: 116.13296, mean: 0.05139
[32m[0906 19-20-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31439, current rewards: 124.02835, mean: 0.05369
[32m[0906 19-20-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31435, current rewards: 131.34725, mean: 0.05566
[32m[0906 19-20-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31408, current rewards: 138.75146, mean: 0.05757
[32m[0906 19-21-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31379, current rewards: 120.58353, mean: 0.04902
[32m[0906 19-21-13 @Agent.py:117][0m Average action selection time: 0.3135
[32m[0906 19-21-13 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-21-13 @MBExp.py:227][0m Rewards obtained: [124.7334247496007], Lows: [40], Highs: [68], Total time: 19851.814576000004
[32m[0906 19-22-00 @MBExp.py:144][0m ####################################################################
[32m[0906 19-22-00 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 19-22-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31637, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-22-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31656, current rewards: -16.23008, mean: -0.27050
[32m[0906 19-22-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31573, current rewards: -11.38840, mean: -0.10353
[32m[0906 19-22-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31523, current rewards: -6.55043, mean: -0.04094
[32m[0906 19-23-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31382, current rewards: -1.71401, mean: -0.00816
[32m[0906 19-23-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31281, current rewards: 3.10196, mean: 0.01193
[32m[0906 19-23-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31254, current rewards: -14.08464, mean: -0.04543
[32m[0906 19-23-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31310, current rewards: -8.43227, mean: -0.02342
[32m[0906 19-24-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31346, current rewards: -1.91036, mean: -0.00466
[32m[0906 19-24-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31369, current rewards: 4.60385, mean: 0.01001
[32m[0906 19-24-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31379, current rewards: 11.12780, mean: 0.02182
[32m[0906 19-24-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31386, current rewards: -25.31389, mean: -0.04520
[32m[0906 19-25-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31392, current rewards: -20.52885, mean: -0.03365
[32m[0906 19-25-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31399, current rewards: -15.72884, mean: -0.02383
[32m[0906 19-25-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31414, current rewards: -10.05317, mean: -0.01416
[32m[0906 19-25-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31414, current rewards: -5.08083, mean: -0.00669
[32m[0906 19-26-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31423, current rewards: -0.10552, mean: -0.00013
[32m[0906 19-26-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31434, current rewards: 4.86827, mean: 0.00566
[32m[0906 19-26-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31442, current rewards: 14.70097, mean: 0.01615
[32m[0906 19-27-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31450, current rewards: 28.48331, mean: 0.02967
[32m[0906 19-27-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31454, current rewards: 33.41862, mean: 0.03309
[32m[0906 19-27-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31454, current rewards: 38.35299, mean: 0.03618
[32m[0906 19-27-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31457, current rewards: 44.73544, mean: 0.04030
[32m[0906 19-28-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31451, current rewards: 49.76847, mean: 0.04290
[32m[0906 19-28-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31457, current rewards: 54.80311, mean: 0.04529
[32m[0906 19-28-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31456, current rewards: 19.91882, mean: 0.01581
[32m[0906 19-28-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31456, current rewards: 25.67899, mean: 0.01960
[32m[0906 19-29-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31459, current rewards: 33.05849, mean: 0.02431
[32m[0906 19-29-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31463, current rewards: 40.43811, mean: 0.02868
[32m[0906 19-29-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31468, current rewards: 47.81495, mean: 0.03275
[32m[0906 19-29-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31552, current rewards: 52.47597, mean: 0.03475
[32m[0906 19-30-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31666, current rewards: 57.70636, mean: 0.03699
[32m[0906 19-30-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31772, current rewards: 63.00717, mean: 0.03913
[32m[0906 19-30-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31876, current rewards: 68.30915, mean: 0.04115
[32m[0906 19-31-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31973, current rewards: 57.02089, mean: 0.03335
[32m[0906 19-31-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32066, current rewards: 55.70908, mean: 0.03165
[32m[0906 19-31-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32149, current rewards: 59.93941, mean: 0.03312
[32m[0906 19-32-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32231, current rewards: 64.17613, mean: 0.03450
[32m[0906 19-32-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32309, current rewards: 68.13794, mean: 0.03567
[32m[0906 19-32-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32383, current rewards: 72.22067, mean: 0.03685
[32m[0906 19-32-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32451, current rewards: 76.32012, mean: 0.03797
[32m[0906 19-33-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32516, current rewards: 80.41664, mean: 0.03904
[32m[0906 19-33-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32575, current rewards: 84.51284, mean: 0.04005
[32m[0906 19-33-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32636, current rewards: 88.60908, mean: 0.04102
[32m[0906 19-34-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32682, current rewards: 92.70717, mean: 0.04195
[32m[0906 19-34-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32718, current rewards: 96.80427, mean: 0.04283
[32m[0906 19-34-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32754, current rewards: 101.08651, mean: 0.04376
[32m[0906 19-34-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32797, current rewards: 112.46006, mean: 0.04765
[32m[0906 19-35-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32812, current rewards: 100.43267, mean: 0.04167
[32m[0906 19-35-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32824, current rewards: 82.47927, mean: 0.03353
[32m[0906 19-35-41 @Agent.py:117][0m Average action selection time: 0.3283
[32m[0906 19-35-41 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-35-41 @MBExp.py:227][0m Rewards obtained: [86.72726297531973], Lows: [60], Highs: [60], Total time: 20673.298812000005
[32m[0906 19-36-36 @MBExp.py:144][0m ####################################################################
[32m[0906 19-36-36 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 19-36-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35412, current rewards: -2.62758, mean: -0.26276
[32m[0906 19-36-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35435, current rewards: -0.07806, mean: -0.00130
[32m[0906 19-37-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35324, current rewards: 5.33650, mean: 0.04851
[32m[0906 19-37-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35223, current rewards: 10.71797, mean: 0.06699
[32m[0906 19-37-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35027, current rewards: 16.09731, mean: 0.07665
[32m[0906 19-38-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34908, current rewards: 21.99316, mean: 0.08459
[32m[0906 19-38-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34832, current rewards: 28.02604, mean: 0.09041
[32m[0906 19-38-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34892, current rewards: 33.47938, mean: 0.09300
[32m[0906 19-38-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34937, current rewards: 38.93263, mean: 0.09496
[32m[0906 19-39-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34976, current rewards: 44.38588, mean: 0.09649
[32m[0906 19-39-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35011, current rewards: -3.39599, mean: -0.00666
[32m[0906 19-39-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35040, current rewards: -53.39599, mean: -0.09535
[32m[0906 19-40-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35061, current rewards: -103.39599, mean: -0.16950
[32m[0906 19-40-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35074, current rewards: -153.39599, mean: -0.23242
[32m[0906 19-40-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35089, current rewards: -203.39599, mean: -0.28647
[32m[0906 19-41-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35101, current rewards: -253.39599, mean: -0.33342
[32m[0906 19-41-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35102, current rewards: -303.39599, mean: -0.37456
[32m[0906 19-41-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35109, current rewards: -353.39599, mean: -0.41093
[32m[0906 19-41-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35107, current rewards: -403.39599, mean: -0.44329
[32m[0906 19-42-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35111, current rewards: -453.39599, mean: -0.47229
[32m[0906 19-42-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35117, current rewards: -503.39599, mean: -0.49841
[32m[0906 19-42-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35124, current rewards: -553.39599, mean: -0.52207
[32m[0906 19-43-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35132, current rewards: -603.39599, mean: -0.54360
[32m[0906 19-43-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35140, current rewards: -653.39599, mean: -0.56327
[32m[0906 19-43-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35140, current rewards: -703.39599, mean: -0.58132
[32m[0906 19-43-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35140, current rewards: -753.39599, mean: -0.59793
[32m[0906 19-44-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35141, current rewards: -803.39599, mean: -0.61328
[32m[0906 19-44-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35071, current rewards: -853.39599, mean: -0.62750
[32m[0906 19-44-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34950, current rewards: -903.39599, mean: -0.64071
[32m[0906 19-45-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34832, current rewards: -953.39599, mean: -0.65301
[32m[0906 19-45-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34720, current rewards: -1003.39599, mean: -0.66450
[32m[0906 19-45-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34613, current rewards: -1053.39599, mean: -0.67525
[32m[0906 19-45-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34514, current rewards: -1103.39599, mean: -0.68534
[32m[0906 19-46-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34421, current rewards: -1153.39599, mean: -0.69482
[32m[0906 19-46-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34337, current rewards: -1203.39599, mean: -0.70374
[32m[0906 19-46-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34255, current rewards: -1253.39599, mean: -0.71216
[32m[0906 19-46-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34181, current rewards: -1303.39599, mean: -0.72011
[32m[0906 19-47-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34106, current rewards: -1353.39599, mean: -0.72763
[32m[0906 19-47-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34038, current rewards: -1403.39599, mean: -0.73476
[32m[0906 19-47-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33970, current rewards: -1453.39599, mean: -0.74153
[32m[0906 19-47-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33907, current rewards: -1503.39599, mean: -0.74796
[32m[0906 19-48-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33846, current rewards: -1553.39599, mean: -0.75408
[32m[0906 19-48-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33792, current rewards: -1603.39599, mean: -0.75990
[32m[0906 19-48-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33739, current rewards: -1653.39599, mean: -0.76546
[32m[0906 19-49-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33677, current rewards: -1703.39599, mean: -0.77077
[32m[0906 19-49-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33614, current rewards: -1753.39599, mean: -0.77584
[32m[0906 19-49-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33554, current rewards: -1803.39599, mean: -0.78069
[32m[0906 19-49-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33498, current rewards: -1853.39599, mean: -0.78534
[32m[0906 19-50-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33430, current rewards: -1903.39599, mean: -0.78979
[32m[0906 19-50-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33359, current rewards: -1953.39599, mean: -0.79406
[32m[0906 19-50-29 @Agent.py:117][0m Average action selection time: 0.3331
[32m[0906 19-50-29 @Agent.py:118][0m Rollout length: 2520
[32m[0906 19-50-29 @MBExp.py:227][0m Rewards obtained: [-1993.395989210009], Lows: [2], Highs: [2041], Total time: 21506.579886000003
[32m[0906 19-51-20 @MBExp.py:144][0m ####################################################################
[32m[0906 19-51-20 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 19-51-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31831, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-51-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31650, current rewards: -16.41558, mean: -0.27359
[32m[0906 19-51-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31586, current rewards: -11.65628, mean: -0.10597
[32m[0906 19-52-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31517, current rewards: -6.90110, mean: -0.04313
[32m[0906 19-52-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31348, current rewards: -2.14498, mean: -0.01021
[32m[0906 19-52-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31258, current rewards: 2.61391, mean: 0.01005
[32m[0906 19-52-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31206, current rewards: 7.37783, mean: 0.02380
[32m[0906 19-53-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31258, current rewards: 12.13535, mean: 0.03371
[32m[0906 19-53-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31307, current rewards: 16.89377, mean: 0.04120
[32m[0906 19-53-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31341, current rewards: 21.65127, mean: 0.04707
[32m[0906 19-54-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31374, current rewards: 26.40821, mean: 0.05178
[32m[0906 19-54-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31392, current rewards: -8.50883, mean: -0.01519
[32m[0906 19-54-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31409, current rewards: -3.11093, mean: -0.00510
[32m[0906 19-54-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31414, current rewards: 1.78321, mean: 0.00270
[32m[0906 19-55-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31411, current rewards: 5.36168, mean: 0.00755
[32m[0906 19-55-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31414, current rewards: 10.59640, mean: 0.01394
[32m[0906 19-55-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31420, current rewards: 15.92815, mean: 0.01966
[32m[0906 19-55-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31424, current rewards: 21.26196, mean: 0.02472
[32m[0906 19-56-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31425, current rewards: 26.59185, mean: 0.02922
[32m[0906 19-56-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31426, current rewards: 15.32470, mean: 0.01596
[32m[0906 19-56-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31426, current rewards: 14.15536, mean: 0.01402
[32m[0906 19-56-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31425, current rewards: 19.68637, mean: 0.01857
[32m[0906 19-57-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31428, current rewards: 24.77551, mean: 0.02232
[32m[0906 19-57-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31430, current rewards: 30.28672, mean: 0.02611
[32m[0906 19-57-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31434, current rewards: 35.80520, mean: 0.02959
[32m[0906 19-57-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31434, current rewards: 41.32586, mean: 0.03280
[32m[0906 19-58-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31436, current rewards: 46.84392, mean: 0.03576
[32m[0906 19-58-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31438, current rewards: 52.35960, mean: 0.03850
[32m[0906 19-58-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31441, current rewards: 57.87487, mean: 0.04105
[32m[0906 19-58-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31441, current rewards: 63.38362, mean: 0.04341
[32m[0906 19-59-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31440, current rewards: 26.35562, mean: 0.01745
[32m[0906 19-59-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31440, current rewards: 31.53978, mean: 0.02022
[32m[0906 19-59-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31442, current rewards: 36.70728, mean: 0.02280
[32m[0906 20-00-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31442, current rewards: 41.87519, mean: 0.02523
[32m[0906 20-00-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31443, current rewards: 47.04687, mean: 0.02751
[32m[0906 20-00-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31442, current rewards: 52.21514, mean: 0.02967
[32m[0906 20-00-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31440, current rewards: 57.38208, mean: 0.03170
[32m[0906 20-01-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31437, current rewards: 62.55267, mean: 0.03363
[32m[0906 20-01-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31436, current rewards: 71.09755, mean: 0.03722
[32m[0906 20-01-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31436, current rewards: 54.17718, mean: 0.02764
[32m[0906 20-01-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31437, current rewards: 59.69003, mean: 0.02970
[32m[0906 20-02-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31436, current rewards: 65.44196, mean: 0.03177
[32m[0906 20-02-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31437, current rewards: 71.19757, mean: 0.03374
[32m[0906 20-02-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31435, current rewards: 76.93479, mean: 0.03562
[32m[0906 20-02-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31425, current rewards: 82.67425, mean: 0.03741
[32m[0906 20-03-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31411, current rewards: 88.41705, mean: 0.03912
[32m[0906 20-03-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31399, current rewards: 93.02361, mean: 0.04027
[32m[0906 20-03-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31387, current rewards: 98.17122, mean: 0.04160
[32m[0906 20-03-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31362, current rewards: 103.46784, mean: 0.04293
[32m[0906 20-04-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31335, current rewards: 108.76283, mean: 0.04421
[32m[0906 20-04-23 @Agent.py:117][0m Average action selection time: 0.3131
[32m[0906 20-04-23 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-04-23 @MBExp.py:227][0m Rewards obtained: [111.77341747665592], Lows: [41], Highs: [61], Total time: 22290.057583
[32m[0906 20-05-15 @MBExp.py:144][0m ####################################################################
[32m[0906 20-05-15 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 20-05-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31814, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-05-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31686, current rewards: -14.60309, mean: -0.24338
[32m[0906 20-05-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31653, current rewards: -4.56330, mean: -0.04148
[32m[0906 20-06-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31551, current rewards: 5.37941, mean: 0.03362
[32m[0906 20-06-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31379, current rewards: 16.31590, mean: 0.07769
[32m[0906 20-06-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31282, current rewards: 27.60833, mean: 0.10619
[32m[0906 20-06-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31224, current rewards: 37.80840, mean: 0.12196
[32m[0906 20-07-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31295, current rewards: 48.05991, mean: 0.13350
[32m[0906 20-07-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31334, current rewards: 58.31974, mean: 0.14224
[32m[0906 20-07-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31361, current rewards: 68.56687, mean: 0.14906
[32m[0906 20-07-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31384, current rewards: 78.80622, mean: 0.15452
[32m[0906 20-08-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31397, current rewards: 53.77893, mean: 0.09603
[32m[0906 20-08-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31415, current rewards: 55.19765, mean: 0.09049
[32m[0906 20-08-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31429, current rewards: 22.73444, mean: 0.03445
[32m[0906 20-08-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31442, current rewards: 17.58099, mean: 0.02476
[32m[0906 20-09-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31454, current rewards: -1.29514, mean: -0.00170
[32m[0906 20-09-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31465, current rewards: -36.27912, mean: -0.04479
[32m[0906 20-09-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31472, current rewards: -69.35076, mean: -0.08064
[32m[0906 20-10-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31480, current rewards: -91.70006, mean: -0.10077
[32m[0906 20-10-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31492, current rewards: -94.78237, mean: -0.09873
[32m[0906 20-10-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31501, current rewards: -127.68851, mean: -0.12642
[32m[0906 20-10-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31501, current rewards: -163.08684, mean: -0.15386
[32m[0906 20-11-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31506, current rewards: -195.72935, mean: -0.17633
[32m[0906 20-11-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31509, current rewards: -215.58110, mean: -0.18585
[32m[0906 20-11-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31515, current rewards: -243.43574, mean: -0.20119
[32m[0906 20-11-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31515, current rewards: -278.76649, mean: -0.22124
[32m[0906 20-12-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31512, current rewards: -313.71208, mean: -0.23947
[32m[0906 20-12-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31512, current rewards: -348.40977, mean: -0.25618
[32m[0906 20-12-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31510, current rewards: -382.87037, mean: -0.27154
[32m[0906 20-12-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31504, current rewards: -415.89327, mean: -0.28486
[32m[0906 20-13-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31504, current rewards: -451.01489, mean: -0.29869
[32m[0906 20-13-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31514, current rewards: -486.20905, mean: -0.31167
[32m[0906 20-13-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31628, current rewards: -520.52768, mean: -0.32331
[32m[0906 20-14-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31734, current rewards: -555.70896, mean: -0.33476
[32m[0906 20-14-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31838, current rewards: -590.05282, mean: -0.34506
[32m[0906 20-14-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31938, current rewards: -625.16426, mean: -0.35521
[32m[0906 20-14-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32032, current rewards: -655.99555, mean: -0.36243
[32m[0906 20-15-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32116, current rewards: -652.92086, mean: -0.35103
[32m[0906 20-15-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32197, current rewards: -642.85641, mean: -0.33657
[32m[0906 20-15-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32273, current rewards: -631.50970, mean: -0.32220
[32m[0906 20-16-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32346, current rewards: -620.06851, mean: -0.30849
[32m[0906 20-16-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32413, current rewards: -608.60019, mean: -0.29544
[32m[0906 20-16-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32477, current rewards: -597.00926, mean: -0.28294
[32m[0906 20-16-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32541, current rewards: -586.00146, mean: -0.27130
[32m[0906 20-17-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32587, current rewards: -647.63371, mean: -0.29305
[32m[0906 20-17-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32627, current rewards: -747.63371, mean: -0.33081
[32m[0906 20-17-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32664, current rewards: -847.63371, mean: -0.36694
[32m[0906 20-18-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32698, current rewards: -947.63371, mean: -0.40154
[32m[0906 20-18-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32717, current rewards: -1047.63371, mean: -0.43470
[32m[0906 20-18-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32730, current rewards: -1147.63371, mean: -0.46652
[32m[0906 20-18-55 @Agent.py:117][0m Average action selection time: 0.3274
[32m[0906 20-18-55 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-18-55 @MBExp.py:227][0m Rewards obtained: [-1227.6337127084018], Lows: [783], Highs: [40], Total time: 23109.210034000003
[32m[0906 20-19-55 @MBExp.py:144][0m ####################################################################
[32m[0906 20-19-55 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 20-19-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35479, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-20-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35326, current rewards: -51.88608, mean: -0.86477
[32m[0906 20-20-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35306, current rewards: -104.01010, mean: -0.94555
[32m[0906 20-20-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35225, current rewards: -151.66961, mean: -0.94794
[32m[0906 20-21-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35030, current rewards: -190.33175, mean: -0.90634
[32m[0906 20-21-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34915, current rewards: -227.16724, mean: -0.87372
[32m[0906 20-21-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34839, current rewards: -305.45044, mean: -0.98532
[32m[0906 20-22-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34892, current rewards: -299.27034, mean: -0.83131
[32m[0906 20-22-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34959, current rewards: -295.12443, mean: -0.71982
[32m[0906 20-22-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34994, current rewards: -290.98030, mean: -0.63257
[32m[0906 20-22-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35022, current rewards: -286.83836, mean: -0.56243
[32m[0906 20-23-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35039, current rewards: -282.69614, mean: -0.50481
[32m[0906 20-23-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35049, current rewards: -278.55649, mean: -0.45665
[32m[0906 20-23-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35064, current rewards: -274.41189, mean: -0.41578
[32m[0906 20-24-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35075, current rewards: -270.26931, mean: -0.38066
[32m[0906 20-24-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35083, current rewards: -278.62217, mean: -0.36661
[32m[0906 20-24-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35091, current rewards: -303.52558, mean: -0.37472
[32m[0906 20-24-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35100, current rewards: -296.25136, mean: -0.34448
[32m[0906 20-25-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35104, current rewards: -288.97715, mean: -0.31756
[32m[0906 20-25-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35108, current rewards: -281.70294, mean: -0.29344
[32m[0906 20-25-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35112, current rewards: -302.20587, mean: -0.29921
[32m[0906 20-26-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35118, current rewards: -352.20587, mean: -0.33227
[32m[0906 20-26-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35120, current rewards: -402.20587, mean: -0.36235
[32m[0906 20-26-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35122, current rewards: -452.20587, mean: -0.38983
[32m[0906 20-27-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35121, current rewards: -502.20587, mean: -0.41505
[32m[0906 20-27-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35126, current rewards: -552.20587, mean: -0.43826
[32m[0906 20-27-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35127, current rewards: -602.20587, mean: -0.45970
[32m[0906 20-27-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35129, current rewards: -652.20587, mean: -0.47956
[32m[0906 20-28-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35129, current rewards: -702.20587, mean: -0.49802
[32m[0906 20-28-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35126, current rewards: -752.20587, mean: -0.51521
[32m[0906 20-28-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35126, current rewards: -802.20587, mean: -0.53126
[32m[0906 20-29-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35127, current rewards: -852.20587, mean: -0.54629
[32m[0906 20-29-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35125, current rewards: -902.20587, mean: -0.56038
[32m[0906 20-29-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35125, current rewards: -952.20587, mean: -0.57362
[32m[0906 20-29-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35127, current rewards: -1002.20587, mean: -0.58609
[32m[0906 20-30-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35125, current rewards: -1052.20587, mean: -0.59784
[32m[0906 20-30-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35122, current rewards: -1102.20587, mean: -0.60895
[32m[0906 20-30-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35120, current rewards: -1152.20587, mean: -0.61947
[32m[0906 20-31-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35118, current rewards: -1202.20587, mean: -0.62943
[32m[0906 20-31-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35120, current rewards: -1252.20587, mean: -0.63888
[32m[0906 20-31-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35118, current rewards: -1302.20587, mean: -0.64786
[32m[0906 20-31-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35116, current rewards: -1352.20587, mean: -0.65641
[32m[0906 20-32-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35115, current rewards: -1402.20587, mean: -0.66455
[32m[0906 20-32-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35114, current rewards: -1452.20587, mean: -0.67232
[32m[0906 20-32-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35101, current rewards: -1502.20587, mean: -0.67973
[32m[0906 20-33-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35085, current rewards: -1552.20587, mean: -0.68682
[32m[0906 20-33-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35067, current rewards: -1602.20587, mean: -0.69360
[32m[0906 20-33-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35046, current rewards: -1652.20587, mean: -0.70009
[32m[0906 20-33-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35015, current rewards: -1702.20587, mean: -0.70631
[32m[0906 20-34-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34980, current rewards: -1752.20587, mean: -0.71228
[32m[0906 20-34-29 @Agent.py:117][0m Average action selection time: 0.3495
[32m[0906 20-34-29 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-34-29 @MBExp.py:227][0m Rewards obtained: [-1792.2058689041287], Lows: [177], Highs: [1535], Total time: 23983.6942
[32m[0906 20-35-32 @MBExp.py:144][0m ####################################################################
[32m[0906 20-35-32 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 20-35-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35398, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-35-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35293, current rewards: -16.49341, mean: -0.27489
[32m[0906 20-36-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35280, current rewards: -12.15302, mean: -0.11048
[32m[0906 20-36-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35204, current rewards: -7.81112, mean: -0.04882
[32m[0906 20-36-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35700, current rewards: -1.78405, mean: -0.00850
[32m[0906 20-37-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35460, current rewards: 5.70930, mean: 0.02196
[32m[0906 20-37-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35301, current rewards: 9.96917, mean: 0.03216
[32m[0906 20-37-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35270, current rewards: 14.22797, mean: 0.03952
[32m[0906 20-37-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35281, current rewards: 18.48579, mean: 0.04509
[32m[0906 20-38-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35278, current rewards: 22.74553, mean: 0.04945
[32m[0906 20-38-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35280, current rewards: 27.00172, mean: 0.05294
[32m[0906 20-38-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35270, current rewards: 24.45129, mean: 0.04366
[32m[0906 20-39-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35263, current rewards: 21.77874, mean: 0.03570
[32m[0906 20-39-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35266, current rewards: -10.18046, mean: -0.01542
[32m[0906 20-39-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35258, current rewards: -7.43578, mean: -0.01047
[32m[0906 20-40-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35257, current rewards: -4.83662, mean: -0.00636
[32m[0906 20-40-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35257, current rewards: -2.23670, mean: -0.00276
[32m[0906 20-40-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35253, current rewards: 0.36484, mean: 0.00042
[32m[0906 20-40-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35250, current rewards: 2.96573, mean: 0.00326
[32m[0906 20-41-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35243, current rewards: 5.56605, mean: 0.00580
[32m[0906 20-41-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35240, current rewards: 8.16660, mean: 0.00809
[32m[0906 20-41-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35233, current rewards: 10.83603, mean: 0.01022
[32m[0906 20-42-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35229, current rewards: 13.41789, mean: 0.01209
[32m[0906 20-42-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35224, current rewards: 16.00998, mean: 0.01380
[32m[0906 20-42-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35221, current rewards: 18.60198, mean: 0.01537
[32m[0906 20-42-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35218, current rewards: -19.28584, mean: -0.01531
[32m[0906 20-43-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35214, current rewards: -14.62128, mean: -0.01116
[32m[0906 20-43-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35212, current rewards: -9.95533, mean: -0.00732
[32m[0906 20-43-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35211, current rewards: -5.28973, mean: -0.00375
[32m[0906 20-44-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35209, current rewards: -0.62977, mean: -0.00043
[32m[0906 20-44-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35210, current rewards: 4.03489, mean: 0.00267
[32m[0906 20-44-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35223, current rewards: 8.69425, mean: 0.00557
[32m[0906 20-45-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35283, current rewards: 13.34860, mean: 0.00829
[32m[0906 20-45-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35350, current rewards: 18.00690, mean: 0.01085
[32m[0906 20-45-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35410, current rewards: 22.67056, mean: 0.01326
[32m[0906 20-45-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35473, current rewards: 27.33121, mean: 0.01553
[32m[0906 20-46-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35525, current rewards: 31.99559, mean: 0.01768
[32m[0906 20-46-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35577, current rewards: 36.56131, mean: 0.01966
[32m[0906 20-46-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35628, current rewards: -0.79258, mean: -0.00041
[32m[0906 20-47-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35677, current rewards: 3.22467, mean: 0.00165
[32m[0906 20-47-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35726, current rewards: 7.26627, mean: 0.00362
[32m[0906 20-47-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35770, current rewards: 11.30985, mean: 0.00549
[32m[0906 20-48-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35791, current rewards: 15.35956, mean: 0.00728
[32m[0906 20-48-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35775, current rewards: 19.40542, mean: 0.00898
[32m[0906 20-48-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35745, current rewards: 23.45022, mean: 0.01061
[32m[0906 20-48-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35714, current rewards: 28.13014, mean: 0.01245
[32m[0906 20-49-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35685, current rewards: 32.34455, mean: 0.01400
[32m[0906 20-49-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35651, current rewards: 36.40575, mean: 0.01543
[32m[0906 20-49-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35609, current rewards: 40.46483, mean: 0.01679
[32m[0906 20-50-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35563, current rewards: 44.52844, mean: 0.01810
[32m[0906 20-50-20 @Agent.py:117][0m Average action selection time: 0.3553
[32m[0906 20-50-20 @Agent.py:118][0m Rollout length: 2520
[32m[0906 20-50-20 @MBExp.py:227][0m Rewards obtained: [47.77683265862183], Lows: [40], Highs: [63], Total time: 24872.544840000002
[32m[0906 20-51-25 @MBExp.py:144][0m ####################################################################
[32m[0906 20-51-25 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 20-51-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35482, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-51-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35273, current rewards: -17.06239, mean: -0.28437
[32m[0906 20-52-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35260, current rewards: -10.65561, mean: -0.09687
[32m[0906 20-52-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35138, current rewards: -3.72770, mean: -0.02330
[32m[0906 20-52-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34954, current rewards: 9.04869, mean: 0.04309
[32m[0906 20-52-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34844, current rewards: 15.47473, mean: 0.05952
[32m[0906 20-53-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34772, current rewards: 21.85346, mean: 0.07050
[32m[0906 20-53-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34811, current rewards: 28.22760, mean: 0.07841
[32m[0906 20-53-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34861, current rewards: 34.60465, mean: 0.08440
[32m[0906 20-54-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34901, current rewards: 40.97965, mean: 0.08909
[32m[0906 20-54-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34925, current rewards: 23.50046, mean: 0.04608
[32m[0906 20-54-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34946, current rewards: 30.21056, mean: 0.05395
[32m[0906 20-54-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34965, current rewards: 38.85216, mean: 0.06369
[32m[0906 20-55-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34985, current rewards: 45.13723, mean: 0.06839
[32m[0906 20-55-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35003, current rewards: 51.44480, mean: 0.07246
[32m[0906 20-55-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35019, current rewards: 57.75452, mean: 0.07599
[32m[0906 20-56-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35026, current rewards: 64.05203, mean: 0.07908
[32m[0906 20-56-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35033, current rewards: 68.23594, mean: 0.07934
[32m[0906 20-56-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35041, current rewards: 33.50205, mean: 0.03682
[32m[0906 20-57-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35051, current rewards: 38.87622, mean: 0.04050
[32m[0906 20-57-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35060, current rewards: 46.90910, mean: 0.04644
[32m[0906 20-57-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35062, current rewards: 36.23597, mean: 0.03418
[32m[0906 20-57-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35070, current rewards: 35.10830, mean: 0.03163
[32m[0906 20-58-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35071, current rewards: 39.65593, mean: 0.03419
[32m[0906 20-58-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35077, current rewards: 44.20314, mean: 0.03653
[32m[0906 20-58-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35077, current rewards: 48.75231, mean: 0.03869
[32m[0906 20-59-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35080, current rewards: 53.29841, mean: 0.04069
[32m[0906 20-59-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35078, current rewards: 57.84457, mean: 0.04253
[32m[0906 20-59-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35082, current rewards: 61.63343, mean: 0.04371
[32m[0906 20-59-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35085, current rewards: 42.23047, mean: 0.02892
[32m[0906 21-00-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35083, current rewards: 46.48917, mean: 0.03079
[32m[0906 21-00-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35083, current rewards: 50.77546, mean: 0.03255
[32m[0906 21-00-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35081, current rewards: 55.06940, mean: 0.03420
[32m[0906 21-01-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35081, current rewards: 59.36765, mean: 0.03576
[32m[0906 21-01-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35081, current rewards: 63.66155, mean: 0.03723
[32m[0906 21-01-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35081, current rewards: 67.96116, mean: 0.03861
[32m[0906 21-02-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35080, current rewards: 31.05176, mean: 0.01716
[32m[0906 21-02-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35078, current rewards: 35.30886, mean: 0.01898
[32m[0906 21-02-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35078, current rewards: 29.68297, mean: 0.01554
[32m[0906 21-02-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35080, current rewards: 20.13800, mean: 0.01027
[32m[0906 21-03-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35084, current rewards: -17.26066, mean: -0.00859
[32m[0906 21-03-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35085, current rewards: -10.70511, mean: -0.00520
[32m[0906 21-03-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35087, current rewards: -4.43661, mean: -0.00210
[32m[0906 21-04-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35086, current rewards: 1.80928, mean: 0.00084
[32m[0906 21-04-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35074, current rewards: 9.07054, mean: 0.00410
[32m[0906 21-04-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35060, current rewards: 17.76069, mean: 0.00786
[32m[0906 21-04-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35046, current rewards: 24.28450, mean: 0.01051
[32m[0906 21-05-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35025, current rewards: 30.81135, mean: 0.01306
[32m[0906 21-05-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34992, current rewards: 37.33761, mean: 0.01549
[32m[0906 21-05-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34958, current rewards: 37.08075, mean: 0.01507
[32m[0906 21-05-59 @Agent.py:117][0m Average action selection time: 0.3493
[32m[0906 21-05-59 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-05-59 @MBExp.py:227][0m Rewards obtained: [22.128335012197105], Lows: [61], Highs: [126], Total time: 25746.532648000004
[32m[0906 21-07-05 @MBExp.py:144][0m ####################################################################
[32m[0906 21-07-05 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 21-07-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35391, current rewards: 0.59203, mean: 0.05920
[32m[0906 21-07-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35392, current rewards: 5.16613, mean: 0.08610
[32m[0906 21-07-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35299, current rewards: 13.27220, mean: 0.12066
[32m[0906 21-08-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35173, current rewards: 18.16476, mean: 0.11353
[32m[0906 21-08-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34991, current rewards: 23.81691, mean: 0.11341
[32m[0906 21-08-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34892, current rewards: 29.48701, mean: 0.11341
[32m[0906 21-08-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34825, current rewards: 35.17144, mean: 0.11346
[32m[0906 21-09-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34844, current rewards: 40.85169, mean: 0.11348
[32m[0906 21-09-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34901, current rewards: 46.52802, mean: 0.11348
[32m[0906 21-09-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34939, current rewards: 52.20537, mean: 0.11349
[32m[0906 21-10-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34967, current rewards: 57.88439, mean: 0.11350
[32m[0906 21-10-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34986, current rewards: 43.25430, mean: 0.07724
[32m[0906 21-10-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35010, current rewards: 52.02295, mean: 0.08528
[32m[0906 21-10-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35028, current rewards: 60.28597, mean: 0.09134
[32m[0906 21-11-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35042, current rewards: 45.27619, mean: 0.06377
[32m[0906 21-11-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35049, current rewards: 62.75840, mean: 0.08258
[32m[0906 21-11-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35059, current rewards: 79.01276, mean: 0.09755
[32m[0906 21-12-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35063, current rewards: 95.29409, mean: 0.11081
[32m[0906 21-12-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35073, current rewards: 111.55653, mean: 0.12259
[32m[0906 21-12-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35081, current rewards: 128.71886, mean: 0.13408
[32m[0906 21-12-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35083, current rewards: 145.97377, mean: 0.14453
[32m[0906 21-13-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35088, current rewards: 163.21476, mean: 0.15398
[32m[0906 21-13-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35092, current rewards: 180.40995, mean: 0.16253
[32m[0906 21-13-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35093, current rewards: 197.60926, mean: 0.17035
[32m[0906 21-14-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35097, current rewards: 214.83150, mean: 0.17755
[32m[0906 21-14-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35105, current rewards: 150.39490, mean: 0.11936
[32m[0906 21-14-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35104, current rewards: 55.88376, mean: 0.04266
[32m[0906 21-15-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35106, current rewards: -38.36715, mean: -0.02821
[32m[0906 21-15-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35106, current rewards: -138.36715, mean: -0.09813
[32m[0906 21-15-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35106, current rewards: -238.36715, mean: -0.16327
[32m[0906 21-15-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35107, current rewards: -338.36715, mean: -0.22408
[32m[0906 21-16-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35107, current rewards: -438.36715, mean: -0.28100
[32m[0906 21-16-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35109, current rewards: -538.36715, mean: -0.33439
[32m[0906 21-16-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35110, current rewards: -619.88886, mean: -0.37343
[32m[0906 21-17-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35116, current rewards: -615.41201, mean: -0.35989
[32m[0906 21-17-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35117, current rewards: -609.73381, mean: -0.34644
[32m[0906 21-17-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35118, current rewards: -605.49441, mean: -0.33453
[32m[0906 21-17-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35117, current rewards: -599.82497, mean: -0.32249
[32m[0906 21-18-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35114, current rewards: -594.17619, mean: -0.31109
[32m[0906 21-18-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35115, current rewards: -588.52979, mean: -0.30027
[32m[0906 21-18-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35116, current rewards: -604.39614, mean: -0.30069
[32m[0906 21-19-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35116, current rewards: -598.29397, mean: -0.29043
[32m[0906 21-19-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35116, current rewards: -592.63548, mean: -0.28087
[32m[0906 21-19-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35114, current rewards: -586.98361, mean: -0.27175
[32m[0906 21-20-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35101, current rewards: -582.53305, mean: -0.26359
[32m[0906 21-20-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35084, current rewards: -576.80192, mean: -0.25522
[32m[0906 21-20-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35067, current rewards: -571.29833, mean: -0.24732
[32m[0906 21-20-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35045, current rewards: -565.79467, mean: -0.23974
[32m[0906 21-21-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35010, current rewards: -560.28577, mean: -0.23248
[32m[0906 21-21-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34976, current rewards: -541.57513, mean: -0.22015
[32m[0906 21-21-39 @Agent.py:117][0m Average action selection time: 0.3495
[32m[0906 21-21-39 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-21-39 @MBExp.py:227][0m Rewards obtained: [-536.8760936152593], Lows: [434], Highs: [40], Total time: 26620.919975000004
[32m[0906 21-22-47 @MBExp.py:144][0m ####################################################################
[32m[0906 21-22-47 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 21-22-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35429, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-23-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35385, current rewards: -17.31818, mean: -0.28864
[32m[0906 21-23-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35349, current rewards: -13.00047, mean: -0.11819
[32m[0906 21-23-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35216, current rewards: -8.73307, mean: -0.05458
[32m[0906 21-24-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35015, current rewards: -4.58983, mean: -0.02186
[32m[0906 21-24-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34905, current rewards: -0.44618, mean: -0.00172
[32m[0906 21-24-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34828, current rewards: 3.69917, mean: 0.01193
[32m[0906 21-24-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34829, current rewards: 7.84441, mean: 0.02179
[32m[0906 21-25-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34891, current rewards: 11.98537, mean: 0.02923
[32m[0906 21-25-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34936, current rewards: 16.12550, mean: 0.03506
[32m[0906 21-25-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34975, current rewards: -19.42341, mean: -0.03809
[32m[0906 21-26-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35006, current rewards: -28.93410, mean: -0.05167
[32m[0906 21-26-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35026, current rewards: -20.63398, mean: -0.03383
[32m[0906 21-26-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35042, current rewards: -12.33386, mean: -0.01869
[32m[0906 21-26-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35057, current rewards: -4.03374, mean: -0.00568
[32m[0906 21-27-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35060, current rewards: 4.26638, mean: 0.00561
[32m[0906 21-27-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35069, current rewards: 12.56650, mean: 0.01551
[32m[0906 21-27-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35080, current rewards: 20.86662, mean: 0.02426
[32m[0906 21-28-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35087, current rewards: 8.17870, mean: 0.00899
[32m[0906 21-28-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35092, current rewards: -41.82130, mean: -0.04356
[32m[0906 21-28-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35099, current rewards: -91.82130, mean: -0.09091
[32m[0906 21-29-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35105, current rewards: -141.82130, mean: -0.13379
[32m[0906 21-29-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35110, current rewards: -191.82130, mean: -0.17281
[32m[0906 21-29-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35118, current rewards: -241.82130, mean: -0.20847
[32m[0906 21-29-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35122, current rewards: -291.82130, mean: -0.24117
[32m[0906 21-30-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35126, current rewards: -341.82130, mean: -0.27129
[32m[0906 21-30-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35128, current rewards: -391.82130, mean: -0.29910
[32m[0906 21-30-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35132, current rewards: -441.82130, mean: -0.32487
[32m[0906 21-31-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35132, current rewards: -491.82130, mean: -0.34881
[32m[0906 21-31-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35134, current rewards: -541.82130, mean: -0.37111
[32m[0906 21-31-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35137, current rewards: -591.82130, mean: -0.39193
[32m[0906 21-31-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35141, current rewards: -641.82130, mean: -0.41142
[32m[0906 21-32-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35141, current rewards: -691.82130, mean: -0.42970
[32m[0906 21-32-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35143, current rewards: -741.82130, mean: -0.44688
[32m[0906 21-32-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35141, current rewards: -791.82130, mean: -0.46305
[32m[0906 21-33-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35142, current rewards: -841.82130, mean: -0.47831
[32m[0906 21-33-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35142, current rewards: -891.82130, mean: -0.49272
[32m[0906 21-33-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35141, current rewards: -941.82130, mean: -0.50636
[32m[0906 21-33-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35144, current rewards: -991.82130, mean: -0.51928
[32m[0906 21-34-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35144, current rewards: -1041.82130, mean: -0.53154
[32m[0906 21-34-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35146, current rewards: -1091.82130, mean: -0.54319
[32m[0906 21-34-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35146, current rewards: -1141.82130, mean: -0.55428
[32m[0906 21-35-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35146, current rewards: -1191.82130, mean: -0.56484
[32m[0906 21-35-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35148, current rewards: -1241.82130, mean: -0.57492
[32m[0906 21-35-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35137, current rewards: -1291.82130, mean: -0.58453
[32m[0906 21-36-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35120, current rewards: -1341.82130, mean: -0.59373
[32m[0906 21-36-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35104, current rewards: -1391.82130, mean: -0.60252
[32m[0906 21-36-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35084, current rewards: -1441.82130, mean: -0.61094
[32m[0906 21-36-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35046, current rewards: -1491.82130, mean: -0.61901
[32m[0906 21-37-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35012, current rewards: -1541.82130, mean: -0.62676
[32m[0906 21-37-23 @Agent.py:117][0m Average action selection time: 0.3499
[32m[0906 21-37-23 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-37-23 @MBExp.py:227][0m Rewards obtained: [-1581.8213005668756], Lows: [29], Highs: [1629], Total time: 27496.244490000005
[32m[0906 21-38-33 @MBExp.py:144][0m ####################################################################
[32m[0906 21-38-33 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 21-38-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35358, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-38-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35347, current rewards: -16.79792, mean: -0.27997
[32m[0906 21-39-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35215, current rewards: -7.85352, mean: -0.07140
[32m[0906 21-39-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35056, current rewards: -3.02327, mean: -0.01890
[32m[0906 21-39-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34891, current rewards: 1.80520, mean: 0.00860
[32m[0906 21-40-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34789, current rewards: -10.14026, mean: -0.03900
[32m[0906 21-40-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34731, current rewards: -29.99672, mean: -0.09676
[32m[0906 21-40-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34724, current rewards: -25.47764, mean: -0.07077
[32m[0906 21-40-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34798, current rewards: -20.96961, mean: -0.05115
[32m[0906 21-41-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34864, current rewards: -16.46163, mean: -0.03579
[32m[0906 21-41-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34906, current rewards: -11.43510, mean: -0.02242
[32m[0906 21-41-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34939, current rewards: -6.90809, mean: -0.01234
[32m[0906 21-42-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34972, current rewards: -2.40534, mean: -0.00394
[32m[0906 21-42-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34980, current rewards: 2.09597, mean: 0.00318
[32m[0906 21-42-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35004, current rewards: 6.59922, mean: 0.00929
[32m[0906 21-42-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35020, current rewards: -11.96516, mean: -0.01574
[32m[0906 21-43-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35039, current rewards: -5.73586, mean: -0.00708
[32m[0906 21-43-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35052, current rewards: 0.45469, mean: 0.00053
[32m[0906 21-43-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35061, current rewards: 8.03075, mean: 0.00882
[32m[0906 21-44-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35073, current rewards: 14.52433, mean: 0.01513
[32m[0906 21-44-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35088, current rewards: 21.05984, mean: 0.02085
[32m[0906 21-44-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35098, current rewards: -15.01691, mean: -0.01417
[32m[0906 21-45-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35104, current rewards: -9.41643, mean: -0.00848
[32m[0906 21-45-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35109, current rewards: -3.76317, mean: -0.00324
[32m[0906 21-45-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35112, current rewards: 1.89395, mean: 0.00157
[32m[0906 21-45-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35119, current rewards: 7.55052, mean: 0.00599
[32m[0906 21-46-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35125, current rewards: 13.20727, mean: 0.01008
[32m[0906 21-46-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35125, current rewards: 18.85952, mean: 0.01387
[32m[0906 21-46-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35128, current rewards: 24.51001, mean: 0.01738
[32m[0906 21-47-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35128, current rewards: 30.16344, mean: 0.02066
[32m[0906 21-47-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35130, current rewards: 35.81535, mean: 0.02372
[32m[0906 21-47-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35132, current rewards: -0.84727, mean: -0.00054
[32m[0906 21-47-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35128, current rewards: 3.80752, mean: 0.00236
[32m[0906 21-48-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35128, current rewards: 8.31293, mean: 0.00501
[32m[0906 21-48-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35132, current rewards: 12.39629, mean: 0.00725
[32m[0906 21-48-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35134, current rewards: 16.91717, mean: 0.00961
[32m[0906 21-49-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35130, current rewards: 21.42106, mean: 0.01183
[32m[0906 21-49-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35130, current rewards: 25.92160, mean: 0.01394
[32m[0906 21-49-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35130, current rewards: 30.42265, mean: 0.01593
[32m[0906 21-50-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35132, current rewards: 34.92161, mean: 0.01782
[32m[0906 21-50-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35130, current rewards: 39.42492, mean: 0.01961
[32m[0906 21-50-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35130, current rewards: 21.97085, mean: 0.01067
[32m[0906 21-50-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35132, current rewards: 26.17956, mean: 0.01241
[32m[0906 21-51-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35131, current rewards: 30.57119, mean: 0.01415
[32m[0906 21-51-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35118, current rewards: 34.99621, mean: 0.01584
[32m[0906 21-51-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35100, current rewards: 39.42072, mean: 0.01744
[32m[0906 21-52-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35084, current rewards: 2.06879, mean: 0.00090
[32m[0906 21-52-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35063, current rewards: 6.59534, mean: 0.00279
[32m[0906 21-52-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35022, current rewards: 11.43617, mean: 0.00475
[32m[0906 21-52-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34988, current rewards: 16.27612, mean: 0.00662
[32m[0906 21-53-07 @Agent.py:117][0m Average action selection time: 0.3496
[32m[0906 21-53-07 @Agent.py:118][0m Rollout length: 2520
[32m[0906 21-53-08 @MBExp.py:227][0m Rewards obtained: [20.342473661405897], Lows: [80], Highs: [61], Total time: 28370.965395000003
[32m[0906 21-54-20 @MBExp.py:144][0m ####################################################################
[32m[0906 21-54-20 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 21-54-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35379, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-54-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35349, current rewards: -15.30506, mean: -0.25508
[32m[0906 21-54-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35244, current rewards: -4.80252, mean: -0.04366
[32m[0906 21-55-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35071, current rewards: 7.46070, mean: 0.04663
[32m[0906 21-55-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34915, current rewards: 16.56786, mean: 0.07889
[32m[0906 21-55-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34803, current rewards: 27.12503, mean: 0.10433
[32m[0906 21-56-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34745, current rewards: 38.82092, mean: 0.12523
[32m[0906 21-56-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34735, current rewards: 47.14610, mean: 0.13096
[32m[0906 21-56-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34817, current rewards: 58.20305, mean: 0.14196
[32m[0906 21-57-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34869, current rewards: 26.19832, mean: 0.05695
[32m[0906 21-57-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34906, current rewards: 12.47242, mean: 0.02446
[32m[0906 21-57-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34935, current rewards: 14.62227, mean: 0.02611
[32m[0906 21-57-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34964, current rewards: 14.86513, mean: 0.02437
[32m[0906 21-58-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34983, current rewards: 6.71760, mean: 0.01018
[32m[0906 21-58-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35007, current rewards: 12.79503, mean: 0.01802
[32m[0906 21-58-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35022, current rewards: 20.39293, mean: 0.02683
[32m[0906 21-59-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35038, current rewards: 26.30245, mean: 0.03247
[32m[0906 21-59-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35049, current rewards: 31.71385, mean: 0.03688
[32m[0906 21-59-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35061, current rewards: 37.17977, mean: 0.04086
[32m[0906 21-59-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35064, current rewards: 42.68100, mean: 0.04446
[32m[0906 22-00-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35070, current rewards: 33.41051, mean: 0.03308
[32m[0906 22-00-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35072, current rewards: 11.12905, mean: 0.01050
[32m[0906 22-00-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35079, current rewards: 26.31655, mean: 0.02371
[32m[0906 22-01-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35085, current rewards: 44.21828, mean: 0.03812
[32m[0906 22-01-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35086, current rewards: 62.14824, mean: 0.05136
[32m[0906 22-01-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35089, current rewards: 29.03067, mean: 0.02304
[32m[0906 22-02-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35090, current rewards: 55.18717, mean: 0.04213
[32m[0906 22-02-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35091, current rewards: 44.08291, mean: 0.03241
[32m[0906 22-02-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35088, current rewards: 55.28404, mean: 0.03921
[32m[0906 22-02-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35089, current rewards: 67.40940, mean: 0.04617
[32m[0906 22-03-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35090, current rewards: 79.53407, mean: 0.05267
[32m[0906 22-03-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35089, current rewards: 91.64626, mean: 0.05875
[32m[0906 22-03-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35085, current rewards: 103.76162, mean: 0.06445
[32m[0906 22-04-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35086, current rewards: 68.79812, mean: 0.04144
[32m[0906 22-04-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35085, current rewards: 74.94292, mean: 0.04383
[32m[0906 22-04-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35086, current rewards: 81.22728, mean: 0.04615
[32m[0906 22-04-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35086, current rewards: 87.51371, mean: 0.04835
[32m[0906 22-05-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35085, current rewards: 93.79991, mean: 0.05043
[32m[0906 22-05-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35085, current rewards: 100.08809, mean: 0.05240
[32m[0906 22-05-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35088, current rewards: 106.37511, mean: 0.05427
[32m[0906 22-06-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35087, current rewards: 112.66045, mean: 0.05605
[32m[0906 22-06-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35088, current rewards: 118.61913, mean: 0.05758
[32m[0906 22-06-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35087, current rewards: 100.83534, mean: 0.04779
[32m[0906 22-06-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35085, current rewards: 105.72554, mean: 0.04895
[32m[0906 22-07-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35071, current rewards: 110.62847, mean: 0.05006
[32m[0906 22-07-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35053, current rewards: 115.51233, mean: 0.05111
[32m[0906 22-07-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35035, current rewards: 120.39500, mean: 0.05212
[32m[0906 22-08-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35015, current rewards: 125.27691, mean: 0.05308
[32m[0906 22-08-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34973, current rewards: 130.16157, mean: 0.05401
[32m[0906 22-08-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34941, current rewards: 135.04612, mean: 0.05490
[32m[0906 22-08-53 @Agent.py:117][0m Average action selection time: 0.3491
[32m[0906 22-08-53 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-08-53 @MBExp.py:227][0m Rewards obtained: [98.08322999049366], Lows: [178], Highs: [60], Total time: 29244.499636000004
[32m[0906 22-10-07 @MBExp.py:144][0m ####################################################################
[32m[0906 22-10-07 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 22-10-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35431, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-10-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35330, current rewards: -25.77956, mean: -0.42966
[32m[0906 22-10-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35269, current rewards: -22.14483, mean: -0.20132
[32m[0906 22-11-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35108, current rewards: -18.34387, mean: -0.11465
[32m[0906 22-11-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34958, current rewards: -14.53610, mean: -0.06922
[32m[0906 22-11-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34859, current rewards: -10.72241, mean: -0.04124
[32m[0906 22-11-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34790, current rewards: -6.90908, mean: -0.02229
[32m[0906 22-12-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34773, current rewards: -44.47573, mean: -0.12354
[32m[0906 22-12-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34837, current rewards: -39.89100, mean: -0.09730
[32m[0906 22-12-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34872, current rewards: -35.28375, mean: -0.07670
[32m[0906 22-13-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34924, current rewards: -30.67592, mean: -0.06015
[32m[0906 22-13-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34949, current rewards: -26.07232, mean: -0.04656
[32m[0906 22-13-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34974, current rewards: -21.46279, mean: -0.03518
[32m[0906 22-13-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34991, current rewards: -16.85760, mean: -0.02554
[32m[0906 22-14-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35007, current rewards: -12.24844, mean: -0.01725
[32m[0906 22-14-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35015, current rewards: -24.01947, mean: -0.03160
[32m[0906 22-14-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35023, current rewards: -24.56176, mean: -0.03032
[32m[0906 22-15-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35028, current rewards: -19.56051, mean: -0.02274
[32m[0906 22-15-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35033, current rewards: -14.55757, mean: -0.01600
[32m[0906 22-15-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35039, current rewards: -9.55537, mean: -0.00995
[32m[0906 22-16-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35043, current rewards: -4.55786, mean: -0.00451
[32m[0906 22-16-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35048, current rewards: 0.43840, mean: 0.00041
[32m[0906 22-16-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35058, current rewards: 5.44027, mean: 0.00490
[32m[0906 22-16-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35061, current rewards: 10.43952, mean: 0.00900
[32m[0906 22-17-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35062, current rewards: 15.43969, mean: 0.01276
[32m[0906 22-17-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35064, current rewards: 20.44218, mean: 0.01622
[32m[0906 22-17-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35063, current rewards: 25.44492, mean: 0.01942
[32m[0906 22-18-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35062, current rewards: 30.44517, mean: 0.02239
[32m[0906 22-18-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35064, current rewards: 35.44302, mean: 0.02514
[32m[0906 22-18-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35063, current rewards: 40.44222, mean: 0.02770
[32m[0906 22-18-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35068, current rewards: 45.44043, mean: 0.03009
[32m[0906 22-19-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35070, current rewards: 50.44344, mean: 0.03234
[32m[0906 22-19-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35068, current rewards: 55.44736, mean: 0.03444
[32m[0906 22-19-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35070, current rewards: 56.24697, mean: 0.03388
[32m[0906 22-20-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35071, current rewards: 23.88778, mean: 0.01397
[32m[0906 22-20-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35074, current rewards: 28.93578, mean: 0.01644
[32m[0906 22-20-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35077, current rewards: 33.99246, mean: 0.01878
[32m[0906 22-21-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35078, current rewards: 39.05508, mean: 0.02100
[32m[0906 22-21-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35081, current rewards: 44.11516, mean: 0.02310
[32m[0906 22-21-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35081, current rewards: 49.18148, mean: 0.02509
[32m[0906 22-21-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35081, current rewards: 54.78941, mean: 0.02726
[32m[0906 22-22-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35083, current rewards: 40.61541, mean: 0.01972
[32m[0906 22-22-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35084, current rewards: 23.43976, mean: 0.01111
[32m[0906 22-22-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35083, current rewards: 28.21493, mean: 0.01306
[32m[0906 22-23-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35073, current rewards: 33.22588, mean: 0.01503
[32m[0906 22-23-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35058, current rewards: 38.23974, mean: 0.01692
[32m[0906 22-23-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35043, current rewards: 43.25159, mean: 0.01872
[32m[0906 22-23-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35022, current rewards: 48.26482, mean: 0.02045
[32m[0906 22-24-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34976, current rewards: 53.28118, mean: 0.02211
[32m[0906 22-24-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34942, current rewards: 56.86425, mean: 0.02312
[32m[0906 22-24-41 @Agent.py:117][0m Average action selection time: 0.3492
[32m[0906 22-24-41 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-24-41 @MBExp.py:227][0m Rewards obtained: [18.322786824564414], Lows: [73], Highs: [69], Total time: 30118.113593000005
[32m[0906 22-25-57 @MBExp.py:144][0m ####################################################################
[32m[0906 22-25-57 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 22-26-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35560, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-26-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35266, current rewards: -15.78982, mean: -0.26316
[32m[0906 22-26-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35268, current rewards: -10.68042, mean: -0.09709
[32m[0906 22-26-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35078, current rewards: -5.56259, mean: -0.03477
[32m[0906 22-27-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34918, current rewards: -0.44960, mean: -0.00214
[32m[0906 22-27-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34814, current rewards: 2.46428, mean: 0.00948
[32m[0906 22-27-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34745, current rewards: -12.02612, mean: -0.03879
[32m[0906 22-28-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34712, current rewards: -5.51793, mean: -0.01533
[32m[0906 22-28-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34784, current rewards: 4.18232, mean: 0.01020
[32m[0906 22-28-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34833, current rewards: 10.45301, mean: 0.02272
[32m[0906 22-28-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34875, current rewards: 16.71132, mean: 0.03277
[32m[0906 22-29-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34908, current rewards: 22.98131, mean: 0.04104
[32m[0906 22-29-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34946, current rewards: 29.24545, mean: 0.04794
[32m[0906 22-29-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34971, current rewards: 35.49825, mean: 0.05379
[32m[0906 22-30-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34993, current rewards: 41.76729, mean: 0.05883
[32m[0906 22-30-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35008, current rewards: 5.27566, mean: 0.00694
[32m[0906 22-30-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35015, current rewards: 11.77035, mean: 0.01453
[32m[0906 22-30-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35022, current rewards: 17.84677, mean: 0.02075
[32m[0906 22-31-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35028, current rewards: 23.90044, mean: 0.02626
[32m[0906 22-31-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35036, current rewards: -12.31263, mean: -0.01283
[32m[0906 22-31-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35047, current rewards: -6.33904, mean: -0.00628
[32m[0906 22-32-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35056, current rewards: -0.40382, mean: -0.00038
[32m[0906 22-32-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35059, current rewards: 5.52214, mean: 0.00497
[32m[0906 22-32-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35065, current rewards: 11.44732, mean: 0.00987
[32m[0906 22-33-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35069, current rewards: -25.87070, mean: -0.02138
[32m[0906 22-33-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35070, current rewards: -20.32483, mean: -0.01613
[32m[0906 22-33-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35075, current rewards: -14.40902, mean: -0.01100
[32m[0906 22-33-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35080, current rewards: -8.49056, mean: -0.00624
[32m[0906 22-34-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35081, current rewards: -2.57502, mean: -0.00183
[32m[0906 22-34-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35085, current rewards: 3.34033, mean: 0.00229
[32m[0906 22-34-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35089, current rewards: 9.25716, mean: 0.00613
[32m[0906 22-35-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35093, current rewards: -8.41496, mean: -0.00539
[32m[0906 22-35-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35097, current rewards: -2.23694, mean: -0.00139
[32m[0906 22-35-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35099, current rewards: 8.21343, mean: 0.00495
[32m[0906 22-35-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35103, current rewards: 13.76428, mean: 0.00805
[32m[0906 22-36-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35101, current rewards: 19.30480, mean: 0.01097
[32m[0906 22-36-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35100, current rewards: 24.84334, mean: 0.01373
[32m[0906 22-36-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35099, current rewards: 30.38566, mean: 0.01634
[32m[0906 22-37-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35096, current rewards: 35.92667, mean: 0.01881
[32m[0906 22-37-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35094, current rewards: 41.47618, mean: 0.02116
[32m[0906 22-37-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35093, current rewards: 47.02035, mean: 0.02339
[32m[0906 22-38-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35092, current rewards: 52.12364, mean: 0.02530
[32m[0906 22-38-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35093, current rewards: 57.65808, mean: 0.02733
[32m[0906 22-38-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35089, current rewards: 63.19611, mean: 0.02926
[32m[0906 22-38-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35080, current rewards: 68.74441, mean: 0.03111
[32m[0906 22-39-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35062, current rewards: 74.28836, mean: 0.03287
[32m[0906 22-39-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35047, current rewards: 48.16715, mean: 0.02085
[32m[0906 22-39-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35026, current rewards: 43.08127, mean: 0.01825
[32m[0906 22-40-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34980, current rewards: 48.98903, mean: 0.02033
[32m[0906 22-40-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34945, current rewards: 52.80606, mean: 0.02147
[32m[0906 22-40-31 @Agent.py:117][0m Average action selection time: 0.3492
[32m[0906 22-40-31 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-40-31 @MBExp.py:227][0m Rewards obtained: [57.08528569702068], Lows: [80], Highs: [61], Total time: 30991.771674000007
[32m[0906 22-41-49 @MBExp.py:144][0m ####################################################################
[32m[0906 22-41-49 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 22-41-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35484, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-42-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35151, current rewards: -16.36174, mean: -0.27270
[32m[0906 22-42-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35158, current rewards: -12.74260, mean: -0.11584
[32m[0906 22-42-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35018, current rewards: -9.21924, mean: -0.05762
[32m[0906 22-43-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34865, current rewards: -26.80786, mean: -0.12766
[32m[0906 22-43-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34779, current rewards: -22.98477, mean: -0.08840
[32m[0906 22-43-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34710, current rewards: -19.30960, mean: -0.06229
[32m[0906 22-43-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34670, current rewards: -15.63483, mean: -0.04343
[32m[0906 22-44-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34755, current rewards: -12.00487, mean: -0.02928
[32m[0906 22-44-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34814, current rewards: -49.76176, mean: -0.10818
[32m[0906 22-44-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34845, current rewards: -40.33685, mean: -0.07909
[32m[0906 22-45-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34875, current rewards: -34.98590, mean: -0.06247
[32m[0906 22-45-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34908, current rewards: -29.67143, mean: -0.04864
[32m[0906 22-45-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34931, current rewards: -26.46292, mean: -0.04010
[32m[0906 22-45-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34950, current rewards: -57.81998, mean: -0.08144
[32m[0906 22-46-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34958, current rewards: -50.54576, mean: -0.06651
[32m[0906 22-46-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34971, current rewards: -46.54360, mean: -0.05746
[32m[0906 22-46-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34974, current rewards: -43.16093, mean: -0.05019
[32m[0906 22-47-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34984, current rewards: -39.77825, mean: -0.04371
[32m[0906 22-47-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34999, current rewards: -78.03406, mean: -0.08129
[32m[0906 22-47-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35007, current rewards: -128.03406, mean: -0.12677
[32m[0906 22-48-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35008, current rewards: -178.03406, mean: -0.16796
[32m[0906 22-48-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35011, current rewards: -228.03406, mean: -0.20544
[32m[0906 22-48-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35013, current rewards: -278.03406, mean: -0.23968
[32m[0906 22-48-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35022, current rewards: -328.03406, mean: -0.27110
[32m[0906 22-49-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35029, current rewards: -378.03406, mean: -0.30003
[32m[0906 22-49-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35039, current rewards: -428.03406, mean: -0.32674
[32m[0906 22-49-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35046, current rewards: -478.03406, mean: -0.35150
[32m[0906 22-50-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35045, current rewards: -528.03406, mean: -0.37449
[32m[0906 22-50-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35049, current rewards: -578.03406, mean: -0.39591
[32m[0906 22-50-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35052, current rewards: -628.03406, mean: -0.41592
[32m[0906 22-50-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35055, current rewards: -678.03406, mean: -0.43464
[32m[0906 22-51-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35057, current rewards: -728.03406, mean: -0.45220
[32m[0906 22-51-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35062, current rewards: -778.03406, mean: -0.46870
[32m[0906 22-51-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35063, current rewards: -828.03406, mean: -0.48423
[32m[0906 22-52-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35064, current rewards: -878.03406, mean: -0.49888
[32m[0906 22-52-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35066, current rewards: -928.03406, mean: -0.51273
[32m[0906 22-52-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35068, current rewards: -978.03406, mean: -0.52582
[32m[0906 22-52-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35070, current rewards: -1028.03406, mean: -0.53824
[32m[0906 22-53-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35076, current rewards: -1078.03406, mean: -0.55002
[32m[0906 22-53-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35076, current rewards: -1128.03406, mean: -0.56121
[32m[0906 22-53-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35078, current rewards: -1178.03406, mean: -0.57186
[32m[0906 22-54-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35080, current rewards: -1228.03406, mean: -0.58201
[32m[0906 22-54-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35082, current rewards: -1278.03406, mean: -0.59168
[32m[0906 22-54-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35073, current rewards: -1328.03406, mean: -0.60092
[32m[0906 22-55-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35057, current rewards: -1378.03406, mean: -0.60975
[32m[0906 22-55-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35043, current rewards: -1428.03406, mean: -0.61820
[32m[0906 22-55-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35024, current rewards: -1478.03406, mean: -0.62629
[32m[0906 22-55-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34981, current rewards: -1528.03406, mean: -0.63404
[32m[0906 22-56-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34947, current rewards: -1578.03406, mean: -0.64148
[32m[0906 22-56-23 @Agent.py:117][0m Average action selection time: 0.3492
[32m[0906 22-56-23 @Agent.py:118][0m Rollout length: 2520
[32m[0906 22-56-23 @MBExp.py:227][0m Rewards obtained: [-1618.0340635401083], Lows: [40], Highs: [1619], Total time: 31865.509884000006
[32m[0906 22-57-43 @MBExp.py:144][0m ####################################################################
[32m[0906 22-57-43 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 22-57-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35292, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-58-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35409, current rewards: -16.95871, mean: -0.28265
[32m[0906 22-58-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35351, current rewards: -13.91560, mean: -0.12651
[32m[0906 22-58-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35167, current rewards: -11.04325, mean: -0.06902
[32m[0906 22-58-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34976, current rewards: -8.16825, mean: -0.03890
[32m[0906 22-59-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34856, current rewards: -4.65604, mean: -0.01791
[32m[0906 22-59-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34775, current rewards: 1.05784, mean: 0.00341
[32m[0906 22-59-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34719, current rewards: 5.69384, mean: 0.01582
[32m[0906 23-00-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34786, current rewards: 10.44137, mean: 0.02547
[32m[0906 23-00-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34831, current rewards: 15.52374, mean: 0.03375
[32m[0906 23-00-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34877, current rewards: 20.66408, mean: 0.04052
[32m[0906 23-00-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34915, current rewards: 25.80733, mean: 0.04608
[32m[0906 23-01-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34945, current rewards: 30.93705, mean: 0.05072
[32m[0906 23-01-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34961, current rewards: 21.35693, mean: 0.03236
[32m[0906 23-01-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34982, current rewards: -0.03617, mean: -0.00005
[32m[0906 23-02-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35001, current rewards: 6.34589, mean: 0.00835
[32m[0906 23-02-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35011, current rewards: 12.98056, mean: 0.01603
[32m[0906 23-02-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35029, current rewards: 20.07615, mean: 0.02334
[32m[0906 23-03-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35040, current rewards: 27.16541, mean: 0.02985
[32m[0906 23-03-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35051, current rewards: 34.25960, mean: 0.03569
[32m[0906 23-03-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35058, current rewards: 41.35435, mean: 0.04094
[32m[0906 23-03-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35064, current rewards: 24.65683, mean: 0.02326
[32m[0906 23-04-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35067, current rewards: 30.72031, mean: 0.02768
[32m[0906 23-04-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35070, current rewards: 37.01891, mean: 0.03191
[32m[0906 23-04-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35074, current rewards: 45.08702, mean: 0.03726
[32m[0906 23-05-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35080, current rewards: 51.25110, mean: 0.04068
[32m[0906 23-05-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35086, current rewards: 57.42338, mean: 0.04383
[32m[0906 23-05-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35088, current rewards: 63.59648, mean: 0.04676
[32m[0906 23-05-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35091, current rewards: 69.77235, mean: 0.04948
[32m[0906 23-06-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35095, current rewards: 75.94747, mean: 0.05202
[32m[0906 23-06-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35095, current rewards: 39.44245, mean: 0.02612
[32m[0906 23-06-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35099, current rewards: 46.30053, mean: 0.02968
[32m[0906 23-07-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35100, current rewards: 52.05685, mean: 0.03233
[32m[0906 23-07-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35105, current rewards: 58.95356, mean: 0.03551
[32m[0906 23-07-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35109, current rewards: 65.86306, mean: 0.03852
[32m[0906 23-08-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35111, current rewards: 72.77290, mean: 0.04135
[32m[0906 23-08-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35113, current rewards: 79.68977, mean: 0.04403
[32m[0906 23-08-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35117, current rewards: 86.59843, mean: 0.04656
[32m[0906 23-08-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35120, current rewards: 93.50830, mean: 0.04896
[32m[0906 23-09-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35118, current rewards: 100.42489, mean: 0.05124
[32m[0906 23-09-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35119, current rewards: 82.10844, mean: 0.04085
[32m[0906 23-09-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35122, current rewards: 73.08152, mean: 0.03548
[32m[0906 23-10-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35120, current rewards: 77.87444, mean: 0.03691
[32m[0906 23-10-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35120, current rewards: 82.66660, mean: 0.03827
[32m[0906 23-10-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35108, current rewards: 87.45871, mean: 0.03957
[32m[0906 23-10-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35091, current rewards: 92.24473, mean: 0.04082
[32m[0906 23-11-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35074, current rewards: 97.03149, mean: 0.04200
[32m[0906 23-11-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35055, current rewards: 101.82274, mean: 0.04315
[32m[0906 23-11-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35013, current rewards: 106.77451, mean: 0.04430
[32m[0906 23-12-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34975, current rewards: 111.57475, mean: 0.04536
[32m[0906 23-12-17 @Agent.py:117][0m Average action selection time: 0.3495
[32m[0906 23-12-17 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-12-17 @MBExp.py:227][0m Rewards obtained: [77.74407835336234], Lows: [72], Highs: [60], Total time: 32739.925901000006
[32m[0906 23-13-39 @MBExp.py:144][0m ####################################################################
[32m[0906 23-13-39 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 23-13-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35527, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-14-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35294, current rewards: -15.69562, mean: -0.26159
[32m[0906 23-14-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35301, current rewards: 2.78493, mean: 0.02532
[32m[0906 23-14-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35126, current rewards: 19.48146, mean: 0.12176
[32m[0906 23-14-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34961, current rewards: 36.20386, mean: 0.17240
[32m[0906 23-15-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34850, current rewards: 50.69754, mean: 0.19499
[32m[0906 23-15-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34783, current rewards: 60.15998, mean: 0.19406
[32m[0906 23-15-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34731, current rewards: 66.03567, mean: 0.18343
[32m[0906 23-16-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34785, current rewards: 71.92326, mean: 0.17542
[32m[0906 23-16-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34836, current rewards: 77.81003, mean: 0.16915
[32m[0906 23-16-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34872, current rewards: 83.70845, mean: 0.16413
[32m[0906 23-16-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34908, current rewards: 47.24413, mean: 0.08436
[32m[0906 23-17-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34940, current rewards: 53.87801, mean: 0.08832
[32m[0906 23-17-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34967, current rewards: 59.79934, mean: 0.09061
[32m[0906 23-17-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34989, current rewards: 65.29703, mean: 0.09197
[32m[0906 23-18-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35007, current rewards: 71.23139, mean: 0.09373
[32m[0906 23-18-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35024, current rewards: 77.22206, mean: 0.09534
[32m[0906 23-18-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35037, current rewards: 83.20783, mean: 0.09675
[32m[0906 23-18-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35038, current rewards: 89.18713, mean: 0.09801
[32m[0906 23-19-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35044, current rewards: 95.17225, mean: 0.09914
[32m[0906 23-19-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35049, current rewards: 101.15394, mean: 0.10015
[32m[0906 23-19-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35050, current rewards: 107.13861, mean: 0.10107
[32m[0906 23-20-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35059, current rewards: 114.98573, mean: 0.10359
[32m[0906 23-20-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35071, current rewards: 123.68342, mean: 0.10662
[32m[0906 23-20-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35082, current rewards: 129.53810, mean: 0.10706
[32m[0906 23-21-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35081, current rewards: 135.38941, mean: 0.10745
[32m[0906 23-21-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35084, current rewards: 98.91148, mean: 0.07550
[32m[0906 23-21-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35083, current rewards: 105.52778, mean: 0.07759
[32m[0906 23-21-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35088, current rewards: 112.23349, mean: 0.07960
[32m[0906 23-22-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35091, current rewards: 118.94078, mean: 0.08147
[32m[0906 23-22-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35092, current rewards: 125.59256, mean: 0.08317
[32m[0906 23-22-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35090, current rewards: 132.60041, mean: 0.08500
[32m[0906 23-23-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35090, current rewards: 140.90773, mean: 0.08752
[32m[0906 23-23-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35089, current rewards: 139.94962, mean: 0.08431
[32m[0906 23-23-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35088, current rewards: 117.22847, mean: 0.06855
[32m[0906 23-23-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35089, current rewards: 39.95152, mean: 0.02270
[32m[0906 23-24-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35087, current rewards: -60.04848, mean: -0.03318
[32m[0906 23-24-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35087, current rewards: -160.04848, mean: -0.08605
[32m[0906 23-24-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35090, current rewards: -260.04848, mean: -0.13615
[32m[0906 23-25-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35090, current rewards: -360.04848, mean: -0.18370
[32m[0906 23-25-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35091, current rewards: -460.04848, mean: -0.22888
[32m[0906 23-25-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35093, current rewards: -487.92978, mean: -0.23686
[32m[0906 23-26-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35096, current rewards: -483.26833, mean: -0.22904
[32m[0906 23-26-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35097, current rewards: -478.60685, mean: -0.22158
[32m[0906 23-26-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35087, current rewards: -473.94578, mean: -0.21446
[32m[0906 23-26-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35070, current rewards: -469.28517, mean: -0.20765
[32m[0906 23-27-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35054, current rewards: -464.62372, mean: -0.20114
[32m[0906 23-27-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35034, current rewards: -471.98738, mean: -0.19999
[32m[0906 23-27-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34990, current rewards: -476.52312, mean: -0.19773
[32m[0906 23-27-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34946, current rewards: -464.71117, mean: -0.18891
[32m[0906 23-28-13 @Agent.py:117][0m Average action selection time: 0.3492
[32m[0906 23-28-13 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-28-13 @MBExp.py:227][0m Rewards obtained: [-455.4166583325128], Lows: [352], Highs: [66], Total time: 33613.634809
[32m[0906 23-29-37 @MBExp.py:144][0m ####################################################################
[32m[0906 23-29-37 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 23-29-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35351, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-29-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35369, current rewards: -20.53758, mean: -0.34229
[32m[0906 23-30-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35372, current rewards: -15.02998, mean: -0.13664
[32m[0906 23-30-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35113, current rewards: -9.63251, mean: -0.06020
[32m[0906 23-30-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34936, current rewards: -4.24041, mean: -0.02019
[32m[0906 23-31-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34834, current rewards: 1.16575, mean: 0.00448
[32m[0906 23-31-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34770, current rewards: 6.84363, mean: 0.02208
[32m[0906 23-31-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34718, current rewards: 12.28446, mean: 0.03412
[32m[0906 23-31-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34761, current rewards: 17.71453, mean: 0.04321
[32m[0906 23-32-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34834, current rewards: 23.15707, mean: 0.05034
[32m[0906 23-32-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34880, current rewards: 28.60534, mean: 0.05609
[32m[0906 23-32-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34923, current rewards: 34.05138, mean: 0.06081
[32m[0906 23-33-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34944, current rewards: 39.49400, mean: 0.06474
[32m[0906 23-33-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34966, current rewards: 2.99142, mean: 0.00453
[32m[0906 23-33-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34982, current rewards: -11.04534, mean: -0.01556
[32m[0906 23-34-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35002, current rewards: -8.07798, mean: -0.01063
[32m[0906 23-34-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35021, current rewards: -2.76159, mean: -0.00341
[32m[0906 23-34-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35039, current rewards: 2.42592, mean: 0.00282
[32m[0906 23-34-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35049, current rewards: -14.75249, mean: -0.01621
[32m[0906 23-35-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35061, current rewards: -10.34336, mean: -0.01077
[32m[0906 23-35-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35066, current rewards: -5.90242, mean: -0.00584
[32m[0906 23-35-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35071, current rewards: -1.46314, mean: -0.00138
[32m[0906 23-36-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35073, current rewards: 2.97442, mean: 0.00268
[32m[0906 23-36-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35083, current rewards: 7.41192, mean: 0.00639
[32m[0906 23-36-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35089, current rewards: 11.84508, mean: 0.00979
[32m[0906 23-36-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35090, current rewards: 16.28379, mean: 0.01292
[32m[0906 23-37-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35100, current rewards: -22.50731, mean: -0.01718
[32m[0906 23-37-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35107, current rewards: -12.65831, mean: -0.00931
[32m[0906 23-37-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35110, current rewards: -3.60487, mean: -0.00256
[32m[0906 23-38-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35115, current rewards: 5.44856, mean: 0.00373
[32m[0906 23-38-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35117, current rewards: 3.87237, mean: 0.00256
[32m[0906 23-38-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35121, current rewards: -46.12763, mean: -0.02957
[32m[0906 23-39-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35123, current rewards: -96.12763, mean: -0.05971
[32m[0906 23-39-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35123, current rewards: -146.12763, mean: -0.08803
[32m[0906 23-39-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35124, current rewards: -196.12763, mean: -0.11469
[32m[0906 23-39-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35127, current rewards: -246.12763, mean: -0.13985
[32m[0906 23-40-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35127, current rewards: -296.12763, mean: -0.16361
[32m[0906 23-40-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35129, current rewards: -346.12763, mean: -0.18609
[32m[0906 23-40-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35129, current rewards: -396.12763, mean: -0.20740
[32m[0906 23-41-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35130, current rewards: -446.12763, mean: -0.22762
[32m[0906 23-41-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35131, current rewards: -496.12763, mean: -0.24683
[32m[0906 23-41-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35130, current rewards: -546.12763, mean: -0.26511
[32m[0906 23-41-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35131, current rewards: -596.12763, mean: -0.28252
[32m[0906 23-42-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35131, current rewards: -646.12763, mean: -0.29913
[32m[0906 23-42-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35117, current rewards: -696.12763, mean: -0.31499
[32m[0906 23-42-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35103, current rewards: -746.12763, mean: -0.33014
[32m[0906 23-43-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35087, current rewards: -796.12763, mean: -0.34464
[32m[0906 23-43-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35068, current rewards: -846.12763, mean: -0.35853
[32m[0906 23-43-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35026, current rewards: -896.12763, mean: -0.37184
[32m[0906 23-43-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34983, current rewards: -946.12763, mean: -0.38460
[32m[0906 23-44-11 @Agent.py:117][0m Average action selection time: 0.3496
[32m[0906 23-44-11 @Agent.py:118][0m Rollout length: 2520
[32m[0906 23-44-11 @MBExp.py:227][0m Rewards obtained: [-986.1276277180833], Lows: [59], Highs: [1040], Total time: 34488.261729000005
[32m[0906 23-45-37 @MBExp.py:144][0m ####################################################################
[32m[0906 23-45-37 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 23-45-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35386, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-45-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35335, current rewards: -16.26266, mean: -0.27104
[32m[0906 23-46-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35395, current rewards: -9.89577, mean: -0.08996
[32m[0906 23-46-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35143, current rewards: -3.53496, mean: -0.02209
[32m[0906 23-46-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34968, current rewards: 2.82893, mean: 0.01347
[32m[0906 23-47-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34868, current rewards: -5.70043, mean: -0.02192
[32m[0906 23-47-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34789, current rewards: -25.86366, mean: -0.08343
[32m[0906 23-47-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34739, current rewards: -19.59877, mean: -0.05444
[32m[0906 23-48-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34776, current rewards: -13.39595, mean: -0.03267
[32m[0906 23-48-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34843, current rewards: -7.19103, mean: -0.01563
[32m[0906 23-48-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34889, current rewards: -0.98837, mean: -0.00194
[32m[0906 23-48-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34924, current rewards: 5.21524, mean: 0.00931
[32m[0906 23-49-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34960, current rewards: 8.04638, mean: 0.01319
[32m[0906 23-49-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34986, current rewards: -5.36026, mean: -0.00812
[32m[0906 23-49-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35018, current rewards: 1.42832, mean: 0.00201
[32m[0906 23-50-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35038, current rewards: 8.24292, mean: 0.01085
[32m[0906 23-50-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35053, current rewards: 15.05620, mean: 0.01859
[32m[0906 23-50-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35060, current rewards: 21.87248, mean: 0.02543
[32m[0906 23-50-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35070, current rewards: 28.68952, mean: 0.03153
[32m[0906 23-51-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35077, current rewards: 35.50062, mean: 0.03698
[32m[0906 23-51-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35089, current rewards: 27.54201, mean: 0.02727
[32m[0906 23-51-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35095, current rewards: 25.63115, mean: 0.02418
[32m[0906 23-52-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35102, current rewards: 31.21456, mean: 0.02812
[32m[0906 23-52-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35108, current rewards: 36.80544, mean: 0.03173
[32m[0906 23-52-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35115, current rewards: 42.38848, mean: 0.03503
[32m[0906 23-53-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35118, current rewards: 47.97112, mean: 0.03807
[32m[0906 23-53-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35121, current rewards: 53.56135, mean: 0.04089
[32m[0906 23-53-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35127, current rewards: 59.14966, mean: 0.04349
[32m[0906 23-53-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35127, current rewards: 64.73396, mean: 0.04591
[32m[0906 23-54-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35131, current rewards: 70.31287, mean: 0.04816
[32m[0906 23-54-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35129, current rewards: 79.58949, mean: 0.05271
[32m[0906 23-54-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35131, current rewards: 84.19872, mean: 0.05397
[32m[0906 23-55-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35129, current rewards: 88.80423, mean: 0.05516
[32m[0906 23-55-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35133, current rewards: 93.16298, mean: 0.05612
[32m[0906 23-55-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35132, current rewards: 97.52220, mean: 0.05703
[32m[0906 23-55-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35135, current rewards: 101.88060, mean: 0.05789
[32m[0906 23-56-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35135, current rewards: 106.24002, mean: 0.05870
[32m[0906 23-56-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35136, current rewards: 72.16755, mean: 0.03880
[32m[0906 23-56-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35137, current rewards: 83.47888, mean: 0.04371
[32m[0906 23-57-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35139, current rewards: 94.72320, mean: 0.04833
[32m[0906 23-57-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35139, current rewards: 105.95551, mean: 0.05271
[32m[0906 23-57-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35135, current rewards: 117.19701, mean: 0.05689
[32m[0906 23-57-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35137, current rewards: 128.43758, mean: 0.06087
[32m[0906 23-58-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35135, current rewards: 139.69374, mean: 0.06467
[32m[0906 23-58-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35123, current rewards: 150.93910, mean: 0.06830
[32m[0906 23-58-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35105, current rewards: 162.16996, mean: 0.07176
[32m[0906 23-59-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35087, current rewards: 172.29706, mean: 0.07459
[32m[0906 23-59-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35066, current rewards: 156.45951, mean: 0.06630
[32m[0906 23-59-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35024, current rewards: 161.98010, mean: 0.06721
[32m[0906 23-59-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34976, current rewards: 167.56078, mean: 0.06811
[32m[0907 00-00-12 @Agent.py:117][0m Average action selection time: 0.3495
[32m[0907 00-00-12 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-00-12 @MBExp.py:227][0m Rewards obtained: [172.02173793562372], Lows: [40], Highs: [80], Total time: 35362.71675000001
[32m[0907 00-01-40 @MBExp.py:144][0m ####################################################################
[32m[0907 00-01-40 @MBExp.py:145][0m Starting training iteration 43.
[32m[0907 00-01-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35356, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-02-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35257, current rewards: -19.27050, mean: -0.32117
[32m[0907 00-02-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35220, current rewards: -15.25595, mean: -0.13869
[32m[0907 00-02-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35007, current rewards: -11.30326, mean: -0.07065
[32m[0907 00-02-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34856, current rewards: -6.34797, mean: -0.03023
[32m[0907 00-03-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34765, current rewards: -2.32742, mean: -0.00895
[32m[0907 00-03-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34713, current rewards: 1.53370, mean: 0.00495
[32m[0907 00-03-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34672, current rewards: 5.39536, mean: 0.01499
[32m[0907 00-04-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34720, current rewards: 9.25573, mean: 0.02257
[32m[0907 00-04-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34769, current rewards: 13.11848, mean: 0.02852
[32m[0907 00-04-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34817, current rewards: 16.97830, mean: 0.03329
[32m[0907 00-04-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34852, current rewards: 1.44860, mean: 0.00259
[32m[0907 00-05-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34878, current rewards: 3.45603, mean: 0.00567
[32m[0907 00-05-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34906, current rewards: 10.27891, mean: 0.01557
[32m[0907 00-05-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34928, current rewards: 15.48439, mean: 0.02181
[32m[0907 00-06-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34946, current rewards: 20.68124, mean: 0.02721
[32m[0907 00-06-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34959, current rewards: 25.88976, mean: 0.03196
[32m[0907 00-06-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34974, current rewards: 31.09434, mean: 0.03616
[32m[0907 00-06-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34983, current rewards: 36.29453, mean: 0.03988
[32m[0907 00-07-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34990, current rewards: 20.09622, mean: 0.02093
[32m[0907 00-07-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34996, current rewards: 23.78504, mean: 0.02355
[32m[0907 00-07-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35002, current rewards: 28.05185, mean: 0.02646
[32m[0907 00-08-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35008, current rewards: 31.82214, mean: 0.02867
[32m[0907 00-08-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35012, current rewards: 35.58854, mean: 0.03068
[32m[0907 00-08-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35017, current rewards: 39.35472, mean: 0.03252
[32m[0907 00-09-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35025, current rewards: 43.11586, mean: 0.03422
[32m[0907 00-09-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35029, current rewards: 5.48729, mean: 0.00419
[32m[0907 00-09-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35035, current rewards: 9.72774, mean: 0.00715
[32m[0907 00-09-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35040, current rewards: 14.03012, mean: 0.00995
[32m[0907 00-10-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35044, current rewards: 18.33510, mean: 0.01256
[32m[0907 00-10-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35047, current rewards: 22.63859, mean: 0.01499
[32m[0907 00-10-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35053, current rewards: 26.94555, mean: 0.01727
[32m[0907 00-11-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35057, current rewards: 31.24912, mean: 0.01941
[32m[0907 00-11-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35062, current rewards: 35.55238, mean: 0.02142
[32m[0907 00-11-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35068, current rewards: 17.47380, mean: 0.01022
[32m[0907 00-11-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35070, current rewards: 21.22714, mean: 0.01206
[32m[0907 00-12-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35072, current rewards: 25.01192, mean: 0.01382
[32m[0907 00-12-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35073, current rewards: 28.65192, mean: 0.01540
[32m[0907 00-12-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35075, current rewards: 32.40508, mean: 0.01697
[32m[0907 00-13-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35078, current rewards: 36.17612, mean: 0.01846
[32m[0907 00-13-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35081, current rewards: 39.94424, mean: 0.01987
[32m[0907 00-13-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35080, current rewards: 43.71524, mean: 0.02122
[32m[0907 00-14-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35081, current rewards: 47.48765, mean: 0.02251
[32m[0907 00-14-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35084, current rewards: 38.80467, mean: 0.01797
[32m[0907 00-14-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35076, current rewards: 14.12236, mean: 0.00639
[32m[0907 00-14-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35060, current rewards: 22.73005, mean: 0.01006
[32m[0907 00-15-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35045, current rewards: 26.98643, mean: 0.01168
[32m[0907 00-15-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35027, current rewards: 30.79415, mean: 0.01305
[32m[0907 00-15-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34991, current rewards: -3.74218, mean: -0.00155
[32m[0907 00-16-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34942, current rewards: 1.72922, mean: 0.00070
[32m[0907 00-16-13 @Agent.py:117][0m Average action selection time: 0.3492
[32m[0907 00-16-13 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-16-13 @MBExp.py:227][0m Rewards obtained: [5.8630100119174], Lows: [50], Highs: [102], Total time: 36236.37115700001
[32m[0907 00-17-43 @MBExp.py:144][0m ####################################################################
[32m[0907 00-17-43 @MBExp.py:145][0m Starting training iteration 44.
[32m[0907 00-17-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35396, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-18-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35332, current rewards: -16.64741, mean: -0.27746
[32m[0907 00-18-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35314, current rewards: -10.51580, mean: -0.09560
[32m[0907 00-18-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35057, current rewards: -4.54840, mean: -0.02843
[32m[0907 00-18-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34927, current rewards: 1.54486, mean: 0.00736
[32m[0907 00-19-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34815, current rewards: 7.74197, mean: 0.02978
[32m[0907 00-19-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34758, current rewards: 13.94637, mean: 0.04499
[32m[0907 00-19-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34717, current rewards: -2.57563, mean: -0.00715
[32m[0907 00-20-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34746, current rewards: 3.42749, mean: 0.00836
[32m[0907 00-20-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34814, current rewards: 9.36138, mean: 0.02035
[32m[0907 00-20-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34858, current rewards: 15.27665, mean: 0.02995
[32m[0907 00-20-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34894, current rewards: 21.50347, mean: 0.03840
[32m[0907 00-21-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34925, current rewards: 15.94205, mean: 0.02613
[32m[0907 00-21-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34954, current rewards: 24.44938, mean: 0.03704
[32m[0907 00-21-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34968, current rewards: 30.22920, mean: 0.04258
[32m[0907 00-22-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34989, current rewards: 35.99862, mean: 0.04737
[32m[0907 00-22-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35001, current rewards: 41.75490, mean: 0.05155
[32m[0907 00-22-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35013, current rewards: 47.52343, mean: 0.05526
[32m[0907 00-23-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35021, current rewards: 53.30595, mean: 0.05858
[32m[0907 00-23-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35034, current rewards: 16.77808, mean: 0.01748
[32m[0907 00-23-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35040, current rewards: 22.20548, mean: 0.02199
[32m[0907 00-23-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35046, current rewards: 27.74989, mean: 0.02618
[32m[0907 00-24-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35056, current rewards: 33.45704, mean: 0.03014
[32m[0907 00-24-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35064, current rewards: 39.16062, mean: 0.03376
[32m[0907 00-24-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35069, current rewards: 44.86613, mean: 0.03708
[32m[0907 00-25-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35076, current rewards: 50.57214, mean: 0.04014
[32m[0907 00-25-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35083, current rewards: 56.27938, mean: 0.04296
[32m[0907 00-25-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35086, current rewards: 39.79287, mean: 0.02926
[32m[0907 00-25-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35092, current rewards: 46.40870, mean: 0.03291
[32m[0907 00-26-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35098, current rewards: 52.94606, mean: 0.03626
[32m[0907 00-26-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35096, current rewards: 61.09933, mean: 0.04046
[32m[0907 00-26-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35101, current rewards: 69.37250, mean: 0.04447
[32m[0907 00-27-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35102, current rewards: 77.64858, mean: 0.04823
[32m[0907 00-27-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35103, current rewards: 85.91254, mean: 0.05175
[32m[0907 00-27-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35105, current rewards: 94.16915, mean: 0.05507
[32m[0907 00-28-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35107, current rewards: 102.43450, mean: 0.05820
[32m[0907 00-28-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35108, current rewards: 110.44327, mean: 0.06102
[32m[0907 00-28-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35109, current rewards: 116.82205, mean: 0.06281
[32m[0907 00-28-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35109, current rewards: 126.29348, mean: 0.06612
[32m[0907 00-29-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35112, current rewards: 135.88208, mean: 0.06933
[32m[0907 00-29-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35114, current rewards: 145.49458, mean: 0.07239
[32m[0907 00-29-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35115, current rewards: 113.44776, mean: 0.05507
[32m[0907 00-30-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35117, current rewards: 112.79049, mean: 0.05346
[32m[0907 00-30-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35115, current rewards: 117.48217, mean: 0.05439
[32m[0907 00-30-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35106, current rewards: 122.21295, mean: 0.05530
[32m[0907 00-30-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35088, current rewards: 128.75711, mean: 0.05697
[32m[0907 00-31-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35071, current rewards: 133.22079, mean: 0.05767
[32m[0907 00-31-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35055, current rewards: 137.62778, mean: 0.05832
[32m[0907 00-31-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35024, current rewards: 142.02842, mean: 0.05893
[32m[0907 00-32-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34970, current rewards: 146.42414, mean: 0.05952
[32m[0907 00-32-17 @Agent.py:117][0m Average action selection time: 0.3494
[32m[0907 00-32-17 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-32-18 @MBExp.py:227][0m Rewards obtained: [149.93899108409255], Lows: [55], Highs: [61], Total time: 37110.64409000001
[32m[0907 00-33-49 @MBExp.py:144][0m ####################################################################
[32m[0907 00-33-49 @MBExp.py:145][0m Starting training iteration 45.
[32m[0907 00-33-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35493, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-34-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35368, current rewards: -16.07507, mean: -0.26792
[32m[0907 00-34-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35303, current rewards: -11.77494, mean: -0.10704
[32m[0907 00-34-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35036, current rewards: -13.41883, mean: -0.08387
[32m[0907 00-35-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34894, current rewards: -8.08373, mean: -0.03849
[32m[0907 00-35-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34802, current rewards: -3.65012, mean: -0.01404
[32m[0907 00-35-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34739, current rewards: 0.72580, mean: 0.00234
[32m[0907 00-35-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34700, current rewards: 5.09710, mean: 0.01416
[32m[0907 00-36-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34734, current rewards: 9.46763, mean: 0.02309
[32m[0907 00-36-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34806, current rewards: 13.84236, mean: 0.03009
[32m[0907 00-36-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34856, current rewards: 18.21716, mean: 0.03572
[32m[0907 00-37-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34898, current rewards: 22.58921, mean: 0.04034
[32m[0907 00-37-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34928, current rewards: 26.89522, mean: 0.04409
[32m[0907 00-37-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34948, current rewards: 31.28127, mean: 0.04740
[32m[0907 00-37-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34969, current rewards: 35.66362, mean: 0.05023
[32m[0907 00-38-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34993, current rewards: 40.04395, mean: 0.05269
[32m[0907 00-38-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35007, current rewards: 4.76037, mean: 0.00588
[32m[0907 00-38-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35020, current rewards: 8.30367, mean: 0.00966
[32m[0907 00-39-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35041, current rewards: 13.39404, mean: 0.01472
[32m[0907 00-39-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35057, current rewards: 18.48995, mean: 0.01926
[32m[0907 00-39-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35063, current rewards: 23.51413, mean: 0.02328
[32m[0907 00-40-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35065, current rewards: 28.60485, mean: 0.02699
[32m[0907 00-40-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35070, current rewards: 33.69454, mean: 0.03036
[32m[0907 00-40-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35072, current rewards: 38.78506, mean: 0.03344
[32m[0907 00-40-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35077, current rewards: 43.87018, mean: 0.03626
[32m[0907 00-41-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35081, current rewards: 48.96370, mean: 0.03886
[32m[0907 00-41-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35082, current rewards: 54.05156, mean: 0.04126
[32m[0907 00-41-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35084, current rewards: 40.22781, mean: 0.02958
[32m[0907 00-42-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35085, current rewards: -23.48503, mean: -0.01666
[32m[0907 00-42-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35091, current rewards: -13.48021, mean: -0.00923
[32m[0907 00-42-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35090, current rewards: -6.12697, mean: -0.00406
[32m[0907 00-42-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35092, current rewards: 0.86276, mean: 0.00055
[32m[0907 00-43-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35094, current rewards: 7.80407, mean: 0.00485
[32m[0907 00-43-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35098, current rewards: 14.71952, mean: 0.00887
[32m[0907 00-43-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35100, current rewards: -22.08884, mean: -0.01292
[32m[0907 00-44-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35103, current rewards: -10.97144, mean: -0.00623
[32m[0907 00-44-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35103, current rewards: -4.39164, mean: -0.00243
[32m[0907 00-44-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35104, current rewards: 2.87293, mean: 0.00154
[32m[0907 00-45-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35109, current rewards: 12.52121, mean: 0.00656
[32m[0907 00-45-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35111, current rewards: 3.11625, mean: 0.00159
[32m[0907 00-45-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35113, current rewards: 4.51002, mean: 0.00224
[32m[0907 00-45-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35114, current rewards: 9.97296, mean: 0.00484
[32m[0907 00-46-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35116, current rewards: 15.42318, mean: 0.00731
[32m[0907 00-46-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35118, current rewards: 20.87319, mean: 0.00966
[32m[0907 00-46-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35109, current rewards: 26.35372, mean: 0.01192
[32m[0907 00-47-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35093, current rewards: 31.85345, mean: 0.01409
[32m[0907 00-47-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35075, current rewards: 37.28319, mean: 0.01614
[32m[0907 00-47-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35059, current rewards: 42.71812, mean: 0.01810
[32m[0907 00-47-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35029, current rewards: 48.14968, mean: 0.01998
[32m[0907 00-48-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34971, current rewards: 53.58897, mean: 0.02178
[32m[0907 00-48-23 @Agent.py:117][0m Average action selection time: 0.3494
[32m[0907 00-48-23 @Agent.py:118][0m Rollout length: 2520
[32m[0907 00-48-23 @MBExp.py:227][0m Rewards obtained: [57.93604401092363], Lows: [85], Highs: [45], Total time: 37984.958042000006
[32m[0907 00-49-57 @MBExp.py:144][0m ####################################################################
[32m[0907 00-49-57 @MBExp.py:145][0m Starting training iteration 46.
[32m[0907 00-50-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35289, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-50-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35253, current rewards: -16.58046, mean: -0.27634
[32m[0907 00-50-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35219, current rewards: -11.12435, mean: -0.10113
[32m[0907 00-50-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34955, current rewards: -7.12937, mean: -0.04456
[32m[0907 00-51-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34834, current rewards: -1.88252, mean: -0.00896
[32m[0907 00-51-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34745, current rewards: 3.38376, mean: 0.01301
[32m[0907 00-51-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34711, current rewards: 8.64205, mean: 0.02788
[32m[0907 00-52-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34668, current rewards: 13.89959, mean: 0.03861
[32m[0907 00-52-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34701, current rewards: 19.15542, mean: 0.04672
[32m[0907 00-52-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34763, current rewards: 2.63334, mean: 0.00572
[32m[0907 00-52-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34820, current rewards: 7.51121, mean: 0.01473
[32m[0907 00-53-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34866, current rewards: 14.86487, mean: 0.02654
[32m[0907 00-53-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34727, current rewards: 19.86298, mean: 0.03256
[32m[0907 00-53-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34506, current rewards: 24.87708, mean: 0.03769
[32m[0907 00-54-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34298, current rewards: 29.89362, mean: 0.04210
[32m[0907 00-54-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34111, current rewards: 34.90620, mean: 0.04593
[32m[0907 00-54-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33954, current rewards: 39.91622, mean: 0.04928
[32m[0907 00-54-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33810, current rewards: 1.86786, mean: 0.00217
[32m[0907 00-55-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33689, current rewards: 7.71258, mean: 0.00848
[32m[0907 00-55-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33576, current rewards: 11.69252, mean: 0.01218
[32m[0907 00-55-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33471, current rewards: 16.30141, mean: 0.01614
[32m[0907 00-55-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33376, current rewards: 20.88390, mean: 0.01970
[32m[0907 00-56-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33293, current rewards: 25.47382, mean: 0.02295
[32m[0907 00-56-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33217, current rewards: 30.06399, mean: 0.02592
[32m[0907 00-56-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33143, current rewards: 11.49058, mean: 0.00950
[32m[0907 00-56-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33076, current rewards: 13.71282, mean: 0.01088
[32m[0907 00-57-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33017, current rewards: 17.60942, mean: 0.01344
[32m[0907 00-57-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32958, current rewards: 20.69115, mean: 0.01521
[32m[0907 00-57-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32906, current rewards: 24.02641, mean: 0.01704
[32m[0907 00-57-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32859, current rewards: 29.00817, mean: 0.01987
[32m[0907 00-58-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32812, current rewards: 33.99185, mean: 0.02251
[32m[0907 00-58-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32773, current rewards: 38.97084, mean: 0.02498
[32m[0907 00-58-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32728, current rewards: 43.95409, mean: 0.02730
[32m[0907 00-59-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32689, current rewards: 48.93162, mean: 0.02948
[32m[0907 00-59-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32651, current rewards: 53.91473, mean: 0.03153
[32m[0907 00-59-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32616, current rewards: 58.91924, mean: 0.03348
[32m[0907 00-59-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32582, current rewards: 50.78624, mean: 0.02806
[32m[0907 01-00-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32553, current rewards: 37.26276, mean: 0.02003
[32m[0907 01-00-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32523, current rewards: 36.73901, mean: 0.01924
[32m[0907 01-00-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32497, current rewards: 41.08344, mean: 0.02096
[32m[0907 01-00-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32469, current rewards: 45.46345, mean: 0.02262
[32m[0907 01-01-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32444, current rewards: 49.83883, mean: 0.02419
[32m[0907 01-01-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32420, current rewards: 54.20760, mean: 0.02569
[32m[0907 01-01-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32396, current rewards: 58.57935, mean: 0.02712
[32m[0907 01-01-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32364, current rewards: 20.90805, mean: 0.00946
[32m[0907 01-02-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32329, current rewards: 26.79472, mean: 0.01186
[32m[0907 01-02-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32296, current rewards: 32.54748, mean: 0.01409
[32m[0907 01-02-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32265, current rewards: 38.29713, mean: 0.01623
[32m[0907 01-02-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32221, current rewards: 44.04893, mean: 0.01828
[32m[0907 01-03-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32157, current rewards: 49.80296, mean: 0.02025
[32m[0907 01-03-21 @Agent.py:117][0m Average action selection time: 0.3212
[32m[0907 01-03-21 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-03-21 @MBExp.py:227][0m Rewards obtained: [54.406828369781444], Lows: [51], Highs: [90], Total time: 38788.59669600001
[32m[0907 01-04-47 @MBExp.py:144][0m ####################################################################
[32m[0907 01-04-47 @MBExp.py:145][0m Starting training iteration 47.
[32m[0907 01-04-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31683, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-05-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31563, current rewards: -17.52865, mean: -0.29214
[32m[0907 01-05-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31452, current rewards: -13.02568, mean: -0.11842
[32m[0907 01-05-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31281, current rewards: -7.80586, mean: -0.04879
[32m[0907 01-05-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31185, current rewards: -3.31428, mean: -0.01578
[32m[0907 01-06-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31117, current rewards: 1.17386, mean: 0.00451
[32m[0907 01-06-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31071, current rewards: 5.66309, mean: 0.01827
[32m[0907 01-06-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31037, current rewards: 10.15410, mean: 0.02821
[32m[0907 01-06-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31060, current rewards: 14.64079, mean: 0.03571
[32m[0907 01-07-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31116, current rewards: 19.12440, mean: 0.04157
[32m[0907 01-07-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31172, current rewards: 23.61767, mean: 0.04631
[32m[0907 01-07-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31205, current rewards: 28.41581, mean: 0.05074
[32m[0907 01-07-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31238, current rewards: 42.39560, mean: 0.06950
[32m[0907 01-08-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31258, current rewards: 45.90518, mean: 0.06955
[32m[0907 01-08-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31277, current rewards: 49.40980, mean: 0.06959
[32m[0907 01-08-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31301, current rewards: 52.91385, mean: 0.06962
[32m[0907 01-09-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31312, current rewards: 56.42038, mean: 0.06965
[32m[0907 01-09-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31318, current rewards: 59.92859, mean: 0.06968
[32m[0907 01-09-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31333, current rewards: 63.43702, mean: 0.06971
[32m[0907 01-09-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31338, current rewards: 68.27342, mean: 0.07112
[32m[0907 01-10-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31347, current rewards: 71.91619, mean: 0.07120
[32m[0907 01-10-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31355, current rewards: 75.49676, mean: 0.07122
[32m[0907 01-10-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31357, current rewards: 58.71840, mean: 0.05290
[32m[0907 01-10-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31362, current rewards: 65.47424, mean: 0.05644
[32m[0907 01-11-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31366, current rewards: 71.17102, mean: 0.05882
[32m[0907 01-11-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31366, current rewards: 76.78549, mean: 0.06094
[32m[0907 01-11-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31366, current rewards: 88.39837, mean: 0.06748
[32m[0907 01-11-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31369, current rewards: 101.27664, mean: 0.07447
[32m[0907 01-12-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31374, current rewards: 105.11985, mean: 0.07455
[32m[0907 01-12-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31374, current rewards: 108.87229, mean: 0.07457
[32m[0907 01-12-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31375, current rewards: 112.62269, mean: 0.07458
[32m[0907 01-12-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31378, current rewards: 110.15078, mean: 0.07061
[32m[0907 01-13-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31380, current rewards: 80.93736, mean: 0.05027
[32m[0907 01-13-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31381, current rewards: 87.39619, mean: 0.05265
[32m[0907 01-13-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31381, current rewards: 93.85501, mean: 0.05489
[32m[0907 01-14-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31380, current rewards: 99.23210, mean: 0.05638
[32m[0907 01-14-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31382, current rewards: 102.15484, mean: 0.05644
[32m[0907 01-14-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31381, current rewards: 105.07758, mean: 0.05649
[32m[0907 01-14-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31383, current rewards: 108.00032, mean: 0.05654
[32m[0907 01-15-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31385, current rewards: 110.92307, mean: 0.05659
[32m[0907 01-15-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31387, current rewards: 113.84581, mean: 0.05664
[32m[0907 01-15-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31386, current rewards: 116.76855, mean: 0.05668
[32m[0907 01-15-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31388, current rewards: 79.47001, mean: 0.03766
[32m[0907 01-16-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31390, current rewards: 29.47001, mean: 0.01364
[32m[0907 01-16-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31379, current rewards: -20.52999, mean: -0.00929
[32m[0907 01-16-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31365, current rewards: -70.52999, mean: -0.03121
[32m[0907 01-16-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31353, current rewards: -120.52999, mean: -0.05218
[32m[0907 01-17-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31341, current rewards: -170.52999, mean: -0.07226
[32m[0907 01-17-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31317, current rewards: -220.52999, mean: -0.09151
[32m[0907 01-17-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31272, current rewards: -270.52999, mean: -0.10997
[32m[0907 01-17-49 @Agent.py:117][0m Average action selection time: 0.3125
[32m[0907 01-17-49 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-17-49 @MBExp.py:227][0m Rewards obtained: [-310.5299939671409], Lows: [20], Highs: [475], Total time: 39570.37608500001
[32m[0907 01-19-17 @MBExp.py:144][0m ####################################################################
[32m[0907 01-19-17 @MBExp.py:145][0m Starting training iteration 48.
[32m[0907 01-19-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31778, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-19-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31546, current rewards: -18.40543, mean: -0.30676
[32m[0907 01-19-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31440, current rewards: -12.79999, mean: -0.11636
[32m[0907 01-20-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31258, current rewards: -6.82313, mean: -0.04264
[32m[0907 01-20-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31162, current rewards: -0.83670, mean: -0.00398
[32m[0907 01-20-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31104, current rewards: 5.15223, mean: 0.01982
[32m[0907 01-20-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31068, current rewards: 11.14327, mean: 0.03595
[32m[0907 01-21-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31047, current rewards: 17.13475, mean: 0.04760
[32m[0907 01-21-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31063, current rewards: 23.12025, mean: 0.05639
[32m[0907 01-21-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31132, current rewards: -10.50276, mean: -0.02283
[32m[0907 01-21-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31175, current rewards: -4.75140, mean: -0.00932
[32m[0907 01-22-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31215, current rewards: 1.21833, mean: 0.00218
[32m[0907 01-22-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31244, current rewards: 7.18740, mean: 0.01178
[32m[0907 01-22-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31270, current rewards: 13.16654, mean: 0.01995
[32m[0907 01-22-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31290, current rewards: 0.07002, mean: 0.00010
[32m[0907 01-23-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31310, current rewards: -17.45941, mean: -0.02297
[32m[0907 01-23-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31328, current rewards: -12.17675, mean: -0.01503
[32m[0907 01-23-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31343, current rewards: -6.91979, mean: -0.00805
[32m[0907 01-24-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31354, current rewards: -1.44996, mean: -0.00159
[32m[0907 01-24-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31364, current rewards: 3.77977, mean: 0.00394
[32m[0907 01-24-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31375, current rewards: 9.01402, mean: 0.00892
[32m[0907 01-24-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31379, current rewards: 5.83555, mean: 0.00551
[32m[0907 01-25-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31384, current rewards: -20.51689, mean: -0.01848
[32m[0907 01-25-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31391, current rewards: -13.97379, mean: -0.01205
[32m[0907 01-25-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31397, current rewards: -7.48063, mean: -0.00618
[32m[0907 01-25-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31400, current rewards: -0.98895, mean: -0.00078
[32m[0907 01-26-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31399, current rewards: 4.43635, mean: 0.00339
[32m[0907 01-26-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31400, current rewards: -12.61152, mean: -0.00927
[32m[0907 01-26-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31401, current rewards: -5.65055, mean: -0.00401
[32m[0907 01-26-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31398, current rewards: 1.41590, mean: 0.00097
[32m[0907 01-27-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31399, current rewards: 8.48540, mean: 0.00562
[32m[0907 01-27-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31400, current rewards: 15.54514, mean: 0.00996
[32m[0907 01-27-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31402, current rewards: 22.60386, mean: 0.01404
[32m[0907 01-27-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31404, current rewards: 29.68162, mean: 0.01788
[32m[0907 01-28-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31402, current rewards: 36.73841, mean: 0.02148
[32m[0907 01-28-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31405, current rewards: 42.73435, mean: 0.02428
[32m[0907 01-28-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31404, current rewards: 49.97700, mean: 0.02761
[32m[0907 01-29-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31406, current rewards: 57.25294, mean: 0.03078
[32m[0907 01-29-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31405, current rewards: 64.61767, mean: 0.03383
[32m[0907 01-29-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31404, current rewards: 71.92917, mean: 0.03670
[32m[0907 01-29-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31407, current rewards: 79.22672, mean: 0.03942
[32m[0907 01-30-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31406, current rewards: 86.52503, mean: 0.04200
[32m[0907 01-30-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31421, current rewards: 75.43263, mean: 0.03575
[32m[0907 01-30-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31420, current rewards: 84.75019, mean: 0.03924
[32m[0907 01-30-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31406, current rewards: 90.48647, mean: 0.04094
[32m[0907 01-31-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31390, current rewards: 96.13084, mean: 0.04254
[32m[0907 01-31-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31375, current rewards: 101.78573, mean: 0.04406
[32m[0907 01-31-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31361, current rewards: 107.43293, mean: 0.04552
[32m[0907 01-31-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31333, current rewards: 113.07382, mean: 0.04692
[32m[0907 01-32-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31286, current rewards: 118.72694, mean: 0.04826
[32m[0907 01-32-19 @Agent.py:117][0m Average action selection time: 0.3126
[32m[0907 01-32-19 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-32-19 @MBExp.py:227][0m Rewards obtained: [123.2491551227335], Lows: [61], Highs: [60], Total time: 40352.50828200001
[32m[0907 01-33-49 @MBExp.py:144][0m ####################################################################
[32m[0907 01-33-49 @MBExp.py:145][0m Starting training iteration 49.
[32m[0907 01-33-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31742, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-34-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31616, current rewards: -29.86710, mean: -0.49778
[32m[0907 01-34-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31443, current rewards: -27.23592, mean: -0.24760
[32m[0907 01-34-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31260, current rewards: -23.12886, mean: -0.14456
[32m[0907 01-34-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31166, current rewards: -19.03426, mean: -0.09064
[32m[0907 01-35-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31099, current rewards: -27.43275, mean: -0.10551
[32m[0907 01-35-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31059, current rewards: -51.91216, mean: -0.16746
[32m[0907 01-35-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31028, current rewards: -47.17542, mean: -0.13104
[32m[0907 01-35-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31045, current rewards: -42.45116, mean: -0.10354
[32m[0907 01-36-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31117, current rewards: -34.98167, mean: -0.07605
[32m[0907 01-36-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31167, current rewards: -29.85756, mean: -0.05854
[32m[0907 01-36-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31199, current rewards: -24.73877, mean: -0.04418
[32m[0907 01-37-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31225, current rewards: -19.62058, mean: -0.03216
[32m[0907 01-37-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31251, current rewards: -34.34431, mean: -0.05204
[32m[0907 01-37-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31275, current rewards: -32.95101, mean: -0.04641
[32m[0907 01-37-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31299, current rewards: -29.39495, mean: -0.03868
[32m[0907 01-38-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31309, current rewards: -25.84107, mean: -0.03190
[32m[0907 01-38-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31316, current rewards: -22.43109, mean: -0.02608
[32m[0907 01-38-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31326, current rewards: -18.64449, mean: -0.02049
[32m[0907 01-38-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31333, current rewards: -13.65341, mean: -0.01422
[32m[0907 01-39-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31344, current rewards: -10.33099, mean: -0.01023
[32m[0907 01-39-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31350, current rewards: -7.49734, mean: -0.00707
[32m[0907 01-39-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31358, current rewards: -4.64318, mean: -0.00418
[32m[0907 01-39-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31359, current rewards: -1.74731, mean: -0.00151
[32m[0907 01-40-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31367, current rewards: 1.08942, mean: 0.00090
[32m[0907 01-40-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31375, current rewards: 4.39487, mean: 0.00349
[32m[0907 01-40-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31380, current rewards: 8.08061, mean: 0.00617
[32m[0907 01-40-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31380, current rewards: 11.11788, mean: 0.00817
[32m[0907 01-41-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31384, current rewards: 14.88186, mean: 0.01055
[32m[0907 01-41-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31386, current rewards: 20.59960, mean: 0.01411
[32m[0907 01-41-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31391, current rewards: 26.04715, mean: 0.01725
[32m[0907 01-41-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31389, current rewards: 31.49945, mean: 0.02019
[32m[0907 01-42-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31391, current rewards: -3.12252, mean: -0.00194
[32m[0907 01-42-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31395, current rewards: -15.16901, mean: -0.00914
[32m[0907 01-42-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31397, current rewards: -11.39918, mean: -0.00667
[32m[0907 01-43-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31397, current rewards: -6.64133, mean: -0.00377
[32m[0907 01-43-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31395, current rewards: -1.36485, mean: -0.00075
[32m[0907 01-43-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31394, current rewards: 3.89919, mean: 0.00210
[32m[0907 01-43-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31396, current rewards: 9.16101, mean: 0.00480
[32m[0907 01-44-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31395, current rewards: 14.42326, mean: 0.00736
[32m[0907 01-44-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31396, current rewards: 19.68623, mean: 0.00979
[32m[0907 01-44-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31397, current rewards: 2.25831, mean: 0.00110
[32m[0907 01-44-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31394, current rewards: 3.21654, mean: 0.00152
[32m[0907 01-45-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31395, current rewards: 7.82546, mean: 0.00362
[32m[0907 01-45-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31383, current rewards: 12.44589, mean: 0.00563
[32m[0907 01-45-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31370, current rewards: 17.06484, mean: 0.00755
[32m[0907 01-45-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31357, current rewards: 21.68448, mean: 0.00939
[32m[0907 01-46-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31345, current rewards: 26.30455, mean: 0.01115
[32m[0907 01-46-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31320, current rewards: 30.92436, mean: 0.01283
[32m[0907 01-46-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31273, current rewards: 35.54364, mean: 0.01445
[32m[0907 01-46-51 @Agent.py:117][0m Average action selection time: 0.3125
[32m[0907 01-46-51 @Agent.py:118][0m Rollout length: 2520
[32m[0907 01-46-51 @MBExp.py:227][0m Rewards obtained: [39.5288540404301], Lows: [54], Highs: [71], Total time: 41134.37033100001
[32m[0907 01-48-23 @MBExp.py:144][0m ####################################################################
[32m[0907 01-48-23 @MBExp.py:145][0m Starting training iteration 50.
[32m[0907 01-48-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31837, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-48-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31598, current rewards: -12.77054, mean: -0.21284
[32m[0907 01-48-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31369, current rewards: -7.14364, mean: -0.06494
[32m[0907 01-49-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31194, current rewards: -1.53652, mean: -0.00960
[32m[0907 01-49-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31096, current rewards: 4.08384, mean: 0.01945
[32m[0907 01-49-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31049, current rewards: 9.70424, mean: 0.03732
[32m[0907 01-49-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31010, current rewards: 15.31294, mean: 0.04940
[32m[0907 01-50-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30988, current rewards: -21.37193, mean: -0.05937
[32m[0907 01-50-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31004, current rewards: -13.35252, mean: -0.03257
[32m[0907 01-50-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31057, current rewards: -6.24714, mean: -0.01358
[32m[0907 01-51-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31108, current rewards: 0.39016, mean: 0.00077
[32m[0907 01-51-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31145, current rewards: 7.00156, mean: 0.01250
[32m[0907 01-51-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31172, current rewards: 13.61474, mean: 0.02232
[32m[0907 01-51-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31200, current rewards: 20.22466, mean: 0.03064
[32m[0907 01-52-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31217, current rewards: 16.64131, mean: 0.02344
[32m[0907 01-52-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31240, current rewards: 10.14273, mean: 0.01335
[32m[0907 01-52-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31256, current rewards: 15.26264, mean: 0.01884
[32m[0907 01-52-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31274, current rewards: 19.65207, mean: 0.02285
[32m[0907 01-53-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31280, current rewards: 24.78852, mean: 0.02724
[32m[0907 01-53-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31291, current rewards: 29.95889, mean: 0.03121
[32m[0907 01-53-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31301, current rewards: 35.13134, mean: 0.03478
[32m[0907 01-53-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31311, current rewards: 40.31186, mean: 0.03803
[32m[0907 01-54-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31320, current rewards: 45.48209, mean: 0.04097
[32m[0907 01-54-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31328, current rewards: 50.66493, mean: 0.04368
[32m[0907 01-54-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31339, current rewards: 55.83543, mean: 0.04614
[32m[0907 01-54-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31348, current rewards: 64.75183, mean: 0.05139
[32m[0907 01-55-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31354, current rewards: 69.90731, mean: 0.05336
[32m[0907 01-55-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31356, current rewards: 75.09568, mean: 0.05522
[32m[0907 01-55-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31361, current rewards: 80.28331, mean: 0.05694
[32m[0907 01-56-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31366, current rewards: 43.39183, mean: 0.02972
[32m[0907 01-56-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31368, current rewards: 50.77817, mean: 0.03363
[32m[0907 01-56-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31369, current rewards: 57.18979, mean: 0.03666
[32m[0907 01-56-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31373, current rewards: 63.57941, mean: 0.03949
[32m[0907 01-57-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31375, current rewards: 59.69384, mean: 0.03596
[32m[0907 01-57-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31376, current rewards: 60.22218, mean: 0.03522
[32m[0907 01-57-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31380, current rewards: 28.91787, mean: 0.01643
[32m[0907 01-57-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31383, current rewards: 32.15190, mean: 0.01776
[32m[0907 01-58-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31388, current rewards: 7.28651, mean: 0.00392
[32m[0907 01-58-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31392, current rewards: 5.96987, mean: 0.00313
[32m[0907 01-58-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31393, current rewards: -2.25978, mean: -0.00115
[32m[0907 01-58-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31396, current rewards: -36.90589, mean: -0.01836
[32m[0907 01-59-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31398, current rewards: -86.90589, mean: -0.04219
[32m[0907 01-59-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31399, current rewards: -136.90589, mean: -0.06488
[32m[0907 01-59-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31399, current rewards: -186.90589, mean: -0.08653
[32m[0907 01-59-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31386, current rewards: -236.90589, mean: -0.10720
[32m[0907 02-00-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31372, current rewards: -286.90589, mean: -0.12695
[32m[0907 02-00-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31356, current rewards: -336.90589, mean: -0.14585
[32m[0907 02-00-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31344, current rewards: -337.83674, mean: -0.14315
[32m[0907 02-00-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31318, current rewards: -334.50072, mean: -0.13880
[32m[0907 02-01-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31273, current rewards: -331.16470, mean: -0.13462
[32m[0907 02-01-25 @Agent.py:117][0m Average action selection time: 0.3125
[32m[0907 02-01-25 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-01-25 @MBExp.py:227][0m Rewards obtained: [-342.4657159850767], Lows: [113], Highs: [394], Total time: 41916.16047300001
[32m[0907 02-02-58 @MBExp.py:144][0m ####################################################################
[32m[0907 02-02-58 @MBExp.py:145][0m Starting training iteration 51.
[32m[0907 02-03-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31719, current rewards: 1.18103, mean: 0.11810
[32m[0907 02-03-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31542, current rewards: -6.52428, mean: -0.10874
[32m[0907 02-03-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31403, current rewards: -0.29552, mean: -0.00269
[32m[0907 02-03-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31228, current rewards: 4.69240, mean: 0.02933
[32m[0907 02-04-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31131, current rewards: 9.67811, mean: 0.04609
[32m[0907 02-04-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31094, current rewards: 14.66030, mean: 0.05639
[32m[0907 02-04-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31063, current rewards: 19.64458, mean: 0.06337
[32m[0907 02-04-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31038, current rewards: 24.62470, mean: 0.06840
[32m[0907 02-05-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31048, current rewards: 29.60539, mean: 0.07221
[32m[0907 02-05-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31117, current rewards: 39.02470, mean: 0.08484
[32m[0907 02-05-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31148, current rewards: 2.79102, mean: 0.00547
[32m[0907 02-05-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31187, current rewards: -46.61320, mean: -0.08324
[32m[0907 02-06-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31206, current rewards: -93.87702, mean: -0.15390
[32m[0907 02-06-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31231, current rewards: -130.00983, mean: -0.19698
[32m[0907 02-06-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31257, current rewards: -165.50421, mean: -0.23310
[32m[0907 02-06-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31273, current rewards: -214.28600, mean: -0.28196
[32m[0907 02-07-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31288, current rewards: -267.71457, mean: -0.33051
[32m[0907 02-07-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31301, current rewards: -318.97733, mean: -0.37090
[32m[0907 02-07-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31315, current rewards: -314.64597, mean: -0.34576
[32m[0907 02-07-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31327, current rewards: -308.81587, mean: -0.32168
[32m[0907 02-08-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31340, current rewards: -302.98755, mean: -0.29999
[32m[0907 02-08-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31353, current rewards: -297.15292, mean: -0.28033
[32m[0907 02-08-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31362, current rewards: -291.31907, mean: -0.26245
[32m[0907 02-09-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31368, current rewards: -285.49910, mean: -0.24612
[32m[0907 02-09-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31368, current rewards: -279.66727, mean: -0.23113
[32m[0907 02-09-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31371, current rewards: -277.80135, mean: -0.22048
[32m[0907 02-09-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31375, current rewards: -288.61829, mean: -0.22032
[32m[0907 02-10-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31381, current rewards: -282.09387, mean: -0.20742
[32m[0907 02-10-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31386, current rewards: -276.88242, mean: -0.19637
[32m[0907 02-10-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31389, current rewards: -293.62713, mean: -0.20111
[32m[0907 02-10-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31390, current rewards: -288.69725, mean: -0.19119
[32m[0907 02-11-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31395, current rewards: -284.07328, mean: -0.18210
[32m[0907 02-11-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31398, current rewards: -279.49814, mean: -0.17360
[32m[0907 02-11-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31401, current rewards: -274.98010, mean: -0.16565
[32m[0907 02-11-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31403, current rewards: -271.01101, mean: -0.15849
[32m[0907 02-12-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31406, current rewards: -266.54670, mean: -0.15145
[32m[0907 02-12-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31408, current rewards: -261.49299, mean: -0.14447
[32m[0907 02-12-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31413, current rewards: -256.78097, mean: -0.13805
[32m[0907 02-12-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31416, current rewards: -293.13510, mean: -0.15347
[32m[0907 02-13-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31416, current rewards: -288.60093, mean: -0.14725
[32m[0907 02-13-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31415, current rewards: -284.03216, mean: -0.14131
[32m[0907 02-13-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31417, current rewards: -279.46080, mean: -0.13566
[32m[0907 02-14-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31416, current rewards: -274.89441, mean: -0.13028
[32m[0907 02-14-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31416, current rewards: -270.32222, mean: -0.12515
[32m[0907 02-14-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31402, current rewards: -265.75536, mean: -0.12025
[32m[0907 02-14-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31388, current rewards: -261.18563, mean: -0.11557
[32m[0907 02-15-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31375, current rewards: -256.61506, mean: -0.11109
[32m[0907 02-15-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31362, current rewards: -256.83279, mean: -0.10883
[32m[0907 02-15-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31337, current rewards: -261.07057, mean: -0.10833
[32m[0907 02-15-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31294, current rewards: -259.95151, mean: -0.10567
[32m[0907 02-16-01 @Agent.py:117][0m Average action selection time: 0.3126
[32m[0907 02-16-01 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-16-01 @MBExp.py:227][0m Rewards obtained: [-260.1252133255484], Lows: [234], Highs: [54], Total time: 42698.43652500001
[32m[0907 02-17-36 @MBExp.py:144][0m ####################################################################
[32m[0907 02-17-36 @MBExp.py:145][0m Starting training iteration 52.
[32m[0907 02-17-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32792, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-17-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31787, current rewards: -25.48806, mean: -0.42480
[32m[0907 02-18-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31436, current rewards: -20.33127, mean: -0.18483
[32m[0907 02-18-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31263, current rewards: -15.15778, mean: -0.09474
[32m[0907 02-18-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31163, current rewards: -9.98691, mean: -0.04756
[32m[0907 02-18-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31102, current rewards: -4.81194, mean: -0.01851
[32m[0907 02-19-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31067, current rewards: 0.35746, mean: 0.00115
[32m[0907 02-19-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31036, current rewards: 5.52909, mean: 0.01536
[32m[0907 02-19-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31054, current rewards: 14.92218, mean: 0.03640
[32m[0907 02-19-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31123, current rewards: 23.44610, mean: 0.05097
[32m[0907 02-20-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31162, current rewards: 28.32130, mean: 0.05553
[32m[0907 02-20-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31196, current rewards: 33.94493, mean: 0.06062
[32m[0907 02-20-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31222, current rewards: 39.56476, mean: 0.06486
[32m[0907 02-21-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31243, current rewards: 45.19287, mean: 0.06847
[32m[0907 02-21-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31254, current rewards: 50.81483, mean: 0.07157
[32m[0907 02-21-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31269, current rewards: 56.44103, mean: 0.07426
[32m[0907 02-21-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31282, current rewards: 20.10832, mean: 0.02483
[32m[0907 02-22-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31296, current rewards: 26.34757, mean: 0.03064
[32m[0907 02-22-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31307, current rewards: 32.16995, mean: 0.03535
[32m[0907 02-22-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31316, current rewards: 37.98890, mean: 0.03957
[32m[0907 02-22-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31324, current rewards: 43.80534, mean: 0.04337
[32m[0907 02-23-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31336, current rewards: 49.62196, mean: 0.04681
[32m[0907 02-23-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31340, current rewards: 55.44435, mean: 0.04995
[32m[0907 02-23-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31349, current rewards: 61.26418, mean: 0.05281
[32m[0907 02-23-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31351, current rewards: 44.55552, mean: 0.03682
[32m[0907 02-24-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31357, current rewards: 31.17488, mean: 0.02474
[32m[0907 02-24-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31359, current rewards: 36.30784, mean: 0.02772
[32m[0907 02-24-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31363, current rewards: 41.36681, mean: 0.03042
[32m[0907 02-24-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31369, current rewards: 46.42794, mean: 0.03293
[32m[0907 02-25-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31373, current rewards: 51.50028, mean: 0.03527
[32m[0907 02-25-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31378, current rewards: 56.56232, mean: 0.03746
[32m[0907 02-25-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31380, current rewards: 61.61982, mean: 0.03950
[32m[0907 02-26-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31384, current rewards: 66.66251, mean: 0.04141
[32m[0907 02-26-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31385, current rewards: 71.71418, mean: 0.04320
[32m[0907 02-26-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31389, current rewards: 76.78973, mean: 0.04491
[32m[0907 02-26-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31390, current rewards: 81.89394, mean: 0.04653
[32m[0907 02-27-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31391, current rewards: 95.22856, mean: 0.05261
[32m[0907 02-27-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31393, current rewards: 100.05635, mean: 0.05379
[32m[0907 02-27-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31395, current rewards: 105.03147, mean: 0.05499
[32m[0907 02-27-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31396, current rewards: 110.01060, mean: 0.05613
[32m[0907 02-28-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31399, current rewards: 114.99028, mean: 0.05721
[32m[0907 02-28-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31401, current rewards: 129.18650, mean: 0.06271
[32m[0907 02-28-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31402, current rewards: 135.33436, mean: 0.06414
[32m[0907 02-28-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31403, current rewards: 140.52666, mean: 0.06506
[32m[0907 02-29-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31391, current rewards: 145.72224, mean: 0.06594
[32m[0907 02-29-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31378, current rewards: 150.91161, mean: 0.06678
[32m[0907 02-29-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31365, current rewards: 156.10722, mean: 0.06758
[32m[0907 02-29-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31353, current rewards: 119.22096, mean: 0.05052
[32m[0907 02-30-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31329, current rewards: 136.22139, mean: 0.05652
[32m[0907 02-30-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31288, current rewards: 143.73358, mean: 0.05843
[32m[0907 02-30-38 @Agent.py:117][0m Average action selection time: 0.3126
[32m[0907 02-30-38 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-30-38 @MBExp.py:227][0m Rewards obtained: [124.05982473762904], Lows: [43], Highs: [83], Total time: 43480.51837300001
[32m[0907 02-32-16 @MBExp.py:144][0m ####################################################################
[32m[0907 02-32-16 @MBExp.py:145][0m Starting training iteration 53.
[32m[0907 02-32-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31803, current rewards: 0.51852, mean: 0.05185
[32m[0907 02-32-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31644, current rewards: 3.17913, mean: 0.05299
[32m[0907 02-32-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31328, current rewards: 5.82871, mean: 0.05299
[32m[0907 02-33-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31174, current rewards: 8.41650, mean: 0.05260
[32m[0907 02-33-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31112, current rewards: 10.99767, mean: 0.05237
[32m[0907 02-33-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31078, current rewards: 13.59104, mean: 0.05227
[32m[0907 02-33-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31058, current rewards: 16.23309, mean: 0.05236
[32m[0907 02-34-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31032, current rewards: 18.82090, mean: 0.05228
[32m[0907 02-34-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31063, current rewards: 4.58244, mean: 0.01118
[32m[0907 02-34-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31105, current rewards: -9.44898, mean: -0.02054
[32m[0907 02-34-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31154, current rewards: -6.47456, mean: -0.01270
[32m[0907 02-35-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31194, current rewards: -3.57485, mean: -0.00638
[32m[0907 02-35-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31221, current rewards: -20.99940, mean: -0.03443
[32m[0907 02-35-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31252, current rewards: -15.47333, mean: -0.02344
[32m[0907 02-35-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31276, current rewards: -9.59792, mean: -0.01352
[32m[0907 02-36-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31286, current rewards: -3.68601, mean: -0.00485
[32m[0907 02-36-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31297, current rewards: 3.15605, mean: 0.00390
[32m[0907 02-36-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31310, current rewards: 10.06533, mean: 0.01170
[32m[0907 02-37-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31327, current rewards: 15.22440, mean: 0.01673
[32m[0907 02-37-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31335, current rewards: -1.75026, mean: -0.00182
[32m[0907 02-37-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31346, current rewards: 4.78005, mean: 0.00473
[32m[0907 02-37-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31354, current rewards: 11.01744, mean: 0.01039
[32m[0907 02-38-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31356, current rewards: 17.25724, mean: 0.01555
[32m[0907 02-38-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31366, current rewards: 23.49246, mean: 0.02025
[32m[0907 02-38-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31375, current rewards: 29.66892, mean: 0.02452
[32m[0907 02-38-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31378, current rewards: 35.49759, mean: 0.02817
[32m[0907 02-39-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31382, current rewards: 41.67860, mean: 0.03182
[32m[0907 02-39-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31384, current rewards: 47.87607, mean: 0.03520
[32m[0907 02-39-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31389, current rewards: 11.27314, mean: 0.00800
[32m[0907 02-39-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31394, current rewards: 15.38344, mean: 0.01054
[32m[0907 02-40-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31398, current rewards: 21.40717, mean: 0.01418
[32m[0907 02-40-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31402, current rewards: 27.71725, mean: 0.01777
[32m[0907 02-40-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31406, current rewards: 34.06026, mean: 0.02116
[32m[0907 02-40-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31407, current rewards: 39.57027, mean: 0.02384
[32m[0907 02-41-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31409, current rewards: 46.23076, mean: 0.02704
[32m[0907 02-41-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31409, current rewards: 8.01233, mean: 0.00455
[32m[0907 02-41-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31411, current rewards: 13.31976, mean: 0.00736
[32m[0907 02-42-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31413, current rewards: 19.36549, mean: 0.01041
[32m[0907 02-42-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31415, current rewards: 25.40445, mean: 0.01330
[32m[0907 02-42-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31415, current rewards: 31.44831, mean: 0.01605
[32m[0907 02-42-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31418, current rewards: 37.49148, mean: 0.01865
[32m[0907 02-43-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31418, current rewards: 43.53094, mean: 0.02113
[32m[0907 02-43-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31419, current rewards: 49.57605, mean: 0.02350
[32m[0907 02-43-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31419, current rewards: 55.61847, mean: 0.02575
[32m[0907 02-43-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31406, current rewards: 61.66854, mean: 0.02790
[32m[0907 02-44-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31392, current rewards: 67.71304, mean: 0.02996
[32m[0907 02-44-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31380, current rewards: 73.76072, mean: 0.03193
[32m[0907 02-44-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31369, current rewards: 79.79913, mean: 0.03381
[32m[0907 02-44-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31346, current rewards: 85.84401, mean: 0.03562
[32m[0907 02-45-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31306, current rewards: 98.29137, mean: 0.03996
[32m[0907 02-45-18 @Agent.py:117][0m Average action selection time: 0.3127
[32m[0907 02-45-18 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-45-18 @MBExp.py:227][0m Rewards obtained: [102.72238881726027], Lows: [41], Highs: [73], Total time: 44262.989774000016
[32m[0907 02-46-58 @MBExp.py:144][0m ####################################################################
[32m[0907 02-46-58 @MBExp.py:145][0m Starting training iteration 54.
[32m[0907 02-47-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31663, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-47-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31623, current rewards: -17.52735, mean: -0.29212
[32m[0907 02-47-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31295, current rewards: -11.85247, mean: -0.10775
[32m[0907 02-47-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31167, current rewards: -6.16312, mean: -0.03852
[32m[0907 02-48-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31081, current rewards: -0.46541, mean: -0.00222
[32m[0907 02-48-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31045, current rewards: 5.23049, mean: 0.02012
[32m[0907 02-48-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31022, current rewards: 10.92088, mean: 0.03523
[32m[0907 02-48-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30995, current rewards: 15.54527, mean: 0.04318
[32m[0907 02-49-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31032, current rewards: 20.83444, mean: 0.05082
[32m[0907 02-49-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31080, current rewards: 26.81004, mean: 0.05828
[32m[0907 02-49-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31121, current rewards: 6.35487, mean: 0.01246
[32m[0907 02-49-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31151, current rewards: 9.85947, mean: 0.01761
[32m[0907 02-50-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31182, current rewards: 15.54938, mean: 0.02549
[32m[0907 02-50-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31207, current rewards: 21.25558, mean: 0.03221
[32m[0907 02-50-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31230, current rewards: 26.97270, mean: 0.03799
[32m[0907 02-50-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31248, current rewards: 32.65657, mean: 0.04297
[32m[0907 02-51-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31265, current rewards: 38.31621, mean: 0.04730
[32m[0907 02-51-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31278, current rewards: 44.02698, mean: 0.05119
[32m[0907 02-51-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31292, current rewards: 49.73890, mean: 0.05466
[32m[0907 02-51-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31299, current rewards: 55.44219, mean: 0.05775
[32m[0907 02-52-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31309, current rewards: 61.15926, mean: 0.06055
[32m[0907 02-52-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31321, current rewards: 66.87649, mean: 0.06309
[32m[0907 02-52-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31332, current rewards: 72.59064, mean: 0.06540
[32m[0907 02-53-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31342, current rewards: 78.36814, mean: 0.06756
[32m[0907 02-53-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31346, current rewards: 20.85678, mean: 0.01724
[32m[0907 02-53-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31348, current rewards: 28.22015, mean: 0.02240
[32m[0907 02-53-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31354, current rewards: 34.74087, mean: 0.02652
[32m[0907 02-54-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31358, current rewards: 41.74103, mean: 0.03069
[32m[0907 02-54-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31363, current rewards: 48.73040, mean: 0.03456
[32m[0907 02-54-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31371, current rewards: 55.72037, mean: 0.03816
[32m[0907 02-54-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31373, current rewards: 54.73205, mean: 0.03625
[32m[0907 02-55-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31377, current rewards: 43.31686, mean: 0.02777
[32m[0907 02-55-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31380, current rewards: 48.11572, mean: 0.02989
[32m[0907 02-55-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31383, current rewards: 53.68358, mean: 0.03234
[32m[0907 02-55-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31385, current rewards: 59.51214, mean: 0.03480
[32m[0907 02-56-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31386, current rewards: 65.34572, mean: 0.03713
[32m[0907 02-56-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31388, current rewards: 28.51656, mean: 0.01576
[32m[0907 02-56-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31391, current rewards: 34.23972, mean: 0.01841
[32m[0907 02-56-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31394, current rewards: 39.82220, mean: 0.02085
[32m[0907 02-57-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31394, current rewards: 45.40477, mean: 0.02317
[32m[0907 02-57-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31396, current rewards: 51.30058, mean: 0.02552
[32m[0907 02-57-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31396, current rewards: 62.58368, mean: 0.03038
[32m[0907 02-58-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31395, current rewards: 68.24888, mean: 0.03235
[32m[0907 02-58-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31396, current rewards: 73.90779, mean: 0.03422
[32m[0907 02-58-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31382, current rewards: 79.56902, mean: 0.03600
[32m[0907 02-58-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31368, current rewards: 85.22104, mean: 0.03771
[32m[0907 02-59-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31356, current rewards: 78.20832, mean: 0.03386
[32m[0907 02-59-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31344, current rewards: 52.56095, mean: 0.02227
[32m[0907 02-59-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31322, current rewards: 57.94464, mean: 0.02404
[32m[0907 02-59-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31286, current rewards: 62.69838, mean: 0.02549
[32m[0907 02-59-59 @Agent.py:117][0m Average action selection time: 0.3125
[32m[0907 02-59-59 @Agent.py:118][0m Rollout length: 2520
[32m[0907 02-59-59 @MBExp.py:227][0m Rewards obtained: [67.0117406081985], Lows: [75], Highs: [65], Total time: 45044.947752000015
[32m[0907 03-01-40 @MBExp.py:144][0m ####################################################################
[32m[0907 03-01-40 @MBExp.py:145][0m Starting training iteration 55.
[32m[0907 03-01-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31792, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-01-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31555, current rewards: -57.70481, mean: -0.96175
[32m[0907 03-02-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31251, current rewards: -98.16672, mean: -0.89242
[32m[0907 03-02-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31132, current rewards: -137.46641, mean: -0.85917
[32m[0907 03-02-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31084, current rewards: -169.32751, mean: -0.80632
[32m[0907 03-03-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31042, current rewards: -204.30599, mean: -0.78579
[32m[0907 03-03-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31017, current rewards: -235.09342, mean: -0.75837
[32m[0907 03-03-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30995, current rewards: -261.50221, mean: -0.72640
[32m[0907 03-03-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31020, current rewards: -290.17064, mean: -0.70773
[32m[0907 03-04-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31084, current rewards: -310.31199, mean: -0.67459
[32m[0907 03-04-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31139, current rewards: -336.88400, mean: -0.66056
[32m[0907 03-04-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31175, current rewards: -369.91816, mean: -0.66057
[32m[0907 03-04-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31205, current rewards: -384.63917, mean: -0.63056
[32m[0907 03-05-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31233, current rewards: -390.62091, mean: -0.59185
[32m[0907 03-05-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31262, current rewards: -392.12952, mean: -0.55230
[32m[0907 03-05-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31287, current rewards: -392.31336, mean: -0.51620
[32m[0907 03-05-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31309, current rewards: -385.09090, mean: -0.47542
[32m[0907 03-06-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31323, current rewards: -376.87631, mean: -0.43823
[32m[0907 03-06-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31339, current rewards: -388.39799, mean: -0.42681
[32m[0907 03-06-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31351, current rewards: -389.34013, mean: -0.40556
[32m[0907 03-06-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31362, current rewards: -383.13144, mean: -0.37934
[32m[0907 03-07-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31365, current rewards: -376.34645, mean: -0.35504
[32m[0907 03-07-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31373, current rewards: -369.37700, mean: -0.33277
[32m[0907 03-07-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31382, current rewards: -362.31266, mean: -0.31234
[32m[0907 03-08-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31385, current rewards: -368.20394, mean: -0.30430
[32m[0907 03-08-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31389, current rewards: -394.17417, mean: -0.31284
[32m[0907 03-08-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31394, current rewards: -387.25810, mean: -0.29562
[32m[0907 03-08-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31402, current rewards: -380.54571, mean: -0.27981
[32m[0907 03-09-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31409, current rewards: -373.83194, mean: -0.26513
[32m[0907 03-09-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31413, current rewards: -367.10570, mean: -0.25144
[32m[0907 03-09-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31423, current rewards: -360.38665, mean: -0.23867
[32m[0907 03-09-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31429, current rewards: -353.67637, mean: -0.22672
[32m[0907 03-10-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31432, current rewards: -344.13372, mean: -0.21375
[32m[0907 03-10-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31435, current rewards: -338.19394, mean: -0.20373
[32m[0907 03-10-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31438, current rewards: -331.70924, mean: -0.19398
[32m[0907 03-10-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31439, current rewards: -325.22979, mean: -0.18479
[32m[0907 03-11-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31438, current rewards: -318.74051, mean: -0.17610
[32m[0907 03-11-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31438, current rewards: -312.24908, mean: -0.16788
[32m[0907 03-11-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31438, current rewards: -305.75805, mean: -0.16008
[32m[0907 03-11-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31440, current rewards: -320.56848, mean: -0.16356
[32m[0907 03-12-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31441, current rewards: -349.59871, mean: -0.17393
[32m[0907 03-12-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31442, current rewards: -352.50366, mean: -0.17112
[32m[0907 03-12-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31442, current rewards: -347.84220, mean: -0.16485
[32m[0907 03-13-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31443, current rewards: -342.33114, mean: -0.15849
[32m[0907 03-13-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31428, current rewards: -336.79899, mean: -0.15240
[32m[0907 03-13-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31413, current rewards: -331.27437, mean: -0.14658
[32m[0907 03-13-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31398, current rewards: -325.74416, mean: -0.14101
[32m[0907 03-14-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31383, current rewards: -320.21676, mean: -0.13569
[32m[0907 03-14-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31358, current rewards: -314.68680, mean: -0.13058
[32m[0907 03-14-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31322, current rewards: -318.36478, mean: -0.12942
[32m[0907 03-14-43 @Agent.py:117][0m Average action selection time: 0.3129
[32m[0907 03-14-43 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-14-43 @MBExp.py:227][0m Rewards obtained: [-337.29996954138414], Lows: [58], Highs: [464], Total time: 45827.732489000016
[32m[0907 03-16-25 @MBExp.py:144][0m ####################################################################
[32m[0907 03-16-25 @MBExp.py:145][0m Starting training iteration 56.
[32m[0907 03-16-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31615, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-16-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31409, current rewards: -45.01315, mean: -0.75022
[32m[0907 03-17-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31161, current rewards: -39.11430, mean: -0.35558
[32m[0907 03-17-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31076, current rewards: -33.88505, mean: -0.21178
[32m[0907 03-17-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31013, current rewards: -28.64717, mean: -0.13642
[32m[0907 03-17-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30979, current rewards: -23.41001, mean: -0.09004
[32m[0907 03-18-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30963, current rewards: -18.17178, mean: -0.05862
[32m[0907 03-18-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30942, current rewards: -12.94122, mean: -0.03595
[32m[0907 03-18-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30967, current rewards: -32.10204, mean: -0.07830
[32m[0907 03-18-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31037, current rewards: -25.71405, mean: -0.05590
[32m[0907 03-19-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31102, current rewards: -20.67634, mean: -0.04054
[32m[0907 03-19-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31147, current rewards: -15.76152, mean: -0.02815
[32m[0907 03-19-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31174, current rewards: -10.83919, mean: -0.01777
[32m[0907 03-19-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31202, current rewards: -5.91431, mean: -0.00896
[32m[0907 03-20-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31223, current rewards: -0.99535, mean: -0.00140
[32m[0907 03-20-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31236, current rewards: 3.92758, mean: 0.00517
[32m[0907 03-20-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31245, current rewards: 15.89584, mean: 0.01962
[32m[0907 03-20-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31263, current rewards: 21.61886, mean: 0.02514
[32m[0907 03-21-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31273, current rewards: 25.54332, mean: 0.02807
[32m[0907 03-21-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31282, current rewards: 31.43269, mean: 0.03274
[32m[0907 03-21-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31291, current rewards: 37.20397, mean: 0.03684
[32m[0907 03-21-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31299, current rewards: 7.01259, mean: 0.00662
[32m[0907 03-22-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31306, current rewards: 5.15965, mean: 0.00465
[32m[0907 03-22-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31311, current rewards: 11.00961, mean: 0.00949
[32m[0907 03-22-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31319, current rewards: 16.80729, mean: 0.01389
[32m[0907 03-23-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31325, current rewards: 20.05613, mean: 0.01592
[32m[0907 03-23-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31327, current rewards: 26.28257, mean: 0.02006
[32m[0907 03-23-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31329, current rewards: 32.75082, mean: 0.02408
[32m[0907 03-23-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31331, current rewards: 39.21583, mean: 0.02781
[32m[0907 03-24-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31338, current rewards: 45.68104, mean: 0.03129
[32m[0907 03-24-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31340, current rewards: 52.15614, mean: 0.03454
[32m[0907 03-24-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31341, current rewards: 58.62041, mean: 0.03758
[32m[0907 03-24-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31342, current rewards: 65.08385, mean: 0.04042
[32m[0907 03-25-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31345, current rewards: 59.78265, mean: 0.03601
[32m[0907 03-25-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31348, current rewards: 65.05110, mean: 0.03804
[32m[0907 03-25-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31348, current rewards: 19.86815, mean: 0.01129
[32m[0907 03-25-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31350, current rewards: 22.56556, mean: 0.01247
[32m[0907 03-26-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31353, current rewards: 27.25522, mean: 0.01465
[32m[0907 03-26-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31356, current rewards: 31.94249, mean: 0.01672
[32m[0907 03-26-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31360, current rewards: 36.63339, mean: 0.01869
[32m[0907 03-26-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31363, current rewards: 41.32117, mean: 0.02056
[32m[0907 03-27-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31364, current rewards: 45.98038, mean: 0.02232
[32m[0907 03-27-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31364, current rewards: 50.63069, mean: 0.02400
[32m[0907 03-27-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31364, current rewards: 55.31212, mean: 0.02561
[32m[0907 03-27-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31351, current rewards: 59.99451, mean: 0.02715
[32m[0907 03-28-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31337, current rewards: 64.67787, mean: 0.02862
[32m[0907 03-28-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31324, current rewards: 69.35907, mean: 0.03003
[32m[0907 03-28-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31312, current rewards: 53.10670, mean: 0.02250
[32m[0907 03-29-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31291, current rewards: 38.39399, mean: 0.01593
[32m[0907 03-29-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31259, current rewards: 42.58935, mean: 0.01731
[32m[0907 03-29-27 @Agent.py:117][0m Average action selection time: 0.3123
[32m[0907 03-29-27 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-29-27 @MBExp.py:227][0m Rewards obtained: [45.94060006023521], Lows: [88], Highs: [43], Total time: 46609.044858000016
[32m[0907 03-31-11 @MBExp.py:144][0m ####################################################################
[32m[0907 03-31-11 @MBExp.py:145][0m Starting training iteration 57.
[32m[0907 03-31-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31726, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-31-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31400, current rewards: -16.05761, mean: -0.26763
[32m[0907 03-31-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31122, current rewards: -9.98953, mean: -0.09081
[32m[0907 03-32-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31025, current rewards: -3.93125, mean: -0.02457
[32m[0907 03-32-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30977, current rewards: 2.13395, mean: 0.01016
[32m[0907 03-32-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30944, current rewards: 8.19812, mean: 0.03153
[32m[0907 03-32-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30933, current rewards: 14.25763, mean: 0.04599
[32m[0907 03-33-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30933, current rewards: 20.41317, mean: 0.05670
[32m[0907 03-33-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30961, current rewards: -3.88113, mean: -0.00947
[32m[0907 03-33-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31029, current rewards: 2.44415, mean: 0.00531
[32m[0907 03-33-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31077, current rewards: 8.47800, mean: 0.01662
[32m[0907 03-34-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31117, current rewards: 14.50931, mean: 0.02591
[32m[0907 03-34-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31155, current rewards: 20.54241, mean: 0.03368
[32m[0907 03-34-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31185, current rewards: -14.67038, mean: -0.02223
[32m[0907 03-34-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31221, current rewards: -8.06192, mean: -0.01135
[32m[0907 03-35-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31240, current rewards: -1.49788, mean: -0.00197
[32m[0907 03-35-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31264, current rewards: -37.27454, mean: -0.04602
[32m[0907 03-35-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31277, current rewards: -41.23069, mean: -0.04794
[32m[0907 03-35-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31293, current rewards: -38.95796, mean: -0.04281
[32m[0907 03-36-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31315, current rewards: -32.99954, mean: -0.03437
[32m[0907 03-36-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31328, current rewards: -27.48221, mean: -0.02721
[32m[0907 03-36-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31340, current rewards: -21.98226, mean: -0.02074
[32m[0907 03-36-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31349, current rewards: -16.48027, mean: -0.01485
[32m[0907 03-37-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31356, current rewards: -10.97721, mean: -0.00946
[32m[0907 03-37-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31366, current rewards: -6.45419, mean: -0.00533
[32m[0907 03-37-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31377, current rewards: -9.13091, mean: -0.00725
[32m[0907 03-38-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31381, current rewards: -3.46048, mean: -0.00264
[32m[0907 03-38-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31388, current rewards: -20.56435, mean: -0.01512
[32m[0907 03-38-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31393, current rewards: -13.05454, mean: -0.00926
[32m[0907 03-38-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31396, current rewards: -5.59255, mean: -0.00383
[32m[0907 03-39-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31401, current rewards: 1.86449, mean: 0.00123
[32m[0907 03-39-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31406, current rewards: 9.34430, mean: 0.00599
[32m[0907 03-39-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31412, current rewards: 17.10282, mean: 0.01062
[32m[0907 03-39-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31417, current rewards: -2.29151, mean: -0.00138
[32m[0907 03-40-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31420, current rewards: 4.31854, mean: 0.00253
[32m[0907 03-40-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31424, current rewards: 10.90933, mean: 0.00620
[32m[0907 03-40-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31429, current rewards: 16.03643, mean: 0.00886
[32m[0907 03-40-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31432, current rewards: 23.96411, mean: 0.01288
[32m[0907 03-41-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31435, current rewards: 32.68738, mean: 0.01711
[32m[0907 03-41-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31438, current rewards: 41.46684, mean: 0.02116
[32m[0907 03-41-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31440, current rewards: 50.25149, mean: 0.02500
[32m[0907 03-41-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31442, current rewards: 59.02816, mean: 0.02865
[32m[0907 03-42-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31443, current rewards: 67.80842, mean: 0.03214
[32m[0907 03-42-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31445, current rewards: 76.57646, mean: 0.03545
[32m[0907 03-42-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31431, current rewards: 85.33832, mean: 0.03861
[32m[0907 03-43-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31419, current rewards: 54.94603, mean: 0.02431
[32m[0907 03-43-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31407, current rewards: 59.48216, mean: 0.02575
[32m[0907 03-43-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31396, current rewards: 65.48294, mean: 0.02775
[32m[0907 03-43-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31374, current rewards: 71.42221, mean: 0.02964
[32m[0907 03-44-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31343, current rewards: 75.94617, mean: 0.03087
[32m[0907 03-44-14 @Agent.py:117][0m Average action selection time: 0.3131
[32m[0907 03-44-14 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-44-14 @MBExp.py:227][0m Rewards obtained: [80.29521028245652], Lows: [105], Highs: [41], Total time: 47392.43140200002
[32m[0907 03-46-01 @MBExp.py:144][0m ####################################################################
[32m[0907 03-46-01 @MBExp.py:145][0m Starting training iteration 58.
[32m[0907 03-46-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31798, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-46-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31383, current rewards: -15.92734, mean: -0.26546
[32m[0907 03-46-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31152, current rewards: -10.09698, mean: -0.09179
[32m[0907 03-46-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31092, current rewards: -4.09048, mean: -0.02557
[32m[0907 03-47-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31057, current rewards: 1.92392, mean: 0.00916
[32m[0907 03-47-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31026, current rewards: 7.94233, mean: 0.03055
[32m[0907 03-47-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31010, current rewards: 13.97020, mean: 0.04507
[32m[0907 03-47-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30996, current rewards: -21.11537, mean: -0.05865
[32m[0907 03-48-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31012, current rewards: -16.09620, mean: -0.03926
[32m[0907 03-48-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31084, current rewards: -10.90478, mean: -0.02371
[32m[0907 03-48-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31139, current rewards: -5.70287, mean: -0.01118
[32m[0907 03-48-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31171, current rewards: -0.50741, mean: -0.00091
[32m[0907 03-49-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31203, current rewards: 4.68778, mean: 0.00768
[32m[0907 03-49-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31239, current rewards: 1.05432, mean: 0.00160
[32m[0907 03-49-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31269, current rewards: -7.45150, mean: -0.01050
[32m[0907 03-49-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31291, current rewards: -2.38272, mean: -0.00314
[32m[0907 03-50-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31315, current rewards: 2.60384, mean: 0.00321
[32m[0907 03-50-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31329, current rewards: 8.22400, mean: 0.00956
[32m[0907 03-50-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31343, current rewards: 13.82653, mean: 0.01519
[32m[0907 03-51-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31353, current rewards: 19.43236, mean: 0.02024
[32m[0907 03-51-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31360, current rewards: 25.04640, mean: 0.02480
[32m[0907 03-51-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31367, current rewards: 30.65813, mean: 0.02892
[32m[0907 03-51-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31377, current rewards: 36.27509, mean: 0.03268
[32m[0907 03-52-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31383, current rewards: 41.88126, mean: 0.03610
[32m[0907 03-52-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31388, current rewards: 16.81407, mean: 0.01390
[32m[0907 03-52-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31391, current rewards: 25.97624, mean: 0.02062
[32m[0907 03-52-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31396, current rewards: 31.26387, mean: 0.02387
[32m[0907 03-53-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31402, current rewards: 36.94088, mean: 0.02716
[32m[0907 03-53-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31406, current rewards: 42.62218, mean: 0.03023
[32m[0907 03-53-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31406, current rewards: 48.30396, mean: 0.03308
[32m[0907 03-53-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31410, current rewards: 53.98149, mean: 0.03575
[32m[0907 03-54-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31410, current rewards: 59.65814, mean: 0.03824
[32m[0907 03-54-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31414, current rewards: 64.91197, mean: 0.04032
[32m[0907 03-54-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31415, current rewards: 70.34074, mean: 0.04237
[32m[0907 03-54-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31417, current rewards: 35.15216, mean: 0.02056
[32m[0907 03-55-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31417, current rewards: 40.89160, mean: 0.02323
[32m[0907 03-55-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31412, current rewards: 46.56500, mean: 0.02573
[32m[0907 03-55-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31414, current rewards: 52.23830, mean: 0.02809
[32m[0907 03-56-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31413, current rewards: 57.91526, mean: 0.03032
[32m[0907 03-56-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31412, current rewards: 63.59130, mean: 0.03244
[32m[0907 03-56-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31412, current rewards: 69.59371, mean: 0.03462
[32m[0907 03-56-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31412, current rewards: 76.76397, mean: 0.03726
[32m[0907 03-57-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31414, current rewards: 82.31422, mean: 0.03901
[32m[0907 03-57-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31413, current rewards: 45.84586, mean: 0.02122
[32m[0907 03-57-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31407, current rewards: 53.70540, mean: 0.02430
[32m[0907 03-57-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31392, current rewards: 61.56493, mean: 0.02724
[32m[0907 03-58-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31378, current rewards: 69.42447, mean: 0.03005
[32m[0907 03-58-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31364, current rewards: 77.28401, mean: 0.03275
[32m[0907 03-58-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31343, current rewards: 85.14355, mean: 0.03533
[32m[0907 03-58-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31313, current rewards: 93.68147, mean: 0.03808
[32m[0907 03-59-03 @Agent.py:117][0m Average action selection time: 0.3128
[32m[0907 03-59-03 @Agent.py:118][0m Rollout length: 2520
[32m[0907 03-59-03 @MBExp.py:227][0m Rewards obtained: [98.91612137823321], Lows: [79], Highs: [40], Total time: 48175.06876300002
[32m[0907 04-00-52 @MBExp.py:144][0m ####################################################################
[32m[0907 04-00-52 @MBExp.py:145][0m Starting training iteration 59.
[32m[0907 04-00-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32023, current rewards: 0.82823, mean: 0.08282
[32m[0907 04-01-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31238, current rewards: 6.96875, mean: 0.11615
[32m[0907 04-01-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31056, current rewards: 18.84707, mean: 0.17134
[32m[0907 04-01-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31012, current rewards: 30.85373, mean: 0.19284
[32m[0907 04-01-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30988, current rewards: 42.94402, mean: 0.20450
[32m[0907 04-02-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30986, current rewards: 39.49066, mean: 0.15189
[32m[0907 04-02-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30976, current rewards: 37.49745, mean: 0.12096
[32m[0907 04-02-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30968, current rewards: 42.82928, mean: 0.11897
[32m[0907 04-02-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30995, current rewards: 47.92298, mean: 0.11689
[32m[0907 04-03-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31068, current rewards: 28.88189, mean: 0.06279
[32m[0907 04-03-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31119, current rewards: 25.30559, mean: 0.04962
[32m[0907 04-03-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31151, current rewards: 31.45936, mean: 0.05618
[32m[0907 04-04-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31178, current rewards: 38.07368, mean: 0.06242
[32m[0907 04-04-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31203, current rewards: 44.68577, mean: 0.06771
[32m[0907 04-04-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31226, current rewards: 51.30689, mean: 0.07226
[32m[0907 04-04-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31243, current rewards: 56.21169, mean: 0.07396
[32m[0907 04-05-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31262, current rewards: 52.19811, mean: 0.06444
[32m[0907 04-05-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31275, current rewards: 9.35811, mean: 0.01088
[32m[0907 04-05-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31289, current rewards: 4.74025, mean: 0.00521
[32m[0907 04-05-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31299, current rewards: 10.15122, mean: 0.01057
[32m[0907 04-06-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31312, current rewards: 15.29256, mean: 0.01514
[32m[0907 04-06-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31324, current rewards: 20.32149, mean: 0.01917
[32m[0907 04-06-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31330, current rewards: 25.38147, mean: 0.02287
[32m[0907 04-06-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31335, current rewards: 30.96888, mean: 0.02670
[32m[0907 04-07-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31341, current rewards: 39.52553, mean: 0.03267
[32m[0907 04-07-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31346, current rewards: 6.69024, mean: 0.00531
[32m[0907 04-07-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31352, current rewards: 7.90102, mean: 0.00603
[32m[0907 04-07-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31358, current rewards: 13.81673, mean: 0.01016
[32m[0907 04-08-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31361, current rewards: 19.73586, mean: 0.01400
[32m[0907 04-08-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31367, current rewards: 25.65296, mean: 0.01757
[32m[0907 04-08-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31371, current rewards: 31.56965, mean: 0.02091
[32m[0907 04-09-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31375, current rewards: 6.97723, mean: 0.00447
[32m[0907 04-09-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31377, current rewards: -2.61933, mean: -0.00163
[32m[0907 04-09-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31380, current rewards: 2.58318, mean: 0.00156
[32m[0907 04-09-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31381, current rewards: 14.64739, mean: 0.00857
[32m[0907 04-10-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31384, current rewards: 20.32023, mean: 0.01155
[32m[0907 04-10-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31387, current rewards: 26.95466, mean: 0.01489
[32m[0907 04-10-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31387, current rewards: 33.59532, mean: 0.01806
[32m[0907 04-10-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31388, current rewards: -6.65343, mean: -0.00348
[32m[0907 04-11-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31389, current rewards: 1.00176, mean: 0.00051
[32m[0907 04-11-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31390, current rewards: 5.82511, mean: 0.00290
[32m[0907 04-11-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31390, current rewards: 9.62436, mean: 0.00467
[32m[0907 04-11-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31393, current rewards: -14.56611, mean: -0.00690
[32m[0907 04-12-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31395, current rewards: -27.90648, mean: -0.01292
[32m[0907 04-12-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31392, current rewards: -30.76678, mean: -0.01392
[32m[0907 04-12-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31380, current rewards: -31.02500, mean: -0.01373
[32m[0907 04-12-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31369, current rewards: -23.94264, mean: -0.01036
[32m[0907 04-13-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31358, current rewards: -18.99802, mean: -0.00805
[32m[0907 04-13-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31337, current rewards: -11.12147, mean: -0.00461
[32m[0907 04-13-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31308, current rewards: -50.46328, mean: -0.02051
[32m[0907 04-13-54 @Agent.py:117][0m Average action selection time: 0.3128
[32m[0907 04-13-54 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-13-54 @MBExp.py:227][0m Rewards obtained: [-53.263806865946606], Lows: [126], Highs: [114], Total time: 48957.674544000016
[32m[0907 04-15-44 @MBExp.py:144][0m ####################################################################
[32m[0907 04-15-44 @MBExp.py:145][0m Starting training iteration 60.
[32m[0907 04-15-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31946, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-16-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31194, current rewards: -18.14141, mean: -0.30236
[32m[0907 04-16-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31054, current rewards: -16.51411, mean: -0.15013
[32m[0907 04-16-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31030, current rewards: -13.92950, mean: -0.08706
[32m[0907 04-16-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31005, current rewards: -13.94529, mean: -0.06641
[32m[0907 04-17-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30986, current rewards: -31.42289, mean: -0.12086
[32m[0907 04-17-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30978, current rewards: -26.17075, mean: -0.08442
[32m[0907 04-17-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30957, current rewards: -20.96767, mean: -0.05824
[32m[0907 04-17-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30993, current rewards: -15.88821, mean: -0.03875
[32m[0907 04-18-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31067, current rewards: -10.79612, mean: -0.02347
[32m[0907 04-18-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31129, current rewards: -5.71042, mean: -0.01120
[32m[0907 04-18-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31174, current rewards: -0.61834, mean: -0.00110
[32m[0907 04-18-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31217, current rewards: 4.46687, mean: 0.00732
[32m[0907 04-19-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31261, current rewards: 9.55374, mean: 0.01448
[32m[0907 04-19-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31289, current rewards: 14.64026, mean: 0.02062
[32m[0907 04-19-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31313, current rewards: 19.73405, mean: 0.02597
[32m[0907 04-19-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31330, current rewards: 24.82265, mean: 0.03065
[32m[0907 04-20-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31342, current rewards: 29.91185, mean: 0.03478
[32m[0907 04-20-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31353, current rewards: 26.18758, mean: 0.02878
[32m[0907 04-20-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31362, current rewards: 5.61782, mean: 0.00585
[32m[0907 04-21-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31372, current rewards: 6.24816, mean: 0.00619
[32m[0907 04-21-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31380, current rewards: 8.76788, mean: 0.00827
[32m[0907 04-21-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31384, current rewards: 13.11539, mean: 0.01182
[32m[0907 04-21-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31393, current rewards: -22.29408, mean: -0.01922
[32m[0907 04-22-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31400, current rewards: -18.53902, mean: -0.01532
[32m[0907 04-22-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31401, current rewards: -15.46416, mean: -0.01227
[32m[0907 04-22-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31408, current rewards: -10.72015, mean: -0.00818
[32m[0907 04-22-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31410, current rewards: -5.72577, mean: -0.00421
[32m[0907 04-23-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31412, current rewards: -56.18138, mean: -0.03984
[32m[0907 04-23-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31415, current rewards: -48.20398, mean: -0.03302
[32m[0907 04-23-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31418, current rewards: -42.71449, mean: -0.02829
[32m[0907 04-23-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31420, current rewards: -55.00958, mean: -0.03526
[32m[0907 04-24-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31422, current rewards: -49.66447, mean: -0.03085
[32m[0907 04-24-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31422, current rewards: -43.05057, mean: -0.02593
[32m[0907 04-24-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31424, current rewards: -36.42808, mean: -0.02130
[32m[0907 04-24-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31426, current rewards: -29.82179, mean: -0.01694
[32m[0907 04-25-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31424, current rewards: -23.20260, mean: -0.01282
[32m[0907 04-25-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31424, current rewards: -16.58393, mean: -0.00892
[32m[0907 04-25-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31425, current rewards: -9.96998, mean: -0.00522
[32m[0907 04-26-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31424, current rewards: -3.25545, mean: -0.00166
[32m[0907 04-26-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31428, current rewards: -18.81677, mean: -0.00936
[32m[0907 04-26-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31430, current rewards: -11.40604, mean: -0.00554
[32m[0907 04-26-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31431, current rewards: -6.66438, mean: -0.00316
[32m[0907 04-27-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31434, current rewards: -1.95941, mean: -0.00091
[32m[0907 04-27-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31431, current rewards: 2.74948, mean: 0.00124
[32m[0907 04-27-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31417, current rewards: 7.46037, mean: 0.00330
[32m[0907 04-27-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31403, current rewards: 12.17803, mean: 0.00527
[32m[0907 04-28-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31390, current rewards: 17.22970, mean: 0.00730
[32m[0907 04-28-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31368, current rewards: 24.54180, mean: 0.01018
[32m[0907 04-28-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31338, current rewards: 29.12856, mean: 0.01184
[32m[0907 04-28-47 @Agent.py:117][0m Average action selection time: 0.3130
[32m[0907 04-28-47 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-28-47 @MBExp.py:227][0m Rewards obtained: [32.80133992804675], Lows: [81], Highs: [94], Total time: 49740.951645000016
[32m[0907 04-30-39 @MBExp.py:144][0m ####################################################################
[32m[0907 04-30-39 @MBExp.py:145][0m Starting training iteration 61.
[32m[0907 04-30-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31719, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-30-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31054, current rewards: -28.43221, mean: -0.47387
[32m[0907 04-31-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30969, current rewards: -19.97440, mean: -0.18159
[32m[0907 04-31-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30958, current rewards: -12.48609, mean: -0.07804
[32m[0907 04-31-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30939, current rewards: -5.00080, mean: -0.02381
[32m[0907 04-31-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30921, current rewards: 2.47452, mean: 0.00952
[32m[0907 04-32-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30906, current rewards: 7.93059, mean: 0.02558
[32m[0907 04-32-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30899, current rewards: -27.76846, mean: -0.07713
[32m[0907 04-32-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30931, current rewards: -21.41208, mean: -0.05222
[32m[0907 04-33-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30994, current rewards: -15.06780, mean: -0.03276
[32m[0907 04-33-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31051, current rewards: -8.73001, mean: -0.01712
[32m[0907 04-33-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31103, current rewards: -2.38344, mean: -0.00426
[32m[0907 04-33-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31150, current rewards: 3.95741, mean: 0.00649
[32m[0907 04-34-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31186, current rewards: 10.29063, mean: 0.01559
[32m[0907 04-34-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31204, current rewards: 16.62978, mean: 0.02342
[32m[0907 04-34-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31228, current rewards: 22.97478, mean: 0.03023
[32m[0907 04-34-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31253, current rewards: 29.32024, mean: 0.03620
[32m[0907 04-35-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31271, current rewards: 35.66820, mean: 0.04147
[32m[0907 04-35-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31290, current rewards: 42.00931, mean: 0.04616
[32m[0907 04-35-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31303, current rewards: 48.35324, mean: 0.05037
[32m[0907 04-35-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31311, current rewards: 32.12608, mean: 0.03181
[32m[0907 04-36-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31321, current rewards: 38.14152, mean: 0.03598
[32m[0907 04-36-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31329, current rewards: 44.64738, mean: 0.04022
[32m[0907 04-36-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31334, current rewards: 51.17009, mean: 0.04411
[32m[0907 04-36-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31336, current rewards: 57.88837, mean: 0.04784
[32m[0907 04-37-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31339, current rewards: 64.61049, mean: 0.05128
[32m[0907 04-37-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31343, current rewards: 71.33123, mean: 0.05445
[32m[0907 04-37-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31346, current rewards: 78.05139, mean: 0.05739
[32m[0907 04-38-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31349, current rewards: 84.78098, mean: 0.06013
[32m[0907 04-38-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31351, current rewards: 90.06880, mean: 0.06169
[32m[0907 04-38-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31355, current rewards: 96.53391, mean: 0.06393
[32m[0907 04-38-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31359, current rewards: 106.24389, mean: 0.06811
[32m[0907 04-39-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31360, current rewards: 112.20112, mean: 0.06969
[32m[0907 04-39-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31360, current rewards: 118.08395, mean: 0.07113
[32m[0907 04-39-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31360, current rewards: 123.95955, mean: 0.07249
[32m[0907 04-39-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31361, current rewards: 129.83512, mean: 0.07377
[32m[0907 04-40-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31364, current rewards: 135.70141, mean: 0.07497
[32m[0907 04-40-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31367, current rewards: 141.57429, mean: 0.07612
[32m[0907 04-40-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31371, current rewards: 147.45001, mean: 0.07720
[32m[0907 04-40-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31374, current rewards: 145.64500, mean: 0.07431
[32m[0907 04-41-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31376, current rewards: 148.03139, mean: 0.07365
[32m[0907 04-41-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31379, current rewards: 153.47548, mean: 0.07450
[32m[0907 04-41-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31380, current rewards: 158.82535, mean: 0.07527
[32m[0907 04-41-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31379, current rewards: 164.16451, mean: 0.07600
[32m[0907 04-42-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31373, current rewards: 169.51096, mean: 0.07670
[32m[0907 04-42-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31360, current rewards: 174.85625, mean: 0.07737
[32m[0907 04-42-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31348, current rewards: 180.20044, mean: 0.07801
[32m[0907 04-42-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31337, current rewards: 187.24916, mean: 0.07934
[32m[0907 04-43-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31318, current rewards: 171.45357, mean: 0.07114
[32m[0907 04-43-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31289, current rewards: 179.85570, mean: 0.07311
[32m[0907 04-43-41 @Agent.py:117][0m Average action selection time: 0.3127
[32m[0907 04-43-41 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-43-41 @MBExp.py:227][0m Rewards obtained: [186.55002496947077], Lows: [33], Highs: [61], Total time: 50523.284902000014
[32m[0907 04-45-34 @MBExp.py:144][0m ####################################################################
[32m[0907 04-45-34 @MBExp.py:145][0m Starting training iteration 62.
[32m[0907 04-45-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30298, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-45-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30301, current rewards: -67.20187, mean: -1.12003
[32m[0907 04-46-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30761, current rewards: -135.72343, mean: -1.23385
[32m[0907 04-46-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30799, current rewards: -127.03673, mean: -0.79398
[32m[0907 04-46-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30834, current rewards: -121.56628, mean: -0.57889
[32m[0907 04-46-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30851, current rewards: -117.27471, mean: -0.45106
[32m[0907 04-47-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30866, current rewards: -112.45139, mean: -0.36275
[32m[0907 04-47-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30862, current rewards: -107.43364, mean: -0.29843
[32m[0907 04-47-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30911, current rewards: -102.41716, mean: -0.24980
[32m[0907 04-47-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30992, current rewards: -97.39811, mean: -0.21174
[32m[0907 04-48-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31070, current rewards: -92.38227, mean: -0.18114
[32m[0907 04-48-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31112, current rewards: -87.36332, mean: -0.15601
[32m[0907 04-48-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31147, current rewards: -102.15231, mean: -0.16746
[32m[0907 04-49-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31180, current rewards: -114.01788, mean: -0.17275
[32m[0907 04-49-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31208, current rewards: -108.73434, mean: -0.15315
[32m[0907 04-49-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31237, current rewards: -102.82869, mean: -0.13530
[32m[0907 04-49-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31257, current rewards: -96.98437, mean: -0.11973
[32m[0907 04-50-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31274, current rewards: -91.13587, mean: -0.10597
[32m[0907 04-50-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31286, current rewards: -85.28458, mean: -0.09372
[32m[0907 04-50-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31300, current rewards: -79.43423, mean: -0.08274
[32m[0907 04-50-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31309, current rewards: -73.57634, mean: -0.07285
[32m[0907 04-51-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31314, current rewards: -67.72104, mean: -0.06389
[32m[0907 04-51-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31318, current rewards: -58.38764, mean: -0.05260
[32m[0907 04-51-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31324, current rewards: -52.48044, mean: -0.04524
[32m[0907 04-51-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31331, current rewards: -46.60670, mean: -0.03852
[32m[0907 04-52-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31335, current rewards: -40.73064, mean: -0.03233
[32m[0907 04-52-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31339, current rewards: -34.85945, mean: -0.02661
[32m[0907 04-52-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31345, current rewards: -48.03835, mean: -0.03532
[32m[0907 04-52-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31350, current rewards: -76.84240, mean: -0.05450
[32m[0907 04-53-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31356, current rewards: -72.39022, mean: -0.04958
[32m[0907 04-53-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31359, current rewards: -65.01321, mean: -0.04306
[32m[0907 04-53-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31360, current rewards: -57.68607, mean: -0.03698
[32m[0907 04-53-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31360, current rewards: -50.35071, mean: -0.03127
[32m[0907 04-54-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31361, current rewards: -42.98796, mean: -0.02590
[32m[0907 04-54-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31361, current rewards: -35.64308, mean: -0.02084
[32m[0907 04-54-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31373, current rewards: -47.60134, mean: -0.02705
[32m[0907 04-55-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31380, current rewards: -108.79666, mean: -0.06011
[32m[0907 04-55-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31380, current rewards: -117.63359, mean: -0.06324
[32m[0907 04-55-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31380, current rewards: -116.78805, mean: -0.06115
[32m[0907 04-55-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31381, current rewards: -113.43778, mean: -0.05788
[32m[0907 04-56-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31383, current rewards: -110.02144, mean: -0.05474
[32m[0907 04-56-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31382, current rewards: -108.92084, mean: -0.05287
[32m[0907 04-56-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31381, current rewards: -125.72990, mean: -0.05959
[32m[0907 04-56-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31384, current rewards: -120.75207, mean: -0.05590
[32m[0907 04-57-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31379, current rewards: -115.65264, mean: -0.05233
[32m[0907 04-57-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31364, current rewards: -110.55139, mean: -0.04892
[32m[0907 04-57-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31351, current rewards: -105.44951, mean: -0.04565
[32m[0907 04-57-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31340, current rewards: -100.34934, mean: -0.04252
[32m[0907 04-58-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31321, current rewards: -95.24785, mean: -0.03952
[32m[0907 04-58-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31292, current rewards: -90.14491, mean: -0.03664
[32m[0907 04-58-36 @Agent.py:117][0m Average action selection time: 0.3127
[32m[0907 04-58-36 @Agent.py:118][0m Rollout length: 2520
[32m[0907 04-58-36 @MBExp.py:227][0m Rewards obtained: [-86.06710653128002], Lows: [153], Highs: [62], Total time: 51305.698504000015
[32m[0907 05-00-31 @MBExp.py:144][0m ####################################################################
[32m[0907 05-00-31 @MBExp.py:145][0m Starting training iteration 63.
[32m[0907 05-00-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29822, current rewards: -8.95116, mean: -0.89512
[32m[0907 05-00-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29958, current rewards: -19.47889, mean: -0.32465
[32m[0907 05-01-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30321, current rewards: -14.19170, mean: -0.12902
[32m[0907 05-01-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30503, current rewards: -8.81850, mean: -0.05512
[32m[0907 05-01-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30599, current rewards: -3.44474, mean: -0.01640
[32m[0907 05-01-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30655, current rewards: 1.92813, mean: 0.00742
[32m[0907 05-02-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30685, current rewards: 7.30020, mean: 0.02355
[32m[0907 05-02-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30706, current rewards: -10.62887, mean: -0.02952
[32m[0907 05-02-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30778, current rewards: -5.45974, mean: -0.01332
[32m[0907 05-02-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30859, current rewards: -0.05595, mean: -0.00012
[32m[0907 05-03-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30935, current rewards: 5.34780, mean: 0.01049
[32m[0907 05-03-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30988, current rewards: 10.75035, mean: 0.01920
[32m[0907 05-03-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31032, current rewards: 16.58612, mean: 0.02719
[32m[0907 05-03-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31074, current rewards: 23.89703, mean: 0.03621
[32m[0907 05-04-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31107, current rewards: 18.71250, mean: 0.02636
[32m[0907 05-04-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31137, current rewards: -6.47416, mean: -0.00852
[32m[0907 05-04-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31165, current rewards: -1.12154, mean: -0.00138
[32m[0907 05-05-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31186, current rewards: 4.22725, mean: 0.00492
[32m[0907 05-05-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31203, current rewards: 9.57520, mean: 0.01052
[32m[0907 05-05-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31226, current rewards: 14.92309, mean: 0.01554
[32m[0907 05-05-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31239, current rewards: -0.75941, mean: -0.00075
[32m[0907 05-06-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31253, current rewards: 3.78781, mean: 0.00357
[32m[0907 05-06-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31264, current rewards: 9.51931, mean: 0.00858
[32m[0907 05-06-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31272, current rewards: 15.25405, mean: 0.01315
[32m[0907 05-06-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31286, current rewards: 20.98817, mean: 0.01735
[32m[0907 05-07-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31295, current rewards: 26.72050, mean: 0.02121
[32m[0907 05-07-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31305, current rewards: 32.44688, mean: 0.02477
[32m[0907 05-07-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31312, current rewards: 38.18365, mean: 0.02808
[32m[0907 05-07-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31316, current rewards: 1.59453, mean: 0.00113
[32m[0907 05-08-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31322, current rewards: 6.10829, mean: 0.00418
[32m[0907 05-08-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31330, current rewards: 12.99785, mean: 0.00861
[32m[0907 05-08-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31338, current rewards: 19.81062, mean: 0.01270
[32m[0907 05-08-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31344, current rewards: 26.62788, mean: 0.01654
[32m[0907 05-09-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31351, current rewards: 33.45420, mean: 0.02015
[32m[0907 05-09-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31354, current rewards: 40.27194, mean: 0.02355
[32m[0907 05-09-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31360, current rewards: 47.09320, mean: 0.02676
[32m[0907 05-09-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31364, current rewards: 53.89484, mean: 0.02978
[32m[0907 05-10-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31366, current rewards: 60.10608, mean: 0.03232
[32m[0907 05-10-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31369, current rewards: 23.70938, mean: 0.01241
[32m[0907 05-10-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31375, current rewards: 26.73385, mean: 0.01364
[32m[0907 05-11-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31378, current rewards: 31.38641, mean: 0.01562
[32m[0907 05-11-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31381, current rewards: 36.03435, mean: 0.01749
[32m[0907 05-11-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31384, current rewards: 40.68115, mean: 0.01928
[32m[0907 05-11-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31387, current rewards: 45.32785, mean: 0.02099
[32m[0907 05-12-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31390, current rewards: 49.97403, mean: 0.02261
[32m[0907 05-12-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31376, current rewards: 57.53581, mean: 0.02546
[32m[0907 05-12-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31364, current rewards: -0.47520, mean: -0.00021
[32m[0907 05-12-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31351, current rewards: 4.66481, mean: 0.00198
[32m[0907 05-13-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31335, current rewards: 10.02839, mean: 0.00416
[32m[0907 05-13-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31307, current rewards: 15.38794, mean: 0.00626
[32m[0907 05-13-34 @Agent.py:117][0m Average action selection time: 0.3128
[32m[0907 05-13-34 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-13-34 @MBExp.py:227][0m Rewards obtained: [19.67582670590131], Lows: [88], Highs: [71], Total time: 52088.47738600001
[32m[0907 05-15-30 @MBExp.py:144][0m ####################################################################
[32m[0907 05-15-30 @MBExp.py:145][0m Starting training iteration 64.
[32m[0907 05-15-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29956, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-15-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30042, current rewards: -23.31306, mean: -0.38855
[32m[0907 05-16-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29987, current rewards: -16.68479, mean: -0.15168
[32m[0907 05-16-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30092, current rewards: -10.10138, mean: -0.06313
[32m[0907 05-16-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30282, current rewards: -14.36690, mean: -0.06841
[32m[0907 05-16-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30413, current rewards: -43.87837, mean: -0.16876
[32m[0907 05-17-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30494, current rewards: -75.50505, mean: -0.24356
[32m[0907 05-17-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30549, current rewards: -75.14961, mean: -0.20875
[32m[0907 05-17-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30645, current rewards: -89.70536, mean: -0.21879
[32m[0907 05-17-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30757, current rewards: -87.81863, mean: -0.19091
[32m[0907 05-18-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30841, current rewards: -83.62365, mean: -0.16397
[32m[0907 05-18-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30907, current rewards: -79.58966, mean: -0.14212
[32m[0907 05-18-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30968, current rewards: -78.18500, mean: -0.12817
[32m[0907 05-18-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31003, current rewards: -73.75044, mean: -0.11174
[32m[0907 05-19-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31048, current rewards: -66.58533, mean: -0.09378
[32m[0907 05-19-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31084, current rewards: -102.36769, mean: -0.13469
[32m[0907 05-19-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31121, current rewards: -95.64439, mean: -0.11808
[32m[0907 05-19-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31152, current rewards: -88.36834, mean: -0.10275
[32m[0907 05-20-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31177, current rewards: -81.08590, mean: -0.08911
[32m[0907 05-20-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31193, current rewards: -73.80534, mean: -0.07688
[32m[0907 05-20-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31206, current rewards: -66.52637, mean: -0.06587
[32m[0907 05-21-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31222, current rewards: -56.94052, mean: -0.05372
[32m[0907 05-21-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31234, current rewards: -49.74738, mean: -0.04482
[32m[0907 05-21-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31248, current rewards: -42.48030, mean: -0.03662
[32m[0907 05-21-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31262, current rewards: -55.83010, mean: -0.04614
[32m[0907 05-22-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31274, current rewards: -64.53342, mean: -0.05122
[32m[0907 05-22-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31281, current rewards: -58.01395, mean: -0.04429
[32m[0907 05-22-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31286, current rewards: -51.36936, mean: -0.03777
[32m[0907 05-22-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31293, current rewards: -44.74168, mean: -0.03173
[32m[0907 05-23-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31301, current rewards: -40.03989, mean: -0.02742
[32m[0907 05-23-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31305, current rewards: -32.75144, mean: -0.02169
[32m[0907 05-23-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31312, current rewards: -24.96871, mean: -0.01601
[32m[0907 05-23-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31318, current rewards: -18.00936, mean: -0.01119
[32m[0907 05-24-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31320, current rewards: -10.26304, mean: -0.00618
[32m[0907 05-24-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31322, current rewards: -3.02291, mean: -0.00177
[32m[0907 05-24-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31325, current rewards: 4.22699, mean: 0.00240
[32m[0907 05-24-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31329, current rewards: 11.98258, mean: 0.00662
[32m[0907 05-25-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31331, current rewards: 19.97011, mean: 0.01074
[32m[0907 05-25-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31334, current rewards: 29.18333, mean: 0.01528
[32m[0907 05-25-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31337, current rewards: 36.00842, mean: 0.01837
[32m[0907 05-26-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31341, current rewards: 1.01996, mean: 0.00051
[32m[0907 05-26-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31343, current rewards: 6.91164, mean: 0.00336
[32m[0907 05-26-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31346, current rewards: 13.10710, mean: 0.00621
[32m[0907 05-26-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31345, current rewards: 19.30727, mean: 0.00894
[32m[0907 05-27-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31345, current rewards: 25.50643, mean: 0.01154
[32m[0907 05-27-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31333, current rewards: 31.62360, mean: 0.01399
[32m[0907 05-27-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31322, current rewards: 37.40025, mean: 0.01619
[32m[0907 05-27-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31310, current rewards: 43.60100, mean: 0.01848
[32m[0907 05-28-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31299, current rewards: 49.79991, mean: 0.02066
[32m[0907 05-28-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31269, current rewards: 55.99497, mean: 0.02276
[32m[0907 05-28-32 @Agent.py:117][0m Average action selection time: 0.3125
[32m[0907 05-28-32 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-28-32 @MBExp.py:227][0m Rewards obtained: [60.95051847136304], Lows: [102], Highs: [66], Total time: 52870.334788000015
[32m[0907 05-30-31 @MBExp.py:144][0m ####################################################################
[32m[0907 05-30-31 @MBExp.py:145][0m Starting training iteration 65.
[32m[0907 05-30-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29907, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-30-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29994, current rewards: -17.41937, mean: -0.29032
[32m[0907 05-31-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30125, current rewards: -41.27803, mean: -0.37525
[32m[0907 05-31-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30060, current rewards: -52.57523, mean: -0.32860
[32m[0907 05-31-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30255, current rewards: -53.32703, mean: -0.25394
[32m[0907 05-31-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30366, current rewards: -48.54031, mean: -0.18669
[32m[0907 05-32-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30438, current rewards: -43.73372, mean: -0.14108
[32m[0907 05-32-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30493, current rewards: -38.92335, mean: -0.10812
[32m[0907 05-32-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30588, current rewards: -34.11603, mean: -0.08321
[32m[0907 05-32-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30703, current rewards: -29.31084, mean: -0.06372
[32m[0907 05-33-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30797, current rewards: -24.50685, mean: -0.04805
[32m[0907 05-33-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30875, current rewards: -19.70236, mean: -0.03518
[32m[0907 05-33-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30940, current rewards: -14.78501, mean: -0.02424
[32m[0907 05-33-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30992, current rewards: -33.39515, mean: -0.05060
[32m[0907 05-34-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31033, current rewards: -47.79347, mean: -0.06731
[32m[0907 05-34-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31066, current rewards: -43.67011, mean: -0.05746
[32m[0907 05-34-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31096, current rewards: -39.61610, mean: -0.04891
[32m[0907 05-34-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31124, current rewards: -35.56511, mean: -0.04135
[32m[0907 05-35-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31150, current rewards: -31.50981, mean: -0.03463
[32m[0907 05-35-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31168, current rewards: -27.45797, mean: -0.02860
[32m[0907 05-35-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31186, current rewards: -22.03176, mean: -0.02181
[32m[0907 05-36-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31201, current rewards: -17.97538, mean: -0.01696
[32m[0907 05-36-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31218, current rewards: -13.93848, mean: -0.01256
[32m[0907 05-36-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31229, current rewards: -9.90431, mean: -0.00854
[32m[0907 05-36-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31238, current rewards: -5.86947, mean: -0.00485
[32m[0907 05-37-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31243, current rewards: -23.37117, mean: -0.01855
[32m[0907 05-37-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31252, current rewards: -16.93389, mean: -0.01293
[32m[0907 05-37-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31261, current rewards: -10.36280, mean: -0.00762
[32m[0907 05-37-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31269, current rewards: -4.96343, mean: -0.00352
[32m[0907 05-38-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31275, current rewards: 3.77026, mean: 0.00258
[32m[0907 05-38-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31283, current rewards: -33.64435, mean: -0.02228
[32m[0907 05-38-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31291, current rewards: -29.38300, mean: -0.01884
[32m[0907 05-38-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31298, current rewards: -25.15774, mean: -0.01563
[32m[0907 05-39-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31306, current rewards: -20.92949, mean: -0.01261
[32m[0907 05-39-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31310, current rewards: -16.70842, mean: -0.00977
[32m[0907 05-39-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31311, current rewards: -12.48533, mean: -0.00709
[32m[0907 05-39-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31315, current rewards: -8.06929, mean: -0.00446
[32m[0907 05-40-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31321, current rewards: -1.06415, mean: -0.00057
[32m[0907 05-40-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31324, current rewards: -38.52637, mean: -0.02017
[32m[0907 05-40-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31325, current rewards: -47.94187, mean: -0.02446
[32m[0907 05-41-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31325, current rewards: -77.49994, mean: -0.03856
[32m[0907 05-41-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31329, current rewards: -127.40023, mean: -0.06184
[32m[0907 05-41-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31336, current rewards: -126.62580, mean: -0.06001
[32m[0907 05-41-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31337, current rewards: -127.12226, mean: -0.05885
[32m[0907 05-42-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31335, current rewards: -125.62989, mean: -0.05685
[32m[0907 05-42-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31322, current rewards: -125.17376, mean: -0.05539
[32m[0907 05-42-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31311, current rewards: -125.94117, mean: -0.05452
[32m[0907 05-42-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31299, current rewards: -143.92094, mean: -0.06098
[32m[0907 05-43-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31286, current rewards: -147.32908, mean: -0.06113
[32m[0907 05-43-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31258, current rewards: -142.80739, mean: -0.05805
[32m[0907 05-43-32 @Agent.py:117][0m Average action selection time: 0.3124
[32m[0907 05-43-32 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-43-32 @MBExp.py:227][0m Rewards obtained: [-139.18830552227166], Lows: [120], Highs: [132], Total time: 53651.90976700001
[32m[0907 05-45-32 @MBExp.py:144][0m ####################################################################
[32m[0907 05-45-32 @MBExp.py:145][0m Starting training iteration 66.
[32m[0907 05-45-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29716, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-45-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29828, current rewards: -23.91100, mean: -0.39852
[32m[0907 05-46-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29869, current rewards: -18.47250, mean: -0.16793
[32m[0907 05-46-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29877, current rewards: -12.85504, mean: -0.08034
[32m[0907 05-46-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30022, current rewards: -7.23805, mean: -0.03447
[32m[0907 05-46-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30175, current rewards: -1.62172, mean: -0.00624
[32m[0907 05-47-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30271, current rewards: 3.99858, mean: 0.01290
[32m[0907 05-47-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30337, current rewards: 9.61472, mean: 0.02671
[32m[0907 05-47-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30436, current rewards: 15.22888, mean: 0.03714
[32m[0907 05-47-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30567, current rewards: -20.39495, mean: -0.04434
[32m[0907 05-48-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30662, current rewards: -14.38038, mean: -0.02820
[32m[0907 05-48-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30748, current rewards: -9.67896, mean: -0.01728
[32m[0907 05-48-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30810, current rewards: -4.84280, mean: -0.00794
[32m[0907 05-48-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30865, current rewards: -22.22288, mean: -0.03367
[32m[0907 05-49-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30916, current rewards: -16.80163, mean: -0.02366
[32m[0907 05-49-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30957, current rewards: -11.23317, mean: -0.01478
[32m[0907 05-49-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30992, current rewards: -5.66390, mean: -0.00699
[32m[0907 05-49-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31025, current rewards: -0.09137, mean: -0.00011
[32m[0907 05-50-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31053, current rewards: 5.48635, mean: 0.00603
[32m[0907 05-50-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31077, current rewards: 13.05755, mean: 0.01360
[32m[0907 05-50-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31099, current rewards: 19.78915, mean: 0.01959
[32m[0907 05-51-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31123, current rewards: 2.72312, mean: 0.00257
[32m[0907 05-51-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31141, current rewards: 7.75979, mean: 0.00699
[32m[0907 05-51-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31157, current rewards: 13.04715, mean: 0.01125
[32m[0907 05-51-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31175, current rewards: 17.67222, mean: 0.01461
[32m[0907 05-52-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31188, current rewards: 23.27012, mean: 0.01847
[32m[0907 05-52-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31200, current rewards: 28.24572, mean: 0.02156
[32m[0907 05-52-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31213, current rewards: 33.12406, mean: 0.02436
[32m[0907 05-52-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31222, current rewards: 37.77092, mean: 0.02679
[32m[0907 05-53-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31231, current rewards: 42.72117, mean: 0.02926
[32m[0907 05-53-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31239, current rewards: 47.64583, mean: 0.03155
[32m[0907 05-53-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31246, current rewards: 52.57438, mean: 0.03370
[32m[0907 05-53-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31252, current rewards: 57.50210, mean: 0.03572
[32m[0907 05-54-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31258, current rewards: 62.43524, mean: 0.03761
[32m[0907 05-54-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31264, current rewards: 67.36222, mean: 0.03939
[32m[0907 05-54-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31267, current rewards: 24.05525, mean: 0.01367
[32m[0907 05-54-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31273, current rewards: -9.94709, mean: -0.00550
[32m[0907 05-55-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31276, current rewards: -69.17265, mean: -0.03719
[32m[0907 05-55-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31280, current rewards: -119.68964, mean: -0.06266
[32m[0907 05-55-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31283, current rewards: -187.51315, mean: -0.09567
[32m[0907 05-56-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31288, current rewards: -257.62004, mean: -0.12817
[32m[0907 05-56-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31291, current rewards: -306.11010, mean: -0.14860
[32m[0907 05-56-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31295, current rewards: -349.53520, mean: -0.16566
[32m[0907 05-56-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31300, current rewards: -343.50385, mean: -0.15903
[32m[0907 05-57-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31303, current rewards: -338.81584, mean: -0.15331
[32m[0907 05-57-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31305, current rewards: -334.00869, mean: -0.14779
[32m[0907 05-57-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31294, current rewards: -329.15020, mean: -0.14249
[32m[0907 05-57-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31284, current rewards: -324.29327, mean: -0.13741
[32m[0907 05-58-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31273, current rewards: -319.44170, mean: -0.13255
[32m[0907 05-58-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31254, current rewards: -314.58712, mean: -0.12788
[32m[0907 05-58-34 @Agent.py:117][0m Average action selection time: 0.3123
[32m[0907 05-58-34 @Agent.py:118][0m Rollout length: 2520
[32m[0907 05-58-34 @MBExp.py:227][0m Rewards obtained: [-310.7031312452073], Lows: [240], Highs: [83], Total time: 54433.429979000015
[32m[0907 06-00-35 @MBExp.py:144][0m ####################################################################
[32m[0907 06-00-35 @MBExp.py:145][0m Starting training iteration 67.
[32m[0907 06-00-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29767, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-00-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29897, current rewards: -47.27560, mean: -0.78793
[32m[0907 06-01-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29921, current rewards: -38.97962, mean: -0.35436
[32m[0907 06-01-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29942, current rewards: -33.16133, mean: -0.20726
[32m[0907 06-01-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30083, current rewards: -27.26342, mean: -0.12983
[32m[0907 06-01-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30225, current rewards: -21.35480, mean: -0.08213
[32m[0907 06-02-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30325, current rewards: -15.45185, mean: -0.04984
[32m[0907 06-02-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30402, current rewards: -9.55149, mean: -0.02653
[32m[0907 06-02-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30498, current rewards: -3.66224, mean: -0.00893
[32m[0907 06-02-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30614, current rewards: 2.24437, mean: 0.00488
[32m[0907 06-03-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30714, current rewards: 12.64317, mean: 0.02479
[32m[0907 06-03-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30789, current rewards: 21.51687, mean: 0.03842
[32m[0907 06-03-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30855, current rewards: 5.49725, mean: 0.00901
[32m[0907 06-04-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30914, current rewards: 12.41498, mean: 0.01881
[32m[0907 06-04-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30955, current rewards: 19.56808, mean: 0.02756
[32m[0907 06-04-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30998, current rewards: 26.72895, mean: 0.03517
[32m[0907 06-04-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31029, current rewards: 33.89122, mean: 0.04184
[32m[0907 06-05-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31060, current rewards: 41.05875, mean: 0.04774
[32m[0907 06-05-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31084, current rewards: 48.12260, mean: 0.05288
[32m[0907 06-05-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31105, current rewards: 55.15925, mean: 0.05746
[32m[0907 06-05-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31122, current rewards: 62.85863, mean: 0.06224
[32m[0907 06-06-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31144, current rewards: 69.87076, mean: 0.06592
[32m[0907 06-06-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31159, current rewards: 76.79636, mean: 0.06919
[32m[0907 06-06-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31173, current rewards: 83.70945, mean: 0.07216
[32m[0907 06-06-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31189, current rewards: 90.63486, mean: 0.07490
[32m[0907 06-07-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31197, current rewards: 78.33434, mean: 0.06217
[32m[0907 06-07-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31208, current rewards: 56.84211, mean: 0.04339
[32m[0907 06-07-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31215, current rewards: 65.97028, mean: 0.04851
[32m[0907 06-07-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31224, current rewards: 75.18507, mean: 0.05332
[32m[0907 06-08-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31232, current rewards: 84.40427, mean: 0.05781
[32m[0907 06-08-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31240, current rewards: 93.62117, mean: 0.06200
[32m[0907 06-08-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31248, current rewards: 102.83967, mean: 0.06592
[32m[0907 06-08-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31258, current rewards: 112.04576, mean: 0.06959
[32m[0907 06-09-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31261, current rewards: 121.26954, mean: 0.07305
[32m[0907 06-09-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31267, current rewards: 130.33286, mean: 0.07622
[32m[0907 06-09-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31272, current rewards: 132.20776, mean: 0.07512
[32m[0907 06-10-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31275, current rewards: 120.78724, mean: 0.06673
[32m[0907 06-10-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31280, current rewards: 127.08270, mean: 0.06832
[32m[0907 06-10-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31284, current rewards: 133.41696, mean: 0.06985
[32m[0907 06-10-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31288, current rewards: 139.74517, mean: 0.07130
[32m[0907 06-11-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31290, current rewards: 146.07260, mean: 0.07267
[32m[0907 06-11-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31295, current rewards: 152.40098, mean: 0.07398
[32m[0907 06-11-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31299, current rewards: 158.73242, mean: 0.07523
[32m[0907 06-11-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31301, current rewards: 165.22267, mean: 0.07649
[32m[0907 06-12-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31306, current rewards: 176.37542, mean: 0.07981
[32m[0907 06-12-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31310, current rewards: 187.70248, mean: 0.08305
[32m[0907 06-12-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31305, current rewards: 199.07180, mean: 0.08618
[32m[0907 06-12-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31294, current rewards: 210.40762, mean: 0.08916
[32m[0907 06-13-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31282, current rewards: 221.77104, mean: 0.09202
[32m[0907 06-13-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31271, current rewards: 233.13726, mean: 0.09477
[32m[0907 06-13-38 @Agent.py:117][0m Average action selection time: 0.3126
[32m[0907 06-13-38 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-13-38 @MBExp.py:227][0m Rewards obtained: [242.24352505794334], Lows: [41], Highs: [61], Total time: 55215.72041100002
[32m[0907 06-15-41 @MBExp.py:144][0m ####################################################################
[32m[0907 06-15-41 @MBExp.py:145][0m Starting training iteration 68.
[32m[0907 06-15-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30742, current rewards: 1.06478, mean: 0.10648
[32m[0907 06-15-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29665, current rewards: -35.60606, mean: -0.59343
[32m[0907 06-16-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29793, current rewards: -112.00673, mean: -1.01824
[32m[0907 06-16-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29831, current rewards: -136.06002, mean: -0.85038
[32m[0907 06-16-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29867, current rewards: -127.27127, mean: -0.60605
[32m[0907 06-16-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30003, current rewards: -118.48261, mean: -0.45570
[32m[0907 06-17-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30147, current rewards: -109.69395, mean: -0.35385
[32m[0907 06-17-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30245, current rewards: -125.59652, mean: -0.34888
[32m[0907 06-17-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30362, current rewards: -175.59652, mean: -0.42828
[32m[0907 06-18-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30485, current rewards: -225.59652, mean: -0.49043
[32m[0907 06-18-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30586, current rewards: -275.59652, mean: -0.54039
[32m[0907 06-18-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30671, current rewards: -325.59652, mean: -0.58142
[32m[0907 06-18-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30742, current rewards: -375.59652, mean: -0.61573
[32m[0907 06-19-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30798, current rewards: -425.59652, mean: -0.64484
[32m[0907 06-19-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30843, current rewards: -475.59652, mean: -0.66985
[32m[0907 06-19-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30882, current rewards: -525.59652, mean: -0.69157
[32m[0907 06-19-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30915, current rewards: -575.59652, mean: -0.71061
[32m[0907 06-20-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30942, current rewards: -625.59652, mean: -0.72744
[32m[0907 06-20-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30969, current rewards: -675.59652, mean: -0.74241
[32m[0907 06-20-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31000, current rewards: -725.59652, mean: -0.75583
[32m[0907 06-20-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31015, current rewards: -775.59652, mean: -0.76792
[32m[0907 06-21-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31032, current rewards: -825.59652, mean: -0.77886
[32m[0907 06-21-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31047, current rewards: -875.59652, mean: -0.78883
[32m[0907 06-21-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31062, current rewards: -925.59652, mean: -0.79793
[32m[0907 06-21-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31078, current rewards: -975.59652, mean: -0.80628
[32m[0907 06-22-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31093, current rewards: -1025.59652, mean: -0.81397
[32m[0907 06-22-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31107, current rewards: -1075.59652, mean: -0.82107
[32m[0907 06-22-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31117, current rewards: -1125.59652, mean: -0.82764
[32m[0907 06-23-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31254, current rewards: -1175.59652, mean: -0.83376
[32m[0907 06-23-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31392, current rewards: -1225.59652, mean: -0.83945
[32m[0907 06-23-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31519, current rewards: -1275.59652, mean: -0.84477
[32m[0907 06-23-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31679, current rewards: -1325.59652, mean: -0.84974
[32m[0907 06-24-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31815, current rewards: -1375.59652, mean: -0.85441
[32m[0907 06-24-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31916, current rewards: -1425.59652, mean: -0.85879
[32m[0907 06-24-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32009, current rewards: -1475.59652, mean: -0.86292
[32m[0907 06-25-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32081, current rewards: -1525.59652, mean: -0.86682
[32m[0907 06-25-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32064, current rewards: -1575.59652, mean: -0.87050
[32m[0907 06-25-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32047, current rewards: -1625.59652, mean: -0.87398
[32m[0907 06-25-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32030, current rewards: -1675.59652, mean: -0.87728
[32m[0907 06-26-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32015, current rewards: -1725.59652, mean: -0.88041
[32m[0907 06-26-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32000, current rewards: -1775.59652, mean: -0.88338
[32m[0907 06-26-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31984, current rewards: -1825.59652, mean: -0.88621
[32m[0907 06-26-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31971, current rewards: -1875.59652, mean: -0.88891
[32m[0907 06-27-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31957, current rewards: -1925.59652, mean: -0.89148
[32m[0907 06-27-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31945, current rewards: -1975.59652, mean: -0.89394
[32m[0907 06-27-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31932, current rewards: -2025.59652, mean: -0.89628
[32m[0907 06-27-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31918, current rewards: -2075.59652, mean: -0.89853
[32m[0907 06-28-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31892, current rewards: -2125.59652, mean: -0.90068
[32m[0907 06-28-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31869, current rewards: -2175.59652, mean: -0.90274
[32m[0907 06-28-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31846, current rewards: -2225.59652, mean: -0.90471
[32m[0907 06-28-58 @Agent.py:117][0m Average action selection time: 0.3183
[32m[0907 06-28-58 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-28-58 @MBExp.py:227][0m Rewards obtained: [-2265.5965220559865], Lows: [76], Highs: [2161], Total time: 56012.158956000014
[32m[0907 06-31-03 @MBExp.py:144][0m ####################################################################
[32m[0907 06-31-03 @MBExp.py:145][0m Starting training iteration 69.
[32m[0907 06-31-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28966, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-31-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29067, current rewards: -15.82539, mean: -0.26376
[32m[0907 06-31-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29237, current rewards: -11.66829, mean: -0.10608
[32m[0907 06-31-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29451, current rewards: -5.77620, mean: -0.03610
[32m[0907 06-32-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29557, current rewards: 0.01957, mean: 0.00009
[32m[0907 06-32-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29738, current rewards: 5.81459, mean: 0.02236
[32m[0907 06-32-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29926, current rewards: 11.60468, mean: 0.03743
[32m[0907 06-32-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30059, current rewards: 17.40228, mean: 0.04834
[32m[0907 06-33-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30191, current rewards: 23.19617, mean: 0.05658
[32m[0907 06-33-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30346, current rewards: 28.98075, mean: 0.06300
[32m[0907 06-33-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30472, current rewards: 35.11680, mean: 0.06886
[32m[0907 06-33-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30576, current rewards: 7.76071, mean: 0.01386
[32m[0907 06-34-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30658, current rewards: -11.09135, mean: -0.01818
[32m[0907 06-34-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30723, current rewards: -33.51921, mean: -0.05079
[32m[0907 06-34-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30780, current rewards: -67.59537, mean: -0.09520
[32m[0907 06-34-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30827, current rewards: -93.70013, mean: -0.12329
[32m[0907 06-35-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30874, current rewards: -130.06192, mean: -0.16057
[32m[0907 06-35-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30919, current rewards: -166.44336, mean: -0.19354
[32m[0907 06-35-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30954, current rewards: -203.95616, mean: -0.22413
[32m[0907 06-36-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30980, current rewards: -234.20179, mean: -0.24396
[32m[0907 06-36-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31004, current rewards: -274.81972, mean: -0.27210
[32m[0907 06-36-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31030, current rewards: -317.51000, mean: -0.29954
[32m[0907 06-36-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31054, current rewards: -373.20401, mean: -0.33622
[32m[0907 06-37-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31073, current rewards: -379.89047, mean: -0.32749
[32m[0907 06-37-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31092, current rewards: -411.12906, mean: -0.33978
[32m[0907 06-37-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31108, current rewards: -443.26170, mean: -0.35179
[32m[0907 06-37-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31120, current rewards: -478.49937, mean: -0.36527
[32m[0907 06-38-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31130, current rewards: -515.97703, mean: -0.37939
[32m[0907 06-38-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31143, current rewards: -527.52426, mean: -0.37413
[32m[0907 06-38-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31159, current rewards: -572.68567, mean: -0.39225
[32m[0907 06-38-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31170, current rewards: -594.43581, mean: -0.39367
[32m[0907 06-39-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31176, current rewards: -588.24112, mean: -0.37708
[32m[0907 06-39-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31184, current rewards: -582.05916, mean: -0.36153
[32m[0907 06-39-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31189, current rewards: -575.87331, mean: -0.34691
[32m[0907 06-39-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31196, current rewards: -569.68779, mean: -0.33315
[32m[0907 06-40-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31204, current rewards: -563.51254, mean: -0.32018
[32m[0907 06-40-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31209, current rewards: -589.18132, mean: -0.32551
[32m[0907 06-40-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31213, current rewards: -621.73822, mean: -0.33427
[32m[0907 06-41-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31218, current rewards: -612.09106, mean: -0.32047
[32m[0907 06-41-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31223, current rewards: -602.73185, mean: -0.30752
[32m[0907 06-41-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31230, current rewards: -593.64903, mean: -0.29535
[32m[0907 06-41-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31235, current rewards: -584.58967, mean: -0.28378
[32m[0907 06-42-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31241, current rewards: -575.53046, mean: -0.27276
[32m[0907 06-42-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31247, current rewards: -568.62507, mean: -0.26325
[32m[0907 06-42-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31253, current rewards: -560.63532, mean: -0.25368
[32m[0907 06-42-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31258, current rewards: -568.71788, mean: -0.25165
[32m[0907 06-43-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31259, current rewards: -570.84765, mean: -0.24712
[32m[0907 06-43-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31261, current rewards: -566.08338, mean: -0.23987
[32m[0907 06-43-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31257, current rewards: -561.31918, mean: -0.23291
[32m[0907 06-43-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31246, current rewards: -556.55777, mean: -0.22624
[32m[0907 06-44-04 @Agent.py:117][0m Average action selection time: 0.3124
[32m[0907 06-44-04 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-44-05 @MBExp.py:227][0m Rewards obtained: [-552.749162729666], Lows: [413], Highs: [77], Total time: 56793.80088300001
[32m[0907 06-46-12 @MBExp.py:144][0m ####################################################################
[32m[0907 06-46-12 @MBExp.py:145][0m Starting training iteration 70.
[32m[0907 06-46-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29108, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-46-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29084, current rewards: -31.95145, mean: -0.53252
[32m[0907 06-46-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29206, current rewards: -88.25581, mean: -0.80233
[32m[0907 06-46-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29431, current rewards: -137.11448, mean: -0.85697
[32m[0907 06-47-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29531, current rewards: -171.83646, mean: -0.81827
[32m[0907 06-47-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29670, current rewards: -213.25760, mean: -0.82022
[32m[0907 06-47-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29863, current rewards: -249.32656, mean: -0.80428
[32m[0907 06-48-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30002, current rewards: -285.13095, mean: -0.79203
[32m[0907 06-48-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30139, current rewards: -327.59205, mean: -0.79900
[32m[0907 06-48-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30311, current rewards: -378.62930, mean: -0.82311
[32m[0907 06-48-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30438, current rewards: -407.22958, mean: -0.79849
[32m[0907 06-49-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30546, current rewards: -456.91444, mean: -0.81592
[32m[0907 06-49-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30629, current rewards: -455.05180, mean: -0.74599
[32m[0907 06-49-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30699, current rewards: -449.35116, mean: -0.68084
[32m[0907 06-49-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30752, current rewards: -443.65384, mean: -0.62486
[32m[0907 06-50-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30798, current rewards: -437.95806, mean: -0.57626
[32m[0907 06-50-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30843, current rewards: -432.26268, mean: -0.53366
[32m[0907 06-50-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30879, current rewards: -426.57209, mean: -0.49601
[32m[0907 06-50-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30914, current rewards: -487.51679, mean: -0.53573
[32m[0907 06-51-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30944, current rewards: -528.03266, mean: -0.55003
[32m[0907 06-51-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30972, current rewards: -547.17675, mean: -0.54176
[32m[0907 06-51-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31000, current rewards: -567.39409, mean: -0.53528
[32m[0907 06-51-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31020, current rewards: -582.97059, mean: -0.52520
[32m[0907 06-52-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31041, current rewards: -597.46823, mean: -0.51506
[32m[0907 06-52-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31060, current rewards: -615.31176, mean: -0.50852
[32m[0907 06-52-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31077, current rewards: -631.66256, mean: -0.50132
[32m[0907 06-52-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31090, current rewards: -660.79625, mean: -0.50442
[32m[0907 06-53-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31107, current rewards: -695.54700, mean: -0.51143
[32m[0907 06-53-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31120, current rewards: -760.29729, mean: -0.53922
[32m[0907 06-53-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31131, current rewards: -824.52495, mean: -0.56474
[32m[0907 06-54-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31181, current rewards: -900.39029, mean: -0.59628
[32m[0907 06-54-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31210, current rewards: -972.49926, mean: -0.62340
[32m[0907 06-54-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31225, current rewards: -1016.98717, mean: -0.63167
[32m[0907 06-54-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31238, current rewards: -1070.96393, mean: -0.64516
[32m[0907 06-55-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31269, current rewards: -1137.59966, mean: -0.66526
[32m[0907 06-55-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31283, current rewards: -1200.75009, mean: -0.68224
[32m[0907 06-55-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31288, current rewards: -1256.19888, mean: -0.69403
[32m[0907 06-55-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31292, current rewards: -1303.69095, mean: -0.70091
[32m[0907 06-56-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31295, current rewards: -1354.61248, mean: -0.70922
[32m[0907 06-56-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31301, current rewards: -1418.28603, mean: -0.72362
[32m[0907 06-56-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31305, current rewards: -1478.46082, mean: -0.73555
[32m[0907 06-56-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31307, current rewards: -1540.99967, mean: -0.74806
[32m[0907 06-57-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31312, current rewards: -1578.11447, mean: -0.74792
[32m[0907 06-57-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31314, current rewards: -1620.42480, mean: -0.75020
[32m[0907 06-57-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31320, current rewards: -1682.63692, mean: -0.76137
[32m[0907 06-58-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31329, current rewards: -1738.67524, mean: -0.76933
[32m[0907 06-58-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31336, current rewards: -1776.96031, mean: -0.76925
[32m[0907 06-58-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31343, current rewards: -1839.05122, mean: -0.77926
[32m[0907 06-58-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31344, current rewards: -1839.33354, mean: -0.76321
[32m[0907 06-59-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31345, current rewards: -1833.57873, mean: -0.74536
[32m[0907 06-59-16 @Agent.py:117][0m Average action selection time: 0.3133
[32m[0907 06-59-16 @Agent.py:118][0m Rollout length: 2520
[32m[0907 06-59-16 @MBExp.py:227][0m Rewards obtained: [-1828.9290066834806], Lows: [1032], Highs: [56], Total time: 57577.86588200001
[32m[0907 07-01-25 @MBExp.py:144][0m ####################################################################
[32m[0907 07-01-25 @MBExp.py:145][0m Starting training iteration 71.
[32m[0907 07-01-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29088, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-01-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29071, current rewards: -41.99854, mean: -0.69998
[32m[0907 07-01-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29068, current rewards: -64.87150, mean: -0.58974
[32m[0907 07-02-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29047, current rewards: -59.09966, mean: -0.36937
[32m[0907 07-02-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29057, current rewards: -53.47695, mean: -0.25465
[32m[0907 07-02-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29291, current rewards: -70.45287, mean: -0.27097
[32m[0907 07-02-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29541, current rewards: -64.21210, mean: -0.20714
[32m[0907 07-03-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29728, current rewards: -58.43649, mean: -0.16232
[32m[0907 07-03-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29872, current rewards: -52.67312, mean: -0.12847
[32m[0907 07-03-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30055, current rewards: -46.90984, mean: -0.10198
[32m[0907 07-03-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30215, current rewards: -41.84188, mean: -0.08204
[32m[0907 07-04-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30347, current rewards: -39.26732, mean: -0.07012
[32m[0907 07-04-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30447, current rewards: -27.93227, mean: -0.04579
[32m[0907 07-04-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30523, current rewards: -21.15466, mean: -0.03205
[32m[0907 07-05-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30594, current rewards: -15.19782, mean: -0.02141
[32m[0907 07-05-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30659, current rewards: -9.63580, mean: -0.01268
[32m[0907 07-05-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30715, current rewards: -3.84743, mean: -0.00475
[32m[0907 07-05-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30774, current rewards: 1.94527, mean: 0.00226
[32m[0907 07-06-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30819, current rewards: 6.61122, mean: 0.00727
[32m[0907 07-06-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30860, current rewards: 12.16602, mean: 0.01267
[32m[0907 07-06-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30900, current rewards: -24.03390, mean: -0.02380
[32m[0907 07-06-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30936, current rewards: -54.81554, mean: -0.05171
[32m[0907 07-07-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30970, current rewards: -80.86548, mean: -0.07285
[32m[0907 07-07-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31000, current rewards: -110.64728, mean: -0.09539
[32m[0907 07-07-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31095, current rewards: -139.60667, mean: -0.11538
[32m[0907 07-07-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31268, current rewards: -157.47385, mean: -0.12498
[32m[0907 07-08-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31422, current rewards: -193.33408, mean: -0.14758
[32m[0907 07-08-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31565, current rewards: -217.04360, mean: -0.15959
[32m[0907 07-08-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31697, current rewards: -240.29924, mean: -0.17042
[32m[0907 07-09-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31828, current rewards: -273.64697, mean: -0.18743
[32m[0907 07-09-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31940, current rewards: -312.47905, mean: -0.20694
[32m[0907 07-09-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32045, current rewards: -343.43467, mean: -0.22015
[32m[0907 07-10-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32146, current rewards: -381.01334, mean: -0.23665
[32m[0907 07-10-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32241, current rewards: -373.96724, mean: -0.22528
[32m[0907 07-10-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32326, current rewards: -366.69512, mean: -0.21444
[32m[0907 07-10-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32406, current rewards: -358.67105, mean: -0.20379
[32m[0907 07-11-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32481, current rewards: -351.15735, mean: -0.19401
[32m[0907 07-11-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32562, current rewards: -343.63999, mean: -0.18475
[32m[0907 07-11-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32632, current rewards: -336.13276, mean: -0.17599
[32m[0907 07-12-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32700, current rewards: -328.62588, mean: -0.16767
[32m[0907 07-12-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32764, current rewards: -377.79723, mean: -0.18796
[32m[0907 07-12-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32825, current rewards: -415.49947, mean: -0.20170
[32m[0907 07-13-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32888, current rewards: -446.53504, mean: -0.21163
[32m[0907 07-13-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32940, current rewards: -490.91355, mean: -0.22727
[32m[0907 07-13-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32989, current rewards: -538.81711, mean: -0.24381
[32m[0907 07-13-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33039, current rewards: -583.27707, mean: -0.25809
[32m[0907 07-14-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33050, current rewards: -623.59888, mean: -0.26996
[32m[0907 07-14-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33020, current rewards: -667.55940, mean: -0.28286
[32m[0907 07-14-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32990, current rewards: -703.42488, mean: -0.29188
[32m[0907 07-14-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32961, current rewards: -745.27134, mean: -0.30296
[32m[0907 07-15-09 @Agent.py:117][0m Average action selection time: 0.3294
[32m[0907 07-15-09 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-15-09 @MBExp.py:227][0m Rewards obtained: [-776.6843661888554], Lows: [505], Highs: [87], Total time: 58402.06159400001
[32m[0907 07-17-21 @MBExp.py:144][0m ####################################################################
[32m[0907 07-17-21 @MBExp.py:145][0m Starting training iteration 72.
[32m[0907 07-17-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28685, current rewards: 0.97906, mean: 0.09791
[32m[0907 07-17-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.28675, current rewards: -38.20049, mean: -0.63667
[32m[0907 07-17-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.28647, current rewards: -33.51372, mean: -0.30467
[32m[0907 07-18-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.28639, current rewards: -28.53911, mean: -0.17837
[32m[0907 07-18-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.28777, current rewards: -23.56191, mean: -0.11220
[32m[0907 07-18-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.28972, current rewards: -18.58558, mean: -0.07148
[32m[0907 07-18-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29251, current rewards: -13.60906, mean: -0.04390
[32m[0907 07-19-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29479, current rewards: -50.30329, mean: -0.13973
[32m[0907 07-19-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29651, current rewards: -66.00241, mean: -0.16098
[32m[0907 07-19-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29850, current rewards: -60.80831, mean: -0.13219
[32m[0907 07-19-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30046, current rewards: -53.45919, mean: -0.10482
[32m[0907 07-20-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30191, current rewards: -48.37612, mean: -0.08639
[32m[0907 07-20-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30313, current rewards: -43.29444, mean: -0.07097
[32m[0907 07-20-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30413, current rewards: -38.20888, mean: -0.05789
[32m[0907 07-20-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30503, current rewards: -33.12593, mean: -0.04666
[32m[0907 07-21-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30581, current rewards: -73.56188, mean: -0.09679
[32m[0907 07-21-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30643, current rewards: -68.64541, mean: -0.08475
[32m[0907 07-21-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30700, current rewards: -64.01007, mean: -0.07443
[32m[0907 07-22-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30749, current rewards: -59.16040, mean: -0.06501
[32m[0907 07-22-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30790, current rewards: -88.93398, mean: -0.09264
[32m[0907 07-22-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30829, current rewards: -92.22030, mean: -0.09131
[32m[0907 07-22-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30876, current rewards: -86.37428, mean: -0.08149
[32m[0907 07-23-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30916, current rewards: -80.54064, mean: -0.07256
[32m[0907 07-23-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30950, current rewards: -74.69530, mean: -0.06439
[32m[0907 07-23-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30981, current rewards: -68.85115, mean: -0.05690
[32m[0907 07-23-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31006, current rewards: -63.00136, mean: -0.05000
[32m[0907 07-24-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31027, current rewards: -59.08092, mean: -0.04510
[32m[0907 07-24-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31047, current rewards: -77.41245, mean: -0.05692
[32m[0907 07-24-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31063, current rewards: -77.57912, mean: -0.05502
[32m[0907 07-24-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31081, current rewards: -72.04844, mean: -0.04935
[32m[0907 07-25-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31094, current rewards: -66.62635, mean: -0.04412
[32m[0907 07-25-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31109, current rewards: -61.20542, mean: -0.03923
[32m[0907 07-25-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31123, current rewards: -55.78560, mean: -0.03465
[32m[0907 07-25-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31138, current rewards: -50.36143, mean: -0.03034
[32m[0907 07-26-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31153, current rewards: -44.25739, mean: -0.02588
[32m[0907 07-26-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31159, current rewards: -45.68998, mean: -0.02596
[32m[0907 07-26-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31171, current rewards: -39.95600, mean: -0.02208
[32m[0907 07-27-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31180, current rewards: -34.20700, mean: -0.01839
[32m[0907 07-27-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31189, current rewards: -28.45463, mean: -0.01490
[32m[0907 07-27-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31194, current rewards: -22.69417, mean: -0.01158
[32m[0907 07-27-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31204, current rewards: -16.94889, mean: -0.00843
[32m[0907 07-28-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31210, current rewards: -54.39409, mean: -0.02640
[32m[0907 07-28-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31215, current rewards: -48.38704, mean: -0.02293
[32m[0907 07-28-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31221, current rewards: -43.74985, mean: -0.02025
[32m[0907 07-28-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31228, current rewards: -38.16625, mean: -0.01727
[32m[0907 07-29-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31233, current rewards: -32.49952, mean: -0.01438
[32m[0907 07-29-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31240, current rewards: -26.82482, mean: -0.01161
[32m[0907 07-29-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31244, current rewards: -21.14784, mean: -0.00896
[32m[0907 07-29-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31248, current rewards: -15.47385, mean: -0.00642
[32m[0907 07-30-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31255, current rewards: -9.78595, mean: -0.00398
[32m[0907 07-30-23 @Agent.py:117][0m Average action selection time: 0.3126
[32m[0907 07-30-23 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-30-23 @MBExp.py:227][0m Rewards obtained: [-5.2231390613761945], Lows: [122], Highs: [41], Total time: 59184.292624000016
[32m[0907 07-32-38 @MBExp.py:144][0m ####################################################################
[32m[0907 07-32-38 @MBExp.py:145][0m Starting training iteration 73.
[32m[0907 07-32-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28592, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-32-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.28598, current rewards: -61.76341, mean: -1.02939
[32m[0907 07-33-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.28597, current rewards: -59.30320, mean: -0.53912
[32m[0907 07-33-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.28619, current rewards: -51.22770, mean: -0.32017
[32m[0907 07-33-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.28620, current rewards: -43.35861, mean: -0.20647
[32m[0907 07-33-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.28690, current rewards: -35.48572, mean: -0.13648
[32m[0907 07-34-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.28880, current rewards: -27.62870, mean: -0.08912
[32m[0907 07-34-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29028, current rewards: -19.73001, mean: -0.05481
[32m[0907 07-34-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29210, current rewards: -11.86621, mean: -0.02894
[32m[0907 07-34-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29415, current rewards: -3.92117, mean: -0.00852
[32m[0907 07-35-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29631, current rewards: -60.16777, mean: -0.11798
[32m[0907 07-35-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29815, current rewards: -74.12703, mean: -0.13237
[32m[0907 07-35-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30221, current rewards: -84.86208, mean: -0.13912
[32m[0907 07-36-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30607, current rewards: -127.82916, mean: -0.19368
[32m[0907 07-36-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30950, current rewards: -122.64737, mean: -0.17274
[32m[0907 07-36-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31244, current rewards: -117.30616, mean: -0.15435
[32m[0907 07-36-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31499, current rewards: -112.00040, mean: -0.13827
[32m[0907 07-37-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31540, current rewards: -106.69527, mean: -0.12406
[32m[0907 07-37-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31543, current rewards: -116.35579, mean: -0.12786
[32m[0907 07-37-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31545, current rewards: -157.85209, mean: -0.16443
[32m[0907 07-37-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31550, current rewards: -148.69003, mean: -0.14722
[32m[0907 07-38-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31553, current rewards: -138.93716, mean: -0.13107
[32m[0907 07-38-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31556, current rewards: -129.05997, mean: -0.11627
[32m[0907 07-38-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31554, current rewards: -119.18955, mean: -0.10275
[32m[0907 07-39-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31555, current rewards: -109.30538, mean: -0.09034
[32m[0907 07-39-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31549, current rewards: -99.43737, mean: -0.07892
[32m[0907 07-39-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31545, current rewards: -89.57089, mean: -0.06837
[32m[0907 07-39-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31545, current rewards: -79.69801, mean: -0.05860
[32m[0907 07-40-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31543, current rewards: -69.82916, mean: -0.04952
[32m[0907 07-40-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31543, current rewards: -59.93468, mean: -0.04105
[32m[0907 07-40-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31540, current rewards: -54.20773, mean: -0.03590
[32m[0907 07-40-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31541, current rewards: -48.19853, mean: -0.03090
[32m[0907 07-41-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31541, current rewards: -42.20628, mean: -0.02622
[32m[0907 07-41-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31542, current rewards: -36.21548, mean: -0.02182
[32m[0907 07-41-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31541, current rewards: -30.22471, mean: -0.01768
[32m[0907 07-41-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31541, current rewards: -25.39178, mean: -0.01443
[32m[0907 07-42-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31538, current rewards: -19.25560, mean: -0.01064
[32m[0907 07-42-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31539, current rewards: -13.18635, mean: -0.00709
[32m[0907 07-42-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31538, current rewards: -7.11911, mean: -0.00373
[32m[0907 07-42-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31539, current rewards: -1.05095, mean: -0.00054
[32m[0907 07-43-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31537, current rewards: 5.01845, mean: 0.00250
[32m[0907 07-43-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31536, current rewards: 11.08267, mean: 0.00538
[32m[0907 07-43-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31534, current rewards: 0.33485, mean: 0.00016
[32m[0907 07-43-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31532, current rewards: -39.60916, mean: -0.01834
[32m[0907 07-44-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31530, current rewards: -38.05257, mean: -0.01722
[32m[0907 07-44-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31528, current rewards: -28.63550, mean: -0.01267
[32m[0907 07-44-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31527, current rewards: -12.18265, mean: -0.00527
[32m[0907 07-45-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31535, current rewards: -44.86716, mean: -0.01901
[32m[0907 07-45-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31532, current rewards: -72.66278, mean: -0.03015
[32m[0907 07-45-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31533, current rewards: -83.69869, mean: -0.03402
[32m[0907 07-45-47 @Agent.py:117][0m Average action selection time: 0.3154
[32m[0907 07-45-47 @Agent.py:118][0m Rollout length: 2520
[32m[0907 07-45-47 @MBExp.py:227][0m Rewards obtained: [-82.18156168347318], Lows: [201], Highs: [44], Total time: 59973.457983000015
[32m[0907 07-48-04 @MBExp.py:144][0m ####################################################################
[32m[0907 07-48-04 @MBExp.py:145][0m Starting training iteration 74.
[32m[0907 07-48-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28646, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-48-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.28577, current rewards: -43.15545, mean: -0.71926
[32m[0907 07-48-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.28582, current rewards: -70.85188, mean: -0.64411
[32m[0907 07-48-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.28595, current rewards: -99.03293, mean: -0.61896
[32m[0907 07-49-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.28619, current rewards: -140.42227, mean: -0.66868
[32m[0907 07-49-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.28630, current rewards: -166.57623, mean: -0.64068
[32m[0907 07-49-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.28658, current rewards: -201.77362, mean: -0.65088
[32m[0907 07-49-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.28797, current rewards: -236.57761, mean: -0.65716
[32m[0907 07-50-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.28931, current rewards: -263.07088, mean: -0.64164
[32m[0907 07-50-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29142, current rewards: -347.00125, mean: -0.75435
[32m[0907 07-50-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29378, current rewards: -441.70740, mean: -0.86609
[32m[0907 07-50-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29582, current rewards: -541.70740, mean: -0.96733
[32m[0907 07-51-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29746, current rewards: -641.70740, mean: -1.05198
[32m[0907 07-51-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29891, current rewards: -741.70740, mean: -1.12380
[32m[0907 07-51-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30014, current rewards: -796.83051, mean: -1.12230
[32m[0907 07-51-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30115, current rewards: -812.13878, mean: -1.06860
[32m[0907 07-52-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30199, current rewards: -838.50526, mean: -1.03519
[32m[0907 07-52-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30278, current rewards: -860.47816, mean: -1.00056
[32m[0907 07-52-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30350, current rewards: -865.73169, mean: -0.95135
[32m[0907 07-52-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30413, current rewards: -860.67370, mean: -0.89654
[32m[0907 07-53-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30473, current rewards: -855.88583, mean: -0.84741
[32m[0907 07-53-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30528, current rewards: -851.10153, mean: -0.80293
[32m[0907 07-53-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30574, current rewards: -846.31020, mean: -0.76244
[32m[0907 07-53-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30610, current rewards: -841.52274, mean: -0.72545
[32m[0907 07-54-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30650, current rewards: -836.73417, mean: -0.69152
[32m[0907 07-54-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30684, current rewards: -831.94639, mean: -0.66027
[32m[0907 07-54-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30714, current rewards: -839.00211, mean: -0.64046
[32m[0907 07-55-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30740, current rewards: -936.64265, mean: -0.68871
[32m[0907 07-55-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30770, current rewards: -1027.39681, mean: -0.72865
[32m[0907 07-55-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30796, current rewards: -1117.63193, mean: -0.76550
[32m[0907 07-55-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30819, current rewards: -1213.15276, mean: -0.80341
[32m[0907 07-56-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30844, current rewards: -1305.58615, mean: -0.83691
[32m[0907 07-56-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30861, current rewards: -1397.15996, mean: -0.86780
[32m[0907 07-56-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30878, current rewards: -1491.40035, mean: -0.89843
[32m[0907 07-56-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30905, current rewards: -1586.25743, mean: -0.92764
[32m[0907 07-57-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30923, current rewards: -1637.87418, mean: -0.93061
[32m[0907 07-57-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30996, current rewards: -1632.40674, mean: -0.90188
[32m[0907 07-57-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31105, current rewards: -1626.66246, mean: -0.87455
[32m[0907 07-58-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31212, current rewards: -1620.90970, mean: -0.84864
[32m[0907 07-58-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31333, current rewards: -1615.16270, mean: -0.82406
[32m[0907 07-58-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31466, current rewards: -1609.41019, mean: -0.80070
[32m[0907 07-58-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31562, current rewards: -1603.66167, mean: -0.77848
[32m[0907 07-59-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31648, current rewards: -1597.91483, mean: -0.75731
[32m[0907 07-59-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31731, current rewards: -1630.20668, mean: -0.75473
[32m[0907 07-59-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31796, current rewards: -1686.92978, mean: -0.76332
[32m[0907 08-00-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31791, current rewards: -1743.08510, mean: -0.77128
[32m[0907 08-00-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31788, current rewards: -1799.25673, mean: -0.77890
[32m[0907 08-00-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31782, current rewards: -1855.62898, mean: -0.78628
[32m[0907 08-00-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31776, current rewards: -1917.10390, mean: -0.79548
[32m[0907 08-01-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31770, current rewards: -1978.71230, mean: -0.80435
[32m[0907 08-01-19 @Agent.py:117][0m Average action selection time: 0.3177
[32m[0907 08-01-19 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-01-19 @MBExp.py:227][0m Rewards obtained: [-2020.2521749253867], Lows: [1096], Highs: [41], Total time: 60768.33118500002
[32m[0907 08-03-38 @MBExp.py:144][0m ####################################################################
[32m[0907 08-03-38 @MBExp.py:145][0m Starting training iteration 75.
[32m[0907 08-03-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28973, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-03-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29021, current rewards: -56.71426, mean: -0.94524
[32m[0907 08-04-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.28949, current rewards: -87.74682, mean: -0.79770
[32m[0907 08-04-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.28860, current rewards: -124.32727, mean: -0.77705
[32m[0907 08-04-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.28828, current rewards: -176.05574, mean: -0.83836
[32m[0907 08-04-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.28792, current rewards: -207.18436, mean: -0.79686
[32m[0907 08-05-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.28786, current rewards: -213.88378, mean: -0.68995
[32m[0907 08-05-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.28862, current rewards: -253.15800, mean: -0.70322
[32m[0907 08-05-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.28961, current rewards: -311.79029, mean: -0.76046
[32m[0907 08-05-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29072, current rewards: -339.53011, mean: -0.73811
[32m[0907 08-06-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29245, current rewards: -342.22470, mean: -0.67103
[32m[0907 08-06-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29389, current rewards: -344.26359, mean: -0.61476
[32m[0907 08-06-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29568, current rewards: -338.90870, mean: -0.55559
[32m[0907 08-06-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29719, current rewards: -333.31727, mean: -0.50503
[32m[0907 08-07-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29863, current rewards: -327.72691, mean: -0.46159
[32m[0907 08-07-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29978, current rewards: -322.13791, mean: -0.42387
[32m[0907 08-07-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30077, current rewards: -316.55110, mean: -0.39080
[32m[0907 08-07-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30165, current rewards: -334.37782, mean: -0.38881
[32m[0907 08-08-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30244, current rewards: -329.64063, mean: -0.36224
[32m[0907 08-08-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30318, current rewards: -324.99001, mean: -0.33853
[32m[0907 08-08-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30381, current rewards: -320.50285, mean: -0.31733
[32m[0907 08-09-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30443, current rewards: -330.18791, mean: -0.31150
[32m[0907 08-09-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30494, current rewards: -356.46015, mean: -0.32114
[32m[0907 08-09-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30538, current rewards: -350.77989, mean: -0.30240
[32m[0907 08-09-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30579, current rewards: -345.66317, mean: -0.28567
[32m[0907 08-10-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30618, current rewards: -340.54948, mean: -0.27028
[32m[0907 08-10-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30654, current rewards: -336.47511, mean: -0.25685
[32m[0907 08-10-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30687, current rewards: -375.15860, mean: -0.27585
[32m[0907 08-10-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30718, current rewards: -375.21958, mean: -0.26611
[32m[0907 08-11-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30748, current rewards: -380.25572, mean: -0.26045
[32m[0907 08-11-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30772, current rewards: -375.61842, mean: -0.24875
[32m[0907 08-11-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30795, current rewards: -370.92751, mean: -0.23777
[32m[0907 08-11-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30818, current rewards: -366.23734, mean: -0.22748
[32m[0907 08-12-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30838, current rewards: -361.54345, mean: -0.21780
[32m[0907 08-12-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30853, current rewards: -357.06231, mean: -0.20881
[32m[0907 08-12-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30871, current rewards: -404.53334, mean: -0.22985
[32m[0907 08-12-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30888, current rewards: -406.21954, mean: -0.22443
[32m[0907 08-13-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30904, current rewards: -412.85628, mean: -0.22197
[32m[0907 08-13-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30920, current rewards: -419.49344, mean: -0.21963
[32m[0907 08-13-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30935, current rewards: -419.40140, mean: -0.21398
[32m[0907 08-14-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30946, current rewards: -419.21260, mean: -0.20856
[32m[0907 08-14-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30960, current rewards: -416.88310, mean: -0.20237
[32m[0907 08-14-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30971, current rewards: -412.97374, mean: -0.19572
[32m[0907 08-14-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30982, current rewards: -432.65258, mean: -0.20030
[32m[0907 08-15-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30993, current rewards: -426.42468, mean: -0.19295
[32m[0907 08-15-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31005, current rewards: -447.91869, mean: -0.19819
[32m[0907 08-15-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31028, current rewards: -445.16671, mean: -0.19271
[32m[0907 08-15-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31037, current rewards: -439.75562, mean: -0.18634
[32m[0907 08-16-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31048, current rewards: -434.37038, mean: -0.18024
[32m[0907 08-16-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31055, current rewards: -428.98865, mean: -0.17439
[32m[0907 08-16-35 @Agent.py:117][0m Average action selection time: 0.3106
[32m[0907 08-16-35 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-16-35 @MBExp.py:227][0m Rewards obtained: [-424.6791415855581], Lows: [298], Highs: [101], Total time: 61545.577267000015
[32m[0907 08-18-57 @MBExp.py:144][0m ####################################################################
[32m[0907 08-18-57 @MBExp.py:145][0m Starting training iteration 76.
[32m[0907 08-19-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28965, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-19-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29072, current rewards: -64.17820, mean: -1.06964
[32m[0907 08-19-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29050, current rewards: -108.71475, mean: -0.98832
[32m[0907 08-19-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.28953, current rewards: -160.52723, mean: -1.00330
[32m[0907 08-19-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.28882, current rewards: -183.83642, mean: -0.87541
[32m[0907 08-20-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.28850, current rewards: -220.04132, mean: -0.84631
[32m[0907 08-20-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.28828, current rewards: -279.20957, mean: -0.90068
[32m[0907 08-20-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.28809, current rewards: -372.40731, mean: -1.03446
[32m[0907 08-20-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.28843, current rewards: -472.40731, mean: -1.15221
[32m[0907 08-21-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.28950, current rewards: -572.40731, mean: -1.24436
[32m[0907 08-21-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29104, current rewards: -672.40731, mean: -1.31845
[32m[0907 08-21-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29272, current rewards: -772.40731, mean: -1.37930
[32m[0907 08-21-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29450, current rewards: -872.40731, mean: -1.43018
[32m[0907 08-22-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29615, current rewards: -972.40731, mean: -1.47334
[32m[0907 08-22-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29760, current rewards: -1072.40731, mean: -1.51043
[32m[0907 08-22-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29885, current rewards: -1148.97179, mean: -1.51180
[32m[0907 08-23-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30005, current rewards: -1227.76243, mean: -1.51576
[32m[0907 08-23-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30104, current rewards: -1279.46404, mean: -1.48775
[32m[0907 08-23-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30183, current rewards: -1258.49765, mean: -1.38296
[32m[0907 08-23-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30256, current rewards: -1287.45976, mean: -1.34110
[32m[0907 08-24-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30318, current rewards: -1331.13948, mean: -1.31796
[32m[0907 08-24-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30378, current rewards: -1374.72837, mean: -1.29691
[32m[0907 08-24-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30431, current rewards: -1404.04017, mean: -1.26490
[32m[0907 08-24-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30479, current rewards: -1425.62307, mean: -1.22899
[32m[0907 08-25-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30524, current rewards: -1451.03611, mean: -1.19920
[32m[0907 08-25-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30567, current rewards: -1469.56955, mean: -1.16633
[32m[0907 08-25-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30611, current rewards: -1494.92761, mean: -1.14117
[32m[0907 08-25-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30719, current rewards: -1554.21033, mean: -1.14280
[32m[0907 08-26-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30746, current rewards: -1579.71983, mean: -1.12037
[32m[0907 08-26-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30772, current rewards: -1627.93644, mean: -1.11502
[32m[0907 08-26-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30792, current rewards: -1623.48624, mean: -1.07516
[32m[0907 08-26-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30812, current rewards: -1672.82401, mean: -1.07232
[32m[0907 08-27-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30833, current rewards: -1772.82401, mean: -1.10113
[32m[0907 08-27-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30853, current rewards: -1872.82401, mean: -1.12821
[32m[0907 08-27-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30873, current rewards: -1873.96801, mean: -1.09589
[32m[0907 08-28-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30890, current rewards: -1868.44800, mean: -1.06162
[32m[0907 08-28-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30908, current rewards: -1862.93034, mean: -1.02924
[32m[0907 08-28-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30924, current rewards: -1857.41473, mean: -0.99861
[32m[0907 08-28-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30938, current rewards: -1889.88402, mean: -0.98947
[32m[0907 08-29-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30951, current rewards: -1882.93752, mean: -0.96068
[32m[0907 08-29-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30963, current rewards: -1876.74660, mean: -0.93370
[32m[0907 08-29-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30974, current rewards: -1870.55118, mean: -0.90803
[32m[0907 08-29-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30985, current rewards: -1881.24213, mean: -0.89158
[32m[0907 08-30-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30996, current rewards: -1881.01595, mean: -0.87084
[32m[0907 08-30-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31006, current rewards: -1955.05310, mean: -0.88464
[32m[0907 08-30-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31017, current rewards: -2055.05310, mean: -0.90932
[32m[0907 08-30-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31024, current rewards: -2155.05310, mean: -0.93292
[32m[0907 08-31-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31032, current rewards: -2255.05310, mean: -0.95553
[32m[0907 08-31-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31040, current rewards: -2355.05310, mean: -0.97720
[32m[0907 08-31-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31047, current rewards: -2455.05310, mean: -0.99799
[32m[0907 08-31-54 @Agent.py:117][0m Average action selection time: 0.3105
[32m[0907 08-31-54 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-31-54 @MBExp.py:227][0m Rewards obtained: [-2535.0530954274845], Lows: [1364], Highs: [108], Total time: 62322.671036000014
[32m[0907 08-34-18 @MBExp.py:144][0m ####################################################################
[32m[0907 08-34-18 @MBExp.py:145][0m Starting training iteration 77.
[32m[0907 08-34-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29884, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-34-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29968, current rewards: -66.26647, mean: -1.10444
[32m[0907 08-34-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29584, current rewards: -135.43711, mean: -1.23125
[32m[0907 08-35-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29516, current rewards: -198.52871, mean: -1.24080
[32m[0907 08-35-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29817, current rewards: -252.03277, mean: -1.20016
[32m[0907 08-35-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29728, current rewards: -312.33867, mean: -1.20130
[32m[0907 08-35-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29565, current rewards: -382.94456, mean: -1.23531
[32m[0907 08-36-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29432, current rewards: -444.99688, mean: -1.23610
[32m[0907 08-36-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29331, current rewards: -500.53375, mean: -1.22081
[32m[0907 08-36-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29333, current rewards: -573.94251, mean: -1.24770
[32m[0907 08-36-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29397, current rewards: -654.20496, mean: -1.28275
[32m[0907 08-37-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29522, current rewards: -754.20496, mean: -1.34679
[32m[0907 08-37-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29634, current rewards: -854.20496, mean: -1.40034
[32m[0907 08-37-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29782, current rewards: -954.20496, mean: -1.44577
[32m[0907 08-37-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29922, current rewards: -1054.20496, mean: -1.48480
[32m[0907 08-38-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30029, current rewards: -1154.20496, mean: -1.51869
[32m[0907 08-38-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30136, current rewards: -1254.20496, mean: -1.54840
[32m[0907 08-38-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30226, current rewards: -1354.20496, mean: -1.57466
[32m[0907 08-38-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30309, current rewards: -1454.20496, mean: -1.59803
[32m[0907 08-39-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30379, current rewards: -1554.20496, mean: -1.61896
[32m[0907 08-39-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30441, current rewards: -1654.20496, mean: -1.63783
[32m[0907 08-39-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30497, current rewards: -1754.20496, mean: -1.65491
[32m[0907 08-39-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30544, current rewards: -1854.20496, mean: -1.67045
[32m[0907 08-40-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30591, current rewards: -1954.20496, mean: -1.68466
[32m[0907 08-40-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30632, current rewards: -2054.20496, mean: -1.69769
[32m[0907 08-40-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30670, current rewards: -2154.20496, mean: -1.70969
[32m[0907 08-41-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30707, current rewards: -2254.20496, mean: -1.72077
[32m[0907 08-41-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30738, current rewards: -2354.20496, mean: -1.73103
[32m[0907 08-41-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30770, current rewards: -2454.20496, mean: -1.74057
[32m[0907 08-41-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30803, current rewards: -2554.20496, mean: -1.74946
[32m[0907 08-42-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30830, current rewards: -2654.20496, mean: -1.75775
[32m[0907 08-42-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30850, current rewards: -2754.20496, mean: -1.76552
[32m[0907 08-42-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30872, current rewards: -2854.20496, mean: -1.77280
[32m[0907 08-42-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30891, current rewards: -2954.20496, mean: -1.77964
[32m[0907 08-43-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30908, current rewards: -3054.20496, mean: -1.78608
[32m[0907 08-43-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30925, current rewards: -3154.20496, mean: -1.79216
[32m[0907 08-43-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30938, current rewards: -3254.20496, mean: -1.79790
[32m[0907 08-43-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30954, current rewards: -3354.20496, mean: -1.80334
[32m[0907 08-44-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30969, current rewards: -3454.20496, mean: -1.80848
[32m[0907 08-44-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30987, current rewards: -3554.20496, mean: -1.81337
[32m[0907 08-44-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30999, current rewards: -3654.20496, mean: -1.81801
[32m[0907 08-44-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31013, current rewards: -3754.20496, mean: -1.82243
[32m[0907 08-45-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31025, current rewards: -3854.20496, mean: -1.82664
[32m[0907 08-45-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31035, current rewards: -3954.20496, mean: -1.83065
[32m[0907 08-45-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31045, current rewards: -4054.20496, mean: -1.83448
[32m[0907 08-46-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31057, current rewards: -4154.20496, mean: -1.83814
[32m[0907 08-46-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31069, current rewards: -4254.20496, mean: -1.84165
[32m[0907 08-46-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31078, current rewards: -4354.20496, mean: -1.84500
[32m[0907 08-46-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31087, current rewards: -4454.20496, mean: -1.84822
[32m[0907 08-47-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31094, current rewards: -4554.20496, mean: -1.85130
[32m[0907 08-47-16 @Agent.py:117][0m Average action selection time: 0.3110
[32m[0907 08-47-16 @Agent.py:118][0m Rollout length: 2520
[32m[0907 08-47-16 @MBExp.py:227][0m Rewards obtained: [-4634.204963512459], Lows: [2313], Highs: [29], Total time: 63100.92708800001
[32m[0907 08-49-42 @MBExp.py:144][0m ####################################################################
[32m[0907 08-49-42 @MBExp.py:145][0m Starting training iteration 78.
[32m[0907 08-49-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30639, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-50-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31236, current rewards: -86.97364, mean: -1.44956
[32m[0907 08-50-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30898, current rewards: -165.73574, mean: -1.50669
[32m[0907 08-50-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30566, current rewards: -220.81451, mean: -1.38009
[32m[0907 08-50-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30409, current rewards: -289.08601, mean: -1.37660
[32m[0907 08-51-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30298, current rewards: -389.08601, mean: -1.49648
[32m[0907 08-51-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30128, current rewards: -489.08601, mean: -1.57770
[32m[0907 08-51-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29942, current rewards: -589.08601, mean: -1.63635
[32m[0907 08-51-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29788, current rewards: -689.08601, mean: -1.68070
[32m[0907 08-51-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29678, current rewards: -789.08601, mean: -1.71540
[32m[0907 08-52-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29629, current rewards: -889.08601, mean: -1.74331
[32m[0907 08-52-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29582, current rewards: -989.08601, mean: -1.76623
[32m[0907 08-52-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29619, current rewards: -1089.08601, mean: -1.78539
[32m[0907 08-52-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29651, current rewards: -1189.08601, mean: -1.80165
[32m[0907 08-53-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29674, current rewards: -1289.08601, mean: -1.81561
[32m[0907 08-53-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29695, current rewards: -1389.08601, mean: -1.82774
[32m[0907 08-53-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29771, current rewards: -1489.08601, mean: -1.83838
[32m[0907 08-53-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29871, current rewards: -1589.08601, mean: -1.84777
[32m[0907 08-54-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29962, current rewards: -1689.08601, mean: -1.85614
[32m[0907 08-54-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30050, current rewards: -1789.08601, mean: -1.86363
[32m[0907 08-54-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30126, current rewards: -1889.08601, mean: -1.87038
[32m[0907 08-55-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30194, current rewards: -1989.08601, mean: -1.87650
[32m[0907 08-55-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30260, current rewards: -2089.08601, mean: -1.88206
[32m[0907 08-55-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30317, current rewards: -2189.08601, mean: -1.88714
[32m[0907 08-55-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30431, current rewards: -2289.08601, mean: -1.89181
[32m[0907 08-56-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30621, current rewards: -2389.08601, mean: -1.89610
[32m[0907 08-56-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30798, current rewards: -2489.08601, mean: -1.90007
[32m[0907 08-56-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30966, current rewards: -2589.08601, mean: -1.90374
[32m[0907 08-57-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31123, current rewards: -2689.08601, mean: -1.90715
[32m[0907 08-57-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31269, current rewards: -2789.08601, mean: -1.91033
[32m[0907 08-57-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31407, current rewards: -2889.08601, mean: -1.91330
[32m[0907 08-57-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31526, current rewards: -2989.08601, mean: -1.91608
[32m[0907 08-58-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31639, current rewards: -3089.08601, mean: -1.91869
[32m[0907 08-58-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31743, current rewards: -3189.08601, mean: -1.92114
[32m[0907 08-58-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31847, current rewards: -3289.08601, mean: -1.92344
[32m[0907 08-59-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31941, current rewards: -3389.08601, mean: -1.92562
[32m[0907 08-59-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32031, current rewards: -3489.08601, mean: -1.92767
[32m[0907 08-59-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32113, current rewards: -3589.08601, mean: -1.92962
[32m[0907 08-59-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32195, current rewards: -3689.08601, mean: -1.93146
[32m[0907 09-00-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32269, current rewards: -3789.08601, mean: -1.93321
[32m[0907 09-00-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32343, current rewards: -3889.08601, mean: -1.93487
[32m[0907 09-00-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32415, current rewards: -3989.08601, mean: -1.93645
[32m[0907 09-01-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32481, current rewards: -4089.08601, mean: -1.93796
[32m[0907 09-01-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32545, current rewards: -4189.08601, mean: -1.93939
[32m[0907 09-01-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32603, current rewards: -4289.08601, mean: -1.94076
[32m[0907 09-02-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32662, current rewards: -4389.08601, mean: -1.94207
[32m[0907 09-02-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32718, current rewards: -4489.08601, mean: -1.94333
[32m[0907 09-02-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32770, current rewards: -4589.08601, mean: -1.94453
[32m[0907 09-02-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32825, current rewards: -4689.08601, mean: -1.94568
[32m[0907 09-03-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32874, current rewards: -4789.08601, mean: -1.94678
[32m[0907 09-03-25 @Agent.py:117][0m Average action selection time: 0.3291
[32m[0907 09-03-25 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-03-25 @MBExp.py:227][0m Rewards obtained: [-4869.086013737308], Lows: [2427], Highs: [28], Total time: 63924.49736900001
[32m[0907 09-06-10 @MBExp.py:144][0m ####################################################################
[32m[0907 09-06-10 @MBExp.py:145][0m Starting training iteration 79.
[32m[0907 09-06-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.54871, current rewards: 0.72046, mean: 0.07205
[32m[0907 09-06-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.40833, current rewards: -39.78272, mean: -0.66305
[32m[0907 09-06-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37807, current rewards: -137.64218, mean: -1.25129
[32m[0907 09-07-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36398, current rewards: -235.46078, mean: -1.47163
[32m[0907 09-07-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35658, current rewards: -331.06160, mean: -1.57648
[32m[0907 09-07-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35210, current rewards: -431.06160, mean: -1.65793
[32m[0907 09-07-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34795, current rewards: -531.06160, mean: -1.71310
[32m[0907 09-08-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34412, current rewards: -631.06160, mean: -1.75295
[32m[0907 09-08-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34019, current rewards: -731.06160, mean: -1.78308
[32m[0907 09-08-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33729, current rewards: -831.06160, mean: -1.80666
[32m[0907 09-09-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33584, current rewards: -931.06160, mean: -1.82561
[32m[0907 09-09-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33468, current rewards: -1031.06160, mean: -1.84118
[32m[0907 09-09-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33404, current rewards: -1131.06160, mean: -1.85420
[32m[0907 09-09-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33398, current rewards: -1231.06160, mean: -1.86524
[32m[0907 09-10-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33394, current rewards: -1331.06160, mean: -1.87473
[32m[0907 09-10-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33393, current rewards: -1431.06160, mean: -1.88298
[32m[0907 09-10-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33443, current rewards: -1531.06160, mean: -1.89020
[32m[0907 09-10-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33522, current rewards: -1631.06160, mean: -1.89658
[32m[0907 09-11-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33613, current rewards: -1731.06160, mean: -1.90227
[32m[0907 09-11-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33719, current rewards: -1831.06160, mean: -1.90736
[32m[0907 09-11-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33816, current rewards: -1931.06160, mean: -1.91194
[32m[0907 09-12-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33906, current rewards: -2031.06160, mean: -1.91610
[32m[0907 09-12-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33991, current rewards: -2131.06160, mean: -1.91988
[32m[0907 09-12-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34065, current rewards: -2231.06160, mean: -1.92333
[32m[0907 09-13-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34132, current rewards: -2331.06160, mean: -1.92650
[32m[0907 09-13-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34199, current rewards: -2431.06160, mean: -1.92941
[32m[0907 09-13-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34259, current rewards: -2531.06160, mean: -1.93211
[32m[0907 09-13-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34315, current rewards: -2631.06160, mean: -1.93460
[32m[0907 09-14-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34366, current rewards: -2731.06160, mean: -1.93692
[32m[0907 09-14-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34412, current rewards: -2831.06160, mean: -1.93908
[32m[0907 09-14-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34454, current rewards: -2931.06160, mean: -1.94110
[32m[0907 09-15-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34491, current rewards: -3031.06160, mean: -1.94299
[32m[0907 09-15-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34526, current rewards: -3131.06160, mean: -1.94476
[32m[0907 09-15-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34563, current rewards: -3231.06160, mean: -1.94642
[32m[0907 09-16-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34597, current rewards: -3331.06160, mean: -1.94799
[32m[0907 09-16-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34627, current rewards: -3431.06160, mean: -1.94947
[32m[0907 09-16-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34658, current rewards: -3531.06160, mean: -1.95086
[32m[0907 09-16-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34689, current rewards: -3631.06160, mean: -1.95218
[32m[0907 09-17-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34718, current rewards: -3731.06160, mean: -1.95344
[32m[0907 09-17-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34741, current rewards: -3831.06160, mean: -1.95462
[32m[0907 09-17-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34764, current rewards: -3931.06160, mean: -1.95575
[32m[0907 09-18-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34785, current rewards: -4031.06160, mean: -1.95683
[32m[0907 09-18-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34805, current rewards: -4131.06160, mean: -1.95785
[32m[0907 09-18-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34826, current rewards: -4231.06160, mean: -1.95882
[32m[0907 09-19-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34843, current rewards: -4331.06160, mean: -1.95976
[32m[0907 09-19-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34861, current rewards: -4431.06160, mean: -1.96065
[32m[0907 09-19-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34877, current rewards: -4531.06160, mean: -1.96150
[32m[0907 09-19-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34893, current rewards: -4631.06160, mean: -1.96231
[32m[0907 09-20-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34909, current rewards: -4731.06160, mean: -1.96310
[32m[0907 09-20-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34926, current rewards: -4831.06160, mean: -1.96385
[32m[0907 09-20-44 @Agent.py:117][0m Average action selection time: 0.3494
[32m[0907 09-20-44 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-20-44 @MBExp.py:227][0m Rewards obtained: [-4911.0615955622625], Lows: [2459], Highs: [0], Total time: 64798.751611000014
[32m[0907 09-23-33 @MBExp.py:144][0m ####################################################################
[32m[0907 09-23-33 @MBExp.py:145][0m Starting training iteration 80.
[32m[0907 09-23-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.57288, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-23-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.40839, current rewards: -85.00000, mean: -1.41667
[32m[0907 09-24-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.38093, current rewards: -146.88809, mean: -1.33535
[32m[0907 09-24-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37572, current rewards: -232.43355, mean: -1.45271
[32m[0907 09-24-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36815, current rewards: -301.26127, mean: -1.43458
[32m[0907 09-25-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36576, current rewards: -376.25370, mean: -1.44713
[32m[0907 09-25-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36427, current rewards: -447.89050, mean: -1.44481
[32m[0907 09-25-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35858, current rewards: -493.86982, mean: -1.37186
[32m[0907 09-25-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35289, current rewards: -543.86982, mean: -1.32651
[32m[0907 09-26-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34885, current rewards: -593.86982, mean: -1.29102
[32m[0907 09-26-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34634, current rewards: -643.86982, mean: -1.26249
[32m[0907 09-26-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34425, current rewards: -693.86982, mean: -1.23905
[32m[0907 09-27-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34243, current rewards: -743.86982, mean: -1.21946
[32m[0907 09-27-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34091, current rewards: -793.86982, mean: -1.20283
[32m[0907 09-27-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33964, current rewards: -843.86982, mean: -1.18855
[32m[0907 09-27-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33917, current rewards: -893.86982, mean: -1.17614
[32m[0907 09-28-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33897, current rewards: -943.86982, mean: -1.16527
[32m[0907 09-28-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33957, current rewards: -993.86982, mean: -1.15566
[32m[0907 09-28-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34033, current rewards: -1043.86982, mean: -1.14711
[32m[0907 09-29-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34104, current rewards: -1093.86982, mean: -1.13945
[32m[0907 09-29-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34171, current rewards: -1143.86982, mean: -1.13254
[32m[0907 09-29-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34237, current rewards: -1193.86982, mean: -1.12629
[32m[0907 09-29-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34286, current rewards: -1243.86982, mean: -1.12060
[32m[0907 09-30-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34329, current rewards: -1273.65416, mean: -1.09798
[32m[0907 09-30-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34369, current rewards: -1270.02083, mean: -1.04960
[32m[0907 09-30-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34411, current rewards: -1266.38750, mean: -1.00507
[32m[0907 09-31-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34447, current rewards: -1262.75417, mean: -0.96393
[32m[0907 09-31-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34483, current rewards: -1259.12084, mean: -0.92582
[32m[0907 09-31-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34512, current rewards: -1255.48751, mean: -0.89042
[32m[0907 09-31-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34540, current rewards: -1272.23485, mean: -0.87139
[32m[0907 09-32-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34565, current rewards: -1322.23485, mean: -0.87565
[32m[0907 09-32-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34591, current rewards: -1372.23485, mean: -0.87964
[32m[0907 09-32-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34615, current rewards: -1422.23485, mean: -0.88338
[32m[0907 09-33-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34635, current rewards: -1472.23485, mean: -0.88689
[32m[0907 09-33-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34655, current rewards: -1522.23485, mean: -0.89020
[32m[0907 09-33-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34672, current rewards: -1572.23485, mean: -0.89332
[32m[0907 09-34-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34692, current rewards: -1622.23485, mean: -0.89626
[32m[0907 09-34-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34710, current rewards: -1672.23485, mean: -0.89905
[32m[0907 09-34-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34724, current rewards: -1722.23485, mean: -0.90169
[32m[0907 09-34-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34737, current rewards: -1772.23485, mean: -0.90420
[32m[0907 09-35-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34752, current rewards: -1822.23485, mean: -0.90658
[32m[0907 09-35-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34764, current rewards: -1872.23485, mean: -0.90885
[32m[0907 09-35-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34776, current rewards: -1922.23485, mean: -0.91101
[32m[0907 09-36-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34786, current rewards: -1972.23485, mean: -0.91307
[32m[0907 09-36-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34797, current rewards: -2022.23485, mean: -0.91504
[32m[0907 09-36-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34806, current rewards: -2072.23485, mean: -0.91692
[32m[0907 09-36-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34815, current rewards: -2122.23485, mean: -0.91872
[32m[0907 09-37-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34823, current rewards: -2172.23485, mean: -0.92044
[32m[0907 09-37-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34831, current rewards: -2222.23485, mean: -0.92209
[32m[0907 09-37-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34839, current rewards: -2272.23485, mean: -0.92367
[32m[0907 09-38-04 @Agent.py:117][0m Average action selection time: 0.3485
[32m[0907 09-38-04 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-38-05 @MBExp.py:227][0m Rewards obtained: [-2272.147358308614], Lows: [225], Highs: [1858], Total time: 65670.67441000002
[32m[0907 09-40-56 @MBExp.py:144][0m ####################################################################
[32m[0907 09-40-56 @MBExp.py:145][0m Starting training iteration 81.
[32m[0907 09-40-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34769, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-41-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34714, current rewards: -31.13504, mean: -0.51892
[32m[0907 09-41-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34728, current rewards: -23.97113, mean: -0.21792
[32m[0907 09-41-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34721, current rewards: -17.28151, mean: -0.10801
[32m[0907 09-42-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34725, current rewards: -10.96683, mean: -0.05222
[32m[0907 09-42-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34628, current rewards: -5.63702, mean: -0.02168
[32m[0907 09-42-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34484, current rewards: 2.93751, mean: 0.00948
[32m[0907 09-42-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34194, current rewards: 8.86515, mean: 0.02463
[32m[0907 09-43-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33888, current rewards: -7.99649, mean: -0.01950
[32m[0907 09-43-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33675, current rewards: -33.07039, mean: -0.07189
[32m[0907 09-43-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33579, current rewards: -35.12373, mean: -0.06887
[32m[0907 09-44-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33488, current rewards: -35.57356, mean: -0.06352
[32m[0907 09-44-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33425, current rewards: -33.20608, mean: -0.05444
[32m[0907 09-44-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33362, current rewards: -34.58362, mean: -0.05240
[32m[0907 09-44-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33314, current rewards: -33.60194, mean: -0.04733
[32m[0907 09-45-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33281, current rewards: -32.60895, mean: -0.04291
[32m[0907 09-45-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33310, current rewards: -84.25984, mean: -0.10402
[32m[0907 09-45-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33380, current rewards: -169.00588, mean: -0.19652
[32m[0907 09-46-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33512, current rewards: -269.00588, mean: -0.29561
[32m[0907 09-46-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33628, current rewards: -369.00588, mean: -0.38438
[32m[0907 09-46-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33729, current rewards: -469.00588, mean: -0.46436
[32m[0907 09-46-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33822, current rewards: -559.00588, mean: -0.52736
[32m[0907 09-47-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33998, current rewards: -606.77902, mean: -0.54665
[32m[0907 09-47-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34074, current rewards: -599.55099, mean: -0.51685
[32m[0907 09-47-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34141, current rewards: -583.73141, mean: -0.48242
[32m[0907 09-48-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34199, current rewards: -567.79481, mean: -0.45063
[32m[0907 09-48-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34257, current rewards: -551.86140, mean: -0.42127
[32m[0907 09-48-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34308, current rewards: -536.08018, mean: -0.39418
[32m[0907 09-49-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34354, current rewards: -520.27550, mean: -0.36899
[32m[0907 09-49-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34399, current rewards: -504.48810, mean: -0.34554
[32m[0907 09-49-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34446, current rewards: -537.50215, mean: -0.35596
[32m[0907 09-49-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34487, current rewards: -555.43794, mean: -0.35605
[32m[0907 09-50-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34522, current rewards: -553.62362, mean: -0.34387
[32m[0907 09-50-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34555, current rewards: -562.61156, mean: -0.33892
[32m[0907 09-50-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34585, current rewards: -581.81708, mean: -0.34024
[32m[0907 09-51-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34612, current rewards: -576.02610, mean: -0.32729
[32m[0907 09-51-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34641, current rewards: -570.27457, mean: -0.31507
[32m[0907 09-51-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34667, current rewards: -564.52177, mean: -0.30351
[32m[0907 09-51-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34692, current rewards: -558.77265, mean: -0.29255
[32m[0907 09-52-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34729, current rewards: -576.10215, mean: -0.29393
[32m[0907 09-52-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34753, current rewards: -642.20231, mean: -0.31950
[32m[0907 09-52-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34774, current rewards: -710.21412, mean: -0.34476
[32m[0907 09-53-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34796, current rewards: -791.72851, mean: -0.37523
[32m[0907 09-53-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34816, current rewards: -870.98189, mean: -0.40323
[32m[0907 09-53-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34834, current rewards: -949.66069, mean: -0.42971
[32m[0907 09-54-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34851, current rewards: -1035.82463, mean: -0.45833
[32m[0907 09-54-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34866, current rewards: -1122.38366, mean: -0.48588
[32m[0907 09-54-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34884, current rewards: -1213.56295, mean: -0.51422
[32m[0907 09-54-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34907, current rewards: -1304.44069, mean: -0.54126
[32m[0907 09-55-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34925, current rewards: -1393.08914, mean: -0.56630
[32m[0907 09-55-30 @Agent.py:117][0m Average action selection time: 0.3494
[32m[0907 09-55-30 @Agent.py:118][0m Rollout length: 2520
[32m[0907 09-55-30 @MBExp.py:227][0m Rewards obtained: [-1455.8965687598547], Lows: [861], Highs: [79], Total time: 66544.97709300002
[32m[0907 09-58-28 @MBExp.py:144][0m ####################################################################
[32m[0907 09-58-28 @MBExp.py:145][0m Starting training iteration 82.
[32m[0907 09-58-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.37599, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-58-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35980, current rewards: -70.92384, mean: -1.18206
[32m[0907 09-59-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35761, current rewards: -107.64540, mean: -0.97859
[32m[0907 09-59-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35559, current rewards: -158.30340, mean: -0.98940
[32m[0907 09-59-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35269, current rewards: -190.37778, mean: -0.90656
[32m[0907 09-59-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35164, current rewards: -224.05051, mean: -0.86173
[32m[0907 10-00-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34958, current rewards: -267.37963, mean: -0.86251
[32m[0907 10-00-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34645, current rewards: -280.48966, mean: -0.77914
[32m[0907 10-00-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34300, current rewards: -319.87379, mean: -0.78018
[32m[0907 10-01-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34010, current rewards: -351.62485, mean: -0.76440
[32m[0907 10-01-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33845, current rewards: -345.01662, mean: -0.67650
[32m[0907 10-01-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33736, current rewards: -338.40838, mean: -0.60430
[32m[0907 10-01-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33646, current rewards: -331.80015, mean: -0.54393
[32m[0907 10-02-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33576, current rewards: -325.19192, mean: -0.49272
[32m[0907 10-02-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33504, current rewards: -320.60350, mean: -0.45155
[32m[0907 10-02-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33441, current rewards: -359.87684, mean: -0.47352
[32m[0907 10-02-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33454, current rewards: -409.87684, mean: -0.50602
[32m[0907 10-03-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33503, current rewards: -459.87684, mean: -0.53474
[32m[0907 10-03-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33603, current rewards: -509.87684, mean: -0.56030
[32m[0907 10-03-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33709, current rewards: -559.87684, mean: -0.58321
[32m[0907 10-04-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33796, current rewards: -609.87684, mean: -0.60384
[32m[0907 10-04-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33868, current rewards: -659.87684, mean: -0.62253
[32m[0907 10-04-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33942, current rewards: -709.87684, mean: -0.63953
[32m[0907 10-05-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34014, current rewards: -759.87684, mean: -0.65507
[32m[0907 10-05-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34088, current rewards: -809.87684, mean: -0.66932
[32m[0907 10-05-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34164, current rewards: -859.87684, mean: -0.68244
[32m[0907 10-05-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34240, current rewards: -909.87684, mean: -0.69456
[32m[0907 10-06-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34312, current rewards: -959.87684, mean: -0.70579
[32m[0907 10-06-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34373, current rewards: -1009.87684, mean: -0.71622
[32m[0907 10-06-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34431, current rewards: -1059.87684, mean: -0.72594
[32m[0907 10-07-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34483, current rewards: -1109.87684, mean: -0.73502
[32m[0907 10-07-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34532, current rewards: -1159.87684, mean: -0.74351
[32m[0907 10-07-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34576, current rewards: -1209.87684, mean: -0.75148
[32m[0907 10-08-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34623, current rewards: -1259.87684, mean: -0.75896
[32m[0907 10-08-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34662, current rewards: -1309.87684, mean: -0.76601
[32m[0907 10-08-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34701, current rewards: -1359.87684, mean: -0.77266
[32m[0907 10-08-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34735, current rewards: -1409.87684, mean: -0.77894
[32m[0907 10-09-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34770, current rewards: -1459.87684, mean: -0.78488
[32m[0907 10-09-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34802, current rewards: -1509.87684, mean: -0.79051
[32m[0907 10-09-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34833, current rewards: -1559.87684, mean: -0.79586
[32m[0907 10-10-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34864, current rewards: -1609.87684, mean: -0.80093
[32m[0907 10-10-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34889, current rewards: -1659.87684, mean: -0.80577
[32m[0907 10-10-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34899, current rewards: -1709.87684, mean: -0.81037
[32m[0907 10-11-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34910, current rewards: -1759.87684, mean: -0.81476
[32m[0907 10-11-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34920, current rewards: -1809.87684, mean: -0.81895
[32m[0907 10-11-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34926, current rewards: -1859.87684, mean: -0.82295
[32m[0907 10-11-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34930, current rewards: -1909.87684, mean: -0.82679
[32m[0907 10-12-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34936, current rewards: -1959.87684, mean: -0.83046
[32m[0907 10-12-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34944, current rewards: -1953.37486, mean: -0.81053
[32m[0907 10-12-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34950, current rewards: -1945.71978, mean: -0.79094
[32m[0907 10-13-02 @Agent.py:117][0m Average action selection time: 0.3495
[32m[0907 10-13-02 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-13-02 @MBExp.py:227][0m Rewards obtained: [-1939.5957120696744], Lows: [100], Highs: [1820], Total time: 67419.60334100002
[32m[0907 10-15-56 @MBExp.py:144][0m ####################################################################
[32m[0907 10-15-56 @MBExp.py:145][0m Starting training iteration 83.
[32m[0907 10-15-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34209, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-16-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34376, current rewards: -43.47193, mean: -0.72453
[32m[0907 10-16-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34366, current rewards: -65.76605, mean: -0.59787
[32m[0907 10-16-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.34349, current rewards: -115.76605, mean: -0.72354
[32m[0907 10-17-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33703, current rewards: -165.76605, mean: -0.78936
[32m[0907 10-17-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33118, current rewards: -215.76605, mean: -0.82987
[32m[0907 10-17-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32591, current rewards: -209.45506, mean: -0.67566
[32m[0907 10-17-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32217, current rewards: -201.99487, mean: -0.56110
[32m[0907 10-18-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31790, current rewards: -194.53468, mean: -0.47447
[32m[0907 10-18-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31454, current rewards: -187.07449, mean: -0.40668
[32m[0907 10-18-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31178, current rewards: -179.61430, mean: -0.35218
[32m[0907 10-18-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30999, current rewards: -172.15411, mean: -0.30742
[32m[0907 10-19-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30844, current rewards: -164.69392, mean: -0.26999
[32m[0907 10-19-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30711, current rewards: -157.96438, mean: -0.23934
[32m[0907 10-19-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30598, current rewards: -198.45385, mean: -0.27951
[32m[0907 10-19-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30498, current rewards: -248.45385, mean: -0.32691
[32m[0907 10-20-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30451, current rewards: -298.45385, mean: -0.36846
[32m[0907 10-20-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30424, current rewards: -348.45385, mean: -0.40518
[32m[0907 10-20-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30440, current rewards: -398.45385, mean: -0.43786
[32m[0907 10-20-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30502, current rewards: -448.45385, mean: -0.46714
[32m[0907 10-21-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30562, current rewards: -498.45385, mean: -0.49352
[32m[0907 10-21-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30611, current rewards: -548.45385, mean: -0.51741
[32m[0907 10-21-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30659, current rewards: -598.45385, mean: -0.53915
[32m[0907 10-21-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30700, current rewards: -648.45385, mean: -0.55901
[32m[0907 10-22-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30736, current rewards: -698.45385, mean: -0.57723
[32m[0907 10-22-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30769, current rewards: -748.45385, mean: -0.59401
[32m[0907 10-22-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30798, current rewards: -798.45385, mean: -0.60951
[32m[0907 10-22-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30825, current rewards: -848.45385, mean: -0.62386
[32m[0907 10-23-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30849, current rewards: -898.45385, mean: -0.63720
[32m[0907 10-23-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30871, current rewards: -948.45385, mean: -0.64963
[32m[0907 10-23-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30893, current rewards: -998.45385, mean: -0.66123
[32m[0907 10-23-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30912, current rewards: -1048.45385, mean: -0.67209
[32m[0907 10-24-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30930, current rewards: -1098.45385, mean: -0.68227
[32m[0907 10-24-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30947, current rewards: -1148.45385, mean: -0.69184
[32m[0907 10-24-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30962, current rewards: -1198.45385, mean: -0.70085
[32m[0907 10-25-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30976, current rewards: -1248.45385, mean: -0.70935
[32m[0907 10-25-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30991, current rewards: -1298.45385, mean: -0.71738
[32m[0907 10-25-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31002, current rewards: -1348.45385, mean: -0.72498
[32m[0907 10-25-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31014, current rewards: -1398.45385, mean: -0.73217
[32m[0907 10-26-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31025, current rewards: -1448.45385, mean: -0.73901
[32m[0907 10-26-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31037, current rewards: -1498.45385, mean: -0.74550
[32m[0907 10-26-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31045, current rewards: -1548.45385, mean: -0.75168
[32m[0907 10-26-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31057, current rewards: -1598.45385, mean: -0.75756
[32m[0907 10-27-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31065, current rewards: -1648.45385, mean: -0.76317
[32m[0907 10-27-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31073, current rewards: -1698.45385, mean: -0.76853
[32m[0907 10-27-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31082, current rewards: -1748.45385, mean: -0.77365
[32m[0907 10-27-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31090, current rewards: -1798.45385, mean: -0.77855
[32m[0907 10-28-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31100, current rewards: -1848.45385, mean: -0.78324
[32m[0907 10-28-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31106, current rewards: -1898.45385, mean: -0.78774
[32m[0907 10-28-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31112, current rewards: -1948.45385, mean: -0.79205
[32m[0907 10-28-54 @Agent.py:117][0m Average action selection time: 0.3112
[32m[0907 10-28-54 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-28-54 @MBExp.py:227][0m Rewards obtained: [-1988.4538510256962], Lows: [7], Highs: [2039], Total time: 68198.31917000002
[32m[0907 10-31-32 @MBExp.py:144][0m ####################################################################
[32m[0907 10-31-32 @MBExp.py:145][0m Starting training iteration 84.
[32m[0907 10-31-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32712, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-31-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33184, current rewards: -50.49978, mean: -0.84166
[32m[0907 10-32-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32168, current rewards: -104.21764, mean: -0.94743
[32m[0907 10-32-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31743, current rewards: -97.93056, mean: -0.61207
[32m[0907 10-32-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31521, current rewards: -92.13522, mean: -0.43874
[32m[0907 10-32-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31372, current rewards: -86.51990, mean: -0.33277
[32m[0907 10-33-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31279, current rewards: -80.98628, mean: -0.26125
[32m[0907 10-33-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31335, current rewards: -108.86910, mean: -0.30241
[32m[0907 10-33-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31203, current rewards: -138.64163, mean: -0.33815
[32m[0907 10-33-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30928, current rewards: -144.80105, mean: -0.31478
[32m[0907 10-34-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30708, current rewards: -139.26193, mean: -0.27306
[32m[0907 10-34-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30553, current rewards: -133.73051, mean: -0.23880
[32m[0907 10-34-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30438, current rewards: -128.19380, mean: -0.21015
[32m[0907 10-34-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30339, current rewards: -122.72480, mean: -0.18595
[32m[0907 10-35-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30250, current rewards: -118.96087, mean: -0.16755
[32m[0907 10-35-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30169, current rewards: -113.64506, mean: -0.14953
[32m[0907 10-35-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30096, current rewards: -108.48041, mean: -0.13393
[32m[0907 10-35-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30060, current rewards: -103.31278, mean: -0.12013
[32m[0907 10-36-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30081, current rewards: -140.20841, mean: -0.15408
[32m[0907 10-36-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30275, current rewards: -145.63092, mean: -0.15170
[32m[0907 10-36-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30370, current rewards: -143.93994, mean: -0.14251
[32m[0907 10-36-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30523, current rewards: -143.67402, mean: -0.13554
[32m[0907 10-37-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30597, current rewards: -218.09903, mean: -0.19649
[32m[0907 10-37-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30708, current rewards: -292.63753, mean: -0.25227
[32m[0907 10-37-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30749, current rewards: -377.36696, mean: -0.31187
[32m[0907 10-38-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30795, current rewards: -408.35636, mean: -0.32409
[32m[0907 10-38-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30827, current rewards: -481.13181, mean: -0.36728
[32m[0907 10-38-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30857, current rewards: -533.10705, mean: -0.39199
[32m[0907 10-38-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30882, current rewards: -595.28786, mean: -0.42219
[32m[0907 10-39-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30906, current rewards: -694.28786, mean: -0.47554
[32m[0907 10-39-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30927, current rewards: -794.28786, mean: -0.52602
[32m[0907 10-39-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31054, current rewards: -894.28786, mean: -0.57326
[32m[0907 10-39-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31184, current rewards: -994.28786, mean: -0.61757
[32m[0907 10-40-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31306, current rewards: -1094.28786, mean: -0.65921
[32m[0907 10-40-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31443, current rewards: -1194.28786, mean: -0.69841
[32m[0907 10-40-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31673, current rewards: -1294.28786, mean: -0.73539
[32m[0907 10-41-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31899, current rewards: -1394.28786, mean: -0.77032
[32m[0907 10-41-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32128, current rewards: -1494.28786, mean: -0.80338
[32m[0907 10-41-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32340, current rewards: -1594.28786, mean: -0.83471
[32m[0907 10-42-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32548, current rewards: -1694.28786, mean: -0.86443
[32m[0907 10-42-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32742, current rewards: -1794.28786, mean: -0.89268
[32m[0907 10-42-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32896, current rewards: -1894.28786, mean: -0.91956
[32m[0907 10-43-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32974, current rewards: -1994.28786, mean: -0.94516
[32m[0907 10-43-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33028, current rewards: -2094.28786, mean: -0.96958
[32m[0907 10-43-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33080, current rewards: -2194.28786, mean: -0.99289
[32m[0907 10-44-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33128, current rewards: -2294.28786, mean: -1.01517
[32m[0907 10-44-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33178, current rewards: -2394.28786, mean: -1.03649
[32m[0907 10-44-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33222, current rewards: -2494.28786, mean: -1.05690
[32m[0907 10-44-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33262, current rewards: -2594.28786, mean: -1.07647
[32m[0907 10-45-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33302, current rewards: -2694.28786, mean: -1.09524
[32m[0907 10-45-26 @Agent.py:117][0m Average action selection time: 0.3333
[32m[0907 10-45-26 @Agent.py:118][0m Rollout length: 2520
[32m[0907 10-45-26 @MBExp.py:227][0m Rewards obtained: [-2774.287859621375], Lows: [1414], Highs: [85], Total time: 69032.39916800002
[32m[0907 10-48-52 @MBExp.py:144][0m ####################################################################
[32m[0907 10-48-52 @MBExp.py:145][0m Starting training iteration 85.
[32m[0907 10-48-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.51408, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-49-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.43093, current rewards: -97.55190, mean: -1.62586
[32m[0907 10-49-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.41671, current rewards: -112.66397, mean: -1.02422
[32m[0907 10-49-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.41090, current rewards: -116.76499, mean: -0.72978
[32m[0907 10-50-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.40656, current rewards: -130.51790, mean: -0.62151
[32m[0907 10-50-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.39679, current rewards: -150.05020, mean: -0.57712
[32m[0907 10-50-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.38823, current rewards: -173.16764, mean: -0.55861
[32m[0907 10-51-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.38210, current rewards: -178.23387, mean: -0.49509
[32m[0907 10-51-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37608, current rewards: -177.59775, mean: -0.43317
[32m[0907 10-51-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36954, current rewards: -175.89857, mean: -0.38239
[32m[0907 10-51-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36425, current rewards: -174.23345, mean: -0.34163
[32m[0907 10-52-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36026, current rewards: -173.61071, mean: -0.31002
[32m[0907 10-52-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35664, current rewards: -171.92231, mean: -0.28184
[32m[0907 10-52-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35324, current rewards: -170.16319, mean: -0.25782
[32m[0907 10-53-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35043, current rewards: -206.70587, mean: -0.29114
[32m[0907 10-53-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34802, current rewards: -200.64990, mean: -0.26401
[32m[0907 10-53-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34451, current rewards: -193.37568, mean: -0.23874
[32m[0907 10-53-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34150, current rewards: -186.10147, mean: -0.21640
[32m[0907 10-54-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33936, current rewards: -178.82725, mean: -0.19651
[32m[0907 10-54-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33802, current rewards: -171.55304, mean: -0.17870
[32m[0907 10-54-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33701, current rewards: -213.53465, mean: -0.21142
[32m[0907 10-54-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33609, current rewards: -263.53465, mean: -0.24862
[32m[0907 10-55-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33525, current rewards: -313.53465, mean: -0.28246
[32m[0907 10-55-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33444, current rewards: -363.53465, mean: -0.31339
[32m[0907 10-55-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33372, current rewards: -413.53465, mean: -0.34176
[32m[0907 10-55-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33299, current rewards: -463.53465, mean: -0.36788
[32m[0907 10-56-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33236, current rewards: -513.53465, mean: -0.39201
[32m[0907 10-56-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33176, current rewards: -563.53465, mean: -0.41436
[32m[0907 10-56-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33122, current rewards: -613.53465, mean: -0.43513
[32m[0907 10-56-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33069, current rewards: -663.53465, mean: -0.45448
[32m[0907 10-57-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33022, current rewards: -713.53465, mean: -0.47254
[32m[0907 10-57-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32976, current rewards: -763.53465, mean: -0.48945
[32m[0907 10-57-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32930, current rewards: -813.53465, mean: -0.50530
[32m[0907 10-57-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32888, current rewards: -863.53465, mean: -0.52020
[32m[0907 10-58-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32850, current rewards: -913.53465, mean: -0.53423
[32m[0907 10-58-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32814, current rewards: -963.53465, mean: -0.54746
[32m[0907 10-58-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32778, current rewards: -1013.53465, mean: -0.55996
[32m[0907 10-59-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32745, current rewards: -1063.53465, mean: -0.57179
[32m[0907 10-59-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32716, current rewards: -1113.53465, mean: -0.58300
[32m[0907 10-59-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32689, current rewards: -1163.53465, mean: -0.59364
[32m[0907 10-59-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32662, current rewards: -1213.53465, mean: -0.60375
[32m[0907 11-00-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32636, current rewards: -1263.53465, mean: -0.61337
[32m[0907 11-00-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32610, current rewards: -1313.53465, mean: -0.62253
[32m[0907 11-00-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32585, current rewards: -1363.53465, mean: -0.63127
[32m[0907 11-00-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32561, current rewards: -1413.53465, mean: -0.63961
[32m[0907 11-01-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32540, current rewards: -1463.53465, mean: -0.64758
[32m[0907 11-01-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32521, current rewards: -1513.53465, mean: -0.65521
[32m[0907 11-01-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32500, current rewards: -1563.53465, mean: -0.66251
[32m[0907 11-01-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32479, current rewards: -1613.53465, mean: -0.66952
[32m[0907 11-02-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32460, current rewards: -1663.53465, mean: -0.67623
[32m[0907 11-02-24 @Agent.py:117][0m Average action selection time: 0.3245
[32m[0907 11-02-24 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-02-24 @MBExp.py:227][0m Rewards obtained: [-1703.5346498104132], Lows: [76], Highs: [1639], Total time: 69844.31103100002
[32m[0907 11-05-05 @MBExp.py:144][0m ####################################################################
[32m[0907 11-05-05 @MBExp.py:145][0m Starting training iteration 86.
[32m[0907 11-05-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31565, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-05-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32124, current rewards: -62.48735, mean: -1.04146
[32m[0907 11-05-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32430, current rewards: -104.16480, mean: -0.94695
[32m[0907 11-05-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33434, current rewards: -145.68115, mean: -0.91051
[32m[0907 11-06-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33516, current rewards: -195.77560, mean: -0.93226
[32m[0907 11-06-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33101, current rewards: -246.87657, mean: -0.94953
[32m[0907 11-06-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33024, current rewards: -295.21473, mean: -0.95231
[32m[0907 11-07-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32762, current rewards: -343.87150, mean: -0.95520
[32m[0907 11-07-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32558, current rewards: -391.51263, mean: -0.95491
[32m[0907 11-07-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32686, current rewards: -460.78890, mean: -1.00171
[32m[0907 11-07-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32640, current rewards: -518.19583, mean: -1.01607
[32m[0907 11-08-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32663, current rewards: -578.72255, mean: -1.03343
[32m[0907 11-08-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32554, current rewards: -639.60338, mean: -1.04853
[32m[0907 11-08-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32550, current rewards: -712.07958, mean: -1.07891
[32m[0907 11-08-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32397, current rewards: -770.88112, mean: -1.08575
[32m[0907 11-09-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32410, current rewards: -826.71275, mean: -1.08778
[32m[0907 11-09-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32363, current rewards: -895.21929, mean: -1.10521
[32m[0907 11-09-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32222, current rewards: -963.44815, mean: -1.12029
[32m[0907 11-09-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32099, current rewards: -958.60563, mean: -1.05341
[32m[0907 11-10-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31998, current rewards: -953.27568, mean: -0.99300
[32m[0907 11-10-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31946, current rewards: -948.61536, mean: -0.93922
[32m[0907 11-10-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31919, current rewards: -944.06708, mean: -0.89063
[32m[0907 11-10-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31906, current rewards: -939.94884, mean: -0.84680
[32m[0907 11-11-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31903, current rewards: -957.49070, mean: -0.82542
[32m[0907 11-11-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31889, current rewards: -1056.49070, mean: -0.87313
[32m[0907 11-11-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31878, current rewards: -1156.49070, mean: -0.91785
[32m[0907 11-12-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31871, current rewards: -1256.49070, mean: -0.95915
[32m[0907 11-12-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31861, current rewards: -1356.49070, mean: -0.99742
[32m[0907 11-12-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31854, current rewards: -1456.49070, mean: -1.03297
[32m[0907 11-12-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31840, current rewards: -1556.49070, mean: -1.06609
[32m[0907 11-13-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31829, current rewards: -1656.49070, mean: -1.09701
[32m[0907 11-13-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31821, current rewards: -1756.49070, mean: -1.12596
[32m[0907 11-13-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31812, current rewards: -1856.49070, mean: -1.15310
[32m[0907 11-13-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31809, current rewards: -1956.49070, mean: -1.17861
[32m[0907 11-14-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31802, current rewards: -2056.49070, mean: -1.20263
[32m[0907 11-14-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31795, current rewards: -2156.49070, mean: -1.22528
[32m[0907 11-14-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31786, current rewards: -2256.49070, mean: -1.24668
[32m[0907 11-14-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31777, current rewards: -2356.49070, mean: -1.26693
[32m[0907 11-15-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31769, current rewards: -2456.49070, mean: -1.28612
[32m[0907 11-15-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31762, current rewards: -2556.49070, mean: -1.30433
[32m[0907 11-15-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31756, current rewards: -2656.49070, mean: -1.32164
[32m[0907 11-15-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31752, current rewards: -2756.49070, mean: -1.33810
[32m[0907 11-16-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31745, current rewards: -2856.49070, mean: -1.35379
[32m[0907 11-16-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31739, current rewards: -2956.49070, mean: -1.36875
[32m[0907 11-16-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31734, current rewards: -3056.49070, mean: -1.38303
[32m[0907 11-17-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31727, current rewards: -3156.49070, mean: -1.39668
[32m[0907 11-17-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31723, current rewards: -3256.49070, mean: -1.40974
[32m[0907 11-17-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31718, current rewards: -3356.49070, mean: -1.42224
[32m[0907 11-17-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31713, current rewards: -3456.49070, mean: -1.43423
[32m[0907 11-18-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31711, current rewards: -3556.49070, mean: -1.44573
[32m[0907 11-18-18 @Agent.py:117][0m Average action selection time: 0.3171
[32m[0907 11-18-18 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-18-18 @MBExp.py:227][0m Rewards obtained: [-3636.4907011985088], Lows: [1861], Highs: [42], Total time: 70637.75875100002
[32m[0907 11-21-01 @MBExp.py:144][0m ####################################################################
[32m[0907 11-21-01 @MBExp.py:145][0m Starting training iteration 87.
[32m[0907 11-21-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31515, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-21-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31420, current rewards: -68.76222, mean: -1.14604
[32m[0907 11-21-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31536, current rewards: -73.51286, mean: -0.66830
[32m[0907 11-21-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31523, current rewards: -65.17704, mean: -0.40736
[32m[0907 11-22-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31511, current rewards: -69.92351, mean: -0.33297
[32m[0907 11-22-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31501, current rewards: -118.77127, mean: -0.45681
[32m[0907 11-22-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31430, current rewards: -163.96551, mean: -0.52892
[32m[0907 11-22-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31522, current rewards: -200.03536, mean: -0.55565
[32m[0907 11-23-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31483, current rewards: -258.94801, mean: -0.63158
[32m[0907 11-23-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31375, current rewards: -328.00473, mean: -0.71305
[32m[0907 11-23-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31262, current rewards: -347.82688, mean: -0.68201
[32m[0907 11-23-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31134, current rewards: -384.27290, mean: -0.68620
[32m[0907 11-24-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30984, current rewards: -430.20093, mean: -0.70525
[32m[0907 11-24-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30864, current rewards: -472.60180, mean: -0.71606
[32m[0907 11-24-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30707, current rewards: -538.44373, mean: -0.75837
[32m[0907 11-24-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30575, current rewards: -558.51515, mean: -0.73489
[32m[0907 11-25-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30457, current rewards: -593.01275, mean: -0.73211
[32m[0907 11-25-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30383, current rewards: -646.21613, mean: -0.75141
[32m[0907 11-25-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30313, current rewards: -691.52809, mean: -0.75992
[32m[0907 11-25-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30252, current rewards: -744.93019, mean: -0.77597
[32m[0907 11-26-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30217, current rewards: -805.47704, mean: -0.79750
[32m[0907 11-26-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30222, current rewards: -873.71480, mean: -0.82426
[32m[0907 11-26-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30272, current rewards: -948.88619, mean: -0.85485
[32m[0907 11-26-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30335, current rewards: -1024.58290, mean: -0.88326
[32m[0907 11-27-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30391, current rewards: -1124.58290, mean: -0.92941
[32m[0907 11-27-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30446, current rewards: -1224.58290, mean: -0.97189
[32m[0907 11-27-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30491, current rewards: -1324.58290, mean: -1.01113
[32m[0907 11-27-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30534, current rewards: -1424.58290, mean: -1.04749
[32m[0907 11-28-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30573, current rewards: -1524.58290, mean: -1.08126
[32m[0907 11-28-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30609, current rewards: -1624.58290, mean: -1.11273
[32m[0907 11-28-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30644, current rewards: -1724.58290, mean: -1.14211
[32m[0907 11-29-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30675, current rewards: -1824.58290, mean: -1.16960
[32m[0907 11-29-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30704, current rewards: -1924.58290, mean: -1.19539
[32m[0907 11-29-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30733, current rewards: -2024.58290, mean: -1.21963
[32m[0907 11-29-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30756, current rewards: -2124.58290, mean: -1.24245
[32m[0907 11-30-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30781, current rewards: -2224.58290, mean: -1.26397
[32m[0907 11-30-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30805, current rewards: -2324.58290, mean: -1.28430
[32m[0907 11-30-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30828, current rewards: -2424.58290, mean: -1.30354
[32m[0907 11-30-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30849, current rewards: -2524.58290, mean: -1.32177
[32m[0907 11-31-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30865, current rewards: -2624.58290, mean: -1.33907
[32m[0907 11-31-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30883, current rewards: -2724.58290, mean: -1.35551
[32m[0907 11-31-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30901, current rewards: -2824.58290, mean: -1.37116
[32m[0907 11-31-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30915, current rewards: -2924.58290, mean: -1.38606
[32m[0907 11-32-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30932, current rewards: -3024.58290, mean: -1.40027
[32m[0907 11-32-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30945, current rewards: -3124.58290, mean: -1.41384
[32m[0907 11-32-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30959, current rewards: -3224.58290, mean: -1.42681
[32m[0907 11-32-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30971, current rewards: -3324.58290, mean: -1.43921
[32m[0907 11-33-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30983, current rewards: -3424.58290, mean: -1.45109
[32m[0907 11-33-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30992, current rewards: -3524.58290, mean: -1.46248
[32m[0907 11-33-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31003, current rewards: -3624.58290, mean: -1.47341
[32m[0907 11-33-57 @Agent.py:117][0m Average action selection time: 0.3101
[32m[0907 11-33-57 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-33-57 @MBExp.py:227][0m Rewards obtained: [-3704.582904481167], Lows: [1894], Highs: [56], Total time: 71413.78258400002
[32m[0907 11-36-43 @MBExp.py:144][0m ####################################################################
[32m[0907 11-36-43 @MBExp.py:145][0m Starting training iteration 88.
[32m[0907 11-36-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33825, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-37-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32101, current rewards: -71.70430, mean: -1.19507
[32m[0907 11-37-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31771, current rewards: -159.48079, mean: -1.44983
[32m[0907 11-37-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31665, current rewards: -259.48079, mean: -1.62175
[32m[0907 11-37-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31619, current rewards: -359.48079, mean: -1.71181
[32m[0907 11-38-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31590, current rewards: -459.48079, mean: -1.76723
[32m[0907 11-38-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31554, current rewards: -559.48079, mean: -1.80478
[32m[0907 11-38-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31504, current rewards: -659.48079, mean: -1.83189
[32m[0907 11-38-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31417, current rewards: -759.48079, mean: -1.85239
[32m[0907 11-39-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31339, current rewards: -859.48079, mean: -1.86844
[32m[0907 11-39-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31191, current rewards: -959.48079, mean: -1.88133
[32m[0907 11-39-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30988, current rewards: -1059.48079, mean: -1.89193
[32m[0907 11-39-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30795, current rewards: -1159.48079, mean: -1.90079
[32m[0907 11-40-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30638, current rewards: -1259.48079, mean: -1.90830
[32m[0907 11-40-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30492, current rewards: -1359.48079, mean: -1.91476
[32m[0907 11-40-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30373, current rewards: -1459.48079, mean: -1.92037
[32m[0907 11-40-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30265, current rewards: -1559.48079, mean: -1.92528
[32m[0907 11-41-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30166, current rewards: -1659.48079, mean: -1.92963
[32m[0907 11-41-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30089, current rewards: -1759.48079, mean: -1.93350
[32m[0907 11-41-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30038, current rewards: -1859.48079, mean: -1.93696
[32m[0907 11-41-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29993, current rewards: -1959.48079, mean: -1.94008
[32m[0907 11-42-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29990, current rewards: -2059.48079, mean: -1.94291
[32m[0907 11-42-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30026, current rewards: -2159.48079, mean: -1.94548
[32m[0907 11-42-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30094, current rewards: -2259.48079, mean: -1.94783
[32m[0907 11-42-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30153, current rewards: -2359.48079, mean: -1.94998
[32m[0907 11-43-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30207, current rewards: -2459.48079, mean: -1.95197
[32m[0907 11-43-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30284, current rewards: -2559.48079, mean: -1.95380
[32m[0907 11-43-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30466, current rewards: -2659.48079, mean: -1.95550
[32m[0907 11-43-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30638, current rewards: -2759.48079, mean: -1.95708
[32m[0907 11-44-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30797, current rewards: -2859.48079, mean: -1.95855
[32m[0907 11-44-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30943, current rewards: -2959.48079, mean: -1.95992
[32m[0907 11-44-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31086, current rewards: -3059.48079, mean: -1.96121
[32m[0907 11-45-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31223, current rewards: -3159.48079, mean: -1.96241
[32m[0907 11-45-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31351, current rewards: -3259.48079, mean: -1.96354
[32m[0907 11-45-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31496, current rewards: -3359.48079, mean: -1.96461
[32m[0907 11-46-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31629, current rewards: -3459.48079, mean: -1.96561
[32m[0907 11-46-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31756, current rewards: -3559.48079, mean: -1.96656
[32m[0907 11-46-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31874, current rewards: -3659.48079, mean: -1.96746
[32m[0907 11-46-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31986, current rewards: -3759.48079, mean: -1.96831
[32m[0907 11-47-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32082, current rewards: -3859.48079, mean: -1.96912
[32m[0907 11-47-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32192, current rewards: -3959.48079, mean: -1.96989
[32m[0907 11-47-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32302, current rewards: -4059.48079, mean: -1.97062
[32m[0907 11-48-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32396, current rewards: -4159.48079, mean: -1.97132
[32m[0907 11-48-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32478, current rewards: -4259.48079, mean: -1.97198
[32m[0907 11-48-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32555, current rewards: -4359.48079, mean: -1.97262
[32m[0907 11-49-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32626, current rewards: -4459.48079, mean: -1.97322
[32m[0907 11-49-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32688, current rewards: -4559.48079, mean: -1.97380
[32m[0907 11-49-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32742, current rewards: -4659.48079, mean: -1.97436
[32m[0907 11-49-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32792, current rewards: -4759.48079, mean: -1.97489
[32m[0907 11-50-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32840, current rewards: -4859.48079, mean: -1.97540
[32m[0907 11-50-25 @Agent.py:117][0m Average action selection time: 0.3288
[32m[0907 11-50-25 @Agent.py:118][0m Rollout length: 2520
[32m[0907 11-50-25 @MBExp.py:227][0m Rewards obtained: [-4939.480792947912], Lows: [2458], Highs: [25], Total time: 72236.49973600001
[32m[0907 11-53-31 @MBExp.py:144][0m ####################################################################
[32m[0907 11-53-31 @MBExp.py:145][0m Starting training iteration 89.
[32m[0907 11-53-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.41269, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-53-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.38754, current rewards: -64.50315, mean: -1.07505
[32m[0907 11-54-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.38494, current rewards: -127.00482, mean: -1.15459
[32m[0907 11-54-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.38343, current rewards: -167.25492, mean: -1.04534
[32m[0907 11-54-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37963, current rewards: -222.56075, mean: -1.05981
[32m[0907 11-55-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37706, current rewards: -237.64515, mean: -0.91402
[32m[0907 11-55-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37569, current rewards: -268.84605, mean: -0.86725
[32m[0907 11-55-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37620, current rewards: -308.09565, mean: -0.85582
[32m[0907 11-56-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37532, current rewards: -340.33764, mean: -0.83009
[32m[0907 11-56-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37294, current rewards: -377.83999, mean: -0.82139
[32m[0907 11-56-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37167, current rewards: -402.40466, mean: -0.78903
[32m[0907 11-56-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36781, current rewards: -450.19816, mean: -0.80393
[32m[0907 11-57-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36494, current rewards: -535.44670, mean: -0.87778
[32m[0907 11-57-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36164, current rewards: -569.53700, mean: -0.86293
[32m[0907 11-57-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35814, current rewards: -577.59601, mean: -0.81352
[32m[0907 11-58-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35510, current rewards: -573.28433, mean: -0.75432
[32m[0907 11-58-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35242, current rewards: -602.64589, mean: -0.74401
[32m[0907 11-58-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35006, current rewards: -652.64589, mean: -0.75889
[32m[0907 11-58-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34838, current rewards: -702.64589, mean: -0.77214
[32m[0907 11-59-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34703, current rewards: -752.64589, mean: -0.78401
[32m[0907 11-59-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34597, current rewards: -802.64589, mean: -0.79470
[32m[0907 11-59-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34551, current rewards: -852.64589, mean: -0.80438
[32m[0907 11-59-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34550, current rewards: -902.64589, mean: -0.81319
[32m[0907 12-00-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34585, current rewards: -952.64589, mean: -0.82125
[32m[0907 12-00-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34618, current rewards: -1002.64589, mean: -0.82863
[32m[0907 12-00-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34647, current rewards: -1052.64589, mean: -0.83543
[32m[0907 12-01-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34677, current rewards: -1102.64589, mean: -0.84171
[32m[0907 12-01-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34703, current rewards: -1152.64589, mean: -0.84753
[32m[0907 12-01-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34730, current rewards: -1202.64589, mean: -0.85294
[32m[0907 12-01-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34749, current rewards: -1252.64589, mean: -0.85798
[32m[0907 12-02-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34773, current rewards: -1302.64589, mean: -0.86268
[32m[0907 12-02-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34792, current rewards: -1352.64589, mean: -0.86708
[32m[0907 12-02-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34808, current rewards: -1402.64589, mean: -0.87121
[32m[0907 12-03-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34824, current rewards: -1452.64589, mean: -0.87509
[32m[0907 12-03-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34841, current rewards: -1502.64589, mean: -0.87874
[32m[0907 12-03-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34856, current rewards: -1552.64589, mean: -0.88219
[32m[0907 12-04-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34857, current rewards: -1602.64589, mean: -0.88544
[32m[0907 12-04-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34770, current rewards: -1652.64589, mean: -0.88852
[32m[0907 12-04-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34694, current rewards: -1702.64589, mean: -0.89144
[32m[0907 12-04-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34614, current rewards: -1752.64589, mean: -0.89421
[32m[0907 12-05-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34537, current rewards: -1802.64589, mean: -0.89684
[32m[0907 12-05-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34466, current rewards: -1852.64589, mean: -0.89934
[32m[0907 12-05-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34397, current rewards: -1902.64589, mean: -0.90173
[32m[0907 12-05-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34328, current rewards: -1952.64589, mean: -0.90400
[32m[0907 12-06-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34266, current rewards: -2002.64589, mean: -0.90617
[32m[0907 12-06-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34207, current rewards: -2052.64589, mean: -0.90825
[32m[0907 12-06-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34150, current rewards: -2102.64589, mean: -0.91024
[32m[0907 12-06-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34095, current rewards: -2152.64589, mean: -0.91214
[32m[0907 12-07-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34043, current rewards: -2202.64589, mean: -0.91396
[32m[0907 12-07-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33991, current rewards: -2252.64589, mean: -0.91571
[32m[0907 12-07-40 @Agent.py:117][0m Average action selection time: 0.3395
[32m[0907 12-07-40 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-07-40 @MBExp.py:227][0m Rewards obtained: [-2292.6458881737603], Lows: [282], Highs: [1796], Total time: 73086.01918300001
[32m[0907 12-10-29 @MBExp.py:144][0m ####################################################################
[32m[0907 12-10-29 @MBExp.py:145][0m Starting training iteration 90.
[32m[0907 12-10-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31750, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-10-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31522, current rewards: -74.21787, mean: -1.23696
[32m[0907 12-11-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31505, current rewards: -82.00443, mean: -0.74549
[32m[0907 12-11-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31513, current rewards: -81.10988, mean: -0.50694
[32m[0907 12-11-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31486, current rewards: -90.37011, mean: -0.43033
[32m[0907 12-11-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31453, current rewards: -93.71919, mean: -0.36046
[32m[0907 12-12-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31440, current rewards: -87.50275, mean: -0.28227
[32m[0907 12-12-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31394, current rewards: -82.11641, mean: -0.22810
[32m[0907 12-12-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31327, current rewards: -76.74331, mean: -0.18718
[32m[0907 12-12-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31269, current rewards: -71.37794, mean: -0.15517
[32m[0907 12-13-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31203, current rewards: -65.99220, mean: -0.12940
[32m[0907 12-13-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31018, current rewards: -75.37339, mean: -0.13460
[32m[0907 12-13-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30828, current rewards: -96.95991, mean: -0.15895
[32m[0907 12-13-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30663, current rewards: -91.77397, mean: -0.13905
[32m[0907 12-14-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30521, current rewards: -86.58533, mean: -0.12195
[32m[0907 12-14-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30399, current rewards: -81.39810, mean: -0.10710
[32m[0907 12-14-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30294, current rewards: -76.21361, mean: -0.09409
[32m[0907 12-14-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30199, current rewards: -132.19823, mean: -0.15372
[32m[0907 12-15-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30118, current rewards: -125.72888, mean: -0.13816
[32m[0907 12-15-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30066, current rewards: -120.21992, mean: -0.12523
[32m[0907 12-15-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30019, current rewards: -114.12479, mean: -0.11299
[32m[0907 12-15-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29976, current rewards: -108.57766, mean: -0.10243
[32m[0907 12-16-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29986, current rewards: -103.04372, mean: -0.09283
[32m[0907 12-16-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30046, current rewards: -97.50522, mean: -0.08406
[32m[0907 12-16-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30112, current rewards: -105.29735, mean: -0.08702
[32m[0907 12-16-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30177, current rewards: -153.95780, mean: -0.12219
[32m[0907 12-17-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30242, current rewards: -197.03971, mean: -0.15041
[32m[0907 12-17-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30387, current rewards: -200.72406, mean: -0.14759
[32m[0907 12-17-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30462, current rewards: -214.68900, mean: -0.15226
[32m[0907 12-17-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30561, current rewards: -222.94366, mean: -0.15270
[32m[0907 12-18-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30618, current rewards: -233.16056, mean: -0.15441
[32m[0907 12-18-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30648, current rewards: -277.81008, mean: -0.17808
[32m[0907 12-18-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30709, current rewards: -309.39762, mean: -0.19217
[32m[0907 12-19-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30763, current rewards: -364.81849, mean: -0.21977
[32m[0907 12-19-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30816, current rewards: -396.52530, mean: -0.23189
[32m[0907 12-19-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30944, current rewards: -449.23641, mean: -0.25525
[32m[0907 12-19-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31006, current rewards: -500.68432, mean: -0.27662
[32m[0907 12-20-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31024, current rewards: -512.89281, mean: -0.27575
[32m[0907 12-20-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31039, current rewards: -539.81971, mean: -0.28263
[32m[0907 12-20-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31203, current rewards: -573.14515, mean: -0.29242
[32m[0907 12-20-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31271, current rewards: -647.69765, mean: -0.32224
[32m[0907 12-21-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31370, current rewards: -716.34027, mean: -0.34774
[32m[0907 12-21-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31425, current rewards: -798.49177, mean: -0.37843
[32m[0907 12-21-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31433, current rewards: -871.80643, mean: -0.40361
[32m[0907 12-22-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31565, current rewards: -934.69711, mean: -0.42294
[32m[0907 12-22-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31619, current rewards: -985.70849, mean: -0.43615
[32m[0907 12-22-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31652, current rewards: -1032.61486, mean: -0.44702
[32m[0907 12-22-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31658, current rewards: -1093.85258, mean: -0.46350
[32m[0907 12-23-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31665, current rewards: -1087.79292, mean: -0.45137
[32m[0907 12-23-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31662, current rewards: -1094.83626, mean: -0.44506
[32m[0907 12-23-41 @Agent.py:117][0m Average action selection time: 0.3166
[32m[0907 12-23-41 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-23-41 @MBExp.py:227][0m Rewards obtained: [-1088.839872803261], Lows: [640], Highs: [94], Total time: 73878.28476100002
[32m[0907 12-26-32 @MBExp.py:144][0m ####################################################################
[32m[0907 12-26-32 @MBExp.py:145][0m Starting training iteration 91.
[32m[0907 12-26-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31645, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-26-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31615, current rewards: -21.01473, mean: -0.35025
[32m[0907 12-27-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31589, current rewards: -15.97662, mean: -0.14524
[32m[0907 12-27-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31603, current rewards: -7.82922, mean: -0.04893
[32m[0907 12-27-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31568, current rewards: -2.88412, mean: -0.01373
[32m[0907 12-27-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31568, current rewards: -21.92066, mean: -0.08431
[32m[0907 12-28-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31510, current rewards: -11.83362, mean: -0.03817
[32m[0907 12-28-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31425, current rewards: 0.82199, mean: 0.00228
[32m[0907 12-28-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31353, current rewards: 13.47290, mean: 0.03286
[32m[0907 12-28-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31281, current rewards: 26.14009, mean: 0.05683
[32m[0907 12-29-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31141, current rewards: 38.79840, mean: 0.07608
[32m[0907 12-29-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30912, current rewards: 46.99964, mean: 0.08393
[32m[0907 12-29-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30728, current rewards: 60.09851, mean: 0.09852
[32m[0907 12-29-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30571, current rewards: 71.79289, mean: 0.10878
[32m[0907 12-30-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30441, current rewards: 83.47486, mean: 0.11757
[32m[0907 12-30-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30322, current rewards: 95.13407, mean: 0.12518
[32m[0907 12-30-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30224, current rewards: 106.78829, mean: 0.13184
[32m[0907 12-30-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30134, current rewards: 87.16977, mean: 0.10136
[32m[0907 12-31-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30078, current rewards: 82.56000, mean: 0.09073
[32m[0907 12-31-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30028, current rewards: 88.53114, mean: 0.09222
[32m[0907 12-31-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30004, current rewards: 84.18391, mean: 0.08335
[32m[0907 12-31-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29987, current rewards: 89.43737, mean: 0.08437
[32m[0907 12-32-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30027, current rewards: 94.46288, mean: 0.08510
[32m[0907 12-32-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30098, current rewards: 86.28138, mean: 0.07438
[32m[0907 12-32-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30165, current rewards: 82.92010, mean: 0.06853
[32m[0907 12-32-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30222, current rewards: 91.48843, mean: 0.07261
[32m[0907 12-33-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30275, current rewards: 100.05585, mean: 0.07638
[32m[0907 12-33-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30321, current rewards: 108.63004, mean: 0.07988
[32m[0907 12-33-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30368, current rewards: 98.37657, mean: 0.06977
[32m[0907 12-33-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30411, current rewards: 106.44297, mean: 0.07291
[32m[0907 12-34-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30485, current rewards: 93.09658, mean: 0.06165
[32m[0907 12-34-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30642, current rewards: -2.59545, mean: -0.00166
[32m[0907 12-34-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30674, current rewards: -35.80322, mean: -0.02224
[32m[0907 12-35-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30703, current rewards: -85.87080, mean: -0.05173
[32m[0907 12-35-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30728, current rewards: -128.83047, mean: -0.07534
[32m[0907 12-35-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30811, current rewards: -183.76238, mean: -0.10441
[32m[0907 12-35-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30843, current rewards: -195.30553, mean: -0.10790
[32m[0907 12-36-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30863, current rewards: -191.57075, mean: -0.10300
[32m[0907 12-36-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30880, current rewards: -187.67118, mean: -0.09826
[32m[0907 12-36-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30894, current rewards: -192.07961, mean: -0.09800
[32m[0907 12-36-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30911, current rewards: -260.52992, mean: -0.12962
[32m[0907 12-37-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30928, current rewards: -254.61813, mean: -0.12360
[32m[0907 12-37-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30944, current rewards: -249.62055, mean: -0.11830
[32m[0907 12-37-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30956, current rewards: -244.64839, mean: -0.11326
[32m[0907 12-37-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30967, current rewards: -239.67747, mean: -0.10845
[32m[0907 12-38-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30979, current rewards: -234.70649, mean: -0.10385
[32m[0907 12-38-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30991, current rewards: -237.43338, mean: -0.10279
[32m[0907 12-38-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31001, current rewards: -247.26341, mean: -0.10477
[32m[0907 12-39-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31011, current rewards: -239.01180, mean: -0.09918
[32m[0907 12-39-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31020, current rewards: -230.68816, mean: -0.09378
[32m[0907 12-39-29 @Agent.py:117][0m Average action selection time: 0.3103
[32m[0907 12-39-29 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-39-29 @MBExp.py:227][0m Rewards obtained: [-224.5252581364605], Lows: [236], Highs: [107], Total time: 74654.75974400001
[32m[0907 12-42-21 @MBExp.py:144][0m ####################################################################
[32m[0907 12-42-21 @MBExp.py:145][0m Starting training iteration 92.
[32m[0907 12-42-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31643, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-42-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31594, current rewards: -25.79845, mean: -0.42997
[32m[0907 12-42-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31578, current rewards: -79.45904, mean: -0.72235
[32m[0907 12-43-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31572, current rewards: -172.78617, mean: -1.07991
[32m[0907 12-43-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31550, current rewards: -243.65245, mean: -1.16025
[32m[0907 12-43-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31536, current rewards: -313.75351, mean: -1.20674
[32m[0907 12-43-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31503, current rewards: -389.81205, mean: -1.25746
[32m[0907 12-44-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31406, current rewards: -461.97091, mean: -1.28325
[32m[0907 12-44-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31325, current rewards: -529.48622, mean: -1.29143
[32m[0907 12-44-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31255, current rewards: -596.19572, mean: -1.29608
[32m[0907 12-45-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31115, current rewards: -667.05383, mean: -1.30795
[32m[0907 12-45-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30947, current rewards: -748.76540, mean: -1.33708
[32m[0907 12-45-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30777, current rewards: -826.61946, mean: -1.35511
[32m[0907 12-45-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30611, current rewards: -922.20970, mean: -1.39729
[32m[0907 12-45-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30475, current rewards: -1004.63642, mean: -1.41498
[32m[0907 12-46-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30355, current rewards: -1102.10618, mean: -1.45014
[32m[0907 12-46-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30247, current rewards: -1184.31666, mean: -1.46212
[32m[0907 12-46-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30158, current rewards: -1282.00218, mean: -1.49070
[32m[0907 12-46-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30113, current rewards: -1354.31485, mean: -1.48826
[32m[0907 12-47-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30060, current rewards: -1375.64655, mean: -1.43297
[32m[0907 12-47-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30011, current rewards: -1412.87725, mean: -1.39889
[32m[0907 12-47-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29980, current rewards: -1473.45619, mean: -1.39005
[32m[0907 12-47-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29983, current rewards: -1499.73816, mean: -1.35112
[32m[0907 12-48-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30019, current rewards: -1533.75484, mean: -1.32220
[32m[0907 12-48-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30073, current rewards: -1580.50020, mean: -1.30620
[32m[0907 12-48-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30137, current rewards: -1634.67338, mean: -1.29736
[32m[0907 12-48-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30195, current rewards: -1674.71033, mean: -1.27840
[32m[0907 12-49-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30266, current rewards: -1709.36331, mean: -1.25688
[32m[0907 12-49-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30314, current rewards: -1740.06381, mean: -1.23409
[32m[0907 12-49-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30356, current rewards: -1742.75736, mean: -1.19367
[32m[0907 12-50-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30430, current rewards: -1787.22302, mean: -1.18359
[32m[0907 12-50-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30515, current rewards: -1807.84060, mean: -1.15887
[32m[0907 12-50-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30608, current rewards: -1852.23906, mean: -1.15046
[32m[0907 12-50-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30670, current rewards: -1872.28704, mean: -1.12788
[32m[0907 12-51-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30709, current rewards: -1880.00736, mean: -1.09942
[32m[0907 12-51-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30733, current rewards: -1873.21261, mean: -1.06433
[32m[0907 12-51-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30755, current rewards: -1897.05313, mean: -1.04810
[32m[0907 12-51-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30774, current rewards: -1903.97673, mean: -1.02364
[32m[0907 12-52-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30796, current rewards: -1895.06070, mean: -0.99218
[32m[0907 12-52-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30813, current rewards: -1887.55706, mean: -0.96304
[32m[0907 12-52-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30830, current rewards: -1880.05880, mean: -0.93535
[32m[0907 12-52-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30846, current rewards: -1872.55735, mean: -0.90901
[32m[0907 12-53-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30861, current rewards: -1865.06753, mean: -0.88392
[32m[0907 12-53-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30875, current rewards: -1857.57573, mean: -0.85999
[32m[0907 12-53-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30906, current rewards: -1900.52434, mean: -0.85997
[32m[0907 12-54-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31025, current rewards: -1914.81413, mean: -0.84726
[32m[0907 12-54-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31097, current rewards: -1949.61903, mean: -0.84399
[32m[0907 12-54-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31186, current rewards: -1982.21768, mean: -0.83992
[32m[0907 12-54-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31259, current rewards: -2005.09638, mean: -0.83199
[32m[0907 12-55-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31322, current rewards: -2051.24989, mean: -0.83384
[32m[0907 12-55-26 @Agent.py:117][0m Average action selection time: 0.3137
[32m[0907 12-55-26 @Agent.py:118][0m Rollout length: 2520
[32m[0907 12-55-26 @MBExp.py:227][0m Rewards obtained: [-2074.015597402763], Lows: [1104], Highs: [118], Total time: 75439.84414200002
[32m[0907 12-58-21 @MBExp.py:144][0m ####################################################################
[32m[0907 12-58-21 @MBExp.py:145][0m Starting training iteration 93.
[32m[0907 12-58-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31585, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-58-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31453, current rewards: -99.00000, mean: -1.65000
[32m[0907 12-58-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31460, current rewards: -199.00000, mean: -1.80909
[32m[0907 12-59-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31471, current rewards: -299.00000, mean: -1.86875
[32m[0907 12-59-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31481, current rewards: -399.00000, mean: -1.90000
[32m[0907 12-59-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31480, current rewards: -499.00000, mean: -1.91923
[32m[0907 12-59-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31396, current rewards: -599.00000, mean: -1.93226
[32m[0907 13-00-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31317, current rewards: -699.00000, mean: -1.94167
[32m[0907 13-00-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31246, current rewards: -799.00000, mean: -1.94878
[32m[0907 13-00-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31171, current rewards: -899.00000, mean: -1.95435
[32m[0907 13-00-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31029, current rewards: -999.00000, mean: -1.95882
[32m[0907 13-01-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30856, current rewards: -1099.00000, mean: -1.96250
[32m[0907 13-01-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30713, current rewards: -1199.00000, mean: -1.96557
[32m[0907 13-01-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30564, current rewards: -1299.00000, mean: -1.96818
[32m[0907 13-01-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30435, current rewards: -1399.00000, mean: -1.97042
[32m[0907 13-02-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30318, current rewards: -1499.00000, mean: -1.97237
[32m[0907 13-02-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30220, current rewards: -1599.00000, mean: -1.97407
[32m[0907 13-02-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30132, current rewards: -1699.00000, mean: -1.97558
[32m[0907 13-02-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30075, current rewards: -1799.00000, mean: -1.97692
[32m[0907 13-03-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30024, current rewards: -1899.00000, mean: -1.97812
[32m[0907 13-03-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29975, current rewards: -1999.00000, mean: -1.97921
[32m[0907 13-03-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29951, current rewards: -2099.00000, mean: -1.98019
[32m[0907 13-03-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29970, current rewards: -2199.00000, mean: -1.98108
[32m[0907 13-04-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30014, current rewards: -2299.00000, mean: -1.98190
[32m[0907 13-04-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30055, current rewards: -2399.00000, mean: -1.98264
[32m[0907 13-04-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30123, current rewards: -2499.00000, mean: -1.98333
[32m[0907 13-04-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30180, current rewards: -2599.00000, mean: -1.98397
[32m[0907 13-05-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30231, current rewards: -2699.00000, mean: -1.98456
[32m[0907 13-05-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30279, current rewards: -2799.00000, mean: -1.98511
[32m[0907 13-05-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30321, current rewards: -2899.00000, mean: -1.98562
[32m[0907 13-05-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30362, current rewards: -2999.00000, mean: -1.98609
[32m[0907 13-06-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30400, current rewards: -3099.00000, mean: -1.98654
[32m[0907 13-06-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30438, current rewards: -3199.00000, mean: -1.98696
[32m[0907 13-06-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30470, current rewards: -3299.00000, mean: -1.98735
[32m[0907 13-07-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30506, current rewards: -3399.00000, mean: -1.98772
[32m[0907 13-07-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30534, current rewards: -3499.00000, mean: -1.98807
[32m[0907 13-07-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30620, current rewards: -3599.00000, mean: -1.98840
[32m[0907 13-07-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30745, current rewards: -3699.00000, mean: -1.98871
[32m[0907 13-08-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30864, current rewards: -3799.00000, mean: -1.98901
[32m[0907 13-08-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30976, current rewards: -3899.00000, mean: -1.98929
[32m[0907 13-08-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31089, current rewards: -3999.00000, mean: -1.98955
[32m[0907 13-09-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31202, current rewards: -4099.00000, mean: -1.98981
[32m[0907 13-09-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31307, current rewards: -4199.00000, mean: -1.99005
[32m[0907 13-09-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31409, current rewards: -4299.00000, mean: -1.99028
[32m[0907 13-09-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31506, current rewards: -4399.00000, mean: -1.99050
[32m[0907 13-10-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31604, current rewards: -4499.00000, mean: -1.99071
[32m[0907 13-10-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31696, current rewards: -4599.00000, mean: -1.99091
[32m[0907 13-10-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31783, current rewards: -4699.00000, mean: -1.99110
[32m[0907 13-11-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31872, current rewards: -4799.00000, mean: -1.99129
[32m[0907 13-11-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31951, current rewards: -4899.00000, mean: -1.99146
[32m[0907 13-11-42 @Agent.py:117][0m Average action selection time: 0.3201
[32m[0907 13-11-42 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-11-42 @MBExp.py:227][0m Rewards obtained: [-4979], Lows: [2479], Highs: [21], Total time: 76240.97079700002
[32m[0907 13-14-57 @MBExp.py:144][0m ####################################################################
[32m[0907 13-14-57 @MBExp.py:145][0m Starting training iteration 94.
[32m[0907 13-15-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.50570, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-15-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.40752, current rewards: -30.61160, mean: -0.51019
[32m[0907 13-15-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37854, current rewards: -62.07807, mean: -0.56435
[32m[0907 13-15-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.38547, current rewards: -101.49136, mean: -0.63432
[32m[0907 13-16-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37183, current rewards: -126.96221, mean: -0.60458
[32m[0907 13-16-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37339, current rewards: -152.47974, mean: -0.58646
[32m[0907 13-16-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37776, current rewards: -186.36191, mean: -0.60117
[32m[0907 13-17-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36969, current rewards: -198.73006, mean: -0.55203
[32m[0907 13-17-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36284, current rewards: -216.87973, mean: -0.52897
[32m[0907 13-17-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36037, current rewards: -274.87395, mean: -0.59755
[32m[0907 13-17-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35457, current rewards: -304.65348, mean: -0.59736
[32m[0907 13-18-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35180, current rewards: -343.62138, mean: -0.61361
[32m[0907 13-18-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34857, current rewards: -366.58082, mean: -0.60095
[32m[0907 13-18-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34480, current rewards: -389.44098, mean: -0.59006
[32m[0907 13-19-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34264, current rewards: -435.14728, mean: -0.61288
[32m[0907 13-19-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34103, current rewards: -484.59355, mean: -0.63762
[32m[0907 13-19-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34054, current rewards: -545.04696, mean: -0.67290
[32m[0907 13-19-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33826, current rewards: -593.48331, mean: -0.69010
[32m[0907 13-20-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33618, current rewards: -643.85646, mean: -0.70753
[32m[0907 13-20-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33623, current rewards: -685.48053, mean: -0.71404
[32m[0907 13-20-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33537, current rewards: -725.96739, mean: -0.71878
[32m[0907 13-20-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33609, current rewards: -761.01654, mean: -0.71794
[32m[0907 13-21-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33599, current rewards: -794.77642, mean: -0.71601
[32m[0907 13-21-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33567, current rewards: -848.47182, mean: -0.73144
[32m[0907 13-21-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33544, current rewards: -905.85586, mean: -0.74864
[32m[0907 13-21-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33467, current rewards: -941.08877, mean: -0.74690
[32m[0907 13-22-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33395, current rewards: -934.91873, mean: -0.71368
[32m[0907 13-22-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33329, current rewards: -963.48343, mean: -0.70844
[32m[0907 13-22-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33266, current rewards: -1013.48343, mean: -0.71878
[32m[0907 13-23-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33209, current rewards: -1063.48343, mean: -0.72841
[32m[0907 13-23-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33157, current rewards: -1113.48343, mean: -0.73741
[32m[0907 13-23-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33107, current rewards: -1163.48343, mean: -0.74582
[32m[0907 13-23-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33060, current rewards: -1213.48343, mean: -0.75372
[32m[0907 13-24-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33019, current rewards: -1263.48343, mean: -0.76113
[32m[0907 13-24-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32979, current rewards: -1313.48343, mean: -0.76812
[32m[0907 13-24-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32939, current rewards: -1363.48343, mean: -0.77471
[32m[0907 13-24-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32899, current rewards: -1413.48343, mean: -0.78093
[32m[0907 13-25-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32867, current rewards: -1463.48343, mean: -0.78682
[32m[0907 13-25-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32835, current rewards: -1513.48343, mean: -0.79240
[32m[0907 13-25-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32805, current rewards: -1563.48343, mean: -0.79770
[32m[0907 13-25-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32775, current rewards: -1613.48343, mean: -0.80273
[32m[0907 13-26-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32747, current rewards: -1663.48343, mean: -0.80752
[32m[0907 13-26-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32719, current rewards: -1713.48343, mean: -0.81208
[32m[0907 13-26-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32693, current rewards: -1763.48343, mean: -0.81643
[32m[0907 13-26-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32666, current rewards: -1813.48343, mean: -0.82058
[32m[0907 13-27-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32642, current rewards: -1863.48343, mean: -0.82455
[32m[0907 13-27-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32618, current rewards: -1913.48343, mean: -0.82835
[32m[0907 13-27-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32597, current rewards: -1963.48343, mean: -0.83198
[32m[0907 13-28-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32575, current rewards: -2013.48343, mean: -0.83547
[32m[0907 13-28-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32553, current rewards: -2063.48343, mean: -0.83881
[32m[0907 13-28-31 @Agent.py:117][0m Average action selection time: 0.3254
[32m[0907 13-28-31 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-28-31 @MBExp.py:227][0m Rewards obtained: [-2103.4834282584725], Lows: [371], Highs: [1461], Total time: 77055.11814200002
[32m[0907 13-31-29 @MBExp.py:144][0m ####################################################################
[32m[0907 13-31-29 @MBExp.py:145][0m Starting training iteration 95.
[32m[0907 13-31-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31585, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-31-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31649, current rewards: -91.69723, mean: -1.52829
[32m[0907 13-32-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31508, current rewards: -187.25018, mean: -1.70227
[32m[0907 13-32-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31441, current rewards: -282.36332, mean: -1.76477
[32m[0907 13-32-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31419, current rewards: -375.60530, mean: -1.78860
[32m[0907 13-32-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31424, current rewards: -471.07953, mean: -1.81184
[32m[0907 13-33-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31428, current rewards: -566.69337, mean: -1.82804
[32m[0907 13-33-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31342, current rewards: -662.15168, mean: -1.83931
[32m[0907 13-33-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31141, current rewards: -755.41110, mean: -1.84247
[32m[0907 13-33-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30914, current rewards: -850.96211, mean: -1.84992
[32m[0907 13-34-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30752, current rewards: -946.61192, mean: -1.85610
[32m[0907 13-34-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30598, current rewards: -1046.61192, mean: -1.86895
[32m[0907 13-34-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30440, current rewards: -1146.61192, mean: -1.87969
[32m[0907 13-34-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30305, current rewards: -1246.61192, mean: -1.88881
[32m[0907 13-35-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30193, current rewards: -1346.61192, mean: -1.89664
[32m[0907 13-35-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30088, current rewards: -1416.89664, mean: -1.86434
[32m[0907 13-35-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29995, current rewards: -1510.53643, mean: -1.86486
[32m[0907 13-35-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29943, current rewards: -1596.45195, mean: -1.85634
[32m[0907 13-36-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29878, current rewards: -1693.96010, mean: -1.86149
[32m[0907 13-36-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29861, current rewards: -1793.96010, mean: -1.86871
[32m[0907 13-36-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29873, current rewards: -1891.79718, mean: -1.87307
[32m[0907 13-36-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29951, current rewards: -1989.66370, mean: -1.87704
[32m[0907 13-37-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30018, current rewards: -2089.66370, mean: -1.88258
[32m[0907 13-37-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30056, current rewards: -2187.20069, mean: -1.88552
[32m[0907 13-37-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30129, current rewards: -2285.08037, mean: -1.88850
[32m[0907 13-37-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30188, current rewards: -2385.08037, mean: -1.89292
[32m[0907 13-38-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30241, current rewards: -2485.08037, mean: -1.89701
[32m[0907 13-38-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30368, current rewards: -2585.08037, mean: -1.90079
[32m[0907 13-38-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30502, current rewards: -2685.08037, mean: -1.90431
[32m[0907 13-38-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30648, current rewards: -2785.08037, mean: -1.90759
[32m[0907 13-39-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30775, current rewards: -2885.08037, mean: -1.91065
[32m[0907 13-39-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30900, current rewards: -2985.08037, mean: -1.91351
[32m[0907 13-39-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31011, current rewards: -3085.08037, mean: -1.91620
[32m[0907 13-40-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31078, current rewards: -3185.08037, mean: -1.91872
[32m[0907 13-40-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31167, current rewards: -3285.08037, mean: -1.92110
[32m[0907 13-40-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31206, current rewards: -3385.08037, mean: -1.92334
[32m[0907 13-40-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31269, current rewards: -3485.08037, mean: -1.92546
[32m[0907 13-41-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31314, current rewards: -3585.08037, mean: -1.92746
[32m[0907 13-41-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31363, current rewards: -3685.08037, mean: -1.92936
[32m[0907 13-41-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31376, current rewards: -3785.08037, mean: -1.93116
[32m[0907 13-42-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31379, current rewards: -3862.08008, mean: -1.92143
[32m[0907 13-42-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31381, current rewards: -3955.61491, mean: -1.92020
[32m[0907 13-42-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31381, current rewards: -4055.61491, mean: -1.92209
[32m[0907 13-42-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31383, current rewards: -4155.61491, mean: -1.92390
[32m[0907 13-43-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31385, current rewards: -4255.61491, mean: -1.92562
[32m[0907 13-43-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31387, current rewards: -4355.61491, mean: -1.92726
[32m[0907 13-43-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31389, current rewards: -4455.61491, mean: -1.92884
[32m[0907 13-43-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31390, current rewards: -4555.61491, mean: -1.93035
[32m[0907 13-44-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31392, current rewards: -4655.61491, mean: -1.93179
[32m[0907 13-44-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31393, current rewards: -4755.61491, mean: -1.93318
[32m[0907 13-44-34 @Agent.py:117][0m Average action selection time: 0.3139
[32m[0907 13-44-34 @Agent.py:118][0m Rollout length: 2520
[32m[0907 13-44-35 @MBExp.py:227][0m Rewards obtained: [-4835.61490882458], Lows: [2417], Highs: [22], Total time: 77840.73495300002
[32m[0907 13-47-34 @MBExp.py:144][0m ####################################################################
[32m[0907 13-47-34 @MBExp.py:145][0m Starting training iteration 96.
[32m[0907 13-47-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.52836, current rewards: 1.20711, mean: 0.12071
[32m[0907 13-47-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35950, current rewards: -54.37780, mean: -0.90630
[32m[0907 13-48-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34067, current rewards: -84.02588, mean: -0.76387
[32m[0907 13-48-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33705, current rewards: -108.52051, mean: -0.67825
[32m[0907 13-48-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33266, current rewards: -170.14258, mean: -0.81020
[32m[0907 13-49-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32954, current rewards: -260.69930, mean: -1.00269
[32m[0907 13-49-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32774, current rewards: -314.09174, mean: -1.01320
[32m[0907 13-49-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32410, current rewards: -406.48020, mean: -1.12911
[32m[0907 13-49-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32094, current rewards: -486.10779, mean: -1.18563
[32m[0907 13-50-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31833, current rewards: -553.89407, mean: -1.20412
[32m[0907 13-50-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31563, current rewards: -625.50463, mean: -1.22648
[32m[0907 13-50-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31327, current rewards: -711.50987, mean: -1.27055
[32m[0907 13-50-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31121, current rewards: -775.43358, mean: -1.27120
[32m[0907 13-50-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30947, current rewards: -839.09163, mean: -1.27135
[32m[0907 13-51-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30836, current rewards: -910.23742, mean: -1.28202
[32m[0907 13-51-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30702, current rewards: -916.44737, mean: -1.20585
[32m[0907 13-51-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30577, current rewards: -957.01871, mean: -1.18150
[32m[0907 13-51-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30462, current rewards: -1020.45743, mean: -1.18658
[32m[0907 13-52-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30362, current rewards: -1120.45743, mean: -1.23127
[32m[0907 13-52-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30329, current rewards: -1220.45743, mean: -1.27131
[32m[0907 13-52-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30351, current rewards: -1320.45743, mean: -1.30738
[32m[0907 13-52-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30376, current rewards: -1420.45743, mean: -1.34005
[32m[0907 13-53-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30399, current rewards: -1520.45743, mean: -1.36978
[32m[0907 13-53-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30421, current rewards: -1620.45743, mean: -1.39695
[32m[0907 13-53-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30450, current rewards: -1720.45743, mean: -1.42187
[32m[0907 13-53-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30495, current rewards: -1820.45743, mean: -1.44481
[32m[0907 13-54-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30535, current rewards: -1920.45743, mean: -1.46600
[32m[0907 13-54-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30572, current rewards: -2020.45743, mean: -1.48563
[32m[0907 13-54-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30610, current rewards: -2120.45743, mean: -1.50387
[32m[0907 13-55-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30644, current rewards: -2220.45743, mean: -1.52086
[32m[0907 13-55-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30678, current rewards: -2320.45743, mean: -1.53673
[32m[0907 13-55-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30707, current rewards: -2420.45743, mean: -1.55158
[32m[0907 13-55-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30734, current rewards: -2520.45743, mean: -1.56550
[32m[0907 13-56-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30758, current rewards: -2620.45743, mean: -1.57859
[32m[0907 13-56-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30780, current rewards: -2720.45743, mean: -1.59091
[32m[0907 13-56-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30803, current rewards: -2820.45743, mean: -1.60253
[32m[0907 13-56-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30824, current rewards: -2920.45743, mean: -1.61351
[32m[0907 13-57-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30844, current rewards: -3020.45743, mean: -1.62390
[32m[0907 13-57-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30862, current rewards: -3120.45743, mean: -1.63375
[32m[0907 13-57-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30880, current rewards: -3220.45743, mean: -1.64309
[32m[0907 13-57-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30896, current rewards: -3320.45743, mean: -1.65197
[32m[0907 13-58-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30912, current rewards: -3420.45743, mean: -1.66042
[32m[0907 13-58-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30927, current rewards: -3520.45743, mean: -1.66846
[32m[0907 13-58-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30941, current rewards: -3620.45743, mean: -1.67614
[32m[0907 13-58-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30954, current rewards: -3720.45743, mean: -1.68346
[32m[0907 13-59-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30967, current rewards: -3820.45743, mean: -1.69047
[32m[0907 13-59-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30977, current rewards: -3920.45743, mean: -1.69717
[32m[0907 13-59-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30986, current rewards: -4020.45743, mean: -1.70358
[32m[0907 14-00-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30995, current rewards: -4120.45743, mean: -1.70973
[32m[0907 14-00-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31005, current rewards: -4220.45743, mean: -1.71563
[32m[0907 14-00-30 @Agent.py:117][0m Average action selection time: 0.3101
[32m[0907 14-00-30 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-00-30 @MBExp.py:227][0m Rewards obtained: [-4300.457433428319], Lows: [2143], Highs: [67], Total time: 78616.81147300002
[32m[0907 14-03-32 @MBExp.py:144][0m ####################################################################
[32m[0907 14-03-32 @MBExp.py:145][0m Starting training iteration 97.
[32m[0907 14-03-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31692, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-03-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31973, current rewards: -72.95297, mean: -1.21588
[32m[0907 14-04-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32811, current rewards: -141.47405, mean: -1.28613
[32m[0907 14-04-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32588, current rewards: -219.51687, mean: -1.37198
[32m[0907 14-04-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32421, current rewards: -304.13281, mean: -1.44825
[32m[0907 14-04-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32470, current rewards: -381.53015, mean: -1.46742
[32m[0907 14-05-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32312, current rewards: -481.53015, mean: -1.55332
[32m[0907 14-05-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32017, current rewards: -581.53015, mean: -1.61536
[32m[0907 14-05-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31757, current rewards: -681.53015, mean: -1.66227
[32m[0907 14-05-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31549, current rewards: -781.53015, mean: -1.69898
[32m[0907 14-06-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31380, current rewards: -881.53015, mean: -1.72849
[32m[0907 14-06-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31241, current rewards: -981.53015, mean: -1.75273
[32m[0907 14-06-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31128, current rewards: -1081.53015, mean: -1.77300
[32m[0907 14-06-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30988, current rewards: -1181.53015, mean: -1.79020
[32m[0907 14-07-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30835, current rewards: -1281.53015, mean: -1.80497
[32m[0907 14-07-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30692, current rewards: -1381.53015, mean: -1.81780
[32m[0907 14-07-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30563, current rewards: -1481.53015, mean: -1.82905
[32m[0907 14-07-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30447, current rewards: -1581.53015, mean: -1.83899
[32m[0907 14-08-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30347, current rewards: -1681.53015, mean: -1.84784
[32m[0907 14-08-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30300, current rewards: -1781.53015, mean: -1.85576
[32m[0907 14-08-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30280, current rewards: -1881.53015, mean: -1.86290
[32m[0907 14-08-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30267, current rewards: -1981.53015, mean: -1.86937
[32m[0907 14-09-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30251, current rewards: -2081.53015, mean: -1.87525
[32m[0907 14-09-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30237, current rewards: -2181.53015, mean: -1.88063
[32m[0907 14-09-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30222, current rewards: -2281.53015, mean: -1.88556
[32m[0907 14-09-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30224, current rewards: -2381.53015, mean: -1.89010
[32m[0907 14-10-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30252, current rewards: -2481.53015, mean: -1.89430
[32m[0907 14-10-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30306, current rewards: -2581.53015, mean: -1.89818
[32m[0907 14-10-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30354, current rewards: -2681.53015, mean: -1.90179
[32m[0907 14-10-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30393, current rewards: -2781.53015, mean: -1.90516
[32m[0907 14-11-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30434, current rewards: -2881.53015, mean: -1.90830
[32m[0907 14-11-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30469, current rewards: -2981.53015, mean: -1.91124
[32m[0907 14-11-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30502, current rewards: -3081.53015, mean: -1.91399
[32m[0907 14-11-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30533, current rewards: -3181.53015, mean: -1.91658
[32m[0907 14-12-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30564, current rewards: -3281.53015, mean: -1.91902
[32m[0907 14-12-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30590, current rewards: -3381.53015, mean: -1.92132
[32m[0907 14-12-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30613, current rewards: -3481.53015, mean: -1.92350
[32m[0907 14-13-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30636, current rewards: -3581.53015, mean: -1.92555
[32m[0907 14-13-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30655, current rewards: -3681.53015, mean: -1.92750
[32m[0907 14-13-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30674, current rewards: -3781.53015, mean: -1.92935
[32m[0907 14-13-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30693, current rewards: -3881.53015, mean: -1.93111
[32m[0907 14-14-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30712, current rewards: -3981.53015, mean: -1.93278
[32m[0907 14-14-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30732, current rewards: -4081.53015, mean: -1.93437
[32m[0907 14-14-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30750, current rewards: -4181.53015, mean: -1.93589
[32m[0907 14-14-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30766, current rewards: -4281.53015, mean: -1.93734
[32m[0907 14-15-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30781, current rewards: -4381.53015, mean: -1.93873
[32m[0907 14-15-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30796, current rewards: -4481.53015, mean: -1.94006
[32m[0907 14-15-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30811, current rewards: -4581.53015, mean: -1.94133
[32m[0907 14-15-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30826, current rewards: -4681.53015, mean: -1.94254
[32m[0907 14-16-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30837, current rewards: -4781.53015, mean: -1.94371
[32m[0907 14-16-24 @Agent.py:117][0m Average action selection time: 0.3085
[32m[0907 14-16-24 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-16-24 @MBExp.py:227][0m Rewards obtained: [-4861.530149756304], Lows: [2402], Highs: [67], Total time: 79388.74354800003
[32m[0907 14-19-27 @MBExp.py:144][0m ####################################################################
[32m[0907 14-19-27 @MBExp.py:145][0m Starting training iteration 98.
[32m[0907 14-19-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.45314, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-19-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37147, current rewards: -46.91178, mean: -0.78186
[32m[0907 14-20-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34551, current rewards: -96.91178, mean: -0.88102
[32m[0907 14-20-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33556, current rewards: -146.91178, mean: -0.91820
[32m[0907 14-20-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33038, current rewards: -196.91178, mean: -0.93768
[32m[0907 14-20-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32718, current rewards: -246.91178, mean: -0.94966
[32m[0907 14-21-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32501, current rewards: -296.91178, mean: -0.95778
[32m[0907 14-21-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32180, current rewards: -346.91178, mean: -0.96364
[32m[0907 14-21-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31892, current rewards: -396.91178, mean: -0.96808
[32m[0907 14-21-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31667, current rewards: -417.86019, mean: -0.90839
[32m[0907 14-22-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31494, current rewards: -414.06094, mean: -0.81188
[32m[0907 14-22-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31350, current rewards: -410.26169, mean: -0.73261
[32m[0907 14-22-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31227, current rewards: -406.46244, mean: -0.66633
[32m[0907 14-22-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31097, current rewards: -402.66319, mean: -0.61010
[32m[0907 14-23-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30951, current rewards: -398.86394, mean: -0.56178
[32m[0907 14-23-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30798, current rewards: -395.06469, mean: -0.51982
[32m[0907 14-23-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30662, current rewards: -391.26544, mean: -0.48304
[32m[0907 14-23-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30546, current rewards: -387.46619, mean: -0.45054
[32m[0907 14-24-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30442, current rewards: -383.66694, mean: -0.42161
[32m[0907 14-24-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30381, current rewards: -414.29921, mean: -0.43156
[32m[0907 14-24-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30362, current rewards: -464.29921, mean: -0.45970
[32m[0907 14-24-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30346, current rewards: -514.29921, mean: -0.48519
[32m[0907 14-25-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30329, current rewards: -564.29921, mean: -0.50838
[32m[0907 14-25-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30312, current rewards: -614.29921, mean: -0.52957
[32m[0907 14-25-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30299, current rewards: -664.29921, mean: -0.54901
[32m[0907 14-25-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30288, current rewards: -714.29921, mean: -0.56690
[32m[0907 14-26-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30310, current rewards: -764.29921, mean: -0.58343
[32m[0907 14-26-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30356, current rewards: -814.29921, mean: -0.59875
[32m[0907 14-26-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30404, current rewards: -864.29921, mean: -0.61298
[32m[0907 14-26-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30447, current rewards: -914.29921, mean: -0.62623
[32m[0907 14-27-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30490, current rewards: -964.29921, mean: -0.63861
[32m[0907 14-27-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30525, current rewards: -1014.29921, mean: -0.65019
[32m[0907 14-27-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30560, current rewards: -1064.29921, mean: -0.66106
[32m[0907 14-27-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30588, current rewards: -1114.29921, mean: -0.67126
[32m[0907 14-28-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30615, current rewards: -1164.29921, mean: -0.68088
[32m[0907 14-28-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30643, current rewards: -1214.29921, mean: -0.68994
[32m[0907 14-28-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30666, current rewards: -1264.29921, mean: -0.69851
[32m[0907 14-28-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30690, current rewards: -1314.29921, mean: -0.70661
[32m[0907 14-29-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30713, current rewards: -1364.29921, mean: -0.71429
[32m[0907 14-29-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30736, current rewards: -1414.29921, mean: -0.72158
[32m[0907 14-29-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30758, current rewards: -1464.29921, mean: -0.72851
[32m[0907 14-30-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30777, current rewards: -1514.29921, mean: -0.73510
[32m[0907 14-30-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30798, current rewards: -1564.29921, mean: -0.74137
[32m[0907 14-30-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30818, current rewards: -1614.29921, mean: -0.74736
[32m[0907 14-30-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30832, current rewards: -1664.29921, mean: -0.75308
[32m[0907 14-31-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30846, current rewards: -1714.29921, mean: -0.75854
[32m[0907 14-31-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30861, current rewards: -1764.29921, mean: -0.76377
[32m[0907 14-31-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30874, current rewards: -1814.29921, mean: -0.76877
[32m[0907 14-31-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30885, current rewards: -1864.29921, mean: -0.77357
[32m[0907 14-32-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30896, current rewards: -1914.29921, mean: -0.77817
[32m[0907 14-32-20 @Agent.py:117][0m Average action selection time: 0.3090
[32m[0907 14-32-20 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-32-20 @MBExp.py:227][0m Rewards obtained: [-1954.299211694899], Lows: [4], Highs: [1985], Total time: 80162.12325000003
[32m[0907 14-35-26 @MBExp.py:144][0m ####################################################################
[32m[0907 14-35-26 @MBExp.py:145][0m Starting training iteration 99.
[32m[0907 14-35-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31573, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-35-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31588, current rewards: -74.16632, mean: -1.23611
[32m[0907 14-36-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31552, current rewards: -174.16632, mean: -1.58333
[32m[0907 14-36-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31546, current rewards: -274.16632, mean: -1.71354
[32m[0907 14-36-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31519, current rewards: -374.16632, mean: -1.78174
[32m[0907 14-36-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31514, current rewards: -474.16632, mean: -1.82372
[32m[0907 14-37-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31516, current rewards: -574.16632, mean: -1.85215
[32m[0907 14-37-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31437, current rewards: -674.16632, mean: -1.87268
[32m[0907 14-37-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31250, current rewards: -774.16632, mean: -1.88821
[32m[0907 14-37-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31106, current rewards: -874.16632, mean: -1.90036
[32m[0907 14-38-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30987, current rewards: -974.16632, mean: -1.91013
[32m[0907 14-38-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30882, current rewards: -1074.16632, mean: -1.91815
[32m[0907 14-38-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30795, current rewards: -1174.16632, mean: -1.92486
[32m[0907 14-38-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30724, current rewards: -1274.16632, mean: -1.93056
[32m[0907 14-39-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30602, current rewards: -1374.16632, mean: -1.93545
[32m[0907 14-39-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30473, current rewards: -1474.16632, mean: -1.93969
[32m[0907 14-39-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30363, current rewards: -1574.16632, mean: -1.94342
[32m[0907 14-39-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30263, current rewards: -1674.16632, mean: -1.94671
[32m[0907 14-40-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30238, current rewards: -1771.40319, mean: -1.94660
[32m[0907 14-40-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30159, current rewards: -1865.82201, mean: -1.94356
[32m[0907 14-40-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30157, current rewards: -1965.82201, mean: -1.94636
[32m[0907 14-40-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30147, current rewards: -2065.82201, mean: -1.94889
[32m[0907 14-41-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30136, current rewards: -2165.82201, mean: -1.95119
[32m[0907 14-41-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30143, current rewards: -2263.35562, mean: -1.95117
[32m[0907 14-41-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30135, current rewards: -2363.35562, mean: -1.95319
[32m[0907 14-41-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30144, current rewards: -2463.35562, mean: -1.95504
[32m[0907 14-42-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30160, current rewards: -2563.35562, mean: -1.95676
[32m[0907 14-42-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30201, current rewards: -2663.35562, mean: -1.95835
[32m[0907 14-42-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30262, current rewards: -2763.35562, mean: -1.95983
[32m[0907 14-42-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30311, current rewards: -2863.35562, mean: -1.96120
[32m[0907 14-43-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30355, current rewards: -2918.14163, mean: -1.93254
[32m[0907 14-43-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30393, current rewards: -2954.36793, mean: -1.89383
[32m[0907 14-43-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30473, current rewards: -2963.78520, mean: -1.84086
[32m[0907 14-43-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30507, current rewards: -2961.17893, mean: -1.78384
[32m[0907 14-44-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30538, current rewards: -2953.82468, mean: -1.72738
[32m[0907 14-44-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30568, current rewards: -2946.47719, mean: -1.67413
[32m[0907 14-44-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30606, current rewards: -2943.42450, mean: -1.62620
[32m[0907 14-44-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30629, current rewards: -3028.68662, mean: -1.62833
[32m[0907 14-45-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30651, current rewards: -3128.68662, mean: -1.63806
[32m[0907 14-45-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30673, current rewards: -3228.68662, mean: -1.64729
[32m[0907 14-45-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30696, current rewards: -3328.68662, mean: -1.65606
[32m[0907 14-45-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30717, current rewards: -3397.53859, mean: -1.64929
[32m[0907 14-46-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30736, current rewards: -3490.00823, mean: -1.65403
[32m[0907 14-46-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30755, current rewards: -3575.02188, mean: -1.65510
[32m[0907 14-46-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30773, current rewards: -3675.02188, mean: -1.66291
[32m[0907 14-47-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30789, current rewards: -3775.02188, mean: -1.67036
[32m[0907 14-47-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30806, current rewards: -3875.02188, mean: -1.67750
[32m[0907 14-47-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30820, current rewards: -3975.02188, mean: -1.68433
[32m[0907 14-47-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30833, current rewards: -4075.02188, mean: -1.69088
[32m[0907 14-48-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30845, current rewards: -4175.02188, mean: -1.69716
[32m[0907 14-48-18 @Agent.py:117][0m Average action selection time: 0.3086
[32m[0907 14-48-18 @Agent.py:118][0m Rollout length: 2520
[32m[0907 14-48-18 @MBExp.py:227][0m Rewards obtained: [-4243.912760531037], Lows: [2134], Highs: [40], Total time: 80934.27902900003
[32m[0907 14-51-26 @MBExp.py:144][0m ####################################################################
[32m[0907 14-51-26 @MBExp.py:145][0m Starting training iteration 100.
[32m[0907 14-51-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33876, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-51-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32462, current rewards: -90.66720, mean: -1.51112
[32m[0907 14-52-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32032, current rewards: -190.66720, mean: -1.73334
[32m[0907 14-52-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31860, current rewards: -290.66720, mean: -1.81667
[32m[0907 14-52-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31821, current rewards: -390.66720, mean: -1.86032
[32m[0907 14-52-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31777, current rewards: -487.75695, mean: -1.87599
[32m[0907 14-53-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31747, current rewards: -584.76247, mean: -1.88633
[32m[0907 14-53-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31669, current rewards: -682.50553, mean: -1.89585
[32m[0907 14-53-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31567, current rewards: -780.37131, mean: -1.90334
[32m[0907 14-53-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31485, current rewards: -880.37131, mean: -1.91385
[32m[0907 14-54-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31354, current rewards: -974.81080, mean: -1.91139
[32m[0907 14-54-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31218, current rewards: -1063.01504, mean: -1.89824
[32m[0907 14-54-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31107, current rewards: -1153.82924, mean: -1.89152
[32m[0907 14-54-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31018, current rewards: -1242.04997, mean: -1.88189
[32m[0907 14-55-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30882, current rewards: -1337.83347, mean: -1.88427
[32m[0907 14-55-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30736, current rewards: -1433.61161, mean: -1.88633
[32m[0907 14-55-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30632, current rewards: -1509.88268, mean: -1.86405
[32m[0907 14-55-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30518, current rewards: -1593.26358, mean: -1.85263
[32m[0907 14-56-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30416, current rewards: -1693.26358, mean: -1.86073
[32m[0907 14-56-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30326, current rewards: -1793.26358, mean: -1.86798
[32m[0907 14-56-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30259, current rewards: -1893.26358, mean: -1.87452
[32m[0907 14-56-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30206, current rewards: -1993.26358, mean: -1.88044
[32m[0907 14-57-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30163, current rewards: -2093.26358, mean: -1.88582
[32m[0907 14-57-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30158, current rewards: -2193.26358, mean: -1.89074
[32m[0907 14-57-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30153, current rewards: -2293.26358, mean: -1.89526
[32m[0907 14-57-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30151, current rewards: -2393.26358, mean: -1.89942
[32m[0907 14-58-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30154, current rewards: -2488.55092, mean: -1.89966
[32m[0907 14-58-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30188, current rewards: -2588.55092, mean: -1.90335
[32m[0907 14-58-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30242, current rewards: -2688.55092, mean: -1.90677
[32m[0907 14-58-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30295, current rewards: -2788.55092, mean: -1.90997
[32m[0907 14-59-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30343, current rewards: -2888.55092, mean: -1.91295
[32m[0907 14-59-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30386, current rewards: -2988.55092, mean: -1.91574
[32m[0907 14-59-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30427, current rewards: -3088.55092, mean: -1.91835
[32m[0907 14-59-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30463, current rewards: -3188.55092, mean: -1.92081
[32m[0907 15-00-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30500, current rewards: -3288.55092, mean: -1.92313
[32m[0907 15-00-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30534, current rewards: -3388.55092, mean: -1.92531
[32m[0907 15-00-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30564, current rewards: -3488.55092, mean: -1.92738
[32m[0907 15-00-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30590, current rewards: -3588.55092, mean: -1.92933
[32m[0907 15-01-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30616, current rewards: -3688.55092, mean: -1.93118
[32m[0907 15-01-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30641, current rewards: -3788.55092, mean: -1.93293
[32m[0907 15-01-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30667, current rewards: -3888.55092, mean: -1.93460
[32m[0907 15-01-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30689, current rewards: -3988.55092, mean: -1.93619
[32m[0907 15-02-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30708, current rewards: -4088.55092, mean: -1.93770
[32m[0907 15-02-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30728, current rewards: -4188.55092, mean: -1.93914
[32m[0907 15-02-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30748, current rewards: -4288.55092, mean: -1.94052
[32m[0907 15-03-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30763, current rewards: -4388.55092, mean: -1.94184
[32m[0907 15-03-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30781, current rewards: -4488.55092, mean: -1.94310
[32m[0907 15-03-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30796, current rewards: -4588.55092, mean: -1.94430
[32m[0907 15-03-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30813, current rewards: -4688.55092, mean: -1.94546
[32m[0907 15-04-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30826, current rewards: -4788.55092, mean: -1.94657
[32m[0907 15-04-18 @Agent.py:117][0m Average action selection time: 0.3084
[32m[0907 15-04-18 @Agent.py:118][0m Rollout length: 2520
[32m[0907 15-04-18 @MBExp.py:227][0m Rewards obtained: [-4868.550917828301], Lows: [2421], Highs: [41], Total time: 81705.96459000003
[32m[0907 15-07-27 @MBExp.py:144][0m ####################################################################
[32m[0907 15-07-27 @MBExp.py:145][0m Starting training iteration 101.
[32m[0907 15-07-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.52756, current rewards: -10.00000, mean: -1.00000
[32m[0907 15-07-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36214, current rewards: -62.97420, mean: -1.04957
[32m[0907 15-08-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.34061, current rewards: -112.97420, mean: -1.02704
[32m[0907 15-08-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33257, current rewards: -162.97420, mean: -1.01859
[32m[0907 15-08-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32827, current rewards: -212.97420, mean: -1.01416
[32m[0907 15-08-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32580, current rewards: -262.97420, mean: -1.01144
[32m[0907 15-09-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32398, current rewards: -312.97420, mean: -1.00959
[32m[0907 15-09-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32251, current rewards: -362.97420, mean: -1.00826
[32m[0907 15-09-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32066, current rewards: -412.97420, mean: -1.00725
[32m[0907 15-09-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31930, current rewards: -462.97420, mean: -1.00647
[32m[0907 15-10-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31821, current rewards: -512.97420, mean: -1.00583
[32m[0907 15-10-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31660, current rewards: -562.97420, mean: -1.00531
[32m[0907 15-10-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31518, current rewards: -612.97420, mean: -1.00488
[32m[0907 15-10-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31394, current rewards: -662.97420, mean: -1.00451
[32m[0907 15-11-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31286, current rewards: -712.97420, mean: -1.00419
[32m[0907 15-11-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31141, current rewards: -762.97420, mean: -1.00391
[32m[0907 15-11-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30986, current rewards: -812.97420, mean: -1.00367
[32m[0907 15-11-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30853, current rewards: -862.97420, mean: -1.00346
[32m[0907 15-12-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30730, current rewards: -912.97420, mean: -1.00327
[32m[0907 15-12-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30624, current rewards: -962.97420, mean: -1.00310
[32m[0907 15-12-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30538, current rewards: -1012.97420, mean: -1.00294
[32m[0907 15-12-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30471, current rewards: -1062.97420, mean: -1.00281
[32m[0907 15-13-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30411, current rewards: -1112.97420, mean: -1.00268
[32m[0907 15-13-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30362, current rewards: -1162.97420, mean: -1.00256
[32m[0907 15-13-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30345, current rewards: -1212.97420, mean: -1.00246
[32m[0907 15-13-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30332, current rewards: -1262.97420, mean: -1.00236
[32m[0907 15-14-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30319, current rewards: -1312.97420, mean: -1.00227
[32m[0907 15-14-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30309, current rewards: -1362.97420, mean: -1.00219
[32m[0907 15-14-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30350, current rewards: -1412.97420, mean: -1.00211
[32m[0907 15-14-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30397, current rewards: -1431.35725, mean: -0.98038
[32m[0907 15-15-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30439, current rewards: -1424.89843, mean: -0.94364
[32m[0907 15-15-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30474, current rewards: -1418.54749, mean: -0.90933
[32m[0907 15-15-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30509, current rewards: -1451.48447, mean: -0.90154
[32m[0907 15-15-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30543, current rewards: -1501.48447, mean: -0.90451
[32m[0907 15-16-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30572, current rewards: -1551.48447, mean: -0.90730
[32m[0907 15-16-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30603, current rewards: -1601.48447, mean: -0.90993
[32m[0907 15-16-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30627, current rewards: -1651.48447, mean: -0.91242
[32m[0907 15-16-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30650, current rewards: -1701.48447, mean: -0.91478
[32m[0907 15-17-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30675, current rewards: -1751.48447, mean: -0.91701
[32m[0907 15-17-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30695, current rewards: -1801.48447, mean: -0.91912
[32m[0907 15-17-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30716, current rewards: -1824.74040, mean: -0.90783
[32m[0907 15-18-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30734, current rewards: -1820.82322, mean: -0.88389
[32m[0907 15-18-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30751, current rewards: -1817.98437, mean: -0.86160
[32m[0907 15-18-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30770, current rewards: -1867.98437, mean: -0.86481
[32m[0907 15-18-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30787, current rewards: -1917.98437, mean: -0.86787
[32m[0907 15-19-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30803, current rewards: -1967.98437, mean: -0.87079
[32m[0907 15-19-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30820, current rewards: -2017.98437, mean: -0.87359
[32m[0907 15-19-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30832, current rewards: -2067.98437, mean: -0.87626
[32m[0907 15-19-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30845, current rewards: -2117.98437, mean: -0.87883
[32m[0907 15-20-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30857, current rewards: -2167.98437, mean: -0.88129
[32m[0907 15-20-19 @Agent.py:117][0m Average action selection time: 0.3087
[32m[0907 15-20-19 @Agent.py:118][0m Rollout length: 2520
[32m[0907 15-20-19 @MBExp.py:227][0m Rewards obtained: [-2207.9843745710095], Lows: [12], Highs: [2213], Total time: 82478.40150900003
[32m[0907 15-23-30 @MBExp.py:144][0m ####################################################################
[32m[0907 15-23-30 @MBExp.py:145][0m Starting training iteration 102.
[32m[0907 15-23-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34609, current rewards: -10.00000, mean: -1.00000
[32m[0907 15-23-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.34893, current rewards: -66.87671, mean: -1.11461
[32m[0907 15-24-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33826, current rewards: -129.58791, mean: -1.17807
[32m[0907 15-24-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33429, current rewards: -195.58771, mean: -1.22242
[32m[0907 15-24-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33357, current rewards: -237.22947, mean: -1.12966
[32m[0907 15-24-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33014, current rewards: -287.98403, mean: -1.10763
[32m[0907 15-25-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32912, current rewards: -335.21468, mean: -1.08134
[32m[0907 15-25-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32761, current rewards: -412.06658, mean: -1.14463
[32m[0907 15-25-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32736, current rewards: -455.94468, mean: -1.11206
[32m[0907 15-26-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32523, current rewards: -555.94468, mean: -1.20858
[32m[0907 15-26-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32352, current rewards: -655.94468, mean: -1.28617
[32m[0907 15-26-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32130, current rewards: -755.94468, mean: -1.34990
[32m[0907 15-26-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31942, current rewards: -855.94468, mean: -1.40319
[32m[0907 15-27-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31787, current rewards: -955.94468, mean: -1.44840
[32m[0907 15-27-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31656, current rewards: -1055.94468, mean: -1.48725
[32m[0907 15-27-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31495, current rewards: -1155.94468, mean: -1.52098
[32m[0907 15-27-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31324, current rewards: -1255.94468, mean: -1.55055
[32m[0907 15-27-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31173, current rewards: -1355.94468, mean: -1.57668
[32m[0907 15-28-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31033, current rewards: -1455.94468, mean: -1.59994
[32m[0907 15-28-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30909, current rewards: -1555.94468, mean: -1.62078
[32m[0907 15-28-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30808, current rewards: -1655.94468, mean: -1.63955
[32m[0907 15-28-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30728, current rewards: -1755.94468, mean: -1.65655
[32m[0907 15-29-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30658, current rewards: -1855.94468, mean: -1.67202
[32m[0907 15-29-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30600, current rewards: -1955.94468, mean: -1.68616
[32m[0907 15-29-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30576, current rewards: -2055.94468, mean: -1.69913
[32m[0907 15-29-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30551, current rewards: -2155.94468, mean: -1.71107
[32m[0907 15-30-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30529, current rewards: -2255.94468, mean: -1.72210
[32m[0907 15-30-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30509, current rewards: -2355.94468, mean: -1.73231
[32m[0907 15-30-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30534, current rewards: -2455.94468, mean: -1.74180
[32m[0907 15-30-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30567, current rewards: -2555.94468, mean: -1.75065
[32m[0907 15-31-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30596, current rewards: -2655.94468, mean: -1.75890
[32m[0907 15-31-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30630, current rewards: -2755.94468, mean: -1.76663
[32m[0907 15-31-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30658, current rewards: -2855.94468, mean: -1.77388
[32m[0907 15-32-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30684, current rewards: -2955.94468, mean: -1.78069
[32m[0907 15-32-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30711, current rewards: -3055.94468, mean: -1.78710
[32m[0907 15-32-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30737, current rewards: -3155.94468, mean: -1.79315
[32m[0907 15-32-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30812, current rewards: -3255.94468, mean: -1.79886
[32m[0907 15-33-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30931, current rewards: -3355.94468, mean: -1.80427
[32m[0907 15-33-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31041, current rewards: -3455.94468, mean: -1.80940
[32m[0907 15-33-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31147, current rewards: -3555.94468, mean: -1.81426
[32m[0907 15-33-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31245, current rewards: -3655.94468, mean: -1.81888
[32m[0907 15-34-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31341, current rewards: -3755.94468, mean: -1.82327
[32m[0907 15-34-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31436, current rewards: -3855.94468, mean: -1.82746
[32m[0907 15-34-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31525, current rewards: -3955.94468, mean: -1.83146
[32m[0907 15-35-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31613, current rewards: -4055.94468, mean: -1.83527
[32m[0907 15-35-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31710, current rewards: -4155.94468, mean: -1.83891
[32m[0907 15-35-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31800, current rewards: -4255.94468, mean: -1.84240
[32m[0907 15-36-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31877, current rewards: -4355.94468, mean: -1.84574
[32m[0907 15-36-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31954, current rewards: -4455.94468, mean: -1.84894
[32m[0907 15-36-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32018, current rewards: -4555.94468, mean: -1.85201
[32m[0907 15-36-53 @Agent.py:117][0m Average action selection time: 0.3207
[32m[0907 15-36-53 @Agent.py:118][0m Rollout length: 2520
[32m[0907 15-36-53 @MBExp.py:227][0m Rewards obtained: [-4635.944679087204], Lows: [2202], Highs: [243], Total time: 83280.93186500004
[32m[0907 15-40-28 @MBExp.py:144][0m ####################################################################
[32m[0907 15-40-28 @MBExp.py:145][0m Starting training iteration 103.
[32m[0907 15-40-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.58867, current rewards: 0.63468, mean: 0.06347
[32m[0907 15-40-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.43607, current rewards: -78.34137, mean: -1.30569
[32m[0907 15-41-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.39843, current rewards: -146.07721, mean: -1.32797
[32m[0907 15-41-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.38440, current rewards: -139.46898, mean: -0.87168
[32m[0907 15-41-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37686, current rewards: -132.86074, mean: -0.63267
[32m[0907 15-42-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37212, current rewards: -127.38467, mean: -0.48994
[32m[0907 15-42-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36890, current rewards: -177.38467, mean: -0.57221
[32m[0907 15-42-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36627, current rewards: -227.38467, mean: -0.63162
[32m[0907 15-42-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36348, current rewards: -277.38467, mean: -0.67655
[32m[0907 15-43-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36137, current rewards: -327.38467, mean: -0.71171
[32m[0907 15-43-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35967, current rewards: -377.38467, mean: -0.73997
[32m[0907 15-43-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35856, current rewards: -427.38467, mean: -0.76319
[32m[0907 15-44-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35789, current rewards: -477.38467, mean: -0.78260
[32m[0907 15-44-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35739, current rewards: -527.38467, mean: -0.79907
[32m[0907 15-44-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35639, current rewards: -577.38467, mean: -0.81322
[32m[0907 15-44-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35489, current rewards: -627.38467, mean: -0.82551
[32m[0907 15-45-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35306, current rewards: -677.38467, mean: -0.83628
[32m[0907 15-45-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35149, current rewards: -727.38467, mean: -0.84580
[32m[0907 15-45-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35006, current rewards: -777.38467, mean: -0.85427
[32m[0907 15-46-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34882, current rewards: -827.38467, mean: -0.86186
[32m[0907 15-46-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34781, current rewards: -877.38467, mean: -0.86870
[32m[0907 15-46-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34735, current rewards: -927.38467, mean: -0.87489
[32m[0907 15-46-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34692, current rewards: -977.38467, mean: -0.88053
[32m[0907 15-47-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34649, current rewards: -1027.38467, mean: -0.88568
[32m[0907 15-47-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34614, current rewards: -1077.38467, mean: -0.89040
[32m[0907 15-47-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34583, current rewards: -1127.38467, mean: -0.89475
[32m[0907 15-48-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34551, current rewards: -1177.38467, mean: -0.89877
[32m[0907 15-48-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34541, current rewards: -1227.38467, mean: -0.90249
[32m[0907 15-48-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34550, current rewards: -1277.38467, mean: -0.90595
[32m[0907 15-48-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34616, current rewards: -1327.38467, mean: -0.90917
[32m[0907 15-49-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34681, current rewards: -1377.38467, mean: -0.91218
[32m[0907 15-49-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34740, current rewards: -1427.38467, mean: -0.91499
[32m[0907 15-49-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34801, current rewards: -1477.38467, mean: -0.91763
[32m[0907 15-50-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34850, current rewards: -1527.38467, mean: -0.92011
[32m[0907 15-50-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34905, current rewards: -1577.38467, mean: -0.92245
[32m[0907 15-50-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34953, current rewards: -1627.38467, mean: -0.92465
[32m[0907 15-51-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34996, current rewards: -1677.38467, mean: -0.92673
[32m[0907 15-51-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35036, current rewards: -1727.38467, mean: -0.92870
[32m[0907 15-51-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35075, current rewards: -1777.38467, mean: -0.93057
[32m[0907 15-51-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35107, current rewards: -1827.38467, mean: -0.93234
[32m[0907 15-52-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35141, current rewards: -1877.38467, mean: -0.93402
[32m[0907 15-52-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35171, current rewards: -1927.38467, mean: -0.93562
[32m[0907 15-52-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35202, current rewards: -1977.38467, mean: -0.93715
[32m[0907 15-53-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35231, current rewards: -2027.38467, mean: -0.93860
[32m[0907 15-53-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35259, current rewards: -2077.38467, mean: -0.93999
[32m[0907 15-53-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35283, current rewards: -2127.38467, mean: -0.94132
[32m[0907 15-54-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35303, current rewards: -2177.38467, mean: -0.94259
[32m[0907 15-54-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35326, current rewards: -2227.38467, mean: -0.94381
[32m[0907 15-54-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35349, current rewards: -2277.38467, mean: -0.94497
[32m[0907 15-54-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35372, current rewards: -2327.38467, mean: -0.94609
[32m[0907 15-55-14 @Agent.py:117][0m Average action selection time: 0.3539
[32m[0907 15-55-14 @Agent.py:118][0m Rollout length: 2520
[32m[0907 15-55-14 @MBExp.py:227][0m Rewards obtained: [-2367.384672261698], Lows: [76], Highs: [2241], Total time: 84166.53565100004
[32m[0907 15-59-05 @MBExp.py:144][0m ####################################################################
[32m[0907 15-59-05 @MBExp.py:145][0m Starting training iteration 104.
[32m[0907 15-59-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.38780, current rewards: 1.36301, mean: 0.13630
[32m[0907 15-59-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36816, current rewards: 6.00759, mean: 0.10013
[32m[0907 15-59-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36638, current rewards: 12.77163, mean: 0.11611
[32m[0907 16-00-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36567, current rewards: 19.53568, mean: 0.12210
[32m[0907 16-00-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36507, current rewards: 26.29971, mean: 0.12524
[32m[0907 16-00-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36485, current rewards: 33.06375, mean: 0.12717
[32m[0907 16-00-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36474, current rewards: 39.82779, mean: 0.12848
[32m[0907 16-01-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36450, current rewards: 46.59183, mean: 0.12942
[32m[0907 16-01-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36344, current rewards: 2.26823, mean: 0.00553
[32m[0907 16-01-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36258, current rewards: -47.73177, mean: -0.10376
[32m[0907 16-02-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36187, current rewards: -97.73177, mean: -0.19163
[32m[0907 16-02-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36127, current rewards: -147.73177, mean: -0.26381
[32m[0907 16-02-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36085, current rewards: -197.73177, mean: -0.32415
[32m[0907 16-03-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36043, current rewards: -247.73177, mean: -0.37535
[32m[0907 16-03-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35998, current rewards: -297.73177, mean: -0.41934
[32m[0907 16-03-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35911, current rewards: -347.73177, mean: -0.45754
[32m[0907 16-03-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35725, current rewards: -397.73177, mean: -0.49103
[32m[0907 16-04-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35557, current rewards: -447.73177, mean: -0.52062
[32m[0907 16-04-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35400, current rewards: -497.73177, mean: -0.54696
[32m[0907 16-04-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35261, current rewards: -547.73177, mean: -0.57055
[32m[0907 16-05-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35136, current rewards: -597.73177, mean: -0.59181
[32m[0907 16-05-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35054, current rewards: -647.73177, mean: -0.61107
[32m[0907 16-05-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35001, current rewards: -697.73177, mean: -0.62859
[32m[0907 16-05-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34954, current rewards: -747.73177, mean: -0.64460
[32m[0907 16-06-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34908, current rewards: -797.73177, mean: -0.65928
[32m[0907 16-06-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34868, current rewards: -847.73177, mean: -0.67280
[32m[0907 16-06-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34830, current rewards: -897.73177, mean: -0.68529
[32m[0907 16-06-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34794, current rewards: -947.73177, mean: -0.69686
[32m[0907 16-07-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34779, current rewards: -997.73177, mean: -0.70761
[32m[0907 16-07-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34795, current rewards: -1047.73177, mean: -0.71762
[32m[0907 16-07-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34852, current rewards: -1097.73177, mean: -0.72697
[32m[0907 16-08-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34907, current rewards: -1147.73177, mean: -0.73573
[32m[0907 16-08-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34959, current rewards: -1197.73177, mean: -0.74393
[32m[0907 16-08-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35006, current rewards: -1247.73177, mean: -0.75165
[32m[0907 16-09-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35053, current rewards: -1297.73177, mean: -0.75891
[32m[0907 16-09-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35099, current rewards: -1347.73177, mean: -0.76576
[32m[0907 16-09-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35138, current rewards: -1397.73177, mean: -0.77223
[32m[0907 16-10-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35174, current rewards: -1447.73177, mean: -0.77835
[32m[0907 16-10-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35207, current rewards: -1497.73177, mean: -0.78415
[32m[0907 16-10-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35239, current rewards: -1547.73177, mean: -0.78966
[32m[0907 16-10-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35269, current rewards: -1597.73177, mean: -0.79489
[32m[0907 16-11-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35300, current rewards: -1647.73177, mean: -0.79987
[32m[0907 16-11-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35326, current rewards: -1697.73177, mean: -0.80461
[32m[0907 16-11-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35348, current rewards: -1747.73177, mean: -0.80914
[32m[0907 16-12-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35373, current rewards: -1797.73177, mean: -0.81345
[32m[0907 16-12-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35394, current rewards: -1847.73177, mean: -0.81758
[32m[0907 16-12-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35416, current rewards: -1897.73177, mean: -0.82153
[32m[0907 16-13-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35436, current rewards: -1947.73177, mean: -0.82531
[32m[0907 16-13-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35456, current rewards: -1997.73177, mean: -0.82893
[32m[0907 16-13-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35477, current rewards: -2047.73177, mean: -0.83241
[32m[0907 16-13-53 @Agent.py:117][0m Average action selection time: 0.3549
[32m[0907 16-13-53 @Agent.py:118][0m Rollout length: 2520
[32m[0907 16-13-54 @MBExp.py:227][0m Rewards obtained: [-2087.731767645152], Lows: [1], Highs: [2135], Total time: 85054.69527600004
[32m[0907 16-17-47 @MBExp.py:144][0m ####################################################################
[32m[0907 16-17-47 @MBExp.py:145][0m Starting training iteration 105.
[32m[0907 16-17-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36370, current rewards: -10.00000, mean: -1.00000
[32m[0907 16-18-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.40132, current rewards: -99.00000, mean: -1.65000
[32m[0907 16-18-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.41720, current rewards: -158.94914, mean: -1.44499
[32m[0907 16-18-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.42318, current rewards: -236.94914, mean: -1.48093
[32m[0907 16-19-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.44307, current rewards: -310.80505, mean: -1.48002
[32m[0907 16-19-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.43329, current rewards: -362.65212, mean: -1.39482
[32m[0907 16-19-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.42248, current rewards: -451.65212, mean: -1.45694
[32m[0907 16-20-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.42384, current rewards: -528.65212, mean: -1.46848
[32m[0907 16-20-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.41632, current rewards: -594.37240, mean: -1.44969
[32m[0907 16-21-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.42161, current rewards: -675.17813, mean: -1.46778
[32m[0907 16-21-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.41642, current rewards: -736.08668, mean: -1.44331
[32m[0907 16-21-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.41345, current rewards: -798.08668, mean: -1.42515
[32m[0907 16-21-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.41081, current rewards: -891.84591, mean: -1.46204
[32m[0907 16-22-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.40686, current rewards: -938.60566, mean: -1.42213
[32m[0907 16-22-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.40338, current rewards: -988.54224, mean: -1.39231
[32m[0907 16-22-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.39923, current rewards: -1036.22664, mean: -1.36346
[32m[0907 16-23-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.39511, current rewards: -1083.61375, mean: -1.33779
[32m[0907 16-23-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.39174, current rewards: -1131.33932, mean: -1.31551
[32m[0907 16-23-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.38855, current rewards: -1181.33932, mean: -1.29818
[32m[0907 16-23-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.38565, current rewards: -1231.33932, mean: -1.28265
[32m[0907 16-24-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.38344, current rewards: -1281.33932, mean: -1.26865
[32m[0907 16-24-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.38158, current rewards: -1331.33932, mean: -1.25598
[32m[0907 16-24-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37990, current rewards: -1381.33932, mean: -1.24445
[32m[0907 16-25-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37837, current rewards: -1431.33932, mean: -1.23391
[32m[0907 16-25-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37692, current rewards: -1481.33932, mean: -1.22425
[32m[0907 16-25-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37563, current rewards: -1531.33932, mean: -1.21535
[32m[0907 16-25-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37441, current rewards: -1581.33932, mean: -1.20713
[32m[0907 16-26-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37349, current rewards: -1631.33932, mean: -1.19951
[32m[0907 16-26-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.37297, current rewards: -1681.33932, mean: -1.19244
[32m[0907 16-26-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.37298, current rewards: -1731.33932, mean: -1.18585
[32m[0907 16-27-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.37299, current rewards: -1781.33932, mean: -1.17969
[32m[0907 16-27-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.37296, current rewards: -1831.33932, mean: -1.17394
[32m[0907 16-27-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.37296, current rewards: -1881.33932, mean: -1.16853
[32m[0907 16-28-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.37291, current rewards: -1931.33932, mean: -1.16346
[32m[0907 16-28-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.37285, current rewards: -1981.33932, mean: -1.15868
[32m[0907 16-28-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.37281, current rewards: -2031.33932, mean: -1.15417
[32m[0907 16-29-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.37275, current rewards: -2081.33932, mean: -1.14991
[32m[0907 16-29-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.37270, current rewards: -2131.33932, mean: -1.14588
[32m[0907 16-29-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.37266, current rewards: -2181.33932, mean: -1.14206
[32m[0907 16-29-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.37259, current rewards: -2231.33932, mean: -1.13844
[32m[0907 16-30-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.37254, current rewards: -2281.33932, mean: -1.13499
[32m[0907 16-30-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.37247, current rewards: -2331.33932, mean: -1.13172
[32m[0907 16-30-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.37243, current rewards: -2381.33932, mean: -1.12860
[32m[0907 16-31-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.37242, current rewards: -2431.33932, mean: -1.12562
[32m[0907 16-31-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.37238, current rewards: -2481.33932, mean: -1.12278
[32m[0907 16-31-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.37233, current rewards: -2531.33932, mean: -1.12006
[32m[0907 16-32-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.37230, current rewards: -2581.33932, mean: -1.11746
[32m[0907 16-32-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.37224, current rewards: -2631.33932, mean: -1.11497
[32m[0907 16-32-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.37220, current rewards: -2681.33932, mean: -1.11259
[32m[0907 16-33-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.37215, current rewards: -2731.33932, mean: -1.11030
[32m[0907 16-33-18 @Agent.py:117][0m Average action selection time: 0.3721
[32m[0907 16-33-18 @Agent.py:118][0m Rollout length: 2520
[32m[0907 16-33-18 @MBExp.py:227][0m Rewards obtained: [-2771.3393166289225], Lows: [298], Highs: [2178], Total time: 85985.88477300004
[32m[0907 16-37-20 @MBExp.py:144][0m ####################################################################
[32m[0907 16-37-20 @MBExp.py:145][0m Starting training iteration 106.
[32m[0907 16-37-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.38378, current rewards: -10.00000, mean: -1.00000
[32m[0907 16-37-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.38948, current rewards: -65.46028, mean: -1.09100
[32m[0907 16-38-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.38314, current rewards: -122.15181, mean: -1.11047
[32m[0907 16-38-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37902, current rewards: -179.61232, mean: -1.12258
[32m[0907 16-38-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37706, current rewards: -229.61232, mean: -1.09339
[32m[0907 16-38-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37594, current rewards: -279.61232, mean: -1.07543
[32m[0907 16-39-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37463, current rewards: -329.61232, mean: -1.06327
[32m[0907 16-39-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37274, current rewards: -379.61232, mean: -1.05448
[32m[0907 16-39-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37140, current rewards: -429.61232, mean: -1.04783
[32m[0907 16-40-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37043, current rewards: -479.61232, mean: -1.04264
[32m[0907 16-40-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36955, current rewards: -529.61232, mean: -1.03846
[32m[0907 16-40-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36890, current rewards: -579.61232, mean: -1.03502
[32m[0907 16-41-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36834, current rewards: -629.61232, mean: -1.03215
[32m[0907 16-41-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36788, current rewards: -679.61232, mean: -1.02972
[32m[0907 16-41-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36726, current rewards: -729.61232, mean: -1.02762
[32m[0907 16-41-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36561, current rewards: -787.45342, mean: -1.03612
[32m[0907 16-42-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36510, current rewards: -854.20531, mean: -1.05457
[32m[0907 16-42-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.36329, current rewards: -954.20531, mean: -1.10954
[32m[0907 16-42-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36162, current rewards: -1054.20531, mean: -1.15847
[32m[0907 16-43-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36009, current rewards: -1154.20531, mean: -1.20230
[32m[0907 16-43-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35908, current rewards: -1254.20531, mean: -1.24179
[32m[0907 16-43-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35839, current rewards: -1354.20531, mean: -1.27755
[32m[0907 16-43-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35777, current rewards: -1454.20531, mean: -1.31009
[32m[0907 16-44-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35714, current rewards: -1554.20531, mean: -1.33983
[32m[0907 16-44-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35658, current rewards: -1654.20531, mean: -1.36711
[32m[0907 16-44-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35606, current rewards: -1754.20531, mean: -1.39223
[32m[0907 16-45-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35556, current rewards: -1854.20531, mean: -1.41542
[32m[0907 16-45-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35512, current rewards: -1954.20531, mean: -1.43692
[32m[0907 16-45-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35479, current rewards: -2054.20531, mean: -1.45688
[32m[0907 16-45-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35519, current rewards: -2154.20531, mean: -1.47548
[32m[0907 16-46-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35572, current rewards: -2254.20531, mean: -1.49285
[32m[0907 16-46-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35622, current rewards: -2354.20531, mean: -1.50911
[32m[0907 16-46-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35669, current rewards: -2454.20531, mean: -1.52435
[32m[0907 16-47-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35713, current rewards: -2554.20531, mean: -1.53868
[32m[0907 16-47-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35750, current rewards: -2654.20531, mean: -1.55217
[32m[0907 16-47-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35781, current rewards: -2754.20531, mean: -1.56489
[32m[0907 16-48-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35815, current rewards: -2854.20531, mean: -1.57691
[32m[0907 16-48-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35847, current rewards: -2954.20531, mean: -1.58828
[32m[0907 16-48-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35880, current rewards: -3054.20531, mean: -1.59906
[32m[0907 16-49-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35908, current rewards: -3154.20531, mean: -1.60929
[32m[0907 16-49-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35936, current rewards: -3254.20531, mean: -1.61901
[32m[0907 16-49-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35963, current rewards: -3354.20531, mean: -1.62826
[32m[0907 16-50-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35989, current rewards: -3454.20531, mean: -1.63706
[32m[0907 16-50-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36013, current rewards: -3554.20531, mean: -1.64547
[32m[0907 16-50-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36034, current rewards: -3654.20531, mean: -1.65349
[32m[0907 16-50-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36055, current rewards: -3754.20531, mean: -1.66115
[32m[0907 16-51-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36074, current rewards: -3854.20531, mean: -1.66849
[32m[0907 16-51-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36092, current rewards: -3954.20531, mean: -1.67551
[32m[0907 16-51-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36111, current rewards: -4054.20531, mean: -1.68224
[32m[0907 16-52-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36128, current rewards: -4154.20531, mean: -1.68870
[32m[0907 16-52-24 @Agent.py:117][0m Average action selection time: 0.3614
[32m[0907 16-52-24 @Agent.py:118][0m Rollout length: 2520
[32m[0907 16-52-24 @MBExp.py:227][0m Rewards obtained: [-4234.20530953587], Lows: [1754], Highs: [728], Total time: 86890.29940600003
[32m[0907 16-56-28 @MBExp.py:144][0m ####################################################################
[32m[0907 16-56-28 @MBExp.py:145][0m Starting training iteration 107.
[32m[0907 16-56-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.39451, current rewards: -10.00000, mean: -1.00000
[32m[0907 16-56-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37430, current rewards: -68.80455, mean: -1.14674
[32m[0907 16-57-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.44067, current rewards: -125.52851, mean: -1.14117
[32m[0907 16-57-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.49223, current rewards: -163.59150, mean: -1.02245
[32m[0907 16-58-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.46796, current rewards: -204.53040, mean: -0.97395
[32m[0907 16-58-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.44895, current rewards: -263.38926, mean: -1.01304
[32m[0907 16-58-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.44295, current rewards: -323.13022, mean: -1.04236
[32m[0907 16-59-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.44255, current rewards: -380.39945, mean: -1.05667
[32m[0907 16-59-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.43272, current rewards: -426.01724, mean: -1.03907
[32m[0907 16-59-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.42523, current rewards: -480.78454, mean: -1.04518
[32m[0907 17-00-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.42421, current rewards: -541.57410, mean: -1.06191
[32m[0907 17-00-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.42032, current rewards: -591.57410, mean: -1.05638
[32m[0907 17-00-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.42195, current rewards: -641.43076, mean: -1.05153
[32m[0907 17-01-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.41919, current rewards: -707.30492, mean: -1.07167
[32m[0907 17-01-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.42031, current rewards: -753.99785, mean: -1.06197
[32m[0907 17-01-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.42035, current rewards: -811.52050, mean: -1.06779
[32m[0907 17-02-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.41892, current rewards: -859.08290, mean: -1.06060
[32m[0907 17-02-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.42095, current rewards: -914.93207, mean: -1.06387
[32m[0907 17-02-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.42176, current rewards: -966.29308, mean: -1.06186
[32m[0907 17-03-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.42508, current rewards: -1016.18817, mean: -1.05853
[32m[0907 17-03-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.42354, current rewards: -1075.57555, mean: -1.06493
[32m[0907 17-03-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.42182, current rewards: -1154.90666, mean: -1.08953
[32m[0907 17-04-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.42247, current rewards: -1216.44355, mean: -1.09590
[32m[0907 17-04-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.42010, current rewards: -1311.37763, mean: -1.13050
[32m[0907 17-05-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.42606, current rewards: -1367.70683, mean: -1.13034
[32m[0907 17-05-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.42626, current rewards: -1456.70683, mean: -1.15612
[32m[0907 17-05-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.42671, current rewards: -1545.49572, mean: -1.17977
[32m[0907 17-06-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.42637, current rewards: -1617.49572, mean: -1.18934
[32m[0907 17-06-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.42781, current rewards: -1661.59277, mean: -1.17843
[32m[0907 17-06-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.42755, current rewards: -1726.94833, mean: -1.18284
[32m[0907 17-07-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.42863, current rewards: -1796.19212, mean: -1.18953
[32m[0907 17-07-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.42943, current rewards: -1862.99961, mean: -1.19423
[32m[0907 17-07-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.42900, current rewards: -1920.80660, mean: -1.19305
[32m[0907 17-08-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.42723, current rewards: -1970.80660, mean: -1.18723
[32m[0907 17-08-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.42558, current rewards: -2020.80660, mean: -1.18176
[32m[0907 17-08-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.42405, current rewards: -2070.80660, mean: -1.17659
[32m[0907 17-09-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.42258, current rewards: -2120.80660, mean: -1.17172
[32m[0907 17-09-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.42116, current rewards: -2170.80660, mean: -1.16710
[32m[0907 17-09-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.41988, current rewards: -2220.80660, mean: -1.16273
[32m[0907 17-10-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.41866, current rewards: -2270.80660, mean: -1.15857
[32m[0907 17-10-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.41744, current rewards: -2320.80660, mean: -1.15463
[32m[0907 17-10-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.41630, current rewards: -2370.80660, mean: -1.15088
[32m[0907 17-11-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.41520, current rewards: -2420.80660, mean: -1.14730
[32m[0907 17-11-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.41416, current rewards: -2423.07292, mean: -1.12179
[32m[0907 17-11-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.41314, current rewards: -2420.00858, mean: -1.09503
[32m[0907 17-12-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.41219, current rewards: -2416.84885, mean: -1.06940
[32m[0907 17-12-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.41124, current rewards: -2413.68911, mean: -1.04489
[32m[0907 17-12-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.41036, current rewards: -2410.52938, mean: -1.02141
[32m[0907 17-12-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.40952, current rewards: -2449.89743, mean: -1.01655
[32m[0907 17-13-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.40869, current rewards: -2499.89743, mean: -1.01622
[32m[0907 17-13-28 @Agent.py:117][0m Average action selection time: 0.4081
[32m[0907 17-13-28 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-13-29 @MBExp.py:227][0m Rewards obtained: [-2539.8974323839566], Lows: [475], Highs: [1627], Total time: 87911.31552900003
[32m[0907 17-17-34 @MBExp.py:144][0m ####################################################################
[32m[0907 17-17-34 @MBExp.py:145][0m Starting training iteration 108.
[32m[0907 17-17-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49099, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-17-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.38355, current rewards: -84.87652, mean: -1.41461
[32m[0907 17-18-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37517, current rewards: -180.63996, mean: -1.64218
[32m[0907 17-18-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37094, current rewards: -269.68054, mean: -1.68550
[32m[0907 17-18-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36850, current rewards: -362.07608, mean: -1.72417
[32m[0907 17-19-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36725, current rewards: -453.05745, mean: -1.74253
[32m[0907 17-19-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36661, current rewards: -538.16046, mean: -1.73600
[32m[0907 17-19-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36628, current rewards: -632.93393, mean: -1.75815
[32m[0907 17-20-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36595, current rewards: -717.64323, mean: -1.75035
[32m[0907 17-20-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36418, current rewards: -805.22678, mean: -1.75049
[32m[0907 17-20-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36132, current rewards: -899.98769, mean: -1.76468
[32m[0907 17-20-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35887, current rewards: -982.72398, mean: -1.75486
[32m[0907 17-21-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35666, current rewards: -1068.02274, mean: -1.75086
[32m[0907 17-21-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35521, current rewards: -1157.83354, mean: -1.75429
[32m[0907 17-21-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35385, current rewards: -1246.10531, mean: -1.75508
[32m[0907 17-22-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35358, current rewards: -1341.96557, mean: -1.76574
[32m[0907 17-22-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35296, current rewards: -1432.15603, mean: -1.76809
[32m[0907 17-22-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35241, current rewards: -1532.15603, mean: -1.78158
[32m[0907 17-22-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35188, current rewards: -1632.15603, mean: -1.79358
[32m[0907 17-23-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35162, current rewards: -1732.15603, mean: -1.80433
[32m[0907 17-23-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35534, current rewards: -1778.62669, mean: -1.76102
[32m[0907 17-23-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35484, current rewards: -1878.62669, mean: -1.77229
[32m[0907 17-24-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35528, current rewards: -1971.51547, mean: -1.77614
[32m[0907 17-24-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35543, current rewards: -2064.04189, mean: -1.77935
[32m[0907 17-24-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35623, current rewards: -2153.73407, mean: -1.77995
[32m[0907 17-25-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35690, current rewards: -2243.43262, mean: -1.78050
[32m[0907 17-25-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35760, current rewards: -2333.13802, mean: -1.78102
[32m[0907 17-25-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35808, current rewards: -2422.81572, mean: -1.78148
[32m[0907 17-26-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35855, current rewards: -2512.48954, mean: -1.78191
[32m[0907 17-26-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35927, current rewards: -2607.96375, mean: -1.78628
[32m[0907 17-26-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35974, current rewards: -2694.36790, mean: -1.78435
[32m[0907 17-26-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36042, current rewards: -2783.02808, mean: -1.78399
[32m[0907 17-27-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36086, current rewards: -2877.91667, mean: -1.78753
[32m[0907 17-27-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36122, current rewards: -2975.91667, mean: -1.79272
[32m[0907 17-27-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36162, current rewards: -3072.79949, mean: -1.79696
[32m[0907 17-28-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36196, current rewards: -3168.79949, mean: -1.80045
[32m[0907 17-28-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36228, current rewards: -3264.57713, mean: -1.80363
[32m[0907 17-28-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36250, current rewards: -3360.30644, mean: -1.80662
[32m[0907 17-29-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36276, current rewards: -3451.72867, mean: -1.80719
[32m[0907 17-29-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36293, current rewards: -3546.53259, mean: -1.80946
[32m[0907 17-29-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36317, current rewards: -3633.68907, mean: -1.80781
[32m[0907 17-30-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36338, current rewards: -3727.38801, mean: -1.80941
[32m[0907 17-30-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36355, current rewards: -3817.12457, mean: -1.80906
[32m[0907 17-30-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36376, current rewards: -3913.03206, mean: -1.81159
[32m[0907 17-30-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36405, current rewards: -4000.75789, mean: -1.81030
[32m[0907 17-31-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36416, current rewards: -4091.32585, mean: -1.81032
[32m[0907 17-31-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36428, current rewards: -4182.20006, mean: -1.81048
[32m[0907 17-31-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36440, current rewards: -4282.20006, mean: -1.81449
[32m[0907 17-32-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36454, current rewards: -4382.20006, mean: -1.81834
[32m[0907 17-32-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36470, current rewards: -4482.20006, mean: -1.82203
[32m[0907 17-32-47 @Agent.py:117][0m Average action selection time: 0.3648
[32m[0907 17-32-47 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-32-47 @MBExp.py:227][0m Rewards obtained: [-4562.200061490705], Lows: [2223], Highs: [140], Total time: 88824.15052600003
[32m[0907 17-36-55 @MBExp.py:144][0m ####################################################################
[32m[0907 17-36-55 @MBExp.py:145][0m Starting training iteration 109.
[32m[0907 17-37-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.51629, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-37-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.43244, current rewards: -59.43470, mean: -0.99058
[32m[0907 17-37-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.40157, current rewards: -134.07904, mean: -1.21890
[32m[0907 17-37-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.38977, current rewards: -186.99675, mean: -1.16873
[32m[0907 17-38-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.38665, current rewards: -242.76150, mean: -1.15601
[32m[0907 17-38-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.38178, current rewards: -320.35135, mean: -1.23212
[32m[0907 17-38-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37847, current rewards: -376.27106, mean: -1.21378
[32m[0907 17-39-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.38015, current rewards: -432.64108, mean: -1.20178
[32m[0907 17-39-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37788, current rewards: -505.76804, mean: -1.23358
[32m[0907 17-39-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37357, current rewards: -555.76804, mean: -1.20819
[32m[0907 17-40-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36963, current rewards: -605.76804, mean: -1.18778
[32m[0907 17-40-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36638, current rewards: -655.76804, mean: -1.17101
[32m[0907 17-40-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36361, current rewards: -705.76804, mean: -1.15700
[32m[0907 17-40-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36136, current rewards: -755.76804, mean: -1.14510
[32m[0907 17-41-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35935, current rewards: -805.76804, mean: -1.13488
[32m[0907 17-41-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35817, current rewards: -855.76804, mean: -1.12601
[32m[0907 17-41-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35729, current rewards: -905.76804, mean: -1.11823
[32m[0907 17-42-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35649, current rewards: -955.76804, mean: -1.11136
[32m[0907 17-42-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35570, current rewards: -1005.76804, mean: -1.10524
[32m[0907 17-42-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35511, current rewards: -1055.76804, mean: -1.09976
[32m[0907 17-42-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35450, current rewards: -1105.76804, mean: -1.09482
[32m[0907 17-43-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35398, current rewards: -1155.76804, mean: -1.09035
[32m[0907 17-43-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35353, current rewards: -1205.76804, mean: -1.08628
[32m[0907 17-43-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35365, current rewards: -1255.76804, mean: -1.08256
[32m[0907 17-44-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35441, current rewards: -1305.76804, mean: -1.07915
[32m[0907 17-44-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35508, current rewards: -1355.76804, mean: -1.07601
[32m[0907 17-44-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35574, current rewards: -1405.76804, mean: -1.07311
[32m[0907 17-45-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35633, current rewards: -1455.76804, mean: -1.07042
[32m[0907 17-45-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35690, current rewards: -1505.76804, mean: -1.06792
[32m[0907 17-45-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35739, current rewards: -1555.76804, mean: -1.06559
[32m[0907 17-45-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35782, current rewards: -1605.76804, mean: -1.06342
[32m[0907 17-46-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35828, current rewards: -1655.76804, mean: -1.06139
[32m[0907 17-46-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35869, current rewards: -1705.76804, mean: -1.05948
[32m[0907 17-46-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35904, current rewards: -1755.76804, mean: -1.05769
[32m[0907 17-47-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35939, current rewards: -1805.76804, mean: -1.05600
[32m[0907 17-47-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35974, current rewards: -1855.76804, mean: -1.05441
[32m[0907 17-47-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36005, current rewards: -1905.76804, mean: -1.05291
[32m[0907 17-48-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36036, current rewards: -1955.76804, mean: -1.05149
[32m[0907 17-48-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36066, current rewards: -2005.76804, mean: -1.05014
[32m[0907 17-48-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36090, current rewards: -2055.76804, mean: -1.04886
[32m[0907 17-49-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36117, current rewards: -2105.76804, mean: -1.04765
[32m[0907 17-49-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36138, current rewards: -2155.76804, mean: -1.04649
[32m[0907 17-49-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36161, current rewards: -2205.76804, mean: -1.04539
[32m[0907 17-49-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36184, current rewards: -2255.76804, mean: -1.04434
[32m[0907 17-50-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36204, current rewards: -2305.76804, mean: -1.04333
[32m[0907 17-50-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36222, current rewards: -2355.76804, mean: -1.04238
[32m[0907 17-50-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36238, current rewards: -2405.76804, mean: -1.04146
[32m[0907 17-51-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36255, current rewards: -2434.65404, mean: -1.03163
[32m[0907 17-51-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36270, current rewards: -2429.09090, mean: -1.00792
[32m[0907 17-51-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36284, current rewards: -2423.52775, mean: -0.98517
[32m[0907 17-52-03 @Agent.py:117][0m Average action selection time: 0.3630
[32m[0907 17-52-03 @Agent.py:118][0m Rollout length: 2520
[32m[0907 17-52-03 @MBExp.py:227][0m Rewards obtained: [-2419.0772310962416], Lows: [123], Highs: [2195], Total time: 89732.44373700002
[32m[0907 17-56-14 @MBExp.py:144][0m ####################################################################
[32m[0907 17-56-14 @MBExp.py:145][0m Starting training iteration 110.
[32m[0907 17-56-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36942, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-56-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36540, current rewards: -97.00000, mean: -1.61667
[32m[0907 17-56-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36392, current rewards: -197.00000, mean: -1.79091
[32m[0907 17-57-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36332, current rewards: -297.00000, mean: -1.85625
[32m[0907 17-57-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36301, current rewards: -397.00000, mean: -1.89048
[32m[0907 17-57-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36278, current rewards: -497.00000, mean: -1.91154
[32m[0907 17-58-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36249, current rewards: -597.00000, mean: -1.92581
[32m[0907 17-58-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36247, current rewards: -697.00000, mean: -1.93611
[32m[0907 17-58-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36239, current rewards: -797.00000, mean: -1.94390
[32m[0907 17-59-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36178, current rewards: -897.00000, mean: -1.95000
[32m[0907 17-59-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35888, current rewards: -997.00000, mean: -1.95490
[32m[0907 17-59-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35655, current rewards: -1097.00000, mean: -1.95893
[32m[0907 17-59-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35454, current rewards: -1197.00000, mean: -1.96230
[32m[0907 18-00-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35285, current rewards: -1297.00000, mean: -1.96515
[32m[0907 18-00-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35147, current rewards: -1397.00000, mean: -1.96761
[32m[0907 18-00-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35053, current rewards: -1497.00000, mean: -1.96974
[32m[0907 18-00-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35012, current rewards: -1597.00000, mean: -1.97160
[32m[0907 18-01-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34972, current rewards: -1697.00000, mean: -1.97326
[32m[0907 18-01-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34936, current rewards: -1797.00000, mean: -1.97473
[32m[0907 18-01-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34906, current rewards: -1897.00000, mean: -1.97604
[32m[0907 18-02-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34881, current rewards: -1997.00000, mean: -1.97723
[32m[0907 18-02-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34851, current rewards: -2097.00000, mean: -1.97830
[32m[0907 18-02-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34831, current rewards: -2197.00000, mean: -1.97928
[32m[0907 18-02-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34809, current rewards: -2297.00000, mean: -1.98017
[32m[0907 18-03-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34852, current rewards: -2397.00000, mean: -1.98099
[32m[0907 18-03-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34941, current rewards: -2497.00000, mean: -1.98175
[32m[0907 18-03-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35029, current rewards: -2597.00000, mean: -1.98244
[32m[0907 18-04-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35104, current rewards: -2697.00000, mean: -1.98309
[32m[0907 18-04-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35176, current rewards: -2797.00000, mean: -1.98369
[32m[0907 18-04-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35242, current rewards: -2897.00000, mean: -1.98425
[32m[0907 18-05-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35305, current rewards: -2997.00000, mean: -1.98477
[32m[0907 18-05-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35364, current rewards: -3097.00000, mean: -1.98526
[32m[0907 18-05-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35421, current rewards: -3197.00000, mean: -1.98571
[32m[0907 18-06-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35470, current rewards: -3297.00000, mean: -1.98614
[32m[0907 18-06-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35518, current rewards: -3397.00000, mean: -1.98655
[32m[0907 18-06-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35560, current rewards: -3497.00000, mean: -1.98693
[32m[0907 18-06-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35602, current rewards: -3597.00000, mean: -1.98729
[32m[0907 18-07-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35638, current rewards: -3697.00000, mean: -1.98763
[32m[0907 18-07-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35676, current rewards: -3797.00000, mean: -1.98796
[32m[0907 18-07-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35713, current rewards: -3897.00000, mean: -1.98827
[32m[0907 18-08-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35749, current rewards: -3997.00000, mean: -1.98856
[32m[0907 18-08-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35778, current rewards: -4097.00000, mean: -1.98883
[32m[0907 18-08-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35809, current rewards: -4197.00000, mean: -1.98910
[32m[0907 18-09-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35839, current rewards: -4297.00000, mean: -1.98935
[32m[0907 18-09-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35868, current rewards: -4397.00000, mean: -1.98959
[32m[0907 18-09-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35893, current rewards: -4497.00000, mean: -1.98982
[32m[0907 18-10-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35917, current rewards: -4597.00000, mean: -1.99004
[32m[0907 18-10-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35941, current rewards: -4697.00000, mean: -1.99025
[32m[0907 18-10-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35962, current rewards: -4797.00000, mean: -1.99046
[32m[0907 18-11-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35983, current rewards: -4897.00000, mean: -1.99065
[32m[0907 18-11-15 @Agent.py:117][0m Average action selection time: 0.3600
[32m[0907 18-11-15 @Agent.py:118][0m Rollout length: 2520
[32m[0907 18-11-15 @MBExp.py:227][0m Rewards obtained: [-4977], Lows: [2477], Highs: [23], Total time: 90633.25738000002
[32m[0907 18-15-28 @MBExp.py:144][0m ####################################################################
[32m[0907 18-15-28 @MBExp.py:145][0m Starting training iteration 111.
[32m[0907 18-15-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.61754, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-15-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.46680, current rewards: -60.00000, mean: -1.00000
[32m[0907 18-16-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.41914, current rewards: -110.00000, mean: -1.00000
[32m[0907 18-16-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.40137, current rewards: -160.00000, mean: -1.00000
[32m[0907 18-16-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.39187, current rewards: -210.00000, mean: -1.00000
[32m[0907 18-17-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.38605, current rewards: -260.00000, mean: -1.00000
[32m[0907 18-17-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.38210, current rewards: -310.00000, mean: -1.00000
[32m[0907 18-17-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37929, current rewards: -360.00000, mean: -1.00000
[32m[0907 18-18-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37716, current rewards: -410.00000, mean: -1.00000
[32m[0907 18-18-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37540, current rewards: -460.00000, mean: -1.00000
[32m[0907 18-18-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37172, current rewards: -510.00000, mean: -1.00000
[32m[0907 18-18-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36829, current rewards: -560.00000, mean: -1.00000
[32m[0907 18-19-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36527, current rewards: -610.00000, mean: -1.00000
[32m[0907 18-19-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36281, current rewards: -660.00000, mean: -1.00000
[32m[0907 18-19-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36071, current rewards: -710.00000, mean: -1.00000
[32m[0907 18-20-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35911, current rewards: -760.00000, mean: -1.00000
[32m[0907 18-20-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35817, current rewards: -810.00000, mean: -1.00000
[32m[0907 18-20-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35736, current rewards: -860.00000, mean: -1.00000
[32m[0907 18-20-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35658, current rewards: -862.10093, mean: -0.94736
[32m[0907 18-21-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35588, current rewards: -856.95528, mean: -0.89266
[32m[0907 18-21-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35533, current rewards: -851.80964, mean: -0.84338
[32m[0907 18-21-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35479, current rewards: -846.66399, mean: -0.79874
[32m[0907 18-22-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35428, current rewards: -841.51834, mean: -0.75812
[32m[0907 18-22-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35380, current rewards: -836.37269, mean: -0.72101
[32m[0907 18-22-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35357, current rewards: -879.75521, mean: -0.72707
[32m[0907 18-22-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35420, current rewards: -929.75521, mean: -0.73790
[32m[0907 18-23-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35489, current rewards: -979.75521, mean: -0.74790
[32m[0907 18-23-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35542, current rewards: -1029.75521, mean: -0.75717
[32m[0907 18-23-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35599, current rewards: -1079.75521, mean: -0.76578
[32m[0907 18-24-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35648, current rewards: -1129.75521, mean: -0.77380
[32m[0907 18-24-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35692, current rewards: -1179.75521, mean: -0.78129
[32m[0907 18-24-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35734, current rewards: -1229.75521, mean: -0.78830
[32m[0907 18-25-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35771, current rewards: -1279.75521, mean: -0.79488
[32m[0907 18-25-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35807, current rewards: -1329.75521, mean: -0.80106
[32m[0907 18-25-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35847, current rewards: -1379.75521, mean: -0.80687
[32m[0907 18-26-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35879, current rewards: -1429.75521, mean: -0.81236
[32m[0907 18-26-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35910, current rewards: -1479.75521, mean: -0.81754
[32m[0907 18-26-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35939, current rewards: -1529.75521, mean: -0.82245
[32m[0907 18-26-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35966, current rewards: -1579.75521, mean: -0.82710
[32m[0907 18-27-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35989, current rewards: -1629.75521, mean: -0.83151
[32m[0907 18-27-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36013, current rewards: -1679.75521, mean: -0.83570
[32m[0907 18-27-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36035, current rewards: -1729.75521, mean: -0.83969
[32m[0907 18-28-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36055, current rewards: -1779.75521, mean: -0.84349
[32m[0907 18-28-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36076, current rewards: -1829.75521, mean: -0.84711
[32m[0907 18-28-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36098, current rewards: -1879.75521, mean: -0.85057
[32m[0907 18-29-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36121, current rewards: -1929.75521, mean: -0.85387
[32m[0907 18-29-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36138, current rewards: -1979.75521, mean: -0.85704
[32m[0907 18-29-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36156, current rewards: -2029.75521, mean: -0.86007
[32m[0907 18-30-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36172, current rewards: -2079.75521, mean: -0.86297
[32m[0907 18-30-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36189, current rewards: -2129.75521, mean: -0.86575
[32m[0907 18-30-34 @Agent.py:117][0m Average action selection time: 0.3620
[32m[0907 18-30-34 @Agent.py:118][0m Rollout length: 2520
[32m[0907 18-30-34 @MBExp.py:227][0m Rewards obtained: [-2169.7552100471107], Lows: [0], Highs: [2200], Total time: 91539.19240600003
[32m[0907 18-34-49 @MBExp.py:144][0m ####################################################################
[32m[0907 18-34-49 @MBExp.py:145][0m Starting training iteration 112.
[32m[0907 18-34-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.38186, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-35-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36598, current rewards: -92.00000, mean: -1.53333
[32m[0907 18-35-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36229, current rewards: -142.00000, mean: -1.29091
[32m[0907 18-35-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36091, current rewards: -192.00000, mean: -1.20000
[32m[0907 18-36-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35981, current rewards: -242.00000, mean: -1.15238
[32m[0907 18-36-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35921, current rewards: -292.00000, mean: -1.12308
[32m[0907 18-36-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35854, current rewards: -342.00000, mean: -1.10323
[32m[0907 18-36-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35813, current rewards: -392.00000, mean: -1.08889
[32m[0907 18-37-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35787, current rewards: -442.00000, mean: -1.07805
[32m[0907 18-37-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35754, current rewards: -492.00000, mean: -1.06957
[32m[0907 18-37-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35642, current rewards: -542.00000, mean: -1.06275
[32m[0907 18-38-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35406, current rewards: -592.00000, mean: -1.05714
[32m[0907 18-38-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35175, current rewards: -642.00000, mean: -1.05246
[32m[0907 18-38-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34984, current rewards: -692.00000, mean: -1.04848
[32m[0907 18-38-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34825, current rewards: -742.00000, mean: -1.04507
[32m[0907 18-39-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34693, current rewards: -792.00000, mean: -1.04211
[32m[0907 18-39-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34625, current rewards: -842.00000, mean: -1.03951
[32m[0907 18-39-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34580, current rewards: -892.00000, mean: -1.03721
[32m[0907 18-40-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34538, current rewards: -942.00000, mean: -1.03516
[32m[0907 18-40-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34494, current rewards: -992.00000, mean: -1.03333
[32m[0907 18-40-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34455, current rewards: -1042.00000, mean: -1.03168
[32m[0907 18-40-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34423, current rewards: -1092.00000, mean: -1.03019
[32m[0907 18-41-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34388, current rewards: -1142.00000, mean: -1.02883
[32m[0907 18-41-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34359, current rewards: -1150.72026, mean: -0.99200
[32m[0907 18-41-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34336, current rewards: -1147.79752, mean: -0.94859
[32m[0907 18-42-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34375, current rewards: -1144.87478, mean: -0.90863
[32m[0907 18-42-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34453, current rewards: -1174.79409, mean: -0.89679
[32m[0907 18-42-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34520, current rewards: -1224.79409, mean: -0.90058
[32m[0907 18-42-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34581, current rewards: -1274.79409, mean: -0.90411
[32m[0907 18-43-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34641, current rewards: -1324.79409, mean: -0.90739
[32m[0907 18-43-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34694, current rewards: -1374.79409, mean: -0.91046
[32m[0907 18-43-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34746, current rewards: -1424.79409, mean: -0.91333
[32m[0907 18-44-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34797, current rewards: -1474.79409, mean: -0.91602
[32m[0907 18-44-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34840, current rewards: -1524.79409, mean: -0.91855
[32m[0907 18-44-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34879, current rewards: -1574.79409, mean: -0.92093
[32m[0907 18-45-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34921, current rewards: -1624.79409, mean: -0.92318
[32m[0907 18-45-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34958, current rewards: -1674.79409, mean: -0.92530
[32m[0907 18-45-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34991, current rewards: -1724.79409, mean: -0.92731
[32m[0907 18-45-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35023, current rewards: -1774.79409, mean: -0.92921
[32m[0907 18-46-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35054, current rewards: -1824.79409, mean: -0.93102
[32m[0907 18-46-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35083, current rewards: -1874.79409, mean: -0.93273
[32m[0907 18-46-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35111, current rewards: -1924.79409, mean: -0.93437
[32m[0907 18-47-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35139, current rewards: -1974.79409, mean: -0.93592
[32m[0907 18-47-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35163, current rewards: -2024.79409, mean: -0.93740
[32m[0907 18-47-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35187, current rewards: -2074.79409, mean: -0.93882
[32m[0907 18-48-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35208, current rewards: -2124.79409, mean: -0.94017
[32m[0907 18-48-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35229, current rewards: -2174.79409, mean: -0.94147
[32m[0907 18-48-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35251, current rewards: -2224.79409, mean: -0.94271
[32m[0907 18-49-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35272, current rewards: -2274.79409, mean: -0.94390
[32m[0907 18-49-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35290, current rewards: -2324.79409, mean: -0.94504
[32m[0907 18-49-32 @Agent.py:117][0m Average action selection time: 0.3531
[32m[0907 18-49-32 @Agent.py:118][0m Rollout length: 2520
[32m[0907 18-49-32 @MBExp.py:227][0m Rewards obtained: [-2364.7940895588054], Lows: [32], Highs: [2310], Total time: 92422.69658400003
[32m[0907 18-53-43 @MBExp.py:144][0m ####################################################################
[32m[0907 18-53-43 @MBExp.py:145][0m Starting training iteration 113.
[32m[0907 18-53-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.40105, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-54-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.39984, current rewards: -95.00000, mean: -1.58333
[32m[0907 18-54-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37919, current rewards: -195.00000, mean: -1.77273
[32m[0907 18-54-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37146, current rewards: -295.00000, mean: -1.84375
[32m[0907 18-55-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36775, current rewards: -395.00000, mean: -1.88095
[32m[0907 18-55-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36526, current rewards: -495.00000, mean: -1.90385
[32m[0907 18-55-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36347, current rewards: -595.00000, mean: -1.91935
[32m[0907 18-55-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36227, current rewards: -695.00000, mean: -1.93056
[32m[0907 18-56-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36138, current rewards: -795.00000, mean: -1.93902
[32m[0907 18-56-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36121, current rewards: -895.00000, mean: -1.94565
[32m[0907 18-56-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36040, current rewards: -990.86828, mean: -1.94288
[32m[0907 18-57-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35785, current rewards: -1090.86828, mean: -1.94798
[32m[0907 18-57-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35530, current rewards: -1190.86828, mean: -1.95224
[32m[0907 18-57-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35320, current rewards: -1290.86828, mean: -1.95586
[32m[0907 18-57-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35131, current rewards: -1390.86828, mean: -1.95897
[32m[0907 18-58-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34976, current rewards: -1490.86828, mean: -1.96167
[32m[0907 18-58-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34889, current rewards: -1590.86828, mean: -1.96403
[32m[0907 18-58-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34820, current rewards: -1690.86828, mean: -1.96613
[32m[0907 18-59-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34768, current rewards: -1790.86828, mean: -1.96799
[32m[0907 18-59-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34720, current rewards: -1890.86828, mean: -1.96965
[32m[0907 18-59-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34672, current rewards: -1990.86828, mean: -1.97116
[32m[0907 18-59-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34629, current rewards: -2090.86828, mean: -1.97252
[32m[0907 19-00-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34590, current rewards: -2190.86828, mean: -1.97376
[32m[0907 19-00-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34548, current rewards: -2290.86828, mean: -1.97489
[32m[0907 19-00-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34517, current rewards: -2390.86828, mean: -1.97592
[32m[0907 19-00-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34496, current rewards: -2490.86828, mean: -1.97688
[32m[0907 19-01-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34568, current rewards: -2590.86828, mean: -1.97776
[32m[0907 19-01-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34643, current rewards: -2690.86828, mean: -1.97858
[32m[0907 19-01-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34708, current rewards: -2790.86828, mean: -1.97934
[32m[0907 19-02-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34765, current rewards: -2890.86828, mean: -1.98005
[32m[0907 19-02-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34820, current rewards: -2990.86828, mean: -1.98071
[32m[0907 19-02-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34871, current rewards: -3090.86828, mean: -1.98133
[32m[0907 19-03-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34918, current rewards: -3190.86828, mean: -1.98191
[32m[0907 19-03-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34961, current rewards: -3290.86828, mean: -1.98245
[32m[0907 19-03-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35003, current rewards: -3390.86828, mean: -1.98296
[32m[0907 19-04-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35042, current rewards: -3490.86828, mean: -1.98345
[32m[0907 19-04-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35079, current rewards: -3590.86828, mean: -1.98391
[32m[0907 19-04-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35114, current rewards: -3690.86828, mean: -1.98434
[32m[0907 19-04-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35144, current rewards: -3790.86828, mean: -1.98475
[32m[0907 19-05-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35176, current rewards: -3890.86828, mean: -1.98514
[32m[0907 19-05-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35204, current rewards: -3990.86828, mean: -1.98551
[32m[0907 19-05-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35228, current rewards: -4090.86828, mean: -1.98586
[32m[0907 19-06-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35255, current rewards: -4190.86828, mean: -1.98619
[32m[0907 19-06-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35279, current rewards: -4290.86828, mean: -1.98651
[32m[0907 19-06-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35304, current rewards: -4390.86828, mean: -1.98682
[32m[0907 19-07-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35324, current rewards: -4490.86828, mean: -1.98711
[32m[0907 19-07-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.35348, current rewards: -4590.86828, mean: -1.98739
[32m[0907 19-07-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.35368, current rewards: -4690.86828, mean: -1.98766
[32m[0907 19-07-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.35386, current rewards: -4790.86828, mean: -1.98791
[32m[0907 19-08-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.35402, current rewards: -4890.86828, mean: -1.98816
[32m[0907 19-08-29 @Agent.py:117][0m Average action selection time: 0.3541
[32m[0907 19-08-29 @Agent.py:118][0m Rollout length: 2520
[32m[0907 19-08-29 @MBExp.py:227][0m Rewards obtained: [-4970.8682801046825], Lows: [2473], Highs: [25], Total time: 93308.95707900003
[32m[0907 19-12-43 @MBExp.py:144][0m ####################################################################
[32m[0907 19-12-43 @MBExp.py:145][0m Starting training iteration 114.
[32m[0907 19-12-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36467, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-13-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36464, current rewards: -100.00000, mean: -1.66667
[32m[0907 19-13-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36098, current rewards: -200.00000, mean: -1.81818
[32m[0907 19-13-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35848, current rewards: -300.00000, mean: -1.87500
[32m[0907 19-13-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35680, current rewards: -400.00000, mean: -1.90476
[32m[0907 19-14-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35532, current rewards: -500.00000, mean: -1.92308
[32m[0907 19-14-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35344, current rewards: -600.00000, mean: -1.93548
[32m[0907 19-14-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35210, current rewards: -700.00000, mean: -1.94444
[32m[0907 19-15-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35100, current rewards: -800.00000, mean: -1.95122
[32m[0907 19-15-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35023, current rewards: -900.00000, mean: -1.95652
[32m[0907 19-15-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34955, current rewards: -1000.00000, mean: -1.96078
[32m[0907 19-15-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34826, current rewards: -1100.00000, mean: -1.96429
[32m[0907 19-16-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34528, current rewards: -1200.00000, mean: -1.96721
[32m[0907 19-16-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34270, current rewards: -1300.00000, mean: -1.96970
[32m[0907 19-16-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34139, current rewards: -1355.59892, mean: -1.90929
[32m[0907 19-17-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34055, current rewards: -1428.45293, mean: -1.87954
[32m[0907 19-17-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33876, current rewards: -1508.64996, mean: -1.86253
[32m[0907 19-17-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33776, current rewards: -1513.30363, mean: -1.75966
[32m[0907 19-17-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33640, current rewards: -1588.52442, mean: -1.74563
[32m[0907 19-18-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33543, current rewards: -1585.11203, mean: -1.65116
[32m[0907 19-18-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33488, current rewards: -1585.99492, mean: -1.57029
[32m[0907 19-18-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33614, current rewards: -1624.89141, mean: -1.53292
[32m[0907 19-18-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33572, current rewards: -1676.58477, mean: -1.51044
[32m[0907 19-19-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33516, current rewards: -1776.58477, mean: -1.53154
[32m[0907 19-19-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33465, current rewards: -1876.58477, mean: -1.55090
[32m[0907 19-19-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33435, current rewards: -1976.58477, mean: -1.56872
[32m[0907 19-20-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33506, current rewards: -2076.58477, mean: -1.58518
[32m[0907 19-20-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33571, current rewards: -2176.58477, mean: -1.60043
[32m[0907 19-20-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33634, current rewards: -2276.58477, mean: -1.61460
[32m[0907 19-20-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33688, current rewards: -2376.58477, mean: -1.62780
[32m[0907 19-21-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33745, current rewards: -2476.58477, mean: -1.64012
[32m[0907 19-21-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33795, current rewards: -2576.58477, mean: -1.65166
[32m[0907 19-21-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33842, current rewards: -2676.58477, mean: -1.66248
[32m[0907 19-22-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33886, current rewards: -2776.58477, mean: -1.67264
[32m[0907 19-22-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33924, current rewards: -2876.58477, mean: -1.68221
[32m[0907 19-22-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33962, current rewards: -2976.58477, mean: -1.69124
[32m[0907 19-22-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33997, current rewards: -3076.58477, mean: -1.69977
[32m[0907 19-23-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34030, current rewards: -3176.58477, mean: -1.70784
[32m[0907 19-23-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34063, current rewards: -3276.58477, mean: -1.71549
[32m[0907 19-23-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34093, current rewards: -3376.58477, mean: -1.72275
[32m[0907 19-24-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34122, current rewards: -3476.58477, mean: -1.72964
[32m[0907 19-24-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34148, current rewards: -3576.58477, mean: -1.73621
[32m[0907 19-24-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34173, current rewards: -3676.58477, mean: -1.74246
[32m[0907 19-25-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34199, current rewards: -3776.58477, mean: -1.74842
[32m[0907 19-25-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34222, current rewards: -3876.58477, mean: -1.75411
[32m[0907 19-25-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34245, current rewards: -3976.58477, mean: -1.75955
[32m[0907 19-25-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34266, current rewards: -4076.58477, mean: -1.76476
[32m[0907 19-26-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34288, current rewards: -4176.58477, mean: -1.76974
[32m[0907 19-26-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34309, current rewards: -4276.58477, mean: -1.77452
[32m[0907 19-26-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34327, current rewards: -4376.58477, mean: -1.77910
[32m[0907 19-27-02 @Agent.py:117][0m Average action selection time: 0.3434
[32m[0907 19-27-02 @Agent.py:118][0m Rollout length: 2520
[32m[0907 19-27-02 @MBExp.py:227][0m Rewards obtained: [-4456.584771492988], Lows: [2217], Highs: [45], Total time: 94168.26951800003
[32m[0907 19-30-51 @MBExp.py:144][0m ####################################################################
[32m[0907 19-30-51 @MBExp.py:145][0m Starting training iteration 115.
[32m[0907 19-30-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32703, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-31-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31798, current rewards: -96.85198, mean: -1.61420
[32m[0907 19-31-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31643, current rewards: -150.69423, mean: -1.36995
[32m[0907 19-31-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31607, current rewards: -242.69423, mean: -1.51684
[32m[0907 19-31-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31562, current rewards: -292.69423, mean: -1.39378
[32m[0907 19-32-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31531, current rewards: -342.69423, mean: -1.31805
[32m[0907 19-32-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31419, current rewards: -392.69423, mean: -1.26676
[32m[0907 19-32-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31315, current rewards: -442.69423, mean: -1.22971
[32m[0907 19-33-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31241, current rewards: -492.69423, mean: -1.20169
[32m[0907 19-33-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31183, current rewards: -542.69423, mean: -1.17977
[32m[0907 19-33-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31141, current rewards: -592.69423, mean: -1.16215
[32m[0907 19-33-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31059, current rewards: -642.69423, mean: -1.14767
[32m[0907 19-34-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30873, current rewards: -692.69423, mean: -1.13556
[32m[0907 19-34-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30706, current rewards: -742.69423, mean: -1.12529
[32m[0907 19-34-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30559, current rewards: -792.69423, mean: -1.11647
[32m[0907 19-34-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30547, current rewards: -842.69423, mean: -1.10881
[32m[0907 19-34-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30588, current rewards: -892.69423, mean: -1.10209
[32m[0907 19-35-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30626, current rewards: -942.69423, mean: -1.09616
[32m[0907 19-35-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30660, current rewards: -992.69423, mean: -1.09087
[32m[0907 19-35-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30694, current rewards: -1042.69423, mean: -1.08614
[32m[0907 19-36-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30737, current rewards: -1092.69423, mean: -1.08188
[32m[0907 19-36-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30812, current rewards: -1142.69423, mean: -1.07801
[32m[0907 19-36-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30885, current rewards: -1192.69423, mean: -1.07450
[32m[0907 19-36-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30946, current rewards: -1242.69423, mean: -1.07129
[32m[0907 19-37-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31008, current rewards: -1292.69423, mean: -1.06834
[32m[0907 19-37-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31066, current rewards: -1308.59816, mean: -1.03857
[32m[0907 19-37-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31177, current rewards: -1305.33504, mean: -0.99644
[32m[0907 19-37-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31346, current rewards: -1302.08915, mean: -0.95742
[32m[0907 19-38-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31502, current rewards: -1298.84327, mean: -0.92117
[32m[0907 19-38-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31650, current rewards: -1295.59738, mean: -0.88740
[32m[0907 19-38-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31788, current rewards: -1338.14296, mean: -0.88619
[32m[0907 19-39-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31918, current rewards: -1388.14296, mean: -0.88984
[32m[0907 19-39-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32039, current rewards: -1438.14296, mean: -0.89326
[32m[0907 19-39-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32150, current rewards: -1488.14296, mean: -0.89647
[32m[0907 19-40-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32256, current rewards: -1538.14296, mean: -0.89950
[32m[0907 19-40-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32357, current rewards: -1588.14296, mean: -0.90235
[32m[0907 19-40-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32452, current rewards: -1638.14296, mean: -0.90505
[32m[0907 19-40-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32545, current rewards: -1688.14296, mean: -0.90760
[32m[0907 19-41-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32633, current rewards: -1738.14296, mean: -0.91002
[32m[0907 19-41-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32714, current rewards: -1788.14296, mean: -0.91232
[32m[0907 19-41-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32787, current rewards: -1838.14296, mean: -0.91450
[32m[0907 19-42-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32858, current rewards: -1888.14296, mean: -0.91657
[32m[0907 19-42-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32940, current rewards: -1938.14296, mean: -0.91855
[32m[0907 19-42-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33035, current rewards: -1988.14296, mean: -0.92044
[32m[0907 19-43-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33120, current rewards: -2038.14296, mean: -0.92224
[32m[0907 19-43-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33200, current rewards: -2088.14296, mean: -0.92396
[32m[0907 19-43-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33256, current rewards: -2138.14296, mean: -0.92560
[32m[0907 19-43-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33309, current rewards: -2188.14296, mean: -0.92718
[32m[0907 19-44-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33359, current rewards: -2238.14296, mean: -0.92869
[32m[0907 19-44-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33406, current rewards: -2288.14296, mean: -0.93014
[32m[0907 19-44-48 @Agent.py:117][0m Average action selection time: 0.3344
[32m[0907 19-44-48 @Agent.py:118][0m Rollout length: 2520
[32m[0907 19-44-48 @MBExp.py:227][0m Rewards obtained: [-2328.1429610779687], Lows: [85], Highs: [2176], Total time: 95005.16561900004
[32m[0907 19-48-58 @MBExp.py:144][0m ####################################################################
[32m[0907 19-48-58 @MBExp.py:145][0m Starting training iteration 116.
[32m[0907 19-49-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35622, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-49-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35772, current rewards: -100.00000, mean: -1.66667
[32m[0907 19-49-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35670, current rewards: -200.00000, mean: -1.81818
[32m[0907 19-49-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35689, current rewards: -300.00000, mean: -1.87500
[32m[0907 19-50-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35686, current rewards: -400.00000, mean: -1.90476
[32m[0907 19-50-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35672, current rewards: -500.00000, mean: -1.92308
[32m[0907 19-50-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35579, current rewards: -600.00000, mean: -1.93548
[32m[0907 19-51-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35477, current rewards: -700.00000, mean: -1.94444
[32m[0907 19-51-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35397, current rewards: -800.00000, mean: -1.95122
[32m[0907 19-51-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35341, current rewards: -900.00000, mean: -1.95652
[32m[0907 19-51-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35297, current rewards: -1000.00000, mean: -1.96078
[32m[0907 19-52-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35262, current rewards: -1100.00000, mean: -1.96429
[32m[0907 19-52-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35077, current rewards: -1200.00000, mean: -1.96721
[32m[0907 19-52-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34851, current rewards: -1300.00000, mean: -1.96970
[32m[0907 19-53-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34649, current rewards: -1400.00000, mean: -1.97183
[32m[0907 19-53-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34467, current rewards: -1500.00000, mean: -1.97368
[32m[0907 19-53-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34310, current rewards: -1600.00000, mean: -1.97531
[32m[0907 19-53-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34175, current rewards: -1700.00000, mean: -1.97674
[32m[0907 19-54-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34051, current rewards: -1800.00000, mean: -1.97802
[32m[0907 19-54-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33941, current rewards: -1900.00000, mean: -1.97917
[32m[0907 19-54-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33842, current rewards: -2000.00000, mean: -1.98020
[32m[0907 19-54-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33781, current rewards: -2100.00000, mean: -1.98113
[32m[0907 19-55-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33742, current rewards: -2200.00000, mean: -1.98198
[32m[0907 19-55-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33706, current rewards: -2300.00000, mean: -1.98276
[32m[0907 19-55-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33668, current rewards: -2400.00000, mean: -1.98347
[32m[0907 19-56-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33630, current rewards: -2500.00000, mean: -1.98413
[32m[0907 19-56-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33594, current rewards: -2600.00000, mean: -1.98473
[32m[0907 19-56-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33644, current rewards: -2700.00000, mean: -1.98529
[32m[0907 19-56-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33739, current rewards: -2800.00000, mean: -1.98582
[32m[0907 19-57-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33832, current rewards: -2900.00000, mean: -1.98630
[32m[0907 19-57-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33923, current rewards: -3000.00000, mean: -1.98675
[32m[0907 19-57-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34003, current rewards: -3100.00000, mean: -1.98718
[32m[0907 19-58-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34089, current rewards: -3200.00000, mean: -1.98758
[32m[0907 19-58-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34173, current rewards: -3300.00000, mean: -1.98795
[32m[0907 19-58-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34248, current rewards: -3400.00000, mean: -1.98830
[32m[0907 19-59-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34332, current rewards: -3500.00000, mean: -1.98864
[32m[0907 19-59-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34400, current rewards: -3600.00000, mean: -1.98895
[32m[0907 19-59-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34477, current rewards: -3697.66409, mean: -1.98799
[32m[0907 19-59-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34532, current rewards: -3797.66409, mean: -1.98831
[32m[0907 20-00-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34583, current rewards: -3891.35431, mean: -1.98538
[32m[0907 20-00-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34634, current rewards: -3991.35431, mean: -1.98575
[32m[0907 20-00-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34671, current rewards: -4091.35431, mean: -1.98609
[32m[0907 20-01-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34707, current rewards: -4191.35431, mean: -1.98642
[32m[0907 20-01-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34737, current rewards: -4291.35431, mean: -1.98674
[32m[0907 20-01-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34759, current rewards: -4391.35431, mean: -1.98704
[32m[0907 20-02-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34779, current rewards: -4491.35431, mean: -1.98732
[32m[0907 20-02-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34799, current rewards: -4591.35431, mean: -1.98760
[32m[0907 20-02-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34818, current rewards: -4691.35431, mean: -1.98786
[32m[0907 20-02-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34835, current rewards: -4791.35431, mean: -1.98811
[32m[0907 20-03-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34851, current rewards: -4891.35431, mean: -1.98836
[32m[0907 20-03-30 @Agent.py:117][0m Average action selection time: 0.3486
[32m[0907 20-03-30 @Agent.py:118][0m Rollout length: 2520
[32m[0907 20-03-31 @MBExp.py:227][0m Rewards obtained: [-4971.354314935636], Lows: [2476], Highs: [20], Total time: 95877.56767200003
[32m[0907 20-07-41 @MBExp.py:144][0m ####################################################################
[32m[0907 20-07-41 @MBExp.py:145][0m Starting training iteration 117.
[32m[0907 20-07-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.35562, current rewards: -10.00000, mean: -1.00000
[32m[0907 20-08-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35720, current rewards: -60.00000, mean: -1.00000
[32m[0907 20-08-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35669, current rewards: -110.00000, mean: -1.00000
[32m[0907 20-08-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35611, current rewards: -160.00000, mean: -1.00000
[32m[0907 20-08-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35604, current rewards: -210.00000, mean: -1.00000
[32m[0907 20-09-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35573, current rewards: -260.00000, mean: -1.00000
[32m[0907 20-09-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35539, current rewards: -310.00000, mean: -1.00000
[32m[0907 20-09-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35424, current rewards: -360.00000, mean: -1.00000
[32m[0907 20-10-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35345, current rewards: -410.00000, mean: -1.00000
[32m[0907 20-10-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35274, current rewards: -460.00000, mean: -1.00000
[32m[0907 20-10-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35218, current rewards: -510.00000, mean: -1.00000
[32m[0907 20-10-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35174, current rewards: -560.00000, mean: -1.00000
[32m[0907 20-11-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35073, current rewards: -610.00000, mean: -1.00000
[32m[0907 20-11-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34888, current rewards: -660.00000, mean: -1.00000
[32m[0907 20-11-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34662, current rewards: -710.00000, mean: -1.00000
[32m[0907 20-12-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34474, current rewards: -760.00000, mean: -1.00000
[32m[0907 20-12-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34319, current rewards: -810.00000, mean: -1.00000
[32m[0907 20-12-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34187, current rewards: -858.95060, mean: -0.99878
[32m[0907 20-12-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34068, current rewards: -856.48052, mean: -0.94119
[32m[0907 20-13-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33984, current rewards: -854.01045, mean: -0.88959
[32m[0907 20-13-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33907, current rewards: -851.54037, mean: -0.84311
[32m[0907 20-13-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33844, current rewards: -849.07029, mean: -0.80101
[32m[0907 20-13-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33825, current rewards: -846.60022, mean: -0.76270
[32m[0907 20-14-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33808, current rewards: -844.13014, mean: -0.72770
[32m[0907 20-14-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33786, current rewards: -853.19304, mean: -0.70512
[32m[0907 20-14-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33751, current rewards: -903.19304, mean: -0.71682
[32m[0907 20-15-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33713, current rewards: -953.19304, mean: -0.72763
[32m[0907 20-15-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33695, current rewards: -1003.19304, mean: -0.73764
[32m[0907 20-15-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33738, current rewards: -1053.19304, mean: -0.74695
[32m[0907 20-15-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33792, current rewards: -1103.19304, mean: -0.75561
[32m[0907 20-16-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33841, current rewards: -1153.19304, mean: -0.76370
[32m[0907 20-16-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33877, current rewards: -1203.19304, mean: -0.77128
[32m[0907 20-16-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33802, current rewards: -1253.19304, mean: -0.77838
[32m[0907 20-17-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33740, current rewards: -1258.08801, mean: -0.75788
[32m[0907 20-17-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33676, current rewards: -1255.64031, mean: -0.73429
[32m[0907 20-17-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33615, current rewards: -1253.19261, mean: -0.71204
[32m[0907 20-17-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33554, current rewards: -1250.74491, mean: -0.69102
[32m[0907 20-18-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33499, current rewards: -1248.29720, mean: -0.67113
[32m[0907 20-18-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33446, current rewards: -1245.84950, mean: -0.65228
[32m[0907 20-18-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33398, current rewards: -1243.40180, mean: -0.63439
[32m[0907 20-18-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33353, current rewards: -1288.15703, mean: -0.64087
[32m[0907 20-19-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33307, current rewards: -1338.15703, mean: -0.64959
[32m[0907 20-19-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33265, current rewards: -1388.15703, mean: -0.65789
[32m[0907 20-19-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33228, current rewards: -1438.15703, mean: -0.66581
[32m[0907 20-19-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33190, current rewards: -1488.15703, mean: -0.67337
[32m[0907 20-20-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33150, current rewards: -1538.15703, mean: -0.68060
[32m[0907 20-20-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33117, current rewards: -1588.15703, mean: -0.68751
[32m[0907 20-20-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33083, current rewards: -1638.15703, mean: -0.69413
[32m[0907 20-20-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33049, current rewards: -1688.15703, mean: -0.70048
[32m[0907 20-21-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33017, current rewards: -1738.15703, mean: -0.70657
[32m[0907 20-21-27 @Agent.py:117][0m Average action selection time: 0.3299
[32m[0907 20-21-27 @Agent.py:118][0m Rollout length: 2520
[32m[0907 20-21-27 @MBExp.py:227][0m Rewards obtained: [-1778.1570298041033], Lows: [0], Highs: [1812], Total time: 96703.18291200003
[32m[0907 20-25-17 @MBExp.py:144][0m ####################################################################
[32m[0907 20-25-17 @MBExp.py:145][0m Starting training iteration 118.
[32m[0907 20-25-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31531, current rewards: -10.00000, mean: -1.00000
[32m[0907 20-25-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31511, current rewards: -56.84511, mean: -0.94742
[32m[0907 20-25-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31483, current rewards: -123.09701, mean: -1.11906
[32m[0907 20-26-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31425, current rewards: -223.09701, mean: -1.39436
[32m[0907 20-26-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31454, current rewards: -323.09701, mean: -1.53856
[32m[0907 20-26-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31468, current rewards: -423.09701, mean: -1.62730
[32m[0907 20-26-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31462, current rewards: -523.09701, mean: -1.68741
[32m[0907 20-27-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31394, current rewards: -623.09701, mean: -1.73083
[32m[0907 20-27-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31317, current rewards: -723.09701, mean: -1.76365
[32m[0907 20-27-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31253, current rewards: -823.09701, mean: -1.78934
[32m[0907 20-27-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31209, current rewards: -923.09701, mean: -1.80999
[32m[0907 20-28-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31170, current rewards: -1023.09701, mean: -1.82696
[32m[0907 20-28-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31140, current rewards: -1123.09701, mean: -1.84114
[32m[0907 20-28-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31069, current rewards: -1223.09701, mean: -1.85318
[32m[0907 20-28-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30921, current rewards: -1323.09701, mean: -1.86352
[32m[0907 20-29-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30772, current rewards: -1423.09701, mean: -1.87250
[32m[0907 20-29-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30634, current rewards: -1523.09701, mean: -1.88037
[32m[0907 20-29-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30561, current rewards: -1594.79552, mean: -1.85441
[32m[0907 20-29-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30481, current rewards: -1675.83703, mean: -1.84158
[32m[0907 20-30-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30393, current rewards: -1741.14224, mean: -1.81369
[32m[0907 20-30-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30307, current rewards: -1806.20003, mean: -1.78832
[32m[0907 20-30-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30234, current rewards: -1856.20003, mean: -1.75113
[32m[0907 20-30-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30176, current rewards: -1906.20003, mean: -1.71730
[32m[0907 20-31-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30148, current rewards: -1956.20003, mean: -1.68638
[32m[0907 20-31-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30103, current rewards: -2004.07870, mean: -1.65626
[32m[0907 20-31-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30062, current rewards: -2054.07870, mean: -1.63022
[32m[0907 20-31-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30027, current rewards: -2104.07870, mean: -1.60617
[32m[0907 20-32-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29993, current rewards: -2154.07870, mean: -1.58388
[32m[0907 20-32-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29982, current rewards: -2204.07870, mean: -1.56318
[32m[0907 20-32-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30022, current rewards: -2254.07870, mean: -1.54389
[32m[0907 20-32-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30074, current rewards: -2304.07870, mean: -1.52588
[32m[0907 20-33-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30125, current rewards: -2354.07870, mean: -1.50902
[32m[0907 20-33-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30167, current rewards: -2404.07870, mean: -1.49322
[32m[0907 20-33-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30207, current rewards: -2454.07870, mean: -1.47836
[32m[0907 20-33-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30243, current rewards: -2504.07870, mean: -1.46437
[32m[0907 20-34-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30278, current rewards: -2554.07870, mean: -1.45118
[32m[0907 20-34-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30312, current rewards: -2604.07870, mean: -1.43872
[32m[0907 20-34-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30341, current rewards: -2654.07870, mean: -1.42692
[32m[0907 20-34-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30372, current rewards: -2704.07870, mean: -1.41575
[32m[0907 20-35-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30401, current rewards: -2754.07870, mean: -1.40514
[32m[0907 20-35-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30426, current rewards: -2804.07870, mean: -1.39506
[32m[0907 20-35-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30450, current rewards: -2854.07870, mean: -1.38548
[32m[0907 20-36-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30471, current rewards: -2904.07870, mean: -1.37634
[32m[0907 20-36-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30495, current rewards: -2954.07870, mean: -1.36763
[32m[0907 20-36-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30516, current rewards: -3004.07870, mean: -1.35931
[32m[0907 20-36-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30539, current rewards: -3020.02921, mean: -1.33630
[32m[0907 20-37-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30560, current rewards: -3016.82688, mean: -1.30599
[32m[0907 20-37-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30579, current rewards: -3013.62455, mean: -1.27696
[32m[0907 20-37-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30597, current rewards: -3009.48741, mean: -1.24875
[32m[0907 20-37-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30617, current rewards: -3004.87264, mean: -1.22149
[32m[0907 20-38-04 @Agent.py:117][0m Average action selection time: 0.3064
[32m[0907 20-38-04 @Agent.py:118][0m Rollout length: 2520
[32m[0907 20-38-04 @MBExp.py:227][0m Rewards obtained: [-3019.749844274287], Lows: [859], Highs: [1328], Total time: 97470.01691600004
[32m[0907 20-41-58 @MBExp.py:144][0m ####################################################################
[32m[0907 20-41-58 @MBExp.py:145][0m Starting training iteration 119.
[32m[0907 20-42-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.37814, current rewards: -10.00000, mean: -1.00000
[32m[0907 20-42-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.36094, current rewards: -86.00000, mean: -1.43333
[32m[0907 20-42-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35736, current rewards: -181.71489, mean: -1.65195
[32m[0907 20-42-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36026, current rewards: -237.17064, mean: -1.48232
[32m[0907 20-43-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35935, current rewards: -308.88068, mean: -1.47086
[32m[0907 20-43-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35790, current rewards: -406.34933, mean: -1.56288
[32m[0907 20-43-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35818, current rewards: -471.62636, mean: -1.52138
[32m[0907 20-44-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35700, current rewards: -519.51915, mean: -1.44311
[32m[0907 20-44-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35538, current rewards: -569.51915, mean: -1.38907
[32m[0907 20-44-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35406, current rewards: -619.51915, mean: -1.34678
[32m[0907 20-44-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35278, current rewards: -669.51915, mean: -1.31278
[32m[0907 20-45-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35197, current rewards: -719.51915, mean: -1.28486
[32m[0907 20-45-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35132, current rewards: -769.51915, mean: -1.26151
[32m[0907 20-45-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35069, current rewards: -819.51915, mean: -1.24170
[32m[0907 20-46-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34940, current rewards: -869.51915, mean: -1.22467
[32m[0907 20-46-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34768, current rewards: -919.51915, mean: -1.20989
[32m[0907 20-46-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34590, current rewards: -968.58572, mean: -1.19578
[32m[0907 20-46-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34415, current rewards: -1017.36957, mean: -1.18299
[32m[0907 20-47-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34242, current rewards: -1017.88514, mean: -1.11856
[32m[0907 20-47-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34085, current rewards: -1014.14260, mean: -1.05640
[32m[0907 20-47-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33958, current rewards: -1010.40007, mean: -1.00040
[32m[0907 20-47-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33839, current rewards: -1006.65753, mean: -0.94968
[32m[0907 20-48-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33737, current rewards: -1002.91500, mean: -0.90353
[32m[0907 20-48-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33680, current rewards: -998.09567, mean: -0.86043
[32m[0907 20-48-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33630, current rewards: -1025.67756, mean: -0.84767
[32m[0907 20-49-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33582, current rewards: -1075.67756, mean: -0.85371
[32m[0907 20-49-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33541, current rewards: -1125.67756, mean: -0.85930
[32m[0907 20-49-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33501, current rewards: -1175.67756, mean: -0.86447
[32m[0907 20-49-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33467, current rewards: -1225.67756, mean: -0.86927
[32m[0907 20-50-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33466, current rewards: -1275.67756, mean: -0.87375
[32m[0907 20-50-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33503, current rewards: -1325.67756, mean: -0.87793
[32m[0907 20-50-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33569, current rewards: -1375.67756, mean: -0.88184
[32m[0907 20-51-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33628, current rewards: -1425.67756, mean: -0.88551
[32m[0907 20-51-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33687, current rewards: -1475.67756, mean: -0.88896
[32m[0907 20-51-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33745, current rewards: -1525.67756, mean: -0.89221
[32m[0907 20-51-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33792, current rewards: -1575.67756, mean: -0.89527
[32m[0907 20-52-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33840, current rewards: -1625.67756, mean: -0.89816
[32m[0907 20-52-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33882, current rewards: -1675.67756, mean: -0.90090
[32m[0907 20-52-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33925, current rewards: -1725.67756, mean: -0.90350
[32m[0907 20-53-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33966, current rewards: -1775.67756, mean: -0.90596
[32m[0907 20-53-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34003, current rewards: -1825.67756, mean: -0.90830
[32m[0907 20-53-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34041, current rewards: -1875.67756, mean: -0.91052
[32m[0907 20-53-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34074, current rewards: -1925.67756, mean: -0.91264
[32m[0907 20-54-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34108, current rewards: -1975.67756, mean: -0.91467
[32m[0907 20-54-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34142, current rewards: -2025.67756, mean: -0.91660
[32m[0907 20-54-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34170, current rewards: -2075.67756, mean: -0.91844
[32m[0907 20-55-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34198, current rewards: -2125.67756, mean: -0.92021
[32m[0907 20-55-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34224, current rewards: -2175.67756, mean: -0.92190
[32m[0907 20-55-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34247, current rewards: -2225.67756, mean: -0.92352
[32m[0907 20-56-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34272, current rewards: -2275.67756, mean: -0.92507
[32m[0907 20-56-16 @Agent.py:117][0m Average action selection time: 0.3429
[32m[0907 20-56-16 @Agent.py:118][0m Rollout length: 2520
[32m[0907 20-56-16 @MBExp.py:227][0m Rewards obtained: [-2315.67756226625], Lows: [207], Highs: [1936], Total time: 98328.12167900003
[32m[0907 21-00-31 @MBExp.py:144][0m ####################################################################
[32m[0907 21-00-31 @MBExp.py:145][0m Starting training iteration 120.
[32m[0907 21-00-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36813, current rewards: -10.00000, mean: -1.00000
[32m[0907 21-00-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35798, current rewards: -60.00000, mean: -1.00000
[32m[0907 21-01-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.35670, current rewards: -110.00000, mean: -1.00000
[32m[0907 21-01-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35629, current rewards: -160.00000, mean: -1.00000
[32m[0907 21-01-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35589, current rewards: -210.00000, mean: -1.00000
[32m[0907 21-02-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35570, current rewards: -260.00000, mean: -1.00000
[32m[0907 21-02-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35553, current rewards: -310.00000, mean: -1.00000
[32m[0907 21-02-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35537, current rewards: -315.21054, mean: -0.87558
[32m[0907 21-02-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35489, current rewards: -307.75034, mean: -0.75061
[32m[0907 21-03-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35394, current rewards: -300.29015, mean: -0.65280
[32m[0907 21-03-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35328, current rewards: -292.82996, mean: -0.57418
[32m[0907 21-03-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35266, current rewards: -285.36977, mean: -0.50959
[32m[0907 21-04-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35217, current rewards: -277.90957, mean: -0.45559
[32m[0907 21-04-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35170, current rewards: -270.44938, mean: -0.40977
[32m[0907 21-04-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35112, current rewards: -262.98919, mean: -0.37041
[32m[0907 21-04-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34949, current rewards: -258.19817, mean: -0.33973
[32m[0907 21-05-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34771, current rewards: -308.19817, mean: -0.38049
[32m[0907 21-05-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34609, current rewards: -358.19817, mean: -0.41651
[32m[0907 21-05-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34463, current rewards: -408.19817, mean: -0.44857
[32m[0907 21-06-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34328, current rewards: -458.19817, mean: -0.47729
[32m[0907 21-06-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34207, current rewards: -508.19817, mean: -0.50317
[32m[0907 21-06-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34100, current rewards: -558.19817, mean: -0.52660
[32m[0907 21-06-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34001, current rewards: -608.19817, mean: -0.54793
[32m[0907 21-07-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33913, current rewards: -658.19817, mean: -0.56741
[32m[0907 21-07-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33859, current rewards: -708.19817, mean: -0.58529
[32m[0907 21-07-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33813, current rewards: -758.19817, mean: -0.60174
[32m[0907 21-07-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33770, current rewards: -808.19817, mean: -0.61695
[32m[0907 21-08-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33730, current rewards: -858.19817, mean: -0.63103
[32m[0907 21-08-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33693, current rewards: -908.19817, mean: -0.64411
[32m[0907 21-08-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33661, current rewards: -958.19817, mean: -0.65630
[32m[0907 21-08-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33666, current rewards: -1008.19817, mean: -0.66768
[32m[0907 21-09-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33709, current rewards: -1058.19817, mean: -0.67833
[32m[0907 21-09-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33768, current rewards: -1108.19817, mean: -0.68832
[32m[0907 21-09-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33823, current rewards: -1158.19817, mean: -0.69771
[32m[0907 21-10-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33866, current rewards: -1208.19817, mean: -0.70655
[32m[0907 21-10-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33913, current rewards: -1258.19817, mean: -0.71489
[32m[0907 21-10-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33955, current rewards: -1308.19817, mean: -0.72276
[32m[0907 21-11-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33997, current rewards: -1358.19817, mean: -0.73021
[32m[0907 21-11-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34035, current rewards: -1408.19817, mean: -0.73728
[32m[0907 21-11-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34071, current rewards: -1458.19817, mean: -0.74398
[32m[0907 21-11-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34102, current rewards: -1508.19817, mean: -0.75035
[32m[0907 21-12-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34134, current rewards: -1558.19817, mean: -0.75641
[32m[0907 21-12-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34166, current rewards: -1608.19817, mean: -0.76218
[32m[0907 21-12-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34195, current rewards: -1658.19817, mean: -0.76768
[32m[0907 21-13-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34221, current rewards: -1708.19817, mean: -0.77294
[32m[0907 21-13-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34248, current rewards: -1758.19817, mean: -0.77796
[32m[0907 21-13-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34275, current rewards: -1808.19817, mean: -0.78277
[32m[0907 21-14-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34300, current rewards: -1858.19817, mean: -0.78737
[32m[0907 21-14-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34323, current rewards: -1908.19817, mean: -0.79178
[32m[0907 21-14-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34347, current rewards: -1958.19817, mean: -0.79602
[32m[0907 21-14-50 @Agent.py:117][0m Average action selection time: 0.3436
[32m[0907 21-14-50 @Agent.py:118][0m Rollout length: 2520
[32m[0907 21-14-51 @MBExp.py:227][0m Rewards obtained: [-1998.1981667920052], Lows: [0], Highs: [2061], Total time: 99188.06034700004
