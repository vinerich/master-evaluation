[32m[0906 13-40-10 @logger.py:99][0m Log file set to /app/logs/dats-delay-1/zinc-coating-v0_2/Tuesday_06_September_2022_01-40PM.log
[32m[0906 13-40-10 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00002, current rewards: -10.62305, mean: -1.06230
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -76.30561, mean: -1.27176
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -138.56402, mean: -1.25967
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -195.59251, mean: -1.22245
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -258.41937, mean: -1.23057
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -323.50286, mean: -1.24424
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -407.39785, mean: -1.31419
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -489.74185, mean: -1.36039
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -580.57980, mean: -1.41605
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -648.84961, mean: -1.41054
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -695.73727, mean: -1.36419
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -750.18378, mean: -1.33961
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -803.16536, mean: -1.31666
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -850.57414, mean: -1.28875
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -901.61142, mean: -1.26988
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -949.48236, mean: -1.24932
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -998.53202, mean: -1.23276
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -1035.12567, mean: -1.20363
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -1093.16035, mean: -1.20128
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -1141.17764, mean: -1.18873
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1189.02339, mean: -1.17725
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1244.41464, mean: -1.17398
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1295.00902, mean: -1.16667
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1359.12970, mean: -1.17166
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1409.79954, mean: -1.16512
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1466.86854, mean: -1.16418
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1514.59056, mean: -1.15618
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1571.82080, mean: -1.15575
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1636.00196, mean: -1.16029
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1695.18362, mean: -1.16108
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1757.49228, mean: -1.16390
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -1811.57445, mean: -1.16127
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -1863.93082, mean: -1.15772
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -1915.17372, mean: -1.15372
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -1965.46808, mean: -1.14940
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -2014.59063, mean: -1.14465
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -2062.09558, mean: -1.13928
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2123.39248, mean: -1.14161
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2184.07072, mean: -1.14349
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2237.99196, mean: -1.14183
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2296.77284, mean: -1.14267
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2351.85923, mean: -1.14168
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2402.77424, mean: -1.13876
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2452.18096, mean: -1.13527
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2503.91689, mean: -1.13299
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2564.93846, mean: -1.13493
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2627.82128, mean: -1.13758
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2685.38807, mean: -1.13788
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2745.43368, mean: -1.13918
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2808.58591, mean: -1.14170
[32m[0906 13-40-10 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-40-10 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-40-12 @MBExp.py:144][0m ####################################################################
[32m[0906 13-40-12 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-40-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.04240, current rewards: -2.36886, mean: -0.23689
[32m[0906 13-40-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03091, current rewards: 1.62370, mean: 0.02706
[32m[0906 13-40-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02994, current rewards: 5.58844, mean: 0.05080
[32m[0906 13-40-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02964, current rewards: 9.55655, mean: 0.05973
[32m[0906 13-40-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02947, current rewards: 13.52011, mean: 0.06438
[32m[0906 13-40-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02932, current rewards: 17.48498, mean: 0.06725
[32m[0906 13-40-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02924, current rewards: 21.45282, mean: 0.06920
[32m[0906 13-40-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02922, current rewards: 23.25641, mean: 0.06460
[32m[0906 13-40-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02922, current rewards: 26.62581, mean: 0.06494
[32m[0906 13-40-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02920, current rewards: 29.88586, mean: 0.06497
[32m[0906 13-40-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02928, current rewards: 33.14579, mean: 0.06499
[32m[0906 13-40-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02928, current rewards: 36.40595, mean: 0.06501
[32m[0906 13-40-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02929, current rewards: 39.66226, mean: 0.06502
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02928, current rewards: 42.92315, mean: 0.06504
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02945, current rewards: 46.18336, mean: 0.06505
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02966, current rewards: 49.64347, mean: 0.06532
[32m[0906 13-40-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02987, current rewards: 54.34337, mean: 0.06709
[32m[0906 13-40-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03006, current rewards: 60.51494, mean: 0.07037
[32m[0906 13-40-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03023, current rewards: 66.69222, mean: 0.07329
[32m[0906 13-40-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03037, current rewards: 72.87434, mean: 0.07591
[32m[0906 13-40-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03049, current rewards: 79.05739, mean: 0.07827
[32m[0906 13-40-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03061, current rewards: 85.24014, mean: 0.08042
[32m[0906 13-40-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03073, current rewards: 91.42012, mean: 0.08236
[32m[0906 13-40-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03084, current rewards: 97.60100, mean: 0.08414
[32m[0906 13-40-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03093, current rewards: 99.85500, mean: 0.08252
[32m[0906 13-40-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03101, current rewards: 109.58346, mean: 0.08697
[32m[0906 13-40-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03108, current rewards: 119.34267, mean: 0.09110
[32m[0906 13-40-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03116, current rewards: 129.10663, mean: 0.09493
[32m[0906 13-40-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03123, current rewards: 138.85759, mean: 0.09848
[32m[0906 13-40-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03128, current rewards: 148.63095, mean: 0.10180
[32m[0906 13-41-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03133, current rewards: 158.39948, mean: 0.10490
[32m[0906 13-41-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03138, current rewards: 168.15319, mean: 0.10779
[32m[0906 13-41-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03142, current rewards: 175.41655, mean: 0.10895
[32m[0906 13-41-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03147, current rewards: 182.06672, mean: 0.10968
[32m[0906 13-41-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03151, current rewards: 188.40715, mean: 0.11018
[32m[0906 13-41-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03156, current rewards: 194.74527, mean: 0.11065
[32m[0906 13-41-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03155, current rewards: 201.09281, mean: 0.11110
[32m[0906 13-41-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03155, current rewards: 207.44184, mean: 0.11153
[32m[0906 13-41-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03158, current rewards: 213.78199, mean: 0.11193
[32m[0906 13-41-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03161, current rewards: 220.12716, mean: 0.11231
[32m[0906 13-41-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03164, current rewards: 226.45710, mean: 0.11267
[32m[0906 13-41-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03171, current rewards: 236.03004, mean: 0.11458
[32m[0906 13-41-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03174, current rewards: 248.87162, mean: 0.11795
[32m[0906 13-41-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03177, current rewards: 261.68762, mean: 0.12115
[32m[0906 13-41-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03183, current rewards: 274.45483, mean: 0.12419
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03192, current rewards: 278.57385, mean: 0.12326
[32m[0906 13-41-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03201, current rewards: 285.85727, mean: 0.12375
[32m[0906 13-41-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03208, current rewards: 293.13772, mean: 0.12421
[32m[0906 13-41-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03216, current rewards: 300.41131, mean: 0.12465
[32m[0906 13-41-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03224, current rewards: 307.17737, mean: 0.12487
[32m[0906 13-41-33 @Agent.py:117][0m Average action selection time: 0.0323
[32m[0906 13-41-33 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-41-33 @MBExp.py:227][0m Rewards obtained: [310.9041611946757], Lows: [5], Highs: [7], Total time: 81.399173
[32m[0906 13-41-38 @MBExp.py:144][0m ####################################################################
[32m[0906 13-41-38 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-41-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03625, current rewards: -3.35506, mean: -0.33551
[32m[0906 13-41-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03629, current rewards: 1.40777, mean: 0.02346
[32m[0906 13-41-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03614, current rewards: 6.20427, mean: 0.05640
[32m[0906 13-41-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03618, current rewards: 11.00497, mean: 0.06878
[32m[0906 13-41-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03618, current rewards: 15.80197, mean: 0.07525
[32m[0906 13-41-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03618, current rewards: 20.60123, mean: 0.07924
[32m[0906 13-41-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03619, current rewards: 25.39553, mean: 0.08192
[32m[0906 13-41-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03618, current rewards: 30.19069, mean: 0.08386
[32m[0906 13-41-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03617, current rewards: 35.61870, mean: 0.08687
[32m[0906 13-41-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03617, current rewards: 41.51572, mean: 0.09025
[32m[0906 13-41-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03617, current rewards: 47.42006, mean: 0.09298
[32m[0906 13-41-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03618, current rewards: 53.32020, mean: 0.09521
[32m[0906 13-42-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03619, current rewards: 59.20595, mean: 0.09706
[32m[0906 13-42-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03613, current rewards: 65.10224, mean: 0.09864
[32m[0906 13-42-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03609, current rewards: 66.64951, mean: 0.09387
[32m[0906 13-42-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03608, current rewards: 72.20093, mean: 0.09500
[32m[0906 13-42-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03609, current rewards: 77.68945, mean: 0.09591
[32m[0906 13-42-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03609, current rewards: 82.59666, mean: 0.09604
[32m[0906 13-42-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03610, current rewards: 87.60510, mean: 0.09627
[32m[0906 13-42-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03613, current rewards: 92.61293, mean: 0.09647
[32m[0906 13-42-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03612, current rewards: 97.62006, mean: 0.09665
[32m[0906 13-42-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03613, current rewards: 102.63072, mean: 0.09682
[32m[0906 13-42-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03613, current rewards: 107.63738, mean: 0.09697
[32m[0906 13-42-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03613, current rewards: 112.64090, mean: 0.09710
[32m[0906 13-42-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03613, current rewards: 117.64540, mean: 0.09723
[32m[0906 13-42-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03613, current rewards: 120.72301, mean: 0.09581
[32m[0906 13-42-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03613, current rewards: 126.10955, mean: 0.09627
[32m[0906 13-42-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03614, current rewards: 131.49518, mean: 0.09669
[32m[0906 13-42-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03615, current rewards: 136.87862, mean: 0.09708
[32m[0906 13-42-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03615, current rewards: 140.00424, mean: 0.09589
[32m[0906 13-42-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03615, current rewards: 145.34352, mean: 0.09625
[32m[0906 13-42-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03615, current rewards: 150.68891, mean: 0.09660
[32m[0906 13-42-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03615, current rewards: 156.02863, mean: 0.09691
[32m[0906 13-42-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03615, current rewards: 161.29287, mean: 0.09716
[32m[0906 13-42-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03615, current rewards: 164.51589, mean: 0.09621
[32m[0906 13-42-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03615, current rewards: 170.52326, mean: 0.09689
[32m[0906 13-42-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03613, current rewards: 176.53551, mean: 0.09753
[32m[0906 13-42-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03611, current rewards: 182.55036, mean: 0.09815
[32m[0906 13-42-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03609, current rewards: 188.57213, mean: 0.09873
[32m[0906 13-42-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03609, current rewards: 194.58627, mean: 0.09928
[32m[0906 13-42-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03610, current rewards: 200.59549, mean: 0.09980
[32m[0906 13-42-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03610, current rewards: 206.47257, mean: 0.10023
[32m[0906 13-42-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03610, current rewards: 207.65344, mean: 0.09841
[32m[0906 13-42-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03611, current rewards: 213.01525, mean: 0.09862
[32m[0906 13-42-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03610, current rewards: 218.37673, mean: 0.09881
[32m[0906 13-43-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03608, current rewards: 223.73901, mean: 0.09900
[32m[0906 13-43-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03608, current rewards: 229.10336, mean: 0.09918
[32m[0906 13-43-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03607, current rewards: 234.46461, mean: 0.09935
[32m[0906 13-43-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03605, current rewards: 239.82970, mean: 0.09951
[32m[0906 13-43-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03604, current rewards: 245.05460, mean: 0.09962
[32m[0906 13-43-09 @Agent.py:117][0m Average action selection time: 0.0360
[32m[0906 13-43-09 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-43-09 @MBExp.py:227][0m Rewards obtained: [248.8081613126225], Lows: [4], Highs: [10], Total time: 172.09904699999998
[32m[0906 13-43-15 @MBExp.py:144][0m ####################################################################
[32m[0906 13-43-15 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-43-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03663, current rewards: -1.06514, mean: -0.10651
[32m[0906 13-43-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03632, current rewards: 5.04347, mean: 0.08406
[32m[0906 13-43-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03630, current rewards: 11.04774, mean: 0.10043
[32m[0906 13-43-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03626, current rewards: 17.05342, mean: 0.10658
[32m[0906 13-43-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03625, current rewards: 23.06110, mean: 0.10981
[32m[0906 13-43-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03621, current rewards: 29.06962, mean: 0.11181
[32m[0906 13-43-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03620, current rewards: 35.07721, mean: 0.11315
[32m[0906 13-43-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03621, current rewards: 39.65499, mean: 0.11015
[32m[0906 13-43-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03625, current rewards: 45.33234, mean: 0.11057
[32m[0906 13-43-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03624, current rewards: 51.03456, mean: 0.11094
[32m[0906 13-43-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03625, current rewards: 56.73898, mean: 0.11125
[32m[0906 13-43-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03621, current rewards: 62.43859, mean: 0.11150
[32m[0906 13-43-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03616, current rewards: 66.02235, mean: 0.10823
[32m[0906 13-43-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03611, current rewards: 71.99836, mean: 0.10909
[32m[0906 13-43-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03605, current rewards: 77.98123, mean: 0.10983
[32m[0906 13-43-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03605, current rewards: 83.95789, mean: 0.11047
[32m[0906 13-43-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03606, current rewards: 90.33002, mean: 0.11152
[32m[0906 13-43-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03608, current rewards: 97.00573, mean: 0.11280
[32m[0906 13-43-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03609, current rewards: 101.66021, mean: 0.11171
[32m[0906 13-43-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03609, current rewards: 108.37554, mean: 0.11289
[32m[0906 13-43-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03610, current rewards: 115.09366, mean: 0.11395
[32m[0906 13-43-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03610, current rewards: 121.81887, mean: 0.11492
[32m[0906 13-43-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03611, current rewards: 126.35894, mean: 0.11384
[32m[0906 13-43-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03612, current rewards: 132.56814, mean: 0.11428
[32m[0906 13-43-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03613, current rewards: 138.49145, mean: 0.11446
[32m[0906 13-44-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03613, current rewards: 143.52656, mean: 0.11391
[32m[0906 13-44-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03613, current rewards: 148.58229, mean: 0.11342
[32m[0906 13-44-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03613, current rewards: 153.64181, mean: 0.11297
[32m[0906 13-44-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03614, current rewards: 158.70015, mean: 0.11255
[32m[0906 13-44-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03614, current rewards: 163.75685, mean: 0.11216
[32m[0906 13-44-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03615, current rewards: 168.81777, mean: 0.11180
[32m[0906 13-44-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03615, current rewards: 173.87207, mean: 0.11146
[32m[0906 13-44-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03615, current rewards: 178.92672, mean: 0.11113
[32m[0906 13-44-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03616, current rewards: 184.64342, mean: 0.11123
[32m[0906 13-44-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03615, current rewards: 188.63689, mean: 0.11031
[32m[0906 13-44-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03616, current rewards: 195.01311, mean: 0.11080
[32m[0906 13-44-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03613, current rewards: 201.38253, mean: 0.11126
[32m[0906 13-44-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03611, current rewards: 207.75560, mean: 0.11170
[32m[0906 13-44-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03610, current rewards: 214.12726, mean: 0.11211
[32m[0906 13-44-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03608, current rewards: 220.50281, mean: 0.11250
[32m[0906 13-44-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03607, current rewards: 226.87833, mean: 0.11287
[32m[0906 13-44-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03607, current rewards: 233.42978, mean: 0.11332
[32m[0906 13-44-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03608, current rewards: 240.00610, mean: 0.11375
[32m[0906 13-44-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03607, current rewards: 246.58872, mean: 0.11416
[32m[0906 13-44-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03606, current rewards: 253.17630, mean: 0.11456
[32m[0906 13-44-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03604, current rewards: 257.56737, mean: 0.11397
[32m[0906 13-44-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03603, current rewards: 263.61455, mean: 0.11412
[32m[0906 13-44-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03603, current rewards: 269.65784, mean: 0.11426
[32m[0906 13-44-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03602, current rewards: 275.70131, mean: 0.11440
[32m[0906 13-44-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03601, current rewards: 281.20488, mean: 0.11431
[32m[0906 13-44-46 @Agent.py:117][0m Average action selection time: 0.0360
[32m[0906 13-44-46 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-44-46 @MBExp.py:227][0m Rewards obtained: [285.3393327136558], Lows: [4], Highs: [5], Total time: 262.741924
[32m[0906 13-44-54 @MBExp.py:144][0m ####################################################################
[32m[0906 13-44-54 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 13-44-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03600, current rewards: -3.34264, mean: -0.33426
[32m[0906 13-44-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03623, current rewards: 1.94347, mean: 0.03239
[32m[0906 13-44-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03625, current rewards: 7.22679, mean: 0.06570
[32m[0906 13-45-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03622, current rewards: 12.50533, mean: 0.07816
[32m[0906 13-45-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03616, current rewards: 17.78669, mean: 0.08470
[32m[0906 13-45-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03614, current rewards: 23.06945, mean: 0.08873
[32m[0906 13-45-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03613, current rewards: 28.35181, mean: 0.09146
[32m[0906 13-45-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03612, current rewards: 33.65031, mean: 0.09347
[32m[0906 13-45-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03608, current rewards: 38.94211, mean: 0.09498
[32m[0906 13-45-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03606, current rewards: 44.23790, mean: 0.09617
[32m[0906 13-45-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03599, current rewards: 49.52605, mean: 0.09711
[32m[0906 13-45-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03592, current rewards: 53.05475, mean: 0.09474
[32m[0906 13-45-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03586, current rewards: 58.55448, mean: 0.09599
[32m[0906 13-45-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03582, current rewards: 64.05378, mean: 0.09705
[32m[0906 13-45-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03578, current rewards: 69.55294, mean: 0.09796
[32m[0906 13-45-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03581, current rewards: 75.05469, mean: 0.09876
[32m[0906 13-45-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03582, current rewards: 80.75833, mean: 0.09970
[32m[0906 13-45-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03584, current rewards: 86.18796, mean: 0.10022
[32m[0906 13-45-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03586, current rewards: 91.62176, mean: 0.10068
[32m[0906 13-45-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03589, current rewards: 97.05251, mean: 0.10110
[32m[0906 13-45-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03590, current rewards: 102.48338, mean: 0.10147
[32m[0906 13-45-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03592, current rewards: 107.91099, mean: 0.10180
[32m[0906 13-45-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03593, current rewards: 111.04937, mean: 0.10004
[32m[0906 13-45-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03594, current rewards: 116.40362, mean: 0.10035
[32m[0906 13-45-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03595, current rewards: 121.70177, mean: 0.10058
[32m[0906 13-45-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03596, current rewards: 127.02144, mean: 0.10081
[32m[0906 13-45-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03597, current rewards: 132.33712, mean: 0.10102
[32m[0906 13-45-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03597, current rewards: 137.64767, mean: 0.10121
[32m[0906 13-45-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03598, current rewards: 142.96147, mean: 0.10139
[32m[0906 13-45-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03598, current rewards: 148.27758, mean: 0.10156
[32m[0906 13-45-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03599, current rewards: 153.58646, mean: 0.10171
[32m[0906 13-45-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03600, current rewards: 158.90536, mean: 0.10186
[32m[0906 13-45-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03600, current rewards: 162.19641, mean: 0.10074
[32m[0906 13-45-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03601, current rewards: 167.62619, mean: 0.10098
[32m[0906 13-45-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03601, current rewards: 173.04572, mean: 0.10120
[32m[0906 13-45-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03602, current rewards: 178.46971, mean: 0.10140
[32m[0906 13-46-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03600, current rewards: 183.89600, mean: 0.10160
[32m[0906 13-46-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03598, current rewards: 189.32013, mean: 0.10179
[32m[0906 13-46-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03596, current rewards: 194.74500, mean: 0.10196
[32m[0906 13-46-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03595, current rewards: 200.16894, mean: 0.10213
[32m[0906 13-46-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03593, current rewards: 205.47322, mean: 0.10223
[32m[0906 13-46-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03592, current rewards: 210.60649, mean: 0.10224
[32m[0906 13-46-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03591, current rewards: 215.73587, mean: 0.10224
[32m[0906 13-46-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03590, current rewards: 220.86441, mean: 0.10225
[32m[0906 13-46-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03589, current rewards: 226.00061, mean: 0.10226
[32m[0906 13-46-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03588, current rewards: 231.13133, mean: 0.10227
[32m[0906 13-46-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03587, current rewards: 236.26098, mean: 0.10228
[32m[0906 13-46-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03587, current rewards: 241.38889, mean: 0.10228
[32m[0906 13-46-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03588, current rewards: 246.67832, mean: 0.10236
[32m[0906 13-46-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03588, current rewards: 250.32983, mean: 0.10176
[32m[0906 13-46-24 @Agent.py:117][0m Average action selection time: 0.0359
[32m[0906 13-46-24 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-46-24 @MBExp.py:227][0m Rewards obtained: [254.73278052577933], Lows: [3], Highs: [6], Total time: 353.03031799999997
[32m[0906 13-46-35 @MBExp.py:144][0m ####################################################################
[32m[0906 13-46-35 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 13-46-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03703, current rewards: -2.27653, mean: -0.22765
[32m[0906 13-46-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03637, current rewards: 3.67376, mean: 0.06123
[32m[0906 13-46-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03621, current rewards: 9.62127, mean: 0.08747
[32m[0906 13-46-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03620, current rewards: 15.56443, mean: 0.09728
[32m[0906 13-46-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03617, current rewards: 21.51355, mean: 0.10245
[32m[0906 13-46-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03614, current rewards: 27.46209, mean: 0.10562
[32m[0906 13-46-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03614, current rewards: 33.40457, mean: 0.10776
[32m[0906 13-46-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03613, current rewards: 38.06299, mean: 0.10573
[32m[0906 13-46-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03611, current rewards: 43.84112, mean: 0.10693
[32m[0906 13-46-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03600, current rewards: 49.61991, mean: 0.10787
[32m[0906 13-46-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03596, current rewards: 55.39783, mean: 0.10862
[32m[0906 13-46-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03589, current rewards: 61.17920, mean: 0.10925
[32m[0906 13-46-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03584, current rewards: 64.95027, mean: 0.10648
[32m[0906 13-46-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03581, current rewards: 71.10954, mean: 0.10774
[32m[0906 13-47-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03580, current rewards: 77.27172, mean: 0.10883
[32m[0906 13-47-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03583, current rewards: 83.32878, mean: 0.10964
[32m[0906 13-47-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03585, current rewards: 89.45325, mean: 0.11044
[32m[0906 13-47-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03587, current rewards: 95.57512, mean: 0.11113
[32m[0906 13-47-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03588, current rewards: 101.69576, mean: 0.11175
[32m[0906 13-47-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03590, current rewards: 107.81454, mean: 0.11231
[32m[0906 13-47-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03590, current rewards: 113.94119, mean: 0.11281
[32m[0906 13-47-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03592, current rewards: 120.06253, mean: 0.11327
[32m[0906 13-47-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03594, current rewards: 126.18228, mean: 0.11368
[32m[0906 13-47-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03595, current rewards: 132.54982, mean: 0.11427
[32m[0906 13-47-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03595, current rewards: 138.72808, mean: 0.11465
[32m[0906 13-47-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03596, current rewards: 144.90694, mean: 0.11501
[32m[0906 13-47-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03597, current rewards: 151.08523, mean: 0.11533
[32m[0906 13-47-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03598, current rewards: 155.70952, mean: 0.11449
[32m[0906 13-47-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03598, current rewards: 162.13339, mean: 0.11499
[32m[0906 13-47-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03599, current rewards: 168.55565, mean: 0.11545
[32m[0906 13-47-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03600, current rewards: 174.97829, mean: 0.11588
[32m[0906 13-47-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03600, current rewards: 181.42073, mean: 0.11630
[32m[0906 13-47-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03600, current rewards: 185.33272, mean: 0.11511
[32m[0906 13-47-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03600, current rewards: 191.60997, mean: 0.11543
[32m[0906 13-47-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03600, current rewards: 197.88290, mean: 0.11572
[32m[0906 13-47-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03601, current rewards: 204.15366, mean: 0.11600
[32m[0906 13-47-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03599, current rewards: 210.42812, mean: 0.11626
[32m[0906 13-47-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03597, current rewards: 216.70993, mean: 0.11651
[32m[0906 13-47-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03595, current rewards: 220.79992, mean: 0.11560
[32m[0906 13-47-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03594, current rewards: 227.02725, mean: 0.11583
[32m[0906 13-47-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03592, current rewards: 233.26617, mean: 0.11605
[32m[0906 13-47-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03589, current rewards: 239.50283, mean: 0.11626
[32m[0906 13-47-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03585, current rewards: 245.74596, mean: 0.11647
[32m[0906 13-47-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03583, current rewards: 250.76330, mean: 0.11609
[32m[0906 13-47-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03582, current rewards: 257.17375, mean: 0.11637
[32m[0906 13-47-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03581, current rewards: 263.58718, mean: 0.11663
[32m[0906 13-47-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03580, current rewards: 269.99835, mean: 0.11688
[32m[0906 13-48-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03580, current rewards: 273.99817, mean: 0.11610
[32m[0906 13-48-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03581, current rewards: 280.14427, mean: 0.11624
[32m[0906 13-48-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03582, current rewards: 286.32807, mean: 0.11639
[32m[0906 13-48-05 @Agent.py:117][0m Average action selection time: 0.0358
[32m[0906 13-48-05 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-48-05 @MBExp.py:227][0m Rewards obtained: [291.2743940654523], Lows: [4], Highs: [8], Total time: 443.21089699999993
[32m[0906 13-48-17 @MBExp.py:144][0m ####################################################################
[32m[0906 13-48-17 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 13-48-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03458, current rewards: -1.67724, mean: -0.16772
[32m[0906 13-48-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03502, current rewards: 4.22226, mean: 0.07037
[32m[0906 13-48-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03563, current rewards: 9.89361, mean: 0.08994
[32m[0906 13-48-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03576, current rewards: 15.55704, mean: 0.09723
[32m[0906 13-48-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03588, current rewards: 21.22153, mean: 0.10105
[32m[0906 13-48-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03591, current rewards: 26.89050, mean: 0.10343
[32m[0906 13-48-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03595, current rewards: 30.58495, mean: 0.09866
[32m[0906 13-48-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03587, current rewards: 36.29679, mean: 0.10082
[32m[0906 13-48-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03582, current rewards: 42.01472, mean: 0.10247
[32m[0906 13-48-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03575, current rewards: 47.72496, mean: 0.10375
[32m[0906 13-48-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03571, current rewards: 53.44184, mean: 0.10479
[32m[0906 13-48-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03565, current rewards: 59.16118, mean: 0.10564
[32m[0906 13-48-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03562, current rewards: 63.77692, mean: 0.10455
[32m[0906 13-48-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03560, current rewards: 70.87347, mean: 0.10738
[32m[0906 13-48-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03559, current rewards: 77.13363, mean: 0.10864
[32m[0906 13-48-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03564, current rewards: 79.98601, mean: 0.10524
[32m[0906 13-48-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03566, current rewards: 82.83618, mean: 0.10227
[32m[0906 13-48-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03569, current rewards: 85.68635, mean: 0.09964
[32m[0906 13-48-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03571, current rewards: 88.53652, mean: 0.09729
[32m[0906 13-48-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03572, current rewards: 91.38670, mean: 0.09519
[32m[0906 13-48-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03573, current rewards: 94.23687, mean: 0.09330
[32m[0906 13-48-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03576, current rewards: 97.08704, mean: 0.09159
[32m[0906 13-48-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03578, current rewards: 99.93721, mean: 0.09003
[32m[0906 13-48-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03580, current rewards: 103.00310, mean: 0.08880
[32m[0906 13-49-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03581, current rewards: 101.83423, mean: 0.08416
[32m[0906 13-49-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03583, current rewards: 51.83423, mean: 0.04114
[32m[0906 13-49-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03584, current rewards: 1.83423, mean: 0.00140
[32m[0906 13-49-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03585, current rewards: -48.16577, mean: -0.03542
[32m[0906 13-49-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03587, current rewards: -98.16577, mean: -0.06962
[32m[0906 13-49-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03588, current rewards: -148.16577, mean: -0.10148
[32m[0906 13-49-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03588, current rewards: -198.16577, mean: -0.13124
[32m[0906 13-49-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03589, current rewards: -248.16577, mean: -0.15908
[32m[0906 13-49-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03590, current rewards: -298.16577, mean: -0.18520
[32m[0906 13-49-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03590, current rewards: -348.16577, mean: -0.20974
[32m[0906 13-49-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03590, current rewards: -398.16577, mean: -0.23285
[32m[0906 13-49-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03590, current rewards: -448.16577, mean: -0.25464
[32m[0906 13-49-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03588, current rewards: -498.16577, mean: -0.27523
[32m[0906 13-49-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03587, current rewards: -548.16577, mean: -0.29471
[32m[0906 13-49-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03585, current rewards: -598.16577, mean: -0.31318
[32m[0906 13-49-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03584, current rewards: -648.16577, mean: -0.33070
[32m[0906 13-49-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03581, current rewards: -698.16577, mean: -0.34735
[32m[0906 13-49-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03579, current rewards: -748.16577, mean: -0.36319
[32m[0906 13-49-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03576, current rewards: -798.16577, mean: -0.37828
[32m[0906 13-49-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03573, current rewards: -848.16577, mean: -0.39267
[32m[0906 13-49-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03572, current rewards: -898.16577, mean: -0.40641
[32m[0906 13-49-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03571, current rewards: -948.16577, mean: -0.41954
[32m[0906 13-49-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03570, current rewards: -998.16577, mean: -0.43211
[32m[0906 13-49-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03571, current rewards: -1048.16577, mean: -0.44414
[32m[0906 13-49-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03572, current rewards: -1098.16577, mean: -0.45567
[32m[0906 13-49-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03572, current rewards: -1148.16577, mean: -0.46673
[32m[0906 13-49-47 @Agent.py:117][0m Average action selection time: 0.0357
[32m[0906 13-49-47 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-49-47 @MBExp.py:227][0m Rewards obtained: [-1188.1657729007288], Lows: [2], Highs: [1297], Total time: 533.170257
[32m[0906 13-50-02 @MBExp.py:144][0m ####################################################################
[32m[0906 13-50-02 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 13-50-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03519, current rewards: -2.22789, mean: -0.22279
[32m[0906 13-50-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03537, current rewards: 3.03572, mean: 0.05060
[32m[0906 13-50-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03534, current rewards: 8.29695, mean: 0.07543
[32m[0906 13-50-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03554, current rewards: 13.56490, mean: 0.08478
[32m[0906 13-50-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03566, current rewards: 18.82832, mean: 0.08966
[32m[0906 13-50-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03574, current rewards: 24.14382, mean: 0.09286
[32m[0906 13-50-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03568, current rewards: 29.43182, mean: 0.09494
[32m[0906 13-50-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03565, current rewards: 34.71791, mean: 0.09644
[32m[0906 13-50-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03565, current rewards: 40.00307, mean: 0.09757
[32m[0906 13-50-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03561, current rewards: 45.29427, mean: 0.09847
[32m[0906 13-50-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03559, current rewards: 50.58068, mean: 0.09918
[32m[0906 13-50-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03558, current rewards: 55.86834, mean: 0.09976
[32m[0906 13-50-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03557, current rewards: 59.20955, mean: 0.09706
[32m[0906 13-50-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03555, current rewards: 64.58244, mean: 0.09785
[32m[0906 13-50-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03559, current rewards: 70.00246, mean: 0.09860
[32m[0906 13-50-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03563, current rewards: 75.41994, mean: 0.09924
[32m[0906 13-50-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03568, current rewards: 80.84098, mean: 0.09980
[32m[0906 13-50-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03570, current rewards: 86.26286, mean: 0.10031
[32m[0906 13-50-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03574, current rewards: 91.68470, mean: 0.10075
[32m[0906 13-50-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03577, current rewards: 97.10473, mean: 0.10115
[32m[0906 13-50-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03578, current rewards: 102.52307, mean: 0.10151
[32m[0906 13-50-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03581, current rewards: 108.04419, mean: 0.10193
[32m[0906 13-50-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03582, current rewards: 112.33526, mean: 0.10120
[32m[0906 13-50-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03584, current rewards: 117.66323, mean: 0.10143
[32m[0906 13-50-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03585, current rewards: 122.99007, mean: 0.10164
[32m[0906 13-50-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03585, current rewards: 128.31500, mean: 0.10184
[32m[0906 13-50-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03586, current rewards: 133.63864, mean: 0.10201
[32m[0906 13-50-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03587, current rewards: 138.96451, mean: 0.10218
[32m[0906 13-50-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03588, current rewards: 144.28764, mean: 0.10233
[32m[0906 13-50-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03589, current rewards: 149.61563, mean: 0.10248
[32m[0906 13-50-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03590, current rewards: 155.16121, mean: 0.10276
[32m[0906 13-50-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03591, current rewards: 160.50417, mean: 0.10289
[32m[0906 13-51-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03592, current rewards: 163.01967, mean: 0.10125
[32m[0906 13-51-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03593, current rewards: 169.55651, mean: 0.10214
[32m[0906 13-51-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03594, current rewards: 176.08502, mean: 0.10297
[32m[0906 13-51-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03594, current rewards: 182.61034, mean: 0.10376
[32m[0906 13-51-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03592, current rewards: 189.14962, mean: 0.10450
[32m[0906 13-51-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03590, current rewards: 195.67413, mean: 0.10520
[32m[0906 13-51-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03589, current rewards: 201.95807, mean: 0.10574
[32m[0906 13-51-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03586, current rewards: 208.76092, mean: 0.10651
[32m[0906 13-51-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03583, current rewards: 215.56837, mean: 0.10725
[32m[0906 13-51-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03580, current rewards: 222.38606, mean: 0.10795
[32m[0906 13-51-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03577, current rewards: 226.57312, mean: 0.10738
[32m[0906 13-51-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03574, current rewards: 232.13343, mean: 0.10747
[32m[0906 13-51-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03571, current rewards: 237.69293, mean: 0.10755
[32m[0906 13-51-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03569, current rewards: 243.25700, mean: 0.10764
[32m[0906 13-51-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03568, current rewards: 248.81563, mean: 0.10771
[32m[0906 13-51-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03569, current rewards: 254.43064, mean: 0.10781
[32m[0906 13-51-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03569, current rewards: 259.99044, mean: 0.10788
[32m[0906 13-51-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03571, current rewards: 263.30661, mean: 0.10704
[32m[0906 13-51-32 @Agent.py:117][0m Average action selection time: 0.0357
[32m[0906 13-51-32 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-51-32 @MBExp.py:227][0m Rewards obtained: [267.6407346914102], Lows: [4], Highs: [5], Total time: 623.0854019999999
[32m[0906 13-51-49 @MBExp.py:144][0m ####################################################################
[32m[0906 13-51-49 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 13-51-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03459, current rewards: -1.05974, mean: -0.10597
[32m[0906 13-51-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03503, current rewards: 5.36232, mean: 0.08937
[32m[0906 13-51-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03521, current rewards: 11.82115, mean: 0.10746
[32m[0906 13-51-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03527, current rewards: 18.27997, mean: 0.11425
[32m[0906 13-51-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03531, current rewards: 24.73880, mean: 0.11780
[32m[0906 13-51-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03532, current rewards: 30.75795, mean: 0.11830
[32m[0906 13-52-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03530, current rewards: 34.67513, mean: 0.11186
[32m[0906 13-52-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03530, current rewards: 21.33882, mean: 0.05927
[32m[0906 13-52-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03534, current rewards: -28.66118, mean: -0.06991
[32m[0906 13-52-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03535, current rewards: -78.66118, mean: -0.17100
[32m[0906 13-52-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03534, current rewards: -128.66118, mean: -0.25228
[32m[0906 13-52-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03533, current rewards: -178.66118, mean: -0.31904
[32m[0906 13-52-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03532, current rewards: -228.66118, mean: -0.37485
[32m[0906 13-52-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03531, current rewards: -278.66118, mean: -0.42221
[32m[0906 13-52-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03539, current rewards: -328.66118, mean: -0.46290
[32m[0906 13-52-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03545, current rewards: -378.66118, mean: -0.49824
[32m[0906 13-52-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03550, current rewards: -428.66118, mean: -0.52921
[32m[0906 13-52-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03554, current rewards: -478.66118, mean: -0.55658
[32m[0906 13-52-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03556, current rewards: -528.66118, mean: -0.58095
[32m[0906 13-52-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03560, current rewards: -578.66118, mean: -0.60277
[32m[0906 13-52-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03562, current rewards: -628.66118, mean: -0.62244
[32m[0906 13-52-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03564, current rewards: -678.66118, mean: -0.64025
[32m[0906 13-52-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03567, current rewards: -728.66118, mean: -0.65645
[32m[0906 13-52-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03571, current rewards: -778.66118, mean: -0.67126
[32m[0906 13-52-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03574, current rewards: -828.66118, mean: -0.68484
[32m[0906 13-52-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03576, current rewards: -878.66118, mean: -0.69735
[32m[0906 13-52-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03577, current rewards: -928.66118, mean: -0.70890
[32m[0906 13-52-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03579, current rewards: -978.66118, mean: -0.71960
[32m[0906 13-52-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03580, current rewards: -1028.66118, mean: -0.72955
[32m[0906 13-52-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03581, current rewards: -1078.66118, mean: -0.73881
[32m[0906 13-52-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03583, current rewards: -1128.66118, mean: -0.74746
[32m[0906 13-52-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03584, current rewards: -1178.66118, mean: -0.75555
[32m[0906 13-52-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03586, current rewards: -1228.66118, mean: -0.76314
[32m[0906 13-52-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03586, current rewards: -1278.66118, mean: -0.77028
[32m[0906 13-52-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03588, current rewards: -1328.66118, mean: -0.77699
[32m[0906 13-52-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03589, current rewards: -1378.66118, mean: -0.78333
[32m[0906 13-52-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03587, current rewards: -1428.66118, mean: -0.78932
[32m[0906 13-52-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03585, current rewards: -1478.66118, mean: -0.79498
[32m[0906 13-52-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03582, current rewards: -1528.66118, mean: -0.80035
[32m[0906 13-52-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03579, current rewards: -1578.66118, mean: -0.80544
[32m[0906 13-53-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03575, current rewards: -1628.66118, mean: -0.81028
[32m[0906 13-53-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03572, current rewards: -1678.66118, mean: -0.81488
[32m[0906 13-53-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03569, current rewards: -1728.66118, mean: -0.81927
[32m[0906 13-53-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03566, current rewards: -1778.66118, mean: -0.82345
[32m[0906 13-53-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03564, current rewards: -1828.66118, mean: -0.82745
[32m[0906 13-53-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03561, current rewards: -1878.66118, mean: -0.83127
[32m[0906 13-53-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03559, current rewards: -1928.66118, mean: -0.83492
[32m[0906 13-53-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03559, current rewards: -1978.66118, mean: -0.83842
[32m[0906 13-53-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03560, current rewards: -2028.66118, mean: -0.84177
[32m[0906 13-53-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03562, current rewards: -2078.66118, mean: -0.84498
[32m[0906 13-53-18 @Agent.py:117][0m Average action selection time: 0.0356
[32m[0906 13-53-18 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-53-18 @MBExp.py:227][0m Rewards obtained: [-2118.6611821025112], Lows: [0], Highs: [2158], Total time: 712.7980869999999
[32m[0906 13-53-37 @MBExp.py:144][0m ####################################################################
[32m[0906 13-53-37 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 13-53-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03521, current rewards: -1.00028, mean: -0.10003
[32m[0906 13-53-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03552, current rewards: 4.87432, mean: 0.08124
[32m[0906 13-53-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03542, current rewards: 10.67762, mean: 0.09707
[32m[0906 13-53-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03516, current rewards: 16.47896, mean: 0.10299
[32m[0906 13-53-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03496, current rewards: 22.28289, mean: 0.10611
[32m[0906 13-53-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03493, current rewards: 28.01560, mean: 0.10775
[32m[0906 13-53-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03499, current rewards: 33.81309, mean: 0.10907
[32m[0906 13-53-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03506, current rewards: 39.60877, mean: 0.11002
[32m[0906 13-53-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03511, current rewards: 45.39962, mean: 0.11073
[32m[0906 13-53-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03515, current rewards: 51.19028, mean: 0.11128
[32m[0906 13-53-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03519, current rewards: 56.98123, mean: 0.11173
[32m[0906 13-53-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03521, current rewards: 60.71146, mean: 0.10841
[32m[0906 13-53-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03521, current rewards: 66.61559, mean: 0.10921
[32m[0906 13-54-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03525, current rewards: 72.53073, mean: 0.10990
[32m[0906 13-54-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03532, current rewards: 78.43546, mean: 0.11047
[32m[0906 13-54-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03537, current rewards: 84.33926, mean: 0.11097
[32m[0906 13-54-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03543, current rewards: 90.24177, mean: 0.11141
[32m[0906 13-54-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03548, current rewards: 96.14431, mean: 0.11180
[32m[0906 13-54-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03551, current rewards: 102.05165, mean: 0.11214
[32m[0906 13-54-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03556, current rewards: 105.60116, mean: 0.11000
[32m[0906 13-54-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03559, current rewards: 111.36708, mean: 0.11026
[32m[0906 13-54-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03562, current rewards: 116.93323, mean: 0.11031
[32m[0906 13-54-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03565, current rewards: 122.65117, mean: 0.11050
[32m[0906 13-54-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03568, current rewards: 128.37161, mean: 0.11067
[32m[0906 13-54-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03570, current rewards: 134.09231, mean: 0.11082
[32m[0906 13-54-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03572, current rewards: 139.81104, mean: 0.11096
[32m[0906 13-54-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03573, current rewards: 145.53747, mean: 0.11110
[32m[0906 13-54-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03575, current rewards: 151.25098, mean: 0.11121
[32m[0906 13-54-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03577, current rewards: 156.96623, mean: 0.11132
[32m[0906 13-54-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03578, current rewards: 162.75321, mean: 0.11147
[32m[0906 13-54-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03580, current rewards: 164.28573, mean: 0.10880
[32m[0906 13-54-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03581, current rewards: 170.19105, mean: 0.10910
[32m[0906 13-54-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03582, current rewards: 176.09458, mean: 0.10938
[32m[0906 13-54-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03583, current rewards: 182.00478, mean: 0.10964
[32m[0906 13-54-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03584, current rewards: 187.91222, mean: 0.10989
[32m[0906 13-54-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03586, current rewards: 193.82118, mean: 0.11013
[32m[0906 13-54-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03584, current rewards: 199.72913, mean: 0.11035
[32m[0906 13-54-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03580, current rewards: 205.86585, mean: 0.11068
[32m[0906 13-54-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03577, current rewards: 211.84975, mean: 0.11092
[32m[0906 13-54-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03574, current rewards: 217.82534, mean: 0.11114
[32m[0906 13-54-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03571, current rewards: 221.53325, mean: 0.11022
[32m[0906 13-54-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03568, current rewards: 227.46440, mean: 0.11042
[32m[0906 13-54-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03566, current rewards: 233.39221, mean: 0.11061
[32m[0906 13-54-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03563, current rewards: 239.32659, mean: 0.11080
[32m[0906 13-54-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03560, current rewards: 245.25111, mean: 0.11097
[32m[0906 13-54-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03557, current rewards: 251.01043, mean: 0.11107
[32m[0906 13-55-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03555, current rewards: 256.59273, mean: 0.11108
[32m[0906 13-55-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03553, current rewards: 262.21186, mean: 0.11111
[32m[0906 13-55-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03555, current rewards: 267.83746, mean: 0.11114
[32m[0906 13-55-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03556, current rewards: 273.46048, mean: 0.11116
[32m[0906 13-55-07 @Agent.py:117][0m Average action selection time: 0.0356
[32m[0906 13-55-07 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-55-07 @MBExp.py:227][0m Rewards obtained: [277.95700413788245], Lows: [3], Highs: [6], Total time: 802.3529489999999
[32m[0906 13-55-27 @MBExp.py:144][0m ####################################################################
[32m[0906 13-55-27 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 13-55-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03440, current rewards: -1.07826, mean: -0.10783
[32m[0906 13-55-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03497, current rewards: 4.48842, mean: 0.07481
[32m[0906 13-55-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03477, current rewards: 10.05832, mean: 0.09144
[32m[0906 13-55-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03463, current rewards: 15.63037, mean: 0.09769
[32m[0906 13-55-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03458, current rewards: 21.23892, mean: 0.10114
[32m[0906 13-55-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03454, current rewards: 26.80253, mean: 0.10309
[32m[0906 13-55-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03453, current rewards: 32.36590, mean: 0.10441
[32m[0906 13-55-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03468, current rewards: 37.92665, mean: 0.10535
[32m[0906 13-55-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03478, current rewards: 43.48765, mean: 0.10607
[32m[0906 13-55-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03484, current rewards: 49.05181, mean: 0.10663
[32m[0906 13-55-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03492, current rewards: 54.61045, mean: 0.10708
[32m[0906 13-55-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03495, current rewards: 60.17729, mean: 0.10746
[32m[0906 13-55-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03499, current rewards: 65.65141, mean: 0.10763
[32m[0906 13-55-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03506, current rewards: 71.23780, mean: 0.10794
[32m[0906 13-55-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03514, current rewards: 76.81993, mean: 0.10820
[32m[0906 13-55-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03522, current rewards: 80.35409, mean: 0.10573
[32m[0906 13-55-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03529, current rewards: 86.03439, mean: 0.10622
[32m[0906 13-55-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03533, current rewards: 91.70812, mean: 0.10664
[32m[0906 13-56-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03538, current rewards: 97.38332, mean: 0.10701
[32m[0906 13-56-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03542, current rewards: 103.06121, mean: 0.10736
[32m[0906 13-56-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03546, current rewards: 108.75084, mean: 0.10767
[32m[0906 13-56-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03551, current rewards: 114.42447, mean: 0.10795
[32m[0906 13-56-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03553, current rewards: 120.10037, mean: 0.10820
[32m[0906 13-56-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03555, current rewards: 125.77793, mean: 0.10843
[32m[0906 13-56-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03557, current rewards: 131.45240, mean: 0.10864
[32m[0906 13-56-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03559, current rewards: 137.13472, mean: 0.10884
[32m[0906 13-56-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03562, current rewards: 142.81442, mean: 0.10902
[32m[0906 13-56-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03564, current rewards: 148.49480, mean: 0.10919
[32m[0906 13-56-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03566, current rewards: 153.35232, mean: 0.10876
[32m[0906 13-56-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03568, current rewards: 159.12594, mean: 0.10899
[32m[0906 13-56-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03569, current rewards: 164.90172, mean: 0.10921
[32m[0906 13-56-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03570, current rewards: 170.67011, mean: 0.10940
[32m[0906 13-56-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03572, current rewards: 176.44645, mean: 0.10959
[32m[0906 13-56-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03573, current rewards: 182.21590, mean: 0.10977
[32m[0906 13-56-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03574, current rewards: 187.98675, mean: 0.10993
[32m[0906 13-56-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03575, current rewards: 193.76086, mean: 0.11009
[32m[0906 13-56-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03572, current rewards: 199.62814, mean: 0.11029
[32m[0906 13-56-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03569, current rewards: 205.49732, mean: 0.11048
[32m[0906 13-56-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03566, current rewards: 211.37287, mean: 0.11067
[32m[0906 13-56-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03563, current rewards: 217.24633, mean: 0.11084
[32m[0906 13-56-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03560, current rewards: 223.11976, mean: 0.11100
[32m[0906 13-56-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03557, current rewards: 226.73865, mean: 0.11007
[32m[0906 13-56-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03554, current rewards: 232.39432, mean: 0.11014
[32m[0906 13-56-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03552, current rewards: 238.05068, mean: 0.11021
[32m[0906 13-56-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03549, current rewards: 243.76915, mean: 0.11030
[32m[0906 13-56-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03548, current rewards: 249.45263, mean: 0.11038
[32m[0906 13-56-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03545, current rewards: 255.13034, mean: 0.11045
[32m[0906 13-56-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03544, current rewards: 260.81200, mean: 0.11051
[32m[0906 13-56-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03544, current rewards: 264.54214, mean: 0.10977
[32m[0906 13-56-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03545, current rewards: 270.10529, mean: 0.10980
[32m[0906 13-56-57 @Agent.py:117][0m Average action selection time: 0.0355
[32m[0906 13-56-57 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-56-57 @MBExp.py:227][0m Rewards obtained: [274.55580494718174], Lows: [3], Highs: [3], Total time: 891.6347989999998
[32m[0906 13-57-20 @MBExp.py:144][0m ####################################################################
[32m[0906 13-57-20 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 13-57-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03476, current rewards: -1.02296, mean: -0.10230
[32m[0906 13-57-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03439, current rewards: 4.54045, mean: 0.07567
[32m[0906 13-57-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03447, current rewards: 10.01530, mean: 0.09105
[32m[0906 13-57-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03446, current rewards: 15.49322, mean: 0.09683
[32m[0906 13-57-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03444, current rewards: 20.97233, mean: 0.09987
[32m[0906 13-57-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03445, current rewards: 26.41450, mean: 0.10159
[32m[0906 13-57-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03443, current rewards: 31.96511, mean: 0.10311
[32m[0906 13-57-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03448, current rewards: 37.52111, mean: 0.10423
[32m[0906 13-57-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03455, current rewards: 43.07429, mean: 0.10506
[32m[0906 13-57-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03462, current rewards: 46.66925, mean: 0.10145
[32m[0906 13-57-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03469, current rewards: 52.19162, mean: 0.10234
[32m[0906 13-57-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03474, current rewards: 57.66227, mean: 0.10297
[32m[0906 13-57-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03479, current rewards: 63.17908, mean: 0.10357
[32m[0906 13-57-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03486, current rewards: 68.69346, mean: 0.10408
[32m[0906 13-57-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03496, current rewards: 74.21570, mean: 0.10453
[32m[0906 13-57-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03503, current rewards: 79.73329, mean: 0.10491
[32m[0906 13-57-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03510, current rewards: 85.24561, mean: 0.10524
[32m[0906 13-57-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03516, current rewards: 90.76353, mean: 0.10554
[32m[0906 13-57-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03524, current rewards: 95.12919, mean: 0.10454
[32m[0906 13-57-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03528, current rewards: 100.56785, mean: 0.10476
[32m[0906 13-57-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03533, current rewards: 106.09366, mean: 0.10504
[32m[0906 13-57-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03537, current rewards: 111.62168, mean: 0.10530
[32m[0906 13-57-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03540, current rewards: 117.15043, mean: 0.10554
[32m[0906 13-58-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03542, current rewards: 122.67474, mean: 0.10575
[32m[0906 13-58-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03545, current rewards: 128.20239, mean: 0.10595
[32m[0906 13-58-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03547, current rewards: 133.73160, mean: 0.10614
[32m[0906 13-58-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03549, current rewards: 139.25604, mean: 0.10630
[32m[0906 13-58-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03552, current rewards: 144.86713, mean: 0.10652
[32m[0906 13-58-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03554, current rewards: 150.46968, mean: 0.10672
[32m[0906 13-58-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03557, current rewards: 156.00316, mean: 0.10685
[32m[0906 13-58-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03559, current rewards: 161.53584, mean: 0.10698
[32m[0906 13-58-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03561, current rewards: 166.18908, mean: 0.10653
[32m[0906 13-58-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03562, current rewards: 171.74561, mean: 0.10667
[32m[0906 13-58-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03565, current rewards: 177.30897, mean: 0.10681
[32m[0906 13-58-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03565, current rewards: 182.86901, mean: 0.10694
[32m[0906 13-58-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03564, current rewards: 188.43131, mean: 0.10706
[32m[0906 13-58-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03561, current rewards: 193.87519, mean: 0.10711
[32m[0906 13-58-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03558, current rewards: 197.19648, mean: 0.10602
[32m[0906 13-58-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03555, current rewards: 202.70781, mean: 0.10613
[32m[0906 13-58-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03552, current rewards: 208.21214, mean: 0.10623
[32m[0906 13-58-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03550, current rewards: 213.71828, mean: 0.10633
[32m[0906 13-58-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03547, current rewards: 219.22572, mean: 0.10642
[32m[0906 13-58-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03545, current rewards: 224.73632, mean: 0.10651
[32m[0906 13-58-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03542, current rewards: 230.24464, mean: 0.10659
[32m[0906 13-58-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03540, current rewards: 235.78271, mean: 0.10669
[32m[0906 13-58-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03538, current rewards: 241.29432, mean: 0.10677
[32m[0906 13-58-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03536, current rewards: 245.69708, mean: 0.10636
[32m[0906 13-58-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03535, current rewards: 251.25245, mean: 0.10646
[32m[0906 13-58-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03535, current rewards: 256.80648, mean: 0.10656
[32m[0906 13-58-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03535, current rewards: 262.36240, mean: 0.10665
[32m[0906 13-58-49 @Agent.py:117][0m Average action selection time: 0.0353
[32m[0906 13-58-49 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-58-49 @MBExp.py:227][0m Rewards obtained: [266.803760587113], Lows: [2], Highs: [5], Total time: 980.6379589999998
[32m[0906 13-59-14 @MBExp.py:144][0m ####################################################################
[32m[0906 13-59-14 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 13-59-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03381, current rewards: -1.10625, mean: -0.11063
[32m[0906 13-59-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03442, current rewards: 4.44555, mean: 0.07409
[32m[0906 13-59-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03440, current rewards: 10.23172, mean: 0.09302
[32m[0906 13-59-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03437, current rewards: 19.54925, mean: 0.12218
[32m[0906 13-59-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03439, current rewards: 28.88269, mean: 0.13754
[32m[0906 13-59-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03439, current rewards: 38.21613, mean: 0.14699
[32m[0906 13-59-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03439, current rewards: 47.54958, mean: 0.15339
[32m[0906 13-59-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03436, current rewards: 56.88302, mean: 0.15801
[32m[0906 13-59-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03436, current rewards: 66.21646, mean: 0.16150
[32m[0906 13-59-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03441, current rewards: 75.54990, mean: 0.16424
[32m[0906 13-59-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03450, current rewards: 32.66991, mean: 0.06406
[32m[0906 13-59-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03456, current rewards: -17.33009, mean: -0.03095
[32m[0906 13-59-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03464, current rewards: -67.33009, mean: -0.11038
[32m[0906 13-59-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03474, current rewards: -117.33009, mean: -0.17777
[32m[0906 13-59-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03484, current rewards: -167.33009, mean: -0.23568
[32m[0906 13-59-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03494, current rewards: -217.33009, mean: -0.28596
[32m[0906 13-59-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03502, current rewards: -267.33009, mean: -0.33004
[32m[0906 13-59-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03509, current rewards: -317.33009, mean: -0.36899
[32m[0906 13-59-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03515, current rewards: -367.33009, mean: -0.40366
[32m[0906 13-59-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03521, current rewards: -417.33009, mean: -0.43472
[32m[0906 13-59-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03525, current rewards: -467.33009, mean: -0.46270
[32m[0906 13-59-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03529, current rewards: -517.33009, mean: -0.48805
[32m[0906 13-59-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03533, current rewards: -567.33009, mean: -0.51111
[32m[0906 13-59-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03536, current rewards: -617.33009, mean: -0.53218
[32m[0906 13-59-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03538, current rewards: -667.33009, mean: -0.55151
[32m[0906 13-59-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03541, current rewards: -717.33009, mean: -0.56931
[32m[0906 14-00-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03544, current rewards: -767.33009, mean: -0.58575
[32m[0906 14-00-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03547, current rewards: -817.33009, mean: -0.60098
[32m[0906 14-00-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03549, current rewards: -867.33009, mean: -0.61513
[32m[0906 14-00-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03552, current rewards: -917.33009, mean: -0.62831
[32m[0906 14-00-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03554, current rewards: -967.33009, mean: -0.64062
[32m[0906 14-00-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03556, current rewards: -1017.33009, mean: -0.65213
[32m[0906 14-00-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03558, current rewards: -1067.33009, mean: -0.66294
[32m[0906 14-00-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03559, current rewards: -1117.33009, mean: -0.67309
[32m[0906 14-00-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03557, current rewards: -1167.33009, mean: -0.68265
[32m[0906 14-00-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03557, current rewards: -1217.33009, mean: -0.69166
[32m[0906 14-00-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03554, current rewards: -1267.33009, mean: -0.70018
[32m[0906 14-00-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03552, current rewards: -1317.33009, mean: -0.70824
[32m[0906 14-00-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03548, current rewards: -1367.33009, mean: -0.71588
[32m[0906 14-00-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03546, current rewards: -1417.33009, mean: -0.72313
[32m[0906 14-00-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03543, current rewards: -1467.33009, mean: -0.73001
[32m[0906 14-00-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03540, current rewards: -1517.33009, mean: -0.73657
[32m[0906 14-00-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03539, current rewards: -1567.33009, mean: -0.74281
[32m[0906 14-00-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03537, current rewards: -1617.33009, mean: -0.74876
[32m[0906 14-00-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03535, current rewards: -1667.33009, mean: -0.75445
[32m[0906 14-00-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03533, current rewards: -1717.33009, mean: -0.75988
[32m[0906 14-00-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03531, current rewards: -1767.33009, mean: -0.76508
[32m[0906 14-00-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03530, current rewards: -1817.33009, mean: -0.77006
[32m[0906 14-00-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03531, current rewards: -1867.33009, mean: -0.77483
[32m[0906 14-00-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03531, current rewards: -1917.33009, mean: -0.77940
[32m[0906 14-00-43 @Agent.py:117][0m Average action selection time: 0.0353
[32m[0906 14-00-43 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-00-43 @MBExp.py:227][0m Rewards obtained: [-1957.330088395515], Lows: [0], Highs: [2036], Total time: 1069.536379
[32m[0906 14-01-10 @MBExp.py:144][0m ####################################################################
[32m[0906 14-01-10 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 14-01-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03457, current rewards: -1.02201, mean: -0.10220
[32m[0906 14-01-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03448, current rewards: 4.51554, mean: 0.07526
[32m[0906 14-01-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03435, current rewards: 9.97386, mean: 0.09067
[32m[0906 14-01-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03441, current rewards: 15.53375, mean: 0.09709
[32m[0906 14-01-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03441, current rewards: 21.09486, mean: 0.10045
[32m[0906 14-01-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03439, current rewards: 26.65943, mean: 0.10254
[32m[0906 14-01-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03438, current rewards: 32.21914, mean: 0.10393
[32m[0906 14-01-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03443, current rewards: 37.78474, mean: 0.10496
[32m[0906 14-01-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03439, current rewards: 43.34402, mean: 0.10572
[32m[0906 14-01-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03439, current rewards: 48.90625, mean: 0.10632
[32m[0906 14-01-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03441, current rewards: 54.45751, mean: 0.10678
[32m[0906 14-01-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03450, current rewards: 60.02480, mean: 0.10719
[32m[0906 14-01-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03456, current rewards: 65.59156, mean: 0.10753
[32m[0906 14-01-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03468, current rewards: 71.15268, mean: 0.10781
[32m[0906 14-01-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03479, current rewards: 76.71603, mean: 0.10805
[32m[0906 14-01-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03488, current rewards: 82.27794, mean: 0.10826
[32m[0906 14-01-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03495, current rewards: 87.84315, mean: 0.10845
[32m[0906 14-01-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03502, current rewards: 92.98350, mean: 0.10812
[32m[0906 14-01-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03509, current rewards: 98.50430, mean: 0.10825
[32m[0906 14-01-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03515, current rewards: 104.02947, mean: 0.10836
[32m[0906 14-01-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03520, current rewards: 109.51817, mean: 0.10843
[32m[0906 14-01-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03525, current rewards: 115.00601, mean: 0.10850
[32m[0906 14-01-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03529, current rewards: 120.49826, mean: 0.10856
[32m[0906 14-01-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03533, current rewards: 125.98371, mean: 0.10861
[32m[0906 14-01-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03536, current rewards: 131.46880, mean: 0.10865
[32m[0906 14-01-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03540, current rewards: 134.77644, mean: 0.10697
[32m[0906 14-01-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03543, current rewards: 140.30643, mean: 0.10710
[32m[0906 14-01-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03547, current rewards: 145.86186, mean: 0.10725
[32m[0906 14-02-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03549, current rewards: 151.38519, mean: 0.10737
[32m[0906 14-02-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03552, current rewards: 156.90548, mean: 0.10747
[32m[0906 14-02-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03554, current rewards: 162.42460, mean: 0.10757
[32m[0906 14-02-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03556, current rewards: 167.94572, mean: 0.10766
[32m[0906 14-02-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03557, current rewards: 173.46987, mean: 0.10775
[32m[0906 14-02-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03556, current rewards: 178.99363, mean: 0.10783
[32m[0906 14-02-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03555, current rewards: 184.51257, mean: 0.10790
[32m[0906 14-02-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03554, current rewards: 190.08187, mean: 0.10800
[32m[0906 14-02-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03551, current rewards: 195.59748, mean: 0.10806
[32m[0906 14-02-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03548, current rewards: 199.48298, mean: 0.10725
[32m[0906 14-02-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03546, current rewards: 204.79600, mean: 0.10722
[32m[0906 14-02-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03544, current rewards: 210.10950, mean: 0.10720
[32m[0906 14-02-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03542, current rewards: 215.42251, mean: 0.10718
[32m[0906 14-02-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03540, current rewards: 220.73620, mean: 0.10715
[32m[0906 14-02-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03538, current rewards: 226.04929, mean: 0.10713
[32m[0906 14-02-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03535, current rewards: 231.36166, mean: 0.10711
[32m[0906 14-02-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03533, current rewards: 236.67664, mean: 0.10709
[32m[0906 14-02-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03531, current rewards: 241.99005, mean: 0.10708
[32m[0906 14-02-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03529, current rewards: 245.18901, mean: 0.10614
[32m[0906 14-02-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03527, current rewards: 250.59032, mean: 0.10618
[32m[0906 14-02-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03527, current rewards: 255.99703, mean: 0.10622
[32m[0906 14-02-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03527, current rewards: 261.40365, mean: 0.10626
[32m[0906 14-02-38 @Agent.py:117][0m Average action selection time: 0.0353
[32m[0906 14-02-38 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-02-38 @MBExp.py:227][0m Rewards obtained: [265.72796280723264], Lows: [2], Highs: [5], Total time: 1158.359964
[32m[0906 14-03-07 @MBExp.py:144][0m ####################################################################
[32m[0906 14-03-07 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 14-03-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03381, current rewards: -0.09446, mean: -0.00945
[32m[0906 14-03-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03421, current rewards: 5.33251, mean: 0.08888
[32m[0906 14-03-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03429, current rewards: 10.82567, mean: 0.09842
[32m[0906 14-03-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03434, current rewards: 16.32176, mean: 0.10201
[32m[0906 14-03-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03436, current rewards: 21.81598, mean: 0.10389
[32m[0906 14-03-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03434, current rewards: 27.30935, mean: 0.10504
[32m[0906 14-03-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03438, current rewards: 32.80978, mean: 0.10584
[32m[0906 14-03-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03439, current rewards: 38.30511, mean: 0.10640
[32m[0906 14-03-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03439, current rewards: 43.80062, mean: 0.10683
[32m[0906 14-03-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03439, current rewards: 49.40756, mean: 0.10741
[32m[0906 14-03-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03440, current rewards: 54.89959, mean: 0.10765
[32m[0906 14-03-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03439, current rewards: 58.30655, mean: 0.10412
[32m[0906 14-03-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03446, current rewards: 63.95958, mean: 0.10485
[32m[0906 14-03-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03459, current rewards: 69.60457, mean: 0.10546
[32m[0906 14-03-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03469, current rewards: 75.24989, mean: 0.10599
[32m[0906 14-03-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03480, current rewards: 80.89712, mean: 0.10644
[32m[0906 14-03-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03489, current rewards: 86.54200, mean: 0.10684
[32m[0906 14-03-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03496, current rewards: 92.14623, mean: 0.10715
[32m[0906 14-03-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03504, current rewards: 97.68616, mean: 0.10735
[32m[0906 14-03-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03510, current rewards: 103.26307, mean: 0.10757
[32m[0906 14-03-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03514, current rewards: 108.84189, mean: 0.10776
[32m[0906 14-03-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03519, current rewards: 114.41755, mean: 0.10794
[32m[0906 14-03-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03524, current rewards: 119.99011, mean: 0.10810
[32m[0906 14-03-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03528, current rewards: 123.38330, mean: 0.10636
[32m[0906 14-03-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03532, current rewards: 128.77929, mean: 0.10643
[32m[0906 14-03-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03535, current rewards: 134.18023, mean: 0.10649
[32m[0906 14-03-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03538, current rewards: 139.51077, mean: 0.10650
[32m[0906 14-03-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03541, current rewards: 144.90142, mean: 0.10655
[32m[0906 14-03-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03543, current rewards: 150.28860, mean: 0.10659
[32m[0906 14-04-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03545, current rewards: 155.67828, mean: 0.10663
[32m[0906 14-04-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03547, current rewards: 159.99761, mean: 0.10596
[32m[0906 14-04-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03548, current rewards: 165.19104, mean: 0.10589
[32m[0906 14-04-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03548, current rewards: 170.38347, mean: 0.10583
[32m[0906 14-04-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03547, current rewards: 175.57561, mean: 0.10577
[32m[0906 14-04-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03547, current rewards: 181.12868, mean: 0.10592
[32m[0906 14-04-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03547, current rewards: 186.64131, mean: 0.10605
[32m[0906 14-04-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03545, current rewards: 192.16036, mean: 0.10617
[32m[0906 14-04-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03542, current rewards: 197.67635, mean: 0.10628
[32m[0906 14-04-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03540, current rewards: 203.19199, mean: 0.10638
[32m[0906 14-04-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03538, current rewards: 205.92545, mean: 0.10506
[32m[0906 14-04-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03536, current rewards: 212.24088, mean: 0.10559
[32m[0906 14-04-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03533, current rewards: 218.55630, mean: 0.10610
[32m[0906 14-04-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03532, current rewards: 224.87173, mean: 0.10657
[32m[0906 14-04-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03530, current rewards: 231.18715, mean: 0.10703
[32m[0906 14-04-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03529, current rewards: 237.50258, mean: 0.10747
[32m[0906 14-04-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03526, current rewards: 197.63935, mean: 0.08745
[32m[0906 14-04-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03525, current rewards: 147.63935, mean: 0.06391
[32m[0906 14-04-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03523, current rewards: 97.63935, mean: 0.04137
[32m[0906 14-04-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03523, current rewards: 47.63935, mean: 0.01977
[32m[0906 14-04-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03524, current rewards: -2.36065, mean: -0.00096
[32m[0906 14-04-36 @Agent.py:117][0m Average action selection time: 0.0352
[32m[0906 14-04-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-04-36 @MBExp.py:227][0m Rewards obtained: [-42.36064703039054], Lows: [4], Highs: [283], Total time: 1247.086455
[32m[0906 14-05-07 @MBExp.py:144][0m ####################################################################
[32m[0906 14-05-07 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 14-05-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03374, current rewards: 1.15758, mean: 0.11576
[32m[0906 14-05-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03432, current rewards: 6.80788, mean: 0.11346
[32m[0906 14-05-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03444, current rewards: 12.45824, mean: 0.11326
[32m[0906 14-05-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03451, current rewards: 18.10624, mean: 0.11316
[32m[0906 14-05-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03445, current rewards: 23.75533, mean: 0.11312
[32m[0906 14-05-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03444, current rewards: 29.40524, mean: 0.11310
[32m[0906 14-05-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03443, current rewards: 35.05570, mean: 0.11308
[32m[0906 14-05-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03443, current rewards: 40.70506, mean: 0.11307
[32m[0906 14-05-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03440, current rewards: 46.47798, mean: 0.11336
[32m[0906 14-05-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03440, current rewards: 52.21313, mean: 0.11351
[32m[0906 14-05-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03438, current rewards: 57.93631, mean: 0.11360
[32m[0906 14-05-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03439, current rewards: 58.02448, mean: 0.10362
[32m[0906 14-05-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03438, current rewards: 63.67109, mean: 0.10438
[32m[0906 14-05-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03451, current rewards: 69.31768, mean: 0.10503
[32m[0906 14-05-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03463, current rewards: 74.96131, mean: 0.10558
[32m[0906 14-05-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03472, current rewards: 80.60260, mean: 0.10606
[32m[0906 14-05-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03482, current rewards: 84.13756, mean: 0.10387
[32m[0906 14-05-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03490, current rewards: 89.83079, mean: 0.10445
[32m[0906 14-05-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03496, current rewards: 95.45097, mean: 0.10489
[32m[0906 14-05-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03502, current rewards: 101.07230, mean: 0.10528
[32m[0906 14-05-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03508, current rewards: 106.69261, mean: 0.10564
[32m[0906 14-05-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03514, current rewards: 112.31451, mean: 0.10596
[32m[0906 14-05-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03519, current rewards: 117.93765, mean: 0.10625
[32m[0906 14-05-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03523, current rewards: 123.49755, mean: 0.10646
[32m[0906 14-05-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03527, current rewards: 129.14286, mean: 0.10673
[32m[0906 14-05-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03529, current rewards: 134.76323, mean: 0.10695
[32m[0906 14-05-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03533, current rewards: 140.40806, mean: 0.10718
[32m[0906 14-05-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03536, current rewards: 146.04638, mean: 0.10739
[32m[0906 14-05-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03538, current rewards: 151.68787, mean: 0.10758
[32m[0906 14-05-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03542, current rewards: 155.57718, mean: 0.10656
[32m[0906 14-06-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03541, current rewards: 161.56558, mean: 0.10700
[32m[0906 14-06-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03541, current rewards: 167.41188, mean: 0.10732
[32m[0906 14-06-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03541, current rewards: 173.26103, mean: 0.10762
[32m[0906 14-06-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03541, current rewards: 179.03361, mean: 0.10785
[32m[0906 14-06-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03540, current rewards: 184.83781, mean: 0.10809
[32m[0906 14-06-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03539, current rewards: 189.47759, mean: 0.10766
[32m[0906 14-06-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03538, current rewards: 195.11170, mean: 0.10780
[32m[0906 14-06-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03536, current rewards: 200.74459, mean: 0.10793
[32m[0906 14-06-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03533, current rewards: 206.37506, mean: 0.10805
[32m[0906 14-06-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03530, current rewards: 211.98845, mean: 0.10816
[32m[0906 14-06-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03528, current rewards: 217.63481, mean: 0.10828
[32m[0906 14-06-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03526, current rewards: 223.31061, mean: 0.10840
[32m[0906 14-06-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03524, current rewards: 228.96745, mean: 0.10852
[32m[0906 14-06-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03521, current rewards: 234.62161, mean: 0.10862
[32m[0906 14-06-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03520, current rewards: 238.37441, mean: 0.10786
[32m[0906 14-06-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03518, current rewards: 244.21070, mean: 0.10806
[32m[0906 14-06-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03516, current rewards: 250.04853, mean: 0.10825
[32m[0906 14-06-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03515, current rewards: 255.88430, mean: 0.10843
[32m[0906 14-06-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03515, current rewards: 261.30320, mean: 0.10842
[32m[0906 14-06-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03516, current rewards: 267.40314, mean: 0.10870
[32m[0906 14-06-36 @Agent.py:117][0m Average action selection time: 0.0352
[32m[0906 14-06-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-06-36 @MBExp.py:227][0m Rewards obtained: [271.9447931498861], Lows: [4], Highs: [6], Total time: 1335.6082239999998
[32m[0906 14-07-09 @MBExp.py:144][0m ####################################################################
[32m[0906 14-07-09 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 14-07-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03421, current rewards: 1.34988, mean: 0.13499
[32m[0906 14-07-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03448, current rewards: 6.07014, mean: 0.10117
[32m[0906 14-07-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03448, current rewards: 11.54306, mean: 0.10494
[32m[0906 14-07-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03451, current rewards: 17.01435, mean: 0.10634
[32m[0906 14-07-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03444, current rewards: 22.48542, mean: 0.10707
[32m[0906 14-07-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03442, current rewards: 26.77545, mean: 0.10298
[32m[0906 14-07-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03441, current rewards: 32.14081, mean: 0.10368
[32m[0906 14-07-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03439, current rewards: 37.46336, mean: 0.10406
[32m[0906 14-07-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03440, current rewards: 42.75249, mean: 0.10427
[32m[0906 14-07-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03441, current rewards: 48.04368, mean: 0.10444
[32m[0906 14-07-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03440, current rewards: 53.33315, mean: 0.10457
[32m[0906 14-07-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03440, current rewards: 58.62234, mean: 0.10468
[32m[0906 14-07-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03442, current rewards: 63.91335, mean: 0.10478
[32m[0906 14-07-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03449, current rewards: 69.20499, mean: 0.10486
[32m[0906 14-07-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03457, current rewards: 74.49179, mean: 0.10492
[32m[0906 14-07-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03468, current rewards: 79.78265, mean: 0.10498
[32m[0906 14-07-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03476, current rewards: 83.97007, mean: 0.10367
[32m[0906 14-07-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03484, current rewards: 89.23456, mean: 0.10376
[32m[0906 14-07-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03493, current rewards: 94.50345, mean: 0.10385
[32m[0906 14-07-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03498, current rewards: 99.77136, mean: 0.10393
[32m[0906 14-07-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03504, current rewards: 105.03658, mean: 0.10400
[32m[0906 14-07-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03509, current rewards: 110.30454, mean: 0.10406
[32m[0906 14-07-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03514, current rewards: 115.57086, mean: 0.10412
[32m[0906 14-07-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03519, current rewards: 120.83788, mean: 0.10417
[32m[0906 14-07-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03523, current rewards: 126.09068, mean: 0.10421
[32m[0906 14-07-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03527, current rewards: 131.35159, mean: 0.10425
[32m[0906 14-07-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03530, current rewards: 136.65912, mean: 0.10432
[32m[0906 14-07-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03533, current rewards: 142.00661, mean: 0.10442
[32m[0906 14-07-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03536, current rewards: 147.35193, mean: 0.10450
[32m[0906 14-08-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03536, current rewards: 152.69466, mean: 0.10459
[32m[0906 14-08-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03535, current rewards: 158.04777, mean: 0.10467
[32m[0906 14-08-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03535, current rewards: 163.38926, mean: 0.10474
[32m[0906 14-08-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03535, current rewards: 168.93775, mean: 0.10493
[32m[0906 14-08-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03535, current rewards: 174.30203, mean: 0.10500
[32m[0906 14-08-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03536, current rewards: 180.08284, mean: 0.10531
[32m[0906 14-08-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03535, current rewards: 185.90404, mean: 0.10563
[32m[0906 14-08-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03534, current rewards: 191.72859, mean: 0.10593
[32m[0906 14-08-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03531, current rewards: 197.55731, mean: 0.10621
[32m[0906 14-08-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03530, current rewards: 203.38207, mean: 0.10648
[32m[0906 14-08-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03528, current rewards: 209.20517, mean: 0.10674
[32m[0906 14-08-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03526, current rewards: 214.92038, mean: 0.10693
[32m[0906 14-08-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03524, current rewards: 220.62529, mean: 0.10710
[32m[0906 14-08-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03522, current rewards: 226.33136, mean: 0.10727
[32m[0906 14-08-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03521, current rewards: 229.87409, mean: 0.10642
[32m[0906 14-08-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03520, current rewards: 235.29320, mean: 0.10647
[32m[0906 14-08-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03518, current rewards: 240.71456, mean: 0.10651
[32m[0906 14-08-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03517, current rewards: 246.13445, mean: 0.10655
[32m[0906 14-08-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03516, current rewards: 251.55296, mean: 0.10659
[32m[0906 14-08-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03516, current rewards: 256.94699, mean: 0.10662
[32m[0906 14-08-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03517, current rewards: 262.35446, mean: 0.10665
[32m[0906 14-08-38 @Agent.py:117][0m Average action selection time: 0.0352
[32m[0906 14-08-38 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-08-38 @MBExp.py:227][0m Rewards obtained: [266.6900692539971], Lows: [1], Highs: [2], Total time: 1424.1720389999998
[32m[0906 14-09-13 @MBExp.py:144][0m ####################################################################
[32m[0906 14-09-13 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 14-09-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03434, current rewards: -0.12206, mean: -0.01221
[32m[0906 14-09-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03442, current rewards: 5.25883, mean: 0.08765
[32m[0906 14-09-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03438, current rewards: 10.82508, mean: 0.09841
[32m[0906 14-09-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03441, current rewards: 16.39621, mean: 0.10248
[32m[0906 14-09-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03443, current rewards: 21.96509, mean: 0.10460
[32m[0906 14-09-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03440, current rewards: 27.53232, mean: 0.10589
[32m[0906 14-09-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03440, current rewards: 33.09519, mean: 0.10676
[32m[0906 14-09-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03438, current rewards: 38.66717, mean: 0.10741
[32m[0906 14-09-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03438, current rewards: 43.09358, mean: 0.10511
[32m[0906 14-09-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03438, current rewards: 48.55703, mean: 0.10556
[32m[0906 14-09-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03438, current rewards: 54.02590, mean: 0.10593
[32m[0906 14-09-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03438, current rewards: 59.48981, mean: 0.10623
[32m[0906 14-09-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03441, current rewards: 64.95248, mean: 0.10648
[32m[0906 14-09-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03447, current rewards: 70.41428, mean: 0.10669
[32m[0906 14-09-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03452, current rewards: 75.87902, mean: 0.10687
[32m[0906 14-09-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03458, current rewards: 81.37614, mean: 0.10707
[32m[0906 14-09-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03467, current rewards: 86.82909, mean: 0.10720
[32m[0906 14-09-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03476, current rewards: 92.28844, mean: 0.10731
[32m[0906 14-09-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03483, current rewards: 97.74035, mean: 0.10741
[32m[0906 14-09-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03489, current rewards: 103.19921, mean: 0.10750
[32m[0906 14-09-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03497, current rewards: 108.65652, mean: 0.10758
[32m[0906 14-09-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03503, current rewards: 114.11408, mean: 0.10765
[32m[0906 14-09-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03508, current rewards: 119.56718, mean: 0.10772
[32m[0906 14-09-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03513, current rewards: 122.44300, mean: 0.10555
[32m[0906 14-09-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03518, current rewards: 127.39689, mean: 0.10529
[32m[0906 14-09-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03522, current rewards: 132.35275, mean: 0.10504
[32m[0906 14-09-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03526, current rewards: 137.30193, mean: 0.10481
[32m[0906 14-10-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03528, current rewards: 142.25306, mean: 0.10460
[32m[0906 14-10-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03528, current rewards: 145.72791, mean: 0.10335
[32m[0906 14-10-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03529, current rewards: 151.32450, mean: 0.10365
[32m[0906 14-10-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03529, current rewards: 156.92105, mean: 0.10392
[32m[0906 14-10-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03530, current rewards: 162.57146, mean: 0.10421
[32m[0906 14-10-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03530, current rewards: 168.15878, mean: 0.10445
[32m[0906 14-10-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03531, current rewards: 173.74514, mean: 0.10467
[32m[0906 14-10-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03531, current rewards: 179.33713, mean: 0.10488
[32m[0906 14-10-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03531, current rewards: 182.79228, mean: 0.10386
[32m[0906 14-10-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03529, current rewards: 188.23201, mean: 0.10400
[32m[0906 14-10-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03527, current rewards: 193.67738, mean: 0.10413
[32m[0906 14-10-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03525, current rewards: 199.12008, mean: 0.10425
[32m[0906 14-10-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03523, current rewards: 204.44495, mean: 0.10431
[32m[0906 14-10-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03521, current rewards: 209.64814, mean: 0.10430
[32m[0906 14-10-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03519, current rewards: 214.92711, mean: 0.10433
[32m[0906 14-10-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03517, current rewards: 220.20949, mean: 0.10436
[32m[0906 14-10-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03516, current rewards: 225.49247, mean: 0.10439
[32m[0906 14-10-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03514, current rewards: 230.77208, mean: 0.10442
[32m[0906 14-10-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03513, current rewards: 236.05580, mean: 0.10445
[32m[0906 14-10-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03511, current rewards: 241.33808, mean: 0.10448
[32m[0906 14-10-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03510, current rewards: 246.62492, mean: 0.10450
[32m[0906 14-10-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03511, current rewards: 252.20773, mean: 0.10465
[32m[0906 14-10-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03512, current rewards: 257.63041, mean: 0.10473
[32m[0906 14-10-41 @Agent.py:117][0m Average action selection time: 0.0351
[32m[0906 14-10-41 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-10-41 @MBExp.py:227][0m Rewards obtained: [261.9704117866978], Lows: [3], Highs: [2], Total time: 1512.5953889999998
[32m[0906 14-11-18 @MBExp.py:144][0m ####################################################################
[32m[0906 14-11-18 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 14-11-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03417, current rewards: -0.12057, mean: -0.01206
[32m[0906 14-11-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03449, current rewards: 5.29641, mean: 0.08827
[32m[0906 14-11-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03454, current rewards: 10.83677, mean: 0.09852
[32m[0906 14-11-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03448, current rewards: 16.37581, mean: 0.10235
[32m[0906 14-11-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03452, current rewards: 21.91566, mean: 0.10436
[32m[0906 14-11-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03448, current rewards: 27.45870, mean: 0.10561
[32m[0906 14-11-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03446, current rewards: 33.01114, mean: 0.10649
[32m[0906 14-11-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03446, current rewards: 38.54554, mean: 0.10707
[32m[0906 14-11-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03449, current rewards: 44.08484, mean: 0.10752
[32m[0906 14-11-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03450, current rewards: 49.62483, mean: 0.10788
[32m[0906 14-11-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03450, current rewards: 55.16519, mean: 0.10817
[32m[0906 14-11-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03450, current rewards: 60.71184, mean: 0.10841
[32m[0906 14-11-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03451, current rewards: 66.24534, mean: 0.10860
[32m[0906 14-11-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03458, current rewards: 71.78630, mean: 0.10877
[32m[0906 14-11-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03462, current rewards: 77.32746, mean: 0.10891
[32m[0906 14-11-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03465, current rewards: 83.00030, mean: 0.10921
[32m[0906 14-11-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03468, current rewards: 88.47192, mean: 0.10922
[32m[0906 14-11-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03475, current rewards: 93.95652, mean: 0.10925
[32m[0906 14-11-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03484, current rewards: 99.44230, mean: 0.10928
[32m[0906 14-11-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03491, current rewards: 104.92519, mean: 0.10930
[32m[0906 14-11-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03498, current rewards: 110.41184, mean: 0.10932
[32m[0906 14-11-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03504, current rewards: 113.78918, mean: 0.10735
[32m[0906 14-11-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03509, current rewards: 119.44194, mean: 0.10761
[32m[0906 14-11-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03512, current rewards: 125.13855, mean: 0.10788
[32m[0906 14-12-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03516, current rewards: 130.80203, mean: 0.10810
[32m[0906 14-12-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03521, current rewards: 136.47039, mean: 0.10831
[32m[0906 14-12-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03523, current rewards: 142.12955, mean: 0.10850
[32m[0906 14-12-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03524, current rewards: 147.79695, mean: 0.10867
[32m[0906 14-12-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03524, current rewards: 151.36218, mean: 0.10735
[32m[0906 14-12-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03524, current rewards: 156.89383, mean: 0.10746
[32m[0906 14-12-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03524, current rewards: 162.43064, mean: 0.10757
[32m[0906 14-12-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03523, current rewards: 167.84349, mean: 0.10759
[32m[0906 14-12-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03523, current rewards: 173.36767, mean: 0.10768
[32m[0906 14-12-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03523, current rewards: 178.89303, mean: 0.10777
[32m[0906 14-12-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03523, current rewards: 184.41976, mean: 0.10785
[32m[0906 14-12-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03524, current rewards: 189.95061, mean: 0.10793
[32m[0906 14-12-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03522, current rewards: 193.37577, mean: 0.10684
[32m[0906 14-12-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03520, current rewards: 198.88884, mean: 0.10693
[32m[0906 14-12-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03518, current rewards: 204.40016, mean: 0.10702
[32m[0906 14-12-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03516, current rewards: 209.90853, mean: 0.10710
[32m[0906 14-12-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03514, current rewards: 215.41929, mean: 0.10717
[32m[0906 14-12-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03513, current rewards: 220.93327, mean: 0.10725
[32m[0906 14-12-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03511, current rewards: 226.44643, mean: 0.10732
[32m[0906 14-12-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03509, current rewards: 231.95648, mean: 0.10739
[32m[0906 14-12-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03507, current rewards: 237.46996, mean: 0.10745
[32m[0906 14-12-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03506, current rewards: 242.97839, mean: 0.10751
[32m[0906 14-12-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03505, current rewards: 248.48915, mean: 0.10757
[32m[0906 14-12-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03504, current rewards: 253.99675, mean: 0.10763
[32m[0906 14-12-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03505, current rewards: 259.50662, mean: 0.10768
[32m[0906 14-12-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03505, current rewards: 263.85159, mean: 0.10726
[32m[0906 14-12-47 @Agent.py:117][0m Average action selection time: 0.0351
[32m[0906 14-12-47 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-12-47 @MBExp.py:227][0m Rewards obtained: [268.25392803990934], Lows: [3], Highs: [2], Total time: 1600.8653719999998
[32m[0906 14-13-26 @MBExp.py:144][0m ####################################################################
[32m[0906 14-13-26 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 14-13-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03412, current rewards: -1.08270, mean: -0.10827
[32m[0906 14-13-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03432, current rewards: 4.51325, mean: 0.07522
[32m[0906 14-13-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03433, current rewards: 10.11305, mean: 0.09194
[32m[0906 14-13-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03440, current rewards: 15.71712, mean: 0.09823
[32m[0906 14-13-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03441, current rewards: 21.31637, mean: 0.10151
[32m[0906 14-13-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03439, current rewards: 26.96781, mean: 0.10372
[32m[0906 14-13-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03441, current rewards: 32.57603, mean: 0.10508
[32m[0906 14-13-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03442, current rewards: 38.18630, mean: 0.10607
[32m[0906 14-13-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03441, current rewards: 43.79747, mean: 0.10682
[32m[0906 14-13-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03441, current rewards: 49.40233, mean: 0.10740
[32m[0906 14-13-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03441, current rewards: 55.01671, mean: 0.10788
[32m[0906 14-13-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03441, current rewards: 60.62413, mean: 0.10826
[32m[0906 14-13-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03446, current rewards: 64.09183, mean: 0.10507
[32m[0906 14-13-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03451, current rewards: 69.71644, mean: 0.10563
[32m[0906 14-13-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03457, current rewards: 75.35514, mean: 0.10613
[32m[0906 14-13-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03463, current rewards: 80.99422, mean: 0.10657
[32m[0906 14-13-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03466, current rewards: 86.62999, mean: 0.10695
[32m[0906 14-13-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03469, current rewards: 92.27045, mean: 0.10729
[32m[0906 14-13-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03475, current rewards: 97.90418, mean: 0.10759
[32m[0906 14-14-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03482, current rewards: 103.54004, mean: 0.10785
[32m[0906 14-14-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03488, current rewards: 109.17531, mean: 0.10809
[32m[0906 14-14-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03494, current rewards: 114.89128, mean: 0.10839
[32m[0906 14-14-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03499, current rewards: 120.71150, mean: 0.10875
[32m[0906 14-14-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03505, current rewards: 126.40734, mean: 0.10897
[32m[0906 14-14-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03509, current rewards: 131.81273, mean: 0.10894
[32m[0906 14-14-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03511, current rewards: 137.16571, mean: 0.10886
[32m[0906 14-14-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03511, current rewards: 142.51778, mean: 0.10879
[32m[0906 14-14-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03512, current rewards: 147.87020, mean: 0.10873
[32m[0906 14-14-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03514, current rewards: 153.22158, mean: 0.10867
[32m[0906 14-14-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03514, current rewards: 158.57569, mean: 0.10861
[32m[0906 14-14-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03515, current rewards: 162.21223, mean: 0.10743
[32m[0906 14-14-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03515, current rewards: 167.92291, mean: 0.10764
[32m[0906 14-14-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03515, current rewards: 173.63545, mean: 0.10785
[32m[0906 14-14-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03515, current rewards: 179.34501, mean: 0.10804
[32m[0906 14-14-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03516, current rewards: 185.05639, mean: 0.10822
[32m[0906 14-14-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03517, current rewards: 189.48110, mean: 0.10766
[32m[0906 14-14-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03515, current rewards: 194.90735, mean: 0.10768
[32m[0906 14-14-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03513, current rewards: 200.33117, mean: 0.10770
[32m[0906 14-14-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03512, current rewards: 205.77046, mean: 0.10773
[32m[0906 14-14-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03510, current rewards: 211.20120, mean: 0.10776
[32m[0906 14-14-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03508, current rewards: 214.96749, mean: 0.10695
[32m[0906 14-14-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03506, current rewards: 222.62257, mean: 0.10807
[32m[0906 14-14-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03505, current rewards: 230.27765, mean: 0.10914
[32m[0906 14-14-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03504, current rewards: 237.93273, mean: 0.11015
[32m[0906 14-14-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03502, current rewards: 245.58781, mean: 0.11113
[32m[0906 14-14-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03501, current rewards: 253.24289, mean: 0.11205
[32m[0906 14-14-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03500, current rewards: 249.94758, mean: 0.10820
[32m[0906 14-14-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03500, current rewards: 199.94758, mean: 0.08472
[32m[0906 14-14-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03500, current rewards: 149.94758, mean: 0.06222
[32m[0906 14-14-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03501, current rewards: 99.94758, mean: 0.04063
[32m[0906 14-14-54 @Agent.py:117][0m Average action selection time: 0.0350
[32m[0906 14-14-54 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-14-54 @MBExp.py:227][0m Rewards obtained: [59.94758197643671], Lows: [4], Highs: [201], Total time: 1689.0153259999997
[32m[0906 14-15-35 @MBExp.py:144][0m ####################################################################
[32m[0906 14-15-35 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 14-15-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03551, current rewards: 0.04749, mean: 0.00475
[32m[0906 14-15-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03459, current rewards: 5.63425, mean: 0.09390
[32m[0906 14-15-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03449, current rewards: 11.17797, mean: 0.10162
[32m[0906 14-15-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03448, current rewards: 16.71867, mean: 0.10449
[32m[0906 14-15-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03443, current rewards: 22.26093, mean: 0.10600
[32m[0906 14-15-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03444, current rewards: 27.79998, mean: 0.10692
[32m[0906 14-15-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03442, current rewards: 33.34871, mean: 0.10758
[32m[0906 14-15-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03445, current rewards: 38.88969, mean: 0.10803
[32m[0906 14-15-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03444, current rewards: 44.43490, mean: 0.10838
[32m[0906 14-15-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03443, current rewards: 49.97908, mean: 0.10865
[32m[0906 14-15-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03442, current rewards: 51.88405, mean: 0.10173
[32m[0906 14-15-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03442, current rewards: 57.39115, mean: 0.10248
[32m[0906 14-15-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03447, current rewards: 62.89952, mean: 0.10311
[32m[0906 14-15-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03455, current rewards: 68.38404, mean: 0.10361
[32m[0906 14-16-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03460, current rewards: 71.65609, mean: 0.10092
[32m[0906 14-16-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03464, current rewards: 77.14667, mean: 0.10151
[32m[0906 14-16-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03469, current rewards: 82.64421, mean: 0.10203
[32m[0906 14-16-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03473, current rewards: 88.13574, mean: 0.10248
[32m[0906 14-16-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03477, current rewards: 93.63317, mean: 0.10289
[32m[0906 14-16-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03482, current rewards: 99.12695, mean: 0.10326
[32m[0906 14-16-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03490, current rewards: 104.62188, mean: 0.10359
[32m[0906 14-16-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03496, current rewards: 107.96553, mean: 0.10185
[32m[0906 14-16-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03502, current rewards: 113.38606, mean: 0.10215
[32m[0906 14-16-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03506, current rewards: 118.80366, mean: 0.10242
[32m[0906 14-16-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03507, current rewards: 124.22467, mean: 0.10267
[32m[0906 14-16-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03507, current rewards: 129.64224, mean: 0.10289
[32m[0906 14-16-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03508, current rewards: 135.05735, mean: 0.10310
[32m[0906 14-16-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03509, current rewards: 140.47078, mean: 0.10329
[32m[0906 14-16-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03510, current rewards: 145.88686, mean: 0.10347
[32m[0906 14-16-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03511, current rewards: 150.35119, mean: 0.10298
[32m[0906 14-16-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03512, current rewards: 155.60328, mean: 0.10305
[32m[0906 14-16-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03513, current rewards: 160.85003, mean: 0.10311
[32m[0906 14-16-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03514, current rewards: 166.10167, mean: 0.10317
[32m[0906 14-16-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03514, current rewards: 171.34639, mean: 0.10322
[32m[0906 14-16-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03515, current rewards: 176.59348, mean: 0.10327
[32m[0906 14-16-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03515, current rewards: 181.84780, mean: 0.10332
[32m[0906 14-16-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03514, current rewards: 187.09376, mean: 0.10337
[32m[0906 14-16-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03511, current rewards: 190.36085, mean: 0.10234
[32m[0906 14-16-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03510, current rewards: 195.47714, mean: 0.10234
[32m[0906 14-16-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03509, current rewards: 200.82227, mean: 0.10246
[32m[0906 14-16-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03507, current rewards: 206.17044, mean: 0.10257
[32m[0906 14-16-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03505, current rewards: 211.51022, mean: 0.10267
[32m[0906 14-16-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03504, current rewards: 216.85832, mean: 0.10278
[32m[0906 14-16-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03503, current rewards: 222.20184, mean: 0.10287
[32m[0906 14-16-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03501, current rewards: 227.54827, mean: 0.10296
[32m[0906 14-16-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03500, current rewards: 232.88808, mean: 0.10305
[32m[0906 14-16-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03499, current rewards: 238.31964, mean: 0.10317
[32m[0906 14-16-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03499, current rewards: 243.69219, mean: 0.10326
[32m[0906 14-17-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03500, current rewards: 249.06389, mean: 0.10335
[32m[0906 14-17-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03500, current rewards: 254.43062, mean: 0.10343
[32m[0906 14-17-03 @Agent.py:117][0m Average action selection time: 0.0350
[32m[0906 14-17-03 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-17-03 @MBExp.py:227][0m Rewards obtained: [258.7233451028772], Lows: [4], Highs: [4], Total time: 1777.1676709999997
[32m[0906 14-17-47 @MBExp.py:144][0m ####################################################################
[32m[0906 14-17-47 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 14-17-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03312, current rewards: -1.16552, mean: -0.11655
[32m[0906 14-17-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03436, current rewards: 4.42248, mean: 0.07371
[32m[0906 14-17-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03449, current rewards: 10.11852, mean: 0.09199
[32m[0906 14-17-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03448, current rewards: 15.80998, mean: 0.09881
[32m[0906 14-17-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03450, current rewards: 21.49472, mean: 0.10236
[32m[0906 14-17-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03451, current rewards: 27.42609, mean: 0.10548
[32m[0906 14-17-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03453, current rewards: 32.98182, mean: 0.10639
[32m[0906 14-17-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03451, current rewards: 38.54157, mean: 0.10706
[32m[0906 14-18-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03450, current rewards: 44.10242, mean: 0.10757
[32m[0906 14-18-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03449, current rewards: 49.66099, mean: 0.10796
[32m[0906 14-18-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03448, current rewards: 55.22000, mean: 0.10827
[32m[0906 14-18-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03446, current rewards: 57.94692, mean: 0.10348
[32m[0906 14-18-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03453, current rewards: 66.48484, mean: 0.10899
[32m[0906 14-18-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03460, current rewards: 74.79210, mean: 0.11332
[32m[0906 14-18-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03464, current rewards: 80.25769, mean: 0.11304
[32m[0906 14-18-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03468, current rewards: 84.09758, mean: 0.11065
[32m[0906 14-18-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03471, current rewards: 89.53415, mean: 0.11054
[32m[0906 14-18-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03474, current rewards: 94.97295, mean: 0.11043
[32m[0906 14-18-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03478, current rewards: 100.41263, mean: 0.11034
[32m[0906 14-18-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03480, current rewards: 105.84821, mean: 0.11026
[32m[0906 14-18-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03485, current rewards: 111.28161, mean: 0.11018
[32m[0906 14-18-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03491, current rewards: 116.72388, mean: 0.11012
[32m[0906 14-18-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03493, current rewards: 122.14381, mean: 0.11004
[32m[0906 14-18-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03494, current rewards: 127.57899, mean: 0.10998
[32m[0906 14-18-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03495, current rewards: 133.02007, mean: 0.10993
[32m[0906 14-18-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03497, current rewards: 137.63039, mean: 0.10923
[32m[0906 14-18-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03498, current rewards: 143.18588, mean: 0.10930
[32m[0906 14-18-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03499, current rewards: 148.73688, mean: 0.10937
[32m[0906 14-18-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03501, current rewards: 154.29004, mean: 0.10943
[32m[0906 14-18-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03503, current rewards: 157.84893, mean: 0.10812
[32m[0906 14-18-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03503, current rewards: 163.17391, mean: 0.10806
[32m[0906 14-18-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03504, current rewards: 168.77068, mean: 0.10819
[32m[0906 14-18-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03505, current rewards: 174.36482, mean: 0.10830
[32m[0906 14-18-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03506, current rewards: 179.96029, mean: 0.10841
[32m[0906 14-18-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03506, current rewards: 185.55989, mean: 0.10851
[32m[0906 14-18-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03507, current rewards: 191.15323, mean: 0.10861
[32m[0906 14-18-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03505, current rewards: 196.74357, mean: 0.10870
[32m[0906 14-18-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03504, current rewards: 202.34041, mean: 0.10879
[32m[0906 14-18-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03502, current rewards: 208.02664, mean: 0.10891
[32m[0906 14-18-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03501, current rewards: 213.63134, mean: 0.10900
[32m[0906 14-18-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03500, current rewards: 219.23561, mean: 0.10907
[32m[0906 14-18-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03499, current rewards: 224.83533, mean: 0.10914
[32m[0906 14-19-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03497, current rewards: 229.21380, mean: 0.10863
[32m[0906 14-19-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03496, current rewards: 234.62828, mean: 0.10862
[32m[0906 14-19-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03495, current rewards: 240.04598, mean: 0.10862
[32m[0906 14-19-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03494, current rewards: 245.46339, mean: 0.10861
[32m[0906 14-19-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03494, current rewards: 250.97954, mean: 0.10865
[32m[0906 14-19-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03494, current rewards: 256.54661, mean: 0.10871
[32m[0906 14-19-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03495, current rewards: 259.39747, mean: 0.10763
[32m[0906 14-19-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03496, current rewards: 266.16151, mean: 0.10820
[32m[0906 14-19-15 @Agent.py:117][0m Average action selection time: 0.0350
[32m[0906 14-19-15 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-19-15 @MBExp.py:227][0m Rewards obtained: [271.5727432555287], Lows: [6], Highs: [6], Total time: 1865.2305579999997
[32m[0906 14-20-00 @MBExp.py:144][0m ####################################################################
[32m[0906 14-20-00 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 14-20-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03437, current rewards: 0.12822, mean: 0.01282
[32m[0906 14-20-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03455, current rewards: 6.29032, mean: 0.10484
[32m[0906 14-20-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03451, current rewards: 12.19057, mean: 0.11082
[32m[0906 14-20-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03450, current rewards: 18.09117, mean: 0.11307
[32m[0906 14-20-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03449, current rewards: 23.99099, mean: 0.11424
[32m[0906 14-20-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03446, current rewards: 27.53364, mean: 0.10590
[32m[0906 14-20-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03445, current rewards: 33.03080, mean: 0.10655
[32m[0906 14-20-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03443, current rewards: 38.53016, mean: 0.10703
[32m[0906 14-20-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03442, current rewards: 44.02812, mean: 0.10739
[32m[0906 14-20-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03442, current rewards: 49.52479, mean: 0.10766
[32m[0906 14-20-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03446, current rewards: 53.94160, mean: 0.10577
[32m[0906 14-20-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03446, current rewards: 59.47401, mean: 0.10620
[32m[0906 14-20-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03454, current rewards: 65.00195, mean: 0.10656
[32m[0906 14-20-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03459, current rewards: 70.56400, mean: 0.10692
[32m[0906 14-20-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03464, current rewards: 76.09456, mean: 0.10718
[32m[0906 14-20-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03468, current rewards: 81.62783, mean: 0.10741
[32m[0906 14-20-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03472, current rewards: 87.16103, mean: 0.10761
[32m[0906 14-20-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03475, current rewards: 90.59263, mean: 0.10534
[32m[0906 14-20-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03479, current rewards: 96.01098, mean: 0.10551
[32m[0906 14-20-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03483, current rewards: 101.42719, mean: 0.10565
[32m[0906 14-20-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03485, current rewards: 106.84660, mean: 0.10579
[32m[0906 14-20-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03485, current rewards: 112.26762, mean: 0.10591
[32m[0906 14-20-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03487, current rewards: 117.68767, mean: 0.10602
[32m[0906 14-20-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03490, current rewards: 123.10419, mean: 0.10612
[32m[0906 14-20-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03492, current rewards: 128.52678, mean: 0.10622
[32m[0906 14-20-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03494, current rewards: 133.94739, mean: 0.10631
[32m[0906 14-20-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03496, current rewards: 139.33053, mean: 0.10636
[32m[0906 14-20-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03497, current rewards: 144.78138, mean: 0.10646
[32m[0906 14-20-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03498, current rewards: 150.22498, mean: 0.10654
[32m[0906 14-20-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03499, current rewards: 155.64019, mean: 0.10660
[32m[0906 14-20-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03500, current rewards: 160.93147, mean: 0.10658
[32m[0906 14-20-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03501, current rewards: 166.37564, mean: 0.10665
[32m[0906 14-20-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03502, current rewards: 169.64051, mean: 0.10537
[32m[0906 14-20-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03503, current rewards: 175.15535, mean: 0.10552
[32m[0906 14-21-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03505, current rewards: 180.66678, mean: 0.10565
[32m[0906 14-21-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03505, current rewards: 186.18240, mean: 0.10579
[32m[0906 14-21-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03503, current rewards: 191.69846, mean: 0.10591
[32m[0906 14-21-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03501, current rewards: 197.21076, mean: 0.10603
[32m[0906 14-21-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03499, current rewards: 199.19106, mean: 0.10429
[32m[0906 14-21-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03498, current rewards: 205.95510, mean: 0.10508
[32m[0906 14-21-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03496, current rewards: 212.71914, mean: 0.10583
[32m[0906 14-21-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03495, current rewards: 219.48318, mean: 0.10655
[32m[0906 14-21-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03494, current rewards: 226.24722, mean: 0.10723
[32m[0906 14-21-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03493, current rewards: 233.01125, mean: 0.10788
[32m[0906 14-21-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03492, current rewards: 239.77529, mean: 0.10850
[32m[0906 14-21-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03490, current rewards: 246.53933, mean: 0.10909
[32m[0906 14-21-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03490, current rewards: 230.59775, mean: 0.09983
[32m[0906 14-21-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03491, current rewards: 180.59775, mean: 0.07652
[32m[0906 14-21-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03492, current rewards: 130.59775, mean: 0.05419
[32m[0906 14-21-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03493, current rewards: 80.59775, mean: 0.03276
[32m[0906 14-21-28 @Agent.py:117][0m Average action selection time: 0.0349
[32m[0906 14-21-28 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-21-28 @MBExp.py:227][0m Rewards obtained: [40.59775233888513], Lows: [4], Highs: [214], Total time: 1953.1903119999997
[32m[0906 14-22-15 @MBExp.py:144][0m ####################################################################
[32m[0906 14-22-15 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 14-22-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03419, current rewards: -1.99766, mean: -0.19977
[32m[0906 14-22-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03432, current rewards: 3.72619, mean: 0.06210
[32m[0906 14-22-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03437, current rewards: 9.31212, mean: 0.08466
[32m[0906 14-22-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03440, current rewards: 14.89428, mean: 0.09309
[32m[0906 14-22-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03443, current rewards: 20.47988, mean: 0.09752
[32m[0906 14-22-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03441, current rewards: 26.06732, mean: 0.10026
[32m[0906 14-22-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03439, current rewards: 31.51451, mean: 0.10166
[32m[0906 14-22-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03436, current rewards: 37.09083, mean: 0.10303
[32m[0906 14-22-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03438, current rewards: 42.67109, mean: 0.10408
[32m[0906 14-22-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03437, current rewards: 48.25349, mean: 0.10490
[32m[0906 14-22-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03438, current rewards: 53.83012, mean: 0.10555
[32m[0906 14-22-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03441, current rewards: 60.16122, mean: 0.10743
[32m[0906 14-22-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03450, current rewards: 65.79019, mean: 0.10785
[32m[0906 14-22-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03455, current rewards: 71.41551, mean: 0.10821
[32m[0906 14-22-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03461, current rewards: 77.25657, mean: 0.10881
[32m[0906 14-22-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03466, current rewards: 82.88340, mean: 0.10906
[32m[0906 14-22-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03471, current rewards: 88.51610, mean: 0.10928
[32m[0906 14-22-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03475, current rewards: 94.14617, mean: 0.10947
[32m[0906 14-22-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03479, current rewards: 99.77912, mean: 0.10965
[32m[0906 14-22-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03479, current rewards: 105.40141, mean: 0.10979
[32m[0906 14-22-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03476, current rewards: 111.02924, mean: 0.10993
[32m[0906 14-22-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03474, current rewards: 116.66135, mean: 0.11006
[32m[0906 14-22-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03474, current rewards: 120.35571, mean: 0.10843
[32m[0906 14-22-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03477, current rewards: 126.03349, mean: 0.10865
[32m[0906 14-22-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03479, current rewards: 131.70989, mean: 0.10885
[32m[0906 14-23-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03482, current rewards: 137.38763, mean: 0.10904
[32m[0906 14-23-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03484, current rewards: 143.06900, mean: 0.10921
[32m[0906 14-23-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03486, current rewards: 148.74668, mean: 0.10937
[32m[0906 14-23-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03488, current rewards: 154.42665, mean: 0.10952
[32m[0906 14-23-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03490, current rewards: 160.10667, mean: 0.10966
[32m[0906 14-23-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03492, current rewards: 165.76781, mean: 0.10978
[32m[0906 14-23-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03493, current rewards: 169.96349, mean: 0.10895
[32m[0906 14-23-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03494, current rewards: 175.40839, mean: 0.10895
[32m[0906 14-23-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03496, current rewards: 180.85330, mean: 0.10895
[32m[0906 14-23-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03497, current rewards: 186.29947, mean: 0.10895
[32m[0906 14-23-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03498, current rewards: 191.74472, mean: 0.10895
[32m[0906 14-23-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03496, current rewards: 197.19153, mean: 0.10895
[32m[0906 14-23-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03494, current rewards: 202.64220, mean: 0.10895
[32m[0906 14-23-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03493, current rewards: 208.09112, mean: 0.10895
[32m[0906 14-23-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03492, current rewards: 213.66623, mean: 0.10901
[32m[0906 14-23-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03491, current rewards: 217.15738, mean: 0.10804
[32m[0906 14-23-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03490, current rewards: 222.68744, mean: 0.10810
[32m[0906 14-23-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03489, current rewards: 228.21997, mean: 0.10816
[32m[0906 14-23-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03488, current rewards: 233.75374, mean: 0.10822
[32m[0906 14-23-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03487, current rewards: 239.28442, mean: 0.10827
[32m[0906 14-23-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03486, current rewards: 244.81548, mean: 0.10833
[32m[0906 14-23-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03487, current rewards: 250.34731, mean: 0.10838
[32m[0906 14-23-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03488, current rewards: 255.82591, mean: 0.10840
[32m[0906 14-23-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03489, current rewards: 261.33911, mean: 0.10844
[32m[0906 14-23-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03490, current rewards: 266.85064, mean: 0.10848
[32m[0906 14-23-43 @Agent.py:117][0m Average action selection time: 0.0349
[32m[0906 14-23-43 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-23-43 @MBExp.py:227][0m Rewards obtained: [271.2588677625287], Lows: [3], Highs: [2], Total time: 2041.0859359999997
[32m[0906 14-24-33 @MBExp.py:144][0m ####################################################################
[32m[0906 14-24-33 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 14-24-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03375, current rewards: 0.97998, mean: 0.09800
[32m[0906 14-24-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03428, current rewards: 6.83367, mean: 0.11389
[32m[0906 14-24-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03437, current rewards: 12.75288, mean: 0.11594
[32m[0906 14-24-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03439, current rewards: 18.67281, mean: 0.11671
[32m[0906 14-24-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03445, current rewards: 24.59261, mean: 0.11711
[32m[0906 14-24-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03442, current rewards: 30.51785, mean: 0.11738
[32m[0906 14-24-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03444, current rewards: 36.37861, mean: 0.11735
[32m[0906 14-24-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03441, current rewards: 40.89072, mean: 0.11359
[32m[0906 14-24-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03440, current rewards: 46.42800, mean: 0.11324
[32m[0906 14-24-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03442, current rewards: 51.96499, mean: 0.11297
[32m[0906 14-24-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03444, current rewards: 57.50478, mean: 0.11275
[32m[0906 14-24-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03447, current rewards: 63.03916, mean: 0.11257
[32m[0906 14-24-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03456, current rewards: 68.57263, mean: 0.11241
[32m[0906 14-24-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03461, current rewards: 74.11047, mean: 0.11229
[32m[0906 14-24-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03467, current rewards: 79.90088, mean: 0.11254
[32m[0906 14-24-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03472, current rewards: 85.46110, mean: 0.11245
[32m[0906 14-25-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03476, current rewards: 91.02820, mean: 0.11238
[32m[0906 14-25-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03478, current rewards: 96.59190, mean: 0.11232
[32m[0906 14-25-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03477, current rewards: 102.15540, mean: 0.11226
[32m[0906 14-25-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03476, current rewards: 107.72266, mean: 0.11221
[32m[0906 14-25-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03475, current rewards: 112.20396, mean: 0.11109
[32m[0906 14-25-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03473, current rewards: 117.77224, mean: 0.11111
[32m[0906 14-25-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03472, current rewards: 123.27684, mean: 0.11106
[32m[0906 14-25-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03472, current rewards: 128.84382, mean: 0.11107
[32m[0906 14-25-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03475, current rewards: 134.40410, mean: 0.11108
[32m[0906 14-25-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03477, current rewards: 139.96708, mean: 0.11108
[32m[0906 14-25-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03480, current rewards: 145.52995, mean: 0.11109
[32m[0906 14-25-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03483, current rewards: 151.09184, mean: 0.11110
[32m[0906 14-25-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03484, current rewards: 156.65690, mean: 0.11110
[32m[0906 14-25-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03486, current rewards: 162.21973, mean: 0.11111
[32m[0906 14-25-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03488, current rewards: 167.86470, mean: 0.11117
[32m[0906 14-25-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03490, current rewards: 173.47261, mean: 0.11120
[32m[0906 14-25-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03491, current rewards: 178.93981, mean: 0.11114
[32m[0906 14-25-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03493, current rewards: 184.45329, mean: 0.11112
[32m[0906 14-25-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03495, current rewards: 189.97207, mean: 0.11109
[32m[0906 14-25-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03495, current rewards: 193.43717, mean: 0.10991
[32m[0906 14-25-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03493, current rewards: 199.03090, mean: 0.10996
[32m[0906 14-25-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03492, current rewards: 204.62558, mean: 0.11001
[32m[0906 14-25-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03491, current rewards: 210.21421, mean: 0.11006
[32m[0906 14-25-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03490, current rewards: 215.73843, mean: 0.11007
[32m[0906 14-25-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03489, current rewards: 221.31664, mean: 0.11011
[32m[0906 14-25-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03488, current rewards: 226.89352, mean: 0.11014
[32m[0906 14-25-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03487, current rewards: 232.47574, mean: 0.11018
[32m[0906 14-25-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03487, current rewards: 238.05817, mean: 0.11021
[32m[0906 14-25-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03486, current rewards: 241.53560, mean: 0.10929
[32m[0906 14-25-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03485, current rewards: 247.12587, mean: 0.10935
[32m[0906 14-25-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03486, current rewards: 252.71828, mean: 0.10940
[32m[0906 14-25-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03487, current rewards: 258.21958, mean: 0.10942
[32m[0906 14-25-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03489, current rewards: 263.78985, mean: 0.10946
[32m[0906 14-25-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03490, current rewards: 269.36366, mean: 0.10950
[32m[0906 14-26-01 @Agent.py:117][0m Average action selection time: 0.0349
[32m[0906 14-26-01 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-26-01 @MBExp.py:227][0m Rewards obtained: [273.82025309754096], Lows: [2], Highs: [2], Total time: 2128.9836349999996
[32m[0906 14-26-52 @MBExp.py:144][0m ####################################################################
[32m[0906 14-26-52 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 14-26-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03363, current rewards: 0.04979, mean: 0.00498
[32m[0906 14-26-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03414, current rewards: 5.75276, mean: 0.09588
[32m[0906 14-26-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03433, current rewards: 11.46117, mean: 0.10419
[32m[0906 14-26-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03439, current rewards: 17.16335, mean: 0.10727
[32m[0906 14-26-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03443, current rewards: 20.77680, mean: 0.09894
[32m[0906 14-27-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03442, current rewards: 26.45322, mean: 0.10174
[32m[0906 14-27-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03441, current rewards: 32.08836, mean: 0.10351
[32m[0906 14-27-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03441, current rewards: 37.72176, mean: 0.10478
[32m[0906 14-27-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03442, current rewards: 43.35388, mean: 0.10574
[32m[0906 14-27-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03444, current rewards: 48.98748, mean: 0.10649
[32m[0906 14-27-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03445, current rewards: 54.62165, mean: 0.10710
[32m[0906 14-27-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03450, current rewards: 60.25551, mean: 0.10760
[32m[0906 14-27-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03458, current rewards: 65.88917, mean: 0.10802
[32m[0906 14-27-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03463, current rewards: 70.62293, mean: 0.10700
[32m[0906 14-27-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03469, current rewards: 76.49822, mean: 0.10774
[32m[0906 14-27-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03473, current rewards: 82.36970, mean: 0.10838
[32m[0906 14-27-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03472, current rewards: 88.24241, mean: 0.10894
[32m[0906 14-27-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03471, current rewards: 94.11148, mean: 0.10943
[32m[0906 14-27-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03470, current rewards: 99.98059, mean: 0.10987
[32m[0906 14-27-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03470, current rewards: 104.36677, mean: 0.10872
[32m[0906 14-27-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03467, current rewards: 110.28465, mean: 0.10919
[32m[0906 14-27-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03467, current rewards: 115.47313, mean: 0.10894
[32m[0906 14-27-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03465, current rewards: 120.95548, mean: 0.10897
[32m[0906 14-27-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03464, current rewards: 126.48665, mean: 0.10904
[32m[0906 14-27-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03463, current rewards: 132.01765, mean: 0.10911
[32m[0906 14-27-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03467, current rewards: 137.54982, mean: 0.10917
[32m[0906 14-27-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03469, current rewards: 143.08633, mean: 0.10923
[32m[0906 14-27-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03472, current rewards: 148.61874, mean: 0.10928
[32m[0906 14-27-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03473, current rewards: 154.15801, mean: 0.10933
[32m[0906 14-27-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03476, current rewards: 159.69198, mean: 0.10938
[32m[0906 14-27-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03479, current rewards: 165.40486, mean: 0.10954
[32m[0906 14-27-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03481, current rewards: 170.88480, mean: 0.10954
[32m[0906 14-27-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03483, current rewards: 174.30660, mean: 0.10826
[32m[0906 14-27-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03484, current rewards: 180.10550, mean: 0.10850
[32m[0906 14-27-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03486, current rewards: 185.90175, mean: 0.10871
[32m[0906 14-27-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03486, current rewards: 191.71167, mean: 0.10893
[32m[0906 14-27-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03484, current rewards: 195.41180, mean: 0.10796
[32m[0906 14-27-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03483, current rewards: 201.06242, mean: 0.10810
[32m[0906 14-27-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03482, current rewards: 206.71026, mean: 0.10823
[32m[0906 14-28-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03480, current rewards: 212.36081, mean: 0.10835
[32m[0906 14-28-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03480, current rewards: 218.00638, mean: 0.10846
[32m[0906 14-28-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03479, current rewards: 223.65647, mean: 0.10857
[32m[0906 14-28-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03478, current rewards: 229.31067, mean: 0.10868
[32m[0906 14-28-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03478, current rewards: 234.94485, mean: 0.10877
[32m[0906 14-28-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03477, current rewards: 240.78239, mean: 0.10895
[32m[0906 14-28-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03478, current rewards: 246.61175, mean: 0.10912
[32m[0906 14-28-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03479, current rewards: 252.31360, mean: 0.10923
[32m[0906 14-28-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03481, current rewards: 258.06185, mean: 0.10935
[32m[0906 14-28-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03482, current rewards: 263.81001, mean: 0.10946
[32m[0906 14-28-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03483, current rewards: 269.55394, mean: 0.10957
[32m[0906 14-28-20 @Agent.py:117][0m Average action selection time: 0.0348
[32m[0906 14-28-20 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-28-20 @MBExp.py:227][0m Rewards obtained: [274.145301173955], Lows: [3], Highs: [4], Total time: 2216.7273929999997
[32m[0906 14-29-13 @MBExp.py:144][0m ####################################################################
[32m[0906 14-29-13 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 14-29-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03439, current rewards: -1.04535, mean: -0.10454
[32m[0906 14-29-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03458, current rewards: 4.50827, mean: 0.07514
[32m[0906 14-29-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03451, current rewards: 10.02687, mean: 0.09115
[32m[0906 14-29-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03445, current rewards: 15.54334, mean: 0.09715
[32m[0906 14-29-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03442, current rewards: 21.02330, mean: 0.10011
[32m[0906 14-29-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03446, current rewards: 26.43365, mean: 0.10167
[32m[0906 14-29-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03442, current rewards: 31.93901, mean: 0.10303
[32m[0906 14-29-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03444, current rewards: 37.43921, mean: 0.10400
[32m[0906 14-29-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03445, current rewards: 42.93200, mean: 0.10471
[32m[0906 14-29-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03447, current rewards: 48.43397, mean: 0.10529
[32m[0906 14-29-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03446, current rewards: 53.93415, mean: 0.10575
[32m[0906 14-29-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03452, current rewards: 58.34747, mean: 0.10419
[32m[0906 14-29-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03458, current rewards: 63.87415, mean: 0.10471
[32m[0906 14-29-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03465, current rewards: 69.32980, mean: 0.10505
[32m[0906 14-29-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03466, current rewards: 74.86489, mean: 0.10544
[32m[0906 14-29-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03466, current rewards: 80.39389, mean: 0.10578
[32m[0906 14-29-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03465, current rewards: 85.92613, mean: 0.10608
[32m[0906 14-29-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03463, current rewards: 91.44704, mean: 0.10633
[32m[0906 14-29-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03463, current rewards: 96.97794, mean: 0.10657
[32m[0906 14-29-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03462, current rewards: 102.50848, mean: 0.10678
[32m[0906 14-29-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03461, current rewards: 108.03678, mean: 0.10697
[32m[0906 14-29-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03460, current rewards: 113.66463, mean: 0.10723
[32m[0906 14-29-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03460, current rewards: 119.18627, mean: 0.10738
[32m[0906 14-29-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03460, current rewards: 124.70500, mean: 0.10750
[32m[0906 14-29-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03460, current rewards: 130.23085, mean: 0.10763
[32m[0906 14-29-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03459, current rewards: 135.71164, mean: 0.10771
[32m[0906 14-29-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03462, current rewards: 141.18704, mean: 0.10778
[32m[0906 14-30-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03466, current rewards: 146.66098, mean: 0.10784
[32m[0906 14-30-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03468, current rewards: 152.13879, mean: 0.10790
[32m[0906 14-30-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03470, current rewards: 157.57561, mean: 0.10793
[32m[0906 14-30-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03473, current rewards: 163.04877, mean: 0.10798
[32m[0906 14-30-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03475, current rewards: 168.52195, mean: 0.10803
[32m[0906 14-30-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03477, current rewards: 174.00306, mean: 0.10808
[32m[0906 14-30-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03478, current rewards: 179.48748, mean: 0.10812
[32m[0906 14-30-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03480, current rewards: 184.96725, mean: 0.10817
[32m[0906 14-30-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03480, current rewards: 190.44048, mean: 0.10820
[32m[0906 14-30-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03479, current rewards: 195.91742, mean: 0.10824
[32m[0906 14-30-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03478, current rewards: 201.45470, mean: 0.10831
[32m[0906 14-30-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03478, current rewards: 206.94755, mean: 0.10835
[32m[0906 14-30-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03477, current rewards: 212.42317, mean: 0.10838
[32m[0906 14-30-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03476, current rewards: 215.78459, mean: 0.10736
[32m[0906 14-30-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03475, current rewards: 221.27176, mean: 0.10741
[32m[0906 14-30-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03475, current rewards: 226.76032, mean: 0.10747
[32m[0906 14-30-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03474, current rewards: 232.24605, mean: 0.10752
[32m[0906 14-30-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03474, current rewards: 237.73223, mean: 0.10757
[32m[0906 14-30-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03474, current rewards: 243.22496, mean: 0.10762
[32m[0906 14-30-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03476, current rewards: 248.78722, mean: 0.10770
[32m[0906 14-30-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03478, current rewards: 254.26904, mean: 0.10774
[32m[0906 14-30-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03479, current rewards: 259.75769, mean: 0.10778
[32m[0906 14-30-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03480, current rewards: 265.24568, mean: 0.10782
[32m[0906 14-30-41 @Agent.py:117][0m Average action selection time: 0.0348
[32m[0906 14-30-41 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-30-41 @MBExp.py:227][0m Rewards obtained: [269.64127037655203], Lows: [1], Highs: [3], Total time: 2304.3972369999997
[32m[0906 14-31-36 @MBExp.py:144][0m ####################################################################
[32m[0906 14-31-36 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 14-31-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03366, current rewards: -1.01508, mean: -0.10151
[32m[0906 14-31-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03413, current rewards: 4.58697, mean: 0.07645
[32m[0906 14-31-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03423, current rewards: 10.14355, mean: 0.09221
[32m[0906 14-31-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03429, current rewards: 15.69099, mean: 0.09807
[32m[0906 14-31-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03434, current rewards: 21.10777, mean: 0.10051
[32m[0906 14-31-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03437, current rewards: 26.62961, mean: 0.10242
[32m[0906 14-31-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03439, current rewards: 32.15337, mean: 0.10372
[32m[0906 14-31-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03437, current rewards: 37.67711, mean: 0.10466
[32m[0906 14-31-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03439, current rewards: 43.20332, mean: 0.10537
[32m[0906 14-31-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03439, current rewards: 46.58103, mean: 0.10126
[32m[0906 14-31-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03441, current rewards: 52.14865, mean: 0.10225
[32m[0906 14-31-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03449, current rewards: 57.71893, mean: 0.10307
[32m[0906 14-31-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03455, current rewards: 63.26563, mean: 0.10371
[32m[0906 14-31-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03454, current rewards: 68.82958, mean: 0.10429
[32m[0906 14-32-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03454, current rewards: 74.39577, mean: 0.10478
[32m[0906 14-32-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03453, current rewards: 79.96842, mean: 0.10522
[32m[0906 14-32-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03452, current rewards: 85.53580, mean: 0.10560
[32m[0906 14-32-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03453, current rewards: 91.10418, mean: 0.10594
[32m[0906 14-32-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03451, current rewards: 96.67383, mean: 0.10623
[32m[0906 14-32-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03450, current rewards: 102.24467, mean: 0.10650
[32m[0906 14-32-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03450, current rewards: 107.79290, mean: 0.10673
[32m[0906 14-32-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03450, current rewards: 113.36762, mean: 0.10695
[32m[0906 14-32-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03450, current rewards: 118.93253, mean: 0.10715
[32m[0906 14-32-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03450, current rewards: 124.50174, mean: 0.10733
[32m[0906 14-32-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03449, current rewards: 127.91617, mean: 0.10572
[32m[0906 14-32-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03449, current rewards: 133.54083, mean: 0.10598
[32m[0906 14-32-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03449, current rewards: 139.16142, mean: 0.10623
[32m[0906 14-32-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03451, current rewards: 144.77732, mean: 0.10645
[32m[0906 14-32-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03454, current rewards: 150.40565, mean: 0.10667
[32m[0906 14-32-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03456, current rewards: 156.42503, mean: 0.10714
[32m[0906 14-32-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03459, current rewards: 162.19194, mean: 0.10741
[32m[0906 14-32-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03462, current rewards: 167.95960, mean: 0.10767
[32m[0906 14-32-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03464, current rewards: 173.72705, mean: 0.10791
[32m[0906 14-32-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03466, current rewards: 179.49453, mean: 0.10813
[32m[0906 14-32-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03468, current rewards: 185.26326, mean: 0.10834
[32m[0906 14-32-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03466, current rewards: 189.76525, mean: 0.10782
[32m[0906 14-32-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03466, current rewards: 195.39114, mean: 0.10795
[32m[0906 14-32-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03465, current rewards: 200.94521, mean: 0.10804
[32m[0906 14-32-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03465, current rewards: 206.55791, mean: 0.10815
[32m[0906 14-32-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03464, current rewards: 212.17114, mean: 0.10825
[32m[0906 14-32-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03464, current rewards: 217.78353, mean: 0.10835
[32m[0906 14-32-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03464, current rewards: 223.39777, mean: 0.10845
[32m[0906 14-32-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03464, current rewards: 229.01447, mean: 0.10854
[32m[0906 14-32-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03464, current rewards: 234.62737, mean: 0.10862
[32m[0906 14-32-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03464, current rewards: 240.24192, mean: 0.10871
[32m[0906 14-32-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03465, current rewards: 246.00172, mean: 0.10885
[32m[0906 14-32-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03467, current rewards: 250.56265, mean: 0.10847
[32m[0906 14-32-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03469, current rewards: 256.18839, mean: 0.10855
[32m[0906 14-33-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03470, current rewards: 261.81523, mean: 0.10864
[32m[0906 14-33-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03472, current rewards: 266.42377, mean: 0.10830
[32m[0906 14-33-04 @Agent.py:117][0m Average action selection time: 0.0347
[32m[0906 14-33-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-33-04 @MBExp.py:227][0m Rewards obtained: [270.814517865726], Lows: [2], Highs: [5], Total time: 2391.8519109999997
[32m[0906 14-34-02 @MBExp.py:144][0m ####################################################################
[32m[0906 14-34-02 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 14-34-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03511, current rewards: -1.07476, mean: -0.10748
[32m[0906 14-34-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03441, current rewards: 4.50423, mean: 0.07507
[32m[0906 14-34-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03440, current rewards: 10.07602, mean: 0.09160
[32m[0906 14-34-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03436, current rewards: 15.68401, mean: 0.09803
[32m[0906 14-34-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03434, current rewards: 21.34607, mean: 0.10165
[32m[0906 14-34-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03433, current rewards: 26.91648, mean: 0.10352
[32m[0906 14-34-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03432, current rewards: 32.48772, mean: 0.10480
[32m[0906 14-34-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03431, current rewards: 38.06502, mean: 0.10574
[32m[0906 14-34-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03432, current rewards: 43.63875, mean: 0.10644
[32m[0906 14-34-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03433, current rewards: 49.21991, mean: 0.10700
[32m[0906 14-34-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03438, current rewards: 54.79810, mean: 0.10745
[32m[0906 14-34-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03441, current rewards: 60.37630, mean: 0.10781
[32m[0906 14-34-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03440, current rewards: 66.04276, mean: 0.10827
[32m[0906 14-34-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03440, current rewards: 69.57323, mean: 0.10541
[32m[0906 14-34-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03441, current rewards: 75.14208, mean: 0.10583
[32m[0906 14-34-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03441, current rewards: 80.71549, mean: 0.10620
[32m[0906 14-34-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03441, current rewards: 86.28119, mean: 0.10652
[32m[0906 14-34-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03442, current rewards: 91.85540, mean: 0.10681
[32m[0906 14-34-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03442, current rewards: 97.42438, mean: 0.10706
[32m[0906 14-34-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03442, current rewards: 99.12244, mean: 0.10325
[32m[0906 14-34-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03442, current rewards: 106.10187, mean: 0.10505
[32m[0906 14-34-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03443, current rewards: 114.40199, mean: 0.10793
[32m[0906 14-34-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03442, current rewards: 122.70211, mean: 0.11054
[32m[0906 14-34-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03442, current rewards: 131.00223, mean: 0.11293
[32m[0906 14-34-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03442, current rewards: 139.30235, mean: 0.11513
[32m[0906 14-34-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03442, current rewards: 147.60247, mean: 0.11714
[32m[0906 14-34-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03442, current rewards: 155.90259, mean: 0.11901
[32m[0906 14-34-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03442, current rewards: 164.20271, mean: 0.12074
[32m[0906 14-34-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03447, current rewards: 149.14581, mean: 0.10578
[32m[0906 14-34-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03450, current rewards: 99.14581, mean: 0.06791
[32m[0906 14-34-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03453, current rewards: 49.14581, mean: 0.03255
[32m[0906 14-34-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03455, current rewards: -0.85419, mean: -0.00055
[32m[0906 14-34-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03457, current rewards: -50.85419, mean: -0.03159
[32m[0906 14-34-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03459, current rewards: -100.85419, mean: -0.06076
[32m[0906 14-35-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03460, current rewards: -150.85419, mean: -0.08822
[32m[0906 14-35-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03459, current rewards: -200.85419, mean: -0.11412
[32m[0906 14-35-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03459, current rewards: -250.85419, mean: -0.13859
[32m[0906 14-35-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03459, current rewards: -300.85419, mean: -0.16175
[32m[0906 14-35-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03458, current rewards: -350.85419, mean: -0.18369
[32m[0906 14-35-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03457, current rewards: -400.85419, mean: -0.20452
[32m[0906 14-35-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03457, current rewards: -450.85419, mean: -0.22431
[32m[0906 14-35-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03457, current rewards: -500.85419, mean: -0.24313
[32m[0906 14-35-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03456, current rewards: -550.85419, mean: -0.26107
[32m[0906 14-35-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03456, current rewards: -600.85419, mean: -0.27817
[32m[0906 14-35-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03457, current rewards: -650.85419, mean: -0.29450
[32m[0906 14-35-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03459, current rewards: -700.85419, mean: -0.31011
[32m[0906 14-35-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03460, current rewards: -750.85419, mean: -0.32505
[32m[0906 14-35-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03462, current rewards: -800.85419, mean: -0.33934
[32m[0906 14-35-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03464, current rewards: -850.85419, mean: -0.35305
[32m[0906 14-35-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03465, current rewards: -900.85419, mean: -0.36620
[32m[0906 14-35-29 @Agent.py:117][0m Average action selection time: 0.0347
[32m[0906 14-35-29 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-35-29 @MBExp.py:227][0m Rewards obtained: [-940.854188250644], Lows: [3], Highs: [1112], Total time: 2479.1671279999996
[32m[0906 14-36-29 @MBExp.py:144][0m ####################################################################
[32m[0906 14-36-29 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 14-36-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03423, current rewards: -0.08724, mean: -0.00872
[32m[0906 14-36-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03441, current rewards: 5.47572, mean: 0.09126
[32m[0906 14-36-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03444, current rewards: 11.04359, mean: 0.10040
[32m[0906 14-36-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03446, current rewards: 16.63209, mean: 0.10395
[32m[0906 14-36-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03447, current rewards: 22.20335, mean: 0.10573
[32m[0906 14-36-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03445, current rewards: 27.77511, mean: 0.10683
[32m[0906 14-36-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03445, current rewards: 33.34564, mean: 0.10757
[32m[0906 14-36-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03445, current rewards: 38.91927, mean: 0.10811
[32m[0906 14-36-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03446, current rewards: 44.48889, mean: 0.10851
[32m[0906 14-36-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03439, current rewards: 49.05928, mean: 0.10665
[32m[0906 14-36-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03438, current rewards: 54.55424, mean: 0.10697
[32m[0906 14-36-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03439, current rewards: 59.97773, mean: 0.10710
[32m[0906 14-36-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03441, current rewards: 65.42868, mean: 0.10726
[32m[0906 14-36-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03442, current rewards: 70.88855, mean: 0.10741
[32m[0906 14-36-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03442, current rewards: 76.34271, mean: 0.10752
[32m[0906 14-36-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03442, current rewards: 81.79861, mean: 0.10763
[32m[0906 14-36-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03442, current rewards: 87.25524, mean: 0.10772
[32m[0906 14-36-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03441, current rewards: 92.71268, mean: 0.10781
[32m[0906 14-37-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03441, current rewards: 98.16239, mean: 0.10787
[32m[0906 14-37-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03441, current rewards: 103.84428, mean: 0.10817
[32m[0906 14-37-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03443, current rewards: 109.41770, mean: 0.10833
[32m[0906 14-37-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03443, current rewards: 114.99555, mean: 0.10849
[32m[0906 14-37-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03444, current rewards: 118.48420, mean: 0.10674
[32m[0906 14-37-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03444, current rewards: 124.09769, mean: 0.10698
[32m[0906 14-37-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03444, current rewards: 129.71233, mean: 0.10720
[32m[0906 14-37-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03445, current rewards: 135.32702, mean: 0.10740
[32m[0906 14-37-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03445, current rewards: 140.87734, mean: 0.10754
[32m[0906 14-37-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03445, current rewards: 146.39914, mean: 0.10765
[32m[0906 14-37-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03445, current rewards: 151.86886, mean: 0.10771
[32m[0906 14-37-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03449, current rewards: 157.42824, mean: 0.10783
[32m[0906 14-37-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03451, current rewards: 162.97942, mean: 0.10793
[32m[0906 14-37-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03455, current rewards: 168.52926, mean: 0.10803
[32m[0906 14-37-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03457, current rewards: 174.08073, mean: 0.10812
[32m[0906 14-37-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03459, current rewards: 179.63634, mean: 0.10821
[32m[0906 14-37-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03460, current rewards: 185.18985, mean: 0.10830
[32m[0906 14-37-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03460, current rewards: 190.74682, mean: 0.10838
[32m[0906 14-37-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03459, current rewards: 196.27038, mean: 0.10844
[32m[0906 14-37-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03459, current rewards: 201.81979, mean: 0.10851
[32m[0906 14-37-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03458, current rewards: 207.37627, mean: 0.10857
[32m[0906 14-37-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03458, current rewards: 212.93076, mean: 0.10864
[32m[0906 14-37-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03458, current rewards: 216.27367, mean: 0.10760
[32m[0906 14-37-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03457, current rewards: 221.81819, mean: 0.10768
[32m[0906 14-37-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03458, current rewards: 227.35190, mean: 0.10775
[32m[0906 14-37-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03457, current rewards: 232.88380, mean: 0.10782
[32m[0906 14-37-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03459, current rewards: 238.53153, mean: 0.10793
[32m[0906 14-37-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03460, current rewards: 244.05004, mean: 0.10799
[32m[0906 14-37-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03462, current rewards: 249.56807, mean: 0.10804
[32m[0906 14-37-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03464, current rewards: 255.08938, mean: 0.10809
[32m[0906 14-37-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03466, current rewards: 260.60571, mean: 0.10814
[32m[0906 14-37-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03467, current rewards: 263.92760, mean: 0.10729
[32m[0906 14-37-56 @Agent.py:117][0m Average action selection time: 0.0347
[32m[0906 14-37-56 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-37-56 @MBExp.py:227][0m Rewards obtained: [268.3895464796443], Lows: [2], Highs: [4], Total time: 2566.5195479999998
[32m[0906 14-38-58 @MBExp.py:144][0m ####################################################################
[32m[0906 14-38-58 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 14-38-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03428, current rewards: -0.13534, mean: -0.01353
[32m[0906 14-39-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03452, current rewards: 5.28412, mean: 0.08807
[32m[0906 14-39-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03453, current rewards: 10.85814, mean: 0.09871
[32m[0906 14-39-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03448, current rewards: 16.51548, mean: 0.10322
[32m[0906 14-39-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03449, current rewards: 22.08908, mean: 0.10519
[32m[0906 14-39-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03448, current rewards: 27.66038, mean: 0.10639
[32m[0906 14-39-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03453, current rewards: 33.23150, mean: 0.10720
[32m[0906 14-39-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03452, current rewards: 38.80528, mean: 0.10779
[32m[0906 14-39-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03440, current rewards: 44.38001, mean: 0.10824
[32m[0906 14-39-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03431, current rewards: 49.95363, mean: 0.10859
[32m[0906 14-39-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03433, current rewards: 51.38769, mean: 0.10076
[32m[0906 14-39-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03434, current rewards: 57.04465, mean: 0.10187
[32m[0906 14-39-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03435, current rewards: 62.78698, mean: 0.10293
[32m[0906 14-39-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03436, current rewards: 68.53082, mean: 0.10383
[32m[0906 14-39-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03437, current rewards: 74.27426, mean: 0.10461
[32m[0906 14-39-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03438, current rewards: 80.01276, mean: 0.10528
[32m[0906 14-39-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03437, current rewards: 85.74355, mean: 0.10586
[32m[0906 14-39-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03439, current rewards: 91.48358, mean: 0.10638
[32m[0906 14-39-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03439, current rewards: 97.22478, mean: 0.10684
[32m[0906 14-39-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03438, current rewards: 101.76944, mean: 0.10601
[32m[0906 14-39-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03439, current rewards: 107.30795, mean: 0.10625
[32m[0906 14-39-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03439, current rewards: 112.85318, mean: 0.10647
[32m[0906 14-39-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03439, current rewards: 118.39340, mean: 0.10666
[32m[0906 14-39-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03439, current rewards: 123.93755, mean: 0.10684
[32m[0906 14-39-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03439, current rewards: 129.47954, mean: 0.10701
[32m[0906 14-39-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03439, current rewards: 135.02106, mean: 0.10716
[32m[0906 14-39-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03439, current rewards: 140.56441, mean: 0.10730
[32m[0906 14-39-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03440, current rewards: 146.03952, mean: 0.10738
[32m[0906 14-39-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03440, current rewards: 151.59627, mean: 0.10752
[32m[0906 14-39-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03441, current rewards: 157.14884, mean: 0.10764
[32m[0906 14-39-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03444, current rewards: 162.69731, mean: 0.10775
[32m[0906 14-39-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03447, current rewards: 168.24857, mean: 0.10785
[32m[0906 14-39-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03450, current rewards: 173.80332, mean: 0.10795
[32m[0906 14-39-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03452, current rewards: 179.35506, mean: 0.10805
[32m[0906 14-39-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03453, current rewards: 183.94977, mean: 0.10757
[32m[0906 14-39-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03453, current rewards: 189.55375, mean: 0.10770
[32m[0906 14-40-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03453, current rewards: 195.11833, mean: 0.10780
[32m[0906 14-40-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03452, current rewards: 200.66938, mean: 0.10789
[32m[0906 14-40-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03453, current rewards: 206.22422, mean: 0.10797
[32m[0906 14-40-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03452, current rewards: 211.76730, mean: 0.10804
[32m[0906 14-40-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03453, current rewards: 217.32235, mean: 0.10812
[32m[0906 14-40-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03453, current rewards: 222.87095, mean: 0.10819
[32m[0906 14-40-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03452, current rewards: 226.41256, mean: 0.10730
[32m[0906 14-40-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03453, current rewards: 232.05075, mean: 0.10743
[32m[0906 14-40-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03455, current rewards: 237.71075, mean: 0.10756
[32m[0906 14-40-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03457, current rewards: 243.32900, mean: 0.10767
[32m[0906 14-40-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03459, current rewards: 248.94494, mean: 0.10777
[32m[0906 14-40-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03461, current rewards: 254.56507, mean: 0.10787
[32m[0906 14-40-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03462, current rewards: 260.18225, mean: 0.10796
[32m[0906 14-40-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03464, current rewards: 265.79491, mean: 0.10805
[32m[0906 14-40-25 @Agent.py:117][0m Average action selection time: 0.0347
[32m[0906 14-40-25 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-40-25 @MBExp.py:227][0m Rewards obtained: [270.2856494120956], Lows: [3], Highs: [3], Total time: 2653.7946209999996
[32m[0906 14-41-29 @MBExp.py:144][0m ####################################################################
[32m[0906 14-41-29 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 14-41-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03519, current rewards: -1.02434, mean: -0.10243
[32m[0906 14-41-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03435, current rewards: 4.63782, mean: 0.07730
[32m[0906 14-41-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03441, current rewards: 10.05594, mean: 0.09142
[32m[0906 14-41-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03447, current rewards: 15.61380, mean: 0.09759
[32m[0906 14-41-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03445, current rewards: 21.17089, mean: 0.10081
[32m[0906 14-41-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03445, current rewards: 26.72593, mean: 0.10279
[32m[0906 14-41-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03434, current rewards: 32.27955, mean: 0.10413
[32m[0906 14-41-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03422, current rewards: 37.83362, mean: 0.10509
[32m[0906 14-41-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03414, current rewards: 43.38475, mean: 0.10582
[32m[0906 14-41-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03410, current rewards: 48.93823, mean: 0.10639
[32m[0906 14-41-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03412, current rewards: 54.47625, mean: 0.10682
[32m[0906 14-41-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03414, current rewards: 60.03438, mean: 0.10720
[32m[0906 14-41-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03419, current rewards: 65.58197, mean: 0.10751
[32m[0906 14-41-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03421, current rewards: 71.07972, mean: 0.10770
[32m[0906 14-41-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03423, current rewards: 76.60907, mean: 0.10790
[32m[0906 14-41-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03424, current rewards: 82.14132, mean: 0.10808
[32m[0906 14-41-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03426, current rewards: 87.68326, mean: 0.10825
[32m[0906 14-41-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03426, current rewards: 93.22162, mean: 0.10840
[32m[0906 14-42-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03427, current rewards: 98.75357, mean: 0.10852
[32m[0906 14-42-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03429, current rewards: 104.51492, mean: 0.10887
[32m[0906 14-42-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03430, current rewards: 110.06235, mean: 0.10897
[32m[0906 14-42-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03431, current rewards: 115.61038, mean: 0.10907
[32m[0906 14-42-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03433, current rewards: 121.15866, mean: 0.10915
[32m[0906 14-42-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03435, current rewards: 126.70538, mean: 0.10923
[32m[0906 14-42-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03435, current rewards: 132.25276, mean: 0.10930
[32m[0906 14-42-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03436, current rewards: 137.79644, mean: 0.10936
[32m[0906 14-42-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03437, current rewards: 143.31001, mean: 0.10940
[32m[0906 14-42-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03437, current rewards: 148.65639, mean: 0.10931
[32m[0906 14-42-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03437, current rewards: 154.11730, mean: 0.10930
[32m[0906 14-42-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03438, current rewards: 159.59699, mean: 0.10931
[32m[0906 14-42-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03438, current rewards: 165.07349, mean: 0.10932
[32m[0906 14-42-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03441, current rewards: 170.55165, mean: 0.10933
[32m[0906 14-42-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03445, current rewards: 176.03125, mean: 0.10934
[32m[0906 14-42-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03448, current rewards: 181.50906, mean: 0.10934
[32m[0906 14-42-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03448, current rewards: 186.98731, mean: 0.10935
[32m[0906 14-42-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03448, current rewards: 192.45463, mean: 0.10935
[32m[0906 14-42-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03449, current rewards: 198.08350, mean: 0.10944
[32m[0906 14-42-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03448, current rewards: 203.58059, mean: 0.10945
[32m[0906 14-42-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03449, current rewards: 206.97790, mean: 0.10837
[32m[0906 14-42-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03449, current rewards: 209.56427, mean: 0.10692
[32m[0906 14-42-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03449, current rewards: 214.25004, mean: 0.10659
[32m[0906 14-42-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03448, current rewards: 218.93599, mean: 0.10628
[32m[0906 14-42-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03448, current rewards: 223.62464, mean: 0.10598
[32m[0906 14-42-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03450, current rewards: 228.30916, mean: 0.10570
[32m[0906 14-42-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03452, current rewards: 232.97337, mean: 0.10542
[32m[0906 14-42-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03454, current rewards: 237.10959, mean: 0.10492
[32m[0906 14-42-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03456, current rewards: 242.66840, mean: 0.10505
[32m[0906 14-42-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03458, current rewards: 248.22786, mean: 0.10518
[32m[0906 14-42-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03459, current rewards: 253.78442, mean: 0.10530
[32m[0906 14-42-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03461, current rewards: 259.34348, mean: 0.10542
[32m[0906 14-42-56 @Agent.py:117][0m Average action selection time: 0.0346
[32m[0906 14-42-56 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-42-56 @MBExp.py:227][0m Rewards obtained: [262.67328404123026], Lows: [2], Highs: [4], Total time: 2740.9892269999996
[32m[0906 14-44-02 @MBExp.py:144][0m ####################################################################
[32m[0906 14-44-02 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 14-44-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03388, current rewards: -0.10899, mean: -0.01090
[32m[0906 14-44-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03442, current rewards: 5.43209, mean: 0.09053
[32m[0906 14-44-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03451, current rewards: 11.10388, mean: 0.10094
[32m[0906 14-44-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03444, current rewards: 16.74665, mean: 0.10467
[32m[0906 14-44-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03436, current rewards: 22.33952, mean: 0.10638
[32m[0906 14-44-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03423, current rewards: 27.93390, mean: 0.10744
[32m[0906 14-44-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03412, current rewards: 33.52432, mean: 0.10814
[32m[0906 14-44-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03405, current rewards: 39.12185, mean: 0.10867
[32m[0906 14-44-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03399, current rewards: 44.71869, mean: 0.10907
[32m[0906 14-44-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03395, current rewards: 50.31099, mean: 0.10937
[32m[0906 14-44-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03401, current rewards: 55.90154, mean: 0.10961
[32m[0906 14-44-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03405, current rewards: 59.10491, mean: 0.10554
[32m[0906 14-44-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03409, current rewards: 64.67000, mean: 0.10602
[32m[0906 14-44-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03414, current rewards: 70.23278, mean: 0.10641
[32m[0906 14-44-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03417, current rewards: 75.79370, mean: 0.10675
[32m[0906 14-44-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03420, current rewards: 81.36379, mean: 0.10706
[32m[0906 14-44-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03422, current rewards: 86.92523, mean: 0.10732
[32m[0906 14-44-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03423, current rewards: 92.48457, mean: 0.10754
[32m[0906 14-44-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03425, current rewards: 98.04721, mean: 0.10774
[32m[0906 14-44-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03427, current rewards: 103.60938, mean: 0.10793
[32m[0906 14-44-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03428, current rewards: 109.17777, mean: 0.10810
[32m[0906 14-44-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03429, current rewards: 114.74499, mean: 0.10825
[32m[0906 14-44-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03430, current rewards: 120.30587, mean: 0.10838
[32m[0906 14-44-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03430, current rewards: 125.86574, mean: 0.10850
[32m[0906 14-44-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03432, current rewards: 131.43190, mean: 0.10862
[32m[0906 14-44-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03433, current rewards: 136.99084, mean: 0.10872
[32m[0906 14-44-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03434, current rewards: 142.55497, mean: 0.10882
[32m[0906 14-44-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03435, current rewards: 146.14010, mean: 0.10746
[32m[0906 14-44-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03435, current rewards: 151.60351, mean: 0.10752
[32m[0906 14-44-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03436, current rewards: 157.06228, mean: 0.10758
[32m[0906 14-44-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03436, current rewards: 162.52269, mean: 0.10763
[32m[0906 14-44-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03437, current rewards: 167.98096, mean: 0.10768
[32m[0906 14-44-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03440, current rewards: 173.44237, mean: 0.10773
[32m[0906 14-44-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03442, current rewards: 178.90128, mean: 0.10777
[32m[0906 14-45-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03443, current rewards: 184.36252, mean: 0.10781
[32m[0906 14-45-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03446, current rewards: 189.83189, mean: 0.10786
[32m[0906 14-45-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03449, current rewards: 195.28999, mean: 0.10790
[32m[0906 14-45-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03452, current rewards: 200.74837, mean: 0.10793
[32m[0906 14-45-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03456, current rewards: 205.09266, mean: 0.10738
[32m[0906 14-45-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03459, current rewards: 210.63366, mean: 0.10747
[32m[0906 14-45-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03462, current rewards: 216.17635, mean: 0.10755
[32m[0906 14-45-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03465, current rewards: 221.71692, mean: 0.10763
[32m[0906 14-45-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03467, current rewards: 227.25123, mean: 0.10770
[32m[0906 14-45-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03471, current rewards: 232.83789, mean: 0.10780
[32m[0906 14-45-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03474, current rewards: 238.46892, mean: 0.10790
[32m[0906 14-45-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03475, current rewards: 244.02268, mean: 0.10797
[32m[0906 14-45-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03477, current rewards: 247.63413, mean: 0.10720
[32m[0906 14-45-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03478, current rewards: 253.20695, mean: 0.10729
[32m[0906 14-45-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03480, current rewards: 258.78242, mean: 0.10738
[32m[0906 14-45-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03481, current rewards: 264.35733, mean: 0.10746
[32m[0906 14-45-29 @Agent.py:117][0m Average action selection time: 0.0348
[32m[0906 14-45-29 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-45-29 @MBExp.py:227][0m Rewards obtained: [268.8192914211563], Lows: [3], Highs: [2], Total time: 2828.6873409999994
[32m[0906 14-46-37 @MBExp.py:144][0m ####################################################################
[32m[0906 14-46-37 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 14-46-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03393, current rewards: -1.08612, mean: -0.10861
[32m[0906 14-46-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03423, current rewards: 4.64685, mean: 0.07745
[32m[0906 14-46-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03428, current rewards: 10.62046, mean: 0.09655
[32m[0906 14-46-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03402, current rewards: 16.42699, mean: 0.10267
[32m[0906 14-46-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03389, current rewards: 22.23472, mean: 0.10588
[32m[0906 14-46-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03387, current rewards: 28.04566, mean: 0.10787
[32m[0906 14-46-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03382, current rewards: 33.84829, mean: 0.10919
[32m[0906 14-46-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03380, current rewards: 39.65331, mean: 0.11015
[32m[0906 14-46-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03376, current rewards: 45.46226, mean: 0.11088
[32m[0906 14-46-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03372, current rewards: 51.21107, mean: 0.11133
[32m[0906 14-46-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03378, current rewards: 56.89815, mean: 0.11157
[32m[0906 14-46-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03383, current rewards: 62.65204, mean: 0.11188
[32m[0906 14-46-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03388, current rewards: 68.40353, mean: 0.11214
[32m[0906 14-47-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03391, current rewards: 74.15185, mean: 0.11235
[32m[0906 14-47-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03395, current rewards: 79.90009, mean: 0.11254
[32m[0906 14-47-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03398, current rewards: 85.62120, mean: 0.11266
[32m[0906 14-47-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03401, current rewards: 91.30481, mean: 0.11272
[32m[0906 14-47-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03403, current rewards: 96.99417, mean: 0.11278
[32m[0906 14-47-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03405, current rewards: 102.70512, mean: 0.11286
[32m[0906 14-47-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03407, current rewards: 108.42641, mean: 0.11294
[32m[0906 14-47-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03409, current rewards: 109.92168, mean: 0.10883
[32m[0906 14-47-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03410, current rewards: 115.62260, mean: 0.10908
[32m[0906 14-47-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03411, current rewards: 121.32329, mean: 0.10930
[32m[0906 14-47-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03413, current rewards: 127.02422, mean: 0.10950
[32m[0906 14-47-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03414, current rewards: 132.72463, mean: 0.10969
[32m[0906 14-47-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03415, current rewards: 138.42459, mean: 0.10986
[32m[0906 14-47-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03416, current rewards: 144.12582, mean: 0.11002
[32m[0906 14-47-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03417, current rewards: 149.78635, mean: 0.11014
[32m[0906 14-47-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03418, current rewards: 153.21695, mean: 0.10866
[32m[0906 14-47-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03419, current rewards: 158.83952, mean: 0.10879
[32m[0906 14-47-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03420, current rewards: 164.46635, mean: 0.10892
[32m[0906 14-47-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03420, current rewards: 170.08820, mean: 0.10903
[32m[0906 14-47-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03421, current rewards: 175.71253, mean: 0.10914
[32m[0906 14-47-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03422, current rewards: 181.33890, mean: 0.10924
[32m[0906 14-47-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03424, current rewards: 186.96448, mean: 0.10934
[32m[0906 14-47-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03424, current rewards: 192.53413, mean: 0.10939
[32m[0906 14-47-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03425, current rewards: 198.13991, mean: 0.10947
[32m[0906 14-47-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03426, current rewards: 203.74511, mean: 0.10954
[32m[0906 14-47-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03427, current rewards: 209.34838, mean: 0.10961
[32m[0906 14-47-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03427, current rewards: 212.92706, mean: 0.10864
[32m[0906 14-47-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03427, current rewards: 218.59354, mean: 0.10875
[32m[0906 14-47-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03428, current rewards: 224.26658, mean: 0.10887
[32m[0906 14-47-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03429, current rewards: 229.94455, mean: 0.10898
[32m[0906 14-47-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03431, current rewards: 235.60079, mean: 0.10907
[32m[0906 14-47-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03433, current rewards: 241.27486, mean: 0.10917
[32m[0906 14-47-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03436, current rewards: 246.94585, mean: 0.10927
[32m[0906 14-47-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03438, current rewards: 252.62308, mean: 0.10936
[32m[0906 14-47-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03441, current rewards: 257.20766, mean: 0.10899
[32m[0906 14-48-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03443, current rewards: 262.89491, mean: 0.10909
[32m[0906 14-48-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03445, current rewards: 268.58395, mean: 0.10918
[32m[0906 14-48-04 @Agent.py:117][0m Average action selection time: 0.0345
[32m[0906 14-48-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-48-04 @MBExp.py:227][0m Rewards obtained: [273.133643655133], Lows: [3], Highs: [5], Total time: 2915.4938069999994
[32m[0906 14-49-14 @MBExp.py:144][0m ####################################################################
[32m[0906 14-49-14 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 14-49-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03505, current rewards: -1.15117, mean: -0.11512
[32m[0906 14-49-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03422, current rewards: 4.33368, mean: 0.07223
[32m[0906 14-49-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03386, current rewards: 9.82607, mean: 0.08933
[32m[0906 14-49-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03378, current rewards: 15.32015, mean: 0.09575
[32m[0906 14-49-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03375, current rewards: 20.80737, mean: 0.09908
[32m[0906 14-49-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03378, current rewards: 26.29461, mean: 0.10113
[32m[0906 14-49-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03376, current rewards: 31.78544, mean: 0.10253
[32m[0906 14-49-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03373, current rewards: 37.27395, mean: 0.10354
[32m[0906 14-49-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03369, current rewards: 42.76765, mean: 0.10431
[32m[0906 14-49-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03370, current rewards: 48.18351, mean: 0.10475
[32m[0906 14-49-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03378, current rewards: 53.64400, mean: 0.10518
[32m[0906 14-49-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03384, current rewards: 59.13668, mean: 0.10560
[32m[0906 14-49-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03390, current rewards: 64.62952, mean: 0.10595
[32m[0906 14-49-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03396, current rewards: 70.12223, mean: 0.10625
[32m[0906 14-49-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03399, current rewards: 75.60981, mean: 0.10649
[32m[0906 14-49-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03402, current rewards: 81.12820, mean: 0.10675
[32m[0906 14-49-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03406, current rewards: 86.65135, mean: 0.10698
[32m[0906 14-49-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03408, current rewards: 92.29100, mean: 0.10732
[32m[0906 14-49-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03411, current rewards: 97.81838, mean: 0.10749
[32m[0906 14-49-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03412, current rewards: 103.34742, mean: 0.10765
[32m[0906 14-49-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03413, current rewards: 108.88144, mean: 0.10780
[32m[0906 14-49-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03415, current rewards: 114.41034, mean: 0.10793
[32m[0906 14-49-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03418, current rewards: 119.93657, mean: 0.10805
[32m[0906 14-49-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03420, current rewards: 125.46879, mean: 0.10816
[32m[0906 14-49-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03422, current rewards: 130.99335, mean: 0.10826
[32m[0906 14-49-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03423, current rewards: 136.57070, mean: 0.10839
[32m[0906 14-49-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03424, current rewards: 140.04357, mean: 0.10690
[32m[0906 14-50-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03425, current rewards: 145.59690, mean: 0.10706
[32m[0906 14-50-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03426, current rewards: 151.14493, mean: 0.10719
[32m[0906 14-50-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03426, current rewards: 156.69343, mean: 0.10732
[32m[0906 14-50-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03427, current rewards: 162.24478, mean: 0.10745
[32m[0906 14-50-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03427, current rewards: 167.79437, mean: 0.10756
[32m[0906 14-50-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03429, current rewards: 173.34095, mean: 0.10767
[32m[0906 14-50-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03427, current rewards: 178.84853, mean: 0.10774
[32m[0906 14-50-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03427, current rewards: 182.34954, mean: 0.10664
[32m[0906 14-50-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03428, current rewards: 187.85733, mean: 0.10674
[32m[0906 14-50-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03429, current rewards: 193.36656, mean: 0.10683
[32m[0906 14-50-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03430, current rewards: 198.87324, mean: 0.10692
[32m[0906 14-50-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03431, current rewards: 204.38409, mean: 0.10701
[32m[0906 14-50-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03431, current rewards: 209.89234, mean: 0.10709
[32m[0906 14-50-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03432, current rewards: 215.39949, mean: 0.10716
[32m[0906 14-50-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03432, current rewards: 220.90865, mean: 0.10724
[32m[0906 14-50-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03434, current rewards: 226.41647, mean: 0.10731
[32m[0906 14-50-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03437, current rewards: 231.92554, mean: 0.10737
[32m[0906 14-50-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03440, current rewards: 233.37577, mean: 0.10560
[32m[0906 14-50-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03442, current rewards: 239.08124, mean: 0.10579
[32m[0906 14-50-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03444, current rewards: 244.78975, mean: 0.10597
[32m[0906 14-50-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03446, current rewards: 250.49907, mean: 0.10614
[32m[0906 14-50-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03448, current rewards: 256.20571, mean: 0.10631
[32m[0906 14-50-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03451, current rewards: 261.91561, mean: 0.10647
[32m[0906 14-50-40 @Agent.py:117][0m Average action selection time: 0.0345
[32m[0906 14-50-40 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-50-41 @MBExp.py:227][0m Rewards obtained: [266.3427168758504], Lows: [4], Highs: [2], Total time: 3002.447872999999
[32m[0906 14-51-52 @MBExp.py:144][0m ####################################################################
[32m[0906 14-51-52 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 14-51-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03262, current rewards: 0.18850, mean: 0.01885
[32m[0906 14-51-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03323, current rewards: 5.58164, mean: 0.09303
[32m[0906 14-51-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03338, current rewards: 11.08560, mean: 0.10078
[32m[0906 14-51-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03340, current rewards: 16.59291, mean: 0.10371
[32m[0906 14-52-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03346, current rewards: 22.09942, mean: 0.10524
[32m[0906 14-52-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03348, current rewards: 27.61061, mean: 0.10619
[32m[0906 14-52-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03348, current rewards: 33.12051, mean: 0.10684
[32m[0906 14-52-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03346, current rewards: 38.63165, mean: 0.10731
[32m[0906 14-52-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03345, current rewards: 44.13910, mean: 0.10766
[32m[0906 14-52-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03348, current rewards: 49.64585, mean: 0.10793
[32m[0906 14-52-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03356, current rewards: 55.15411, mean: 0.10815
[32m[0906 14-52-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03364, current rewards: 60.66888, mean: 0.10834
[32m[0906 14-52-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03371, current rewards: 66.15237, mean: 0.10845
[32m[0906 14-52-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03377, current rewards: 71.70028, mean: 0.10864
[32m[0906 14-52-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03381, current rewards: 77.24906, mean: 0.10880
[32m[0906 14-52-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03385, current rewards: 82.79422, mean: 0.10894
[32m[0906 14-52-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03389, current rewards: 88.40531, mean: 0.10914
[32m[0906 14-52-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03392, current rewards: 93.94914, mean: 0.10924
[32m[0906 14-52-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03394, current rewards: 99.49413, mean: 0.10933
[32m[0906 14-52-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03397, current rewards: 105.03613, mean: 0.10941
[32m[0906 14-52-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03398, current rewards: 110.57852, mean: 0.10948
[32m[0906 14-52-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03400, current rewards: 116.12539, mean: 0.10955
[32m[0906 14-52-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03402, current rewards: 119.55140, mean: 0.10770
[32m[0906 14-52-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03403, current rewards: 125.10949, mean: 0.10785
[32m[0906 14-52-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03405, current rewards: 130.66901, mean: 0.10799
[32m[0906 14-52-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03407, current rewards: 136.27324, mean: 0.10815
[32m[0906 14-52-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03408, current rewards: 141.84009, mean: 0.10827
[32m[0906 14-52-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03410, current rewards: 147.40216, mean: 0.10838
[32m[0906 14-52-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03411, current rewards: 152.96327, mean: 0.10848
[32m[0906 14-52-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03412, current rewards: 158.52228, mean: 0.10858
[32m[0906 14-52-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03413, current rewards: 164.08271, mean: 0.10866
[32m[0906 14-52-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03415, current rewards: 169.64627, mean: 0.10875
[32m[0906 14-52-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03414, current rewards: 175.21081, mean: 0.10883
[32m[0906 14-52-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03413, current rewards: 180.70464, mean: 0.10886
[32m[0906 14-52-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03411, current rewards: 184.19339, mean: 0.10772
[32m[0906 14-52-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03411, current rewards: 189.75314, mean: 0.10781
[32m[0906 14-52-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03412, current rewards: 195.30858, mean: 0.10791
[32m[0906 14-52-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03414, current rewards: 200.86714, mean: 0.10799
[32m[0906 14-52-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03414, current rewards: 206.42721, mean: 0.10808
[32m[0906 14-53-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03415, current rewards: 211.98040, mean: 0.10815
[32m[0906 14-53-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03416, current rewards: 217.53582, mean: 0.10823
[32m[0906 14-53-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03416, current rewards: 223.25276, mean: 0.10838
[32m[0906 14-53-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03420, current rewards: 227.72567, mean: 0.10793
[32m[0906 14-53-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03422, current rewards: 233.29404, mean: 0.10801
[32m[0906 14-53-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03425, current rewards: 238.85757, mean: 0.10808
[32m[0906 14-53-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03428, current rewards: 244.42766, mean: 0.10815
[32m[0906 14-53-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03431, current rewards: 245.80520, mean: 0.10641
[32m[0906 14-53-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03433, current rewards: 251.73603, mean: 0.10667
[32m[0906 14-53-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03435, current rewards: 257.66613, mean: 0.10692
[32m[0906 14-53-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03437, current rewards: 263.59747, mean: 0.10715
[32m[0906 14-53-19 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 14-53-19 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-53-19 @MBExp.py:227][0m Rewards obtained: [268.34193495770035], Lows: [4], Highs: [2], Total time: 3089.0475499999993
[32m[0906 14-54-33 @MBExp.py:144][0m ####################################################################
[32m[0906 14-54-33 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 14-54-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03263, current rewards: -1.06580, mean: -0.10658
[32m[0906 14-54-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03324, current rewards: 4.51973, mean: 0.07533
[32m[0906 14-54-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03344, current rewards: 10.04325, mean: 0.09130
[32m[0906 14-54-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03352, current rewards: 15.56448, mean: 0.09728
[32m[0906 14-54-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03355, current rewards: 21.08558, mean: 0.10041
[32m[0906 14-54-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03353, current rewards: 26.60444, mean: 0.10232
[32m[0906 14-54-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03350, current rewards: 30.97416, mean: 0.09992
[32m[0906 14-54-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03349, current rewards: 36.34648, mean: 0.10096
[32m[0906 14-54-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03351, current rewards: 41.61042, mean: 0.10149
[32m[0906 14-54-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03351, current rewards: 46.98298, mean: 0.10214
[32m[0906 14-54-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03360, current rewards: 52.33917, mean: 0.10263
[32m[0906 14-54-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03366, current rewards: 57.70698, mean: 0.10305
[32m[0906 14-54-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03374, current rewards: 63.06694, mean: 0.10339
[32m[0906 14-54-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03378, current rewards: 68.43305, mean: 0.10369
[32m[0906 14-54-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03383, current rewards: 73.79939, mean: 0.10394
[32m[0906 14-54-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03387, current rewards: 79.16134, mean: 0.10416
[32m[0906 14-55-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03392, current rewards: 84.57576, mean: 0.10441
[32m[0906 14-55-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03396, current rewards: 89.95738, mean: 0.10460
[32m[0906 14-55-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03398, current rewards: 95.32833, mean: 0.10476
[32m[0906 14-55-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03401, current rewards: 100.70738, mean: 0.10490
[32m[0906 14-55-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03403, current rewards: 106.08620, mean: 0.10504
[32m[0906 14-55-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03405, current rewards: 111.45669, mean: 0.10515
[32m[0906 14-55-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03408, current rewards: 114.73349, mean: 0.10336
[32m[0906 14-55-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03409, current rewards: 120.11340, mean: 0.10355
[32m[0906 14-55-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03410, current rewards: 125.71510, mean: 0.10390
[32m[0906 14-55-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03412, current rewards: 131.18695, mean: 0.10412
[32m[0906 14-55-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03414, current rewards: 136.65898, mean: 0.10432
[32m[0906 14-55-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03415, current rewards: 142.13151, mean: 0.10451
[32m[0906 14-55-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03416, current rewards: 146.51847, mean: 0.10391
[32m[0906 14-55-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03417, current rewards: 151.87916, mean: 0.10403
[32m[0906 14-55-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03419, current rewards: 157.23880, mean: 0.10413
[32m[0906 14-55-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03420, current rewards: 162.60187, mean: 0.10423
[32m[0906 14-55-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03418, current rewards: 167.92989, mean: 0.10430
[32m[0906 14-55-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03417, current rewards: 173.14680, mean: 0.10431
[32m[0906 14-55-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03415, current rewards: 178.46070, mean: 0.10436
[32m[0906 14-55-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03414, current rewards: 183.77958, mean: 0.10442
[32m[0906 14-55-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03413, current rewards: 189.09219, mean: 0.10447
[32m[0906 14-55-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03414, current rewards: 194.40029, mean: 0.10452
[32m[0906 14-55-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03416, current rewards: 199.71325, mean: 0.10456
[32m[0906 14-55-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03416, current rewards: 205.03348, mean: 0.10461
[32m[0906 14-55-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03418, current rewards: 206.09173, mean: 0.10253
[32m[0906 14-55-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03419, current rewards: 211.13974, mean: 0.10250
[32m[0906 14-55-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03422, current rewards: 216.31012, mean: 0.10252
[32m[0906 14-55-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03424, current rewards: 221.48444, mean: 0.10254
[32m[0906 14-55-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03427, current rewards: 226.65577, mean: 0.10256
[32m[0906 14-55-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03430, current rewards: 231.82953, mean: 0.10258
[32m[0906 14-55-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03432, current rewards: 237.00321, mean: 0.10260
[32m[0906 14-55-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03434, current rewards: 242.17862, mean: 0.10262
[32m[0906 14-55-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03436, current rewards: 247.35489, mean: 0.10264
[32m[0906 14-55-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03438, current rewards: 252.51601, mean: 0.10265
[32m[0906 14-56-00 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 14-56-00 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-56-00 @MBExp.py:227][0m Rewards obtained: [256.3459211664864], Lows: [3], Highs: [4], Total time: 3175.6935929999995
[32m[0906 14-57-16 @MBExp.py:144][0m ####################################################################
[32m[0906 14-57-16 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 14-57-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03482, current rewards: -0.04581, mean: -0.00458
[32m[0906 14-57-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03367, current rewards: 5.41545, mean: 0.09026
[32m[0906 14-57-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03369, current rewards: 10.94782, mean: 0.09953
[32m[0906 14-57-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03362, current rewards: 16.48073, mean: 0.10300
[32m[0906 14-57-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03359, current rewards: 22.01879, mean: 0.10485
[32m[0906 14-57-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03359, current rewards: 27.54362, mean: 0.10594
[32m[0906 14-57-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03357, current rewards: 33.07317, mean: 0.10669
[32m[0906 14-57-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03357, current rewards: 38.60901, mean: 0.10725
[32m[0906 14-57-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03360, current rewards: 44.35798, mean: 0.10819
[32m[0906 14-57-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03359, current rewards: 49.92632, mean: 0.10854
[32m[0906 14-57-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03367, current rewards: 55.50037, mean: 0.10882
[32m[0906 14-57-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03373, current rewards: 61.07141, mean: 0.10906
[32m[0906 14-57-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03379, current rewards: 66.64559, mean: 0.10926
[32m[0906 14-57-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03383, current rewards: 72.14476, mean: 0.10931
[32m[0906 14-57-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03389, current rewards: 77.69330, mean: 0.10943
[32m[0906 14-57-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03392, current rewards: 83.24244, mean: 0.10953
[32m[0906 14-57-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03395, current rewards: 86.62977, mean: 0.10695
[32m[0906 14-57-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03400, current rewards: 91.92098, mean: 0.10688
[32m[0906 14-57-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03402, current rewards: 97.43596, mean: 0.10707
[32m[0906 14-57-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03404, current rewards: 102.95303, mean: 0.10724
[32m[0906 14-57-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03406, current rewards: 108.47473, mean: 0.10740
[32m[0906 14-57-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03408, current rewards: 113.99102, mean: 0.10754
[32m[0906 14-57-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03409, current rewards: 119.50748, mean: 0.10766
[32m[0906 14-57-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03410, current rewards: 125.03052, mean: 0.10778
[32m[0906 14-57-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03411, current rewards: 130.55143, mean: 0.10789
[32m[0906 14-57-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03412, current rewards: 136.07533, mean: 0.10800
[32m[0906 14-58-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03414, current rewards: 141.58618, mean: 0.10808
[32m[0906 14-58-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03415, current rewards: 147.10052, mean: 0.10816
[32m[0906 14-58-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03417, current rewards: 152.60774, mean: 0.10823
[32m[0906 14-58-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03417, current rewards: 158.11753, mean: 0.10830
[32m[0906 14-58-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03419, current rewards: 163.62923, mean: 0.10836
[32m[0906 14-58-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03419, current rewards: 169.14112, mean: 0.10842
[32m[0906 14-58-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03418, current rewards: 174.64333, mean: 0.10847
[32m[0906 14-58-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03416, current rewards: 180.10866, mean: 0.10850
[32m[0906 14-58-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03414, current rewards: 185.60925, mean: 0.10854
[32m[0906 14-58-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03412, current rewards: 191.11151, mean: 0.10859
[32m[0906 14-58-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03411, current rewards: 196.60773, mean: 0.10862
[32m[0906 14-58-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03410, current rewards: 202.11486, mean: 0.10866
[32m[0906 14-58-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03411, current rewards: 207.61781, mean: 0.10870
[32m[0906 14-58-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03412, current rewards: 213.12467, mean: 0.10874
[32m[0906 14-58-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03413, current rewards: 218.62763, mean: 0.10877
[32m[0906 14-58-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03415, current rewards: 224.11511, mean: 0.10879
[32m[0906 14-58-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03418, current rewards: 229.61262, mean: 0.10882
[32m[0906 14-58-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03421, current rewards: 232.99003, mean: 0.10787
[32m[0906 14-58-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03424, current rewards: 238.51848, mean: 0.10793
[32m[0906 14-58-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03426, current rewards: 244.05160, mean: 0.10799
[32m[0906 14-58-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03429, current rewards: 249.58132, mean: 0.10804
[32m[0906 14-58-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03431, current rewards: 255.10951, mean: 0.10810
[32m[0906 14-58-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03433, current rewards: 260.63359, mean: 0.10815
[32m[0906 14-58-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03435, current rewards: 266.26435, mean: 0.10824
[32m[0906 14-58-42 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 14-58-42 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-58-42 @MBExp.py:227][0m Rewards obtained: [270.81074617768513], Lows: [2], Highs: [1], Total time: 3262.2580539999994
[32m[0906 15-00-00 @MBExp.py:144][0m ####################################################################
[32m[0906 15-00-00 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 15-00-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03289, current rewards: 0.01823, mean: 0.00182
[32m[0906 15-00-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03342, current rewards: 5.47011, mean: 0.09117
[32m[0906 15-00-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03352, current rewards: 10.92459, mean: 0.09931
[32m[0906 15-00-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03358, current rewards: 16.37844, mean: 0.10237
[32m[0906 15-00-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03362, current rewards: 21.82967, mean: 0.10395
[32m[0906 15-00-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03362, current rewards: 27.27602, mean: 0.10491
[32m[0906 15-00-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03359, current rewards: 32.73183, mean: 0.10559
[32m[0906 15-00-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03358, current rewards: 38.18383, mean: 0.10607
[32m[0906 15-00-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03357, current rewards: 44.33607, mean: 0.10814
[32m[0906 15-00-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03358, current rewards: 49.90581, mean: 0.10849
[32m[0906 15-00-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03367, current rewards: 55.47181, mean: 0.10877
[32m[0906 15-00-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03373, current rewards: 61.04727, mean: 0.10901
[32m[0906 15-00-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03378, current rewards: 66.61912, mean: 0.10921
[32m[0906 15-00-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03383, current rewards: 72.18603, mean: 0.10937
[32m[0906 15-00-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03388, current rewards: 77.74951, mean: 0.10951
[32m[0906 15-00-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03391, current rewards: 83.31548, mean: 0.10963
[32m[0906 15-00-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03394, current rewards: 89.00934, mean: 0.10989
[32m[0906 15-00-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03396, current rewards: 94.58683, mean: 0.10998
[32m[0906 15-00-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03398, current rewards: 97.98966, mean: 0.10768
[32m[0906 15-00-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03400, current rewards: 103.49338, mean: 0.10781
[32m[0906 15-00-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03401, current rewards: 108.99938, mean: 0.10792
[32m[0906 15-00-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03403, current rewards: 114.50184, mean: 0.10802
[32m[0906 15-00-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03405, current rewards: 120.00856, mean: 0.10812
[32m[0906 15-00-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03406, current rewards: 123.55415, mean: 0.10651
[32m[0906 15-00-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03408, current rewards: 129.30949, mean: 0.10687
[32m[0906 15-00-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03409, current rewards: 137.11761, mean: 0.10882
[32m[0906 15-00-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03410, current rewards: 145.41773, mean: 0.11101
[32m[0906 15-00-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03411, current rewards: 153.71785, mean: 0.11303
[32m[0906 15-00-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03411, current rewards: 138.69793, mean: 0.09837
[32m[0906 15-00-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03413, current rewards: 88.69793, mean: 0.06075
[32m[0906 15-00-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03413, current rewards: 38.69793, mean: 0.02563
[32m[0906 15-00-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03414, current rewards: -11.30207, mean: -0.00724
[32m[0906 15-00-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03412, current rewards: -61.30207, mean: -0.03808
[32m[0906 15-00-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03411, current rewards: -111.30207, mean: -0.06705
[32m[0906 15-00-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03410, current rewards: -161.30207, mean: -0.09433
[32m[0906 15-01-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03409, current rewards: -211.30207, mean: -0.12006
[32m[0906 15-01-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03407, current rewards: -261.30207, mean: -0.14437
[32m[0906 15-01-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03406, current rewards: -311.30207, mean: -0.16737
[32m[0906 15-01-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03405, current rewards: -361.30207, mean: -0.18916
[32m[0906 15-01-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03405, current rewards: -411.30207, mean: -0.20985
[32m[0906 15-01-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03406, current rewards: -461.30207, mean: -0.22950
[32m[0906 15-01-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03408, current rewards: -511.30207, mean: -0.24820
[32m[0906 15-01-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03412, current rewards: -561.30207, mean: -0.26602
[32m[0906 15-01-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03414, current rewards: -611.30207, mean: -0.28301
[32m[0906 15-01-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03417, current rewards: -661.30207, mean: -0.29923
[32m[0906 15-01-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03420, current rewards: -711.30207, mean: -0.31474
[32m[0906 15-01-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03423, current rewards: -761.30207, mean: -0.32957
[32m[0906 15-01-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03425, current rewards: -811.30207, mean: -0.34377
[32m[0906 15-01-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03428, current rewards: -861.30207, mean: -0.35739
[32m[0906 15-01-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03430, current rewards: -911.30207, mean: -0.37045
[32m[0906 15-01-27 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 15-01-27 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-01-27 @MBExp.py:227][0m Rewards obtained: [-951.3020742997718], Lows: [2], Highs: [1111], Total time: 3348.6974599999994
[32m[0906 15-02-47 @MBExp.py:144][0m ####################################################################
[32m[0906 15-02-47 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 15-02-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03311, current rewards: 0.11677, mean: 0.01168
[32m[0906 15-02-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03360, current rewards: 5.58840, mean: 0.09314
[32m[0906 15-02-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03363, current rewards: 11.05675, mean: 0.10052
[32m[0906 15-02-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03365, current rewards: 16.52632, mean: 0.10329
[32m[0906 15-02-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03365, current rewards: 21.99649, mean: 0.10475
[32m[0906 15-02-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03363, current rewards: 27.46847, mean: 0.10565
[32m[0906 15-02-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03364, current rewards: 32.93777, mean: 0.10625
[32m[0906 15-02-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03362, current rewards: 37.27388, mean: 0.10354
[32m[0906 15-03-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03362, current rewards: 42.78899, mean: 0.10436
[32m[0906 15-03-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03364, current rewards: 48.33223, mean: 0.10507
[32m[0906 15-03-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03373, current rewards: 53.85631, mean: 0.10560
[32m[0906 15-03-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03377, current rewards: 59.36463, mean: 0.10601
[32m[0906 15-03-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03384, current rewards: 64.88092, mean: 0.10636
[32m[0906 15-03-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03390, current rewards: 70.39708, mean: 0.10666
[32m[0906 15-03-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03394, current rewards: 75.91850, mean: 0.10693
[32m[0906 15-03-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03397, current rewards: 81.43567, mean: 0.10715
[32m[0906 15-03-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03400, current rewards: 86.95345, mean: 0.10735
[32m[0906 15-03-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03402, current rewards: 92.37559, mean: 0.10741
[32m[0906 15-03-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03404, current rewards: 96.79789, mean: 0.10637
[32m[0906 15-03-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03406, current rewards: 102.22321, mean: 0.10648
[32m[0906 15-03-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03408, current rewards: 107.64774, mean: 0.10658
[32m[0906 15-03-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03409, current rewards: 113.07936, mean: 0.10668
[32m[0906 15-03-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03411, current rewards: 118.51115, mean: 0.10677
[32m[0906 15-03-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03414, current rewards: 123.93454, mean: 0.10684
[32m[0906 15-03-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03415, current rewards: 129.36467, mean: 0.10691
[32m[0906 15-03-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03415, current rewards: 134.79736, mean: 0.10698
[32m[0906 15-03-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03417, current rewards: 140.88281, mean: 0.10754
[32m[0906 15-03-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03418, current rewards: 146.41045, mean: 0.10765
[32m[0906 15-03-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03420, current rewards: 151.94129, mean: 0.10776
[32m[0906 15-03-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03421, current rewards: 157.47232, mean: 0.10786
[32m[0906 15-03-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03422, current rewards: 162.99497, mean: 0.10794
[32m[0906 15-03-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03421, current rewards: 168.51837, mean: 0.10802
[32m[0906 15-03-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03420, current rewards: 174.04709, mean: 0.10810
[32m[0906 15-03-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03418, current rewards: 179.68557, mean: 0.10824
[32m[0906 15-03-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03416, current rewards: 183.12040, mean: 0.10709
[32m[0906 15-03-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03415, current rewards: 188.64887, mean: 0.10719
[32m[0906 15-03-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03413, current rewards: 194.17767, mean: 0.10728
[32m[0906 15-03-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03412, current rewards: 199.70046, mean: 0.10737
[32m[0906 15-03-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03411, current rewards: 205.22393, mean: 0.10745
[32m[0906 15-03-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03410, current rewards: 210.75129, mean: 0.10753
[32m[0906 15-03-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03411, current rewards: 216.28185, mean: 0.10760
[32m[0906 15-03-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03413, current rewards: 221.91436, mean: 0.10773
[32m[0906 15-03-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03416, current rewards: 227.45763, mean: 0.10780
[32m[0906 15-04-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03419, current rewards: 232.99832, mean: 0.10787
[32m[0906 15-04-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03421, current rewards: 238.53950, mean: 0.10794
[32m[0906 15-04-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03424, current rewards: 242.07474, mean: 0.10711
[32m[0906 15-04-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03427, current rewards: 247.64454, mean: 0.10721
[32m[0906 15-04-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03429, current rewards: 253.21455, mean: 0.10729
[32m[0906 15-04-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03432, current rewards: 258.78335, mean: 0.10738
[32m[0906 15-04-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03434, current rewards: 264.43754, mean: 0.10749
[32m[0906 15-04-13 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 15-04-13 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-04-13 @MBExp.py:227][0m Rewards obtained: [268.9013704930779], Lows: [2], Highs: [3], Total time: 3435.2393679999996
[32m[0906 15-05-36 @MBExp.py:144][0m ####################################################################
[32m[0906 15-05-36 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 15-05-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03339, current rewards: -0.07492, mean: -0.00749
[32m[0906 15-05-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03371, current rewards: 5.34195, mean: 0.08903
[32m[0906 15-05-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03369, current rewards: 10.75636, mean: 0.09779
[32m[0906 15-05-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03366, current rewards: 16.16874, mean: 0.10105
[32m[0906 15-05-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03368, current rewards: 21.58000, mean: 0.10276
[32m[0906 15-05-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03367, current rewards: 26.99486, mean: 0.10383
[32m[0906 15-05-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03368, current rewards: 32.41320, mean: 0.10456
[32m[0906 15-05-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03369, current rewards: 37.82692, mean: 0.10507
[32m[0906 15-05-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03371, current rewards: 41.14133, mean: 0.10034
[32m[0906 15-05-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03376, current rewards: 46.64898, mean: 0.10141
[32m[0906 15-05-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03383, current rewards: 52.16326, mean: 0.10228
[32m[0906 15-05-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03391, current rewards: 57.67389, mean: 0.10299
[32m[0906 15-05-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03397, current rewards: 63.18635, mean: 0.10358
[32m[0906 15-05-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03401, current rewards: 68.69854, mean: 0.10409
[32m[0906 15-06-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03404, current rewards: 74.21325, mean: 0.10453
[32m[0906 15-06-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03407, current rewards: 78.40599, mean: 0.10317
[32m[0906 15-06-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03408, current rewards: 83.84444, mean: 0.10351
[32m[0906 15-06-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03412, current rewards: 89.10143, mean: 0.10361
[32m[0906 15-06-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03413, current rewards: 94.35921, mean: 0.10369
[32m[0906 15-06-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03416, current rewards: 99.61073, mean: 0.10376
[32m[0906 15-06-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03417, current rewards: 104.86355, mean: 0.10383
[32m[0906 15-06-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03419, current rewards: 110.75987, mean: 0.10449
[32m[0906 15-06-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03420, current rewards: 116.21837, mean: 0.10470
[32m[0906 15-06-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03422, current rewards: 121.67462, mean: 0.10489
[32m[0906 15-06-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03423, current rewards: 126.97551, mean: 0.10494
[32m[0906 15-06-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03424, current rewards: 132.33388, mean: 0.10503
[32m[0906 15-06-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03425, current rewards: 137.68980, mean: 0.10511
[32m[0906 15-06-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03426, current rewards: 141.26354, mean: 0.10387
[32m[0906 15-06-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03427, current rewards: 147.02583, mean: 0.10427
[32m[0906 15-06-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03428, current rewards: 152.78774, mean: 0.10465
[32m[0906 15-06-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03429, current rewards: 158.55243, mean: 0.10500
[32m[0906 15-06-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03429, current rewards: 164.32181, mean: 0.10533
[32m[0906 15-06-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03426, current rewards: 168.85407, mean: 0.10488
[32m[0906 15-06-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03424, current rewards: 174.33162, mean: 0.10502
[32m[0906 15-06-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03422, current rewards: 179.76243, mean: 0.10512
[32m[0906 15-06-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03421, current rewards: 185.19644, mean: 0.10523
[32m[0906 15-06-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03420, current rewards: 190.63046, mean: 0.10532
[32m[0906 15-06-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03419, current rewards: 194.20976, mean: 0.10441
[32m[0906 15-06-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03417, current rewards: 199.85209, mean: 0.10463
[32m[0906 15-06-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03416, current rewards: 205.49305, mean: 0.10484
[32m[0906 15-06-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03415, current rewards: 211.13615, mean: 0.10504
[32m[0906 15-06-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03417, current rewards: 216.74105, mean: 0.10521
[32m[0906 15-06-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03420, current rewards: 222.45810, mean: 0.10543
[32m[0906 15-06-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03423, current rewards: 225.77505, mean: 0.10453
[32m[0906 15-06-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03426, current rewards: 231.23212, mean: 0.10463
[32m[0906 15-06-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03428, current rewards: 236.69091, mean: 0.10473
[32m[0906 15-06-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03430, current rewards: 242.15033, mean: 0.10483
[32m[0906 15-06-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03433, current rewards: 247.60595, mean: 0.10492
[32m[0906 15-06-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03435, current rewards: 253.06084, mean: 0.10500
[32m[0906 15-07-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03437, current rewards: 258.42714, mean: 0.10505
[32m[0906 15-07-02 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 15-07-02 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-07-02 @MBExp.py:227][0m Rewards obtained: [262.7658113247161], Lows: [3], Highs: [5], Total time: 3521.8817029999996
[32m[0906 15-08-26 @MBExp.py:144][0m ####################################################################
[32m[0906 15-08-26 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 15-08-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03295, current rewards: -0.09539, mean: -0.00954
[32m[0906 15-08-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03347, current rewards: 5.42204, mean: 0.09037
[32m[0906 15-08-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03351, current rewards: 10.98380, mean: 0.09985
[32m[0906 15-08-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03353, current rewards: 16.54136, mean: 0.10338
[32m[0906 15-08-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03358, current rewards: 22.10453, mean: 0.10526
[32m[0906 15-08-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03359, current rewards: 25.66442, mean: 0.09871
[32m[0906 15-08-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03363, current rewards: 31.03182, mean: 0.10010
[32m[0906 15-08-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03361, current rewards: 36.26759, mean: 0.10074
[32m[0906 15-08-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03360, current rewards: 41.62624, mean: 0.10153
[32m[0906 15-08-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03367, current rewards: 46.98561, mean: 0.10214
[32m[0906 15-08-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03377, current rewards: 52.34825, mean: 0.10264
[32m[0906 15-08-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03382, current rewards: 57.71116, mean: 0.10306
[32m[0906 15-08-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03386, current rewards: 63.07511, mean: 0.10340
[32m[0906 15-08-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03389, current rewards: 68.43643, mean: 0.10369
[32m[0906 15-08-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03393, current rewards: 73.79411, mean: 0.10394
[32m[0906 15-08-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03395, current rewards: 79.15293, mean: 0.10415
[32m[0906 15-08-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03398, current rewards: 82.50488, mean: 0.10186
[32m[0906 15-08-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03401, current rewards: 88.03481, mean: 0.10237
[32m[0906 15-08-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03403, current rewards: 93.56860, mean: 0.10282
[32m[0906 15-08-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03405, current rewards: 99.09452, mean: 0.10322
[32m[0906 15-09-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03407, current rewards: 104.62115, mean: 0.10359
[32m[0906 15-09-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03408, current rewards: 110.15024, mean: 0.10392
[32m[0906 15-09-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03410, current rewards: 115.68825, mean: 0.10422
[32m[0906 15-09-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03411, current rewards: 121.21751, mean: 0.10450
[32m[0906 15-09-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03413, current rewards: 126.74707, mean: 0.10475
[32m[0906 15-09-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03415, current rewards: 132.27690, mean: 0.10498
[32m[0906 15-09-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03416, current rewards: 137.80646, mean: 0.10520
[32m[0906 15-09-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03417, current rewards: 143.33282, mean: 0.10539
[32m[0906 15-09-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03419, current rewards: 148.86439, mean: 0.10558
[32m[0906 15-09-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03420, current rewards: 154.39281, mean: 0.10575
[32m[0906 15-09-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03421, current rewards: 159.92123, mean: 0.10591
[32m[0906 15-09-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03420, current rewards: 163.30203, mean: 0.10468
[32m[0906 15-09-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03419, current rewards: 169.11443, mean: 0.10504
[32m[0906 15-09-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03418, current rewards: 174.70816, mean: 0.10525
[32m[0906 15-09-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03417, current rewards: 180.29997, mean: 0.10544
[32m[0906 15-09-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03415, current rewards: 185.89108, mean: 0.10562
[32m[0906 15-09-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03414, current rewards: 191.48382, mean: 0.10579
[32m[0906 15-09-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03413, current rewards: 197.07344, mean: 0.10595
[32m[0906 15-09-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03411, current rewards: 202.66620, mean: 0.10611
[32m[0906 15-09-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03409, current rewards: 208.25784, mean: 0.10625
[32m[0906 15-09-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03408, current rewards: 213.86942, mean: 0.10640
[32m[0906 15-09-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03409, current rewards: 219.46700, mean: 0.10654
[32m[0906 15-09-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03410, current rewards: 225.06495, mean: 0.10667
[32m[0906 15-09-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03413, current rewards: 230.66359, mean: 0.10679
[32m[0906 15-09-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03417, current rewards: 234.36812, mean: 0.10605
[32m[0906 15-09-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03420, current rewards: 239.96700, mean: 0.10618
[32m[0906 15-09-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03422, current rewards: 245.56905, mean: 0.10631
[32m[0906 15-09-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03425, current rewards: 251.16792, mean: 0.10643
[32m[0906 15-09-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03427, current rewards: 256.65298, mean: 0.10650
[32m[0906 15-09-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03430, current rewards: 262.23163, mean: 0.10660
[32m[0906 15-09-53 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 15-09-53 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-09-53 @MBExp.py:227][0m Rewards obtained: [266.6954221094758], Lows: [3], Highs: [3], Total time: 3608.3321719999994
[32m[0906 15-11-19 @MBExp.py:144][0m ####################################################################
[32m[0906 15-11-19 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 15-11-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03309, current rewards: -1.11087, mean: -0.11109
[32m[0906 15-11-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03329, current rewards: 4.55587, mean: 0.07593
[32m[0906 15-11-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03331, current rewards: 10.22179, mean: 0.09293
[32m[0906 15-11-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03335, current rewards: 15.89183, mean: 0.09932
[32m[0906 15-11-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03343, current rewards: 21.55951, mean: 0.10266
[32m[0906 15-11-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03348, current rewards: 27.22312, mean: 0.10470
[32m[0906 15-11-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03349, current rewards: 32.87863, mean: 0.10606
[32m[0906 15-11-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03348, current rewards: 38.53471, mean: 0.10704
[32m[0906 15-11-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03349, current rewards: 44.18823, mean: 0.10778
[32m[0906 15-11-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03355, current rewards: 49.84528, mean: 0.10836
[32m[0906 15-11-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03364, current rewards: 55.50276, mean: 0.10883
[32m[0906 15-11-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03372, current rewards: 60.01798, mean: 0.10717
[32m[0906 15-11-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03377, current rewards: 65.58376, mean: 0.10751
[32m[0906 15-11-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03382, current rewards: 71.15336, mean: 0.10781
[32m[0906 15-11-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03385, current rewards: 76.74623, mean: 0.10809
[32m[0906 15-11-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03389, current rewards: 80.32055, mean: 0.10568
[32m[0906 15-11-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03393, current rewards: 85.93345, mean: 0.10609
[32m[0906 15-11-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03396, current rewards: 91.54165, mean: 0.10644
[32m[0906 15-11-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03399, current rewards: 97.15631, mean: 0.10677
[32m[0906 15-11-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03401, current rewards: 102.76578, mean: 0.10705
[32m[0906 15-11-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03403, current rewards: 108.37822, mean: 0.10731
[32m[0906 15-11-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03405, current rewards: 113.99091, mean: 0.10754
[32m[0906 15-11-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03407, current rewards: 119.60026, mean: 0.10775
[32m[0906 15-11-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03409, current rewards: 125.12634, mean: 0.10787
[32m[0906 15-12-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03411, current rewards: 130.72355, mean: 0.10804
[32m[0906 15-12-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03412, current rewards: 136.32038, mean: 0.10819
[32m[0906 15-12-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03413, current rewards: 140.77462, mean: 0.10746
[32m[0906 15-12-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03414, current rewards: 146.36730, mean: 0.10762
[32m[0906 15-12-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03416, current rewards: 151.96407, mean: 0.10778
[32m[0906 15-12-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03417, current rewards: 157.55796, mean: 0.10792
[32m[0906 15-12-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03418, current rewards: 163.15297, mean: 0.10805
[32m[0906 15-12-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03417, current rewards: 168.69418, mean: 0.10814
[32m[0906 15-12-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03415, current rewards: 174.27968, mean: 0.10825
[32m[0906 15-12-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03414, current rewards: 179.86467, mean: 0.10835
[32m[0906 15-12-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03413, current rewards: 185.44902, mean: 0.10845
[32m[0906 15-12-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03412, current rewards: 191.03858, mean: 0.10854
[32m[0906 15-12-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03411, current rewards: 195.53426, mean: 0.10803
[32m[0906 15-12-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03410, current rewards: 201.12302, mean: 0.10813
[32m[0906 15-12-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03408, current rewards: 206.71221, mean: 0.10823
[32m[0906 15-12-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03407, current rewards: 212.45145, mean: 0.10839
[32m[0906 15-12-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03406, current rewards: 218.07572, mean: 0.10850
[32m[0906 15-12-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03407, current rewards: 223.70222, mean: 0.10859
[32m[0906 15-12-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03408, current rewards: 229.33226, mean: 0.10869
[32m[0906 15-12-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03410, current rewards: 234.95854, mean: 0.10878
[32m[0906 15-12-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03413, current rewards: 240.58826, mean: 0.10886
[32m[0906 15-12-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03416, current rewards: 244.46044, mean: 0.10817
[32m[0906 15-12-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03419, current rewards: 250.27577, mean: 0.10834
[32m[0906 15-12-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03422, current rewards: 256.40306, mean: 0.10865
[32m[0906 15-12-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03425, current rewards: 263.32971, mean: 0.10927
[32m[0906 15-12-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03427, current rewards: 270.25637, mean: 0.10986
[32m[0906 15-12-45 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 15-12-45 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-12-45 @MBExp.py:227][0m Rewards obtained: [275.79770058364915], Lows: [2], Highs: [5], Total time: 3694.7057409999993
[32m[0906 15-14-13 @MBExp.py:144][0m ####################################################################
[32m[0906 15-14-13 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 15-14-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03316, current rewards: 0.07118, mean: 0.00712
[32m[0906 15-14-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03325, current rewards: 5.72501, mean: 0.09542
[32m[0906 15-14-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03348, current rewards: 11.33928, mean: 0.10308
[32m[0906 15-14-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03346, current rewards: 16.95010, mean: 0.10594
[32m[0906 15-14-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03350, current rewards: 22.56328, mean: 0.10744
[32m[0906 15-14-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03355, current rewards: 28.17339, mean: 0.10836
[32m[0906 15-14-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03355, current rewards: 33.69347, mean: 0.10869
[32m[0906 15-14-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03355, current rewards: 39.29895, mean: 0.10916
[32m[0906 15-14-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03352, current rewards: 44.89941, mean: 0.10951
[32m[0906 15-14-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03357, current rewards: 50.50099, mean: 0.10978
[32m[0906 15-14-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03364, current rewards: 56.10591, mean: 0.11001
[32m[0906 15-14-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03371, current rewards: 61.70546, mean: 0.11019
[32m[0906 15-14-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03377, current rewards: 67.30798, mean: 0.11034
[32m[0906 15-14-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03381, current rewards: 72.91016, mean: 0.11047
[32m[0906 15-14-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03384, current rewards: 78.67282, mean: 0.11081
[32m[0906 15-14-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03389, current rewards: 82.27667, mean: 0.10826
[32m[0906 15-14-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03392, current rewards: 87.87272, mean: 0.10848
[32m[0906 15-14-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03395, current rewards: 93.47378, mean: 0.10869
[32m[0906 15-14-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03399, current rewards: 99.07378, mean: 0.10887
[32m[0906 15-14-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03401, current rewards: 104.67334, mean: 0.10903
[32m[0906 15-14-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03402, current rewards: 109.14200, mean: 0.10806
[32m[0906 15-14-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03403, current rewards: 114.73136, mean: 0.10824
[32m[0906 15-14-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03405, current rewards: 120.33370, mean: 0.10841
[32m[0906 15-14-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03407, current rewards: 125.92399, mean: 0.10856
[32m[0906 15-14-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03409, current rewards: 131.51481, mean: 0.10869
[32m[0906 15-14-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03410, current rewards: 137.10660, mean: 0.10881
[32m[0906 15-14-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03412, current rewards: 142.69728, mean: 0.10893
[32m[0906 15-15-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03413, current rewards: 147.30028, mean: 0.10831
[32m[0906 15-15-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03415, current rewards: 152.89155, mean: 0.10843
[32m[0906 15-15-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03416, current rewards: 158.49191, mean: 0.10856
[32m[0906 15-15-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03416, current rewards: 164.11397, mean: 0.10868
[32m[0906 15-15-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03414, current rewards: 169.70617, mean: 0.10879
[32m[0906 15-15-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03413, current rewards: 175.30251, mean: 0.10888
[32m[0906 15-15-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03411, current rewards: 180.89541, mean: 0.10897
[32m[0906 15-15-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03410, current rewards: 186.48987, mean: 0.10906
[32m[0906 15-15-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03408, current rewards: 192.08063, mean: 0.10914
[32m[0906 15-15-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03407, current rewards: 197.67981, mean: 0.10922
[32m[0906 15-15-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03407, current rewards: 203.27478, mean: 0.10929
[32m[0906 15-15-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03405, current rewards: 206.77762, mean: 0.10826
[32m[0906 15-15-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03404, current rewards: 212.36155, mean: 0.10835
[32m[0906 15-15-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03403, current rewards: 217.94105, mean: 0.10843
[32m[0906 15-15-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03405, current rewards: 223.52936, mean: 0.10851
[32m[0906 15-15-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03406, current rewards: 229.11817, mean: 0.10859
[32m[0906 15-15-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03407, current rewards: 234.70443, mean: 0.10866
[32m[0906 15-15-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03409, current rewards: 240.28950, mean: 0.10873
[32m[0906 15-15-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03412, current rewards: 245.87735, mean: 0.10880
[32m[0906 15-15-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03415, current rewards: 251.35443, mean: 0.10881
[32m[0906 15-15-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03417, current rewards: 256.94350, mean: 0.10887
[32m[0906 15-15-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03420, current rewards: 261.47901, mean: 0.10850
[32m[0906 15-15-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03423, current rewards: 267.05203, mean: 0.10856
[32m[0906 15-15-40 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-15-40 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-15-40 @MBExp.py:227][0m Rewards obtained: [271.5130691058877], Lows: [2], Highs: [4], Total time: 3780.972665999999
[32m[0906 15-17-10 @MBExp.py:144][0m ####################################################################
[32m[0906 15-17-10 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 15-17-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03262, current rewards: -0.01388, mean: -0.00139
[32m[0906 15-17-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03328, current rewards: 5.54064, mean: 0.09234
[32m[0906 15-17-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03331, current rewards: 11.11328, mean: 0.10103
[32m[0906 15-17-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03335, current rewards: 16.69139, mean: 0.10432
[32m[0906 15-17-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03330, current rewards: 22.27222, mean: 0.10606
[32m[0906 15-17-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03333, current rewards: 28.04984, mean: 0.10788
[32m[0906 15-17-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03335, current rewards: 33.71780, mean: 0.10877
[32m[0906 15-17-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03341, current rewards: 39.38678, mean: 0.10941
[32m[0906 15-17-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03343, current rewards: 45.05798, mean: 0.10990
[32m[0906 15-17-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03350, current rewards: 50.72526, mean: 0.11027
[32m[0906 15-17-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03359, current rewards: 54.38295, mean: 0.10663
[32m[0906 15-17-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03368, current rewards: 59.99456, mean: 0.10713
[32m[0906 15-17-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03377, current rewards: 65.60444, mean: 0.10755
[32m[0906 15-17-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03381, current rewards: 71.09850, mean: 0.10772
[32m[0906 15-17-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03384, current rewards: 76.69637, mean: 0.10802
[32m[0906 15-17-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03389, current rewards: 82.29548, mean: 0.10828
[32m[0906 15-17-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03392, current rewards: 86.79858, mean: 0.10716
[32m[0906 15-17-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03395, current rewards: 92.27445, mean: 0.10730
[32m[0906 15-17-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03398, current rewards: 97.74934, mean: 0.10742
[32m[0906 15-17-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03399, current rewards: 103.22692, mean: 0.10753
[32m[0906 15-17-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03401, current rewards: 108.70413, mean: 0.10763
[32m[0906 15-17-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03402, current rewards: 114.18026, mean: 0.10772
[32m[0906 15-17-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03404, current rewards: 119.66192, mean: 0.10780
[32m[0906 15-17-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03406, current rewards: 125.13955, mean: 0.10788
[32m[0906 15-17-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03407, current rewards: 128.69897, mean: 0.10636
[32m[0906 15-17-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03408, current rewards: 134.20616, mean: 0.10651
[32m[0906 15-17-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03409, current rewards: 139.71120, mean: 0.10665
[32m[0906 15-17-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03411, current rewards: 145.21568, mean: 0.10678
[32m[0906 15-17-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03411, current rewards: 150.72028, mean: 0.10689
[32m[0906 15-18-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03413, current rewards: 156.18002, mean: 0.10697
[32m[0906 15-18-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03412, current rewards: 161.67131, mean: 0.10707
[32m[0906 15-18-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03411, current rewards: 167.16787, mean: 0.10716
[32m[0906 15-18-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03409, current rewards: 171.47738, mean: 0.10651
[32m[0906 15-18-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03408, current rewards: 176.88093, mean: 0.10655
[32m[0906 15-18-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03406, current rewards: 182.28781, mean: 0.10660
[32m[0906 15-18-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03405, current rewards: 187.68766, mean: 0.10664
[32m[0906 15-18-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03404, current rewards: 193.09307, mean: 0.10668
[32m[0906 15-18-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03402, current rewards: 198.57795, mean: 0.10676
[32m[0906 15-18-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03401, current rewards: 204.11197, mean: 0.10686
[32m[0906 15-18-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03400, current rewards: 209.56880, mean: 0.10692
[32m[0906 15-18-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03400, current rewards: 214.10066, mean: 0.10652
[32m[0906 15-18-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03401, current rewards: 219.63020, mean: 0.10662
[32m[0906 15-18-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03402, current rewards: 225.16517, mean: 0.10671
[32m[0906 15-18-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03402, current rewards: 230.69845, mean: 0.10680
[32m[0906 15-18-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03403, current rewards: 236.23210, mean: 0.10689
[32m[0906 15-18-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03405, current rewards: 241.76301, mean: 0.10697
[32m[0906 15-18-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03407, current rewards: 247.11816, mean: 0.10698
[32m[0906 15-18-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03410, current rewards: 252.64835, mean: 0.10705
[32m[0906 15-18-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03413, current rewards: 258.17845, mean: 0.10713
[32m[0906 15-18-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03415, current rewards: 263.71939, mean: 0.10720
[32m[0906 15-18-36 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-18-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-18-36 @MBExp.py:227][0m Rewards obtained: [268.14951957042354], Lows: [2], Highs: [4], Total time: 3867.066001999999
[32m[0906 15-20-08 @MBExp.py:144][0m ####################################################################
[32m[0906 15-20-08 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 15-20-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03268, current rewards: -1.04800, mean: -0.10480
[32m[0906 15-20-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03340, current rewards: 4.60682, mean: 0.07678
[32m[0906 15-20-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03340, current rewards: 10.19860, mean: 0.09271
[32m[0906 15-20-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03341, current rewards: 15.78308, mean: 0.09864
[32m[0906 15-20-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03342, current rewards: 21.37540, mean: 0.10179
[32m[0906 15-20-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03345, current rewards: 26.80778, mean: 0.10311
[32m[0906 15-20-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03344, current rewards: 32.35420, mean: 0.10437
[32m[0906 15-20-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03347, current rewards: 37.90222, mean: 0.10528
[32m[0906 15-20-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03348, current rewards: 43.44956, mean: 0.10597
[32m[0906 15-20-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03356, current rewards: 48.99821, mean: 0.10652
[32m[0906 15-20-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03365, current rewards: 54.54761, mean: 0.10696
[32m[0906 15-20-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03373, current rewards: 59.11677, mean: 0.10557
[32m[0906 15-20-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03378, current rewards: 64.63086, mean: 0.10595
[32m[0906 15-20-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03382, current rewards: 70.14663, mean: 0.10628
[32m[0906 15-20-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03386, current rewards: 75.66353, mean: 0.10657
[32m[0906 15-20-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03389, current rewards: 81.17834, mean: 0.10681
[32m[0906 15-20-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03393, current rewards: 86.69099, mean: 0.10703
[32m[0906 15-20-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03395, current rewards: 92.20307, mean: 0.10721
[32m[0906 15-20-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03397, current rewards: 97.71996, mean: 0.10738
[32m[0906 15-20-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03400, current rewards: 103.24028, mean: 0.10754
[32m[0906 15-20-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03402, current rewards: 108.75851, mean: 0.10768
[32m[0906 15-20-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03403, current rewards: 114.51712, mean: 0.10804
[32m[0906 15-20-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03406, current rewards: 120.06022, mean: 0.10816
[32m[0906 15-20-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03407, current rewards: 125.60312, mean: 0.10828
[32m[0906 15-20-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03408, current rewards: 131.06707, mean: 0.10832
[32m[0906 15-20-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03409, current rewards: 136.57361, mean: 0.10839
[32m[0906 15-20-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03409, current rewards: 142.07133, mean: 0.10845
[32m[0906 15-20-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03410, current rewards: 147.57303, mean: 0.10851
[32m[0906 15-20-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03411, current rewards: 153.07134, mean: 0.10856
[32m[0906 15-20-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03412, current rewards: 158.60267, mean: 0.10863
[32m[0906 15-21-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03411, current rewards: 164.09828, mean: 0.10867
[32m[0906 15-21-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03409, current rewards: 169.59533, mean: 0.10871
[32m[0906 15-21-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03408, current rewards: 171.09685, mean: 0.10627
[32m[0906 15-21-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03407, current rewards: 178.76099, mean: 0.10769
[32m[0906 15-21-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03405, current rewards: 186.41607, mean: 0.10902
[32m[0906 15-21-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03404, current rewards: 194.07115, mean: 0.11027
[32m[0906 15-21-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03403, current rewards: 201.72623, mean: 0.11145
[32m[0906 15-21-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03401, current rewards: 209.37014, mean: 0.11256
[32m[0906 15-21-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03400, current rewards: 212.81756, mean: 0.11142
[32m[0906 15-21-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03399, current rewards: 215.77773, mean: 0.11009
[32m[0906 15-21-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03399, current rewards: 172.13295, mean: 0.08564
[32m[0906 15-21-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03400, current rewards: 122.13295, mean: 0.05929
[32m[0906 15-21-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03401, current rewards: 72.13295, mean: 0.03419
[32m[0906 15-21-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03401, current rewards: 22.13295, mean: 0.01025
[32m[0906 15-21-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03402, current rewards: -27.86705, mean: -0.01261
[32m[0906 15-21-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03402, current rewards: -77.86705, mean: -0.03445
[32m[0906 15-21-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03403, current rewards: -127.86705, mean: -0.05535
[32m[0906 15-21-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03406, current rewards: -177.86705, mean: -0.07537
[32m[0906 15-21-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03408, current rewards: -227.86705, mean: -0.09455
[32m[0906 15-21-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03410, current rewards: -277.86705, mean: -0.11295
[32m[0906 15-21-34 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-21-34 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-21-34 @MBExp.py:227][0m Rewards obtained: [-317.86705123591446], Lows: [2], Highs: [537], Total time: 3953.019451999999
[32m[0906 15-23-08 @MBExp.py:144][0m ####################################################################
[32m[0906 15-23-08 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 15-23-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03270, current rewards: 0.06050, mean: 0.00605
[32m[0906 15-23-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03338, current rewards: 5.59928, mean: 0.09332
[32m[0906 15-23-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03344, current rewards: 11.14183, mean: 0.10129
[32m[0906 15-23-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03356, current rewards: 16.68120, mean: 0.10426
[32m[0906 15-23-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03358, current rewards: 22.29469, mean: 0.10617
[32m[0906 15-23-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03359, current rewards: 27.86327, mean: 0.10717
[32m[0906 15-23-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03359, current rewards: 33.40610, mean: 0.10776
[32m[0906 15-23-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03361, current rewards: 38.94657, mean: 0.10818
[32m[0906 15-23-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03362, current rewards: 44.48551, mean: 0.10850
[32m[0906 15-23-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03369, current rewards: 48.94839, mean: 0.10641
[32m[0906 15-23-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03377, current rewards: 54.49181, mean: 0.10685
[32m[0906 15-23-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03383, current rewards: 60.02688, mean: 0.10719
[32m[0906 15-23-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03389, current rewards: 65.56362, mean: 0.10748
[32m[0906 15-23-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03392, current rewards: 71.04359, mean: 0.10764
[32m[0906 15-23-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03395, current rewards: 76.57287, mean: 0.10785
[32m[0906 15-23-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03398, current rewards: 82.10563, mean: 0.10803
[32m[0906 15-23-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03401, current rewards: 87.63621, mean: 0.10819
[32m[0906 15-23-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03404, current rewards: 93.16134, mean: 0.10833
[32m[0906 15-23-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03407, current rewards: 98.68668, mean: 0.10845
[32m[0906 15-23-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03410, current rewards: 100.13240, mean: 0.10430
[32m[0906 15-23-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03412, current rewards: 105.66630, mean: 0.10462
[32m[0906 15-23-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03414, current rewards: 110.92419, mean: 0.10465
[32m[0906 15-23-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03416, current rewards: 116.47265, mean: 0.10493
[32m[0906 15-23-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03419, current rewards: 122.01921, mean: 0.10519
[32m[0906 15-23-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03420, current rewards: 127.56469, mean: 0.10543
[32m[0906 15-23-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03421, current rewards: 133.10815, mean: 0.10564
[32m[0906 15-23-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03422, current rewards: 138.65559, mean: 0.10584
[32m[0906 15-23-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03423, current rewards: 144.19613, mean: 0.10603
[32m[0906 15-23-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03424, current rewards: 148.60167, mean: 0.10539
[32m[0906 15-23-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03424, current rewards: 154.27704, mean: 0.10567
[32m[0906 15-24-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03422, current rewards: 159.98519, mean: 0.10595
[32m[0906 15-24-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03420, current rewards: 165.52505, mean: 0.10611
[32m[0906 15-24-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03419, current rewards: 171.06294, mean: 0.10625
[32m[0906 15-24-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03417, current rewards: 176.60613, mean: 0.10639
[32m[0906 15-24-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03416, current rewards: 182.14891, mean: 0.10652
[32m[0906 15-24-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03415, current rewards: 187.69158, mean: 0.10664
[32m[0906 15-24-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03413, current rewards: 192.15324, mean: 0.10616
[32m[0906 15-24-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03412, current rewards: 197.70917, mean: 0.10630
[32m[0906 15-24-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03410, current rewards: 203.09492, mean: 0.10633
[32m[0906 15-24-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03409, current rewards: 208.59418, mean: 0.10643
[32m[0906 15-24-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03409, current rewards: 214.09393, mean: 0.10651
[32m[0906 15-24-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03410, current rewards: 219.59955, mean: 0.10660
[32m[0906 15-24-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03410, current rewards: 225.09954, mean: 0.10668
[32m[0906 15-24-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03411, current rewards: 230.59825, mean: 0.10676
[32m[0906 15-24-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03412, current rewards: 236.10129, mean: 0.10683
[32m[0906 15-24-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03413, current rewards: 241.65110, mean: 0.10693
[32m[0906 15-24-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03414, current rewards: 247.28173, mean: 0.10705
[32m[0906 15-24-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03416, current rewards: 252.85296, mean: 0.10714
[32m[0906 15-24-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03419, current rewards: 256.35230, mean: 0.10637
[32m[0906 15-24-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03421, current rewards: 261.88022, mean: 0.10646
[32m[0906 15-24-34 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-24-34 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-24-34 @MBExp.py:227][0m Rewards obtained: [266.31033531131123], Lows: [3], Highs: [4], Total time: 4039.250340999999
[32m[0906 15-26-10 @MBExp.py:144][0m ####################################################################
[32m[0906 15-26-10 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 15-26-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03277, current rewards: 0.94605, mean: 0.09460
[32m[0906 15-26-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03357, current rewards: 6.29071, mean: 0.10485
[32m[0906 15-26-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03353, current rewards: 11.87679, mean: 0.10797
[32m[0906 15-26-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03352, current rewards: 17.46347, mean: 0.10915
[32m[0906 15-26-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03355, current rewards: 23.05054, mean: 0.10976
[32m[0906 15-26-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03355, current rewards: 28.82627, mean: 0.11087
[32m[0906 15-26-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03356, current rewards: 34.42491, mean: 0.11105
[32m[0906 15-26-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03355, current rewards: 40.01505, mean: 0.11115
[32m[0906 15-26-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03357, current rewards: 45.60429, mean: 0.11123
[32m[0906 15-26-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03368, current rewards: 50.08334, mean: 0.10888
[32m[0906 15-26-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03373, current rewards: 55.64408, mean: 0.10911
[32m[0906 15-26-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03380, current rewards: 61.20100, mean: 0.10929
[32m[0906 15-26-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03385, current rewards: 66.75752, mean: 0.10944
[32m[0906 15-26-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03389, current rewards: 72.31134, mean: 0.10956
[32m[0906 15-26-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03394, current rewards: 77.74488, mean: 0.10950
[32m[0906 15-26-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03397, current rewards: 83.28680, mean: 0.10959
[32m[0906 15-26-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03399, current rewards: 88.82856, mean: 0.10966
[32m[0906 15-26-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03401, current rewards: 94.36913, mean: 0.10973
[32m[0906 15-26-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03404, current rewards: 99.91307, mean: 0.10979
[32m[0906 15-26-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03406, current rewards: 105.45357, mean: 0.10985
[32m[0906 15-26-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03407, current rewards: 108.89317, mean: 0.10782
[32m[0906 15-26-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03409, current rewards: 114.49333, mean: 0.10801
[32m[0906 15-26-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03410, current rewards: 120.41487, mean: 0.10848
[32m[0906 15-26-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03412, current rewards: 126.03489, mean: 0.10865
[32m[0906 15-26-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03413, current rewards: 131.65015, mean: 0.10880
[32m[0906 15-26-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03415, current rewards: 137.27121, mean: 0.10895
[32m[0906 15-26-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03416, current rewards: 141.87186, mean: 0.10830
[32m[0906 15-26-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03418, current rewards: 147.46829, mean: 0.10843
[32m[0906 15-26-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03419, current rewards: 153.06242, mean: 0.10855
[32m[0906 15-27-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03418, current rewards: 158.65904, mean: 0.10867
[32m[0906 15-27-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03416, current rewards: 164.23861, mean: 0.10877
[32m[0906 15-27-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03415, current rewards: 165.36742, mean: 0.10600
[32m[0906 15-27-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03413, current rewards: 170.86277, mean: 0.10613
[32m[0906 15-27-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03412, current rewards: 176.35690, mean: 0.10624
[32m[0906 15-27-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03411, current rewards: 181.85140, mean: 0.10635
[32m[0906 15-27-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03410, current rewards: 187.34898, mean: 0.10645
[32m[0906 15-27-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03408, current rewards: 192.84588, mean: 0.10654
[32m[0906 15-27-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03407, current rewards: 198.34351, mean: 0.10664
[32m[0906 15-27-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03406, current rewards: 203.84110, mean: 0.10672
[32m[0906 15-27-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03405, current rewards: 209.80741, mean: 0.10704
[32m[0906 15-27-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03405, current rewards: 216.73406, mean: 0.10783
[32m[0906 15-27-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03406, current rewards: 223.66072, mean: 0.10857
[32m[0906 15-27-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03407, current rewards: 193.01579, mean: 0.09148
[32m[0906 15-27-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03408, current rewards: 143.01579, mean: 0.06621
[32m[0906 15-27-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03409, current rewards: 93.01579, mean: 0.04209
[32m[0906 15-27-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03410, current rewards: 43.01579, mean: 0.01903
[32m[0906 15-27-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03411, current rewards: -6.98421, mean: -0.00302
[32m[0906 15-27-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03412, current rewards: -56.98421, mean: -0.02415
[32m[0906 15-27-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03413, current rewards: -106.98421, mean: -0.04439
[32m[0906 15-27-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03416, current rewards: -156.98421, mean: -0.06381
[32m[0906 15-27-36 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-27-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-27-36 @MBExp.py:227][0m Rewards obtained: [-196.98421254844777], Lows: [3], Highs: [425], Total time: 4125.362971999999
[32m[0906 15-29-15 @MBExp.py:144][0m ####################################################################
[32m[0906 15-29-15 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 15-29-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03312, current rewards: 0.02534, mean: 0.00253
[32m[0906 15-29-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03365, current rewards: 5.72924, mean: 0.09549
[32m[0906 15-29-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03363, current rewards: 11.43729, mean: 0.10398
[32m[0906 15-29-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03368, current rewards: 17.14002, mean: 0.10713
[32m[0906 15-29-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03367, current rewards: 22.84168, mean: 0.10877
[32m[0906 15-29-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03368, current rewards: 28.54403, mean: 0.10978
[32m[0906 15-29-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03370, current rewards: 34.14615, mean: 0.11015
[32m[0906 15-29-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03370, current rewards: 39.80251, mean: 0.11056
[32m[0906 15-29-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03373, current rewards: 43.44079, mean: 0.10595
[32m[0906 15-29-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03381, current rewards: 49.08860, mean: 0.10671
[32m[0906 15-29-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03386, current rewards: 54.74178, mean: 0.10734
[32m[0906 15-29-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03392, current rewards: 60.38957, mean: 0.10784
[32m[0906 15-29-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03395, current rewards: 66.04220, mean: 0.10827
[32m[0906 15-29-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03400, current rewards: 71.69387, mean: 0.10863
[32m[0906 15-29-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03401, current rewards: 77.71626, mean: 0.10946
[32m[0906 15-29-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03404, current rewards: 83.62008, mean: 0.11003
[32m[0906 15-29-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03407, current rewards: 89.52044, mean: 0.11052
[32m[0906 15-29-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03409, current rewards: 95.42015, mean: 0.11095
[32m[0906 15-29-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03411, current rewards: 101.31984, mean: 0.11134
[32m[0906 15-29-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03413, current rewards: 107.22447, mean: 0.11169
[32m[0906 15-29-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03415, current rewards: 113.12410, mean: 0.11200
[32m[0906 15-29-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03416, current rewards: 116.68408, mean: 0.11008
[32m[0906 15-29-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03417, current rewards: 122.35729, mean: 0.11023
[32m[0906 15-29-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03419, current rewards: 127.96733, mean: 0.11032
[32m[0906 15-29-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03420, current rewards: 133.58164, mean: 0.11040
[32m[0906 15-29-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03420, current rewards: 139.19049, mean: 0.11047
[32m[0906 15-30-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03421, current rewards: 144.80415, mean: 0.11054
[32m[0906 15-30-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03422, current rewards: 150.39939, mean: 0.11059
[32m[0906 15-30-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03423, current rewards: 156.02250, mean: 0.11065
[32m[0906 15-30-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03420, current rewards: 161.64560, mean: 0.11072
[32m[0906 15-30-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03420, current rewards: 167.23754, mean: 0.11075
[32m[0906 15-30-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03418, current rewards: 172.85291, mean: 0.11080
[32m[0906 15-30-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03417, current rewards: 178.46587, mean: 0.11085
[32m[0906 15-30-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03415, current rewards: 184.08220, mean: 0.11089
[32m[0906 15-30-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03413, current rewards: 189.68892, mean: 0.11093
[32m[0906 15-30-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03413, current rewards: 195.25202, mean: 0.11094
[32m[0906 15-30-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03411, current rewards: 200.82040, mean: 0.11095
[32m[0906 15-30-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03410, current rewards: 206.39178, mean: 0.11096
[32m[0906 15-30-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03408, current rewards: 211.96314, mean: 0.11098
[32m[0906 15-30-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03407, current rewards: 215.51261, mean: 0.10996
[32m[0906 15-30-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03408, current rewards: 221.37578, mean: 0.11014
[32m[0906 15-30-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03409, current rewards: 227.24448, mean: 0.11031
[32m[0906 15-30-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03410, current rewards: 233.11425, mean: 0.11048
[32m[0906 15-30-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03411, current rewards: 238.99018, mean: 0.11064
[32m[0906 15-30-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03412, current rewards: 244.86134, mean: 0.11080
[32m[0906 15-30-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03413, current rewards: 250.72918, mean: 0.11094
[32m[0906 15-30-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03414, current rewards: 256.59728, mean: 0.11108
[32m[0906 15-30-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03414, current rewards: 262.46582, mean: 0.11121
[32m[0906 15-30-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03415, current rewards: 268.33664, mean: 0.11134
[32m[0906 15-30-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03417, current rewards: 274.19911, mean: 0.11146
[32m[0906 15-30-41 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-30-41 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-30-41 @MBExp.py:227][0m Rewards obtained: [277.570503313004], Lows: [2], Highs: [4], Total time: 4211.505790999999
[32m[0906 15-32-22 @MBExp.py:144][0m ####################################################################
[32m[0906 15-32-22 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 15-32-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03412, current rewards: -0.09180, mean: -0.00918
[32m[0906 15-32-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03354, current rewards: 5.21083, mean: 0.08685
[32m[0906 15-32-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03353, current rewards: 10.66211, mean: 0.09693
[32m[0906 15-32-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03355, current rewards: 16.11669, mean: 0.10073
[32m[0906 15-32-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03353, current rewards: 21.56930, mean: 0.10271
[32m[0906 15-32-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03354, current rewards: 27.14856, mean: 0.10442
[32m[0906 15-32-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03359, current rewards: 32.58337, mean: 0.10511
[32m[0906 15-32-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03360, current rewards: 38.02193, mean: 0.10562
[32m[0906 15-32-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03365, current rewards: 43.46414, mean: 0.10601
[32m[0906 15-32-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03374, current rewards: 48.89727, mean: 0.10630
[32m[0906 15-32-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03380, current rewards: 54.33353, mean: 0.10654
[32m[0906 15-32-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03385, current rewards: 59.76858, mean: 0.10673
[32m[0906 15-32-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03390, current rewards: 65.20151, mean: 0.10689
[32m[0906 15-32-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03394, current rewards: 69.52481, mean: 0.10534
[32m[0906 15-32-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03397, current rewards: 74.98398, mean: 0.10561
[32m[0906 15-32-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03400, current rewards: 80.43890, mean: 0.10584
[32m[0906 15-32-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03404, current rewards: 85.89793, mean: 0.10605
[32m[0906 15-32-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03406, current rewards: 91.35973, mean: 0.10623
[32m[0906 15-32-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03410, current rewards: 96.82175, mean: 0.10640
[32m[0906 15-32-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03411, current rewards: 102.27993, mean: 0.10654
[32m[0906 15-32-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03413, current rewards: 103.32907, mean: 0.10231
[32m[0906 15-32-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03415, current rewards: 108.60015, mean: 0.10245
[32m[0906 15-33-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03417, current rewards: 113.85208, mean: 0.10257
[32m[0906 15-33-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03418, current rewards: 119.06941, mean: 0.10265
[32m[0906 15-33-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03419, current rewards: 124.28724, mean: 0.10272
[32m[0906 15-33-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03420, current rewards: 129.50386, mean: 0.10278
[32m[0906 15-33-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03421, current rewards: 132.69846, mean: 0.10130
[32m[0906 15-33-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03422, current rewards: 138.27103, mean: 0.10167
[32m[0906 15-33-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03422, current rewards: 143.84260, mean: 0.10202
[32m[0906 15-33-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03420, current rewards: 149.41697, mean: 0.10234
[32m[0906 15-33-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03418, current rewards: 154.87519, mean: 0.10257
[32m[0906 15-33-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03417, current rewards: 158.28057, mean: 0.10146
[32m[0906 15-33-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03415, current rewards: 163.85762, mean: 0.10177
[32m[0906 15-33-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03414, current rewards: 169.43719, mean: 0.10207
[32m[0906 15-33-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03413, current rewards: 175.01048, mean: 0.10235
[32m[0906 15-33-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03411, current rewards: 180.58184, mean: 0.10260
[32m[0906 15-33-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03410, current rewards: 186.15003, mean: 0.10285
[32m[0906 15-33-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03409, current rewards: 191.72315, mean: 0.10308
[32m[0906 15-33-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03408, current rewards: 197.46321, mean: 0.10338
[32m[0906 15-33-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03407, current rewards: 203.04510, mean: 0.10359
[32m[0906 15-33-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03408, current rewards: 208.62670, mean: 0.10379
[32m[0906 15-33-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03409, current rewards: 214.20687, mean: 0.10398
[32m[0906 15-33-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03410, current rewards: 217.64658, mean: 0.10315
[32m[0906 15-33-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03411, current rewards: 223.16937, mean: 0.10332
[32m[0906 15-33-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03412, current rewards: 228.69082, mean: 0.10348
[32m[0906 15-33-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03413, current rewards: 234.21294, mean: 0.10363
[32m[0906 15-33-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03414, current rewards: 239.81968, mean: 0.10382
[32m[0906 15-33-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03415, current rewards: 245.42775, mean: 0.10399
[32m[0906 15-33-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03416, current rewards: 251.03019, mean: 0.10416
[32m[0906 15-33-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03417, current rewards: 252.76507, mean: 0.10275
[32m[0906 15-33-48 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-33-48 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-33-48 @MBExp.py:227][0m Rewards obtained: [259.5954055014034], Lows: [6], Highs: [4], Total time: 4297.641642999999
[32m[0906 15-35-30 @MBExp.py:144][0m ####################################################################
[32m[0906 15-35-30 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 15-35-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03375, current rewards: -0.06944, mean: -0.00694
[32m[0906 15-35-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03341, current rewards: 7.16854, mean: 0.11948
[32m[0906 15-35-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03335, current rewards: 15.02808, mean: 0.13662
[32m[0906 15-35-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03338, current rewards: 22.88762, mean: 0.14305
[32m[0906 15-35-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03341, current rewards: 30.74716, mean: 0.14642
[32m[0906 15-35-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03350, current rewards: 36.92762, mean: 0.14203
[32m[0906 15-35-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03351, current rewards: 39.51485, mean: 0.12747
[32m[0906 15-35-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03351, current rewards: 43.90078, mean: 0.12195
[32m[0906 15-35-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03357, current rewards: 48.84675, mean: 0.11914
[32m[0906 15-35-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03366, current rewards: 53.78999, mean: 0.11693
[32m[0906 15-35-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03373, current rewards: 58.75492, mean: 0.11521
[32m[0906 15-35-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03380, current rewards: 62.77854, mean: 0.11210
[32m[0906 15-35-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03385, current rewards: 68.40219, mean: 0.11213
[32m[0906 15-35-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03390, current rewards: 74.03122, mean: 0.11217
[32m[0906 15-35-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03392, current rewards: 79.68999, mean: 0.11224
[32m[0906 15-35-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03395, current rewards: 85.30698, mean: 0.11225
[32m[0906 15-35-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03398, current rewards: 90.92216, mean: 0.11225
[32m[0906 15-36-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03401, current rewards: 96.53736, mean: 0.11225
[32m[0906 15-36-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03403, current rewards: 102.15488, mean: 0.11226
[32m[0906 15-36-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03405, current rewards: 107.77576, mean: 0.11227
[32m[0906 15-36-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03406, current rewards: 113.39320, mean: 0.11227
[32m[0906 15-36-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03406, current rewards: 119.01288, mean: 0.11228
[32m[0906 15-36-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03408, current rewards: 124.67036, mean: 0.11232
[32m[0906 15-36-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03408, current rewards: 130.28434, mean: 0.11231
[32m[0906 15-36-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03409, current rewards: 133.82354, mean: 0.11060
[32m[0906 15-36-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03410, current rewards: 139.44943, mean: 0.11067
[32m[0906 15-36-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03411, current rewards: 145.07704, mean: 0.11075
[32m[0906 15-36-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03412, current rewards: 150.70340, mean: 0.11081
[32m[0906 15-36-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03410, current rewards: 156.33201, mean: 0.11087
[32m[0906 15-36-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03408, current rewards: 160.86682, mean: 0.11018
[32m[0906 15-36-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03406, current rewards: 166.41279, mean: 0.11021
[32m[0906 15-36-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03405, current rewards: 172.04011, mean: 0.11028
[32m[0906 15-36-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03404, current rewards: 177.66755, mean: 0.11035
[32m[0906 15-36-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03402, current rewards: 183.29624, mean: 0.11042
[32m[0906 15-36-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03401, current rewards: 188.92415, mean: 0.11048
[32m[0906 15-36-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03400, current rewards: 192.43188, mean: 0.10934
[32m[0906 15-36-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03398, current rewards: 198.07119, mean: 0.10943
[32m[0906 15-36-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03398, current rewards: 203.70714, mean: 0.10952
[32m[0906 15-36-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03397, current rewards: 209.47744, mean: 0.10967
[32m[0906 15-36-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03398, current rewards: 215.12209, mean: 0.10976
[32m[0906 15-36-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03399, current rewards: 220.76809, mean: 0.10983
[32m[0906 15-36-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03400, current rewards: 226.40939, mean: 0.10991
[32m[0906 15-36-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03401, current rewards: 232.05071, mean: 0.10998
[32m[0906 15-36-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03402, current rewards: 237.69605, mean: 0.11004
[32m[0906 15-36-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03403, current rewards: 242.22251, mean: 0.10960
[32m[0906 15-36-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03404, current rewards: 247.79533, mean: 0.10964
[32m[0906 15-36-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03405, current rewards: 253.26676, mean: 0.10964
[32m[0906 15-36-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03406, current rewards: 258.83857, mean: 0.10968
[32m[0906 15-36-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03407, current rewards: 264.42516, mean: 0.10972
[32m[0906 15-36-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03408, current rewards: 270.01422, mean: 0.10976
[32m[0906 15-36-56 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-36-56 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-36-56 @MBExp.py:227][0m Rewards obtained: [274.48027468154504], Lows: [2], Highs: [4], Total time: 4383.542397999999
[32m[0906 15-38-41 @MBExp.py:144][0m ####################################################################
[32m[0906 15-38-41 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 15-38-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03403, current rewards: -0.11295, mean: -0.01130
[32m[0906 15-38-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03368, current rewards: 5.42455, mean: 0.09041
[32m[0906 15-38-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03361, current rewards: 10.96926, mean: 0.09972
[32m[0906 15-38-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03361, current rewards: 16.51321, mean: 0.10321
[32m[0906 15-38-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03359, current rewards: 22.05643, mean: 0.10503
[32m[0906 15-38-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03360, current rewards: 26.71623, mean: 0.10275
[32m[0906 15-38-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03360, current rewards: 34.79052, mean: 0.11223
[32m[0906 15-38-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03361, current rewards: 42.86481, mean: 0.11907
[32m[0906 15-38-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03367, current rewards: 50.93909, mean: 0.12424
[32m[0906 15-38-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03374, current rewards: 59.01338, mean: 0.12829
[32m[0906 15-38-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03381, current rewards: 67.08767, mean: 0.13154
[32m[0906 15-39-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03388, current rewards: 65.87007, mean: 0.11763
[32m[0906 15-39-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03394, current rewards: 15.87007, mean: 0.02602
[32m[0906 15-39-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03397, current rewards: -34.12993, mean: -0.05171
[32m[0906 15-39-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03400, current rewards: -84.12993, mean: -0.11849
[32m[0906 15-39-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03404, current rewards: -134.12993, mean: -0.17649
[32m[0906 15-39-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03406, current rewards: -184.12993, mean: -0.22732
[32m[0906 15-39-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03408, current rewards: -234.12993, mean: -0.27224
[32m[0906 15-39-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03410, current rewards: -284.12993, mean: -0.31223
[32m[0906 15-39-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03411, current rewards: -334.12993, mean: -0.34805
[32m[0906 15-39-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03413, current rewards: -384.12993, mean: -0.38033
[32m[0906 15-39-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03415, current rewards: -434.12993, mean: -0.40956
[32m[0906 15-39-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03416, current rewards: -484.12993, mean: -0.43615
[32m[0906 15-39-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03418, current rewards: -534.12993, mean: -0.46046
[32m[0906 15-39-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03419, current rewards: -584.12993, mean: -0.48275
[32m[0906 15-39-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03420, current rewards: -634.12993, mean: -0.50328
[32m[0906 15-39-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03420, current rewards: -684.12993, mean: -0.52224
[32m[0906 15-39-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03419, current rewards: -734.12993, mean: -0.53980
[32m[0906 15-39-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03418, current rewards: -784.12993, mean: -0.55612
[32m[0906 15-39-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03415, current rewards: -834.12993, mean: -0.57132
[32m[0906 15-39-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03414, current rewards: -884.12993, mean: -0.58552
[32m[0906 15-39-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03412, current rewards: -934.12993, mean: -0.59880
[32m[0906 15-39-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03411, current rewards: -984.12993, mean: -0.61126
[32m[0906 15-39-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03408, current rewards: -1034.12993, mean: -0.62297
[32m[0906 15-39-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03407, current rewards: -1084.12993, mean: -0.63399
[32m[0906 15-39-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03406, current rewards: -1134.12993, mean: -0.64439
[32m[0906 15-39-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03405, current rewards: -1184.12993, mean: -0.65422
[32m[0906 15-39-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03404, current rewards: -1234.12993, mean: -0.66351
[32m[0906 15-39-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03402, current rewards: -1284.12993, mean: -0.67232
[32m[0906 15-39-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03403, current rewards: -1334.12993, mean: -0.68068
[32m[0906 15-39-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03404, current rewards: -1384.12993, mean: -0.68862
[32m[0906 15-39-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03405, current rewards: -1434.12993, mean: -0.69618
[32m[0906 15-39-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03406, current rewards: -1484.12993, mean: -0.70338
[32m[0906 15-39-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03406, current rewards: -1534.12993, mean: -0.71025
[32m[0906 15-39-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03407, current rewards: -1584.12993, mean: -0.71680
[32m[0906 15-39-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03408, current rewards: -1634.12993, mean: -0.72307
[32m[0906 15-40-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03409, current rewards: -1684.12993, mean: -0.72906
[32m[0906 15-40-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03410, current rewards: -1734.12993, mean: -0.73480
[32m[0906 15-40-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03411, current rewards: -1729.20557, mean: -0.71751
[32m[0906 15-40-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03412, current rewards: -1723.16031, mean: -0.70047
[32m[0906 15-40-07 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-40-07 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-40-07 @MBExp.py:227][0m Rewards obtained: [-1718.3240962142218], Lows: [1], Highs: [1810], Total time: 4469.531713999999
[32m[0906 15-41-53 @MBExp.py:144][0m ####################################################################
[32m[0906 15-41-53 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 15-41-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03236, current rewards: -0.05126, mean: -0.00513
[32m[0906 15-41-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03312, current rewards: 5.29934, mean: 0.08832
[32m[0906 15-41-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03355, current rewards: 10.73510, mean: 0.09759
[32m[0906 15-41-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03360, current rewards: 16.17858, mean: 0.10112
[32m[0906 15-42-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03357, current rewards: 21.60768, mean: 0.10289
[32m[0906 15-42-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03358, current rewards: 27.03093, mean: 0.10397
[32m[0906 15-42-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03356, current rewards: 32.46600, mean: 0.10473
[32m[0906 15-42-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03356, current rewards: 37.90031, mean: 0.10528
[32m[0906 15-42-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03360, current rewards: 43.33612, mean: 0.10570
[32m[0906 15-42-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03371, current rewards: 48.77718, mean: 0.10604
[32m[0906 15-42-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03376, current rewards: 52.10281, mean: 0.10216
[32m[0906 15-42-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03382, current rewards: 57.59824, mean: 0.10285
[32m[0906 15-42-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03389, current rewards: 63.09553, mean: 0.10344
[32m[0906 15-42-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03394, current rewards: 68.59031, mean: 0.10392
[32m[0906 15-42-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03398, current rewards: 74.08434, mean: 0.10434
[32m[0906 15-42-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03401, current rewards: 79.57483, mean: 0.10470
[32m[0906 15-42-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03403, current rewards: 85.07116, mean: 0.10503
[32m[0906 15-42-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03405, current rewards: 90.56503, mean: 0.10531
[32m[0906 15-42-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03406, current rewards: 96.06374, mean: 0.10556
[32m[0906 15-42-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03408, current rewards: 101.55961, mean: 0.10579
[32m[0906 15-42-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03409, current rewards: 107.05052, mean: 0.10599
[32m[0906 15-42-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03410, current rewards: 112.71306, mean: 0.10633
[32m[0906 15-42-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03411, current rewards: 116.68200, mean: 0.10512
[32m[0906 15-42-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03413, current rewards: 122.40751, mean: 0.10552
[32m[0906 15-42-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03415, current rewards: 128.13220, mean: 0.10589
[32m[0906 15-42-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03416, current rewards: 133.85745, mean: 0.10624
[32m[0906 15-42-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03417, current rewards: 139.58264, mean: 0.10655
[32m[0906 15-42-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03415, current rewards: 145.30752, mean: 0.10684
[32m[0906 15-42-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03413, current rewards: 151.03259, mean: 0.10712
[32m[0906 15-42-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03410, current rewards: 155.48304, mean: 0.10650
[32m[0906 15-42-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03408, current rewards: 160.77164, mean: 0.10647
[32m[0906 15-42-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03406, current rewards: 166.24646, mean: 0.10657
[32m[0906 15-42-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03405, current rewards: 171.72026, mean: 0.10666
[32m[0906 15-42-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03404, current rewards: 177.19514, mean: 0.10674
[32m[0906 15-42-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03402, current rewards: 182.67162, mean: 0.10683
[32m[0906 15-42-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03401, current rewards: 188.14275, mean: 0.10690
[32m[0906 15-42-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03400, current rewards: 192.54823, mean: 0.10638
[32m[0906 15-42-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03399, current rewards: 198.03736, mean: 0.10647
[32m[0906 15-42-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03399, current rewards: 203.51189, mean: 0.10655
[32m[0906 15-43-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03400, current rewards: 209.00243, mean: 0.10663
[32m[0906 15-43-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03401, current rewards: 214.48876, mean: 0.10671
[32m[0906 15-43-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03402, current rewards: 219.97671, mean: 0.10678
[32m[0906 15-43-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03402, current rewards: 224.43416, mean: 0.10637
[32m[0906 15-43-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03404, current rewards: 229.99533, mean: 0.10648
[32m[0906 15-43-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03405, current rewards: 235.55011, mean: 0.10658
[32m[0906 15-43-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03405, current rewards: 241.10770, mean: 0.10668
[32m[0906 15-43-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03407, current rewards: 246.70986, mean: 0.10680
[32m[0906 15-43-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03408, current rewards: 250.13913, mean: 0.10599
[32m[0906 15-43-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03408, current rewards: 255.65591, mean: 0.10608
[32m[0906 15-43-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03409, current rewards: 261.17279, mean: 0.10617
[32m[0906 15-43-19 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-43-19 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-43-19 @MBExp.py:227][0m Rewards obtained: [265.5906239435542], Lows: [3], Highs: [4], Total time: 4555.437159999999
[32m[0906 15-45-08 @MBExp.py:144][0m ####################################################################
[32m[0906 15-45-08 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 15-45-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03285, current rewards: 1.39279, mean: 0.13928
[32m[0906 15-45-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03324, current rewards: 7.70822, mean: 0.12847
[32m[0906 15-45-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03347, current rewards: 14.02364, mean: 0.12749
[32m[0906 15-45-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03351, current rewards: 20.33907, mean: 0.12712
[32m[0906 15-45-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03352, current rewards: 25.97572, mean: 0.12369
[32m[0906 15-45-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03352, current rewards: 29.35840, mean: 0.11292
[32m[0906 15-45-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03351, current rewards: 32.74107, mean: 0.10562
[32m[0906 15-45-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03354, current rewards: 36.12375, mean: 0.10034
[32m[0906 15-45-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03360, current rewards: 39.50642, mean: 0.09636
[32m[0906 15-45-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03370, current rewards: 42.88910, mean: 0.09324
[32m[0906 15-45-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03376, current rewards: 46.27177, mean: 0.09073
[32m[0906 15-45-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03382, current rewards: 29.36903, mean: 0.05244
[32m[0906 15-45-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03387, current rewards: -20.63097, mean: -0.03382
[32m[0906 15-45-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03391, current rewards: -70.63097, mean: -0.10702
[32m[0906 15-45-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03394, current rewards: -120.63097, mean: -0.16990
[32m[0906 15-45-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03397, current rewards: -170.63097, mean: -0.22451
[32m[0906 15-45-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03400, current rewards: -220.63097, mean: -0.27238
[32m[0906 15-45-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03402, current rewards: -270.63097, mean: -0.31469
[32m[0906 15-45-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03404, current rewards: -320.63097, mean: -0.35234
[32m[0906 15-45-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03405, current rewards: -370.63097, mean: -0.38607
[32m[0906 15-45-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03407, current rewards: -420.63097, mean: -0.41647
[32m[0906 15-45-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03409, current rewards: -470.63097, mean: -0.44399
[32m[0906 15-45-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03411, current rewards: -520.63097, mean: -0.46904
[32m[0906 15-45-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03412, current rewards: -570.63097, mean: -0.49192
[32m[0906 15-45-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03414, current rewards: -620.63097, mean: -0.51292
[32m[0906 15-45-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03415, current rewards: -670.63097, mean: -0.53225
[32m[0906 15-45-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03416, current rewards: -720.63097, mean: -0.55010
[32m[0906 15-45-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03413, current rewards: -770.63097, mean: -0.56664
[32m[0906 15-45-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03411, current rewards: -820.63097, mean: -0.58201
[32m[0906 15-45-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03410, current rewards: -870.63097, mean: -0.59632
[32m[0906 15-45-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03409, current rewards: -920.63097, mean: -0.60969
[32m[0906 15-46-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03407, current rewards: -970.63097, mean: -0.62220
[32m[0906 15-46-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03406, current rewards: -1020.63097, mean: -0.63393
[32m[0906 15-46-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03404, current rewards: -1070.63097, mean: -0.64496
[32m[0906 15-46-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03403, current rewards: -1120.63097, mean: -0.65534
[32m[0906 15-46-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03402, current rewards: -1170.63097, mean: -0.66513
[32m[0906 15-46-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03401, current rewards: -1220.63097, mean: -0.67438
[32m[0906 15-46-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03400, current rewards: -1270.63097, mean: -0.68313
[32m[0906 15-46-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03400, current rewards: -1320.63097, mean: -0.69143
[32m[0906 15-46-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03401, current rewards: -1370.63097, mean: -0.69930
[32m[0906 15-46-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03402, current rewards: -1420.63097, mean: -0.70678
[32m[0906 15-46-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03404, current rewards: -1470.63097, mean: -0.71390
[32m[0906 15-46-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03405, current rewards: -1520.63097, mean: -0.72068
[32m[0906 15-46-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03405, current rewards: -1570.63097, mean: -0.72714
[32m[0906 15-46-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03406, current rewards: -1620.63097, mean: -0.73332
[32m[0906 15-46-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03407, current rewards: -1670.63097, mean: -0.73922
[32m[0906 15-46-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03408, current rewards: -1720.63097, mean: -0.74486
[32m[0906 15-46-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03409, current rewards: -1770.63097, mean: -0.75027
[32m[0906 15-46-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03409, current rewards: -1820.63097, mean: -0.75545
[32m[0906 15-46-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03410, current rewards: -1870.63097, mean: -0.76042
[32m[0906 15-46-33 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-46-33 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-46-34 @MBExp.py:227][0m Rewards obtained: [-1910.6309686071872], Lows: [0], Highs: [1959], Total time: 4641.383949999999
[32m[0906 15-48-24 @MBExp.py:144][0m ####################################################################
[32m[0906 15-48-24 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 15-48-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03272, current rewards: 0.09589, mean: 0.00959
[32m[0906 15-48-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03333, current rewards: 5.70653, mean: 0.09511
[32m[0906 15-48-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03349, current rewards: 11.29093, mean: 0.10264
[32m[0906 15-48-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03350, current rewards: 16.83406, mean: 0.10521
[32m[0906 15-48-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03354, current rewards: 22.26247, mean: 0.10601
[32m[0906 15-48-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03349, current rewards: 27.81866, mean: 0.10699
[32m[0906 15-48-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03352, current rewards: 33.37533, mean: 0.10766
[32m[0906 15-48-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03352, current rewards: 38.93302, mean: 0.10815
[32m[0906 15-48-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03356, current rewards: 44.48950, mean: 0.10851
[32m[0906 15-48-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03364, current rewards: 50.04647, mean: 0.10880
[32m[0906 15-48-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03373, current rewards: 55.60496, mean: 0.10903
[32m[0906 15-48-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03378, current rewards: 61.16649, mean: 0.10923
[32m[0906 15-48-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03383, current rewards: 66.99180, mean: 0.10982
[32m[0906 15-48-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03387, current rewards: 72.57810, mean: 0.10997
[32m[0906 15-48-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03391, current rewards: 77.10431, mean: 0.10860
[32m[0906 15-48-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03394, current rewards: 82.74172, mean: 0.10887
[32m[0906 15-48-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03397, current rewards: 88.39568, mean: 0.10913
[32m[0906 15-48-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03399, current rewards: 94.04028, mean: 0.10935
[32m[0906 15-48-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03401, current rewards: 99.68550, mean: 0.10954
[32m[0906 15-48-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03403, current rewards: 103.20247, mean: 0.10750
[32m[0906 15-48-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03405, current rewards: 108.78741, mean: 0.10771
[32m[0906 15-49-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03406, current rewards: 114.37326, mean: 0.10790
[32m[0906 15-49-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03408, current rewards: 119.95598, mean: 0.10807
[32m[0906 15-49-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03409, current rewards: 125.54347, mean: 0.10823
[32m[0906 15-49-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03411, current rewards: 131.13147, mean: 0.10837
[32m[0906 15-49-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03412, current rewards: 136.71475, mean: 0.10850
[32m[0906 15-49-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03411, current rewards: 142.29909, mean: 0.10863
[32m[0906 15-49-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03410, current rewards: 147.88615, mean: 0.10874
[32m[0906 15-49-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03407, current rewards: 153.37252, mean: 0.10877
[32m[0906 15-49-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03405, current rewards: 158.89903, mean: 0.10883
[32m[0906 15-49-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03404, current rewards: 164.48332, mean: 0.10893
[32m[0906 15-49-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03402, current rewards: 170.06553, mean: 0.10902
[32m[0906 15-49-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03401, current rewards: 175.65292, mean: 0.10910
[32m[0906 15-49-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03399, current rewards: 181.23253, mean: 0.10918
[32m[0906 15-49-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03398, current rewards: 186.81625, mean: 0.10925
[32m[0906 15-49-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03396, current rewards: 192.39714, mean: 0.10932
[32m[0906 15-49-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03396, current rewards: 197.96069, mean: 0.10937
[32m[0906 15-49-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03395, current rewards: 203.46749, mean: 0.10939
[32m[0906 15-49-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03396, current rewards: 209.05333, mean: 0.10945
[32m[0906 15-49-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03397, current rewards: 214.64401, mean: 0.10951
[32m[0906 15-49-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03398, current rewards: 220.23203, mean: 0.10957
[32m[0906 15-49-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03400, current rewards: 225.83123, mean: 0.10963
[32m[0906 15-49-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03401, current rewards: 231.41577, mean: 0.10968
[32m[0906 15-49-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03402, current rewards: 237.00287, mean: 0.10972
[32m[0906 15-49-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03403, current rewards: 240.52155, mean: 0.10883
[32m[0906 15-49-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03404, current rewards: 246.15313, mean: 0.10892
[32m[0906 15-49-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03405, current rewards: 251.83128, mean: 0.10902
[32m[0906 15-49-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03406, current rewards: 257.50555, mean: 0.10911
[32m[0906 15-49-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03407, current rewards: 263.17510, mean: 0.10920
[32m[0906 15-49-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03407, current rewards: 268.84986, mean: 0.10929
[32m[0906 15-49-50 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-49-50 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-49-50 @MBExp.py:227][0m Rewards obtained: [273.3877106789217], Lows: [2], Highs: [2], Total time: 4727.231642999998
[32m[0906 15-51-42 @MBExp.py:144][0m ####################################################################
[32m[0906 15-51-42 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 15-51-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03345, current rewards: -0.05774, mean: -0.00577
[32m[0906 15-51-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03345, current rewards: 5.42250, mean: 0.09038
[32m[0906 15-51-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03346, current rewards: 10.90332, mean: 0.09912
[32m[0906 15-51-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03347, current rewards: 16.37565, mean: 0.10235
[32m[0906 15-51-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03345, current rewards: 21.84471, mean: 0.10402
[32m[0906 15-51-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03346, current rewards: 27.31742, mean: 0.10507
[32m[0906 15-51-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03342, current rewards: 32.79914, mean: 0.10580
[32m[0906 15-51-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03343, current rewards: 38.27761, mean: 0.10633
[32m[0906 15-51-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03350, current rewards: 43.75371, mean: 0.10672
[32m[0906 15-51-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03361, current rewards: 49.16968, mean: 0.10689
[32m[0906 15-52-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03370, current rewards: 54.68886, mean: 0.10723
[32m[0906 15-52-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03375, current rewards: 60.20439, mean: 0.10751
[32m[0906 15-52-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03379, current rewards: 65.72055, mean: 0.10774
[32m[0906 15-52-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03385, current rewards: 71.24326, mean: 0.10794
[32m[0906 15-52-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03389, current rewards: 76.73023, mean: 0.10807
[32m[0906 15-52-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03393, current rewards: 82.30466, mean: 0.10830
[32m[0906 15-52-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03396, current rewards: 87.87609, mean: 0.10849
[32m[0906 15-52-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03399, current rewards: 93.44686, mean: 0.10866
[32m[0906 15-52-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03401, current rewards: 99.02062, mean: 0.10881
[32m[0906 15-52-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03403, current rewards: 104.61719, mean: 0.10898
[32m[0906 15-52-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03404, current rewards: 110.16778, mean: 0.10908
[32m[0906 15-52-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03406, current rewards: 115.72584, mean: 0.10918
[32m[0906 15-52-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03407, current rewards: 121.23784, mean: 0.10922
[32m[0906 15-52-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03409, current rewards: 126.80156, mean: 0.10931
[32m[0906 15-52-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03410, current rewards: 132.36737, mean: 0.10939
[32m[0906 15-52-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03412, current rewards: 137.93032, mean: 0.10947
[32m[0906 15-52-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03410, current rewards: 143.49146, mean: 0.10954
[32m[0906 15-52-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03408, current rewards: 149.15505, mean: 0.10967
[32m[0906 15-52-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03407, current rewards: 154.67607, mean: 0.10970
[32m[0906 15-52-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03405, current rewards: 160.19653, mean: 0.10972
[32m[0906 15-52-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03404, current rewards: 163.63715, mean: 0.10837
[32m[0906 15-52-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03403, current rewards: 169.24076, mean: 0.10849
[32m[0906 15-52-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03401, current rewards: 174.81958, mean: 0.10858
[32m[0906 15-52-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03400, current rewards: 180.39391, mean: 0.10867
[32m[0906 15-52-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03399, current rewards: 185.97344, mean: 0.10876
[32m[0906 15-52-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03398, current rewards: 191.42354, mean: 0.10876
[32m[0906 15-52-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03397, current rewards: 197.10117, mean: 0.10890
[32m[0906 15-52-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03396, current rewards: 200.79768, mean: 0.10796
[32m[0906 15-52-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03397, current rewards: 206.41935, mean: 0.10807
[32m[0906 15-52-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03398, current rewards: 212.04280, mean: 0.10819
[32m[0906 15-52-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03400, current rewards: 217.67015, mean: 0.10829
[32m[0906 15-52-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03401, current rewards: 223.29359, mean: 0.10839
[32m[0906 15-52-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03403, current rewards: 228.91618, mean: 0.10849
[32m[0906 15-52-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03403, current rewards: 234.51898, mean: 0.10857
[32m[0906 15-52-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03404, current rewards: 240.11793, mean: 0.10865
[32m[0906 15-53-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03405, current rewards: 245.77061, mean: 0.10875
[32m[0906 15-53-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03406, current rewards: 251.42377, mean: 0.10884
[32m[0906 15-53-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03407, current rewards: 257.07863, mean: 0.10893
[32m[0906 15-53-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03408, current rewards: 262.73498, mean: 0.10902
[32m[0906 15-53-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03409, current rewards: 268.38837, mean: 0.10910
[32m[0906 15-53-08 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-53-08 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-53-08 @MBExp.py:227][0m Rewards obtained: [272.9105513435336], Lows: [2], Highs: [1], Total time: 4813.122168999998
[32m[0906 15-55-03 @MBExp.py:144][0m ####################################################################
[32m[0906 15-55-03 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 15-55-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03299, current rewards: 0.32323, mean: 0.03232
[32m[0906 15-55-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03372, current rewards: 5.91204, mean: 0.09853
[32m[0906 15-55-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03365, current rewards: 11.38893, mean: 0.10354
[32m[0906 15-55-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03358, current rewards: 16.95718, mean: 0.10598
[32m[0906 15-55-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03363, current rewards: 22.52386, mean: 0.10726
[32m[0906 15-55-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03365, current rewards: 28.08752, mean: 0.10803
[32m[0906 15-55-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03362, current rewards: 33.66083, mean: 0.10858
[32m[0906 15-55-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03361, current rewards: 39.22819, mean: 0.10897
[32m[0906 15-55-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03369, current rewards: 44.79120, mean: 0.10925
[32m[0906 15-55-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03377, current rewards: 50.35951, mean: 0.10948
[32m[0906 15-55-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03383, current rewards: 55.79982, mean: 0.10941
[32m[0906 15-55-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03388, current rewards: 61.35117, mean: 0.10956
[32m[0906 15-55-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03393, current rewards: 65.81136, mean: 0.10789
[32m[0906 15-55-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03396, current rewards: 71.34954, mean: 0.10811
[32m[0906 15-55-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03400, current rewards: 76.88457, mean: 0.10829
[32m[0906 15-55-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03403, current rewards: 82.42443, mean: 0.10845
[32m[0906 15-55-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03405, current rewards: 87.96376, mean: 0.10860
[32m[0906 15-55-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03408, current rewards: 93.49239, mean: 0.10871
[32m[0906 15-55-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03410, current rewards: 99.16154, mean: 0.10897
[32m[0906 15-55-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03411, current rewards: 104.80052, mean: 0.10917
[32m[0906 15-55-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03414, current rewards: 108.38618, mean: 0.10731
[32m[0906 15-55-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03415, current rewards: 113.94564, mean: 0.10750
[32m[0906 15-55-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03416, current rewards: 119.50384, mean: 0.10766
[32m[0906 15-55-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03417, current rewards: 125.06934, mean: 0.10782
[32m[0906 15-55-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03419, current rewards: 130.63166, mean: 0.10796
[32m[0906 15-55-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03418, current rewards: 135.09330, mean: 0.10722
[32m[0906 15-55-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03415, current rewards: 140.64590, mean: 0.10736
[32m[0906 15-55-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03414, current rewards: 146.12527, mean: 0.10745
[32m[0906 15-55-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03412, current rewards: 151.68676, mean: 0.10758
[32m[0906 15-55-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03410, current rewards: 157.24661, mean: 0.10770
[32m[0906 15-55-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03408, current rewards: 162.81297, mean: 0.10782
[32m[0906 15-55-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03406, current rewards: 166.26383, mean: 0.10658
[32m[0906 15-55-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03405, current rewards: 169.70662, mean: 0.10541
[32m[0906 15-55-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03403, current rewards: 175.17469, mean: 0.10553
[32m[0906 15-56-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03402, current rewards: 180.64143, mean: 0.10564
[32m[0906 15-56-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03401, current rewards: 186.17232, mean: 0.10578
[32m[0906 15-56-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03399, current rewards: 191.64515, mean: 0.10588
[32m[0906 15-56-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03400, current rewards: 197.11786, mean: 0.10598
[32m[0906 15-56-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03401, current rewards: 200.32782, mean: 0.10488
[32m[0906 15-56-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03403, current rewards: 205.90861, mean: 0.10506
[32m[0906 15-56-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03404, current rewards: 211.49173, mean: 0.10522
[32m[0906 15-56-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03405, current rewards: 217.07488, mean: 0.10538
[32m[0906 15-56-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03407, current rewards: 222.66136, mean: 0.10553
[32m[0906 15-56-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03408, current rewards: 228.29927, mean: 0.10569
[32m[0906 15-56-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03409, current rewards: 233.89047, mean: 0.10583
[32m[0906 15-56-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03410, current rewards: 238.30853, mean: 0.10545
[32m[0906 15-56-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03410, current rewards: 243.86903, mean: 0.10557
[32m[0906 15-56-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03412, current rewards: 249.42936, mean: 0.10569
[32m[0906 15-56-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03412, current rewards: 254.98180, mean: 0.10580
[32m[0906 15-56-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03413, current rewards: 260.53211, mean: 0.10591
[32m[0906 15-56-28 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-56-28 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-56-29 @MBExp.py:227][0m Rewards obtained: [264.97801162447956], Lows: [3], Highs: [6], Total time: 4899.143947999998
[32m[0906 15-58-25 @MBExp.py:144][0m ####################################################################
[32m[0906 15-58-25 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 15-58-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03357, current rewards: 0.06607, mean: 0.00661
[32m[0906 15-58-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03340, current rewards: 5.72364, mean: 0.09539
[32m[0906 15-58-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03344, current rewards: 11.17076, mean: 0.10155
[32m[0906 15-58-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03351, current rewards: 16.75418, mean: 0.10471
[32m[0906 15-58-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03350, current rewards: 22.33671, mean: 0.10637
[32m[0906 15-58-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03354, current rewards: 27.91758, mean: 0.10738
[32m[0906 15-58-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03355, current rewards: 33.49926, mean: 0.10806
[32m[0906 15-58-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03352, current rewards: 36.93991, mean: 0.10261
[32m[0906 15-58-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03360, current rewards: 42.63859, mean: 0.10400
[32m[0906 15-58-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03368, current rewards: 48.32998, mean: 0.10507
[32m[0906 15-58-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03375, current rewards: 54.19103, mean: 0.10626
[32m[0906 15-58-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03383, current rewards: 59.87530, mean: 0.10692
[32m[0906 15-58-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03388, current rewards: 65.55675, mean: 0.10747
[32m[0906 15-58-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03393, current rewards: 71.24216, mean: 0.10794
[32m[0906 15-58-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03398, current rewards: 76.92415, mean: 0.10834
[32m[0906 15-58-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03401, current rewards: 82.61048, mean: 0.10870
[32m[0906 15-58-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03405, current rewards: 88.29446, mean: 0.10901
[32m[0906 15-58-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03407, current rewards: 93.97810, mean: 0.10928
[32m[0906 15-58-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03410, current rewards: 99.60642, mean: 0.10946
[32m[0906 15-58-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03412, current rewards: 103.02668, mean: 0.10732
[32m[0906 15-59-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03413, current rewards: 108.61306, mean: 0.10754
[32m[0906 15-59-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03415, current rewards: 114.20112, mean: 0.10774
[32m[0906 15-59-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03416, current rewards: 119.78886, mean: 0.10792
[32m[0906 15-59-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03418, current rewards: 125.37899, mean: 0.10809
[32m[0906 15-59-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03419, current rewards: 130.96322, mean: 0.10823
[32m[0906 15-59-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03415, current rewards: 136.55088, mean: 0.10837
[32m[0906 15-59-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03415, current rewards: 142.03475, mean: 0.10842
[32m[0906 15-59-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03412, current rewards: 147.61094, mean: 0.10854
[32m[0906 15-59-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03410, current rewards: 153.19950, mean: 0.10865
[32m[0906 15-59-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03408, current rewards: 158.77406, mean: 0.10875
[32m[0906 15-59-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03406, current rewards: 164.35589, mean: 0.10884
[32m[0906 15-59-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03406, current rewards: 169.93498, mean: 0.10893
[32m[0906 15-59-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03405, current rewards: 175.51995, mean: 0.10902
[32m[0906 15-59-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03403, current rewards: 181.04135, mean: 0.10906
[32m[0906 15-59-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03402, current rewards: 186.52738, mean: 0.10908
[32m[0906 15-59-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03400, current rewards: 191.99993, mean: 0.10909
[32m[0906 15-59-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03399, current rewards: 197.46671, mean: 0.10910
[32m[0906 15-59-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03400, current rewards: 202.94174, mean: 0.10911
[32m[0906 15-59-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03402, current rewards: 208.41691, mean: 0.10912
[32m[0906 15-59-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03403, current rewards: 213.89497, mean: 0.10913
[32m[0906 15-59-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03404, current rewards: 219.36706, mean: 0.10914
[32m[0906 15-59-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03405, current rewards: 224.83866, mean: 0.10914
[32m[0906 15-59-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03406, current rewards: 230.35643, mean: 0.10917
[32m[0906 15-59-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03408, current rewards: 235.86513, mean: 0.10920
[32m[0906 15-59-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03409, current rewards: 241.35936, mean: 0.10921
[32m[0906 15-59-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03410, current rewards: 244.71575, mean: 0.10828
[32m[0906 15-59-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03411, current rewards: 250.32899, mean: 0.10837
[32m[0906 15-59-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03412, current rewards: 255.93961, mean: 0.10845
[32m[0906 15-59-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03413, current rewards: 261.54766, mean: 0.10853
[32m[0906 15-59-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03414, current rewards: 267.15657, mean: 0.10860
[32m[0906 15-59-51 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-59-51 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-59-51 @MBExp.py:227][0m Rewards obtained: [271.6489053427899], Lows: [2], Highs: [3], Total time: 4985.185575999998
[32m[0906 16-01-50 @MBExp.py:144][0m ####################################################################
[32m[0906 16-01-50 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 16-01-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03353, current rewards: -0.13123, mean: -0.01312
[32m[0906 16-01-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03365, current rewards: 5.33265, mean: 0.08888
[32m[0906 16-01-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03361, current rewards: 10.90024, mean: 0.09909
[32m[0906 16-01-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03357, current rewards: 16.46927, mean: 0.10293
[32m[0906 16-01-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03355, current rewards: 22.03927, mean: 0.10495
[32m[0906 16-01-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03358, current rewards: 27.60807, mean: 0.10618
[32m[0906 16-02-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03361, current rewards: 33.17512, mean: 0.10702
[32m[0906 16-02-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03361, current rewards: 38.73894, mean: 0.10761
[32m[0906 16-02-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03367, current rewards: 44.30849, mean: 0.10807
[32m[0906 16-02-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03374, current rewards: 49.94714, mean: 0.10858
[32m[0906 16-02-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03382, current rewards: 55.52053, mean: 0.10886
[32m[0906 16-02-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03387, current rewards: 61.09384, mean: 0.10910
[32m[0906 16-02-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03392, current rewards: 66.66725, mean: 0.10929
[32m[0906 16-02-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03396, current rewards: 72.24255, mean: 0.10946
[32m[0906 16-02-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03399, current rewards: 77.81818, mean: 0.10960
[32m[0906 16-02-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03402, current rewards: 83.39197, mean: 0.10973
[32m[0906 16-02-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03404, current rewards: 88.96655, mean: 0.10984
[32m[0906 16-02-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03407, current rewards: 94.51329, mean: 0.10990
[32m[0906 16-02-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03409, current rewards: 98.97348, mean: 0.10876
[32m[0906 16-02-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03411, current rewards: 104.54473, mean: 0.10890
[32m[0906 16-02-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03414, current rewards: 110.11419, mean: 0.10902
[32m[0906 16-02-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03416, current rewards: 115.68180, mean: 0.10913
[32m[0906 16-02-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03417, current rewards: 121.25050, mean: 0.10923
[32m[0906 16-02-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03418, current rewards: 126.81818, mean: 0.10933
[32m[0906 16-02-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03416, current rewards: 132.38475, mean: 0.10941
[32m[0906 16-02-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03414, current rewards: 137.95666, mean: 0.10949
[32m[0906 16-02-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03411, current rewards: 143.53392, mean: 0.10957
[32m[0906 16-02-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03410, current rewards: 149.05257, mean: 0.10960
[32m[0906 16-02-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03408, current rewards: 154.62474, mean: 0.10966
[32m[0906 16-02-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03407, current rewards: 160.20318, mean: 0.10973
[32m[0906 16-02-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03406, current rewards: 165.78143, mean: 0.10979
[32m[0906 16-02-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03406, current rewards: 171.35758, mean: 0.10984
[32m[0906 16-02-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03404, current rewards: 176.93145, mean: 0.10990
[32m[0906 16-02-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03403, current rewards: 182.61028, mean: 0.11001
[32m[0906 16-02-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03402, current rewards: 188.18895, mean: 0.11005
[32m[0906 16-02-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03401, current rewards: 193.76981, mean: 0.11010
[32m[0906 16-02-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03400, current rewards: 199.35094, mean: 0.11014
[32m[0906 16-02-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03402, current rewards: 204.93247, mean: 0.11018
[32m[0906 16-02-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03403, current rewards: 210.51306, mean: 0.11022
[32m[0906 16-02-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03405, current rewards: 214.02860, mean: 0.10920
[32m[0906 16-02-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03406, current rewards: 219.66489, mean: 0.10929
[32m[0906 16-03-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03408, current rewards: 225.29100, mean: 0.10936
[32m[0906 16-03-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03409, current rewards: 230.92727, mean: 0.10944
[32m[0906 16-03-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03410, current rewards: 236.56479, mean: 0.10952
[32m[0906 16-03-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03411, current rewards: 242.20311, mean: 0.10959
[32m[0906 16-03-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03412, current rewards: 245.62829, mean: 0.10869
[32m[0906 16-03-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03413, current rewards: 251.20102, mean: 0.10875
[32m[0906 16-03-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03414, current rewards: 256.77209, mean: 0.10880
[32m[0906 16-03-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03414, current rewards: 262.34144, mean: 0.10886
[32m[0906 16-03-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03415, current rewards: 267.94585, mean: 0.10892
[32m[0906 16-03-16 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 16-03-16 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-03-16 @MBExp.py:227][0m Rewards obtained: [272.41717611048244], Lows: [1], Highs: [4], Total time: 5071.265112999998
[32m[0906 16-05-17 @MBExp.py:144][0m ####################################################################
[32m[0906 16-05-17 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 16-05-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03318, current rewards: 0.02593, mean: 0.00259
[32m[0906 16-05-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03357, current rewards: 5.61083, mean: 0.09351
[32m[0906 16-05-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03364, current rewards: 11.18618, mean: 0.10169
[32m[0906 16-05-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03359, current rewards: 16.76587, mean: 0.10479
[32m[0906 16-05-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03357, current rewards: 22.34371, mean: 0.10640
[32m[0906 16-05-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03358, current rewards: 27.92497, mean: 0.10740
[32m[0906 16-05-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03361, current rewards: 33.50587, mean: 0.10808
[32m[0906 16-05-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03361, current rewards: 39.08437, mean: 0.10857
[32m[0906 16-05-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03371, current rewards: 44.69002, mean: 0.10900
[32m[0906 16-05-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03381, current rewards: 50.27404, mean: 0.10929
[32m[0906 16-05-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03390, current rewards: 55.85518, mean: 0.10952
[32m[0906 16-05-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03394, current rewards: 60.44499, mean: 0.10794
[32m[0906 16-05-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03400, current rewards: 66.10108, mean: 0.10836
[32m[0906 16-05-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03405, current rewards: 71.75565, mean: 0.10872
[32m[0906 16-05-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03408, current rewards: 77.41618, mean: 0.10904
[32m[0906 16-05-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03410, current rewards: 83.07718, mean: 0.10931
[32m[0906 16-05-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03413, current rewards: 88.69493, mean: 0.10950
[32m[0906 16-05-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03416, current rewards: 94.34111, mean: 0.10970
[32m[0906 16-05-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03416, current rewards: 99.98962, mean: 0.10988
[32m[0906 16-05-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03417, current rewards: 105.63239, mean: 0.11003
[32m[0906 16-05-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03418, current rewards: 111.28130, mean: 0.11018
[32m[0906 16-05-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03419, current rewards: 114.63241, mean: 0.10814
[32m[0906 16-05-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03420, current rewards: 120.06760, mean: 0.10817
[32m[0906 16-05-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03420, current rewards: 125.50455, mean: 0.10819
[32m[0906 16-05-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03417, current rewards: 130.89966, mean: 0.10818
[32m[0906 16-06-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03414, current rewards: 136.32425, mean: 0.10819
[32m[0906 16-06-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03412, current rewards: 141.88234, mean: 0.10831
[32m[0906 16-06-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03410, current rewards: 147.40025, mean: 0.10838
[32m[0906 16-06-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03409, current rewards: 152.92045, mean: 0.10845
[32m[0906 16-06-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03407, current rewards: 158.43727, mean: 0.10852
[32m[0906 16-06-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03405, current rewards: 163.95084, mean: 0.10858
[32m[0906 16-06-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03403, current rewards: 169.46659, mean: 0.10863
[32m[0906 16-06-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03402, current rewards: 175.05683, mean: 0.10873
[32m[0906 16-06-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03400, current rewards: 180.57526, mean: 0.10878
[32m[0906 16-06-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03399, current rewards: 186.09605, mean: 0.10883
[32m[0906 16-06-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03398, current rewards: 191.61514, mean: 0.10887
[32m[0906 16-06-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03397, current rewards: 197.13693, mean: 0.10892
[32m[0906 16-06-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03399, current rewards: 202.65937, mean: 0.10896
[32m[0906 16-06-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03400, current rewards: 206.13638, mean: 0.10792
[32m[0906 16-06-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03401, current rewards: 211.64190, mean: 0.10798
[32m[0906 16-06-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03402, current rewards: 217.14285, mean: 0.10803
[32m[0906 16-06-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03404, current rewards: 222.65600, mean: 0.10809
[32m[0906 16-06-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03405, current rewards: 228.16555, mean: 0.10814
[32m[0906 16-06-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03406, current rewards: 233.67382, mean: 0.10818
[32m[0906 16-06-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03407, current rewards: 239.18509, mean: 0.10823
[32m[0906 16-06-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03408, current rewards: 244.70063, mean: 0.10827
[32m[0906 16-06-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03409, current rewards: 250.21895, mean: 0.10832
[32m[0906 16-06-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03410, current rewards: 255.73570, mean: 0.10836
[32m[0906 16-06-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03411, current rewards: 261.27617, mean: 0.10841
[32m[0906 16-06-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03412, current rewards: 265.41858, mean: 0.10789
[32m[0906 16-06-43 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 16-06-43 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-06-43 @MBExp.py:227][0m Rewards obtained: [270.1527521884688], Lows: [3], Highs: [2], Total time: 5157.260698999998
[32m[0906 16-08-46 @MBExp.py:144][0m ####################################################################
[32m[0906 16-08-46 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 16-08-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03275, current rewards: -0.95106, mean: -0.09511
[32m[0906 16-08-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03339, current rewards: 4.84426, mean: 0.08074
[32m[0906 16-08-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03346, current rewards: 10.64572, mean: 0.09678
[32m[0906 16-08-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03340, current rewards: 16.44631, mean: 0.10279
[32m[0906 16-08-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03346, current rewards: 22.24853, mean: 0.10595
[32m[0906 16-08-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03350, current rewards: 28.04728, mean: 0.10787
[32m[0906 16-08-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03352, current rewards: 33.71383, mean: 0.10875
[32m[0906 16-08-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03352, current rewards: 39.50255, mean: 0.10973
[32m[0906 16-08-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03365, current rewards: 45.34903, mean: 0.11061
[32m[0906 16-09-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03373, current rewards: 51.19368, mean: 0.11129
[32m[0906 16-09-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03378, current rewards: 57.03539, mean: 0.11183
[32m[0906 16-09-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03383, current rewards: 62.88013, mean: 0.11229
[32m[0906 16-09-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03388, current rewards: 68.72122, mean: 0.11266
[32m[0906 16-09-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03392, current rewards: 72.17173, mean: 0.10935
[32m[0906 16-09-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03396, current rewards: 77.74595, mean: 0.10950
[32m[0906 16-09-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03399, current rewards: 83.45370, mean: 0.10981
[32m[0906 16-09-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03400, current rewards: 89.03276, mean: 0.10992
[32m[0906 16-09-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03403, current rewards: 94.61670, mean: 0.11002
[32m[0906 16-09-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03406, current rewards: 100.20080, mean: 0.11011
[32m[0906 16-09-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03408, current rewards: 105.78548, mean: 0.11019
[32m[0906 16-09-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03411, current rewards: 111.36776, mean: 0.11027
[32m[0906 16-09-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03412, current rewards: 114.84487, mean: 0.10834
[32m[0906 16-09-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03413, current rewards: 120.40194, mean: 0.10847
[32m[0906 16-09-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03412, current rewards: 125.86475, mean: 0.10850
[32m[0906 16-09-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03410, current rewards: 131.41150, mean: 0.10860
[32m[0906 16-09-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03409, current rewards: 136.96196, mean: 0.10870
[32m[0906 16-09-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03408, current rewards: 142.51087, mean: 0.10879
[32m[0906 16-09-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03406, current rewards: 148.05846, mean: 0.10887
[32m[0906 16-09-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03404, current rewards: 153.60439, mean: 0.10894
[32m[0906 16-09-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03402, current rewards: 159.15214, mean: 0.10901
[32m[0906 16-09-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03400, current rewards: 164.70116, mean: 0.10907
[32m[0906 16-09-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03400, current rewards: 170.24555, mean: 0.10913
[32m[0906 16-09-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03398, current rewards: 175.79093, mean: 0.10919
[32m[0906 16-09-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03398, current rewards: 181.33796, mean: 0.10924
[32m[0906 16-09-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03396, current rewards: 186.88946, mean: 0.10929
[32m[0906 16-09-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03396, current rewards: 192.43323, mean: 0.10934
[32m[0906 16-09-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03396, current rewards: 197.89702, mean: 0.10934
[32m[0906 16-09-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03398, current rewards: 203.41807, mean: 0.10936
[32m[0906 16-09-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03399, current rewards: 208.94096, mean: 0.10939
[32m[0906 16-09-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03401, current rewards: 214.68123, mean: 0.10953
[32m[0906 16-09-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03403, current rewards: 220.29873, mean: 0.10960
[32m[0906 16-09-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03404, current rewards: 225.77891, mean: 0.10960
[32m[0906 16-09-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03404, current rewards: 231.33265, mean: 0.10964
[32m[0906 16-10-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03405, current rewards: 236.88852, mean: 0.10967
[32m[0906 16-10-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03407, current rewards: 242.44332, mean: 0.10970
[32m[0906 16-10-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03408, current rewards: 247.99906, mean: 0.10973
[32m[0906 16-10-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03409, current rewards: 253.55356, mean: 0.10976
[32m[0906 16-10-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03410, current rewards: 259.11269, mean: 0.10979
[32m[0906 16-10-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03411, current rewards: 262.46433, mean: 0.10891
[32m[0906 16-10-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03411, current rewards: 268.02024, mean: 0.10895
[32m[0906 16-10-11 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 16-10-11 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-10-12 @MBExp.py:227][0m Rewards obtained: [272.4632322763558], Lows: [3], Highs: [2], Total time: 5243.246469999997
[32m[0906 16-12-16 @MBExp.py:144][0m ####################################################################
[32m[0906 16-12-16 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 16-12-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03230, current rewards: 0.02946, mean: 0.00295
[32m[0906 16-12-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03326, current rewards: 5.82364, mean: 0.09706
[32m[0906 16-12-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03335, current rewards: 11.61395, mean: 0.10558
[32m[0906 16-12-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03340, current rewards: 17.40820, mean: 0.10880
[32m[0906 16-12-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03341, current rewards: 23.20019, mean: 0.11048
[32m[0906 16-12-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03342, current rewards: 28.99592, mean: 0.11152
[32m[0906 16-12-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03341, current rewards: 34.79742, mean: 0.11225
[32m[0906 16-12-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03343, current rewards: 40.58868, mean: 0.11275
[32m[0906 16-12-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03356, current rewards: 46.38168, mean: 0.11313
[32m[0906 16-12-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03365, current rewards: 52.17583, mean: 0.11343
[32m[0906 16-12-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03374, current rewards: 57.96757, mean: 0.11366
[32m[0906 16-12-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03380, current rewards: 63.76045, mean: 0.11386
[32m[0906 16-12-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03385, current rewards: 69.55253, mean: 0.11402
[32m[0906 16-12-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03390, current rewards: 74.05207, mean: 0.11220
[32m[0906 16-12-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03395, current rewards: 79.67831, mean: 0.11222
[32m[0906 16-12-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03398, current rewards: 85.22598, mean: 0.11214
[32m[0906 16-12-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03400, current rewards: 90.77192, mean: 0.11206
[32m[0906 16-12-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03401, current rewards: 96.32094, mean: 0.11200
[32m[0906 16-12-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03405, current rewards: 101.87112, mean: 0.11195
[32m[0906 16-12-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03406, current rewards: 107.42346, mean: 0.11190
[32m[0906 16-12-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03408, current rewards: 112.96893, mean: 0.11185
[32m[0906 16-12-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03410, current rewards: 117.69807, mean: 0.11104
[32m[0906 16-12-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03409, current rewards: 123.30687, mean: 0.11109
[32m[0906 16-12-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03406, current rewards: 128.94572, mean: 0.11116
[32m[0906 16-12-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03404, current rewards: 134.51049, mean: 0.11117
[32m[0906 16-12-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03403, current rewards: 140.06898, mean: 0.11117
[32m[0906 16-13-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03401, current rewards: 145.63011, mean: 0.11117
[32m[0906 16-13-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03399, current rewards: 151.19187, mean: 0.11117
[32m[0906 16-13-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03398, current rewards: 156.75648, mean: 0.11117
[32m[0906 16-13-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03396, current rewards: 162.31413, mean: 0.11117
[32m[0906 16-13-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03394, current rewards: 167.83874, mean: 0.11115
[32m[0906 16-13-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03394, current rewards: 173.39234, mean: 0.11115
[32m[0906 16-13-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03393, current rewards: 178.95086, mean: 0.11115
[32m[0906 16-13-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03392, current rewards: 184.51151, mean: 0.11115
[32m[0906 16-13-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03391, current rewards: 190.07195, mean: 0.11115
[32m[0906 16-13-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03391, current rewards: 195.62984, mean: 0.11115
[32m[0906 16-13-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03391, current rewards: 201.18874, mean: 0.11115
[32m[0906 16-13-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03393, current rewards: 204.63104, mean: 0.11002
[32m[0906 16-13-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03395, current rewards: 210.17911, mean: 0.11004
[32m[0906 16-13-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03396, current rewards: 215.78059, mean: 0.11009
[32m[0906 16-13-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03397, current rewards: 221.33035, mean: 0.11011
[32m[0906 16-13-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03398, current rewards: 226.88202, mean: 0.11014
[32m[0906 16-13-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03400, current rewards: 232.43531, mean: 0.11016
[32m[0906 16-13-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03400, current rewards: 235.93770, mean: 0.10923
[32m[0906 16-13-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03401, current rewards: 241.50801, mean: 0.10928
[32m[0906 16-13-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03402, current rewards: 247.07744, mean: 0.10933
[32m[0906 16-13-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03404, current rewards: 252.64879, mean: 0.10937
[32m[0906 16-13-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03405, current rewards: 258.16004, mean: 0.10939
[32m[0906 16-13-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03406, current rewards: 261.65819, mean: 0.10857
[32m[0906 16-13-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03407, current rewards: 267.21832, mean: 0.10863
[32m[0906 16-13-42 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 16-13-42 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-13-42 @MBExp.py:227][0m Rewards obtained: [271.6713994866093], Lows: [3], Highs: [3], Total time: 5329.131713999997
[32m[0906 16-15-49 @MBExp.py:144][0m ####################################################################
[32m[0906 16-15-49 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 16-15-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03266, current rewards: 0.01405, mean: 0.00140
[32m[0906 16-15-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03336, current rewards: 5.67017, mean: 0.09450
[32m[0906 16-15-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03345, current rewards: 11.24333, mean: 0.10221
[32m[0906 16-15-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03353, current rewards: 16.82135, mean: 0.10513
[32m[0906 16-15-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03359, current rewards: 22.39775, mean: 0.10666
[32m[0906 16-15-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03363, current rewards: 28.01053, mean: 0.10773
[32m[0906 16-15-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03357, current rewards: 33.68200, mean: 0.10865
[32m[0906 16-16-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03359, current rewards: 39.29104, mean: 0.10914
[32m[0906 16-16-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03369, current rewards: 44.90232, mean: 0.10952
[32m[0906 16-16-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03380, current rewards: 50.51292, mean: 0.10981
[32m[0906 16-16-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03386, current rewards: 54.05937, mean: 0.10600
[32m[0906 16-16-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03391, current rewards: 59.71676, mean: 0.10664
[32m[0906 16-16-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03396, current rewards: 65.37328, mean: 0.10717
[32m[0906 16-16-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03400, current rewards: 71.03448, mean: 0.10763
[32m[0906 16-16-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03402, current rewards: 75.34307, mean: 0.10612
[32m[0906 16-16-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03405, current rewards: 80.82700, mean: 0.10635
[32m[0906 16-16-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03409, current rewards: 86.32529, mean: 0.10657
[32m[0906 16-16-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03411, current rewards: 91.82539, mean: 0.10677
[32m[0906 16-16-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03413, current rewards: 97.32020, mean: 0.10695
[32m[0906 16-16-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03415, current rewards: 102.82010, mean: 0.10710
[32m[0906 16-16-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03416, current rewards: 108.31469, mean: 0.10724
[32m[0906 16-16-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03418, current rewards: 113.81384, mean: 0.10737
[32m[0906 16-16-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03415, current rewards: 119.32583, mean: 0.10750
[32m[0906 16-16-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03412, current rewards: 124.82608, mean: 0.10761
[32m[0906 16-16-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03411, current rewards: 130.32101, mean: 0.10770
[32m[0906 16-16-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03409, current rewards: 135.81753, mean: 0.10779
[32m[0906 16-16-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03407, current rewards: 141.31903, mean: 0.10788
[32m[0906 16-16-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03405, current rewards: 146.81928, mean: 0.10796
[32m[0906 16-16-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03404, current rewards: 152.32057, mean: 0.10803
[32m[0906 16-16-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03402, current rewards: 157.82008, mean: 0.10810
[32m[0906 16-16-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03401, current rewards: 161.22628, mean: 0.10677
[32m[0906 16-16-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03399, current rewards: 166.91506, mean: 0.10700
[32m[0906 16-16-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03397, current rewards: 172.61722, mean: 0.10722
[32m[0906 16-16-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03396, current rewards: 178.31898, mean: 0.10742
[32m[0906 16-16-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03396, current rewards: 184.02419, mean: 0.10762
[32m[0906 16-16-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03395, current rewards: 189.72520, mean: 0.10780
[32m[0906 16-16-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03397, current rewards: 195.42847, mean: 0.10797
[32m[0906 16-16-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03398, current rewards: 201.12943, mean: 0.10813
[32m[0906 16-16-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03399, current rewards: 206.96713, mean: 0.10836
[32m[0906 16-16-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03400, current rewards: 210.48452, mean: 0.10739
[32m[0906 16-16-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03402, current rewards: 216.02143, mean: 0.10747
[32m[0906 16-16-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03403, current rewards: 221.55391, mean: 0.10755
[32m[0906 16-17-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03404, current rewards: 227.09301, mean: 0.10763
[32m[0906 16-17-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03405, current rewards: 232.62970, mean: 0.10770
[32m[0906 16-17-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03406, current rewards: 238.16827, mean: 0.10777
[32m[0906 16-17-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03407, current rewards: 243.70695, mean: 0.10783
[32m[0906 16-17-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03408, current rewards: 248.12670, mean: 0.10741
[32m[0906 16-17-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03409, current rewards: 253.47259, mean: 0.10740
[32m[0906 16-17-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03410, current rewards: 258.96351, mean: 0.10745
[32m[0906 16-17-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03411, current rewards: 264.45263, mean: 0.10750
[32m[0906 16-17-14 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 16-17-14 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-17-15 @MBExp.py:227][0m Rewards obtained: [268.843073859739], Lows: [2], Highs: [5], Total time: 5415.1134699999975
[32m[0906 16-19-23 @MBExp.py:144][0m ####################################################################
[32m[0906 16-19-23 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 16-19-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03310, current rewards: 1.07042, mean: 0.10704
[32m[0906 16-19-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03348, current rewards: 6.73644, mean: 0.11227
[32m[0906 16-19-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03362, current rewards: 12.40621, mean: 0.11278
[32m[0906 16-19-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03364, current rewards: 18.07293, mean: 0.11296
[32m[0906 16-19-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03363, current rewards: 23.73714, mean: 0.11303
[32m[0906 16-19-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03357, current rewards: 29.52697, mean: 0.11357
[32m[0906 16-19-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03358, current rewards: 38.34933, mean: 0.12371
[32m[0906 16-19-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03362, current rewards: 4.88429, mean: 0.01357
[32m[0906 16-19-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03372, current rewards: -45.11571, mean: -0.11004
[32m[0906 16-19-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03380, current rewards: -95.11571, mean: -0.20677
[32m[0906 16-19-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03388, current rewards: -122.03872, mean: -0.23929
[32m[0906 16-19-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03393, current rewards: -119.59102, mean: -0.21356
[32m[0906 16-19-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03395, current rewards: -117.14332, mean: -0.19204
[32m[0906 16-19-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03399, current rewards: -116.79352, mean: -0.17696
[32m[0906 16-19-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03401, current rewards: -166.79352, mean: -0.23492
[32m[0906 16-19-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03403, current rewards: -216.79352, mean: -0.28525
[32m[0906 16-19-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03404, current rewards: -266.79352, mean: -0.32937
[32m[0906 16-19-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03407, current rewards: -316.79352, mean: -0.36836
[32m[0906 16-19-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03410, current rewards: -366.79352, mean: -0.40307
[32m[0906 16-19-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03414, current rewards: -416.79352, mean: -0.43416
[32m[0906 16-19-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03415, current rewards: -466.79352, mean: -0.46217
[32m[0906 16-20-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03412, current rewards: -516.79352, mean: -0.48754
[32m[0906 16-20-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03410, current rewards: -566.79352, mean: -0.51062
[32m[0906 16-20-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03408, current rewards: -616.79352, mean: -0.53172
[32m[0906 16-20-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03405, current rewards: -666.79352, mean: -0.55107
[32m[0906 16-20-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03403, current rewards: -716.79352, mean: -0.56888
[32m[0906 16-20-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03401, current rewards: -766.79352, mean: -0.58534
[32m[0906 16-20-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03400, current rewards: -816.79352, mean: -0.60058
[32m[0906 16-20-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03398, current rewards: -866.79352, mean: -0.61475
[32m[0906 16-20-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03397, current rewards: -916.79352, mean: -0.62794
[32m[0906 16-20-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03395, current rewards: -966.79352, mean: -0.64026
[32m[0906 16-20-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03395, current rewards: -1016.79352, mean: -0.65179
[32m[0906 16-20-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03394, current rewards: -1066.79352, mean: -0.66260
[32m[0906 16-20-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03393, current rewards: -1116.79352, mean: -0.67277
[32m[0906 16-20-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03392, current rewards: -1166.79352, mean: -0.68234
[32m[0906 16-20-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03392, current rewards: -1216.79352, mean: -0.69136
[32m[0906 16-20-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03394, current rewards: -1266.79352, mean: -0.69989
[32m[0906 16-20-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03395, current rewards: -1316.79352, mean: -0.70795
[32m[0906 16-20-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03397, current rewards: -1366.79352, mean: -0.71560
[32m[0906 16-20-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03399, current rewards: -1416.79352, mean: -0.72285
[32m[0906 16-20-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03400, current rewards: -1466.79352, mean: -0.72975
[32m[0906 16-20-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03401, current rewards: -1516.79352, mean: -0.73631
[32m[0906 16-20-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03402, current rewards: -1566.79352, mean: -0.74256
[32m[0906 16-20-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03403, current rewards: -1616.79352, mean: -0.74852
[32m[0906 16-20-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03404, current rewards: -1666.79352, mean: -0.75421
[32m[0906 16-20-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03405, current rewards: -1716.79352, mean: -0.75964
[32m[0906 16-20-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03405, current rewards: -1766.79352, mean: -0.76485
[32m[0906 16-20-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03406, current rewards: -1816.79352, mean: -0.76983
[32m[0906 16-20-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03406, current rewards: -1866.79352, mean: -0.77460
[32m[0906 16-20-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03407, current rewards: -1916.79352, mean: -0.77918
[32m[0906 16-20-49 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 16-20-49 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-20-49 @MBExp.py:227][0m Rewards obtained: [-1956.7935224929838], Lows: [0], Highs: [2006], Total time: 5501.010877999997
[32m[0906 16-23-00 @MBExp.py:144][0m ####################################################################
[32m[0906 16-23-00 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 16-23-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03250, current rewards: -1.07835, mean: -0.10783
[32m[0906 16-23-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03328, current rewards: 4.53568, mean: 0.07559
[32m[0906 16-23-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03349, current rewards: 10.15023, mean: 0.09227
[32m[0906 16-23-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03354, current rewards: 15.76617, mean: 0.09854
[32m[0906 16-23-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03351, current rewards: 21.38216, mean: 0.10182
[32m[0906 16-23-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03350, current rewards: 27.37177, mean: 0.10528
[32m[0906 16-23-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03349, current rewards: 32.99660, mean: 0.10644
[32m[0906 16-23-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03364, current rewards: 38.61737, mean: 0.10727
[32m[0906 16-23-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03376, current rewards: 44.23994, mean: 0.10790
[32m[0906 16-23-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03383, current rewards: 48.73078, mean: 0.10594
[32m[0906 16-23-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03390, current rewards: 54.26373, mean: 0.10640
[32m[0906 16-23-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03393, current rewards: 59.80162, mean: 0.10679
[32m[0906 16-23-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03397, current rewards: 65.33579, mean: 0.10711
[32m[0906 16-23-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03400, current rewards: 70.90225, mean: 0.10743
[32m[0906 16-23-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03403, current rewards: 76.41140, mean: 0.10762
[32m[0906 16-23-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03404, current rewards: 81.92634, mean: 0.10780
[32m[0906 16-23-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03406, current rewards: 86.44061, mean: 0.10672
[32m[0906 16-23-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03409, current rewards: 92.07675, mean: 0.10707
[32m[0906 16-23-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03411, current rewards: 97.71686, mean: 0.10738
[32m[0906 16-23-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03412, current rewards: 103.36060, mean: 0.10767
[32m[0906 16-23-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03414, current rewards: 109.00896, mean: 0.10793
[32m[0906 16-23-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03411, current rewards: 114.65149, mean: 0.10816
[32m[0906 16-23-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03408, current rewards: 116.41514, mean: 0.10488
[32m[0906 16-23-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03405, current rewards: 124.27468, mean: 0.10713
[32m[0906 16-23-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03403, current rewards: 132.13422, mean: 0.10920
[32m[0906 16-23-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03401, current rewards: 139.99376, mean: 0.11111
[32m[0906 16-23-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03399, current rewards: 116.60915, mean: 0.08901
[32m[0906 16-23-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03397, current rewards: 118.82360, mean: 0.08737
[32m[0906 16-23-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03395, current rewards: 124.42246, mean: 0.08824
[32m[0906 16-23-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03395, current rewards: 129.98518, mean: 0.08903
[32m[0906 16-23-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03394, current rewards: 134.46262, mean: 0.08905
[32m[0906 16-23-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03393, current rewards: 139.96313, mean: 0.08972
[32m[0906 16-23-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03392, current rewards: 145.46356, mean: 0.09035
[32m[0906 16-23-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03391, current rewards: 150.95488, mean: 0.09094
[32m[0906 16-23-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03390, current rewards: 156.45151, mean: 0.09149
[32m[0906 16-24-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03392, current rewards: 161.94705, mean: 0.09202
[32m[0906 16-24-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03393, current rewards: 167.44747, mean: 0.09251
[32m[0906 16-24-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03394, current rewards: 172.92555, mean: 0.09297
[32m[0906 16-24-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03396, current rewards: 179.14968, mean: 0.09380
[32m[0906 16-24-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03397, current rewards: 184.78194, mean: 0.09428
[32m[0906 16-24-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03399, current rewards: 190.42015, mean: 0.09474
[32m[0906 16-24-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03401, current rewards: 196.05981, mean: 0.09517
[32m[0906 16-24-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03402, current rewards: 201.69638, mean: 0.09559
[32m[0906 16-24-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03403, current rewards: 207.33048, mean: 0.09599
[32m[0906 16-24-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03404, current rewards: 212.96841, mean: 0.09637
[32m[0906 16-24-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03405, current rewards: 218.60595, mean: 0.09673
[32m[0906 16-24-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03407, current rewards: 224.23660, mean: 0.09707
[32m[0906 16-24-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03407, current rewards: 227.61239, mean: 0.09645
[32m[0906 16-24-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03408, current rewards: 233.01467, mean: 0.09669
[32m[0906 16-24-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03408, current rewards: 238.41298, mean: 0.09692
[32m[0906 16-24-25 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 16-24-25 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-24-25 @MBExp.py:227][0m Rewards obtained: [242.7318250300196], Lows: [4], Highs: [35], Total time: 5586.915053999997
[32m[0906 16-26-38 @MBExp.py:144][0m ####################################################################
[32m[0906 16-26-38 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 16-26-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03336, current rewards: 0.02778, mean: 0.00278
[32m[0906 16-26-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03377, current rewards: 5.59126, mean: 0.09319
[32m[0906 16-26-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03371, current rewards: 11.13127, mean: 0.10119
[32m[0906 16-26-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03358, current rewards: 16.68664, mean: 0.10429
[32m[0906 16-26-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03355, current rewards: 22.38248, mean: 0.10658
[32m[0906 16-26-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03357, current rewards: 27.94885, mean: 0.10750
[32m[0906 16-26-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03361, current rewards: 33.51004, mean: 0.10810
[32m[0906 16-26-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03373, current rewards: 36.94256, mean: 0.10262
[32m[0906 16-26-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03381, current rewards: 42.46070, mean: 0.10356
[32m[0906 16-26-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03387, current rewards: 47.98159, mean: 0.10431
[32m[0906 16-26-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03393, current rewards: 53.49695, mean: 0.10490
[32m[0906 16-26-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03396, current rewards: 59.01424, mean: 0.10538
[32m[0906 16-26-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03399, current rewards: 64.52946, mean: 0.10579
[32m[0906 16-27-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03402, current rewards: 69.86266, mean: 0.10585
[32m[0906 16-27-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03404, current rewards: 75.38397, mean: 0.10617
[32m[0906 16-27-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03407, current rewards: 78.75998, mean: 0.10363
[32m[0906 16-27-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03410, current rewards: 84.32816, mean: 0.10411
[32m[0906 16-27-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03412, current rewards: 89.89602, mean: 0.10453
[32m[0906 16-27-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03413, current rewards: 95.46250, mean: 0.10490
[32m[0906 16-27-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03413, current rewards: 101.03006, mean: 0.10524
[32m[0906 16-27-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03409, current rewards: 106.59738, mean: 0.10554
[32m[0906 16-27-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03407, current rewards: 112.16854, mean: 0.10582
[32m[0906 16-27-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03405, current rewards: 117.73775, mean: 0.10607
[32m[0906 16-27-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03402, current rewards: 123.30264, mean: 0.10630
[32m[0906 16-27-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03401, current rewards: 128.87308, mean: 0.10651
[32m[0906 16-27-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03399, current rewards: 133.32130, mean: 0.10581
[32m[0906 16-27-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03397, current rewards: 138.87760, mean: 0.10601
[32m[0906 16-27-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03396, current rewards: 144.44234, mean: 0.10621
[32m[0906 16-27-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03395, current rewards: 150.00651, mean: 0.10639
[32m[0906 16-27-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03393, current rewards: 155.55754, mean: 0.10655
[32m[0906 16-27-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03392, current rewards: 161.12488, mean: 0.10671
[32m[0906 16-27-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03391, current rewards: 166.68823, mean: 0.10685
[32m[0906 16-27-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03390, current rewards: 170.10389, mean: 0.10565
[32m[0906 16-27-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03390, current rewards: 175.63721, mean: 0.10581
[32m[0906 16-27-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03391, current rewards: 181.17248, mean: 0.10595
[32m[0906 16-27-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03393, current rewards: 186.70485, mean: 0.10608
[32m[0906 16-27-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03395, current rewards: 192.23930, mean: 0.10621
[32m[0906 16-27-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03397, current rewards: 198.27109, mean: 0.10660
[32m[0906 16-27-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03398, current rewards: 203.91390, mean: 0.10676
[32m[0906 16-27-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03399, current rewards: 209.54506, mean: 0.10691
[32m[0906 16-27-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03400, current rewards: 215.17588, mean: 0.10705
[32m[0906 16-27-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03401, current rewards: 220.80764, mean: 0.10719
[32m[0906 16-27-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03402, current rewards: 226.43912, mean: 0.10732
[32m[0906 16-27-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03403, current rewards: 232.07071, mean: 0.10744
[32m[0906 16-27-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03404, current rewards: 234.37194, mean: 0.10605
[32m[0906 16-27-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03405, current rewards: 239.95433, mean: 0.10617
[32m[0906 16-27-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03406, current rewards: 245.32741, mean: 0.10620
[32m[0906 16-27-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03406, current rewards: 250.91283, mean: 0.10632
[32m[0906 16-28-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03407, current rewards: 256.49136, mean: 0.10643
[32m[0906 16-28-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03408, current rewards: 262.06933, mean: 0.10653
[32m[0906 16-28-04 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 16-28-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-28-04 @MBExp.py:227][0m Rewards obtained: [266.5053537649348], Lows: [3], Highs: [5], Total time: 5672.855183999997
[32m[0906 16-30-19 @MBExp.py:144][0m ####################################################################
[32m[0906 16-30-19 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 16-30-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03345, current rewards: -2.04087, mean: -0.20409
[32m[0906 16-30-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03330, current rewards: 3.54350, mean: 0.05906
[32m[0906 16-30-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03352, current rewards: 9.12440, mean: 0.08295
[32m[0906 16-30-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03352, current rewards: 14.70295, mean: 0.09189
[32m[0906 16-30-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03350, current rewards: 20.16671, mean: 0.09603
[32m[0906 16-30-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03354, current rewards: 25.58637, mean: 0.09841
[32m[0906 16-30-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03360, current rewards: 31.14007, mean: 0.10045
[32m[0906 16-30-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03372, current rewards: 36.69302, mean: 0.10193
[32m[0906 16-30-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03380, current rewards: 42.24053, mean: 0.10303
[32m[0906 16-30-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03386, current rewards: 47.79017, mean: 0.10389
[32m[0906 16-30-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03392, current rewards: 53.34213, mean: 0.10459
[32m[0906 16-30-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03395, current rewards: 56.68596, mean: 0.10122
[32m[0906 16-30-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03397, current rewards: 62.10412, mean: 0.10181
[32m[0906 16-30-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03401, current rewards: 67.84124, mean: 0.10279
[32m[0906 16-30-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03405, current rewards: 73.37892, mean: 0.10335
[32m[0906 16-30-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03407, current rewards: 78.91264, mean: 0.10383
[32m[0906 16-30-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03410, current rewards: 84.45145, mean: 0.10426
[32m[0906 16-30-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03410, current rewards: 89.98402, mean: 0.10463
[32m[0906 16-30-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03411, current rewards: 95.52364, mean: 0.10497
[32m[0906 16-30-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03409, current rewards: 101.05879, mean: 0.10527
[32m[0906 16-30-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03407, current rewards: 106.59306, mean: 0.10554
[32m[0906 16-30-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03404, current rewards: 112.11179, mean: 0.10577
[32m[0906 16-30-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03402, current rewards: 117.63646, mean: 0.10598
[32m[0906 16-30-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03400, current rewards: 122.02590, mean: 0.10519
[32m[0906 16-31-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03398, current rewards: 127.59387, mean: 0.10545
[32m[0906 16-31-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03397, current rewards: 133.16752, mean: 0.10569
[32m[0906 16-31-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03395, current rewards: 138.74033, mean: 0.10591
[32m[0906 16-31-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03394, current rewards: 144.31308, mean: 0.10611
[32m[0906 16-31-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03392, current rewards: 149.88574, mean: 0.10630
[32m[0906 16-31-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03391, current rewards: 154.26056, mean: 0.10566
[32m[0906 16-31-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03390, current rewards: 159.81459, mean: 0.10584
[32m[0906 16-31-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03389, current rewards: 165.36550, mean: 0.10600
[32m[0906 16-31-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03388, current rewards: 170.91515, mean: 0.10616
[32m[0906 16-31-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03387, current rewards: 176.46926, mean: 0.10631
[32m[0906 16-31-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03388, current rewards: 179.89167, mean: 0.10520
[32m[0906 16-31-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03389, current rewards: 185.45251, mean: 0.10537
[32m[0906 16-31-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03390, current rewards: 191.01187, mean: 0.10553
[32m[0906 16-31-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03391, current rewards: 196.65737, mean: 0.10573
[32m[0906 16-31-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03393, current rewards: 202.31247, mean: 0.10592
[32m[0906 16-31-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03394, current rewards: 207.88801, mean: 0.10607
[32m[0906 16-31-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03395, current rewards: 213.46244, mean: 0.10620
[32m[0906 16-31-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03396, current rewards: 219.03264, mean: 0.10633
[32m[0906 16-31-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03396, current rewards: 223.48271, mean: 0.10592
[32m[0906 16-31-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03397, current rewards: 229.05730, mean: 0.10605
[32m[0906 16-31-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03398, current rewards: 234.63089, mean: 0.10617
[32m[0906 16-31-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03399, current rewards: 240.20076, mean: 0.10628
[32m[0906 16-31-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03400, current rewards: 245.66637, mean: 0.10635
[32m[0906 16-31-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03400, current rewards: 251.23791, mean: 0.10646
[32m[0906 16-31-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03401, current rewards: 254.66063, mean: 0.10567
[32m[0906 16-31-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03402, current rewards: 260.22122, mean: 0.10578
[32m[0906 16-31-44 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 16-31-44 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-31-44 @MBExp.py:227][0m Rewards obtained: [264.67450984507707], Lows: [4], Highs: [4], Total time: 5758.632016999997
[32m[0906 16-34-01 @MBExp.py:144][0m ####################################################################
[32m[0906 16-34-01 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 16-34-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03264, current rewards: -0.07925, mean: -0.00792
[32m[0906 16-34-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03324, current rewards: 5.44283, mean: 0.09071
[32m[0906 16-34-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03338, current rewards: 11.00507, mean: 0.10005
[32m[0906 16-34-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03339, current rewards: 16.56552, mean: 0.10353
[32m[0906 16-34-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03344, current rewards: 22.05466, mean: 0.10502
[32m[0906 16-34-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03343, current rewards: 27.61806, mean: 0.10622
[32m[0906 16-34-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03353, current rewards: 33.17821, mean: 0.10703
[32m[0906 16-34-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03365, current rewards: 38.74374, mean: 0.10762
[32m[0906 16-34-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03372, current rewards: 44.30802, mean: 0.10807
[32m[0906 16-34-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03382, current rewards: 49.87453, mean: 0.10842
[32m[0906 16-34-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03386, current rewards: 55.43629, mean: 0.10870
[32m[0906 16-34-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03389, current rewards: 59.85359, mean: 0.10688
[32m[0906 16-34-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03395, current rewards: 65.41467, mean: 0.10724
[32m[0906 16-34-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03397, current rewards: 71.09983, mean: 0.10773
[32m[0906 16-34-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03399, current rewards: 76.65034, mean: 0.10796
[32m[0906 16-34-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03401, current rewards: 82.20307, mean: 0.10816
[32m[0906 16-34-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03404, current rewards: 87.75663, mean: 0.10834
[32m[0906 16-34-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03405, current rewards: 93.31361, mean: 0.10850
[32m[0906 16-34-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03408, current rewards: 96.79071, mean: 0.10636
[32m[0906 16-34-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03404, current rewards: 102.36044, mean: 0.10663
[32m[0906 16-34-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03402, current rewards: 107.93146, mean: 0.10686
[32m[0906 16-34-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03399, current rewards: 113.35267, mean: 0.10694
[32m[0906 16-34-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03397, current rewards: 118.91489, mean: 0.10713
[32m[0906 16-34-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03395, current rewards: 124.47206, mean: 0.10730
[32m[0906 16-34-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03394, current rewards: 130.03633, mean: 0.10747
[32m[0906 16-34-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03393, current rewards: 135.58831, mean: 0.10761
[32m[0906 16-34-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03391, current rewards: 141.14634, mean: 0.10775
[32m[0906 16-34-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03391, current rewards: 146.70360, mean: 0.10787
[32m[0906 16-34-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03389, current rewards: 152.26194, mean: 0.10799
[32m[0906 16-34-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03388, current rewards: 157.82787, mean: 0.10810
[32m[0906 16-34-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03387, current rewards: 163.38763, mean: 0.10820
[32m[0906 16-34-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03387, current rewards: 166.82748, mean: 0.10694
[32m[0906 16-34-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03387, current rewards: 172.39647, mean: 0.10708
[32m[0906 16-34-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03386, current rewards: 177.96852, mean: 0.10721
[32m[0906 16-34-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03388, current rewards: 183.53683, mean: 0.10733
[32m[0906 16-35-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03390, current rewards: 189.10485, mean: 0.10745
[32m[0906 16-35-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03392, current rewards: 194.67543, mean: 0.10756
[32m[0906 16-35-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03393, current rewards: 200.21386, mean: 0.10764
[32m[0906 16-35-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03395, current rewards: 205.78438, mean: 0.10774
[32m[0906 16-35-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03396, current rewards: 211.35449, mean: 0.10783
[32m[0906 16-35-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03397, current rewards: 216.92679, mean: 0.10792
[32m[0906 16-35-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03398, current rewards: 222.50086, mean: 0.10801
[32m[0906 16-35-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03399, current rewards: 228.07142, mean: 0.10809
[32m[0906 16-35-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03400, current rewards: 233.64476, mean: 0.10817
[32m[0906 16-35-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03401, current rewards: 239.21965, mean: 0.10824
[32m[0906 16-35-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03403, current rewards: 242.95268, mean: 0.10750
[32m[0906 16-35-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03404, current rewards: 250.50831, mean: 0.10845
[32m[0906 16-35-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03404, current rewards: 258.80843, mean: 0.10966
[32m[0906 16-35-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03405, current rewards: 267.10855, mean: 0.11083
[32m[0906 16-35-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03406, current rewards: 275.40867, mean: 0.11195
[32m[0906 16-35-27 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 16-35-27 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-35-27 @MBExp.py:227][0m Rewards obtained: [282.0487631557522], Lows: [3], Highs: [2], Total time: 5844.540248999997
[32m[0906 16-37-45 @MBExp.py:144][0m ####################################################################
[32m[0906 16-37-45 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 16-37-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03276, current rewards: 0.04284, mean: 0.00428
[32m[0906 16-37-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03316, current rewards: 5.57440, mean: 0.09291
[32m[0906 16-37-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03321, current rewards: 11.07118, mean: 0.10065
[32m[0906 16-37-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03329, current rewards: 16.57314, mean: 0.10358
[32m[0906 16-37-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03335, current rewards: 22.18501, mean: 0.10564
[32m[0906 16-37-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03336, current rewards: 27.70772, mean: 0.10657
[32m[0906 16-37-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03355, current rewards: 33.99079, mean: 0.10965
[32m[0906 16-37-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03368, current rewards: 39.55832, mean: 0.10988
[32m[0906 16-37-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03378, current rewards: 45.12482, mean: 0.11006
[32m[0906 16-38-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03385, current rewards: 50.69609, mean: 0.11021
[32m[0906 16-38-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03390, current rewards: 56.26304, mean: 0.11032
[32m[0906 16-38-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03394, current rewards: 61.83488, mean: 0.11042
[32m[0906 16-38-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03398, current rewards: 67.44123, mean: 0.11056
[32m[0906 16-38-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03402, current rewards: 73.01548, mean: 0.11063
[32m[0906 16-38-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03406, current rewards: 78.59397, mean: 0.11070
[32m[0906 16-38-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03409, current rewards: 84.16884, mean: 0.11075
[32m[0906 16-38-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03410, current rewards: 87.61187, mean: 0.10816
[32m[0906 16-38-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03411, current rewards: 93.18445, mean: 0.10835
[32m[0906 16-38-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03407, current rewards: 98.75820, mean: 0.10853
[32m[0906 16-38-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03403, current rewards: 104.33360, mean: 0.10868
[32m[0906 16-38-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03400, current rewards: 109.92752, mean: 0.10884
[32m[0906 16-38-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03398, current rewards: 115.50366, mean: 0.10897
[32m[0906 16-38-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03397, current rewards: 121.07844, mean: 0.10908
[32m[0906 16-38-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03395, current rewards: 126.65427, mean: 0.10918
[32m[0906 16-38-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03393, current rewards: 132.23457, mean: 0.10928
[32m[0906 16-38-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03392, current rewards: 137.80683, mean: 0.10937
[32m[0906 16-38-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03390, current rewards: 141.30789, mean: 0.10787
[32m[0906 16-38-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03389, current rewards: 146.90022, mean: 0.10801
[32m[0906 16-38-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03388, current rewards: 152.44682, mean: 0.10812
[32m[0906 16-38-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03387, current rewards: 158.08070, mean: 0.10827
[32m[0906 16-38-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03386, current rewards: 163.71799, mean: 0.10842
[32m[0906 16-38-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03385, current rewards: 169.35915, mean: 0.10856
[32m[0906 16-38-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03385, current rewards: 174.99859, mean: 0.10869
[32m[0906 16-38-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03386, current rewards: 180.63667, mean: 0.10882
[32m[0906 16-38-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03388, current rewards: 186.27257, mean: 0.10893
[32m[0906 16-38-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03390, current rewards: 191.91059, mean: 0.10904
[32m[0906 16-38-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03391, current rewards: 197.54940, mean: 0.10914
[32m[0906 16-38-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03392, current rewards: 203.28125, mean: 0.10929
[32m[0906 16-38-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03393, current rewards: 205.52247, mean: 0.10760
[32m[0906 16-38-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03395, current rewards: 211.11877, mean: 0.10771
[32m[0906 16-38-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03396, current rewards: 216.71003, mean: 0.10782
[32m[0906 16-38-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03398, current rewards: 222.31104, mean: 0.10792
[32m[0906 16-38-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03399, current rewards: 227.90638, mean: 0.10801
[32m[0906 16-38-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03399, current rewards: 233.50367, mean: 0.10810
[32m[0906 16-39-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03401, current rewards: 239.09864, mean: 0.10819
[32m[0906 16-39-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03402, current rewards: 244.58349, mean: 0.10822
[32m[0906 16-39-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03402, current rewards: 250.15907, mean: 0.10829
[32m[0906 16-39-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03403, current rewards: 253.60559, mean: 0.10746
[32m[0906 16-39-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03404, current rewards: 259.19737, mean: 0.10755
[32m[0906 16-39-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03405, current rewards: 264.78501, mean: 0.10764
[32m[0906 16-39-11 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 16-39-11 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-39-11 @MBExp.py:227][0m Rewards obtained: [269.2555575810115], Lows: [3], Highs: [4], Total time: 5930.395237999997
[32m[0906 16-41-31 @MBExp.py:144][0m ####################################################################
[32m[0906 16-41-31 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 16-41-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03224, current rewards: 0.05013, mean: 0.00501
[32m[0906 16-41-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03328, current rewards: 5.66347, mean: 0.09439
[32m[0906 16-41-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03343, current rewards: 11.27184, mean: 0.10247
[32m[0906 16-41-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03347, current rewards: 16.83378, mean: 0.10521
[32m[0906 16-41-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03352, current rewards: 22.33175, mean: 0.10634
[32m[0906 16-41-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03355, current rewards: 27.94087, mean: 0.10746
[32m[0906 16-41-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03367, current rewards: 33.57541, mean: 0.10831
[32m[0906 16-41-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03377, current rewards: 39.18290, mean: 0.10884
[32m[0906 16-41-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03387, current rewards: 44.79531, mean: 0.10926
[32m[0906 16-41-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03393, current rewards: 50.40842, mean: 0.10958
[32m[0906 16-41-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03399, current rewards: 56.01437, mean: 0.10983
[32m[0906 16-41-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03403, current rewards: 61.62161, mean: 0.11004
[32m[0906 16-41-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03408, current rewards: 67.38183, mean: 0.11046
[32m[0906 16-41-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03411, current rewards: 72.99562, mean: 0.11060
[32m[0906 16-41-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03414, current rewards: 78.61353, mean: 0.11072
[32m[0906 16-41-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03416, current rewards: 84.22449, mean: 0.11082
[32m[0906 16-41-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03416, current rewards: 89.84459, mean: 0.11092
[32m[0906 16-42-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03414, current rewards: 93.35224, mean: 0.10855
[32m[0906 16-42-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03410, current rewards: 98.96417, mean: 0.10875
[32m[0906 16-42-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03406, current rewards: 104.57576, mean: 0.10893
[32m[0906 16-42-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03405, current rewards: 110.10412, mean: 0.10901
[32m[0906 16-42-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03402, current rewards: 113.62242, mean: 0.10719
[32m[0906 16-42-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03401, current rewards: 119.22882, mean: 0.10741
[32m[0906 16-42-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03399, current rewards: 124.83593, mean: 0.10762
[32m[0906 16-42-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03397, current rewards: 130.44132, mean: 0.10780
[32m[0906 16-42-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03396, current rewards: 136.04398, mean: 0.10797
[32m[0906 16-42-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03394, current rewards: 141.64641, mean: 0.10813
[32m[0906 16-42-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03392, current rewards: 147.25301, mean: 0.10827
[32m[0906 16-42-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03391, current rewards: 152.83233, mean: 0.10839
[32m[0906 16-42-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03390, current rewards: 158.40413, mean: 0.10850
[32m[0906 16-42-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03389, current rewards: 164.00194, mean: 0.10861
[32m[0906 16-42-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03388, current rewards: 169.60017, mean: 0.10872
[32m[0906 16-42-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03387, current rewards: 175.19829, mean: 0.10882
[32m[0906 16-42-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03389, current rewards: 180.79806, mean: 0.10891
[32m[0906 16-42-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03390, current rewards: 184.28523, mean: 0.10777
[32m[0906 16-42-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03391, current rewards: 189.96823, mean: 0.10794
[32m[0906 16-42-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03392, current rewards: 195.59575, mean: 0.10806
[32m[0906 16-42-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03394, current rewards: 202.45649, mean: 0.10885
[32m[0906 16-42-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03396, current rewards: 210.31602, mean: 0.11011
[32m[0906 16-42-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03397, current rewards: 218.17556, mean: 0.11131
[32m[0906 16-42-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03398, current rewards: 226.03510, mean: 0.11246
[32m[0906 16-42-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03399, current rewards: 233.89464, mean: 0.11354
[32m[0906 16-42-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03400, current rewards: 241.75418, mean: 0.11458
[32m[0906 16-42-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03401, current rewards: 249.61372, mean: 0.11556
[32m[0906 16-42-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03402, current rewards: 234.32944, mean: 0.10603
[32m[0906 16-42-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03403, current rewards: 184.32944, mean: 0.08156
[32m[0906 16-42-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03403, current rewards: 134.32944, mean: 0.05815
[32m[0906 16-42-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03404, current rewards: 84.32944, mean: 0.03573
[32m[0906 16-42-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03405, current rewards: 34.32944, mean: 0.01424
[32m[0906 16-42-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03406, current rewards: -15.67056, mean: -0.00637
[32m[0906 16-42-57 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 16-42-57 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-42-57 @MBExp.py:227][0m Rewards obtained: [-55.670560659999126], Lows: [3], Highs: [311], Total time: 6016.278049999997
[32m[0906 16-45-19 @MBExp.py:144][0m ####################################################################
[32m[0906 16-45-19 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 16-45-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03411, current rewards: 0.05489, mean: 0.00549
[32m[0906 16-45-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03366, current rewards: 5.44803, mean: 0.09080
[32m[0906 16-45-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03357, current rewards: 10.79002, mean: 0.09809
[32m[0906 16-45-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03357, current rewards: 16.13451, mean: 0.10084
[32m[0906 16-45-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03361, current rewards: 21.48068, mean: 0.10229
[32m[0906 16-45-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03370, current rewards: 26.82767, mean: 0.10318
[32m[0906 16-45-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03383, current rewards: 32.17500, mean: 0.10379
[32m[0906 16-45-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03393, current rewards: 37.52468, mean: 0.10424
[32m[0906 16-45-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03399, current rewards: 42.86726, mean: 0.10455
[32m[0906 16-45-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03401, current rewards: 48.21079, mean: 0.10481
[32m[0906 16-45-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03405, current rewards: 51.44865, mean: 0.10088
[32m[0906 16-45-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03408, current rewards: 56.82048, mean: 0.10147
[32m[0906 16-45-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03409, current rewards: 62.05497, mean: 0.10173
[32m[0906 16-45-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03410, current rewards: 67.39612, mean: 0.10212
[32m[0906 16-45-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03412, current rewards: 72.73308, mean: 0.10244
[32m[0906 16-45-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03413, current rewards: 78.07022, mean: 0.10272
[32m[0906 16-45-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03416, current rewards: 83.40774, mean: 0.10297
[32m[0906 16-45-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03412, current rewards: 88.74860, mean: 0.10320
[32m[0906 16-45-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03409, current rewards: 94.08842, mean: 0.10339
[32m[0906 16-45-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03406, current rewards: 99.42930, mean: 0.10357
[32m[0906 16-45-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03405, current rewards: 104.83501, mean: 0.10380
[32m[0906 16-45-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03404, current rewards: 108.14863, mean: 0.10203
[32m[0906 16-45-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03402, current rewards: 113.62177, mean: 0.10236
[32m[0906 16-45-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03401, current rewards: 119.09620, mean: 0.10267
[32m[0906 16-46-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03400, current rewards: 124.57054, mean: 0.10295
[32m[0906 16-46-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03398, current rewards: 130.04645, mean: 0.10321
[32m[0906 16-46-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03397, current rewards: 135.52413, mean: 0.10345
[32m[0906 16-46-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03395, current rewards: 141.00071, mean: 0.10368
[32m[0906 16-46-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03394, current rewards: 146.53632, mean: 0.10393
[32m[0906 16-46-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03393, current rewards: 152.11734, mean: 0.10419
[32m[0906 16-46-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03391, current rewards: 156.44174, mean: 0.10360
[32m[0906 16-46-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03390, current rewards: 161.88064, mean: 0.10377
[32m[0906 16-46-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03390, current rewards: 167.32647, mean: 0.10393
[32m[0906 16-46-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03392, current rewards: 172.76537, mean: 0.10408
[32m[0906 16-46-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03393, current rewards: 178.20574, mean: 0.10421
[32m[0906 16-46-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03395, current rewards: 183.64104, mean: 0.10434
[32m[0906 16-46-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03397, current rewards: 189.08236, mean: 0.10447
[32m[0906 16-46-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03398, current rewards: 194.33743, mean: 0.10448
[32m[0906 16-46-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03399, current rewards: 199.73549, mean: 0.10457
[32m[0906 16-46-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03401, current rewards: 205.13080, mean: 0.10466
[32m[0906 16-46-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03402, current rewards: 210.52717, mean: 0.10474
[32m[0906 16-46-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03403, current rewards: 215.92083, mean: 0.10482
[32m[0906 16-46-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03404, current rewards: 219.17778, mean: 0.10388
[32m[0906 16-46-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03405, current rewards: 224.65116, mean: 0.10401
[32m[0906 16-46-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03406, current rewards: 230.12212, mean: 0.10413
[32m[0906 16-46-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03407, current rewards: 235.59523, mean: 0.10425
[32m[0906 16-46-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03408, current rewards: 241.20774, mean: 0.10442
[32m[0906 16-46-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03408, current rewards: 246.63003, mean: 0.10450
[32m[0906 16-46-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03409, current rewards: 252.05530, mean: 0.10459
[32m[0906 16-46-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03410, current rewards: 257.47804, mean: 0.10467
[32m[0906 16-46-45 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 16-46-45 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-46-45 @MBExp.py:227][0m Rewards obtained: [261.8168506749734], Lows: [3], Highs: [2], Total time: 6102.284568999997
[32m[0906 16-49-10 @MBExp.py:144][0m ####################################################################
[32m[0906 16-49-10 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 16-49-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03280, current rewards: -0.12796, mean: -0.01280
[32m[0906 16-49-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03364, current rewards: 5.19097, mean: 0.08652
[32m[0906 16-49-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03360, current rewards: 10.51037, mean: 0.09555
[32m[0906 16-49-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03359, current rewards: 15.83275, mean: 0.09895
[32m[0906 16-49-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03362, current rewards: 21.29646, mean: 0.10141
[32m[0906 16-49-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03372, current rewards: 26.65954, mean: 0.10254
[32m[0906 16-49-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03382, current rewards: 32.01634, mean: 0.10328
[32m[0906 16-49-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03391, current rewards: 37.37713, mean: 0.10383
[32m[0906 16-49-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03398, current rewards: 42.73761, mean: 0.10424
[32m[0906 16-49-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03403, current rewards: 45.88977, mean: 0.09976
[32m[0906 16-49-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03408, current rewards: 51.30979, mean: 0.10061
[32m[0906 16-49-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03411, current rewards: 56.73380, mean: 0.10131
[32m[0906 16-49-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03414, current rewards: 62.07131, mean: 0.10176
[32m[0906 16-49-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03416, current rewards: 67.46391, mean: 0.10222
[32m[0906 16-49-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03419, current rewards: 72.86083, mean: 0.10262
[32m[0906 16-49-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03420, current rewards: 78.25340, mean: 0.10296
[32m[0906 16-49-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03415, current rewards: 83.64932, mean: 0.10327
[32m[0906 16-49-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03412, current rewards: 89.05044, mean: 0.10355
[32m[0906 16-49-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03410, current rewards: 94.44926, mean: 0.10379
[32m[0906 16-49-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03408, current rewards: 99.84552, mean: 0.10401
[32m[0906 16-49-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03406, current rewards: 105.28292, mean: 0.10424
[32m[0906 16-49-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03405, current rewards: 108.88279, mean: 0.10272
[32m[0906 16-49-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03403, current rewards: 114.42902, mean: 0.10309
[32m[0906 16-49-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03402, current rewards: 119.97345, mean: 0.10343
[32m[0906 16-49-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03402, current rewards: 125.51578, mean: 0.10373
[32m[0906 16-49-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03400, current rewards: 131.06094, mean: 0.10402
[32m[0906 16-49-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03399, current rewards: 136.52523, mean: 0.10422
[32m[0906 16-49-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03398, current rewards: 142.05547, mean: 0.10445
[32m[0906 16-49-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03396, current rewards: 147.58872, mean: 0.10467
[32m[0906 16-50-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03395, current rewards: 152.98907, mean: 0.10479
[32m[0906 16-50-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03393, current rewards: 158.51826, mean: 0.10498
[32m[0906 16-50-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03392, current rewards: 164.04782, mean: 0.10516
[32m[0906 16-50-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03393, current rewards: 169.57517, mean: 0.10533
[32m[0906 16-50-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03394, current rewards: 175.10588, mean: 0.10549
[32m[0906 16-50-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03396, current rewards: 180.63119, mean: 0.10563
[32m[0906 16-50-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03398, current rewards: 186.16039, mean: 0.10577
[32m[0906 16-50-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03400, current rewards: 191.69210, mean: 0.10591
[32m[0906 16-50-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03401, current rewards: 195.30404, mean: 0.10500
[32m[0906 16-50-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03402, current rewards: 200.87199, mean: 0.10517
[32m[0906 16-50-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03404, current rewards: 206.43833, mean: 0.10533
[32m[0906 16-50-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03405, current rewards: 212.00729, mean: 0.10548
[32m[0906 16-50-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03406, current rewards: 217.57612, mean: 0.10562
[32m[0906 16-50-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03407, current rewards: 223.14189, mean: 0.10575
[32m[0906 16-50-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03408, current rewards: 227.42681, mean: 0.10529
[32m[0906 16-50-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03409, current rewards: 232.87557, mean: 0.10537
[32m[0906 16-50-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03410, current rewards: 238.32548, mean: 0.10545
[32m[0906 16-50-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03411, current rewards: 243.52379, mean: 0.10542
[32m[0906 16-50-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03412, current rewards: 248.91583, mean: 0.10547
[32m[0906 16-50-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03412, current rewards: 254.30432, mean: 0.10552
[32m[0906 16-50-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03414, current rewards: 259.69303, mean: 0.10557
[32m[0906 16-50-36 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 16-50-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-50-36 @MBExp.py:227][0m Rewards obtained: [264.0054310710652], Lows: [2], Highs: [4], Total time: 6188.377184999997
[32m[0906 16-53-03 @MBExp.py:144][0m ####################################################################
[32m[0906 16-53-03 @MBExp.py:145][0m Starting training iteration 72.
[32m[0906 16-53-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03371, current rewards: -2.16568, mean: -0.21657
[32m[0906 16-53-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03352, current rewards: 3.25722, mean: 0.05429
[32m[0906 16-53-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03367, current rewards: 8.76887, mean: 0.07972
[32m[0906 16-53-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03366, current rewards: 14.28814, mean: 0.08930
[32m[0906 16-53-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03364, current rewards: 19.80827, mean: 0.09433
[32m[0906 16-53-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03384, current rewards: 25.49800, mean: 0.09807
[32m[0906 16-53-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03392, current rewards: 31.02622, mean: 0.10008
[32m[0906 16-53-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03399, current rewards: 36.54881, mean: 0.10152
[32m[0906 16-53-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03404, current rewards: 42.06874, mean: 0.10261
[32m[0906 16-53-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03408, current rewards: 47.58992, mean: 0.10346
[32m[0906 16-53-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03411, current rewards: 53.11356, mean: 0.10414
[32m[0906 16-53-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03415, current rewards: 58.63684, mean: 0.10471
[32m[0906 16-53-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03420, current rewards: 64.16480, mean: 0.10519
[32m[0906 16-53-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03423, current rewards: 67.43565, mean: 0.10218
[32m[0906 16-53-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03424, current rewards: 72.95644, mean: 0.10276
[32m[0906 16-53-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03420, current rewards: 78.47211, mean: 0.10325
[32m[0906 16-53-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03416, current rewards: 83.99130, mean: 0.10369
[32m[0906 16-53-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03413, current rewards: 89.50835, mean: 0.10408
[32m[0906 16-53-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03412, current rewards: 95.02585, mean: 0.10442
[32m[0906 16-53-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03410, current rewards: 99.56354, mean: 0.10371
[32m[0906 16-53-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03408, current rewards: 105.07251, mean: 0.10403
[32m[0906 16-53-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03405, current rewards: 110.57378, mean: 0.10431
[32m[0906 16-53-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03404, current rewards: 116.08092, mean: 0.10458
[32m[0906 16-53-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03402, current rewards: 121.58592, mean: 0.10482
[32m[0906 16-53-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03400, current rewards: 127.08964, mean: 0.10503
[32m[0906 16-53-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03399, current rewards: 132.59043, mean: 0.10523
[32m[0906 16-53-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03398, current rewards: 138.10160, mean: 0.10542
[32m[0906 16-53-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03397, current rewards: 143.60678, mean: 0.10559
[32m[0906 16-53-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03395, current rewards: 149.11155, mean: 0.10575
[32m[0906 16-53-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03394, current rewards: 154.55437, mean: 0.10586
[32m[0906 16-53-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03393, current rewards: 160.05413, mean: 0.10600
[32m[0906 16-53-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03392, current rewards: 163.41159, mean: 0.10475
[32m[0906 16-53-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03394, current rewards: 168.92107, mean: 0.10492
[32m[0906 16-53-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03396, current rewards: 174.42916, mean: 0.10508
[32m[0906 16-54-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03397, current rewards: 179.94244, mean: 0.10523
[32m[0906 16-54-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03399, current rewards: 185.45349, mean: 0.10537
[32m[0906 16-54-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03400, current rewards: 190.96233, mean: 0.10550
[32m[0906 16-54-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03402, current rewards: 196.47546, mean: 0.10563
[32m[0906 16-54-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03403, current rewards: 202.24566, mean: 0.10589
[32m[0906 16-54-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03404, current rewards: 207.78450, mean: 0.10601
[32m[0906 16-54-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03405, current rewards: 213.32231, mean: 0.10613
[32m[0906 16-54-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03407, current rewards: 218.86502, mean: 0.10625
[32m[0906 16-54-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03408, current rewards: 224.40316, mean: 0.10635
[32m[0906 16-54-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03408, current rewards: 229.94299, mean: 0.10646
[32m[0906 16-54-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03409, current rewards: 235.48486, mean: 0.10655
[32m[0906 16-54-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03410, current rewards: 241.02598, mean: 0.10665
[32m[0906 16-54-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03411, current rewards: 245.47088, mean: 0.10626
[32m[0906 16-54-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03412, current rewards: 251.01181, mean: 0.10636
[32m[0906 16-54-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03413, current rewards: 256.55587, mean: 0.10645
[32m[0906 16-54-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03414, current rewards: 262.10215, mean: 0.10655
[32m[0906 16-54-29 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 16-54-29 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-54-29 @MBExp.py:227][0m Rewards obtained: [266.53925305958563], Lows: [3], Highs: [3], Total time: 6274.473406999997
[32m[0906 16-56-58 @MBExp.py:144][0m ####################################################################
[32m[0906 16-56-58 @MBExp.py:145][0m Starting training iteration 73.
[32m[0906 16-56-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03344, current rewards: -0.00824, mean: -0.00082
[32m[0906 16-57-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03356, current rewards: 5.56000, mean: 0.09267
[32m[0906 16-57-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03365, current rewards: 11.12740, mean: 0.10116
[32m[0906 16-57-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03365, current rewards: 16.69436, mean: 0.10434
[32m[0906 16-57-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03369, current rewards: 22.05055, mean: 0.10500
[32m[0906 16-57-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03382, current rewards: 27.59325, mean: 0.10613
[32m[0906 16-57-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03392, current rewards: 33.13853, mean: 0.10690
[32m[0906 16-57-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03399, current rewards: 38.68450, mean: 0.10746
[32m[0906 16-57-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03402, current rewards: 42.40119, mean: 0.10342
[32m[0906 16-57-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03409, current rewards: 47.97488, mean: 0.10429
[32m[0906 16-57-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03415, current rewards: 53.54800, mean: 0.10500
[32m[0906 16-57-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03418, current rewards: 59.12463, mean: 0.10558
[32m[0906 16-57-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03422, current rewards: 64.69897, mean: 0.10606
[32m[0906 16-57-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03423, current rewards: 68.02830, mean: 0.10307
[32m[0906 16-57-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03418, current rewards: 73.57135, mean: 0.10362
[32m[0906 16-57-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03414, current rewards: 79.11867, mean: 0.10410
[32m[0906 16-57-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03412, current rewards: 84.66110, mean: 0.10452
[32m[0906 16-57-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03409, current rewards: 90.19989, mean: 0.10488
[32m[0906 16-57-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03406, current rewards: 95.74010, mean: 0.10521
[32m[0906 16-57-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03405, current rewards: 101.28360, mean: 0.10550
[32m[0906 16-57-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03403, current rewards: 106.82433, mean: 0.10577
[32m[0906 16-57-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03401, current rewards: 112.36482, mean: 0.10600
[32m[0906 16-57-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03400, current rewards: 117.90927, mean: 0.10622
[32m[0906 16-57-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03398, current rewards: 123.45471, mean: 0.10643
[32m[0906 16-57-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03397, current rewards: 128.99980, mean: 0.10661
[32m[0906 16-57-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03396, current rewards: 134.54990, mean: 0.10679
[32m[0906 16-57-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03395, current rewards: 137.98812, mean: 0.10533
[32m[0906 16-57-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03394, current rewards: 143.55605, mean: 0.10556
[32m[0906 16-57-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03393, current rewards: 149.14593, mean: 0.10578
[32m[0906 16-57-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03392, current rewards: 154.86100, mean: 0.10607
[32m[0906 16-57-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03391, current rewards: 160.43491, mean: 0.10625
[32m[0906 16-57-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03392, current rewards: 166.01308, mean: 0.10642
[32m[0906 16-57-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03393, current rewards: 171.58780, mean: 0.10658
[32m[0906 16-57-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03394, current rewards: 177.16337, mean: 0.10672
[32m[0906 16-57-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03396, current rewards: 182.73686, mean: 0.10686
[32m[0906 16-57-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03398, current rewards: 186.35018, mean: 0.10588
[32m[0906 16-58-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03400, current rewards: 191.92593, mean: 0.10604
[32m[0906 16-58-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03402, current rewards: 197.54931, mean: 0.10621
[32m[0906 16-58-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03403, current rewards: 203.13095, mean: 0.10635
[32m[0906 16-58-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03404, current rewards: 208.70676, mean: 0.10648
[32m[0906 16-58-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03406, current rewards: 214.28800, mean: 0.10661
[32m[0906 16-58-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03407, current rewards: 219.86690, mean: 0.10673
[32m[0906 16-58-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03408, current rewards: 224.31552, mean: 0.10631
[32m[0906 16-58-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03409, current rewards: 229.89290, mean: 0.10643
[32m[0906 16-58-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03410, current rewards: 235.46907, mean: 0.10655
[32m[0906 16-58-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03411, current rewards: 241.00415, mean: 0.10664
[32m[0906 16-58-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03411, current rewards: 246.57834, mean: 0.10674
[32m[0906 16-58-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03412, current rewards: 252.15001, mean: 0.10684
[32m[0906 16-58-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03413, current rewards: 257.72256, mean: 0.10694
[32m[0906 16-58-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03413, current rewards: 263.29250, mean: 0.10703
[32m[0906 16-58-24 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 16-58-24 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-58-24 @MBExp.py:227][0m Rewards obtained: [268.53311350416794], Lows: [3], Highs: [4], Total time: 6360.549479999997
[32m[0906 17-00-54 @MBExp.py:144][0m ####################################################################
[32m[0906 17-00-54 @MBExp.py:145][0m Starting training iteration 74.
[32m[0906 17-00-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03310, current rewards: 0.99106, mean: 0.09911
[32m[0906 17-00-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03353, current rewards: 6.34839, mean: 0.10581
[32m[0906 17-00-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03345, current rewards: 11.89493, mean: 0.10814
[32m[0906 17-01-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03348, current rewards: 17.44224, mean: 0.10901
[32m[0906 17-01-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03364, current rewards: 23.74121, mean: 0.11305
[32m[0906 17-01-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03378, current rewards: 29.91890, mean: 0.11507
[32m[0906 17-01-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03385, current rewards: 36.09658, mean: 0.11644
[32m[0906 17-01-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03391, current rewards: 42.27426, mean: 0.11743
[32m[0906 17-01-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03399, current rewards: 48.45194, mean: 0.11818
[32m[0906 17-01-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03403, current rewards: 54.62962, mean: 0.11876
[32m[0906 17-01-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03408, current rewards: 60.80731, mean: 0.11923
[32m[0906 17-01-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03409, current rewards: 36.64904, mean: 0.06544
[32m[0906 17-01-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03412, current rewards: -13.35096, mean: -0.02189
[32m[0906 17-01-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03408, current rewards: -63.35096, mean: -0.09599
[32m[0906 17-01-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03406, current rewards: -113.35096, mean: -0.15965
[32m[0906 17-01-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03404, current rewards: -163.35096, mean: -0.21494
[32m[0906 17-01-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03400, current rewards: -213.35096, mean: -0.26340
[32m[0906 17-01-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03396, current rewards: -263.35096, mean: -0.30622
[32m[0906 17-01-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03395, current rewards: -313.35096, mean: -0.34434
[32m[0906 17-01-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03392, current rewards: -363.35096, mean: -0.37849
[32m[0906 17-01-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03391, current rewards: -376.70457, mean: -0.37297
[32m[0906 17-01-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03390, current rewards: -371.13783, mean: -0.35013
[32m[0906 17-01-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03388, current rewards: -365.57227, mean: -0.32934
[32m[0906 17-01-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03386, current rewards: -360.00781, mean: -0.31035
[32m[0906 17-01-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03385, current rewards: -354.44574, mean: -0.29293
[32m[0906 17-01-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03384, current rewards: -348.88406, mean: -0.27689
[32m[0906 17-01-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03383, current rewards: -343.37425, mean: -0.26212
[32m[0906 17-01-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03381, current rewards: -337.75453, mean: -0.24835
[32m[0906 17-01-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03381, current rewards: -332.18496, mean: -0.23559
[32m[0906 17-01-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03382, current rewards: -326.66690, mean: -0.22374
[32m[0906 17-01-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03381, current rewards: -321.07482, mean: -0.21263
[32m[0906 17-01-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03382, current rewards: -315.48451, mean: -0.20223
[32m[0906 17-01-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03385, current rewards: -309.88780, mean: -0.19248
[32m[0906 17-01-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03387, current rewards: -304.29199, mean: -0.18331
[32m[0906 17-01-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03388, current rewards: -298.69489, mean: -0.17468
[32m[0906 17-01-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03390, current rewards: -293.10244, mean: -0.16654
[32m[0906 17-01-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03391, current rewards: -287.50713, mean: -0.15884
[32m[0906 17-01-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03393, current rewards: -281.64735, mean: -0.15142
[32m[0906 17-02-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03395, current rewards: -278.05251, mean: -0.14558
[32m[0906 17-02-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03396, current rewards: -272.41140, mean: -0.13899
[32m[0906 17-02-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03398, current rewards: -266.77194, mean: -0.13272
[32m[0906 17-02-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03399, current rewards: -261.13235, mean: -0.12676
[32m[0906 17-02-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03401, current rewards: -255.55324, mean: -0.12112
[32m[0906 17-02-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03401, current rewards: -249.95028, mean: -0.11572
[32m[0906 17-02-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03402, current rewards: -244.34684, mean: -0.11056
[32m[0906 17-02-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03403, current rewards: -238.74093, mean: -0.10564
[32m[0906 17-02-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03404, current rewards: -233.13822, mean: -0.10093
[32m[0906 17-02-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03405, current rewards: -227.53067, mean: -0.09641
[32m[0906 17-02-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03406, current rewards: -223.95404, mean: -0.09293
[32m[0906 17-02-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03406, current rewards: -218.29837, mean: -0.08874
[32m[0906 17-02-20 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 17-02-20 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-02-20 @MBExp.py:227][0m Rewards obtained: [-213.7757946843777], Lows: [2], Highs: [444], Total time: 6446.449174999997
[32m[0906 17-04-53 @MBExp.py:144][0m ####################################################################
[32m[0906 17-04-53 @MBExp.py:145][0m Starting training iteration 75.
[32m[0906 17-04-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03325, current rewards: -1.17595, mean: -0.11760
[32m[0906 17-04-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03344, current rewards: 4.41351, mean: 0.07356
[32m[0906 17-04-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03347, current rewards: 10.00253, mean: 0.09093
[32m[0906 17-04-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03358, current rewards: 15.59075, mean: 0.09744
[32m[0906 17-05-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03369, current rewards: 21.27596, mean: 0.10131
[32m[0906 17-05-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03384, current rewards: 24.81115, mean: 0.09543
[32m[0906 17-05-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03395, current rewards: 30.37298, mean: 0.09798
[32m[0906 17-05-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03400, current rewards: 35.93734, mean: 0.09983
[32m[0906 17-05-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03405, current rewards: 41.49805, mean: 0.10121
[32m[0906 17-05-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03411, current rewards: 47.05399, mean: 0.10229
[32m[0906 17-05-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03415, current rewards: 52.61121, mean: 0.10316
[32m[0906 17-05-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03420, current rewards: 58.17095, mean: 0.10388
[32m[0906 17-05-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03417, current rewards: 63.64197, mean: 0.10433
[32m[0906 17-05-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03415, current rewards: 69.22758, mean: 0.10489
[32m[0906 17-05-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03412, current rewards: 74.81240, mean: 0.10537
[32m[0906 17-05-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03408, current rewards: 79.31894, mean: 0.10437
[32m[0906 17-05-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03404, current rewards: 84.96362, mean: 0.10489
[32m[0906 17-05-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03401, current rewards: 90.60917, mean: 0.10536
[32m[0906 17-05-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03400, current rewards: 96.25151, mean: 0.10577
[32m[0906 17-05-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03399, current rewards: 101.89274, mean: 0.10614
[32m[0906 17-05-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03397, current rewards: 107.63837, mean: 0.10657
[32m[0906 17-05-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03395, current rewards: 111.19545, mean: 0.10490
[32m[0906 17-05-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03394, current rewards: 116.74199, mean: 0.10517
[32m[0906 17-05-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03393, current rewards: 122.28795, mean: 0.10542
[32m[0906 17-05-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03392, current rewards: 127.83240, mean: 0.10565
[32m[0906 17-05-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03390, current rewards: 133.37822, mean: 0.10586
[32m[0906 17-05-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03390, current rewards: 137.75321, mean: 0.10516
[32m[0906 17-05-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03388, current rewards: 143.23652, mean: 0.10532
[32m[0906 17-05-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03389, current rewards: 148.58122, mean: 0.10538
[32m[0906 17-05-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03388, current rewards: 153.92833, mean: 0.10543
[32m[0906 17-05-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03387, current rewards: 159.38864, mean: 0.10556
[32m[0906 17-05-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03390, current rewards: 164.85035, mean: 0.10567
[32m[0906 17-05-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03392, current rewards: 170.30999, mean: 0.10578
[32m[0906 17-05-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03394, current rewards: 175.76744, mean: 0.10588
[32m[0906 17-05-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03395, current rewards: 181.22606, mean: 0.10598
[32m[0906 17-05-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03397, current rewards: 186.68191, mean: 0.10607
[32m[0906 17-05-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03398, current rewards: 192.14344, mean: 0.10616
[32m[0906 17-05-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03400, current rewards: 197.61251, mean: 0.10624
[32m[0906 17-05-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03401, current rewards: 203.07190, mean: 0.10632
[32m[0906 17-06-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03402, current rewards: 208.53325, mean: 0.10639
[32m[0906 17-06-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03403, current rewards: 213.99370, mean: 0.10646
[32m[0906 17-06-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03404, current rewards: 217.34968, mean: 0.10551
[32m[0906 17-06-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03406, current rewards: 223.18864, mean: 0.10578
[32m[0906 17-06-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03406, current rewards: 229.02500, mean: 0.10603
[32m[0906 17-06-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03408, current rewards: 234.86100, mean: 0.10627
[32m[0906 17-06-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03410, current rewards: 240.92851, mean: 0.10661
[32m[0906 17-06-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03411, current rewards: 246.61428, mean: 0.10676
[32m[0906 17-06-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03412, current rewards: 252.29873, mean: 0.10691
[32m[0906 17-06-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03413, current rewards: 255.65846, mean: 0.10608
[32m[0906 17-06-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03413, current rewards: 261.22175, mean: 0.10619
[32m[0906 17-06-19 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 17-06-19 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-06-19 @MBExp.py:227][0m Rewards obtained: [265.6783601134724], Lows: [3], Highs: [6], Total time: 6532.544100999997
[32m[0906 17-08-54 @MBExp.py:144][0m ####################################################################
[32m[0906 17-08-54 @MBExp.py:145][0m Starting training iteration 76.
[32m[0906 17-08-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03322, current rewards: -0.11615, mean: -0.01161
[32m[0906 17-08-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03352, current rewards: 5.45036, mean: 0.09084
[32m[0906 17-08-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03348, current rewards: 11.01637, mean: 0.10015
[32m[0906 17-08-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03352, current rewards: 16.47667, mean: 0.10298
[32m[0906 17-09-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03374, current rewards: 21.97835, mean: 0.10466
[32m[0906 17-09-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03388, current rewards: 26.53072, mean: 0.10204
[32m[0906 17-09-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03392, current rewards: 32.12296, mean: 0.10362
[32m[0906 17-09-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03399, current rewards: 37.69754, mean: 0.10472
[32m[0906 17-09-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03406, current rewards: 43.27003, mean: 0.10554
[32m[0906 17-09-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03413, current rewards: 48.84391, mean: 0.10618
[32m[0906 17-09-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03416, current rewards: 54.41649, mean: 0.10670
[32m[0906 17-09-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03411, current rewards: 59.99409, mean: 0.10713
[32m[0906 17-09-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03408, current rewards: 61.54187, mean: 0.10089
[32m[0906 17-09-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03405, current rewards: 67.40096, mean: 0.10212
[32m[0906 17-09-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03402, current rewards: 73.26927, mean: 0.10320
[32m[0906 17-09-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03400, current rewards: 79.13789, mean: 0.10413
[32m[0906 17-09-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03398, current rewards: 85.00760, mean: 0.10495
[32m[0906 17-09-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03398, current rewards: 88.43786, mean: 0.10283
[32m[0906 17-09-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03397, current rewards: 93.95800, mean: 0.10325
[32m[0906 17-09-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03395, current rewards: 99.47710, mean: 0.10362
[32m[0906 17-09-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03394, current rewards: 104.95769, mean: 0.10392
[32m[0906 17-09-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03393, current rewards: 110.47384, mean: 0.10422
[32m[0906 17-09-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03392, current rewards: 115.99324, mean: 0.10450
[32m[0906 17-09-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03391, current rewards: 121.51282, mean: 0.10475
[32m[0906 17-09-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03390, current rewards: 127.02842, mean: 0.10498
[32m[0906 17-09-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03389, current rewards: 130.45452, mean: 0.10354
[32m[0906 17-09-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03389, current rewards: 135.99176, mean: 0.10381
[32m[0906 17-09-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03388, current rewards: 141.52919, mean: 0.10407
[32m[0906 17-09-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03388, current rewards: 147.17635, mean: 0.10438
[32m[0906 17-09-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03387, current rewards: 152.70824, mean: 0.10459
[32m[0906 17-09-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03387, current rewards: 158.24361, mean: 0.10480
[32m[0906 17-09-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03389, current rewards: 161.70097, mean: 0.10365
[32m[0906 17-09-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03390, current rewards: 167.25578, mean: 0.10389
[32m[0906 17-09-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03392, current rewards: 172.81077, mean: 0.10410
[32m[0906 17-09-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03394, current rewards: 178.36146, mean: 0.10430
[32m[0906 17-09-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03396, current rewards: 183.91471, mean: 0.10450
[32m[0906 17-09-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03397, current rewards: 189.39853, mean: 0.10464
[32m[0906 17-09-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03399, current rewards: 194.86894, mean: 0.10477
[32m[0906 17-09-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03400, current rewards: 200.40945, mean: 0.10493
[32m[0906 17-10-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03401, current rewards: 205.95074, mean: 0.10508
[32m[0906 17-10-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03402, current rewards: 211.48798, mean: 0.10522
[32m[0906 17-10-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03403, current rewards: 217.02809, mean: 0.10535
[32m[0906 17-10-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03404, current rewards: 221.51410, mean: 0.10498
[32m[0906 17-10-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03405, current rewards: 227.07796, mean: 0.10513
[32m[0906 17-10-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03406, current rewards: 232.63481, mean: 0.10526
[32m[0906 17-10-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03407, current rewards: 238.24585, mean: 0.10542
[32m[0906 17-10-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03408, current rewards: 243.80774, mean: 0.10554
[32m[0906 17-10-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03409, current rewards: 249.37010, mean: 0.10567
[32m[0906 17-10-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03410, current rewards: 255.70103, mean: 0.10610
[32m[0906 17-10-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03411, current rewards: 261.21542, mean: 0.10619
[32m[0906 17-10-20 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 17-10-20 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-10-20 @MBExp.py:227][0m Rewards obtained: [265.633243587933], Lows: [4], Highs: [5], Total time: 6618.578972999997
[32m[0906 17-12-57 @MBExp.py:144][0m ####################################################################
[32m[0906 17-12-57 @MBExp.py:145][0m Starting training iteration 77.
[32m[0906 17-12-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03249, current rewards: -0.02148, mean: -0.00215
[32m[0906 17-12-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03353, current rewards: 5.47644, mean: 0.09127
[32m[0906 17-13-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03359, current rewards: 10.97239, mean: 0.09975
[32m[0906 17-13-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03371, current rewards: 16.26867, mean: 0.10168
[32m[0906 17-13-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03390, current rewards: 21.81136, mean: 0.10386
[32m[0906 17-13-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03395, current rewards: 27.35406, mean: 0.10521
[32m[0906 17-13-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03406, current rewards: 32.89957, mean: 0.10613
[32m[0906 17-13-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03413, current rewards: 38.44377, mean: 0.10679
[32m[0906 17-13-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03417, current rewards: 43.98379, mean: 0.10728
[32m[0906 17-13-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03419, current rewards: 49.52259, mean: 0.10766
[32m[0906 17-13-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03416, current rewards: 52.95866, mean: 0.10384
[32m[0906 17-13-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03413, current rewards: 58.37081, mean: 0.10423
[32m[0906 17-13-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03408, current rewards: 63.78663, mean: 0.10457
[32m[0906 17-13-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03404, current rewards: 69.19707, mean: 0.10484
[32m[0906 17-13-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03401, current rewards: 74.60823, mean: 0.10508
[32m[0906 17-13-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03401, current rewards: 80.01741, mean: 0.10529
[32m[0906 17-13-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03400, current rewards: 85.42781, mean: 0.10547
[32m[0906 17-13-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03399, current rewards: 90.83918, mean: 0.10563
[32m[0906 17-13-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03397, current rewards: 96.25083, mean: 0.10577
[32m[0906 17-13-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03394, current rewards: 101.57191, mean: 0.10580
[32m[0906 17-13-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03393, current rewards: 106.99700, mean: 0.10594
[32m[0906 17-13-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03392, current rewards: 112.42784, mean: 0.10606
[32m[0906 17-13-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03390, current rewards: 116.74331, mean: 0.10517
[32m[0906 17-13-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03387, current rewards: 122.23055, mean: 0.10537
[32m[0906 17-13-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03386, current rewards: 127.71343, mean: 0.10555
[32m[0906 17-13-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03384, current rewards: 133.20687, mean: 0.10572
[32m[0906 17-13-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03384, current rewards: 138.69103, mean: 0.10587
[32m[0906 17-13-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03383, current rewards: 144.17630, mean: 0.10601
[32m[0906 17-13-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03382, current rewards: 149.71398, mean: 0.10618
[32m[0906 17-13-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03380, current rewards: 155.20259, mean: 0.10630
[32m[0906 17-13-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03382, current rewards: 160.70057, mean: 0.10642
[32m[0906 17-13-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03384, current rewards: 166.19076, mean: 0.10653
[32m[0906 17-13-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03385, current rewards: 170.88638, mean: 0.10614
[32m[0906 17-13-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03387, current rewards: 176.56645, mean: 0.10637
[32m[0906 17-13-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03388, current rewards: 182.24907, mean: 0.10658
[32m[0906 17-13-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03390, current rewards: 187.93316, mean: 0.10678
[32m[0906 17-13-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03392, current rewards: 193.59117, mean: 0.10696
[32m[0906 17-14-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03394, current rewards: 199.26480, mean: 0.10713
[32m[0906 17-14-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03395, current rewards: 204.93721, mean: 0.10730
[32m[0906 17-14-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03398, current rewards: 210.61249, mean: 0.10746
[32m[0906 17-14-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03400, current rewards: 216.28919, mean: 0.10761
[32m[0906 17-14-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03400, current rewards: 221.97087, mean: 0.10775
[32m[0906 17-14-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03401, current rewards: 227.64487, mean: 0.10789
[32m[0906 17-14-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03402, current rewards: 233.32424, mean: 0.10802
[32m[0906 17-14-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03403, current rewards: 239.32413, mean: 0.10829
[32m[0906 17-14-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03404, current rewards: 244.99781, mean: 0.10841
[32m[0906 17-14-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03405, current rewards: 251.42287, mean: 0.10884
[32m[0906 17-14-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03405, current rewards: 256.92309, mean: 0.10887
[32m[0906 17-14-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03406, current rewards: 262.42252, mean: 0.10889
[32m[0906 17-14-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03407, current rewards: 267.92470, mean: 0.10891
[32m[0906 17-14-23 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 17-14-23 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-14-23 @MBExp.py:227][0m Rewards obtained: [270.644874127017], Lows: [2], Highs: [3], Total time: 6704.5053439999965
[32m[0906 17-17-02 @MBExp.py:144][0m ####################################################################
[32m[0906 17-17-02 @MBExp.py:145][0m Starting training iteration 78.
[32m[0906 17-17-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03274, current rewards: 1.10810, mean: 0.11081
[32m[0906 17-17-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03327, current rewards: 6.30495, mean: 0.10508
[32m[0906 17-17-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03326, current rewards: 11.76418, mean: 0.10695
[32m[0906 17-17-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03336, current rewards: 17.39840, mean: 0.10874
[32m[0906 17-17-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03343, current rewards: 22.88339, mean: 0.10897
[32m[0906 17-17-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03356, current rewards: 28.37254, mean: 0.10913
[32m[0906 17-17-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03371, current rewards: 33.86212, mean: 0.10923
[32m[0906 17-17-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03384, current rewards: 39.35106, mean: 0.10931
[32m[0906 17-17-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03389, current rewards: 44.84204, mean: 0.10937
[32m[0906 17-17-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03393, current rewards: 50.32978, mean: 0.10941
[32m[0906 17-17-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03385, current rewards: 55.81772, mean: 0.10945
[32m[0906 17-17-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03382, current rewards: 59.03696, mean: 0.10542
[32m[0906 17-17-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03380, current rewards: 64.52065, mean: 0.10577
[32m[0906 17-17-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03377, current rewards: 70.00376, mean: 0.10607
[32m[0906 17-17-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03375, current rewards: 75.49017, mean: 0.10632
[32m[0906 17-17-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03376, current rewards: 80.97941, mean: 0.10655
[32m[0906 17-17-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03374, current rewards: 86.46363, mean: 0.10675
[32m[0906 17-17-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03373, current rewards: 91.94904, mean: 0.10692
[32m[0906 17-17-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03372, current rewards: 97.42772, mean: 0.10706
[32m[0906 17-17-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03372, current rewards: 102.97536, mean: 0.10727
[32m[0906 17-17-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03372, current rewards: 108.50997, mean: 0.10744
[32m[0906 17-17-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03372, current rewards: 114.02814, mean: 0.10757
[32m[0906 17-17-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03370, current rewards: 119.54472, mean: 0.10770
[32m[0906 17-17-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03371, current rewards: 123.98057, mean: 0.10688
[32m[0906 17-17-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03369, current rewards: 129.53681, mean: 0.10706
[32m[0906 17-17-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03370, current rewards: 135.09758, mean: 0.10722
[32m[0906 17-17-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03368, current rewards: 140.65013, mean: 0.10737
[32m[0906 17-17-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03368, current rewards: 146.20933, mean: 0.10751
[32m[0906 17-17-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03367, current rewards: 152.07424, mean: 0.10785
[32m[0906 17-17-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03366, current rewards: 157.66240, mean: 0.10799
[32m[0906 17-17-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03369, current rewards: 163.24383, mean: 0.10811
[32m[0906 17-17-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03372, current rewards: 168.75836, mean: 0.10818
[32m[0906 17-17-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03375, current rewards: 174.31728, mean: 0.10827
[32m[0906 17-17-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03378, current rewards: 179.87627, mean: 0.10836
[32m[0906 17-18-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03380, current rewards: 185.43945, mean: 0.10844
[32m[0906 17-18-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03382, current rewards: 191.00166, mean: 0.10852
[32m[0906 17-18-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03384, current rewards: 196.55758, mean: 0.10860
[32m[0906 17-18-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03386, current rewards: 199.86521, mean: 0.10745
[32m[0906 17-18-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03388, current rewards: 205.12461, mean: 0.10740
[32m[0906 17-18-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03389, current rewards: 210.38337, mean: 0.10734
[32m[0906 17-18-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03390, current rewards: 215.64230, mean: 0.10728
[32m[0906 17-18-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03392, current rewards: 220.89869, mean: 0.10723
[32m[0906 17-18-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03393, current rewards: 226.15430, mean: 0.10718
[32m[0906 17-18-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03394, current rewards: 230.43613, mean: 0.10668
[32m[0906 17-18-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03395, current rewards: 235.88124, mean: 0.10673
[32m[0906 17-18-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03396, current rewards: 241.45332, mean: 0.10684
[32m[0906 17-18-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03397, current rewards: 247.05396, mean: 0.10695
[32m[0906 17-18-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03398, current rewards: 252.64770, mean: 0.10705
[32m[0906 17-18-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03399, current rewards: 258.24483, mean: 0.10716
[32m[0906 17-18-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03400, current rewards: 263.83617, mean: 0.10725
[32m[0906 17-18-27 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 17-18-27 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-18-27 @MBExp.py:227][0m Rewards obtained: [268.3089244809844], Lows: [1], Highs: [4], Total time: 6790.258799999997
[32m[0906 17-21-08 @MBExp.py:144][0m ####################################################################
[32m[0906 17-21-08 @MBExp.py:145][0m Starting training iteration 79.
[32m[0906 17-21-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03274, current rewards: -1.05045, mean: -0.10505
[32m[0906 17-21-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03349, current rewards: 4.67741, mean: 0.07796
[32m[0906 17-21-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03361, current rewards: 10.30521, mean: 0.09368
[32m[0906 17-21-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03365, current rewards: 15.85978, mean: 0.09912
[32m[0906 17-21-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03367, current rewards: 21.42138, mean: 0.10201
[32m[0906 17-21-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03370, current rewards: 26.98313, mean: 0.10378
[32m[0906 17-21-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03379, current rewards: 31.28794, mean: 0.10093
[32m[0906 17-21-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03390, current rewards: 36.75349, mean: 0.10209
[32m[0906 17-21-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03388, current rewards: 42.19487, mean: 0.10291
[32m[0906 17-21-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03388, current rewards: 47.64449, mean: 0.10357
[32m[0906 17-21-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03385, current rewards: 53.09763, mean: 0.10411
[32m[0906 17-21-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03382, current rewards: 58.64164, mean: 0.10472
[32m[0906 17-21-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03383, current rewards: 63.36571, mean: 0.10388
[32m[0906 17-21-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03382, current rewards: 69.06930, mean: 0.10465
[32m[0906 17-21-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03381, current rewards: 74.77457, mean: 0.10532
[32m[0906 17-21-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03380, current rewards: 80.49891, mean: 0.10592
[32m[0906 17-21-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03379, current rewards: 86.24407, mean: 0.10647
[32m[0906 17-21-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03379, current rewards: 91.98653, mean: 0.10696
[32m[0906 17-21-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03378, current rewards: 97.73868, mean: 0.10741
[32m[0906 17-21-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03377, current rewards: 103.49988, mean: 0.10781
[32m[0906 17-21-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03377, current rewards: 109.22657, mean: 0.10815
[32m[0906 17-21-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03377, current rewards: 114.94498, mean: 0.10844
[32m[0906 17-21-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03377, current rewards: 118.48829, mean: 0.10675
[32m[0906 17-21-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03375, current rewards: 123.98247, mean: 0.10688
[32m[0906 17-21-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03374, current rewards: 129.44939, mean: 0.10698
[32m[0906 17-21-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03375, current rewards: 134.91585, mean: 0.10708
[32m[0906 17-21-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03375, current rewards: 140.38386, mean: 0.10716
[32m[0906 17-21-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03376, current rewards: 145.85027, mean: 0.10724
[32m[0906 17-21-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03374, current rewards: 151.27025, mean: 0.10728
[32m[0906 17-21-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03375, current rewards: 157.01623, mean: 0.10755
[32m[0906 17-21-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03377, current rewards: 162.74808, mean: 0.10778
[32m[0906 17-22-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03379, current rewards: 168.56577, mean: 0.10805
[32m[0906 17-22-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03382, current rewards: 173.25313, mean: 0.10761
[32m[0906 17-22-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03384, current rewards: 181.38785, mean: 0.10927
[32m[0906 17-22-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03386, current rewards: 189.67225, mean: 0.11092
[32m[0906 17-22-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03388, current rewards: 197.63131, mean: 0.11229
[32m[0906 17-22-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03389, current rewards: 205.97663, mean: 0.11380
[32m[0906 17-22-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03392, current rewards: 212.97092, mean: 0.11450
[32m[0906 17-22-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03393, current rewards: 220.01509, mean: 0.11519
[32m[0906 17-22-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03395, current rewards: 227.05180, mean: 0.11584
[32m[0906 17-22-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03396, current rewards: 234.05532, mean: 0.11645
[32m[0906 17-22-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03397, current rewards: 241.16372, mean: 0.11707
[32m[0906 17-22-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03399, current rewards: 248.37160, mean: 0.11771
[32m[0906 17-22-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03400, current rewards: 255.45867, mean: 0.11827
[32m[0906 17-22-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03401, current rewards: 262.55561, mean: 0.11880
[32m[0906 17-22-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03402, current rewards: 268.84230, mean: 0.11896
[32m[0906 17-22-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03403, current rewards: 271.08188, mean: 0.11735
[32m[0906 17-22-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03404, current rewards: 276.49704, mean: 0.11716
[32m[0906 17-22-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03405, current rewards: 281.91706, mean: 0.11698
[32m[0906 17-22-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03406, current rewards: 287.33512, mean: 0.11680
[32m[0906 17-22-34 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 17-22-34 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-22-34 @MBExp.py:227][0m Rewards obtained: [291.6711986465243], Lows: [3], Highs: [5], Total time: 6876.171233999997
[32m[0906 17-25-17 @MBExp.py:144][0m ####################################################################
[32m[0906 17-25-17 @MBExp.py:145][0m Starting training iteration 80.
[32m[0906 17-25-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03305, current rewards: -0.04527, mean: -0.00453
[32m[0906 17-25-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03342, current rewards: 5.28997, mean: 0.08817
[32m[0906 17-25-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03349, current rewards: 10.63867, mean: 0.09672
[32m[0906 17-25-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03352, current rewards: 16.02057, mean: 0.10013
[32m[0906 17-25-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03354, current rewards: 21.36326, mean: 0.10173
[32m[0906 17-25-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03362, current rewards: 26.70845, mean: 0.10272
[32m[0906 17-25-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03376, current rewards: 32.04316, mean: 0.10337
[32m[0906 17-25-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03384, current rewards: 37.37842, mean: 0.10383
[32m[0906 17-25-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03375, current rewards: 42.71642, mean: 0.10419
[32m[0906 17-25-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03372, current rewards: 48.05495, mean: 0.10447
[32m[0906 17-25-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03370, current rewards: 53.39727, mean: 0.10470
[32m[0906 17-25-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03369, current rewards: 58.73746, mean: 0.10489
[32m[0906 17-25-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03370, current rewards: 64.08043, mean: 0.10505
[32m[0906 17-25-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03369, current rewards: 69.41748, mean: 0.10518
[32m[0906 17-25-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03368, current rewards: 70.60543, mean: 0.09944
[32m[0906 17-25-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03368, current rewards: 76.10030, mean: 0.10013
[32m[0906 17-25-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03367, current rewards: 81.59770, mean: 0.10074
[32m[0906 17-25-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03368, current rewards: 87.09859, mean: 0.10128
[32m[0906 17-25-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03368, current rewards: 92.59663, mean: 0.10175
[32m[0906 17-25-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03367, current rewards: 98.23165, mean: 0.10232
[32m[0906 17-25-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03365, current rewards: 103.77517, mean: 0.10275
[32m[0906 17-25-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03364, current rewards: 109.31751, mean: 0.10313
[32m[0906 17-25-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03364, current rewards: 114.85839, mean: 0.10348
[32m[0906 17-25-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03362, current rewards: 120.40248, mean: 0.10380
[32m[0906 17-25-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03362, current rewards: 125.94517, mean: 0.10409
[32m[0906 17-26-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03363, current rewards: 131.48883, mean: 0.10436
[32m[0906 17-26-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03363, current rewards: 137.03519, mean: 0.10461
[32m[0906 17-26-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03363, current rewards: 140.50533, mean: 0.10331
[32m[0906 17-26-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03362, current rewards: 146.32133, mean: 0.10377
[32m[0906 17-26-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03364, current rewards: 152.13510, mean: 0.10420
[32m[0906 17-26-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03367, current rewards: 157.94461, mean: 0.10460
[32m[0906 17-26-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03369, current rewards: 163.74748, mean: 0.10497
[32m[0906 17-26-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03372, current rewards: 169.55650, mean: 0.10531
[32m[0906 17-26-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03374, current rewards: 175.37093, mean: 0.10565
[32m[0906 17-26-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03376, current rewards: 181.18731, mean: 0.10596
[32m[0906 17-26-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03378, current rewards: 187.08567, mean: 0.10630
[32m[0906 17-26-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03380, current rewards: 190.72170, mean: 0.10537
[32m[0906 17-26-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03382, current rewards: 196.50164, mean: 0.10565
[32m[0906 17-26-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03384, current rewards: 202.28994, mean: 0.10591
[32m[0906 17-26-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03385, current rewards: 208.07493, mean: 0.10616
[32m[0906 17-26-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03387, current rewards: 213.86189, mean: 0.10640
[32m[0906 17-26-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03388, current rewards: 219.64152, mean: 0.10662
[32m[0906 17-26-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03389, current rewards: 223.15070, mean: 0.10576
[32m[0906 17-26-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03389, current rewards: 228.48078, mean: 0.10578
[32m[0906 17-26-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03390, current rewards: 233.83311, mean: 0.10581
[32m[0906 17-26-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03392, current rewards: 239.25630, mean: 0.10587
[32m[0906 17-26-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03393, current rewards: 244.67521, mean: 0.10592
[32m[0906 17-26-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03394, current rewards: 250.09805, mean: 0.10597
[32m[0906 17-26-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03395, current rewards: 255.51646, mean: 0.10602
[32m[0906 17-26-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03396, current rewards: 260.93667, mean: 0.10607
[32m[0906 17-26-42 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 17-26-42 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-26-43 @MBExp.py:227][0m Rewards obtained: [264.45128381206047], Lows: [4], Highs: [4], Total time: 6961.835006999997
[32m[0906 17-29-27 @MBExp.py:144][0m ####################################################################
[32m[0906 17-29-27 @MBExp.py:145][0m Starting training iteration 81.
[32m[0906 17-29-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03338, current rewards: -0.02750, mean: -0.00275
[32m[0906 17-29-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03347, current rewards: 5.54639, mean: 0.09244
[32m[0906 17-29-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03348, current rewards: 11.12971, mean: 0.10118
[32m[0906 17-29-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03350, current rewards: 16.70499, mean: 0.10441
[32m[0906 17-29-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03346, current rewards: 22.28340, mean: 0.10611
[32m[0906 17-29-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03359, current rewards: 27.85483, mean: 0.10713
[32m[0906 17-29-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03375, current rewards: 33.43262, mean: 0.10785
[32m[0906 17-29-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03370, current rewards: 39.01014, mean: 0.10836
[32m[0906 17-29-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03371, current rewards: 44.58275, mean: 0.10874
[32m[0906 17-29-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03370, current rewards: 50.15671, mean: 0.10904
[32m[0906 17-29-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03370, current rewards: 55.82605, mean: 0.10946
[32m[0906 17-29-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03369, current rewards: 59.36902, mean: 0.10602
[32m[0906 17-29-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03367, current rewards: 64.91052, mean: 0.10641
[32m[0906 17-29-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03366, current rewards: 70.45401, mean: 0.10675
[32m[0906 17-29-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03367, current rewards: 75.99833, mean: 0.10704
[32m[0906 17-29-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03366, current rewards: 81.54366, mean: 0.10729
[32m[0906 17-29-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03366, current rewards: 87.09218, mean: 0.10752
[32m[0906 17-29-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03364, current rewards: 92.63657, mean: 0.10772
[32m[0906 17-29-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03363, current rewards: 95.84585, mean: 0.10533
[32m[0906 17-29-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03363, current rewards: 101.31665, mean: 0.10554
[32m[0906 17-30-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03363, current rewards: 106.78524, mean: 0.10573
[32m[0906 17-30-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03363, current rewards: 112.25134, mean: 0.10590
[32m[0906 17-30-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03364, current rewards: 117.72003, mean: 0.10605
[32m[0906 17-30-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03363, current rewards: 123.18688, mean: 0.10620
[32m[0906 17-30-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03363, current rewards: 128.65390, mean: 0.10633
[32m[0906 17-30-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03363, current rewards: 134.11916, mean: 0.10644
[32m[0906 17-30-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03362, current rewards: 139.58698, mean: 0.10655
[32m[0906 17-30-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03361, current rewards: 145.06465, mean: 0.10667
[32m[0906 17-30-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03360, current rewards: 150.52421, mean: 0.10675
[32m[0906 17-30-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03362, current rewards: 155.98308, mean: 0.10684
[32m[0906 17-30-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03365, current rewards: 161.43980, mean: 0.10691
[32m[0906 17-30-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03368, current rewards: 166.89607, mean: 0.10698
[32m[0906 17-30-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03370, current rewards: 170.19369, mean: 0.10571
[32m[0906 17-30-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03373, current rewards: 175.72660, mean: 0.10586
[32m[0906 17-30-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03375, current rewards: 181.26718, mean: 0.10600
[32m[0906 17-30-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03376, current rewards: 186.79817, mean: 0.10614
[32m[0906 17-30-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03378, current rewards: 192.33141, mean: 0.10626
[32m[0906 17-30-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03380, current rewards: 197.86063, mean: 0.10638
[32m[0906 17-30-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03382, current rewards: 203.39759, mean: 0.10649
[32m[0906 17-30-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03384, current rewards: 208.92632, mean: 0.10660
[32m[0906 17-30-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03385, current rewards: 214.46280, mean: 0.10670
[32m[0906 17-30-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03387, current rewards: 219.99144, mean: 0.10679
[32m[0906 17-30-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03388, current rewards: 225.52133, mean: 0.10688
[32m[0906 17-30-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03390, current rewards: 231.17802, mean: 0.10703
[32m[0906 17-30-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03391, current rewards: 236.72717, mean: 0.10712
[32m[0906 17-30-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03392, current rewards: 242.27270, mean: 0.10720
[32m[0906 17-30-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03393, current rewards: 247.82129, mean: 0.10728
[32m[0906 17-30-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03395, current rewards: 254.12653, mean: 0.10768
[32m[0906 17-30-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03396, current rewards: 259.67874, mean: 0.10775
[32m[0906 17-30-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03397, current rewards: 265.22988, mean: 0.10782
[32m[0906 17-30-53 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 17-30-53 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-30-53 @MBExp.py:227][0m Rewards obtained: [269.6776950202038], Lows: [2], Highs: [3], Total time: 7047.548248999997
[32m[0906 17-33-39 @MBExp.py:144][0m ####################################################################
[32m[0906 17-33-39 @MBExp.py:145][0m Starting training iteration 82.
[32m[0906 17-33-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03257, current rewards: 1.02804, mean: 0.10280
[32m[0906 17-33-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03325, current rewards: 6.89013, mean: 0.11484
[32m[0906 17-33-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03339, current rewards: 13.20556, mean: 0.12005
[32m[0906 17-33-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03346, current rewards: 19.52098, mean: 0.12201
[32m[0906 17-33-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03348, current rewards: 25.83641, mean: 0.12303
[32m[0906 17-33-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03351, current rewards: 32.15183, mean: 0.12366
[32m[0906 17-33-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03333, current rewards: 38.46726, mean: 0.12409
[32m[0906 17-33-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03331, current rewards: 44.78268, mean: 0.12440
[32m[0906 17-33-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03333, current rewards: 6.04577, mean: 0.01475
[32m[0906 17-33-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03334, current rewards: -43.95423, mean: -0.09555
[32m[0906 17-33-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03336, current rewards: -82.93578, mean: -0.16262
[32m[0906 17-33-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03340, current rewards: -77.51501, mean: -0.13842
[32m[0906 17-34-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03342, current rewards: -72.09525, mean: -0.11819
[32m[0906 17-34-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03344, current rewards: -66.67249, mean: -0.10102
[32m[0906 17-34-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03345, current rewards: -61.25773, mean: -0.08628
[32m[0906 17-34-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03346, current rewards: -60.01187, mean: -0.07896
[32m[0906 17-34-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03347, current rewards: -54.51670, mean: -0.06730
[32m[0906 17-34-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03349, current rewards: -49.13864, mean: -0.05714
[32m[0906 17-34-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03350, current rewards: -43.85627, mean: -0.04819
[32m[0906 17-34-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03351, current rewards: -38.41128, mean: -0.04001
[32m[0906 17-34-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03352, current rewards: -32.95929, mean: -0.03263
[32m[0906 17-34-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03354, current rewards: -27.51335, mean: -0.02596
[32m[0906 17-34-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03353, current rewards: -22.06304, mean: -0.01988
[32m[0906 17-34-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03353, current rewards: -16.63032, mean: -0.01434
[32m[0906 17-34-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03352, current rewards: -11.18027, mean: -0.00924
[32m[0906 17-34-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03353, current rewards: -7.79228, mean: -0.00618
[32m[0906 17-34-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03351, current rewards: -2.14803, mean: -0.00164
[32m[0906 17-34-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03352, current rewards: 3.39663, mean: 0.00250
[32m[0906 17-34-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03352, current rewards: 8.93972, mean: 0.00634
[32m[0906 17-34-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03355, current rewards: 14.48351, mean: 0.00992
[32m[0906 17-34-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03358, current rewards: 20.02506, mean: 0.01326
[32m[0906 17-34-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03361, current rewards: 25.56517, mean: 0.01639
[32m[0906 17-34-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03363, current rewards: 31.11284, mean: 0.01932
[32m[0906 17-34-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03366, current rewards: 35.68294, mean: 0.02150
[32m[0906 17-34-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03368, current rewards: 41.39901, mean: 0.02421
[32m[0906 17-34-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03370, current rewards: 46.95338, mean: 0.02668
[32m[0906 17-34-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03372, current rewards: 52.49744, mean: 0.02900
[32m[0906 17-34-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03374, current rewards: 58.04471, mean: 0.03121
[32m[0906 17-34-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03375, current rewards: 63.58389, mean: 0.03329
[32m[0906 17-34-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03377, current rewards: 69.13331, mean: 0.03527
[32m[0906 17-34-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03379, current rewards: 74.68025, mean: 0.03715
[32m[0906 17-34-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03381, current rewards: 80.22863, mean: 0.03895
[32m[0906 17-34-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03383, current rewards: 83.85306, mean: 0.03974
[32m[0906 17-34-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03384, current rewards: 89.57406, mean: 0.04147
[32m[0906 17-34-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03385, current rewards: 95.29800, mean: 0.04312
[32m[0906 17-34-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03386, current rewards: 101.02149, mean: 0.04470
[32m[0906 17-34-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03387, current rewards: 106.74586, mean: 0.04621
[32m[0906 17-35-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03389, current rewards: 112.46577, mean: 0.04765
[32m[0906 17-35-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03390, current rewards: 118.18909, mean: 0.04904
[32m[0906 17-35-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03391, current rewards: 123.91344, mean: 0.05037
[32m[0906 17-35-05 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 17-35-05 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-35-05 @MBExp.py:227][0m Rewards obtained: [128.48855197886866], Lows: [4], Highs: [131], Total time: 7133.097910999997
[32m[0906 17-37-53 @MBExp.py:144][0m ####################################################################
[32m[0906 17-37-53 @MBExp.py:145][0m Starting training iteration 83.
[32m[0906 17-37-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03271, current rewards: 1.47372, mean: 0.14737
[32m[0906 17-37-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03340, current rewards: 6.84862, mean: 0.11414
[32m[0906 17-37-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03350, current rewards: 12.48948, mean: 0.11354
[32m[0906 17-37-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03362, current rewards: 18.12633, mean: 0.11329
[32m[0906 17-38-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03359, current rewards: 23.76566, mean: 0.11317
[32m[0906 17-38-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03331, current rewards: 29.40673, mean: 0.11310
[32m[0906 17-38-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03318, current rewards: 35.04684, mean: 0.11305
[32m[0906 17-38-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03318, current rewards: 40.68741, mean: 0.11302
[32m[0906 17-38-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03320, current rewards: 46.32812, mean: 0.11300
[32m[0906 17-38-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03325, current rewards: 50.84198, mean: 0.11053
[32m[0906 17-38-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03327, current rewards: 56.42273, mean: 0.11063
[32m[0906 17-38-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03330, current rewards: 62.00348, mean: 0.11072
[32m[0906 17-38-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03332, current rewards: 67.58604, mean: 0.11080
[32m[0906 17-38-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03335, current rewards: 73.16376, mean: 0.11085
[32m[0906 17-38-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03337, current rewards: 77.62951, mean: 0.10934
[32m[0906 17-38-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03339, current rewards: 83.23505, mean: 0.10952
[32m[0906 17-38-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03340, current rewards: 88.83889, mean: 0.10968
[32m[0906 17-38-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03342, current rewards: 94.39114, mean: 0.10976
[32m[0906 17-38-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03342, current rewards: 100.00607, mean: 0.10990
[32m[0906 17-38-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03342, current rewards: 105.61613, mean: 0.11002
[32m[0906 17-38-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03343, current rewards: 111.22308, mean: 0.11012
[32m[0906 17-38-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03343, current rewards: 114.70556, mean: 0.10821
[32m[0906 17-38-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03344, current rewards: 120.26302, mean: 0.10835
[32m[0906 17-38-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03344, current rewards: 125.81924, mean: 0.10846
[32m[0906 17-38-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03345, current rewards: 131.38470, mean: 0.10858
[32m[0906 17-38-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03345, current rewards: 137.01553, mean: 0.10874
[32m[0906 17-38-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03346, current rewards: 142.58014, mean: 0.10884
[32m[0906 17-38-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03346, current rewards: 148.14397, mean: 0.10893
[32m[0906 17-38-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03347, current rewards: 153.71456, mean: 0.10902
[32m[0906 17-38-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03350, current rewards: 159.27433, mean: 0.10909
[32m[0906 17-38-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03354, current rewards: 164.83800, mean: 0.10916
[32m[0906 17-38-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03356, current rewards: 170.34713, mean: 0.10920
[32m[0906 17-38-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03360, current rewards: 175.91360, mean: 0.10926
[32m[0906 17-38-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03362, current rewards: 181.54438, mean: 0.10936
[32m[0906 17-38-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03365, current rewards: 187.11455, mean: 0.10942
[32m[0906 17-38-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03367, current rewards: 192.69153, mean: 0.10948
[32m[0906 17-38-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03369, current rewards: 196.23652, mean: 0.10842
[32m[0906 17-38-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03371, current rewards: 201.83041, mean: 0.10851
[32m[0906 17-38-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03373, current rewards: 207.42301, mean: 0.10860
[32m[0906 17-39-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03374, current rewards: 213.01514, mean: 0.10868
[32m[0906 17-39-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03376, current rewards: 218.61253, mean: 0.10876
[32m[0906 17-39-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03377, current rewards: 224.19114, mean: 0.10883
[32m[0906 17-39-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03379, current rewards: 229.61146, mean: 0.10882
[32m[0906 17-39-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03380, current rewards: 234.15457, mean: 0.10840
[32m[0906 17-39-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03382, current rewards: 239.76869, mean: 0.10849
[32m[0906 17-39-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03383, current rewards: 245.38891, mean: 0.10858
[32m[0906 17-39-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03385, current rewards: 251.00389, mean: 0.10866
[32m[0906 17-39-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03386, current rewards: 256.61270, mean: 0.10873
[32m[0906 17-39-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03387, current rewards: 262.21929, mean: 0.10880
[32m[0906 17-39-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03388, current rewards: 267.83374, mean: 0.10888
[32m[0906 17-39-18 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 17-39-18 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-39-19 @MBExp.py:227][0m Rewards obtained: [273.1575484963355], Lows: [2], Highs: [3], Total time: 7218.571747999997
[32m[0906 17-42-09 @MBExp.py:144][0m ####################################################################
[32m[0906 17-42-09 @MBExp.py:145][0m Starting training iteration 84.
[32m[0906 17-42-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03270, current rewards: 0.04947, mean: 0.00495
[32m[0906 17-42-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03332, current rewards: 5.68050, mean: 0.09467
[32m[0906 17-42-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03349, current rewards: 11.27765, mean: 0.10252
[32m[0906 17-42-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03342, current rewards: 16.87677, mean: 0.10548
[32m[0906 17-42-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03325, current rewards: 22.47569, mean: 0.10703
[32m[0906 17-42-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03315, current rewards: 28.07599, mean: 0.10798
[32m[0906 17-42-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03309, current rewards: 33.67520, mean: 0.10863
[32m[0906 17-42-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03303, current rewards: 39.27914, mean: 0.10911
[32m[0906 17-42-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03295, current rewards: 44.81466, mean: 0.10930
[32m[0906 17-42-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03304, current rewards: 50.42881, mean: 0.10963
[32m[0906 17-42-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03309, current rewards: 56.04155, mean: 0.10989
[32m[0906 17-42-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03315, current rewards: 61.65280, mean: 0.11009
[32m[0906 17-42-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03321, current rewards: 65.15607, mean: 0.10681
[32m[0906 17-42-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03323, current rewards: 70.71949, mean: 0.10715
[32m[0906 17-42-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03326, current rewards: 76.28553, mean: 0.10744
[32m[0906 17-42-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03328, current rewards: 81.84971, mean: 0.10770
[32m[0906 17-42-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03330, current rewards: 87.37428, mean: 0.10787
[32m[0906 17-42-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03331, current rewards: 92.91292, mean: 0.10804
[32m[0906 17-42-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03334, current rewards: 98.47452, mean: 0.10821
[32m[0906 17-42-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03335, current rewards: 104.03864, mean: 0.10837
[32m[0906 17-42-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03336, current rewards: 109.60423, mean: 0.10852
[32m[0906 17-42-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03338, current rewards: 115.16566, mean: 0.10865
[32m[0906 17-42-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03340, current rewards: 118.89260, mean: 0.10711
[32m[0906 17-42-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03339, current rewards: 124.35038, mean: 0.10720
[32m[0906 17-42-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03341, current rewards: 129.80581, mean: 0.10728
[32m[0906 17-42-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03341, current rewards: 135.33268, mean: 0.10741
[32m[0906 17-42-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03341, current rewards: 140.81184, mean: 0.10749
[32m[0906 17-42-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03342, current rewards: 146.29019, mean: 0.10757
[32m[0906 17-42-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03343, current rewards: 151.76863, mean: 0.10764
[32m[0906 17-42-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03345, current rewards: 157.24769, mean: 0.10770
[32m[0906 17-43-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03349, current rewards: 162.72409, mean: 0.10776
[32m[0906 17-43-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03352, current rewards: 168.20457, mean: 0.10782
[32m[0906 17-43-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03355, current rewards: 174.39120, mean: 0.10832
[32m[0906 17-43-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03359, current rewards: 179.99808, mean: 0.10843
[32m[0906 17-43-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03361, current rewards: 185.55619, mean: 0.10851
[32m[0906 17-43-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03365, current rewards: 191.11253, mean: 0.10859
[32m[0906 17-43-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03367, current rewards: 196.66896, mean: 0.10866
[32m[0906 17-43-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03369, current rewards: 200.08838, mean: 0.10757
[32m[0906 17-43-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03371, current rewards: 205.64314, mean: 0.10767
[32m[0906 17-43-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03374, current rewards: 211.19495, mean: 0.10775
[32m[0906 17-43-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03376, current rewards: 216.74816, mean: 0.10783
[32m[0906 17-43-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03377, current rewards: 222.30793, mean: 0.10792
[32m[0906 17-43-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03378, current rewards: 227.86665, mean: 0.10799
[32m[0906 17-43-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03380, current rewards: 233.42278, mean: 0.10807
[32m[0906 17-43-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03381, current rewards: 238.98368, mean: 0.10814
[32m[0906 17-43-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03382, current rewards: 242.38391, mean: 0.10725
[32m[0906 17-43-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03384, current rewards: 247.90954, mean: 0.10732
[32m[0906 17-43-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03385, current rewards: 253.43308, mean: 0.10739
[32m[0906 17-43-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03386, current rewards: 258.96330, mean: 0.10745
[32m[0906 17-43-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03388, current rewards: 264.36322, mean: 0.10746
[32m[0906 17-43-34 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 17-43-34 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-43-34 @MBExp.py:227][0m Rewards obtained: [268.77102644442203], Lows: [3], Highs: [3], Total time: 7304.043563999997
[32m[0906 17-46-27 @MBExp.py:144][0m ####################################################################
[32m[0906 17-46-27 @MBExp.py:145][0m Starting training iteration 85.
[32m[0906 17-46-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03281, current rewards: -1.20419, mean: -0.12042
[32m[0906 17-46-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03341, current rewards: 4.28598, mean: 0.07143
[32m[0906 17-46-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03342, current rewards: 9.84409, mean: 0.08949
[32m[0906 17-46-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03313, current rewards: 15.39661, mean: 0.09623
[32m[0906 17-46-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03298, current rewards: 20.95027, mean: 0.09976
[32m[0906 17-46-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03292, current rewards: 26.49987, mean: 0.10192
[32m[0906 17-46-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03287, current rewards: 32.05428, mean: 0.10340
[32m[0906 17-46-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03286, current rewards: 37.63157, mean: 0.10453
[32m[0906 17-46-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03279, current rewards: 43.37513, mean: 0.10579
[32m[0906 17-46-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03288, current rewards: 48.93515, mean: 0.10638
[32m[0906 17-46-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03294, current rewards: 52.36998, mean: 0.10269
[32m[0906 17-46-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03301, current rewards: 57.94379, mean: 0.10347
[32m[0906 17-46-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03305, current rewards: 63.49821, mean: 0.10410
[32m[0906 17-46-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03310, current rewards: 69.05030, mean: 0.10462
[32m[0906 17-46-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03312, current rewards: 74.60351, mean: 0.10508
[32m[0906 17-46-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03316, current rewards: 80.15517, mean: 0.10547
[32m[0906 17-46-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03319, current rewards: 85.70872, mean: 0.10581
[32m[0906 17-46-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03320, current rewards: 91.26222, mean: 0.10612
[32m[0906 17-46-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03321, current rewards: 96.81492, mean: 0.10639
[32m[0906 17-46-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03324, current rewards: 102.36784, mean: 0.10663
[32m[0906 17-47-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03325, current rewards: 107.92034, mean: 0.10685
[32m[0906 17-47-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03327, current rewards: 111.18985, mean: 0.10490
[32m[0906 17-47-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03329, current rewards: 116.73354, mean: 0.10517
[32m[0906 17-47-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03331, current rewards: 122.27804, mean: 0.10541
[32m[0906 17-47-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03332, current rewards: 127.83294, mean: 0.10565
[32m[0906 17-47-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03333, current rewards: 133.37485, mean: 0.10585
[32m[0906 17-47-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03333, current rewards: 138.91336, mean: 0.10604
[32m[0906 17-47-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03334, current rewards: 144.44961, mean: 0.10621
[32m[0906 17-47-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03335, current rewards: 149.98885, mean: 0.10638
[32m[0906 17-47-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03337, current rewards: 155.53020, mean: 0.10653
[32m[0906 17-47-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03341, current rewards: 159.60995, mean: 0.10570
[32m[0906 17-47-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03344, current rewards: 165.10888, mean: 0.10584
[32m[0906 17-47-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03347, current rewards: 170.68587, mean: 0.10602
[32m[0906 17-47-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03351, current rewards: 176.20097, mean: 0.10615
[32m[0906 17-47-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03353, current rewards: 181.73942, mean: 0.10628
[32m[0906 17-47-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03355, current rewards: 187.26690, mean: 0.10640
[32m[0906 17-47-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03357, current rewards: 192.76824, mean: 0.10650
[32m[0906 17-47-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03359, current rewards: 198.27481, mean: 0.10660
[32m[0906 17-47-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03361, current rewards: 203.78001, mean: 0.10669
[32m[0906 17-47-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03364, current rewards: 209.28576, mean: 0.10678
[32m[0906 17-47-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03366, current rewards: 213.56307, mean: 0.10625
[32m[0906 17-47-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03368, current rewards: 219.04882, mean: 0.10633
[32m[0906 17-47-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03370, current rewards: 224.53087, mean: 0.10641
[32m[0906 17-47-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03372, current rewards: 230.01467, mean: 0.10649
[32m[0906 17-47-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03373, current rewards: 235.49508, mean: 0.10656
[32m[0906 17-47-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03374, current rewards: 240.97470, mean: 0.10663
[32m[0906 17-47-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03376, current rewards: 246.45396, mean: 0.10669
[32m[0906 17-47-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03378, current rewards: 251.84256, mean: 0.10671
[32m[0906 17-47-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03379, current rewards: 257.34485, mean: 0.10678
[32m[0906 17-47-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03381, current rewards: 262.71472, mean: 0.10679
[32m[0906 17-47-52 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-47-52 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-47-52 @MBExp.py:227][0m Rewards obtained: [267.01774647117753], Lows: [2], Highs: [5], Total time: 7389.348939999997
[32m[0906 17-50-47 @MBExp.py:144][0m ####################################################################
[32m[0906 17-50-47 @MBExp.py:145][0m Starting training iteration 86.
[32m[0906 17-50-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03278, current rewards: -1.20773, mean: -0.12077
[32m[0906 17-50-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03333, current rewards: 4.30282, mean: 0.07171
[32m[0906 17-50-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03317, current rewards: 9.81681, mean: 0.08924
[32m[0906 17-50-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03300, current rewards: 15.32977, mean: 0.09581
[32m[0906 17-50-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03285, current rewards: 20.84735, mean: 0.09927
[32m[0906 17-50-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03282, current rewards: 26.35861, mean: 0.10138
[32m[0906 17-50-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03278, current rewards: 31.86453, mean: 0.10279
[32m[0906 17-50-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03276, current rewards: 37.37242, mean: 0.10381
[32m[0906 17-51-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03273, current rewards: 42.87968, mean: 0.10458
[32m[0906 17-51-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03284, current rewards: 48.39869, mean: 0.10521
[32m[0906 17-51-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03291, current rewards: 51.75335, mean: 0.10148
[32m[0906 17-51-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03295, current rewards: 56.91028, mean: 0.10163
[32m[0906 17-51-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03300, current rewards: 62.06788, mean: 0.10175
[32m[0906 17-51-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03305, current rewards: 67.22643, mean: 0.10186
[32m[0906 17-51-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03308, current rewards: 72.38640, mean: 0.10195
[32m[0906 17-51-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03311, current rewards: 77.98201, mean: 0.10261
[32m[0906 17-51-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03314, current rewards: 83.54515, mean: 0.10314
[32m[0906 17-51-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03317, current rewards: 89.10830, mean: 0.10361
[32m[0906 17-51-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03319, current rewards: 85.78135, mean: 0.09427
[32m[0906 17-51-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03321, current rewards: 35.78135, mean: 0.03727
[32m[0906 17-51-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03323, current rewards: -14.21865, mean: -0.01408
[32m[0906 17-51-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03325, current rewards: -64.21865, mean: -0.06058
[32m[0906 17-51-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03328, current rewards: -114.21865, mean: -0.10290
[32m[0906 17-51-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03329, current rewards: -164.21865, mean: -0.14157
[32m[0906 17-51-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03330, current rewards: -214.21865, mean: -0.17704
[32m[0906 17-51-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03331, current rewards: -264.21865, mean: -0.20970
[32m[0906 17-51-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03332, current rewards: -314.21865, mean: -0.23986
[32m[0906 17-51-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03333, current rewards: -364.21865, mean: -0.26781
[32m[0906 17-51-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03334, current rewards: -414.21865, mean: -0.29377
[32m[0906 17-51-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03334, current rewards: -464.21865, mean: -0.31796
[32m[0906 17-51-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03340, current rewards: -514.21865, mean: -0.34054
[32m[0906 17-51-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03343, current rewards: -564.21865, mean: -0.36168
[32m[0906 17-51-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03347, current rewards: -614.21865, mean: -0.38150
[32m[0906 17-51-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03350, current rewards: -664.21865, mean: -0.40013
[32m[0906 17-51-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03353, current rewards: -714.21865, mean: -0.41767
[32m[0906 17-51-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03355, current rewards: -764.21865, mean: -0.43422
[32m[0906 17-51-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03358, current rewards: -814.21865, mean: -0.44984
[32m[0906 17-51-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03360, current rewards: -864.21865, mean: -0.46463
[32m[0906 17-51-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03363, current rewards: -914.21865, mean: -0.47865
[32m[0906 17-51-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03365, current rewards: -964.21865, mean: -0.49195
[32m[0906 17-51-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03367, current rewards: -1014.21865, mean: -0.50459
[32m[0906 17-51-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03368, current rewards: -1064.21865, mean: -0.51661
[32m[0906 17-51-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03370, current rewards: -1114.21865, mean: -0.52807
[32m[0906 17-52-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03372, current rewards: -1164.21865, mean: -0.53899
[32m[0906 17-52-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03374, current rewards: -1214.21865, mean: -0.54942
[32m[0906 17-52-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03375, current rewards: -1264.21865, mean: -0.55939
[32m[0906 17-52-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03377, current rewards: -1314.21865, mean: -0.56893
[32m[0906 17-52-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03378, current rewards: -1364.21865, mean: -0.57806
[32m[0906 17-52-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03380, current rewards: -1414.21865, mean: -0.58681
[32m[0906 17-52-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03382, current rewards: -1464.21865, mean: -0.59521
[32m[0906 17-52-12 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-52-12 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-52-12 @MBExp.py:227][0m Rewards obtained: [-1504.2186532867195], Lows: [1], Highs: [1600], Total time: 7474.667042999997
[32m[0906 17-55-09 @MBExp.py:144][0m ####################################################################
[32m[0906 17-55-09 @MBExp.py:145][0m Starting training iteration 87.
[32m[0906 17-55-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03255, current rewards: 0.04324, mean: 0.00432
[32m[0906 17-55-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03285, current rewards: 5.59971, mean: 0.09333
[32m[0906 17-55-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03278, current rewards: 11.15312, mean: 0.10139
[32m[0906 17-55-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03280, current rewards: 16.70745, mean: 0.10442
[32m[0906 17-55-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03276, current rewards: 22.26332, mean: 0.10602
[32m[0906 17-55-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03277, current rewards: 27.81795, mean: 0.10699
[32m[0906 17-55-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03277, current rewards: 33.19319, mean: 0.10707
[32m[0906 17-55-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03277, current rewards: 38.72430, mean: 0.10757
[32m[0906 17-55-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03273, current rewards: 44.25900, mean: 0.10795
[32m[0906 17-55-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03271, current rewards: 49.79559, mean: 0.10825
[32m[0906 17-55-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03277, current rewards: 55.32642, mean: 0.10848
[32m[0906 17-55-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03286, current rewards: 58.63730, mean: 0.10471
[32m[0906 17-55-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03292, current rewards: 64.06678, mean: 0.10503
[32m[0906 17-55-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03296, current rewards: 69.49667, mean: 0.10530
[32m[0906 17-55-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03302, current rewards: 75.22746, mean: 0.10595
[32m[0906 17-55-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03307, current rewards: 80.70111, mean: 0.10619
[32m[0906 17-55-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03312, current rewards: 83.88700, mean: 0.10356
[32m[0906 17-55-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03314, current rewards: 89.31551, mean: 0.10386
[32m[0906 17-55-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03317, current rewards: 94.73916, mean: 0.10411
[32m[0906 17-55-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03320, current rewards: 100.16982, mean: 0.10434
[32m[0906 17-55-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03322, current rewards: 105.60259, mean: 0.10456
[32m[0906 17-55-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03324, current rewards: 111.03209, mean: 0.10475
[32m[0906 17-55-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03327, current rewards: 116.48509, mean: 0.10494
[32m[0906 17-55-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03327, current rewards: 121.95562, mean: 0.10513
[32m[0906 17-55-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03330, current rewards: 127.39209, mean: 0.10528
[32m[0906 17-55-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03331, current rewards: 130.91237, mean: 0.10390
[32m[0906 17-55-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03332, current rewards: 136.45384, mean: 0.10416
[32m[0906 17-55-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03332, current rewards: 141.98393, mean: 0.10440
[32m[0906 17-55-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03334, current rewards: 147.52107, mean: 0.10462
[32m[0906 17-55-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03335, current rewards: 153.05139, mean: 0.10483
[32m[0906 17-56-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03336, current rewards: 158.58645, mean: 0.10502
[32m[0906 17-56-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03337, current rewards: 163.91463, mean: 0.10507
[32m[0906 17-56-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03338, current rewards: 169.46004, mean: 0.10525
[32m[0906 17-56-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03340, current rewards: 175.00141, mean: 0.10542
[32m[0906 17-56-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03344, current rewards: 180.48120, mean: 0.10554
[32m[0906 17-56-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03347, current rewards: 185.98485, mean: 0.10567
[32m[0906 17-56-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03350, current rewards: 191.49041, mean: 0.10580
[32m[0906 17-56-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03352, current rewards: 196.99036, mean: 0.10591
[32m[0906 17-56-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03355, current rewards: 202.48890, mean: 0.10602
[32m[0906 17-56-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03358, current rewards: 208.17062, mean: 0.10621
[32m[0906 17-56-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03360, current rewards: 213.71449, mean: 0.10633
[32m[0906 17-56-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03363, current rewards: 219.23752, mean: 0.10643
[32m[0906 17-56-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03365, current rewards: 224.76248, mean: 0.10652
[32m[0906 17-56-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03367, current rewards: 230.28443, mean: 0.10661
[32m[0906 17-56-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03368, current rewards: 235.76833, mean: 0.10668
[32m[0906 17-56-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03370, current rewards: 241.30918, mean: 0.10677
[32m[0906 17-56-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03372, current rewards: 246.85731, mean: 0.10686
[32m[0906 17-56-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03374, current rewards: 252.40122, mean: 0.10695
[32m[0906 17-56-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03375, current rewards: 257.93266, mean: 0.10703
[32m[0906 17-56-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03377, current rewards: 263.48015, mean: 0.10711
[32m[0906 17-56-34 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-56-34 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-56-34 @MBExp.py:227][0m Rewards obtained: [267.9157681414581], Lows: [2], Highs: [3], Total time: 7559.873924999997
[32m[0906 17-59-33 @MBExp.py:144][0m ####################################################################
[32m[0906 17-59-33 @MBExp.py:145][0m Starting training iteration 88.
[32m[0906 17-59-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03242, current rewards: 0.01629, mean: 0.00163
[32m[0906 17-59-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03242, current rewards: 5.60329, mean: 0.09339
[32m[0906 17-59-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03248, current rewards: 11.18320, mean: 0.10167
[32m[0906 17-59-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03251, current rewards: 16.75949, mean: 0.10475
[32m[0906 17-59-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03251, current rewards: 22.33992, mean: 0.10638
[32m[0906 17-59-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03253, current rewards: 27.91982, mean: 0.10738
[32m[0906 17-59-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03252, current rewards: 33.34199, mean: 0.10755
[32m[0906 17-59-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03258, current rewards: 38.87704, mean: 0.10799
[32m[0906 17-59-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03259, current rewards: 44.40806, mean: 0.10831
[32m[0906 17-59-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03258, current rewards: 49.94099, mean: 0.10857
[32m[0906 17-59-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03267, current rewards: 55.50482, mean: 0.10883
[32m[0906 17-59-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03276, current rewards: 61.06534, mean: 0.10905
[32m[0906 17-59-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03281, current rewards: 66.62840, mean: 0.10923
[32m[0906 17-59-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03287, current rewards: 72.18986, mean: 0.10938
[32m[0906 17-59-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03294, current rewards: 78.00635, mean: 0.10987
[32m[0906 17-59-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03299, current rewards: 83.57139, mean: 0.10996
[32m[0906 18-00-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03304, current rewards: 89.13732, mean: 0.11005
[32m[0906 18-00-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03307, current rewards: 94.70175, mean: 0.11012
[32m[0906 18-00-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03310, current rewards: 99.30607, mean: 0.10913
[32m[0906 18-00-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03314, current rewards: 104.87197, mean: 0.10924
[32m[0906 18-00-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03317, current rewards: 110.44073, mean: 0.10935
[32m[0906 18-00-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03319, current rewards: 116.00592, mean: 0.10944
[32m[0906 18-00-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03320, current rewards: 122.34025, mean: 0.11022
[32m[0906 18-00-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03321, current rewards: 127.86805, mean: 0.11023
[32m[0906 18-00-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03323, current rewards: 133.43341, mean: 0.11028
[32m[0906 18-00-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03325, current rewards: 138.99304, mean: 0.11031
[32m[0906 18-00-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03328, current rewards: 144.55673, mean: 0.11035
[32m[0906 18-00-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03328, current rewards: 145.99527, mean: 0.10735
[32m[0906 18-00-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03330, current rewards: 151.58289, mean: 0.10751
[32m[0906 18-00-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03331, current rewards: 157.17221, mean: 0.10765
[32m[0906 18-00-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03332, current rewards: 162.75615, mean: 0.10779
[32m[0906 18-00-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03332, current rewards: 168.24591, mean: 0.10785
[32m[0906 18-00-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03333, current rewards: 173.82644, mean: 0.10797
[32m[0906 18-00-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03334, current rewards: 179.40482, mean: 0.10808
[32m[0906 18-00-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03338, current rewards: 184.98527, mean: 0.10818
[32m[0906 18-00-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03340, current rewards: 190.56668, mean: 0.10828
[32m[0906 18-00-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03342, current rewards: 195.02155, mean: 0.10775
[32m[0906 18-00-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03345, current rewards: 200.66355, mean: 0.10788
[32m[0906 18-00-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03348, current rewards: 206.22116, mean: 0.10797
[32m[0906 18-00-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03350, current rewards: 211.87585, mean: 0.10810
[32m[0906 18-00-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03352, current rewards: 217.43639, mean: 0.10818
[32m[0906 18-00-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03354, current rewards: 222.99377, mean: 0.10825
[32m[0906 18-00-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03357, current rewards: 228.55970, mean: 0.10832
[32m[0906 18-00-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03359, current rewards: 234.11648, mean: 0.10839
[32m[0906 18-00-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03361, current rewards: 239.67589, mean: 0.10845
[32m[0906 18-00-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03363, current rewards: 243.39155, mean: 0.10770
[32m[0906 18-00-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03365, current rewards: 248.97761, mean: 0.10778
[32m[0906 18-00-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03366, current rewards: 254.56318, mean: 0.10787
[32m[0906 18-00-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03368, current rewards: 260.15072, mean: 0.10795
[32m[0906 18-00-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03370, current rewards: 265.73511, mean: 0.10802
[32m[0906 18-00-58 @Agent.py:117][0m Average action selection time: 0.0337
[32m[0906 18-00-58 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-00-58 @MBExp.py:227][0m Rewards obtained: [270.2047160860506], Lows: [3], Highs: [3], Total time: 7644.920008999997
[32m[0906 18-03-59 @MBExp.py:144][0m ####################################################################
[32m[0906 18-03-59 @MBExp.py:145][0m Starting training iteration 89.
[32m[0906 18-03-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03214, current rewards: 1.62292, mean: 0.16229
[32m[0906 18-04-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03254, current rewards: 7.20715, mean: 0.12012
[32m[0906 18-04-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03254, current rewards: 12.79330, mean: 0.11630
[32m[0906 18-04-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03265, current rewards: 18.37938, mean: 0.11487
[32m[0906 18-04-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03257, current rewards: 23.96504, mean: 0.11412
[32m[0906 18-04-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03263, current rewards: 30.26756, mean: 0.11641
[32m[0906 18-04-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03260, current rewards: 38.56768, mean: 0.12441
[32m[0906 18-04-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03264, current rewards: 46.86780, mean: 0.13019
[32m[0906 18-04-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03263, current rewards: 20.18784, mean: 0.04924
[32m[0906 18-04-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03262, current rewards: -29.81216, mean: -0.06481
[32m[0906 18-04-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03260, current rewards: -79.81216, mean: -0.15649
[32m[0906 18-04-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03261, current rewards: -78.17383, mean: -0.13960
[32m[0906 18-04-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03262, current rewards: -72.59314, mean: -0.11901
[32m[0906 18-04-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03270, current rewards: -67.05857, mean: -0.10160
[32m[0906 18-04-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03277, current rewards: -61.52264, mean: -0.08665
[32m[0906 18-04-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03283, current rewards: -55.91875, mean: -0.07358
[32m[0906 18-04-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03288, current rewards: -50.31343, mean: -0.06212
[32m[0906 18-04-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03292, current rewards: -44.71007, mean: -0.05199
[32m[0906 18-04-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03295, current rewards: -39.10442, mean: -0.04297
[32m[0906 18-04-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03298, current rewards: -33.50080, mean: -0.03490
[32m[0906 18-04-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03302, current rewards: -30.07752, mean: -0.02978
[32m[0906 18-04-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03306, current rewards: -24.57891, mean: -0.02319
[32m[0906 18-04-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03308, current rewards: -19.14658, mean: -0.01725
[32m[0906 18-04-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03309, current rewards: -13.64033, mean: -0.01176
[32m[0906 18-04-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03310, current rewards: -8.13619, mean: -0.00672
[32m[0906 18-04-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03312, current rewards: -2.62952, mean: -0.00209
[32m[0906 18-04-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03313, current rewards: 2.87651, mean: 0.00220
[32m[0906 18-04-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03314, current rewards: 6.33128, mean: 0.00466
[32m[0906 18-04-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03316, current rewards: 11.85415, mean: 0.00841
[32m[0906 18-04-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03317, current rewards: 17.38155, mean: 0.01191
[32m[0906 18-04-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03318, current rewards: 23.08218, mean: 0.01529
[32m[0906 18-04-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03320, current rewards: 28.78491, mean: 0.01845
[32m[0906 18-04-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03322, current rewards: 34.45989, mean: 0.02140
[32m[0906 18-04-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03323, current rewards: 40.14666, mean: 0.02418
[32m[0906 18-04-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03327, current rewards: 45.81300, mean: 0.02679
[32m[0906 18-04-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03331, current rewards: 49.47007, mean: 0.02811
[32m[0906 18-05-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03334, current rewards: 55.06338, mean: 0.03042
[32m[0906 18-05-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03338, current rewards: 60.65626, mean: 0.03261
[32m[0906 18-05-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03341, current rewards: 66.24743, mean: 0.03468
[32m[0906 18-05-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03343, current rewards: 71.84101, mean: 0.03665
[32m[0906 18-05-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03346, current rewards: 77.43471, mean: 0.03852
[32m[0906 18-05-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03348, current rewards: 83.02668, mean: 0.04030
[32m[0906 18-05-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03351, current rewards: 88.61913, mean: 0.04200
[32m[0906 18-05-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03353, current rewards: 94.21426, mean: 0.04362
[32m[0906 18-05-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03354, current rewards: 99.80905, mean: 0.04516
[32m[0906 18-05-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03356, current rewards: 104.27443, mean: 0.04614
[32m[0906 18-05-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03358, current rewards: 109.85715, mean: 0.04756
[32m[0906 18-05-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03360, current rewards: 115.44825, mean: 0.04892
[32m[0906 18-05-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03363, current rewards: 121.02757, mean: 0.05022
[32m[0906 18-05-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03365, current rewards: 126.60963, mean: 0.05147
[32m[0906 18-05-24 @Agent.py:117][0m Average action selection time: 0.0337
[32m[0906 18-05-24 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-05-24 @MBExp.py:227][0m Rewards obtained: [131.07955809829113], Lows: [3], Highs: [135], Total time: 7729.859437999997
[32m[0906 18-08-27 @MBExp.py:144][0m ####################################################################
[32m[0906 18-08-27 @MBExp.py:145][0m Starting training iteration 90.
[32m[0906 18-08-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03316, current rewards: 0.23631, mean: 0.02363
[32m[0906 18-08-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03264, current rewards: 5.77003, mean: 0.09617
[32m[0906 18-08-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03266, current rewards: 11.30833, mean: 0.10280
[32m[0906 18-08-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03263, current rewards: 16.84598, mean: 0.10529
[32m[0906 18-08-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03258, current rewards: 22.38498, mean: 0.10660
[32m[0906 18-08-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03259, current rewards: 28.17644, mean: 0.10837
[32m[0906 18-08-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03260, current rewards: 33.75310, mean: 0.10888
[32m[0906 18-08-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03260, current rewards: 39.32981, mean: 0.10925
[32m[0906 18-08-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03257, current rewards: 41.53487, mean: 0.10130
[32m[0906 18-08-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03260, current rewards: 47.07115, mean: 0.10233
[32m[0906 18-08-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03259, current rewards: 52.60829, mean: 0.10315
[32m[0906 18-08-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03259, current rewards: 58.14356, mean: 0.10383
[32m[0906 18-08-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03259, current rewards: 63.67933, mean: 0.10439
[32m[0906 18-08-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03265, current rewards: 69.16198, mean: 0.10479
[32m[0906 18-08-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03272, current rewards: 73.64391, mean: 0.10372
[32m[0906 18-08-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03277, current rewards: 79.19964, mean: 0.10421
[32m[0906 18-08-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03281, current rewards: 84.76342, mean: 0.10465
[32m[0906 18-08-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03287, current rewards: 90.32943, mean: 0.10503
[32m[0906 18-08-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03291, current rewards: 93.90813, mean: 0.10320
[32m[0906 18-08-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03296, current rewards: 99.47725, mean: 0.10362
[32m[0906 18-09-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03299, current rewards: 105.04541, mean: 0.10401
[32m[0906 18-09-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03302, current rewards: 110.53850, mean: 0.10428
[32m[0906 18-09-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03304, current rewards: 116.03692, mean: 0.10454
[32m[0906 18-09-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03307, current rewards: 121.60891, mean: 0.10484
[32m[0906 18-09-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03308, current rewards: 127.18677, mean: 0.10511
[32m[0906 18-09-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03311, current rewards: 132.75763, mean: 0.10536
[32m[0906 18-09-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03312, current rewards: 138.32757, mean: 0.10559
[32m[0906 18-09-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03314, current rewards: 143.90216, mean: 0.10581
[32m[0906 18-09-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03317, current rewards: 149.47797, mean: 0.10601
[32m[0906 18-09-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03318, current rewards: 155.05163, mean: 0.10620
[32m[0906 18-09-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03320, current rewards: 160.94526, mean: 0.10659
[32m[0906 18-09-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03320, current rewards: 166.51158, mean: 0.10674
[32m[0906 18-09-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03322, current rewards: 171.01534, mean: 0.10622
[32m[0906 18-09-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03323, current rewards: 176.65703, mean: 0.10642
[32m[0906 18-09-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03327, current rewards: 182.29982, mean: 0.10661
[32m[0906 18-09-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03331, current rewards: 187.94212, mean: 0.10679
[32m[0906 18-09-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03335, current rewards: 193.58109, mean: 0.10695
[32m[0906 18-09-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03338, current rewards: 199.22347, mean: 0.10711
[32m[0906 18-09-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03341, current rewards: 204.76446, mean: 0.10721
[32m[0906 18-09-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03343, current rewards: 210.40316, mean: 0.10735
[32m[0906 18-09-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03346, current rewards: 216.03837, mean: 0.10748
[32m[0906 18-09-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03348, current rewards: 220.60178, mean: 0.10709
[32m[0906 18-09-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03351, current rewards: 226.38348, mean: 0.10729
[32m[0906 18-09-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03353, current rewards: 232.16034, mean: 0.10748
[32m[0906 18-09-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03356, current rewards: 237.94239, mean: 0.10767
[32m[0906 18-09-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03357, current rewards: 241.59327, mean: 0.10690
[32m[0906 18-09-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03359, current rewards: 247.13973, mean: 0.10699
[32m[0906 18-09-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03361, current rewards: 252.70049, mean: 0.10708
[32m[0906 18-09-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03364, current rewards: 258.25861, mean: 0.10716
[32m[0906 18-09-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03365, current rewards: 263.82382, mean: 0.10725
[32m[0906 18-09-52 @Agent.py:117][0m Average action selection time: 0.0337
[32m[0906 18-09-52 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-09-52 @MBExp.py:227][0m Rewards obtained: [268.2763786763856], Lows: [2], Highs: [7], Total time: 7814.779734999996
[32m[0906 18-12-57 @MBExp.py:144][0m ####################################################################
[32m[0906 18-12-57 @MBExp.py:145][0m Starting training iteration 91.
[32m[0906 18-12-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03284, current rewards: 0.90402, mean: 0.09040
[32m[0906 18-12-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03240, current rewards: 6.32003, mean: 0.10533
[32m[0906 18-13-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03255, current rewards: 11.73887, mean: 0.10672
[32m[0906 18-13-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03259, current rewards: 17.15964, mean: 0.10725
[32m[0906 18-13-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03255, current rewards: 22.57986, mean: 0.10752
[32m[0906 18-13-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03256, current rewards: 29.31224, mean: 0.11274
[32m[0906 18-13-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03255, current rewards: 37.85016, mean: 0.12210
[32m[0906 18-13-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03256, current rewards: 40.53428, mean: 0.11260
[32m[0906 18-13-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03257, current rewards: -9.46572, mean: -0.02309
[32m[0906 18-13-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03254, current rewards: -59.46572, mean: -0.12927
[32m[0906 18-13-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03254, current rewards: -109.46572, mean: -0.21464
[32m[0906 18-13-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03252, current rewards: -159.46572, mean: -0.28476
[32m[0906 18-13-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03253, current rewards: -209.46572, mean: -0.34339
[32m[0906 18-13-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03256, current rewards: -259.46572, mean: -0.39313
[32m[0906 18-13-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03254, current rewards: -309.46572, mean: -0.43587
[32m[0906 18-13-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03257, current rewards: -359.46572, mean: -0.47298
[32m[0906 18-13-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03263, current rewards: -409.46572, mean: -0.50551
[32m[0906 18-13-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03270, current rewards: -459.46572, mean: -0.53426
[32m[0906 18-13-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03273, current rewards: -509.46572, mean: -0.55985
[32m[0906 18-13-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03277, current rewards: -559.46572, mean: -0.58278
[32m[0906 18-13-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03281, current rewards: -609.46572, mean: -0.60343
[32m[0906 18-13-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03285, current rewards: -659.46572, mean: -0.62214
[32m[0906 18-13-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03289, current rewards: -709.46572, mean: -0.63916
[32m[0906 18-13-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03292, current rewards: -759.46572, mean: -0.65471
[32m[0906 18-13-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03295, current rewards: -809.46572, mean: -0.66898
[32m[0906 18-13-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03296, current rewards: -859.46572, mean: -0.68212
[32m[0906 18-13-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03297, current rewards: -909.46572, mean: -0.69425
[32m[0906 18-13-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03299, current rewards: -959.46572, mean: -0.70549
[32m[0906 18-13-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03301, current rewards: -1009.46572, mean: -0.71593
[32m[0906 18-13-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03303, current rewards: -1059.46572, mean: -0.72566
[32m[0906 18-13-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03305, current rewards: -1109.46572, mean: -0.73475
[32m[0906 18-13-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03307, current rewards: -1159.46572, mean: -0.74325
[32m[0906 18-13-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03309, current rewards: -1209.46572, mean: -0.75122
[32m[0906 18-13-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03310, current rewards: -1229.07332, mean: -0.74041
[32m[0906 18-13-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03314, current rewards: -1226.67265, mean: -0.71735
[32m[0906 18-13-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03317, current rewards: -1224.27197, mean: -0.69561
[32m[0906 18-13-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03321, current rewards: -1221.87130, mean: -0.67507
[32m[0906 18-13-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03324, current rewards: -1219.47062, mean: -0.65563
[32m[0906 18-14-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03327, current rewards: -1217.06995, mean: -0.63721
[32m[0906 18-14-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03330, current rewards: -1267.06995, mean: -0.64646
[32m[0906 18-14-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03333, current rewards: -1317.06995, mean: -0.65526
[32m[0906 18-14-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03336, current rewards: -1367.06995, mean: -0.66363
[32m[0906 18-14-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03339, current rewards: -1417.06995, mean: -0.67160
[32m[0906 18-14-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03341, current rewards: -1467.06995, mean: -0.67920
[32m[0906 18-14-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03343, current rewards: -1517.06995, mean: -0.68646
[32m[0906 18-14-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03345, current rewards: -1567.06995, mean: -0.69339
[32m[0906 18-14-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03348, current rewards: -1617.06995, mean: -0.70003
[32m[0906 18-14-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03350, current rewards: -1667.06995, mean: -0.70639
[32m[0906 18-14-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03351, current rewards: -1717.06995, mean: -0.71248
[32m[0906 18-14-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03354, current rewards: -1767.06995, mean: -0.71832
[32m[0906 18-14-22 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 18-14-22 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-14-22 @MBExp.py:227][0m Rewards obtained: [-1807.0699471682663], Lows: [0], Highs: [1866], Total time: 7899.396852999997
[32m[0906 18-17-28 @MBExp.py:144][0m ####################################################################
[32m[0906 18-17-28 @MBExp.py:145][0m Starting training iteration 92.
[32m[0906 18-17-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03231, current rewards: 1.07238, mean: 0.10724
[32m[0906 18-17-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03242, current rewards: 6.67122, mean: 0.11119
[32m[0906 18-17-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03255, current rewards: 12.27075, mean: 0.11155
[32m[0906 18-17-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03250, current rewards: 17.87094, mean: 0.11169
[32m[0906 18-17-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03252, current rewards: 23.47084, mean: 0.11177
[32m[0906 18-17-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03251, current rewards: 28.83213, mean: 0.11089
[32m[0906 18-17-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03255, current rewards: 34.40569, mean: 0.11099
[32m[0906 18-17-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03259, current rewards: 39.98184, mean: 0.11106
[32m[0906 18-17-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03255, current rewards: 45.55826, mean: 0.11112
[32m[0906 18-17-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03260, current rewards: 51.13527, mean: 0.11116
[32m[0906 18-17-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03263, current rewards: 56.70702, mean: 0.11119
[32m[0906 18-17-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03262, current rewards: 62.28200, mean: 0.11122
[32m[0906 18-17-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03263, current rewards: 67.85427, mean: 0.11124
[32m[0906 18-17-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03263, current rewards: 73.46430, mean: 0.11131
[32m[0906 18-17-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03264, current rewards: 79.24631, mean: 0.11161
[32m[0906 18-17-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03265, current rewards: 83.65696, mean: 0.11007
[32m[0906 18-17-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03271, current rewards: 89.21849, mean: 0.11015
[32m[0906 18-17-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03276, current rewards: 94.78032, mean: 0.11021
[32m[0906 18-17-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03281, current rewards: 100.33699, mean: 0.11026
[32m[0906 18-18-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03287, current rewards: 105.89933, mean: 0.11031
[32m[0906 18-18-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03291, current rewards: 110.35333, mean: 0.10926
[32m[0906 18-18-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03294, current rewards: 115.92350, mean: 0.10936
[32m[0906 18-18-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03296, current rewards: 121.44997, mean: 0.10941
[32m[0906 18-18-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03299, current rewards: 127.00975, mean: 0.10949
[32m[0906 18-18-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03301, current rewards: 132.57578, mean: 0.10957
[32m[0906 18-18-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03304, current rewards: 138.13244, mean: 0.10963
[32m[0906 18-18-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03306, current rewards: 143.70041, mean: 0.10969
[32m[0906 18-18-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03307, current rewards: 149.26597, mean: 0.10975
[32m[0906 18-18-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03309, current rewards: 154.83253, mean: 0.10981
[32m[0906 18-18-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03311, current rewards: 160.39975, mean: 0.10986
[32m[0906 18-18-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03313, current rewards: 163.79334, mean: 0.10847
[32m[0906 18-18-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03315, current rewards: 169.40188, mean: 0.10859
[32m[0906 18-18-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03317, current rewards: 175.00621, mean: 0.10870
[32m[0906 18-18-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03318, current rewards: 180.62162, mean: 0.10881
[32m[0906 18-18-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03321, current rewards: 186.23177, mean: 0.10891
[32m[0906 18-18-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03325, current rewards: 191.84084, mean: 0.10900
[32m[0906 18-18-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03329, current rewards: 197.44821, mean: 0.10909
[32m[0906 18-18-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03331, current rewards: 203.05139, mean: 0.10917
[32m[0906 18-18-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03334, current rewards: 206.51620, mean: 0.10812
[32m[0906 18-18-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03337, current rewards: 212.05505, mean: 0.10819
[32m[0906 18-18-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03340, current rewards: 217.60599, mean: 0.10826
[32m[0906 18-18-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03343, current rewards: 223.15164, mean: 0.10833
[32m[0906 18-18-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03344, current rewards: 228.69428, mean: 0.10839
[32m[0906 18-18-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03347, current rewards: 234.23423, mean: 0.10844
[32m[0906 18-18-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03350, current rewards: 239.77727, mean: 0.10850
[32m[0906 18-18-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03352, current rewards: 245.31826, mean: 0.10855
[32m[0906 18-18-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03354, current rewards: 251.00011, mean: 0.10866
[32m[0906 18-18-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03356, current rewards: 256.65062, mean: 0.10875
[32m[0906 18-18-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03358, current rewards: 262.28437, mean: 0.10883
[32m[0906 18-18-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03360, current rewards: 267.92653, mean: 0.10891
[32m[0906 18-18-53 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 18-18-53 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-18-53 @MBExp.py:227][0m Rewards obtained: [270.2546809335143], Lows: [2], Highs: [4], Total time: 7984.181251999997
[32m[0906 18-22-02 @MBExp.py:144][0m ####################################################################
[32m[0906 18-22-02 @MBExp.py:145][0m Starting training iteration 93.
[32m[0906 18-22-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03219, current rewards: -0.94394, mean: -0.09439
[32m[0906 18-22-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03236, current rewards: 4.65372, mean: 0.07756
[32m[0906 18-22-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03235, current rewards: 10.18353, mean: 0.09258
[32m[0906 18-22-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03245, current rewards: 15.70442, mean: 0.09815
[32m[0906 18-22-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03244, current rewards: 21.22189, mean: 0.10106
[32m[0906 18-22-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03248, current rewards: 26.77039, mean: 0.10296
[32m[0906 18-22-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03247, current rewards: 32.30032, mean: 0.10419
[32m[0906 18-22-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03248, current rewards: 37.82497, mean: 0.10507
[32m[0906 18-22-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03245, current rewards: 41.19420, mean: 0.10047
[32m[0906 18-22-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03248, current rewards: 46.72511, mean: 0.10158
[32m[0906 18-22-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03253, current rewards: 52.25272, mean: 0.10246
[32m[0906 18-22-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03252, current rewards: 57.78244, mean: 0.10318
[32m[0906 18-22-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03253, current rewards: 63.31347, mean: 0.10379
[32m[0906 18-22-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03253, current rewards: 68.73630, mean: 0.10415
[32m[0906 18-22-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03253, current rewards: 74.26500, mean: 0.10460
[32m[0906 18-22-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03254, current rewards: 79.79904, mean: 0.10500
[32m[0906 18-22-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03261, current rewards: 83.01766, mean: 0.10249
[32m[0906 18-22-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03267, current rewards: 88.36128, mean: 0.10275
[32m[0906 18-22-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03272, current rewards: 93.70201, mean: 0.10297
[32m[0906 18-22-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03276, current rewards: 99.04657, mean: 0.10317
[32m[0906 18-22-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03281, current rewards: 104.38969, mean: 0.10336
[32m[0906 18-22-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03284, current rewards: 109.76877, mean: 0.10356
[32m[0906 18-22-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03286, current rewards: 115.09814, mean: 0.10369
[32m[0906 18-22-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03289, current rewards: 120.42866, mean: 0.10382
[32m[0906 18-22-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03291, current rewards: 125.75566, mean: 0.10393
[32m[0906 18-22-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03292, current rewards: 131.08572, mean: 0.10404
[32m[0906 18-22-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03295, current rewards: 136.41422, mean: 0.10413
[32m[0906 18-22-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03298, current rewards: 141.74469, mean: 0.10422
[32m[0906 18-22-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03300, current rewards: 147.07226, mean: 0.10431
[32m[0906 18-22-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03303, current rewards: 152.34880, mean: 0.10435
[32m[0906 18-22-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03304, current rewards: 155.87149, mean: 0.10323
[32m[0906 18-22-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03306, current rewards: 161.25941, mean: 0.10337
[32m[0906 18-22-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03307, current rewards: 166.64855, mean: 0.10351
[32m[0906 18-22-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03309, current rewards: 172.03551, mean: 0.10364
[32m[0906 18-22-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03312, current rewards: 177.42574, mean: 0.10376
[32m[0906 18-23-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03315, current rewards: 182.80675, mean: 0.10387
[32m[0906 18-23-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03319, current rewards: 188.19567, mean: 0.10398
[32m[0906 18-23-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03322, current rewards: 193.67850, mean: 0.10413
[32m[0906 18-23-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03326, current rewards: 199.25858, mean: 0.10432
[32m[0906 18-23-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03329, current rewards: 202.46984, mean: 0.10330
[32m[0906 18-23-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03332, current rewards: 207.96334, mean: 0.10346
[32m[0906 18-23-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03335, current rewards: 213.49041, mean: 0.10364
[32m[0906 18-23-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03338, current rewards: 219.01636, mean: 0.10380
[32m[0906 18-23-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03340, current rewards: 223.37883, mean: 0.10342
[32m[0906 18-23-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03342, current rewards: 228.78684, mean: 0.10352
[32m[0906 18-23-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03344, current rewards: 234.19128, mean: 0.10362
[32m[0906 18-23-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03347, current rewards: 239.39593, mean: 0.10363
[32m[0906 18-23-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03349, current rewards: 244.75777, mean: 0.10371
[32m[0906 18-23-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03351, current rewards: 250.13060, mean: 0.10379
[32m[0906 18-23-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03353, current rewards: 255.48959, mean: 0.10386
[32m[0906 18-23-26 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 18-23-26 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-23-26 @MBExp.py:227][0m Rewards obtained: [259.7833948619024], Lows: [3], Highs: [5], Total time: 8068.815483999997
[32m[0906 18-26-37 @MBExp.py:144][0m ####################################################################
[32m[0906 18-26-37 @MBExp.py:145][0m Starting training iteration 94.
[32m[0906 18-26-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03252, current rewards: -0.92811, mean: -0.09281
[32m[0906 18-26-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03209, current rewards: 5.38806, mean: 0.08980
[32m[0906 18-26-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03207, current rewards: 11.61404, mean: 0.10558
[32m[0906 18-26-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03218, current rewards: 17.83824, mean: 0.11149
[32m[0906 18-26-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03224, current rewards: 24.06312, mean: 0.11459
[32m[0906 18-26-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03227, current rewards: 30.09511, mean: 0.11575
[32m[0906 18-26-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03230, current rewards: 36.23593, mean: 0.11689
[32m[0906 18-26-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03230, current rewards: 40.94796, mean: 0.11374
[32m[0906 18-26-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03232, current rewards: 46.51004, mean: 0.11344
[32m[0906 18-26-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03232, current rewards: 52.07287, mean: 0.11320
[32m[0906 18-26-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03232, current rewards: 57.63317, mean: 0.11301
[32m[0906 18-26-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03232, current rewards: 63.19272, mean: 0.11284
[32m[0906 18-26-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03235, current rewards: 68.75489, mean: 0.11271
[32m[0906 18-26-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03236, current rewards: 74.50978, mean: 0.11289
[32m[0906 18-27-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03236, current rewards: 80.09432, mean: 0.11281
[32m[0906 18-27-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03236, current rewards: 85.68450, mean: 0.11274
[32m[0906 18-27-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03243, current rewards: 91.27113, mean: 0.11268
[32m[0906 18-27-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03249, current rewards: 96.85777, mean: 0.11263
[32m[0906 18-27-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03256, current rewards: 102.44452, mean: 0.11258
[32m[0906 18-27-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03260, current rewards: 108.03221, mean: 0.11253
[32m[0906 18-27-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03264, current rewards: 110.31340, mean: 0.10922
[32m[0906 18-27-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03269, current rewards: 115.75909, mean: 0.10921
[32m[0906 18-27-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03272, current rewards: 121.27683, mean: 0.10926
[32m[0906 18-27-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03276, current rewards: 126.79310, mean: 0.10930
[32m[0906 18-27-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03278, current rewards: 132.31729, mean: 0.10935
[32m[0906 18-27-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03281, current rewards: 137.83330, mean: 0.10939
[32m[0906 18-27-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03284, current rewards: 143.35436, mean: 0.10943
[32m[0906 18-27-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03287, current rewards: 148.87118, mean: 0.10946
[32m[0906 18-27-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03289, current rewards: 154.38999, mean: 0.10950
[32m[0906 18-27-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03291, current rewards: 159.97767, mean: 0.10957
[32m[0906 18-27-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03293, current rewards: 161.26317, mean: 0.10680
[32m[0906 18-27-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03295, current rewards: 166.81198, mean: 0.10693
[32m[0906 18-27-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03297, current rewards: 172.36133, mean: 0.10706
[32m[0906 18-27-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03299, current rewards: 177.90778, mean: 0.10717
[32m[0906 18-27-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03302, current rewards: 183.45192, mean: 0.10728
[32m[0906 18-27-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03306, current rewards: 188.99961, mean: 0.10739
[32m[0906 18-27-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03309, current rewards: 192.27865, mean: 0.10623
[32m[0906 18-27-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03313, current rewards: 197.85116, mean: 0.10637
[32m[0906 18-27-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03316, current rewards: 203.56120, mean: 0.10658
[32m[0906 18-27-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03319, current rewards: 209.15002, mean: 0.10671
[32m[0906 18-27-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03322, current rewards: 214.73467, mean: 0.10683
[32m[0906 18-27-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03325, current rewards: 220.32449, mean: 0.10695
[32m[0906 18-27-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03327, current rewards: 225.91786, mean: 0.10707
[32m[0906 18-27-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03330, current rewards: 231.50405, mean: 0.10718
[32m[0906 18-27-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03332, current rewards: 237.09628, mean: 0.10728
[32m[0906 18-27-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03334, current rewards: 242.63796, mean: 0.10736
[32m[0906 18-27-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03336, current rewards: 248.12455, mean: 0.10741
[32m[0906 18-27-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03338, current rewards: 253.66558, mean: 0.10749
[32m[0906 18-27-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03340, current rewards: 259.21081, mean: 0.10756
[32m[0906 18-28-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03342, current rewards: 264.75222, mean: 0.10762
[32m[0906 18-28-02 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 18-28-02 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-28-02 @MBExp.py:227][0m Rewards obtained: [269.1828997451131], Lows: [3], Highs: [6], Total time: 8153.163185999997
[32m[0906 18-31-14 @MBExp.py:144][0m ####################################################################
[32m[0906 18-31-14 @MBExp.py:145][0m Starting training iteration 95.
[32m[0906 18-31-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03189, current rewards: 0.00954, mean: 0.00095
[32m[0906 18-31-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03224, current rewards: 5.72215, mean: 0.09537
[32m[0906 18-31-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03230, current rewards: 11.35994, mean: 0.10327
[32m[0906 18-31-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03232, current rewards: 16.99444, mean: 0.10622
[32m[0906 18-31-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03234, current rewards: 22.53592, mean: 0.10731
[32m[0906 18-31-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03238, current rewards: 28.16114, mean: 0.10831
[32m[0906 18-31-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03240, current rewards: 33.78894, mean: 0.10900
[32m[0906 18-31-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03245, current rewards: 39.42176, mean: 0.10950
[32m[0906 18-31-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03246, current rewards: 44.93621, mean: 0.10960
[32m[0906 18-31-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03246, current rewards: 50.45292, mean: 0.10968
[32m[0906 18-31-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03247, current rewards: 55.97644, mean: 0.10976
[32m[0906 18-31-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03247, current rewards: 61.49802, mean: 0.10982
[32m[0906 18-31-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03250, current rewards: 66.98950, mean: 0.10982
[32m[0906 18-31-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03249, current rewards: 70.35384, mean: 0.10660
[32m[0906 18-31-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03250, current rewards: 75.92907, mean: 0.10694
[32m[0906 18-31-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03249, current rewards: 81.50554, mean: 0.10724
[32m[0906 18-31-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03254, current rewards: 87.08448, mean: 0.10751
[32m[0906 18-31-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03260, current rewards: 92.66513, mean: 0.10775
[32m[0906 18-31-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03266, current rewards: 98.24490, mean: 0.10796
[32m[0906 18-31-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03271, current rewards: 103.82467, mean: 0.10815
[32m[0906 18-31-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03276, current rewards: 109.40272, mean: 0.10832
[32m[0906 18-31-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03281, current rewards: 115.02686, mean: 0.10852
[32m[0906 18-31-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03284, current rewards: 120.61138, mean: 0.10866
[32m[0906 18-31-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03286, current rewards: 126.19520, mean: 0.10879
[32m[0906 18-31-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03289, current rewards: 131.77841, mean: 0.10891
[32m[0906 18-31-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03290, current rewards: 137.36304, mean: 0.10902
[32m[0906 18-31-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03292, current rewards: 141.92747, mean: 0.10834
[32m[0906 18-31-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03294, current rewards: 147.43370, mean: 0.10841
[32m[0906 18-32-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03296, current rewards: 152.94224, mean: 0.10847
[32m[0906 18-32-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03298, current rewards: 158.53470, mean: 0.10859
[32m[0906 18-32-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03300, current rewards: 164.03461, mean: 0.10863
[32m[0906 18-32-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03302, current rewards: 169.53148, mean: 0.10867
[32m[0906 18-32-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03303, current rewards: 175.02878, mean: 0.10871
[32m[0906 18-32-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03304, current rewards: 180.52472, mean: 0.10875
[32m[0906 18-32-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03305, current rewards: 181.91780, mean: 0.10638
[32m[0906 18-32-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03307, current rewards: 187.50566, mean: 0.10654
[32m[0906 18-32-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03307, current rewards: 193.09238, mean: 0.10668
[32m[0906 18-32-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03312, current rewards: 198.52436, mean: 0.10673
[32m[0906 18-32-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03315, current rewards: 204.09556, mean: 0.10686
[32m[0906 18-32-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03318, current rewards: 209.66392, mean: 0.10697
[32m[0906 18-32-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03322, current rewards: 215.23800, mean: 0.10708
[32m[0906 18-32-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03325, current rewards: 220.81093, mean: 0.10719
[32m[0906 18-32-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03327, current rewards: 226.37856, mean: 0.10729
[32m[0906 18-32-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03329, current rewards: 231.94524, mean: 0.10738
[32m[0906 18-32-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03332, current rewards: 237.51375, mean: 0.10747
[32m[0906 18-32-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03334, current rewards: 243.16825, mean: 0.10760
[32m[0906 18-32-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03336, current rewards: 250.44758, mean: 0.10842
[32m[0906 18-32-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03338, current rewards: 228.18766, mean: 0.09669
[32m[0906 18-32-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03340, current rewards: 233.76375, mean: 0.09700
[32m[0906 18-32-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03342, current rewards: 239.33632, mean: 0.09729
[32m[0906 18-32-38 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 18-32-38 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-32-39 @MBExp.py:227][0m Rewards obtained: [243.80216440040766], Lows: [3], Highs: [27], Total time: 8237.509470999998
[32m[0906 18-35-53 @MBExp.py:144][0m ####################################################################
[32m[0906 18-35-53 @MBExp.py:145][0m Starting training iteration 96.
[32m[0906 18-35-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03304, current rewards: -1.25378, mean: -0.12538
[32m[0906 18-35-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03242, current rewards: 4.18635, mean: 0.06977
[32m[0906 18-35-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03240, current rewards: 9.60045, mean: 0.08728
[32m[0906 18-35-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03238, current rewards: 15.01908, mean: 0.09387
[32m[0906 18-36-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03241, current rewards: 20.43045, mean: 0.09729
[32m[0906 18-36-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03249, current rewards: 25.85248, mean: 0.09943
[32m[0906 18-36-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03252, current rewards: 31.26890, mean: 0.10087
[32m[0906 18-36-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03258, current rewards: 36.68582, mean: 0.10191
[32m[0906 18-36-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03260, current rewards: 42.10095, mean: 0.10269
[32m[0906 18-36-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03258, current rewards: 47.51741, mean: 0.10330
[32m[0906 18-36-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03261, current rewards: 52.93012, mean: 0.10378
[32m[0906 18-36-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03259, current rewards: 58.34796, mean: 0.10419
[32m[0906 18-36-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03259, current rewards: 63.84826, mean: 0.10467
[32m[0906 18-36-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03255, current rewards: 68.56701, mean: 0.10389
[32m[0906 18-36-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03256, current rewards: 74.24158, mean: 0.10457
[32m[0906 18-36-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03257, current rewards: 79.91049, mean: 0.10515
[32m[0906 18-36-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03262, current rewards: 85.58383, mean: 0.10566
[32m[0906 18-36-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03269, current rewards: 86.78462, mean: 0.10091
[32m[0906 18-36-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03273, current rewards: 92.26236, mean: 0.10139
[32m[0906 18-36-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03278, current rewards: 97.74056, mean: 0.10181
[32m[0906 18-36-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03282, current rewards: 103.33229, mean: 0.10231
[32m[0906 18-36-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03286, current rewards: 108.76570, mean: 0.10261
[32m[0906 18-36-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03289, current rewards: 114.20528, mean: 0.10289
[32m[0906 18-36-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03291, current rewards: 119.64297, mean: 0.10314
[32m[0906 18-36-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03294, current rewards: 123.95630, mean: 0.10244
[32m[0906 18-36-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03295, current rewards: 129.48766, mean: 0.10277
[32m[0906 18-36-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03297, current rewards: 135.01375, mean: 0.10306
[32m[0906 18-36-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03299, current rewards: 140.54575, mean: 0.10334
[32m[0906 18-36-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03301, current rewards: 146.01726, mean: 0.10356
[32m[0906 18-36-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03303, current rewards: 151.40068, mean: 0.10370
[32m[0906 18-36-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03305, current rewards: 155.97469, mean: 0.10329
[32m[0906 18-36-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03306, current rewards: 161.59821, mean: 0.10359
[32m[0906 18-36-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03308, current rewards: 167.22757, mean: 0.10387
[32m[0906 18-36-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03310, current rewards: 172.85267, mean: 0.10413
[32m[0906 18-36-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03311, current rewards: 178.48231, mean: 0.10438
[32m[0906 18-36-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03313, current rewards: 182.14461, mean: 0.10349
[32m[0906 18-36-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03315, current rewards: 187.89515, mean: 0.10381
[32m[0906 18-36-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03317, current rewards: 193.73634, mean: 0.10416
[32m[0906 18-36-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03321, current rewards: 199.54255, mean: 0.10447
[32m[0906 18-36-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03324, current rewards: 205.34736, mean: 0.10477
[32m[0906 18-37-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03327, current rewards: 211.14891, mean: 0.10505
[32m[0906 18-37-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03330, current rewards: 216.95200, mean: 0.10532
[32m[0906 18-37-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03333, current rewards: 222.75377, mean: 0.10557
[32m[0906 18-37-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03336, current rewards: 228.55609, mean: 0.10581
[32m[0906 18-37-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03338, current rewards: 234.36119, mean: 0.10605
[32m[0906 18-37-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03341, current rewards: 238.86345, mean: 0.10569
[32m[0906 18-37-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03343, current rewards: 244.21883, mean: 0.10572
[32m[0906 18-37-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03345, current rewards: 249.57718, mean: 0.10575
[32m[0906 18-37-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03348, current rewards: 254.93442, mean: 0.10578
[32m[0906 18-37-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03349, current rewards: 260.29235, mean: 0.10581
[32m[0906 18-37-18 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 18-37-18 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-37-18 @MBExp.py:227][0m Rewards obtained: [264.5778101824142], Lows: [3], Highs: [6], Total time: 8322.050095999997
[32m[0906 18-40-34 @MBExp.py:144][0m ####################################################################
[32m[0906 18-40-34 @MBExp.py:145][0m Starting training iteration 97.
[32m[0906 18-40-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03246, current rewards: 1.10364, mean: 0.11036
[32m[0906 18-40-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03233, current rewards: 7.02151, mean: 0.11703
[32m[0906 18-40-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03240, current rewards: 12.93939, mean: 0.11763
[32m[0906 18-40-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03239, current rewards: 18.85726, mean: 0.11786
[32m[0906 18-40-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03246, current rewards: 24.77514, mean: 0.11798
[32m[0906 18-40-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03247, current rewards: 30.69301, mean: 0.11805
[32m[0906 18-40-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03249, current rewards: 14.24374, mean: 0.04595
[32m[0906 18-40-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03249, current rewards: -35.75626, mean: -0.09932
[32m[0906 18-40-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03248, current rewards: -85.75626, mean: -0.20916
[32m[0906 18-40-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03252, current rewards: -135.75626, mean: -0.29512
[32m[0906 18-40-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03253, current rewards: -185.75626, mean: -0.36423
[32m[0906 18-40-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03254, current rewards: -235.75626, mean: -0.42099
[32m[0906 18-40-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03254, current rewards: -238.82887, mean: -0.39152
[32m[0906 18-40-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03253, current rewards: -232.62496, mean: -0.35246
[32m[0906 18-40-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03254, current rewards: -226.40839, mean: -0.31889
[32m[0906 18-40-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03253, current rewards: -220.21891, mean: -0.28976
[32m[0906 18-41-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03258, current rewards: -214.03827, mean: -0.26424
[32m[0906 18-41-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03262, current rewards: -209.00948, mean: -0.24303
[32m[0906 18-41-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03266, current rewards: -203.55985, mean: -0.22369
[32m[0906 18-41-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03271, current rewards: -198.11360, mean: -0.20637
[32m[0906 18-41-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03275, current rewards: -192.64249, mean: -0.19074
[32m[0906 18-41-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03280, current rewards: -187.21641, mean: -0.17662
[32m[0906 18-41-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03283, current rewards: -181.79322, mean: -0.16378
[32m[0906 18-41-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03285, current rewards: -176.37147, mean: -0.15204
[32m[0906 18-41-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03288, current rewards: -170.94874, mean: -0.14128
[32m[0906 18-41-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03291, current rewards: -165.52819, mean: -0.13137
[32m[0906 18-41-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03293, current rewards: -160.09734, mean: -0.12221
[32m[0906 18-41-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03295, current rewards: -156.85992, mean: -0.11534
[32m[0906 18-41-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03297, current rewards: -151.41535, mean: -0.10739
[32m[0906 18-41-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03298, current rewards: -145.97137, mean: -0.09998
[32m[0906 18-41-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03301, current rewards: -140.52794, mean: -0.09306
[32m[0906 18-41-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03302, current rewards: -135.08481, mean: -0.08659
[32m[0906 18-41-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03304, current rewards: -129.64315, mean: -0.08052
[32m[0906 18-41-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03305, current rewards: -124.21132, mean: -0.07483
[32m[0906 18-41-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03307, current rewards: -118.76920, mean: -0.06946
[32m[0906 18-41-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03308, current rewards: -113.33055, mean: -0.06439
[32m[0906 18-41-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03309, current rewards: -107.82566, mean: -0.05957
[32m[0906 18-41-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03312, current rewards: -102.45745, mean: -0.05508
[32m[0906 18-41-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03315, current rewards: -97.09368, mean: -0.05083
[32m[0906 18-41-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03319, current rewards: -91.72680, mean: -0.04680
[32m[0906 18-41-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03322, current rewards: -86.36226, mean: -0.04297
[32m[0906 18-41-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03325, current rewards: -83.09249, mean: -0.04034
[32m[0906 18-41-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03328, current rewards: -77.68549, mean: -0.03682
[32m[0906 18-41-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03331, current rewards: -72.28097, mean: -0.03346
[32m[0906 18-41-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03333, current rewards: -67.03150, mean: -0.03033
[32m[0906 18-41-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03335, current rewards: -61.67796, mean: -0.02729
[32m[0906 18-41-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03338, current rewards: -59.47259, mean: -0.02575
[32m[0906 18-41-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03339, current rewards: -53.95968, mean: -0.02286
[32m[0906 18-41-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03341, current rewards: -48.44503, mean: -0.02010
[32m[0906 18-41-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03343, current rewards: -42.93344, mean: -0.01745
[32m[0906 18-41-58 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 18-41-58 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-41-59 @MBExp.py:227][0m Rewards obtained: [-38.52667299783673], Lows: [3], Highs: [280], Total time: 8406.420783999998
[32m[0906 18-45-17 @MBExp.py:144][0m ####################################################################
[32m[0906 18-45-17 @MBExp.py:145][0m Starting training iteration 98.
[32m[0906 18-45-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03209, current rewards: 0.06704, mean: 0.00670
[32m[0906 18-45-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03232, current rewards: 5.65091, mean: 0.09418
[32m[0906 18-45-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03245, current rewards: 11.20613, mean: 0.10187
[32m[0906 18-45-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03251, current rewards: 16.66676, mean: 0.10417
[32m[0906 18-45-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03249, current rewards: 22.15728, mean: 0.10551
[32m[0906 18-45-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03250, current rewards: 27.65017, mean: 0.10635
[32m[0906 18-45-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03250, current rewards: 33.13409, mean: 0.10688
[32m[0906 18-45-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03253, current rewards: 38.62228, mean: 0.10728
[32m[0906 18-45-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03250, current rewards: 44.11506, mean: 0.10760
[32m[0906 18-45-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03247, current rewards: 47.47849, mean: 0.10321
[32m[0906 18-45-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03248, current rewards: 53.05004, mean: 0.10402
[32m[0906 18-45-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03249, current rewards: 58.66687, mean: 0.10476
[32m[0906 18-45-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03250, current rewards: 64.24346, mean: 0.10532
[32m[0906 18-45-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03250, current rewards: 69.82180, mean: 0.10579
[32m[0906 18-45-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03250, current rewards: 75.39617, mean: 0.10619
[32m[0906 18-45-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03250, current rewards: 80.97354, mean: 0.10654
[32m[0906 18-45-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03254, current rewards: 85.43937, mean: 0.10548
[32m[0906 18-45-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03260, current rewards: 91.05112, mean: 0.10587
[32m[0906 18-45-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03265, current rewards: 96.66839, mean: 0.10623
[32m[0906 18-45-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03271, current rewards: 102.34517, mean: 0.10661
[32m[0906 18-45-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03275, current rewards: 107.99339, mean: 0.10692
[32m[0906 18-45-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03278, current rewards: 113.63576, mean: 0.10720
[32m[0906 18-45-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03281, current rewards: 119.28448, mean: 0.10746
[32m[0906 18-45-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03286, current rewards: 120.84848, mean: 0.10418
[32m[0906 18-45-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03289, current rewards: 126.52554, mean: 0.10457
[32m[0906 18-45-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03291, current rewards: 132.20261, mean: 0.10492
[32m[0906 18-46-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03292, current rewards: 137.87968, mean: 0.10525
[32m[0906 18-46-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03295, current rewards: 142.76603, mean: 0.10498
[32m[0906 18-46-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03297, current rewards: 92.76603, mean: 0.06579
[32m[0906 18-46-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03299, current rewards: 42.76603, mean: 0.02929
[32m[0906 18-46-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03301, current rewards: -7.23397, mean: -0.00479
[32m[0906 18-46-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03303, current rewards: -57.23397, mean: -0.03669
[32m[0906 18-46-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03304, current rewards: -107.23397, mean: -0.06660
[32m[0906 18-46-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03306, current rewards: -157.23397, mean: -0.09472
[32m[0906 18-46-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03308, current rewards: -207.23397, mean: -0.12119
[32m[0906 18-46-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03309, current rewards: -257.23397, mean: -0.14616
[32m[0906 18-46-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03311, current rewards: -307.23397, mean: -0.16974
[32m[0906 18-46-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03312, current rewards: -357.23397, mean: -0.19206
[32m[0906 18-46-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03315, current rewards: -407.23397, mean: -0.21321
[32m[0906 18-46-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03319, current rewards: -457.23397, mean: -0.23328
[32m[0906 18-46-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03322, current rewards: -506.18362, mean: -0.25183
[32m[0906 18-46-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03324, current rewards: -500.59268, mean: -0.24301
[32m[0906 18-46-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03327, current rewards: -495.00762, mean: -0.23460
[32m[0906 18-46-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03330, current rewards: -489.42074, mean: -0.22658
[32m[0906 18-46-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03333, current rewards: -483.92263, mean: -0.21897
[32m[0906 18-46-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03335, current rewards: -478.39673, mean: -0.21168
[32m[0906 18-46-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03337, current rewards: -472.81161, mean: -0.20468
[32m[0906 18-46-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03339, current rewards: -467.22705, mean: -0.19798
[32m[0906 18-46-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03341, current rewards: -461.64356, mean: -0.19155
[32m[0906 18-46-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03344, current rewards: -456.05577, mean: -0.18539
[32m[0906 18-46-41 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 18-46-41 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-46-41 @MBExp.py:227][0m Rewards obtained: [-451.5854943369513], Lows: [3], Highs: [651], Total time: 8490.822427999998
[32m[0906 18-50-01 @MBExp.py:144][0m ####################################################################
[32m[0906 18-50-01 @MBExp.py:145][0m Starting training iteration 99.
[32m[0906 18-50-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03240, current rewards: -1.13468, mean: -0.11347
[32m[0906 18-50-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03246, current rewards: 4.47719, mean: 0.07462
[32m[0906 18-50-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03241, current rewards: 10.04669, mean: 0.09133
[32m[0906 18-50-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03240, current rewards: 15.51438, mean: 0.09696
[32m[0906 18-50-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03248, current rewards: 21.06673, mean: 0.10032
[32m[0906 18-50-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03253, current rewards: 26.61766, mean: 0.10238
[32m[0906 18-50-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03255, current rewards: 32.16803, mean: 0.10377
[32m[0906 18-50-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03254, current rewards: 37.71723, mean: 0.10477
[32m[0906 18-50-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03258, current rewards: 43.26564, mean: 0.10553
[32m[0906 18-50-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03260, current rewards: 48.81716, mean: 0.10612
[32m[0906 18-50-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03261, current rewards: 51.07167, mean: 0.10014
[32m[0906 18-50-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03262, current rewards: 56.51751, mean: 0.10092
[32m[0906 18-50-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03265, current rewards: 62.11042, mean: 0.10182
[32m[0906 18-50-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03263, current rewards: 67.70260, mean: 0.10258
[32m[0906 18-50-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03261, current rewards: 73.29448, mean: 0.10323
[32m[0906 18-50-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03261, current rewards: 78.89259, mean: 0.10381
[32m[0906 18-50-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03259, current rewards: 84.49217, mean: 0.10431
[32m[0906 18-50-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03262, current rewards: 90.09196, mean: 0.10476
[32m[0906 18-50-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03266, current rewards: 95.68627, mean: 0.10515
[32m[0906 18-50-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03270, current rewards: 101.32609, mean: 0.10555
[32m[0906 18-50-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03274, current rewards: 104.96421, mean: 0.10392
[32m[0906 18-50-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03278, current rewards: 110.47041, mean: 0.10422
[32m[0906 18-50-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03280, current rewards: 116.04482, mean: 0.10454
[32m[0906 18-50-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03284, current rewards: 121.62373, mean: 0.10485
[32m[0906 18-50-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03287, current rewards: 127.20214, mean: 0.10513
[32m[0906 18-50-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03290, current rewards: 132.77936, mean: 0.10538
[32m[0906 18-50-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03293, current rewards: 136.26066, mean: 0.10402
[32m[0906 18-50-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03294, current rewards: 141.54358, mean: 0.10408
[32m[0906 18-50-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03297, current rewards: 146.82504, mean: 0.10413
[32m[0906 18-50-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03299, current rewards: 152.10385, mean: 0.10418
[32m[0906 18-50-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03302, current rewards: 157.38609, mean: 0.10423
[32m[0906 18-50-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03303, current rewards: 162.66695, mean: 0.10427
[32m[0906 18-50-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03306, current rewards: 167.94800, mean: 0.10432
[32m[0906 18-50-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03307, current rewards: 173.22949, mean: 0.10436
[32m[0906 18-50-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03309, current rewards: 178.51218, mean: 0.10439
[32m[0906 18-51-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03311, current rewards: 183.78917, mean: 0.10443
[32m[0906 18-51-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03312, current rewards: 189.06928, mean: 0.10446
[32m[0906 18-51-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03314, current rewards: 192.18833, mean: 0.10333
[32m[0906 18-51-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03316, current rewards: 197.76007, mean: 0.10354
[32m[0906 18-51-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03320, current rewards: 203.34119, mean: 0.10375
[32m[0906 18-51-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03322, current rewards: 208.92251, mean: 0.10394
[32m[0906 18-51-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03325, current rewards: 214.50426, mean: 0.10413
[32m[0906 18-51-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03328, current rewards: 220.07853, mean: 0.10430
[32m[0906 18-51-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03331, current rewards: 225.65519, mean: 0.10447
[32m[0906 18-51-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03333, current rewards: 231.11312, mean: 0.10458
[32m[0906 18-51-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03337, current rewards: 233.36797, mean: 0.10326
[32m[0906 18-51-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03338, current rewards: 238.93770, mean: 0.10344
[32m[0906 18-51-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03341, current rewards: 244.51267, mean: 0.10361
[32m[0906 18-51-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03343, current rewards: 250.08091, mean: 0.10377
[32m[0906 18-51-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03345, current rewards: 255.65681, mean: 0.10393
[32m[0906 18-51-25 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 18-51-25 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-51-26 @MBExp.py:227][0m Rewards obtained: [260.11204165711194], Lows: [4], Highs: [6], Total time: 8575.261725999997
[32m[0906 18-54-48 @MBExp.py:144][0m ####################################################################
[32m[0906 18-54-48 @MBExp.py:145][0m Starting training iteration 100.
[32m[0906 18-54-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03246, current rewards: 1.11204, mean: 0.11120
[32m[0906 18-54-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03258, current rewards: 7.28995, mean: 0.12150
[32m[0906 18-54-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03261, current rewards: 13.36739, mean: 0.12152
[32m[0906 18-54-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03248, current rewards: 16.36800, mean: 0.10230
[32m[0906 18-54-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03252, current rewards: 19.21817, mean: 0.09152
[32m[0906 18-54-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03258, current rewards: 22.06834, mean: 0.08488
[32m[0906 18-54-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03259, current rewards: 24.91851, mean: 0.08038
[32m[0906 18-55-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03256, current rewards: 27.76869, mean: 0.07714
[32m[0906 18-55-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03258, current rewards: 30.61886, mean: 0.07468
[32m[0906 18-55-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03258, current rewards: 33.46903, mean: 0.07276
[32m[0906 18-55-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03256, current rewards: -7.01794, mean: -0.01376
[32m[0906 18-55-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03256, current rewards: -57.01794, mean: -0.10182
[32m[0906 18-55-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03254, current rewards: -107.01794, mean: -0.17544
[32m[0906 18-55-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03254, current rewards: -157.01794, mean: -0.23791
[32m[0906 18-55-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03253, current rewards: -207.01794, mean: -0.29157
[32m[0906 18-55-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03253, current rewards: -257.01794, mean: -0.33818
[32m[0906 18-55-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03252, current rewards: -307.01794, mean: -0.37903
[32m[0906 18-55-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03255, current rewards: -357.01794, mean: -0.41514
[32m[0906 18-55-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03260, current rewards: -407.01794, mean: -0.44727
[32m[0906 18-55-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03265, current rewards: -457.01794, mean: -0.47606
[32m[0906 18-55-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03269, current rewards: -507.01794, mean: -0.50200
[32m[0906 18-55-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03273, current rewards: -557.01794, mean: -0.52549
[32m[0906 18-55-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03275, current rewards: -607.01794, mean: -0.54686
[32m[0906 18-55-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03278, current rewards: -657.01794, mean: -0.56639
[32m[0906 18-55-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03282, current rewards: -707.01794, mean: -0.58431
[32m[0906 18-55-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03285, current rewards: -757.01794, mean: -0.60081
[32m[0906 18-55-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03288, current rewards: -807.01794, mean: -0.61604
[32m[0906 18-55-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03290, current rewards: -857.01794, mean: -0.63016
[32m[0906 18-55-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03291, current rewards: -907.01794, mean: -0.64328
[32m[0906 18-55-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03294, current rewards: -957.01794, mean: -0.65549
[32m[0906 18-55-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03296, current rewards: -1007.01794, mean: -0.66690
[32m[0906 18-55-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03298, current rewards: -1057.01794, mean: -0.67758
[32m[0906 18-55-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03300, current rewards: -1107.01794, mean: -0.68759
[32m[0906 18-55-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03302, current rewards: -1157.01794, mean: -0.69700
[32m[0906 18-55-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03304, current rewards: -1207.01794, mean: -0.70586
[32m[0906 18-55-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03305, current rewards: -1257.01794, mean: -0.71421
[32m[0906 18-55-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03307, current rewards: -1307.01794, mean: -0.72211
[32m[0906 18-55-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03309, current rewards: -1357.01794, mean: -0.72958
[32m[0906 18-55-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03310, current rewards: -1407.01794, mean: -0.73666
[32m[0906 18-55-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03313, current rewards: -1457.01794, mean: -0.74338
[32m[0906 18-55-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03317, current rewards: -1507.01794, mean: -0.74976
[32m[0906 18-55-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03319, current rewards: -1557.01794, mean: -0.75583
[32m[0906 18-55-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03322, current rewards: -1607.01794, mean: -0.76162
[32m[0906 18-56-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03325, current rewards: -1657.01794, mean: -0.76714
[32m[0906 18-56-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03327, current rewards: -1707.01794, mean: -0.77241
[32m[0906 18-56-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03330, current rewards: -1757.01794, mean: -0.77744
[32m[0906 18-56-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03331, current rewards: -1807.01794, mean: -0.78226
[32m[0906 18-56-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03333, current rewards: -1857.01794, mean: -0.78687
[32m[0906 18-56-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03336, current rewards: -1907.01794, mean: -0.79129
[32m[0906 18-56-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03338, current rewards: -1957.01794, mean: -0.79554
[32m[0906 18-56-12 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 18-56-12 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-56-12 @MBExp.py:227][0m Rewards obtained: [-1997.0179384207736], Lows: [0], Highs: [2031], Total time: 8659.515325999997
[32m[0906 18-59-36 @MBExp.py:144][0m ####################################################################
[32m[0906 18-59-36 @MBExp.py:145][0m Starting training iteration 101.
[32m[0906 18-59-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03228, current rewards: 0.99955, mean: 0.09995
[32m[0906 18-59-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03231, current rewards: 6.38484, mean: 0.10641
[32m[0906 18-59-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03244, current rewards: 11.76719, mean: 0.10697
[32m[0906 18-59-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03245, current rewards: 17.14707, mean: 0.10717
[32m[0906 18-59-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03236, current rewards: 22.53128, mean: 0.10729
[32m[0906 18-59-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03234, current rewards: 27.91559, mean: 0.10737
[32m[0906 18-59-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03237, current rewards: 33.29381, mean: 0.10740
[32m[0906 18-59-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03242, current rewards: 38.67382, mean: 0.10743
[32m[0906 18-59-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03245, current rewards: 44.05567, mean: 0.10745
[32m[0906 18-59-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03247, current rewards: 49.43941, mean: 0.10748
[32m[0906 18-59-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03244, current rewards: 55.01022, mean: 0.10786
[32m[0906 18-59-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03244, current rewards: 60.34509, mean: 0.10776
[32m[0906 18-59-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03246, current rewards: 62.35452, mean: 0.10222
[32m[0906 18-59-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03245, current rewards: 67.86289, mean: 0.10282
[32m[0906 18-59-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03247, current rewards: 73.37080, mean: 0.10334
[32m[0906 19-00-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03250, current rewards: 78.88107, mean: 0.10379
[32m[0906 19-00-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03252, current rewards: 84.38451, mean: 0.10418
[32m[0906 19-00-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03253, current rewards: 89.89328, mean: 0.10453
[32m[0906 19-00-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03260, current rewards: 95.26234, mean: 0.10468
[32m[0906 19-00-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03266, current rewards: 100.74923, mean: 0.10495
[32m[0906 19-00-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03270, current rewards: 106.25942, mean: 0.10521
[32m[0906 19-00-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03272, current rewards: 111.76719, mean: 0.10544
[32m[0906 19-00-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03275, current rewards: 117.27722, mean: 0.10566
[32m[0906 19-00-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03280, current rewards: 122.78679, mean: 0.10585
[32m[0906 19-00-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03283, current rewards: 126.17944, mean: 0.10428
[32m[0906 19-00-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03286, current rewards: 131.74504, mean: 0.10456
[32m[0906 19-00-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03289, current rewards: 137.29756, mean: 0.10481
[32m[0906 19-00-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03292, current rewards: 142.80862, mean: 0.10501
[32m[0906 19-00-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03294, current rewards: 148.36214, mean: 0.10522
[32m[0906 19-00-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03296, current rewards: 153.91968, mean: 0.10542
[32m[0906 19-00-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03298, current rewards: 159.47361, mean: 0.10561
[32m[0906 19-00-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03299, current rewards: 165.02875, mean: 0.10579
[32m[0906 19-00-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03301, current rewards: 170.58330, mean: 0.10595
[32m[0906 19-00-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03302, current rewards: 176.13427, mean: 0.10610
[32m[0906 19-00-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03304, current rewards: 181.68530, mean: 0.10625
[32m[0906 19-00-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03305, current rewards: 187.23603, mean: 0.10638
[32m[0906 19-00-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03306, current rewards: 191.64212, mean: 0.10588
[32m[0906 19-00-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03307, current rewards: 197.21947, mean: 0.10603
[32m[0906 19-00-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03309, current rewards: 202.79541, mean: 0.10618
[32m[0906 19-00-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03313, current rewards: 208.36999, mean: 0.10631
[32m[0906 19-00-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03316, current rewards: 213.94949, mean: 0.10644
[32m[0906 19-00-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03319, current rewards: 219.51291, mean: 0.10656
[32m[0906 19-00-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03322, current rewards: 225.08457, mean: 0.10668
[32m[0906 19-00-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03325, current rewards: 230.73562, mean: 0.10682
[32m[0906 19-00-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03328, current rewards: 236.30709, mean: 0.10693
[32m[0906 19-00-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03330, current rewards: 241.88639, mean: 0.10703
[32m[0906 19-00-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03333, current rewards: 247.44637, mean: 0.10712
[32m[0906 19-00-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03335, current rewards: 252.99745, mean: 0.10720
[32m[0906 19-00-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03338, current rewards: 258.54716, mean: 0.10728
[32m[0906 19-00-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03340, current rewards: 264.09727, mean: 0.10736
[32m[0906 19-01-00 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 19-01-00 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-01-00 @MBExp.py:227][0m Rewards obtained: [268.54365862878495], Lows: [1], Highs: [4], Total time: 8743.830455999998
[32m[0906 19-04-26 @MBExp.py:144][0m ####################################################################
[32m[0906 19-04-26 @MBExp.py:145][0m Starting training iteration 102.
[32m[0906 19-04-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03261, current rewards: -0.15362, mean: -0.01536
[32m[0906 19-04-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03264, current rewards: 5.59249, mean: 0.09321
[32m[0906 19-04-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03241, current rewards: 11.18635, mean: 0.10169
[32m[0906 19-04-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03241, current rewards: 16.74519, mean: 0.10466
[32m[0906 19-04-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03245, current rewards: 22.30351, mean: 0.10621
[32m[0906 19-04-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03247, current rewards: 27.85962, mean: 0.10715
[32m[0906 19-04-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03249, current rewards: 33.41530, mean: 0.10779
[32m[0906 19-04-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03252, current rewards: 37.75067, mean: 0.10486
[32m[0906 19-04-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03256, current rewards: 43.29522, mean: 0.10560
[32m[0906 19-04-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03257, current rewards: 48.84452, mean: 0.10618
[32m[0906 19-04-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03257, current rewards: 54.39269, mean: 0.10665
[32m[0906 19-04-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03257, current rewards: 58.20070, mean: 0.10393
[32m[0906 19-04-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03258, current rewards: 63.76398, mean: 0.10453
[32m[0906 19-04-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03258, current rewards: 69.32357, mean: 0.10504
[32m[0906 19-04-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03256, current rewards: 74.88743, mean: 0.10548
[32m[0906 19-04-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03256, current rewards: 80.45408, mean: 0.10586
[32m[0906 19-04-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03257, current rewards: 86.01791, mean: 0.10619
[32m[0906 19-04-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03258, current rewards: 91.58013, mean: 0.10649
[32m[0906 19-04-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03264, current rewards: 96.84475, mean: 0.10642
[32m[0906 19-04-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03269, current rewards: 100.34775, mean: 0.10453
[32m[0906 19-04-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03273, current rewards: 106.14869, mean: 0.10510
[32m[0906 19-05-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03276, current rewards: 111.95676, mean: 0.10562
[32m[0906 19-05-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03281, current rewards: 117.75768, mean: 0.10609
[32m[0906 19-05-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03284, current rewards: 123.56309, mean: 0.10652
[32m[0906 19-05-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03288, current rewards: 129.36720, mean: 0.10692
[32m[0906 19-05-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03291, current rewards: 135.16743, mean: 0.10728
[32m[0906 19-05-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03293, current rewards: 141.15687, mean: 0.10775
[32m[0906 19-05-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03295, current rewards: 145.67654, mean: 0.10712
[32m[0906 19-05-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03296, current rewards: 151.21463, mean: 0.10724
[32m[0906 19-05-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03298, current rewards: 156.74334, mean: 0.10736
[32m[0906 19-05-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03300, current rewards: 162.27159, mean: 0.10746
[32m[0906 19-05-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03301, current rewards: 167.80105, mean: 0.10756
[32m[0906 19-05-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03303, current rewards: 173.32864, mean: 0.10766
[32m[0906 19-05-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03305, current rewards: 177.75954, mean: 0.10708
[32m[0906 19-05-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03306, current rewards: 183.28615, mean: 0.10718
[32m[0906 19-05-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03308, current rewards: 188.70026, mean: 0.10722
[32m[0906 19-05-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03308, current rewards: 194.21725, mean: 0.10730
[32m[0906 19-05-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03310, current rewards: 199.73809, mean: 0.10739
[32m[0906 19-05-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03310, current rewards: 205.25453, mean: 0.10746
[32m[0906 19-05-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03314, current rewards: 210.76868, mean: 0.10754
[32m[0906 19-05-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03317, current rewards: 216.28953, mean: 0.10761
[32m[0906 19-05-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03321, current rewards: 221.80480, mean: 0.10767
[32m[0906 19-05-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03323, current rewards: 227.31732, mean: 0.10773
[32m[0906 19-05-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03326, current rewards: 233.05160, mean: 0.10789
[32m[0906 19-05-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03329, current rewards: 238.58763, mean: 0.10796
[32m[0906 19-05-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03331, current rewards: 242.05731, mean: 0.10711
[32m[0906 19-05-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03333, current rewards: 247.59979, mean: 0.10719
[32m[0906 19-05-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03336, current rewards: 253.14571, mean: 0.10727
[32m[0906 19-05-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03338, current rewards: 258.68983, mean: 0.10734
[32m[0906 19-05-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03340, current rewards: 264.23351, mean: 0.10741
[32m[0906 19-05-50 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 19-05-50 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-05-50 @MBExp.py:227][0m Rewards obtained: [268.6699501045457], Lows: [3], Highs: [4], Total time: 8828.157339999998
[32m[0906 19-09-18 @MBExp.py:144][0m ####################################################################
[32m[0906 19-09-18 @MBExp.py:145][0m Starting training iteration 103.
[32m[0906 19-09-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03185, current rewards: 0.04677, mean: 0.00468
[32m[0906 19-09-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03231, current rewards: 5.64752, mean: 0.09413
[32m[0906 19-09-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03236, current rewards: 11.28188, mean: 0.10256
[32m[0906 19-09-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03235, current rewards: 16.85076, mean: 0.10532
[32m[0906 19-09-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03236, current rewards: 22.41604, mean: 0.10674
[32m[0906 19-09-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03243, current rewards: 27.98981, mean: 0.10765
[32m[0906 19-09-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03241, current rewards: 33.55989, mean: 0.10826
[32m[0906 19-09-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03244, current rewards: 36.96803, mean: 0.10269
[32m[0906 19-09-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03243, current rewards: 42.42917, mean: 0.10349
[32m[0906 19-09-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03243, current rewards: 47.89293, mean: 0.10412
[32m[0906 19-09-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03244, current rewards: 53.18228, mean: 0.10428
[32m[0906 19-09-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03243, current rewards: 58.61238, mean: 0.10466
[32m[0906 19-09-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03244, current rewards: 64.04386, mean: 0.10499
[32m[0906 19-09-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03245, current rewards: 69.47646, mean: 0.10527
[32m[0906 19-09-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03245, current rewards: 74.90709, mean: 0.10550
[32m[0906 19-09-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03246, current rewards: 80.33702, mean: 0.10571
[32m[0906 19-09-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03246, current rewards: 84.79490, mean: 0.10469
[32m[0906 19-09-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03247, current rewards: 90.36101, mean: 0.10507
[32m[0906 19-09-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03252, current rewards: 96.00005, mean: 0.10549
[32m[0906 19-09-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03257, current rewards: 101.57134, mean: 0.10580
[32m[0906 19-09-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03261, current rewards: 107.14662, mean: 0.10609
[32m[0906 19-09-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03266, current rewards: 112.72239, mean: 0.10634
[32m[0906 19-09-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03270, current rewards: 118.29427, mean: 0.10657
[32m[0906 19-09-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03273, current rewards: 123.86953, mean: 0.10678
[32m[0906 19-09-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03277, current rewards: 129.44703, mean: 0.10698
[32m[0906 19-09-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03280, current rewards: 135.01726, mean: 0.10716
[32m[0906 19-10-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03283, current rewards: 140.70723, mean: 0.10741
[32m[0906 19-10-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03285, current rewards: 146.29137, mean: 0.10757
[32m[0906 19-10-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03287, current rewards: 149.72383, mean: 0.10619
[32m[0906 19-10-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03290, current rewards: 155.30983, mean: 0.10638
[32m[0906 19-10-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03292, current rewards: 160.89480, mean: 0.10655
[32m[0906 19-10-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03294, current rewards: 166.48570, mean: 0.10672
[32m[0906 19-10-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03297, current rewards: 170.97412, mean: 0.10620
[32m[0906 19-10-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03299, current rewards: 176.54721, mean: 0.10635
[32m[0906 19-10-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03301, current rewards: 182.10199, mean: 0.10649
[32m[0906 19-10-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03303, current rewards: 187.67107, mean: 0.10663
[32m[0906 19-10-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03304, current rewards: 193.23788, mean: 0.10676
[32m[0906 19-10-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03305, current rewards: 198.80950, mean: 0.10689
[32m[0906 19-10-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03306, current rewards: 199.98790, mean: 0.10471
[32m[0906 19-10-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03309, current rewards: 205.39473, mean: 0.10479
[32m[0906 19-10-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03312, current rewards: 210.83588, mean: 0.10489
[32m[0906 19-10-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03316, current rewards: 216.27960, mean: 0.10499
[32m[0906 19-10-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03319, current rewards: 221.69284, mean: 0.10507
[32m[0906 19-10-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03322, current rewards: 227.12440, mean: 0.10515
[32m[0906 19-10-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03325, current rewards: 230.42464, mean: 0.10426
[32m[0906 19-10-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03328, current rewards: 236.00441, mean: 0.10443
[32m[0906 19-10-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03330, current rewards: 241.58297, mean: 0.10458
[32m[0906 19-10-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03332, current rewards: 247.15631, mean: 0.10473
[32m[0906 19-10-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03334, current rewards: 252.73642, mean: 0.10487
[32m[0906 19-10-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03337, current rewards: 258.31638, mean: 0.10501
[32m[0906 19-10-42 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 19-10-42 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-10-42 @MBExp.py:227][0m Rewards obtained: [262.78150198012236], Lows: [4], Highs: [5], Total time: 8912.403940999999
[32m[0906 19-14-12 @MBExp.py:144][0m ####################################################################
[32m[0906 19-14-12 @MBExp.py:145][0m Starting training iteration 104.
[32m[0906 19-14-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03184, current rewards: -1.21226, mean: -0.12123
[32m[0906 19-14-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03238, current rewards: 4.19262, mean: 0.06988
[32m[0906 19-14-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03250, current rewards: 9.73704, mean: 0.08852
[32m[0906 19-14-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03247, current rewards: 15.28105, mean: 0.09551
[32m[0906 19-14-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03247, current rewards: 20.82964, mean: 0.09919
[32m[0906 19-14-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03247, current rewards: 26.37432, mean: 0.10144
[32m[0906 19-14-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03250, current rewards: 31.92042, mean: 0.10297
[32m[0906 19-14-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03252, current rewards: 37.46202, mean: 0.10406
[32m[0906 19-14-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03250, current rewards: 43.00393, mean: 0.10489
[32m[0906 19-14-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03252, current rewards: 47.72137, mean: 0.10374
[32m[0906 19-14-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03254, current rewards: 53.13356, mean: 0.10418
[32m[0906 19-14-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03252, current rewards: 58.54005, mean: 0.10454
[32m[0906 19-14-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03251, current rewards: 63.94448, mean: 0.10483
[32m[0906 19-14-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03250, current rewards: 69.34792, mean: 0.10507
[32m[0906 19-14-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03248, current rewards: 74.75342, mean: 0.10529
[32m[0906 19-14-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03249, current rewards: 80.15647, mean: 0.10547
[32m[0906 19-14-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03250, current rewards: 85.56194, mean: 0.10563
[32m[0906 19-14-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03249, current rewards: 90.98926, mean: 0.10580
[32m[0906 19-14-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03255, current rewards: 94.98668, mean: 0.10438
[32m[0906 19-14-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03261, current rewards: 100.51219, mean: 0.10470
[32m[0906 19-14-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03264, current rewards: 106.03633, mean: 0.10499
[32m[0906 19-14-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03269, current rewards: 111.56219, mean: 0.10525
[32m[0906 19-14-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03273, current rewards: 117.08776, mean: 0.10548
[32m[0906 19-14-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03277, current rewards: 122.61509, mean: 0.10570
[32m[0906 19-14-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03280, current rewards: 129.48019, mean: 0.10701
[32m[0906 19-14-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03284, current rewards: 140.06122, mean: 0.11116
[32m[0906 19-14-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03287, current rewards: 146.19362, mean: 0.11160
[32m[0906 19-14-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03291, current rewards: 151.75793, mean: 0.11159
[32m[0906 19-14-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03293, current rewards: 157.32307, mean: 0.11158
[32m[0906 19-15-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03296, current rewards: 162.89047, mean: 0.11157
[32m[0906 19-15-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03298, current rewards: 168.45835, mean: 0.11156
[32m[0906 19-15-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03300, current rewards: 174.02762, mean: 0.11156
[32m[0906 19-15-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03303, current rewards: 179.59318, mean: 0.11155
[32m[0906 19-15-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03304, current rewards: 184.14471, mean: 0.11093
[32m[0906 19-15-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03306, current rewards: 189.89343, mean: 0.11105
[32m[0906 19-15-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03308, current rewards: 195.40984, mean: 0.11103
[32m[0906 19-15-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03311, current rewards: 200.92952, mean: 0.11101
[32m[0906 19-15-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03312, current rewards: 206.44399, mean: 0.11099
[32m[0906 19-15-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03314, current rewards: 211.96297, mean: 0.11098
[32m[0906 19-15-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03315, current rewards: 217.48264, mean: 0.11096
[32m[0906 19-15-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03318, current rewards: 223.00160, mean: 0.11095
[32m[0906 19-15-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03322, current rewards: 227.15324, mean: 0.11027
[32m[0906 19-15-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03325, current rewards: 232.57245, mean: 0.11022
[32m[0906 19-15-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03328, current rewards: 237.94618, mean: 0.11016
[32m[0906 19-15-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03330, current rewards: 243.37499, mean: 0.11012
[32m[0906 19-15-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03333, current rewards: 248.80557, mean: 0.11009
[32m[0906 19-15-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03336, current rewards: 254.23694, mean: 0.11006
[32m[0906 19-15-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03338, current rewards: 259.66532, mean: 0.11003
[32m[0906 19-15-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03340, current rewards: 265.09834, mean: 0.11000
[32m[0906 19-15-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03343, current rewards: 270.52654, mean: 0.10997
[32m[0906 19-15-36 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 19-15-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-15-36 @MBExp.py:227][0m Rewards obtained: [274.8703510476702], Lows: [2], Highs: [5], Total time: 8996.789981999998
[32m[0906 19-19-08 @MBExp.py:144][0m ####################################################################
[32m[0906 19-19-08 @MBExp.py:145][0m Starting training iteration 105.
[32m[0906 19-19-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03238, current rewards: -0.03654, mean: -0.00365
[32m[0906 19-19-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03239, current rewards: 5.29382, mean: 0.08823
[32m[0906 19-19-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03241, current rewards: 10.85188, mean: 0.09865
[32m[0906 19-19-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03242, current rewards: 16.41554, mean: 0.10260
[32m[0906 19-19-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03247, current rewards: 21.97644, mean: 0.10465
[32m[0906 19-19-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03248, current rewards: 27.53102, mean: 0.10589
[32m[0906 19-19-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03247, current rewards: 33.09396, mean: 0.10675
[32m[0906 19-19-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03251, current rewards: 38.65500, mean: 0.10738
[32m[0906 19-19-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03250, current rewards: 44.21612, mean: 0.10784
[32m[0906 19-19-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03250, current rewards: 49.73596, mean: 0.10812
[32m[0906 19-19-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03247, current rewards: 55.31724, mean: 0.10847
[32m[0906 19-19-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03247, current rewards: 60.89498, mean: 0.10874
[32m[0906 19-19-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03247, current rewards: 66.48196, mean: 0.10899
[32m[0906 19-19-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03247, current rewards: 69.86224, mean: 0.10585
[32m[0906 19-19-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03246, current rewards: 75.40647, mean: 0.10621
[32m[0906 19-19-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03248, current rewards: 80.95343, mean: 0.10652
[32m[0906 19-19-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03249, current rewards: 86.50139, mean: 0.10679
[32m[0906 19-19-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03250, current rewards: 92.21926, mean: 0.10723
[32m[0906 19-19-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03249, current rewards: 97.94846, mean: 0.10764
[32m[0906 19-19-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03254, current rewards: 103.61833, mean: 0.10794
[32m[0906 19-19-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03257, current rewards: 109.28734, mean: 0.10821
[32m[0906 19-19-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03261, current rewards: 114.95579, mean: 0.10845
[32m[0906 19-19-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03265, current rewards: 119.51334, mean: 0.10767
[32m[0906 19-19-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03269, current rewards: 125.04214, mean: 0.10779
[32m[0906 19-19-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03272, current rewards: 130.57360, mean: 0.10791
[32m[0906 19-19-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03275, current rewards: 136.10377, mean: 0.10802
[32m[0906 19-19-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03278, current rewards: 141.74703, mean: 0.10820
[32m[0906 19-19-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03281, current rewards: 145.24156, mean: 0.10680
[32m[0906 19-19-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03284, current rewards: 154.29499, mean: 0.10943
[32m[0906 19-19-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03287, current rewards: 163.34842, mean: 0.11188
[32m[0906 19-19-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03290, current rewards: 172.40186, mean: 0.11417
[32m[0906 19-19-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03292, current rewards: 181.45529, mean: 0.11632
[32m[0906 19-20-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03294, current rewards: 190.50872, mean: 0.11833
[32m[0906 19-20-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03295, current rewards: 199.56215, mean: 0.12022
[32m[0906 19-20-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03297, current rewards: 179.78231, mean: 0.10514
[32m[0906 19-20-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03298, current rewards: 129.78231, mean: 0.07374
[32m[0906 19-20-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03300, current rewards: 79.78231, mean: 0.04408
[32m[0906 19-20-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03301, current rewards: 29.78231, mean: 0.01601
[32m[0906 19-20-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03302, current rewards: -20.21769, mean: -0.01059
[32m[0906 19-20-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03303, current rewards: -70.21769, mean: -0.03583
[32m[0906 19-20-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03306, current rewards: -120.21769, mean: -0.05981
[32m[0906 19-20-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03310, current rewards: -170.21769, mean: -0.08263
[32m[0906 19-20-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03313, current rewards: -220.21769, mean: -0.10437
[32m[0906 19-20-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03316, current rewards: -270.21769, mean: -0.12510
[32m[0906 19-20-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03318, current rewards: -320.21769, mean: -0.14489
[32m[0906 19-20-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03321, current rewards: -370.21769, mean: -0.16381
[32m[0906 19-20-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03323, current rewards: -420.21769, mean: -0.18191
[32m[0906 19-20-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03325, current rewards: -470.21769, mean: -0.19924
[32m[0906 19-20-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03328, current rewards: -520.21769, mean: -0.21586
[32m[0906 19-20-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03330, current rewards: -570.21769, mean: -0.23180
[32m[0906 19-20-31 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 19-20-31 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-20-32 @MBExp.py:227][0m Rewards obtained: [-610.2176945693409], Lows: [3], Highs: [816], Total time: 9080.84429
[32m[0906 19-24-05 @MBExp.py:144][0m ####################################################################
[32m[0906 19-24-05 @MBExp.py:145][0m Starting training iteration 106.
[32m[0906 19-24-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03192, current rewards: -0.00636, mean: -0.00064
[32m[0906 19-24-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03232, current rewards: 5.60939, mean: 0.09349
[32m[0906 19-24-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03234, current rewards: 11.18658, mean: 0.10170
[32m[0906 19-24-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03242, current rewards: 16.76178, mean: 0.10476
[32m[0906 19-24-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03241, current rewards: 22.33955, mean: 0.10638
[32m[0906 19-24-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03241, current rewards: 27.91507, mean: 0.10737
[32m[0906 19-24-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03239, current rewards: 33.49184, mean: 0.10804
[32m[0906 19-24-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03241, current rewards: 39.06737, mean: 0.10852
[32m[0906 19-24-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03242, current rewards: 44.64935, mean: 0.10890
[32m[0906 19-24-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03244, current rewards: 49.14700, mean: 0.10684
[32m[0906 19-24-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03247, current rewards: 54.73592, mean: 0.10733
[32m[0906 19-24-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03247, current rewards: 60.30919, mean: 0.10769
[32m[0906 19-24-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03248, current rewards: 65.88051, mean: 0.10800
[32m[0906 19-24-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03249, current rewards: 69.37533, mean: 0.10511
[32m[0906 19-24-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03251, current rewards: 74.92268, mean: 0.10552
[32m[0906 19-24-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03252, current rewards: 80.46796, mean: 0.10588
[32m[0906 19-24-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03253, current rewards: 86.00621, mean: 0.10618
[32m[0906 19-24-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03253, current rewards: 91.55071, mean: 0.10645
[32m[0906 19-24-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03251, current rewards: 96.76027, mean: 0.10633
[32m[0906 19-24-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03256, current rewards: 102.28373, mean: 0.10655
[32m[0906 19-24-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03260, current rewards: 107.81359, mean: 0.10675
[32m[0906 19-24-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03265, current rewards: 113.32892, mean: 0.10691
[32m[0906 19-24-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03269, current rewards: 118.84539, mean: 0.10707
[32m[0906 19-24-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03272, current rewards: 124.36411, mean: 0.10721
[32m[0906 19-24-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03275, current rewards: 129.88596, mean: 0.10734
[32m[0906 19-24-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03278, current rewards: 135.40521, mean: 0.10746
[32m[0906 19-24-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03281, current rewards: 139.10678, mean: 0.10619
[32m[0906 19-24-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03284, current rewards: 144.88777, mean: 0.10654
[32m[0906 19-24-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03287, current rewards: 150.45526, mean: 0.10671
[32m[0906 19-24-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03289, current rewards: 156.02313, mean: 0.10687
[32m[0906 19-24-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03291, current rewards: 161.58998, mean: 0.10701
[32m[0906 19-24-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03293, current rewards: 164.80103, mean: 0.10564
[32m[0906 19-24-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03295, current rewards: 170.33747, mean: 0.10580
[32m[0906 19-25-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03297, current rewards: 175.86578, mean: 0.10594
[32m[0906 19-25-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03299, current rewards: 181.40367, mean: 0.10608
[32m[0906 19-25-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03301, current rewards: 185.64355, mean: 0.10548
[32m[0906 19-25-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03303, current rewards: 191.17544, mean: 0.10562
[32m[0906 19-25-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03304, current rewards: 196.70672, mean: 0.10576
[32m[0906 19-25-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03306, current rewards: 202.23672, mean: 0.10588
[32m[0906 19-25-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03307, current rewards: 207.76578, mean: 0.10600
[32m[0906 19-25-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03310, current rewards: 213.29219, mean: 0.10612
[32m[0906 19-25-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03313, current rewards: 218.81942, mean: 0.10622
[32m[0906 19-25-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03316, current rewards: 224.34442, mean: 0.10632
[32m[0906 19-25-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03319, current rewards: 229.89379, mean: 0.10643
[32m[0906 19-25-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03323, current rewards: 233.26298, mean: 0.10555
[32m[0906 19-25-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03325, current rewards: 238.80448, mean: 0.10567
[32m[0906 19-25-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03328, current rewards: 244.34940, mean: 0.10578
[32m[0906 19-25-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03330, current rewards: 249.89425, mean: 0.10589
[32m[0906 19-25-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03332, current rewards: 255.43594, mean: 0.10599
[32m[0906 19-25-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03335, current rewards: 260.97785, mean: 0.10609
[32m[0906 19-25-28 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 19-25-28 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-25-29 @MBExp.py:227][0m Rewards obtained: [265.41085991895244], Lows: [3], Highs: [5], Total time: 9165.025784
[32m[0906 19-29-04 @MBExp.py:144][0m ####################################################################
[32m[0906 19-29-04 @MBExp.py:145][0m Starting training iteration 107.
[32m[0906 19-29-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03243, current rewards: 0.92931, mean: 0.09293
[32m[0906 19-29-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03266, current rewards: 6.03231, mean: 0.10054
[32m[0906 19-29-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03252, current rewards: 11.16703, mean: 0.10152
[32m[0906 19-29-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03255, current rewards: 16.30503, mean: 0.10191
[32m[0906 19-29-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03247, current rewards: 21.44309, mean: 0.10211
[32m[0906 19-29-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03243, current rewards: 25.40193, mean: 0.09770
[32m[0906 19-29-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03244, current rewards: 30.93949, mean: 0.09980
[32m[0906 19-29-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03244, current rewards: 36.47808, mean: 0.10133
[32m[0906 19-29-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03246, current rewards: 42.01194, mean: 0.10247
[32m[0906 19-29-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03246, current rewards: 47.54663, mean: 0.10336
[32m[0906 19-29-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03246, current rewards: 52.94396, mean: 0.10381
[32m[0906 19-29-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03249, current rewards: 58.45705, mean: 0.10439
[32m[0906 19-29-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03249, current rewards: 63.96812, mean: 0.10487
[32m[0906 19-29-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03249, current rewards: 69.48548, mean: 0.10528
[32m[0906 19-29-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03249, current rewards: 74.99662, mean: 0.10563
[32m[0906 19-29-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03250, current rewards: 80.51247, mean: 0.10594
[32m[0906 19-29-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03251, current rewards: 86.03152, mean: 0.10621
[32m[0906 19-29-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03249, current rewards: 90.51691, mean: 0.10525
[32m[0906 19-29-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03249, current rewards: 96.43615, mean: 0.10597
[32m[0906 19-29-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03251, current rewards: 102.19612, mean: 0.10645
[32m[0906 19-29-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03255, current rewards: 107.94934, mean: 0.10688
[32m[0906 19-29-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03259, current rewards: 113.70515, mean: 0.10727
[32m[0906 19-29-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03264, current rewards: 117.27826, mean: 0.10566
[32m[0906 19-29-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03267, current rewards: 122.98872, mean: 0.10602
[32m[0906 19-29-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03271, current rewards: 128.70214, mean: 0.10637
[32m[0906 19-29-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03275, current rewards: 134.40980, mean: 0.10667
[32m[0906 19-29-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03278, current rewards: 139.96597, mean: 0.10684
[32m[0906 19-29-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03281, current rewards: 145.62735, mean: 0.10708
[32m[0906 19-29-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03283, current rewards: 151.31710, mean: 0.10732
[32m[0906 19-29-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03286, current rewards: 154.78767, mean: 0.10602
[32m[0906 19-29-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03288, current rewards: 160.35220, mean: 0.10619
[32m[0906 19-29-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03290, current rewards: 165.91748, mean: 0.10636
[32m[0906 19-29-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03292, current rewards: 171.47846, mean: 0.10651
[32m[0906 19-29-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03294, current rewards: 177.04523, mean: 0.10665
[32m[0906 19-30-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03297, current rewards: 182.61192, mean: 0.10679
[32m[0906 19-30-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03299, current rewards: 188.18233, mean: 0.10692
[32m[0906 19-30-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03300, current rewards: 193.74625, mean: 0.10704
[32m[0906 19-30-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03302, current rewards: 199.30993, mean: 0.10716
[32m[0906 19-30-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03304, current rewards: 204.87727, mean: 0.10727
[32m[0906 19-30-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03306, current rewards: 210.44149, mean: 0.10737
[32m[0906 19-30-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03307, current rewards: 216.00926, mean: 0.10747
[32m[0906 19-30-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03308, current rewards: 221.57344, mean: 0.10756
[32m[0906 19-30-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03308, current rewards: 227.13956, mean: 0.10765
[32m[0906 19-30-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03310, current rewards: 232.71130, mean: 0.10774
[32m[0906 19-30-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03313, current rewards: 238.27912, mean: 0.10782
[32m[0906 19-30-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03316, current rewards: 243.92420, mean: 0.10793
[32m[0906 19-30-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03319, current rewards: 249.78234, mean: 0.10813
[32m[0906 19-30-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03321, current rewards: 255.63754, mean: 0.10832
[32m[0906 19-30-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03324, current rewards: 261.49296, mean: 0.10850
[32m[0906 19-30-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03327, current rewards: 267.34797, mean: 0.10868
[32m[0906 19-30-28 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 19-30-28 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-30-28 @MBExp.py:227][0m Rewards obtained: [272.0351777252087], Lows: [2], Highs: [2], Total time: 9249.00562
[32m[0906 19-34-05 @MBExp.py:144][0m ####################################################################
[32m[0906 19-34-05 @MBExp.py:145][0m Starting training iteration 108.
[32m[0906 19-34-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03223, current rewards: 0.44480, mean: 0.04448
[32m[0906 19-34-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03242, current rewards: 5.90233, mean: 0.09837
[32m[0906 19-34-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03234, current rewards: 11.37263, mean: 0.10339
[32m[0906 19-34-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03237, current rewards: 16.84862, mean: 0.10530
[32m[0906 19-34-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03239, current rewards: 22.32007, mean: 0.10629
[32m[0906 19-34-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03243, current rewards: 27.79375, mean: 0.10690
[32m[0906 19-34-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03244, current rewards: 33.26389, mean: 0.10730
[32m[0906 19-34-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03244, current rewards: 38.73611, mean: 0.10760
[32m[0906 19-34-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03245, current rewards: 44.20793, mean: 0.10782
[32m[0906 19-34-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03248, current rewards: 49.52286, mean: 0.10766
[32m[0906 19-34-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03249, current rewards: 54.98361, mean: 0.10781
[32m[0906 19-34-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03250, current rewards: 60.44517, mean: 0.10794
[32m[0906 19-34-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03252, current rewards: 65.90834, mean: 0.10805
[32m[0906 19-34-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03251, current rewards: 71.37155, mean: 0.10814
[32m[0906 19-34-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03251, current rewards: 75.92284, mean: 0.10693
[32m[0906 19-34-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03252, current rewards: 81.43377, mean: 0.10715
[32m[0906 19-34-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03252, current rewards: 86.93839, mean: 0.10733
[32m[0906 19-34-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03250, current rewards: 92.55683, mean: 0.10762
[32m[0906 19-34-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03250, current rewards: 98.12278, mean: 0.10783
[32m[0906 19-34-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03251, current rewards: 103.63418, mean: 0.10795
[32m[0906 19-34-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03254, current rewards: 109.13215, mean: 0.10805
[32m[0906 19-34-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03259, current rewards: 114.63988, mean: 0.10815
[32m[0906 19-34-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03264, current rewards: 120.13915, mean: 0.10823
[32m[0906 19-34-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03267, current rewards: 125.64710, mean: 0.10832
[32m[0906 19-34-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03271, current rewards: 131.14604, mean: 0.10839
[32m[0906 19-34-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03275, current rewards: 134.62739, mean: 0.10685
[32m[0906 19-34-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03278, current rewards: 140.15144, mean: 0.10699
[32m[0906 19-34-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03281, current rewards: 145.69213, mean: 0.10713
[32m[0906 19-34-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03284, current rewards: 151.23187, mean: 0.10726
[32m[0906 19-34-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03287, current rewards: 156.77232, mean: 0.10738
[32m[0906 19-34-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03289, current rewards: 160.17495, mean: 0.10608
[32m[0906 19-34-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03290, current rewards: 165.59352, mean: 0.10615
[32m[0906 19-34-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03293, current rewards: 171.01398, mean: 0.10622
[32m[0906 19-35-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03294, current rewards: 176.43466, mean: 0.10629
[32m[0906 19-35-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03296, current rewards: 181.61911, mean: 0.10621
[32m[0906 19-35-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03297, current rewards: 186.99560, mean: 0.10625
[32m[0906 19-35-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03298, current rewards: 192.37579, mean: 0.10628
[32m[0906 19-35-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03300, current rewards: 197.05711, mean: 0.10594
[32m[0906 19-35-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03302, current rewards: 202.53159, mean: 0.10604
[32m[0906 19-35-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03303, current rewards: 208.01989, mean: 0.10613
[32m[0906 19-35-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03305, current rewards: 213.51124, mean: 0.10622
[32m[0906 19-35-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03306, current rewards: 219.00189, mean: 0.10631
[32m[0906 19-35-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03307, current rewards: 224.69970, mean: 0.10649
[32m[0906 19-35-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03308, current rewards: 230.26827, mean: 0.10661
[32m[0906 19-35-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03311, current rewards: 233.70049, mean: 0.10575
[32m[0906 19-35-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03314, current rewards: 239.20865, mean: 0.10584
[32m[0906 19-35-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03317, current rewards: 244.71523, mean: 0.10594
[32m[0906 19-35-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03319, current rewards: 246.82969, mean: 0.10459
[32m[0906 19-35-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03321, current rewards: 254.90398, mean: 0.10577
[32m[0906 19-35-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03324, current rewards: 262.97827, mean: 0.10690
[32m[0906 19-35-29 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 19-35-29 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-35-29 @MBExp.py:227][0m Rewards obtained: [269.43770398129624], Lows: [5], Highs: [3], Total time: 9332.928373
[32m[0906 19-39-08 @MBExp.py:144][0m ####################################################################
[32m[0906 19-39-08 @MBExp.py:145][0m Starting training iteration 109.
[32m[0906 19-39-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03175, current rewards: 1.13286, mean: 0.11329
[32m[0906 19-39-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03227, current rewards: 6.39020, mean: 0.10650
[32m[0906 19-39-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03236, current rewards: 10.43173, mean: 0.09483
[32m[0906 19-39-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03244, current rewards: 14.47327, mean: 0.09046
[32m[0906 19-39-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03242, current rewards: 18.51480, mean: 0.08817
[32m[0906 19-39-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03243, current rewards: 22.55634, mean: 0.08676
[32m[0906 19-39-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03243, current rewards: 26.59787, mean: 0.08580
[32m[0906 19-39-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03240, current rewards: -21.24047, mean: -0.05900
[32m[0906 19-39-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03237, current rewards: -71.24047, mean: -0.17376
[32m[0906 19-39-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03238, current rewards: -121.24047, mean: -0.26357
[32m[0906 19-39-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03239, current rewards: -171.24047, mean: -0.33577
[32m[0906 19-39-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03242, current rewards: -221.24047, mean: -0.39507
[32m[0906 19-39-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03243, current rewards: -271.24047, mean: -0.44466
[32m[0906 19-39-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03243, current rewards: -321.24047, mean: -0.48673
[32m[0906 19-39-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03243, current rewards: -371.24047, mean: -0.52287
[32m[0906 19-39-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03242, current rewards: -421.24047, mean: -0.55426
[32m[0906 19-39-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03244, current rewards: -471.24047, mean: -0.58178
[32m[0906 19-39-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03244, current rewards: -521.24047, mean: -0.60609
[32m[0906 19-39-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03242, current rewards: -571.24047, mean: -0.62774
[32m[0906 19-39-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03244, current rewards: -621.24047, mean: -0.64713
[32m[0906 19-39-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03243, current rewards: -671.24047, mean: -0.66459
[32m[0906 19-39-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03243, current rewards: -721.24047, mean: -0.68042
[32m[0906 19-39-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03248, current rewards: -771.24047, mean: -0.69481
[32m[0906 19-39-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03252, current rewards: -821.24047, mean: -0.70797
[32m[0906 19-39-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03255, current rewards: -871.24047, mean: -0.72003
[32m[0906 19-39-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03260, current rewards: -921.24047, mean: -0.73114
[32m[0906 19-39-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03264, current rewards: -971.24047, mean: -0.74140
[32m[0906 19-39-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03267, current rewards: -1021.24047, mean: -0.75091
[32m[0906 19-39-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03270, current rewards: -1071.24047, mean: -0.75975
[32m[0906 19-39-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03273, current rewards: -1121.24047, mean: -0.76797
[32m[0906 19-39-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03276, current rewards: -1171.24047, mean: -0.77566
[32m[0906 19-40-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03279, current rewards: -1221.24047, mean: -0.78285
[32m[0906 19-40-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03280, current rewards: -1271.24047, mean: -0.78959
[32m[0906 19-40-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03282, current rewards: -1321.24047, mean: -0.79593
[32m[0906 19-40-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03284, current rewards: -1371.24047, mean: -0.80190
[32m[0906 19-40-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03287, current rewards: -1421.24047, mean: -0.80752
[32m[0906 19-40-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03289, current rewards: -1471.24047, mean: -0.81284
[32m[0906 19-40-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03291, current rewards: -1521.24047, mean: -0.81787
[32m[0906 19-40-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03293, current rewards: -1571.24047, mean: -0.82264
[32m[0906 19-40-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03294, current rewards: -1621.24047, mean: -0.82716
[32m[0906 19-40-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03297, current rewards: -1671.24047, mean: -0.83146
[32m[0906 19-40-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03298, current rewards: -1721.24047, mean: -0.83555
[32m[0906 19-40-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03299, current rewards: -1771.24047, mean: -0.83945
[32m[0906 19-40-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03301, current rewards: -1821.24047, mean: -0.84317
[32m[0906 19-40-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03302, current rewards: -1871.24047, mean: -0.84672
[32m[0906 19-40-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03305, current rewards: -1921.24047, mean: -0.85011
[32m[0906 19-40-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03308, current rewards: -1971.24047, mean: -0.85335
[32m[0906 19-40-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03310, current rewards: -2021.24047, mean: -0.85646
[32m[0906 19-40-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03313, current rewards: -2071.24047, mean: -0.85944
[32m[0906 19-40-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03316, current rewards: -2121.24047, mean: -0.86229
[32m[0906 19-40-32 @Agent.py:117][0m Average action selection time: 0.0332
[32m[0906 19-40-32 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-40-32 @MBExp.py:227][0m Rewards obtained: [-2161.240466810478], Lows: [0], Highs: [2188], Total time: 9416.639017000001
[32m[0906 19-44-14 @MBExp.py:144][0m ####################################################################
[32m[0906 19-44-14 @MBExp.py:145][0m Starting training iteration 110.
[32m[0906 19-44-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03195, current rewards: 0.10096, mean: 0.01010
[32m[0906 19-44-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03245, current rewards: 5.63910, mean: 0.09398
[32m[0906 19-44-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03242, current rewards: 11.17831, mean: 0.10162
[32m[0906 19-44-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03242, current rewards: 16.72430, mean: 0.10453
[32m[0906 19-44-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03244, current rewards: 22.26354, mean: 0.10602
[32m[0906 19-44-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03241, current rewards: 27.80587, mean: 0.10695
[32m[0906 19-44-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03240, current rewards: 31.24547, mean: 0.10079
[32m[0906 19-44-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03245, current rewards: 36.80841, mean: 0.10225
[32m[0906 19-44-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03245, current rewards: 42.28879, mean: 0.10314
[32m[0906 19-44-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03248, current rewards: 47.64934, mean: 0.10359
[32m[0906 19-44-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03248, current rewards: 53.17034, mean: 0.10426
[32m[0906 19-44-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03251, current rewards: 58.68943, mean: 0.10480
[32m[0906 19-44-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03253, current rewards: 64.21000, mean: 0.10526
[32m[0906 19-44-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03252, current rewards: 69.54768, mean: 0.10538
[32m[0906 19-44-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03250, current rewards: 75.07025, mean: 0.10573
[32m[0906 19-44-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03250, current rewards: 80.59948, mean: 0.10605
[32m[0906 19-44-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03250, current rewards: 86.12940, mean: 0.10633
[32m[0906 19-44-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03252, current rewards: 91.77115, mean: 0.10671
[32m[0906 19-44-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03252, current rewards: 97.30679, mean: 0.10693
[32m[0906 19-44-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03253, current rewards: 102.83493, mean: 0.10712
[32m[0906 19-44-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03254, current rewards: 108.37034, mean: 0.10730
[32m[0906 19-44-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03255, current rewards: 113.91200, mean: 0.10746
[32m[0906 19-44-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03259, current rewards: 119.44946, mean: 0.10761
[32m[0906 19-44-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03261, current rewards: 122.84268, mean: 0.10590
[32m[0906 19-44-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03265, current rewards: 128.38354, mean: 0.10610
[32m[0906 19-44-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03268, current rewards: 133.88399, mean: 0.10626
[32m[0906 19-44-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03272, current rewards: 139.41057, mean: 0.10642
[32m[0906 19-44-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03275, current rewards: 144.94419, mean: 0.10658
[32m[0906 19-45-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03279, current rewards: 150.47731, mean: 0.10672
[32m[0906 19-45-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03281, current rewards: 154.03494, mean: 0.10550
[32m[0906 19-45-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03283, current rewards: 159.57055, mean: 0.10568
[32m[0906 19-45-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03286, current rewards: 165.10858, mean: 0.10584
[32m[0906 19-45-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03289, current rewards: 170.64367, mean: 0.10599
[32m[0906 19-45-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03290, current rewards: 176.03707, mean: 0.10605
[32m[0906 19-45-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03293, current rewards: 181.49899, mean: 0.10614
[32m[0906 19-45-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03295, current rewards: 187.01141, mean: 0.10626
[32m[0906 19-45-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03296, current rewards: 192.51955, mean: 0.10636
[32m[0906 19-45-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03298, current rewards: 196.91748, mean: 0.10587
[32m[0906 19-45-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03299, current rewards: 202.46135, mean: 0.10600
[32m[0906 19-45-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03301, current rewards: 208.00563, mean: 0.10613
[32m[0906 19-45-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03303, current rewards: 213.54506, mean: 0.10624
[32m[0906 19-45-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03304, current rewards: 219.08903, mean: 0.10635
[32m[0906 19-45-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03305, current rewards: 224.71787, mean: 0.10650
[32m[0906 19-45-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03306, current rewards: 230.25918, mean: 0.10660
[32m[0906 19-45-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03307, current rewards: 235.80621, mean: 0.10670
[32m[0906 19-45-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03309, current rewards: 241.35221, mean: 0.10679
[32m[0906 19-45-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03311, current rewards: 246.89668, mean: 0.10688
[32m[0906 19-45-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03311, current rewards: 252.44256, mean: 0.10697
[32m[0906 19-45-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03312, current rewards: 257.98664, mean: 0.10705
[32m[0906 19-45-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03313, current rewards: 263.53120, mean: 0.10713
[32m[0906 19-45-37 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 19-45-37 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-45-37 @MBExp.py:227][0m Rewards obtained: [267.9729581614154], Lows: [3], Highs: [3], Total time: 9500.286957000002
[32m[0906 19-49-22 @MBExp.py:144][0m ####################################################################
[32m[0906 19-49-22 @MBExp.py:145][0m Starting training iteration 111.
[32m[0906 19-49-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03580, current rewards: -3.18605, mean: -0.31860
[32m[0906 19-49-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03304, current rewards: 2.67585, mean: 0.04460
[32m[0906 19-49-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03278, current rewards: 8.28877, mean: 0.07535
[32m[0906 19-49-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03261, current rewards: 13.90270, mean: 0.08689
[32m[0906 19-49-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03256, current rewards: 19.51255, mean: 0.09292
[32m[0906 19-49-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03260, current rewards: 25.12271, mean: 0.09663
[32m[0906 19-49-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03253, current rewards: 30.73873, mean: 0.09916
[32m[0906 19-49-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03253, current rewards: 36.35240, mean: 0.10098
[32m[0906 19-49-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03250, current rewards: 41.95205, mean: 0.10232
[32m[0906 19-49-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03252, current rewards: 47.34423, mean: 0.10292
[32m[0906 19-49-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03251, current rewards: 50.60590, mean: 0.09923
[32m[0906 19-49-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03252, current rewards: 55.68252, mean: 0.09943
[32m[0906 19-49-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03252, current rewards: 60.75990, mean: 0.09961
[32m[0906 19-49-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03253, current rewards: 65.84130, mean: 0.09976
[32m[0906 19-49-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03253, current rewards: 70.91896, mean: 0.09989
[32m[0906 19-49-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03253, current rewards: 75.99669, mean: 0.10000
[32m[0906 19-49-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03254, current rewards: 81.07581, mean: 0.10009
[32m[0906 19-49-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03254, current rewards: 84.21238, mean: 0.09792
[32m[0906 19-49-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03254, current rewards: 89.76055, mean: 0.09864
[32m[0906 19-49-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03255, current rewards: 95.32819, mean: 0.09930
[32m[0906 19-49-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03253, current rewards: 100.88579, mean: 0.09989
[32m[0906 19-49-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03255, current rewards: 106.44044, mean: 0.10042
[32m[0906 19-49-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03255, current rewards: 111.99867, mean: 0.10090
[32m[0906 19-50-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03260, current rewards: 117.55632, mean: 0.10134
[32m[0906 19-50-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03263, current rewards: 123.11157, mean: 0.10175
[32m[0906 19-50-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03267, current rewards: 128.71047, mean: 0.10215
[32m[0906 19-50-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03269, current rewards: 134.27309, mean: 0.10250
[32m[0906 19-50-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03273, current rewards: 137.71096, mean: 0.10126
[32m[0906 19-50-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03277, current rewards: 143.21629, mean: 0.10157
[32m[0906 19-50-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03279, current rewards: 148.72629, mean: 0.10187
[32m[0906 19-50-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03281, current rewards: 154.23555, mean: 0.10214
[32m[0906 19-50-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03283, current rewards: 159.74062, mean: 0.10240
[32m[0906 19-50-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03285, current rewards: 165.25455, mean: 0.10264
[32m[0906 19-50-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03286, current rewards: 170.66992, mean: 0.10281
[32m[0906 19-50-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03288, current rewards: 174.06351, mean: 0.10179
[32m[0906 19-50-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03290, current rewards: 179.44310, mean: 0.10196
[32m[0906 19-50-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03292, current rewards: 184.81603, mean: 0.10211
[32m[0906 19-50-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03293, current rewards: 190.19475, mean: 0.10226
[32m[0906 19-50-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03295, current rewards: 195.57782, mean: 0.10240
[32m[0906 19-50-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03297, current rewards: 200.95812, mean: 0.10253
[32m[0906 19-50-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03299, current rewards: 203.34656, mean: 0.10117
[32m[0906 19-50-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03300, current rewards: 208.90839, mean: 0.10141
[32m[0906 19-50-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03301, current rewards: 214.59010, mean: 0.10170
[32m[0906 19-50-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03302, current rewards: 220.16679, mean: 0.10193
[32m[0906 19-50-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03303, current rewards: 225.74905, mean: 0.10215
[32m[0906 19-50-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03304, current rewards: 229.28112, mean: 0.10145
[32m[0906 19-50-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03304, current rewards: 234.79131, mean: 0.10164
[32m[0906 19-50-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03305, current rewards: 240.29332, mean: 0.10182
[32m[0906 19-50-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03306, current rewards: 245.80691, mean: 0.10199
[32m[0906 19-50-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03307, current rewards: 251.31640, mean: 0.10216
[32m[0906 19-50-46 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 19-50-46 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-50-46 @MBExp.py:227][0m Rewards obtained: [255.5471441788861], Lows: [6], Highs: [5], Total time: 9583.751563000002
[32m[0906 19-54-33 @MBExp.py:144][0m ####################################################################
[32m[0906 19-54-33 @MBExp.py:145][0m Starting training iteration 112.
[32m[0906 19-54-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03273, current rewards: -1.14973, mean: -0.11497
[32m[0906 19-54-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03328, current rewards: 4.15600, mean: 0.06927
[32m[0906 19-54-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03264, current rewards: 9.59954, mean: 0.08727
[32m[0906 19-54-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03263, current rewards: 15.04643, mean: 0.09404
[32m[0906 19-54-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03259, current rewards: 20.48864, mean: 0.09756
[32m[0906 19-54-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03256, current rewards: 25.93118, mean: 0.09974
[32m[0906 19-54-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03254, current rewards: 31.37259, mean: 0.10120
[32m[0906 19-54-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03252, current rewards: 36.81825, mean: 0.10227
[32m[0906 19-54-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03253, current rewards: 42.26263, mean: 0.10308
[32m[0906 19-54-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03251, current rewards: 47.77455, mean: 0.10386
[32m[0906 19-54-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03252, current rewards: 53.24124, mean: 0.10439
[32m[0906 19-54-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03255, current rewards: 58.70838, mean: 0.10484
[32m[0906 19-54-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03253, current rewards: 64.17574, mean: 0.10521
[32m[0906 19-54-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03253, current rewards: 69.64046, mean: 0.10552
[32m[0906 19-54-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03254, current rewards: 75.10505, mean: 0.10578
[32m[0906 19-54-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03251, current rewards: 80.56963, mean: 0.10601
[32m[0906 19-54-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03250, current rewards: 86.03832, mean: 0.10622
[32m[0906 19-55-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03248, current rewards: 91.54438, mean: 0.10645
[32m[0906 19-55-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03249, current rewards: 97.12356, mean: 0.10673
[32m[0906 19-55-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03249, current rewards: 102.69550, mean: 0.10697
[32m[0906 19-55-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03249, current rewards: 108.26405, mean: 0.10719
[32m[0906 19-55-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03249, current rewards: 113.83571, mean: 0.10739
[32m[0906 19-55-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03248, current rewards: 119.40850, mean: 0.10758
[32m[0906 19-55-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03251, current rewards: 124.98404, mean: 0.10774
[32m[0906 19-55-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03254, current rewards: 130.55810, mean: 0.10790
[32m[0906 19-55-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03258, current rewards: 136.28642, mean: 0.10816
[32m[0906 19-55-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03262, current rewards: 141.91518, mean: 0.10833
[32m[0906 19-55-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03267, current rewards: 147.54613, mean: 0.10849
[32m[0906 19-55-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03269, current rewards: 151.19442, mean: 0.10723
[32m[0906 19-55-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03272, current rewards: 157.00148, mean: 0.10754
[32m[0906 19-55-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03274, current rewards: 162.80890, mean: 0.10782
[32m[0906 19-55-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03276, current rewards: 168.61432, mean: 0.10809
[32m[0906 19-55-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03279, current rewards: 174.41974, mean: 0.10834
[32m[0906 19-55-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03281, current rewards: 180.20314, mean: 0.10856
[32m[0906 19-55-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03282, current rewards: 185.99169, mean: 0.10877
[32m[0906 19-55-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03285, current rewards: 191.77688, mean: 0.10896
[32m[0906 19-55-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03287, current rewards: 195.61896, mean: 0.10808
[32m[0906 19-55-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03289, current rewards: 201.51543, mean: 0.10834
[32m[0906 19-55-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03290, current rewards: 207.41831, mean: 0.10860
[32m[0906 19-55-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03292, current rewards: 213.31414, mean: 0.10883
[32m[0906 19-55-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03293, current rewards: 219.21124, mean: 0.10906
[32m[0906 19-55-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03295, current rewards: 224.95343, mean: 0.10920
[32m[0906 19-55-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03297, current rewards: 228.71558, mean: 0.10840
[32m[0906 19-55-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03298, current rewards: 234.35377, mean: 0.10850
[32m[0906 19-55-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03299, current rewards: 239.99184, mean: 0.10859
[32m[0906 19-55-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03300, current rewards: 245.62738, mean: 0.10868
[32m[0906 19-55-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03301, current rewards: 251.26080, mean: 0.10877
[32m[0906 19-55-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03303, current rewards: 256.89475, mean: 0.10885
[32m[0906 19-55-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03304, current rewards: 262.52591, mean: 0.10893
[32m[0906 19-55-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03305, current rewards: 268.16386, mean: 0.10901
[32m[0906 19-55-56 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 19-55-56 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-55-56 @MBExp.py:227][0m Rewards obtained: [272.6750455570896], Lows: [2], Highs: [4], Total time: 9667.183521
[32m[0906 19-59-46 @MBExp.py:144][0m ####################################################################
[32m[0906 19-59-46 @MBExp.py:145][0m Starting training iteration 113.
[32m[0906 19-59-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03248, current rewards: -0.03657, mean: -0.00366
[32m[0906 19-59-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03340, current rewards: 5.50184, mean: 0.09170
[32m[0906 19-59-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03348, current rewards: 11.04318, mean: 0.10039
[32m[0906 19-59-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03300, current rewards: 16.57799, mean: 0.10361
[32m[0906 19-59-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03299, current rewards: 22.11781, mean: 0.10532
[32m[0906 19-59-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03292, current rewards: 27.66045, mean: 0.10639
[32m[0906 19-59-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03278, current rewards: 33.20360, mean: 0.10711
[32m[0906 19-59-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03273, current rewards: 35.09298, mean: 0.09748
[32m[0906 19-59-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03272, current rewards: 40.57163, mean: 0.09896
[32m[0906 20-00-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03272, current rewards: 46.09212, mean: 0.10020
[32m[0906 20-00-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03271, current rewards: 51.61373, mean: 0.10120
[32m[0906 20-00-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03271, current rewards: 57.13507, mean: 0.10203
[32m[0906 20-00-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03272, current rewards: 62.65561, mean: 0.10271
[32m[0906 20-00-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03270, current rewards: 68.17867, mean: 0.10330
[32m[0906 20-00-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03268, current rewards: 73.69796, mean: 0.10380
[32m[0906 20-00-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03267, current rewards: 78.07289, mean: 0.10273
[32m[0906 20-00-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03265, current rewards: 83.40539, mean: 0.10297
[32m[0906 20-00-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03264, current rewards: 88.92465, mean: 0.10340
[32m[0906 20-00-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03263, current rewards: 94.44988, mean: 0.10379
[32m[0906 20-00-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03263, current rewards: 99.97325, mean: 0.10414
[32m[0906 20-00-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03262, current rewards: 105.50238, mean: 0.10446
[32m[0906 20-00-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03262, current rewards: 111.02490, mean: 0.10474
[32m[0906 20-00-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03263, current rewards: 112.37546, mean: 0.10124
[32m[0906 20-00-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03265, current rewards: 117.90605, mean: 0.10164
[32m[0906 20-00-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03268, current rewards: 123.58425, mean: 0.10214
[32m[0906 20-00-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03271, current rewards: 129.11897, mean: 0.10248
[32m[0906 20-00-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03275, current rewards: 134.65483, mean: 0.10279
[32m[0906 20-00-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03279, current rewards: 140.18737, mean: 0.10308
[32m[0906 20-00-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03282, current rewards: 145.72100, mean: 0.10335
[32m[0906 20-00-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03284, current rewards: 151.25424, mean: 0.10360
[32m[0906 20-00-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03286, current rewards: 156.78736, mean: 0.10383
[32m[0906 20-00-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03288, current rewards: 162.32402, mean: 0.10405
[32m[0906 20-00-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03290, current rewards: 167.92853, mean: 0.10430
[32m[0906 20-00-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03292, current rewards: 173.63772, mean: 0.10460
[32m[0906 20-00-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03294, current rewards: 178.74860, mean: 0.10453
[32m[0906 20-00-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03296, current rewards: 184.27545, mean: 0.10470
[32m[0906 20-00-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03298, current rewards: 189.80369, mean: 0.10486
[32m[0906 20-00-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03300, current rewards: 195.33265, mean: 0.10502
[32m[0906 20-00-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03302, current rewards: 200.86300, mean: 0.10516
[32m[0906 20-00-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03303, current rewards: 202.47947, mean: 0.10331
[32m[0906 20-00-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03304, current rewards: 211.26814, mean: 0.10511
[32m[0906 20-00-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03305, current rewards: 216.66286, mean: 0.10518
[32m[0906 20-00-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03306, current rewards: 220.09329, mean: 0.10431
[32m[0906 20-00-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03308, current rewards: 223.52373, mean: 0.10348
[32m[0906 20-00-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03308, current rewards: 226.95416, mean: 0.10269
[32m[0906 20-01-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03309, current rewards: 230.38459, mean: 0.10194
[32m[0906 20-01-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03311, current rewards: 233.81502, mean: 0.10122
[32m[0906 20-01-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03312, current rewards: 237.24546, mean: 0.10053
[32m[0906 20-01-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03313, current rewards: 240.67589, mean: 0.09987
[32m[0906 20-01-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03314, current rewards: 244.58360, mean: 0.09942
[32m[0906 20-01-09 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 20-01-09 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-01-09 @MBExp.py:227][0m Rewards obtained: [248.408090486274], Lows: [6], Highs: [3], Total time: 9750.831363000001
[32m[0906 20-05-00 @MBExp.py:144][0m ####################################################################
[32m[0906 20-05-00 @MBExp.py:145][0m Starting training iteration 114.
[32m[0906 20-05-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03439, current rewards: -0.03113, mean: -0.00311
[32m[0906 20-05-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03359, current rewards: 5.54297, mean: 0.09238
[32m[0906 20-05-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03353, current rewards: 11.11376, mean: 0.10103
[32m[0906 20-05-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03308, current rewards: 16.68836, mean: 0.10430
[32m[0906 20-05-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03296, current rewards: 22.25753, mean: 0.10599
[32m[0906 20-05-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03285, current rewards: 27.83074, mean: 0.10704
[32m[0906 20-05-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03274, current rewards: 33.40468, mean: 0.10776
[32m[0906 20-05-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03275, current rewards: 38.86357, mean: 0.10795
[32m[0906 20-05-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03273, current rewards: 44.38366, mean: 0.10825
[32m[0906 20-05-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03271, current rewards: 49.92995, mean: 0.10854
[32m[0906 20-05-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03270, current rewards: 55.47407, mean: 0.10877
[32m[0906 20-05-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03272, current rewards: 58.90517, mean: 0.10519
[32m[0906 20-05-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03272, current rewards: 64.59911, mean: 0.10590
[32m[0906 20-05-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03271, current rewards: 70.42885, mean: 0.10671
[32m[0906 20-05-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03270, current rewards: 76.25929, mean: 0.10741
[32m[0906 20-05-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03271, current rewards: 82.08814, mean: 0.10801
[32m[0906 20-05-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03270, current rewards: 87.77499, mean: 0.10836
[32m[0906 20-05-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03268, current rewards: 93.56485, mean: 0.10880
[32m[0906 20-05-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03266, current rewards: 99.35477, mean: 0.10918
[32m[0906 20-05-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03264, current rewards: 105.14979, mean: 0.10953
[32m[0906 20-05-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03264, current rewards: 110.94873, mean: 0.10985
[32m[0906 20-05-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03263, current rewards: 116.74005, mean: 0.11013
[32m[0906 20-05-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03262, current rewards: 122.53418, mean: 0.11039
[32m[0906 20-05-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03263, current rewards: 128.32937, mean: 0.11063
[32m[0906 20-05-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03267, current rewards: 134.15623, mean: 0.11087
[32m[0906 20-05-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03270, current rewards: 139.96126, mean: 0.11108
[32m[0906 20-05-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03273, current rewards: 145.76140, mean: 0.11127
[32m[0906 20-05-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03276, current rewards: 151.56537, mean: 0.11145
[32m[0906 20-05-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03279, current rewards: 155.90459, mean: 0.11057
[32m[0906 20-05-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03282, current rewards: 161.39150, mean: 0.11054
[32m[0906 20-05-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03285, current rewards: 166.87998, mean: 0.11052
[32m[0906 20-05-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03286, current rewards: 172.36625, mean: 0.11049
[32m[0906 20-05-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03288, current rewards: 177.84862, mean: 0.11046
[32m[0906 20-05-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03290, current rewards: 183.33504, mean: 0.11044
[32m[0906 20-05-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03293, current rewards: 188.81972, mean: 0.11042
[32m[0906 20-05-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03294, current rewards: 194.30446, mean: 0.11040
[32m[0906 20-06-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03295, current rewards: 199.78886, mean: 0.11038
[32m[0906 20-06-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03297, current rewards: 205.27645, mean: 0.11036
[32m[0906 20-06-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03299, current rewards: 209.69431, mean: 0.10979
[32m[0906 20-06-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03300, current rewards: 215.18118, mean: 0.10979
[32m[0906 20-06-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03302, current rewards: 220.96389, mean: 0.10993
[32m[0906 20-06-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03303, current rewards: 226.47655, mean: 0.10994
[32m[0906 20-06-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03304, current rewards: 231.98333, mean: 0.10994
[32m[0906 20-06-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03306, current rewards: 237.48915, mean: 0.10995
[32m[0906 20-06-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03307, current rewards: 242.06971, mean: 0.10953
[32m[0906 20-06-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03307, current rewards: 247.62238, mean: 0.10957
[32m[0906 20-06-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03309, current rewards: 253.17762, mean: 0.10960
[32m[0906 20-06-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03310, current rewards: 258.73597, mean: 0.10963
[32m[0906 20-06-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03311, current rewards: 264.20789, mean: 0.10963
[32m[0906 20-06-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03312, current rewards: 269.70819, mean: 0.10964
[32m[0906 20-06-23 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 20-06-23 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-06-24 @MBExp.py:227][0m Rewards obtained: [274.1468804963138], Lows: [1], Highs: [4], Total time: 9834.415536
[32m[0906 20-10-16 @MBExp.py:144][0m ####################################################################
[32m[0906 20-10-16 @MBExp.py:145][0m Starting training iteration 115.
[32m[0906 20-10-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03252, current rewards: -1.06869, mean: -0.10687
[32m[0906 20-10-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03328, current rewards: 4.45825, mean: 0.07430
[32m[0906 20-10-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03317, current rewards: 9.98509, mean: 0.09077
[32m[0906 20-10-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03285, current rewards: 15.51106, mean: 0.09694
[32m[0906 20-10-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03271, current rewards: 21.04351, mean: 0.10021
[32m[0906 20-10-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03264, current rewards: 26.57447, mean: 0.10221
[32m[0906 20-10-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03262, current rewards: 32.09893, mean: 0.10354
[32m[0906 20-10-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03260, current rewards: 37.63226, mean: 0.10453
[32m[0906 20-10-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03258, current rewards: 43.16424, mean: 0.10528
[32m[0906 20-10-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03259, current rewards: 48.69870, mean: 0.10587
[32m[0906 20-10-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03257, current rewards: 54.22664, mean: 0.10633
[32m[0906 20-10-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03256, current rewards: 59.75701, mean: 0.10671
[32m[0906 20-10-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03257, current rewards: 65.29100, mean: 0.10703
[32m[0906 20-10-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03257, current rewards: 70.82060, mean: 0.10730
[32m[0906 20-10-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03255, current rewards: 71.21721, mean: 0.10031
[32m[0906 20-10-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03256, current rewards: 76.82290, mean: 0.10108
[32m[0906 20-10-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03254, current rewards: 82.38044, mean: 0.10170
[32m[0906 20-10-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03253, current rewards: 87.94327, mean: 0.10226
[32m[0906 20-10-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03252, current rewards: 93.49620, mean: 0.10274
[32m[0906 20-10-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03252, current rewards: 99.05498, mean: 0.10318
[32m[0906 20-10-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03253, current rewards: 104.61134, mean: 0.10358
[32m[0906 20-10-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03255, current rewards: 110.16876, mean: 0.10393
[32m[0906 20-10-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03253, current rewards: 115.72591, mean: 0.10426
[32m[0906 20-10-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03254, current rewards: 121.32602, mean: 0.10459
[32m[0906 20-10-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03257, current rewards: 126.89150, mean: 0.10487
[32m[0906 20-10-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03261, current rewards: 132.46154, mean: 0.10513
[32m[0906 20-10-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03265, current rewards: 135.92028, mean: 0.10376
[32m[0906 20-11-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03267, current rewards: 141.44006, mean: 0.10400
[32m[0906 20-11-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03270, current rewards: 146.97934, mean: 0.10424
[32m[0906 20-11-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03273, current rewards: 152.51666, mean: 0.10446
[32m[0906 20-11-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03275, current rewards: 158.05815, mean: 0.10467
[32m[0906 20-11-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03277, current rewards: 163.60667, mean: 0.10488
[32m[0906 20-11-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03280, current rewards: 169.14811, mean: 0.10506
[32m[0906 20-11-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03281, current rewards: 174.68683, mean: 0.10523
[32m[0906 20-11-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03283, current rewards: 180.22574, mean: 0.10540
[32m[0906 20-11-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03284, current rewards: 183.66582, mean: 0.10436
[32m[0906 20-11-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03286, current rewards: 189.24064, mean: 0.10455
[32m[0906 20-11-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03288, current rewards: 194.81341, mean: 0.10474
[32m[0906 20-11-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03290, current rewards: 200.38792, mean: 0.10492
[32m[0906 20-11-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03291, current rewards: 205.80696, mean: 0.10500
[32m[0906 20-11-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03292, current rewards: 211.37725, mean: 0.10516
[32m[0906 20-11-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03294, current rewards: 216.95377, mean: 0.10532
[32m[0906 20-11-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03296, current rewards: 222.52655, mean: 0.10546
[32m[0906 20-11-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03297, current rewards: 227.15834, mean: 0.10517
[32m[0906 20-11-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03299, current rewards: 232.70149, mean: 0.10529
[32m[0906 20-11-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03300, current rewards: 238.24059, mean: 0.10542
[32m[0906 20-11-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03301, current rewards: 243.78819, mean: 0.10554
[32m[0906 20-11-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03302, current rewards: 249.34119, mean: 0.10565
[32m[0906 20-11-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03304, current rewards: 254.87295, mean: 0.10576
[32m[0906 20-11-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03305, current rewards: 260.41047, mean: 0.10586
[32m[0906 20-11-39 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 20-11-39 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-11-39 @MBExp.py:227][0m Rewards obtained: [264.84500279688604], Lows: [4], Highs: [4], Total time: 9917.84259
[32m[0906 20-15-34 @MBExp.py:144][0m ####################################################################
[32m[0906 20-15-34 @MBExp.py:145][0m Starting training iteration 116.
[32m[0906 20-15-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03248, current rewards: -1.09137, mean: -0.10914
[32m[0906 20-15-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03316, current rewards: 4.42097, mean: 0.07368
[32m[0906 20-15-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03333, current rewards: 9.93219, mean: 0.09029
[32m[0906 20-15-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03286, current rewards: 15.44088, mean: 0.09651
[32m[0906 20-15-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03279, current rewards: 20.95127, mean: 0.09977
[32m[0906 20-15-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03273, current rewards: 26.46260, mean: 0.10178
[32m[0906 20-15-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03269, current rewards: 31.97081, mean: 0.10313
[32m[0906 20-15-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03262, current rewards: 32.82255, mean: 0.09117
[32m[0906 20-15-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03261, current rewards: 38.35134, mean: 0.09354
[32m[0906 20-15-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03257, current rewards: 43.88198, mean: 0.09540
[32m[0906 20-15-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03255, current rewards: 49.40806, mean: 0.09688
[32m[0906 20-15-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03256, current rewards: 54.93101, mean: 0.09809
[32m[0906 20-15-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03256, current rewards: 60.46392, mean: 0.09912
[32m[0906 20-15-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03257, current rewards: 65.99232, mean: 0.09999
[32m[0906 20-15-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03257, current rewards: 65.62818, mean: 0.09243
[32m[0906 20-15-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03256, current rewards: 71.16008, mean: 0.09363
[32m[0906 20-16-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03256, current rewards: 76.68791, mean: 0.09468
[32m[0906 20-16-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03254, current rewards: 82.21527, mean: 0.09560
[32m[0906 20-16-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03254, current rewards: 87.74094, mean: 0.09642
[32m[0906 20-16-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03255, current rewards: 93.26809, mean: 0.09715
[32m[0906 20-16-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03255, current rewards: 98.79608, mean: 0.09782
[32m[0906 20-16-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03253, current rewards: 104.32306, mean: 0.09842
[32m[0906 20-16-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03254, current rewards: 109.69121, mean: 0.09882
[32m[0906 20-16-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03254, current rewards: 115.22967, mean: 0.09934
[32m[0906 20-16-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03255, current rewards: 120.76888, mean: 0.09981
[32m[0906 20-16-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03257, current rewards: 126.30786, mean: 0.10024
[32m[0906 20-16-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03262, current rewards: 125.52601, mean: 0.09582
[32m[0906 20-16-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03264, current rewards: 131.06914, mean: 0.09637
[32m[0906 20-16-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03268, current rewards: 136.61213, mean: 0.09689
[32m[0906 20-16-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03271, current rewards: 142.15528, mean: 0.09737
[32m[0906 20-16-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03274, current rewards: 147.58333, mean: 0.09774
[32m[0906 20-16-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03277, current rewards: 153.09544, mean: 0.09814
[32m[0906 20-16-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03278, current rewards: 154.41750, mean: 0.09591
[32m[0906 20-16-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03280, current rewards: 159.93280, mean: 0.09635
[32m[0906 20-16-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03283, current rewards: 165.45368, mean: 0.09676
[32m[0906 20-16-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03285, current rewards: 170.97633, mean: 0.09715
[32m[0906 20-16-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03286, current rewards: 176.50006, mean: 0.09751
[32m[0906 20-16-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03288, current rewards: 182.01936, mean: 0.09786
[32m[0906 20-16-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03290, current rewards: 187.47383, mean: 0.09815
[32m[0906 20-16-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03292, current rewards: 192.98470, mean: 0.09846
[32m[0906 20-16-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03294, current rewards: 198.51702, mean: 0.09876
[32m[0906 20-16-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03295, current rewards: 204.04300, mean: 0.09905
[32m[0906 20-16-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03297, current rewards: 209.56725, mean: 0.09932
[32m[0906 20-16-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03298, current rewards: 212.98479, mean: 0.09860
[32m[0906 20-16-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03300, current rewards: 218.51886, mean: 0.09888
[32m[0906 20-16-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03301, current rewards: 224.05244, mean: 0.09914
[32m[0906 20-16-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03303, current rewards: 229.58900, mean: 0.09939
[32m[0906 20-16-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03304, current rewards: 235.11756, mean: 0.09963
[32m[0906 20-16-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03305, current rewards: 240.65940, mean: 0.09986
[32m[0906 20-16-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03306, current rewards: 246.19292, mean: 0.10008
[32m[0906 20-16-57 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 20-16-57 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-16-57 @MBExp.py:227][0m Rewards obtained: [250.61869307743743], Lows: [10], Highs: [5], Total time: 10001.30103
[32m[0906 20-20-54 @MBExp.py:144][0m ####################################################################
[32m[0906 20-20-54 @MBExp.py:145][0m Starting training iteration 117.
[32m[0906 20-20-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03241, current rewards: -1.11250, mean: -0.11125
[32m[0906 20-20-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03311, current rewards: 4.56351, mean: 0.07606
[32m[0906 20-20-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03284, current rewards: 10.09588, mean: 0.09178
[32m[0906 20-20-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03276, current rewards: 15.62602, mean: 0.09766
[32m[0906 20-21-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03271, current rewards: 21.06224, mean: 0.10030
[32m[0906 20-21-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03265, current rewards: 26.58360, mean: 0.10224
[32m[0906 20-21-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03264, current rewards: 32.11785, mean: 0.10361
[32m[0906 20-21-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03261, current rewards: 37.65487, mean: 0.10460
[32m[0906 20-21-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03257, current rewards: 43.19400, mean: 0.10535
[32m[0906 20-21-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03257, current rewards: 45.01042, mean: 0.09785
[32m[0906 20-21-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03258, current rewards: 50.53188, mean: 0.09908
[32m[0906 20-21-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03259, current rewards: 56.05432, mean: 0.10010
[32m[0906 20-21-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03259, current rewards: 61.57148, mean: 0.10094
[32m[0906 20-21-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03260, current rewards: 66.96035, mean: 0.10146
[32m[0906 20-21-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03261, current rewards: 72.49447, mean: 0.10210
[32m[0906 20-21-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03261, current rewards: 78.02892, mean: 0.10267
[32m[0906 20-21-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03262, current rewards: 83.56676, mean: 0.10317
[32m[0906 20-21-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03260, current rewards: 89.10090, mean: 0.10361
[32m[0906 20-21-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03259, current rewards: 93.45922, mean: 0.10270
[32m[0906 20-21-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03259, current rewards: 98.99289, mean: 0.10312
[32m[0906 20-21-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03257, current rewards: 104.51701, mean: 0.10348
[32m[0906 20-21-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03258, current rewards: 110.10739, mean: 0.10387
[32m[0906 20-21-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03258, current rewards: 115.72136, mean: 0.10425
[32m[0906 20-21-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03257, current rewards: 121.24724, mean: 0.10452
[32m[0906 20-21-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03256, current rewards: 122.77131, mean: 0.10146
[32m[0906 20-21-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03261, current rewards: 128.32319, mean: 0.10184
[32m[0906 20-21-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03265, current rewards: 133.87274, mean: 0.10219
[32m[0906 20-21-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03267, current rewards: 139.41976, mean: 0.10251
[32m[0906 20-21-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03270, current rewards: 143.92891, mean: 0.10208
[32m[0906 20-21-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03272, current rewards: 149.45881, mean: 0.10237
[32m[0906 20-21-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03275, current rewards: 154.84846, mean: 0.10255
[32m[0906 20-21-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03277, current rewards: 160.38859, mean: 0.10281
[32m[0906 20-21-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03278, current rewards: 165.92053, mean: 0.10306
[32m[0906 20-21-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03281, current rewards: 171.46213, mean: 0.10329
[32m[0906 20-21-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03283, current rewards: 176.99955, mean: 0.10351
[32m[0906 20-21-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03284, current rewards: 182.53569, mean: 0.10371
[32m[0906 20-21-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03285, current rewards: 188.06547, mean: 0.10390
[32m[0906 20-21-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03287, current rewards: 193.60444, mean: 0.10409
[32m[0906 20-21-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03290, current rewards: 199.24586, mean: 0.10432
[32m[0906 20-21-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03292, current rewards: 202.70945, mean: 0.10342
[32m[0906 20-22-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03294, current rewards: 208.24435, mean: 0.10360
[32m[0906 20-22-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03295, current rewards: 213.78081, mean: 0.10378
[32m[0906 20-22-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03296, current rewards: 219.31825, mean: 0.10394
[32m[0906 20-22-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03297, current rewards: 224.85344, mean: 0.10410
[32m[0906 20-22-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03297, current rewards: 230.39245, mean: 0.10425
[32m[0906 20-22-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03299, current rewards: 235.93108, mean: 0.10439
[32m[0906 20-22-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03300, current rewards: 241.50469, mean: 0.10455
[32m[0906 20-22-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03301, current rewards: 247.04259, mean: 0.10468
[32m[0906 20-22-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03302, current rewards: 251.54100, mean: 0.10437
[32m[0906 20-22-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03303, current rewards: 257.07177, mean: 0.10450
[32m[0906 20-22-17 @Agent.py:117][0m Average action selection time: 0.0330
[32m[0906 20-22-17 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-22-17 @MBExp.py:227][0m Rewards obtained: [261.49981507915766], Lows: [5], Highs: [5], Total time: 10084.682308000001
[32m[0906 20-26-16 @MBExp.py:144][0m ####################################################################
[32m[0906 20-26-16 @MBExp.py:145][0m Starting training iteration 118.
[32m[0906 20-26-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03228, current rewards: -0.08234, mean: -0.00823
[32m[0906 20-26-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03330, current rewards: 5.53585, mean: 0.09226
[32m[0906 20-26-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03300, current rewards: 11.15390, mean: 0.10140
[32m[0906 20-26-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03283, current rewards: 16.77023, mean: 0.10481
[32m[0906 20-26-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03278, current rewards: 22.38992, mean: 0.10662
[32m[0906 20-26-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03272, current rewards: 27.65146, mean: 0.10635
[32m[0906 20-26-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03269, current rewards: 33.18423, mean: 0.10705
[32m[0906 20-26-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03269, current rewards: 38.72393, mean: 0.10757
[32m[0906 20-26-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03266, current rewards: 44.25806, mean: 0.10795
[32m[0906 20-26-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03264, current rewards: 49.79480, mean: 0.10825
[32m[0906 20-26-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03262, current rewards: 55.33705, mean: 0.10850
[32m[0906 20-26-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03262, current rewards: 60.87570, mean: 0.10871
[32m[0906 20-26-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03262, current rewards: 66.41025, mean: 0.10887
[32m[0906 20-26-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03259, current rewards: 72.03505, mean: 0.10914
[32m[0906 20-26-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03259, current rewards: 76.97176, mean: 0.10841
[32m[0906 20-26-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03258, current rewards: 82.71881, mean: 0.10884
[32m[0906 20-26-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03258, current rewards: 88.46911, mean: 0.10922
[32m[0906 20-26-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03260, current rewards: 94.21444, mean: 0.10955
[32m[0906 20-26-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03260, current rewards: 99.96481, mean: 0.10985
[32m[0906 20-26-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03260, current rewards: 105.71490, mean: 0.11012
[32m[0906 20-26-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03260, current rewards: 111.46180, mean: 0.11036
[32m[0906 20-26-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03260, current rewards: 113.52076, mean: 0.10710
[32m[0906 20-26-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03260, current rewards: 119.30845, mean: 0.10749
[32m[0906 20-26-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03261, current rewards: 125.14947, mean: 0.10789
[32m[0906 20-26-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03260, current rewards: 130.98726, mean: 0.10825
[32m[0906 20-26-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03262, current rewards: 136.83145, mean: 0.10860
[32m[0906 20-26-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03266, current rewards: 140.36984, mean: 0.10715
[32m[0906 20-27-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03269, current rewards: 145.88969, mean: 0.10727
[32m[0906 20-27-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03271, current rewards: 151.40335, mean: 0.10738
[32m[0906 20-27-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03274, current rewards: 156.92342, mean: 0.10748
[32m[0906 20-27-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03278, current rewards: 162.43776, mean: 0.10757
[32m[0906 20-27-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03281, current rewards: 167.95479, mean: 0.10766
[32m[0906 20-27-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03283, current rewards: 173.47347, mean: 0.10775
[32m[0906 20-27-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03285, current rewards: 178.99206, mean: 0.10783
[32m[0906 20-27-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03288, current rewards: 184.51124, mean: 0.10790
[32m[0906 20-27-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03290, current rewards: 190.03368, mean: 0.10797
[32m[0906 20-27-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03292, current rewards: 192.33180, mean: 0.10626
[32m[0906 20-27-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03295, current rewards: 195.66967, mean: 0.10520
[32m[0906 20-27-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03297, current rewards: 201.08598, mean: 0.10528
[32m[0906 20-27-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03297, current rewards: 206.61220, mean: 0.10541
[32m[0906 20-27-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03298, current rewards: 212.13596, mean: 0.10554
[32m[0906 20-27-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03300, current rewards: 217.66720, mean: 0.10566
[32m[0906 20-27-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03302, current rewards: 223.19738, mean: 0.10578
[32m[0906 20-27-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03304, current rewards: 228.72615, mean: 0.10589
[32m[0906 20-27-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03305, current rewards: 234.25740, mean: 0.10600
[32m[0906 20-27-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03306, current rewards: 239.78774, mean: 0.10610
[32m[0906 20-27-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03308, current rewards: 242.27527, mean: 0.10488
[32m[0906 20-27-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03309, current rewards: 247.92203, mean: 0.10505
[32m[0906 20-27-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03310, current rewards: 253.48863, mean: 0.10518
[32m[0906 20-27-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03311, current rewards: 259.05792, mean: 0.10531
[32m[0906 20-27-40 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 20-27-40 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-27-40 @MBExp.py:227][0m Rewards obtained: [263.5171901724327], Lows: [5], Highs: [6], Total time: 10168.276238000002
[32m[0906 20-31-41 @MBExp.py:144][0m ####################################################################
[32m[0906 20-31-41 @MBExp.py:145][0m Starting training iteration 119.
[32m[0906 20-31-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03234, current rewards: -1.29248, mean: -0.12925
[32m[0906 20-31-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03355, current rewards: 4.14840, mean: 0.06914
[32m[0906 20-31-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03363, current rewards: 9.59404, mean: 0.08722
[32m[0906 20-31-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03356, current rewards: 15.04104, mean: 0.09401
[32m[0906 20-31-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03352, current rewards: 20.49199, mean: 0.09758
[32m[0906 20-31-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03355, current rewards: 25.76001, mean: 0.09908
[32m[0906 20-31-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03350, current rewards: 27.88744, mean: 0.08996
[32m[0906 20-31-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03329, current rewards: 33.39561, mean: 0.09277
[32m[0906 20-31-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03323, current rewards: 38.93853, mean: 0.09497
[32m[0906 20-31-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03317, current rewards: 44.48306, mean: 0.09670
[32m[0906 20-31-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03311, current rewards: 50.02760, mean: 0.09809
[32m[0906 20-32-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03305, current rewards: 55.57736, mean: 0.09925
[32m[0906 20-32-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03301, current rewards: 61.12435, mean: 0.10020
[32m[0906 20-32-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03298, current rewards: 66.76887, mean: 0.10116
[32m[0906 20-32-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03296, current rewards: 72.36046, mean: 0.10192
[32m[0906 20-32-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03294, current rewards: 76.67132, mean: 0.10088
[32m[0906 20-32-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03292, current rewards: 82.16426, mean: 0.10144
[32m[0906 20-32-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03290, current rewards: 87.65919, mean: 0.10193
[32m[0906 20-32-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03288, current rewards: 93.14780, mean: 0.10236
[32m[0906 20-32-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03286, current rewards: 98.63760, mean: 0.10275
[32m[0906 20-32-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03285, current rewards: 104.12894, mean: 0.10310
[32m[0906 20-32-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03283, current rewards: 109.62165, mean: 0.10342
[32m[0906 20-32-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03283, current rewards: 115.23896, mean: 0.10382
[32m[0906 20-32-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03281, current rewards: 120.76271, mean: 0.10411
[32m[0906 20-32-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03280, current rewards: 126.28622, mean: 0.10437
[32m[0906 20-32-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03282, current rewards: 129.69008, mean: 0.10293
[32m[0906 20-32-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03284, current rewards: 135.24764, mean: 0.10324
[32m[0906 20-32-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03285, current rewards: 140.80108, mean: 0.10353
[32m[0906 20-32-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03287, current rewards: 146.35943, mean: 0.10380
[32m[0906 20-32-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03289, current rewards: 151.91596, mean: 0.10405
[32m[0906 20-32-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03291, current rewards: 157.38443, mean: 0.10423
[32m[0906 20-32-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03294, current rewards: 162.92579, mean: 0.10444
[32m[0906 20-32-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03295, current rewards: 168.46624, mean: 0.10464
[32m[0906 20-32-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03296, current rewards: 174.00562, mean: 0.10482
[32m[0906 20-32-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03298, current rewards: 179.55019, mean: 0.10500
[32m[0906 20-32-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03299, current rewards: 182.71473, mean: 0.10382
[32m[0906 20-32-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03300, current rewards: 187.99422, mean: 0.10386
[32m[0906 20-32-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03301, current rewards: 193.27016, mean: 0.10391
[32m[0906 20-32-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03302, current rewards: 199.26046, mean: 0.10432
[32m[0906 20-32-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03303, current rewards: 207.56058, mean: 0.10590
[32m[0906 20-32-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03304, current rewards: 215.86070, mean: 0.10739
[32m[0906 20-32-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03305, current rewards: 224.16082, mean: 0.10882
[32m[0906 20-32-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03306, current rewards: 232.46094, mean: 0.11017
[32m[0906 20-32-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03307, current rewards: 240.76106, mean: 0.11146
[32m[0906 20-32-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03308, current rewards: 228.07314, mean: 0.10320
[32m[0906 20-32-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03309, current rewards: 178.07314, mean: 0.07879
[32m[0906 20-32-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03309, current rewards: 128.07314, mean: 0.05544
[32m[0906 20-33-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03310, current rewards: 78.07314, mean: 0.03308
[32m[0906 20-33-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03311, current rewards: 28.07314, mean: 0.01165
[32m[0906 20-33-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03312, current rewards: -21.92686, mean: -0.00891
[32m[0906 20-33-04 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 20-33-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-33-05 @MBExp.py:227][0m Rewards obtained: [-61.92686472980233], Lows: [3], Highs: [312], Total time: 10251.891406000002
[32m[0906 20-36-59 @MBExp.py:144][0m ####################################################################
[32m[0906 20-36-59 @MBExp.py:145][0m Starting training iteration 120.
[32m[0906 20-36-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03022, current rewards: -0.08592, mean: -0.00859
[32m[0906 20-37-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02999, current rewards: 5.53078, mean: 0.09218
[32m[0906 20-37-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03010, current rewards: 10.99089, mean: 0.09992
[32m[0906 20-37-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03006, current rewards: 16.45333, mean: 0.10283
[32m[0906 20-37-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03005, current rewards: 21.91252, mean: 0.10435
[32m[0906 20-37-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03006, current rewards: 27.30628, mean: 0.10502
[32m[0906 20-37-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02956, current rewards: 32.77389, mean: 0.10572
[32m[0906 20-37-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02906, current rewards: 38.24267, mean: 0.10623
[32m[0906 20-37-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02869, current rewards: 43.70819, mean: 0.10661
[32m[0906 20-37-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02843, current rewards: 44.37101, mean: 0.09646
[32m[0906 20-37-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02818, current rewards: 49.87207, mean: 0.09779
[32m[0906 20-37-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02799, current rewards: 55.36583, mean: 0.09887
[32m[0906 20-37-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02783, current rewards: 60.86826, mean: 0.09978
[32m[0906 20-37-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02768, current rewards: 66.27096, mean: 0.10041
[32m[0906 20-37-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02757, current rewards: 71.76861, mean: 0.10108
[32m[0906 20-37-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02747, current rewards: 77.26551, mean: 0.10167
[32m[0906 20-37-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02737, current rewards: 82.76114, mean: 0.10217
[32m[0906 20-37-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02728, current rewards: 88.25531, mean: 0.10262
[32m[0906 20-37-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02720, current rewards: 93.75080, mean: 0.10302
[32m[0906 20-37-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02714, current rewards: 99.24421, mean: 0.10338
[32m[0906 20-37-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02708, current rewards: 100.56091, mean: 0.09957
[32m[0906 20-37-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02702, current rewards: 106.06232, mean: 0.10006
[32m[0906 20-37-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02697, current rewards: 111.58181, mean: 0.10052
[32m[0906 20-37-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02693, current rewards: 117.07995, mean: 0.10093
[32m[0906 20-37-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02689, current rewards: 122.58022, mean: 0.10131
[32m[0906 20-37-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02685, current rewards: 128.07424, mean: 0.10165
[32m[0906 20-37-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02686, current rewards: 133.57415, mean: 0.10196
[32m[0906 20-37-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02687, current rewards: 139.07433, mean: 0.10226
[32m[0906 20-37-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02687, current rewards: 144.57060, mean: 0.10253
[32m[0906 20-37-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02688, current rewards: 150.06887, mean: 0.10279
[32m[0906 20-37-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02689, current rewards: 155.68612, mean: 0.10310
[32m[0906 20-37-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02690, current rewards: 161.19834, mean: 0.10333
[32m[0906 20-37-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02692, current rewards: 165.58037, mean: 0.10284
[32m[0906 20-37-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02693, current rewards: 171.08975, mean: 0.10307
[32m[0906 20-37-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02693, current rewards: 176.60385, mean: 0.10328
[32m[0906 20-37-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02694, current rewards: 182.11874, mean: 0.10348
[32m[0906 20-37-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02694, current rewards: 187.63385, mean: 0.10367
[32m[0906 20-37-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02695, current rewards: 193.15156, mean: 0.10384
[32m[0906 20-37-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02695, current rewards: 198.66999, mean: 0.10402
[32m[0906 20-37-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02696, current rewards: 204.18579, mean: 0.10418
[32m[0906 20-37-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02696, current rewards: 209.69962, mean: 0.10433
[32m[0906 20-37-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02697, current rewards: 215.21594, mean: 0.10447
[32m[0906 20-37-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02698, current rewards: 214.49397, mean: 0.10166
[32m[0906 20-37-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02698, current rewards: 220.00581, mean: 0.10185
[32m[0906 20-37-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02699, current rewards: 225.51743, mean: 0.10204
[32m[0906 20-38-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02700, current rewards: 231.02869, mean: 0.10223
[32m[0906 20-38-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02701, current rewards: 236.47356, mean: 0.10237
[32m[0906 20-38-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02701, current rewards: 241.97352, mean: 0.10253
[32m[0906 20-38-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02701, current rewards: 247.47374, mean: 0.10269
[32m[0906 20-38-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02702, current rewards: 252.97392, mean: 0.10283
[32m[0906 20-38-07 @Agent.py:117][0m Average action selection time: 0.0270
[32m[0906 20-38-07 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-38-07 @MBExp.py:227][0m Rewards obtained: [257.37382273341075], Lows: [7], Highs: [3], Total time: 10320.171383000003
