[32m[0906 13-39-52 @logger.py:99][0m Log file set to /app/logs/dats-delay-1/zinc-coating-v0_1/Tuesday_06_September_2022_01-39PM.log
[32m[0906 13-39-52 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00002, current rewards: -17.00000, mean: -1.70000
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00001, current rewards: -85.19673, mean: -1.41995
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00001, current rewards: -154.09256, mean: -1.40084
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00001, current rewards: -229.14722, mean: -1.43217
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00001, current rewards: -293.15445, mean: -1.39597
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00001, current rewards: -350.03409, mean: -1.34628
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00001, current rewards: -414.02919, mean: -1.33558
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00001, current rewards: -469.98924, mean: -1.30553
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00001, current rewards: -529.84746, mean: -1.29231
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00001, current rewards: -591.65368, mean: -1.28620
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00001, current rewards: -644.62825, mean: -1.26398
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00001, current rewards: -701.13835, mean: -1.25203
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00001, current rewards: -765.43103, mean: -1.25480
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00001, current rewards: -817.28328, mean: -1.23831
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00001, current rewards: -869.98772, mean: -1.22533
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00001, current rewards: -921.23325, mean: -1.21215
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00001, current rewards: -974.25967, mean: -1.20279
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00001, current rewards: -1026.46651, mean: -1.19357
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00001, current rewards: -1086.68791, mean: -1.19416
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00001, current rewards: -1141.06606, mean: -1.18861
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00001, current rewards: -1194.64390, mean: -1.18282
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00001, current rewards: -1252.52034, mean: -1.18162
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00001, current rewards: -1302.76802, mean: -1.17366
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00001, current rewards: -1358.84227, mean: -1.17142
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00001, current rewards: -1417.86102, mean: -1.17179
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00001, current rewards: -1484.41223, mean: -1.17810
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00001, current rewards: -1545.49268, mean: -1.17977
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00001, current rewards: -1608.98163, mean: -1.18307
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00001, current rewards: -1672.92808, mean: -1.18647
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00001, current rewards: -1715.30166, mean: -1.17486
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00001, current rewards: -1770.34499, mean: -1.17241
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00001, current rewards: -1832.33573, mean: -1.17457
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00001, current rewards: -1884.12199, mean: -1.17026
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00001, current rewards: -1953.43299, mean: -1.17677
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00001, current rewards: -2007.67710, mean: -1.17408
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00001, current rewards: -2058.82477, mean: -1.16979
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00001, current rewards: -2122.92230, mean: -1.17289
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00001, current rewards: -2176.53273, mean: -1.17018
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00001, current rewards: -2229.93460, mean: -1.16751
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2285.31438, mean: -1.16598
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00001, current rewards: -2339.34202, mean: -1.16385
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2399.40459, mean: -1.16476
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2450.53720, mean: -1.16139
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2499.73237, mean: -1.15728
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2570.68630, mean: -1.16321
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2636.50416, mean: -1.16659
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2704.54145, mean: -1.17080
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2766.15303, mean: -1.17210
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2824.55461, mean: -1.17201
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2884.77397, mean: -1.17267
[32m[0906 13-39-52 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-39-52 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-39-54 @MBExp.py:144][0m ####################################################################
[32m[0906 13-39-54 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03703, current rewards: -13.38534, mean: -1.33853
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02671, current rewards: -113.38534, mean: -1.88976
[32m[0906 13-39-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02581, current rewards: -213.38534, mean: -1.93987
[32m[0906 13-39-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02554, current rewards: -313.38534, mean: -1.95866
[32m[0906 13-39-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02533, current rewards: -413.38534, mean: -1.96850
[32m[0906 13-40-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02519, current rewards: -513.38534, mean: -1.97456
[32m[0906 13-40-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02516, current rewards: -586.44843, mean: -1.89177
[32m[0906 13-40-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02511, current rewards: -582.57779, mean: -1.61827
[32m[0906 13-40-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02499, current rewards: -578.74369, mean: -1.41157
[32m[0906 13-40-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02490, current rewards: -575.66654, mean: -1.25145
[32m[0906 13-40-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02486, current rewards: -572.65735, mean: -1.12286
[32m[0906 13-40-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02486, current rewards: -569.64703, mean: -1.01723
[32m[0906 13-40-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02488, current rewards: -566.63749, mean: -0.92891
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02492, current rewards: -563.62666, mean: -0.85398
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02509, current rewards: -560.61519, mean: -0.78960
[32m[0906 13-40-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02531, current rewards: -557.60581, mean: -0.73369
[32m[0906 13-40-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02554, current rewards: -552.46270, mean: -0.68205
[32m[0906 13-40-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02573, current rewards: -575.37738, mean: -0.66904
[32m[0906 13-40-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02590, current rewards: -675.37738, mean: -0.74217
[32m[0906 13-40-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02607, current rewards: -775.37738, mean: -0.80768
[32m[0906 13-40-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02620, current rewards: -872.83623, mean: -0.86419
[32m[0906 13-40-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02633, current rewards: -972.83623, mean: -0.91777
[32m[0906 13-40-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02644, current rewards: -1072.83623, mean: -0.96652
[32m[0906 13-40-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02654, current rewards: -1172.83623, mean: -1.01107
[32m[0906 13-40-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02666, current rewards: -1272.83623, mean: -1.05193
[32m[0906 13-40-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02677, current rewards: -1372.83623, mean: -1.08955
[32m[0906 13-40-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02687, current rewards: -1472.83623, mean: -1.12430
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02695, current rewards: -1572.83623, mean: -1.15650
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02706, current rewards: -1616.42959, mean: -1.14640
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02721, current rewards: -1660.03908, mean: -1.13701
[32m[0906 13-40-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02739, current rewards: -1703.63215, mean: -1.12823
[32m[0906 13-40-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02757, current rewards: -1747.21977, mean: -1.12001
[32m[0906 13-40-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02775, current rewards: -1790.82815, mean: -1.11232
[32m[0906 13-40-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02790, current rewards: -1834.42661, mean: -1.10508
[32m[0906 13-40-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02805, current rewards: -1878.02567, mean: -1.09826
[32m[0906 13-40-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02819, current rewards: -1921.62058, mean: -1.09183
[32m[0906 13-40-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02832, current rewards: -1965.21334, mean: -1.08575
[32m[0906 13-40-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02844, current rewards: -2049.42531, mean: -1.10184
[32m[0906 13-40-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02856, current rewards: -2149.42531, mean: -1.12535
[32m[0906 13-40-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02867, current rewards: -2249.42531, mean: -1.14767
[32m[0906 13-40-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02877, current rewards: -2349.42531, mean: -1.16887
[32m[0906 13-40-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02888, current rewards: -2449.42531, mean: -1.18904
[32m[0906 13-40-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02897, current rewards: -2482.68883, mean: -1.17663
[32m[0906 13-40-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02905, current rewards: -2526.49197, mean: -1.16967
[32m[0906 13-40-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02914, current rewards: -2570.32353, mean: -1.16304
[32m[0906 13-41-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02922, current rewards: -2614.13142, mean: -1.15670
[32m[0906 13-41-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02930, current rewards: -2657.93801, mean: -1.15062
[32m[0906 13-41-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02937, current rewards: -2701.75193, mean: -1.14481
[32m[0906 13-41-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02944, current rewards: -2745.54024, mean: -1.13923
[32m[0906 13-41-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02952, current rewards: -2789.34553, mean: -1.13388
[32m[0906 13-41-08 @Agent.py:117][0m Average action selection time: 0.0296
[32m[0906 13-41-08 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-41-08 @MBExp.py:227][0m Rewards obtained: [-2824.1258797654314], Lows: [1493], Highs: [3], Total time: 74.501579
[32m[0906 13-41-12 @MBExp.py:144][0m ####################################################################
[32m[0906 13-41-12 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-41-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03263, current rewards: -2.43322, mean: -0.24332
[32m[0906 13-41-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03271, current rewards: 1.26495, mean: 0.02108
[32m[0906 13-41-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03272, current rewards: 4.92420, mean: 0.04477
[32m[0906 13-41-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03305, current rewards: 8.58139, mean: 0.05363
[32m[0906 13-41-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03302, current rewards: 12.24063, mean: 0.05829
[32m[0906 13-41-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03301, current rewards: 15.89978, mean: 0.06115
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03304, current rewards: 19.55759, mean: 0.06309
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03338, current rewards: 23.21634, mean: 0.06449
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03365, current rewards: 26.87195, mean: 0.06554
[32m[0906 13-41-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03385, current rewards: 31.88303, mean: 0.06931
[32m[0906 13-41-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03401, current rewards: 37.25328, mean: 0.07305
[32m[0906 13-41-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03416, current rewards: 42.62810, mean: 0.07612
[32m[0906 13-41-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03434, current rewards: 47.99457, mean: 0.07868
[32m[0906 13-41-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03443, current rewards: 52.37572, mean: 0.07936
[32m[0906 13-41-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03451, current rewards: 59.25459, mean: 0.08346
[32m[0906 13-41-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03461, current rewards: 66.13912, mean: 0.08703
[32m[0906 13-41-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03472, current rewards: 73.02368, mean: 0.09015
[32m[0906 13-41-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03480, current rewards: 79.57110, mean: 0.09252
[32m[0906 13-41-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03489, current rewards: 85.75435, mean: 0.09424
[32m[0906 13-41-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03496, current rewards: 91.93310, mean: 0.09576
[32m[0906 13-41-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03503, current rewards: 98.10678, mean: 0.09714
[32m[0906 13-41-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03509, current rewards: 104.28199, mean: 0.09838
[32m[0906 13-41-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03514, current rewards: 104.64089, mean: 0.09427
[32m[0906 13-41-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03518, current rewards: 111.27272, mean: 0.09592
[32m[0906 13-41-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03523, current rewards: 117.84803, mean: 0.09740
[32m[0906 13-41-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03527, current rewards: 124.71824, mean: 0.09898
[32m[0906 13-41-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03530, current rewards: 131.80540, mean: 0.10061
[32m[0906 13-42-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03533, current rewards: 138.89390, mean: 0.10213
[32m[0906 13-42-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03533, current rewards: 145.97898, mean: 0.10353
[32m[0906 13-42-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03533, current rewards: 151.89529, mean: 0.10404
[32m[0906 13-42-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03536, current rewards: 159.12642, mean: 0.10538
[32m[0906 13-42-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03539, current rewards: 166.36597, mean: 0.10664
[32m[0906 13-42-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03542, current rewards: 173.59523, mean: 0.10782
[32m[0906 13-42-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03544, current rewards: 178.58610, mean: 0.10758
[32m[0906 13-42-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03546, current rewards: 186.33729, mean: 0.10897
[32m[0906 13-42-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03548, current rewards: 194.10620, mean: 0.11029
[32m[0906 13-42-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03550, current rewards: 201.85950, mean: 0.11152
[32m[0906 13-42-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03552, current rewards: 209.60747, mean: 0.11269
[32m[0906 13-42-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03554, current rewards: 216.95301, mean: 0.11359
[32m[0906 13-42-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03556, current rewards: 222.40322, mean: 0.11347
[32m[0906 13-42-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03558, current rewards: 227.84904, mean: 0.11336
[32m[0906 13-42-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03559, current rewards: 233.19139, mean: 0.11320
[32m[0906 13-42-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03561, current rewards: 236.89781, mean: 0.11227
[32m[0906 13-42-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03563, current rewards: 236.93640, mean: 0.10969
[32m[0906 13-42-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03564, current rewards: 241.32898, mean: 0.10920
[32m[0906 13-42-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03566, current rewards: 245.72281, mean: 0.10873
[32m[0906 13-42-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03567, current rewards: 250.11110, mean: 0.10827
[32m[0906 13-42-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03569, current rewards: 254.50038, mean: 0.10784
[32m[0906 13-42-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03570, current rewards: 258.88962, mean: 0.10742
[32m[0906 13-42-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03571, current rewards: 263.28071, mean: 0.10702
[32m[0906 13-42-42 @Agent.py:117][0m Average action selection time: 0.0357
[32m[0906 13-42-42 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-42-42 @MBExp.py:227][0m Rewards obtained: [267.3280893713288], Lows: [5], Highs: [8], Total time: 164.412788
[32m[0906 13-42-48 @MBExp.py:144][0m ####################################################################
[32m[0906 13-42-48 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-42-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03617, current rewards: -1.32521, mean: -0.13252
[32m[0906 13-42-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03623, current rewards: 2.73862, mean: 0.04564
[32m[0906 13-42-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03614, current rewards: 6.80114, mean: 0.06183
[32m[0906 13-42-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03618, current rewards: 10.86401, mean: 0.06790
[32m[0906 13-42-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03622, current rewards: 14.92862, mean: 0.07109
[32m[0906 13-42-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03613, current rewards: 18.99358, mean: 0.07305
[32m[0906 13-43-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03600, current rewards: 23.06120, mean: 0.07439
[32m[0906 13-43-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03595, current rewards: 27.12823, mean: 0.07536
[32m[0906 13-43-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03591, current rewards: 31.23812, mean: 0.07619
[32m[0906 13-43-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03586, current rewards: 36.20705, mean: 0.07871
[32m[0906 13-43-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03582, current rewards: 41.18818, mean: 0.08076
[32m[0906 13-43-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03577, current rewards: 46.14789, mean: 0.08241
[32m[0906 13-43-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03567, current rewards: 51.30287, mean: 0.08410
[32m[0906 13-43-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03565, current rewards: 56.46022, mean: 0.08555
[32m[0906 13-43-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03565, current rewards: 61.61957, mean: 0.08679
[32m[0906 13-43-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03568, current rewards: 66.77802, mean: 0.08787
[32m[0906 13-43-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03572, current rewards: 71.93307, mean: 0.08881
[32m[0906 13-43-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03576, current rewards: 76.90025, mean: 0.08942
[32m[0906 13-43-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03579, current rewards: 81.70953, mean: 0.08979
[32m[0906 13-43-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03582, current rewards: 86.51522, mean: 0.09012
[32m[0906 13-43-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03583, current rewards: 87.42771, mean: 0.08656
[32m[0906 13-43-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03586, current rewards: 92.17748, mean: 0.08696
[32m[0906 13-43-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03587, current rewards: 96.92799, mean: 0.08732
[32m[0906 13-43-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03589, current rewards: 101.67643, mean: 0.08765
[32m[0906 13-43-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03591, current rewards: 106.42529, mean: 0.08795
[32m[0906 13-43-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03591, current rewards: 111.26084, mean: 0.08830
[32m[0906 13-43-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03590, current rewards: 116.19516, mean: 0.08870
[32m[0906 13-43-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03588, current rewards: 121.12620, mean: 0.08906
[32m[0906 13-43-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03587, current rewards: 126.05736, mean: 0.08940
[32m[0906 13-43-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03585, current rewards: 130.98846, mean: 0.08972
[32m[0906 13-43-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03586, current rewards: 135.91942, mean: 0.09001
[32m[0906 13-43-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03588, current rewards: 137.53198, mean: 0.08816
[32m[0906 13-43-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03589, current rewards: 142.53147, mean: 0.08853
[32m[0906 13-43-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03591, current rewards: 147.52666, mean: 0.08887
[32m[0906 13-43-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03592, current rewards: 152.10174, mean: 0.08895
[32m[0906 13-43-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03593, current rewards: 156.72677, mean: 0.08905
[32m[0906 13-43-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03594, current rewards: 161.35656, mean: 0.08915
[32m[0906 13-43-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03594, current rewards: 164.09595, mean: 0.08822
[32m[0906 13-43-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03595, current rewards: 168.81059, mean: 0.08838
[32m[0906 13-43-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03596, current rewards: 173.52438, mean: 0.08853
[32m[0906 13-44-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03596, current rewards: 178.23758, mean: 0.08868
[32m[0906 13-44-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03597, current rewards: 182.95508, mean: 0.08881
[32m[0906 13-44-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03598, current rewards: 187.48451, mean: 0.08886
[32m[0906 13-44-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03599, current rewards: 192.00434, mean: 0.08889
[32m[0906 13-44-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03599, current rewards: 196.52724, mean: 0.08893
[32m[0906 13-44-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03600, current rewards: 201.05187, mean: 0.08896
[32m[0906 13-44-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03600, current rewards: 204.05495, mean: 0.08834
[32m[0906 13-44-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03601, current rewards: 208.82603, mean: 0.08849
[32m[0906 13-44-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03601, current rewards: 213.59262, mean: 0.08863
[32m[0906 13-44-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03602, current rewards: 218.35804, mean: 0.08876
[32m[0906 13-44-19 @Agent.py:117][0m Average action selection time: 0.0360
[32m[0906 13-44-19 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-44-19 @MBExp.py:227][0m Rewards obtained: [222.17342430599118], Lows: [4], Highs: [5], Total time: 255.085528
[32m[0906 13-44-28 @MBExp.py:144][0m ####################################################################
[32m[0906 13-44-28 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 13-44-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03542, current rewards: -5.37319, mean: -0.53732
[32m[0906 13-44-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03616, current rewards: -0.30260, mean: -0.00504
[32m[0906 13-44-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03617, current rewards: 4.71825, mean: 0.04289
[32m[0906 13-44-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03598, current rewards: 9.74603, mean: 0.06091
[32m[0906 13-44-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03580, current rewards: 14.76141, mean: 0.07029
[32m[0906 13-44-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03575, current rewards: 17.89596, mean: 0.06883
[32m[0906 13-44-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03573, current rewards: 23.04907, mean: 0.07435
[32m[0906 13-44-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03582, current rewards: 28.20187, mean: 0.07834
[32m[0906 13-44-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03578, current rewards: 33.29009, mean: 0.08120
[32m[0906 13-44-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03576, current rewards: 37.92490, mean: 0.08245
[32m[0906 13-44-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03571, current rewards: 42.64227, mean: 0.08361
[32m[0906 13-44-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03561, current rewards: 47.35573, mean: 0.08456
[32m[0906 13-44-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03552, current rewards: 52.07914, mean: 0.08538
[32m[0906 13-44-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03544, current rewards: 56.79453, mean: 0.08605
[32m[0906 13-44-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03543, current rewards: 61.50946, mean: 0.08663
[32m[0906 13-44-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03545, current rewards: 61.80025, mean: 0.08132
[32m[0906 13-44-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03552, current rewards: 66.25078, mean: 0.08179
[32m[0906 13-44-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03556, current rewards: 70.97397, mean: 0.08253
[32m[0906 13-45-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03558, current rewards: 75.64928, mean: 0.08313
[32m[0906 13-45-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03562, current rewards: 80.32751, mean: 0.08367
[32m[0906 13-45-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03565, current rewards: 85.00401, mean: 0.08416
[32m[0906 13-45-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03568, current rewards: 89.68222, mean: 0.08461
[32m[0906 13-45-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03575, current rewards: 94.35890, mean: 0.08501
[32m[0906 13-45-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03576, current rewards: 99.03604, mean: 0.08538
[32m[0906 13-45-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03578, current rewards: 103.71136, mean: 0.08571
[32m[0906 13-45-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03576, current rewards: 108.39313, mean: 0.08603
[32m[0906 13-45-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03575, current rewards: 113.06666, mean: 0.08631
[32m[0906 13-45-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03574, current rewards: 117.74412, mean: 0.08658
[32m[0906 13-45-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03572, current rewards: 120.32613, mean: 0.08534
[32m[0906 13-45-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03571, current rewards: 125.13753, mean: 0.08571
[32m[0906 13-45-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03573, current rewards: 129.94974, mean: 0.08606
[32m[0906 13-45-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03574, current rewards: 134.76285, mean: 0.08639
[32m[0906 13-45-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03576, current rewards: 139.57428, mean: 0.08669
[32m[0906 13-45-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03577, current rewards: 144.56758, mean: 0.08709
[32m[0906 13-45-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03578, current rewards: 149.53831, mean: 0.08745
[32m[0906 13-45-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03579, current rewards: 154.50906, mean: 0.08779
[32m[0906 13-45-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03581, current rewards: 157.68336, mean: 0.08712
[32m[0906 13-45-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03582, current rewards: 162.78771, mean: 0.08752
[32m[0906 13-45-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03583, current rewards: 167.88716, mean: 0.08790
[32m[0906 13-45-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03584, current rewards: 172.99192, mean: 0.08826
[32m[0906 13-45-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03585, current rewards: 178.09103, mean: 0.08860
[32m[0906 13-45-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03586, current rewards: 180.97738, mean: 0.08785
[32m[0906 13-45-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03587, current rewards: 186.14535, mean: 0.08822
[32m[0906 13-45-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03588, current rewards: 191.31315, mean: 0.08857
[32m[0906 13-45-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03588, current rewards: 196.48802, mean: 0.08891
[32m[0906 13-45-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03589, current rewards: 201.66597, mean: 0.08923
[32m[0906 13-45-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03590, current rewards: 206.83993, mean: 0.08954
[32m[0906 13-45-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03591, current rewards: 212.01006, mean: 0.08983
[32m[0906 13-45-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03592, current rewards: 217.18495, mean: 0.09012
[32m[0906 13-45-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03593, current rewards: 218.11675, mean: 0.08867
[32m[0906 13-45-58 @Agent.py:117][0m Average action selection time: 0.0359
[32m[0906 13-45-58 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-45-58 @MBExp.py:227][0m Rewards obtained: [222.30968286060417], Lows: [7], Highs: [8], Total time: 345.532461
[32m[0906 13-46-09 @MBExp.py:144][0m ####################################################################
[32m[0906 13-46-09 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 13-46-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03647, current rewards: -2.34135, mean: -0.23414
[32m[0906 13-46-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03555, current rewards: 2.79557, mean: 0.04659
[32m[0906 13-46-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03548, current rewards: 8.08809, mean: 0.07353
[32m[0906 13-46-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03542, current rewards: 13.38326, mean: 0.08365
[32m[0906 13-46-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03541, current rewards: 18.67622, mean: 0.08893
[32m[0906 13-46-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03547, current rewards: 23.96770, mean: 0.09218
[32m[0906 13-46-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03558, current rewards: 29.25708, mean: 0.09438
[32m[0906 13-46-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03567, current rewards: 34.55538, mean: 0.09599
[32m[0906 13-46-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03567, current rewards: 39.84755, mean: 0.09719
[32m[0906 13-46-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03562, current rewards: 45.14101, mean: 0.09813
[32m[0906 13-46-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03550, current rewards: 50.43141, mean: 0.09889
[32m[0906 13-46-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03543, current rewards: 55.72080, mean: 0.09950
[32m[0906 13-46-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03537, current rewards: 61.00816, mean: 0.10001
[32m[0906 13-46-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03532, current rewards: 66.30343, mean: 0.10046
[32m[0906 13-46-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03526, current rewards: 71.91242, mean: 0.10129
[32m[0906 13-46-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03531, current rewards: 77.65113, mean: 0.10217
[32m[0906 13-46-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03537, current rewards: 83.53034, mean: 0.10312
[32m[0906 13-46-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03541, current rewards: 89.30722, mean: 0.10385
[32m[0906 13-46-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03546, current rewards: 95.07836, mean: 0.10448
[32m[0906 13-46-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03551, current rewards: 100.85465, mean: 0.10506
[32m[0906 13-46-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03555, current rewards: 106.63422, mean: 0.10558
[32m[0906 13-46-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03557, current rewards: 110.53300, mean: 0.10428
[32m[0906 13-46-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03559, current rewards: 116.12024, mean: 0.10461
[32m[0906 13-46-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03561, current rewards: 121.70639, mean: 0.10492
[32m[0906 13-46-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03561, current rewards: 127.39190, mean: 0.10528
[32m[0906 13-46-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03560, current rewards: 131.80049, mean: 0.10460
[32m[0906 13-46-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03559, current rewards: 137.29482, mean: 0.10481
[32m[0906 13-46-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03558, current rewards: 142.78996, mean: 0.10499
[32m[0906 13-46-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03557, current rewards: 148.28199, mean: 0.10516
[32m[0906 13-47-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03558, current rewards: 153.77717, mean: 0.10533
[32m[0906 13-47-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03560, current rewards: 159.27324, mean: 0.10548
[32m[0906 13-47-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03562, current rewards: 164.76789, mean: 0.10562
[32m[0906 13-47-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03563, current rewards: 170.25600, mean: 0.10575
[32m[0906 13-47-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03564, current rewards: 175.69920, mean: 0.10584
[32m[0906 13-47-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03566, current rewards: 181.17089, mean: 0.10595
[32m[0906 13-47-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03566, current rewards: 186.64324, mean: 0.10605
[32m[0906 13-47-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03567, current rewards: 189.89914, mean: 0.10492
[32m[0906 13-47-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03569, current rewards: 195.30900, mean: 0.10500
[32m[0906 13-47-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03570, current rewards: 200.71900, mean: 0.10509
[32m[0906 13-47-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03571, current rewards: 206.13912, mean: 0.10517
[32m[0906 13-47-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03572, current rewards: 211.55706, mean: 0.10525
[32m[0906 13-47-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03574, current rewards: 216.94135, mean: 0.10531
[32m[0906 13-47-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03574, current rewards: 222.34588, mean: 0.10538
[32m[0906 13-47-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03576, current rewards: 227.74401, mean: 0.10544
[32m[0906 13-47-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03577, current rewards: 233.14258, mean: 0.10549
[32m[0906 13-47-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03578, current rewards: 238.54604, mean: 0.10555
[32m[0906 13-47-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03579, current rewards: 243.95001, mean: 0.10561
[32m[0906 13-47-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03580, current rewards: 249.41545, mean: 0.10568
[32m[0906 13-47-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03581, current rewards: 254.87399, mean: 0.10576
[32m[0906 13-47-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03582, current rewards: 260.18449, mean: 0.10577
[32m[0906 13-47-39 @Agent.py:117][0m Average action selection time: 0.0358
[32m[0906 13-47-39 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-47-39 @MBExp.py:227][0m Rewards obtained: [264.4660646746999], Lows: [1], Highs: [6], Total time: 435.723772
[32m[0906 13-47-51 @MBExp.py:144][0m ####################################################################
[32m[0906 13-47-51 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 13-47-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03494, current rewards: 0.94156, mean: 0.09416
[32m[0906 13-47-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03521, current rewards: 6.48303, mean: 0.10805
[32m[0906 13-47-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03520, current rewards: 12.03801, mean: 0.10944
[32m[0906 13-47-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03524, current rewards: 17.59759, mean: 0.10998
[32m[0906 13-47-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03536, current rewards: 23.15622, mean: 0.11027
[32m[0906 13-48-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03550, current rewards: 28.71237, mean: 0.11043
[32m[0906 13-48-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03560, current rewards: 32.00771, mean: 0.10325
[32m[0906 13-48-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03567, current rewards: 37.64673, mean: 0.10457
[32m[0906 13-48-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03559, current rewards: 43.23189, mean: 0.10544
[32m[0906 13-48-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03550, current rewards: 48.81598, mean: 0.10612
[32m[0906 13-48-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03539, current rewards: 54.40096, mean: 0.10667
[32m[0906 13-48-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03530, current rewards: 59.98596, mean: 0.10712
[32m[0906 13-48-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03521, current rewards: 65.57562, mean: 0.10750
[32m[0906 13-48-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03514, current rewards: 71.26900, mean: 0.10798
[32m[0906 13-48-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03510, current rewards: 76.96042, mean: 0.10839
[32m[0906 13-48-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03509, current rewards: 82.64879, mean: 0.10875
[32m[0906 13-48-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03512, current rewards: 88.34269, mean: 0.10907
[32m[0906 13-48-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03519, current rewards: 94.03443, mean: 0.10934
[32m[0906 13-48-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03525, current rewards: 97.57729, mean: 0.10723
[32m[0906 13-48-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03530, current rewards: 103.24496, mean: 0.10755
[32m[0906 13-48-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03535, current rewards: 108.91576, mean: 0.10784
[32m[0906 13-48-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03538, current rewards: 114.58929, mean: 0.10810
[32m[0906 13-48-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03539, current rewards: 120.26363, mean: 0.10835
[32m[0906 13-48-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03538, current rewards: 126.10374, mean: 0.10871
[32m[0906 13-48-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03539, current rewards: 131.79736, mean: 0.10892
[32m[0906 13-48-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03539, current rewards: 137.48252, mean: 0.10911
[32m[0906 13-48-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03540, current rewards: 143.17677, mean: 0.10930
[32m[0906 13-48-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03540, current rewards: 146.76523, mean: 0.10792
[32m[0906 13-48-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03539, current rewards: 152.14995, mean: 0.10791
[32m[0906 13-48-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03541, current rewards: 157.53522, mean: 0.10790
[32m[0906 13-48-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03543, current rewards: 162.92163, mean: 0.10790
[32m[0906 13-48-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03545, current rewards: 168.26887, mean: 0.10786
[32m[0906 13-48-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03547, current rewards: 173.62605, mean: 0.10784
[32m[0906 13-48-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03550, current rewards: 178.98154, mean: 0.10782
[32m[0906 13-48-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03553, current rewards: 184.33612, mean: 0.10780
[32m[0906 13-48-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03554, current rewards: 189.69369, mean: 0.10778
[32m[0906 13-48-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03556, current rewards: 193.92481, mean: 0.10714
[32m[0906 13-48-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03558, current rewards: 199.64106, mean: 0.10733
[32m[0906 13-49-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03559, current rewards: 205.36411, mean: 0.10752
[32m[0906 13-49-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03561, current rewards: 211.08486, mean: 0.10770
[32m[0906 13-49-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03562, current rewards: 216.54854, mean: 0.10774
[32m[0906 13-49-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03563, current rewards: 222.29719, mean: 0.10791
[32m[0906 13-49-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03564, current rewards: 228.04371, mean: 0.10808
[32m[0906 13-49-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03566, current rewards: 233.79244, mean: 0.10824
[32m[0906 13-49-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03567, current rewards: 239.54105, mean: 0.10839
[32m[0906 13-49-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03568, current rewards: 244.14084, mean: 0.10803
[32m[0906 13-49-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03569, current rewards: 249.72254, mean: 0.10810
[32m[0906 13-49-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03570, current rewards: 255.29696, mean: 0.10818
[32m[0906 13-49-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03571, current rewards: 261.13482, mean: 0.10835
[32m[0906 13-49-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03572, current rewards: 266.89385, mean: 0.10849
[32m[0906 13-49-21 @Agent.py:117][0m Average action selection time: 0.0357
[32m[0906 13-49-21 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-49-21 @MBExp.py:227][0m Rewards obtained: [271.4806876435915], Lows: [2], Highs: [4], Total time: 525.675923
[32m[0906 13-49-36 @MBExp.py:144][0m ####################################################################
[32m[0906 13-49-36 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 13-49-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03520, current rewards: 1.13133, mean: 0.11313
[32m[0906 13-49-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03520, current rewards: 6.41898, mean: 0.10698
[32m[0906 13-49-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03524, current rewards: 11.88345, mean: 0.10803
[32m[0906 13-49-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03535, current rewards: 17.34725, mean: 0.10842
[32m[0906 13-49-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03555, current rewards: 22.81139, mean: 0.10863
[32m[0906 13-49-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03563, current rewards: 28.27393, mean: 0.10875
[32m[0906 13-49-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03570, current rewards: 33.73800, mean: 0.10883
[32m[0906 13-49-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03566, current rewards: 39.33392, mean: 0.10926
[32m[0906 13-49-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03559, current rewards: 44.85192, mean: 0.10939
[32m[0906 13-49-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03545, current rewards: 50.36926, mean: 0.10950
[32m[0906 13-49-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03536, current rewards: 55.88597, mean: 0.10958
[32m[0906 13-49-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03527, current rewards: 60.25246, mean: 0.10759
[32m[0906 13-49-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03521, current rewards: 65.73181, mean: 0.10776
[32m[0906 13-49-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03515, current rewards: 71.21300, mean: 0.10790
[32m[0906 13-50-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03509, current rewards: 76.68544, mean: 0.10801
[32m[0906 13-50-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03508, current rewards: 82.20280, mean: 0.10816
[32m[0906 13-50-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03510, current rewards: 87.67688, mean: 0.10824
[32m[0906 13-50-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03513, current rewards: 93.15322, mean: 0.10832
[32m[0906 13-50-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03520, current rewards: 98.62901, mean: 0.10838
[32m[0906 13-50-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03527, current rewards: 104.10741, mean: 0.10845
[32m[0906 13-50-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03530, current rewards: 108.44716, mean: 0.10737
[32m[0906 13-50-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03531, current rewards: 113.92792, mean: 0.10748
[32m[0906 13-50-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03531, current rewards: 119.40436, mean: 0.10757
[32m[0906 13-50-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03530, current rewards: 124.85857, mean: 0.10764
[32m[0906 13-50-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03531, current rewards: 130.33257, mean: 0.10771
[32m[0906 13-50-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03530, current rewards: 135.80788, mean: 0.10778
[32m[0906 13-50-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03530, current rewards: 141.27886, mean: 0.10785
[32m[0906 13-50-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03532, current rewards: 146.75560, mean: 0.10791
[32m[0906 13-50-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03534, current rewards: 152.22618, mean: 0.10796
[32m[0906 13-50-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03537, current rewards: 156.61538, mean: 0.10727
[32m[0906 13-50-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03539, current rewards: 162.06624, mean: 0.10733
[32m[0906 13-50-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03543, current rewards: 167.45178, mean: 0.10734
[32m[0906 13-50-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03545, current rewards: 172.88969, mean: 0.10738
[32m[0906 13-50-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03546, current rewards: 178.32833, mean: 0.10743
[32m[0906 13-50-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03548, current rewards: 183.76366, mean: 0.10746
[32m[0906 13-50-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03550, current rewards: 189.19857, mean: 0.10750
[32m[0906 13-50-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03552, current rewards: 194.63721, mean: 0.10753
[32m[0906 13-50-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03553, current rewards: 200.68736, mean: 0.10790
[32m[0906 13-50-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03555, current rewards: 206.22855, mean: 0.10797
[32m[0906 13-50-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03557, current rewards: 211.83762, mean: 0.10808
[32m[0906 13-50-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03559, current rewards: 217.38711, mean: 0.10815
[32m[0906 13-50-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03560, current rewards: 222.93333, mean: 0.10822
[32m[0906 13-50-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03561, current rewards: 228.48687, mean: 0.10829
[32m[0906 13-50-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03563, current rewards: 234.03532, mean: 0.10835
[32m[0906 13-50-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03564, current rewards: 239.58587, mean: 0.10841
[32m[0906 13-50-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03565, current rewards: 245.13814, mean: 0.10847
[32m[0906 13-50-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03567, current rewards: 250.68283, mean: 0.10852
[32m[0906 13-51-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03568, current rewards: 254.08596, mean: 0.10766
[32m[0906 13-51-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03569, current rewards: 259.64301, mean: 0.10774
[32m[0906 13-51-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03570, current rewards: 265.07604, mean: 0.10775
[32m[0906 13-51-06 @Agent.py:117][0m Average action selection time: 0.0357
[32m[0906 13-51-06 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-51-06 @MBExp.py:227][0m Rewards obtained: [269.4264032922262], Lows: [1], Highs: [3], Total time: 615.570248
[32m[0906 13-51-22 @MBExp.py:144][0m ####################################################################
[32m[0906 13-51-22 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 13-51-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03567, current rewards: -3.34623, mean: -0.33462
[32m[0906 13-51-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03550, current rewards: 2.25880, mean: 0.03765
[32m[0906 13-51-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03560, current rewards: 7.96264, mean: 0.07239
[32m[0906 13-51-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03584, current rewards: 13.67072, mean: 0.08544
[32m[0906 13-51-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03589, current rewards: 19.38512, mean: 0.09231
[32m[0906 13-51-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03598, current rewards: 25.10115, mean: 0.09654
[32m[0906 13-51-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03591, current rewards: 30.95541, mean: 0.09986
[32m[0906 13-51-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03585, current rewards: 36.62977, mean: 0.10175
[32m[0906 13-51-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03572, current rewards: 39.54722, mean: 0.09646
[32m[0906 13-51-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03559, current rewards: 44.50910, mean: 0.09676
[32m[0906 13-51-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03549, current rewards: 49.46763, mean: 0.09700
[32m[0906 13-51-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03540, current rewards: 54.42863, mean: 0.09719
[32m[0906 13-51-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03533, current rewards: 58.36329, mean: 0.09568
[32m[0906 13-51-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03528, current rewards: 63.86827, mean: 0.09677
[32m[0906 13-51-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03522, current rewards: 69.36581, mean: 0.09770
[32m[0906 13-51-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03524, current rewards: 74.81130, mean: 0.09844
[32m[0906 13-51-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03526, current rewards: 80.30771, mean: 0.09915
[32m[0906 13-51-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03526, current rewards: 85.81276, mean: 0.09978
[32m[0906 13-51-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03527, current rewards: 91.31319, mean: 0.10034
[32m[0906 13-51-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03530, current rewards: 96.80697, mean: 0.10084
[32m[0906 13-51-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03529, current rewards: 102.30038, mean: 0.10129
[32m[0906 13-52-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03530, current rewards: 107.79882, mean: 0.10170
[32m[0906 13-52-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03530, current rewards: 113.29819, mean: 0.10207
[32m[0906 13-52-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03532, current rewards: 118.79666, mean: 0.10241
[32m[0906 13-52-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03532, current rewards: 124.29483, mean: 0.10272
[32m[0906 13-52-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03533, current rewards: 129.78890, mean: 0.10301
[32m[0906 13-52-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03534, current rewards: 135.23229, mean: 0.10323
[32m[0906 13-52-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03534, current rewards: 140.70082, mean: 0.10346
[32m[0906 13-52-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03535, current rewards: 146.17674, mean: 0.10367
[32m[0906 13-52-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03538, current rewards: 151.64705, mean: 0.10387
[32m[0906 13-52-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03541, current rewards: 157.12237, mean: 0.10405
[32m[0906 13-52-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03544, current rewards: 160.77292, mean: 0.10306
[32m[0906 13-52-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03546, current rewards: 166.37227, mean: 0.10334
[32m[0906 13-52-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03547, current rewards: 171.96981, mean: 0.10360
[32m[0906 13-52-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03550, current rewards: 177.56626, mean: 0.10384
[32m[0906 13-52-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03552, current rewards: 183.16674, mean: 0.10407
[32m[0906 13-52-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03554, current rewards: 188.76569, mean: 0.10429
[32m[0906 13-52-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03556, current rewards: 194.36927, mean: 0.10450
[32m[0906 13-52-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03558, current rewards: 199.97178, mean: 0.10470
[32m[0906 13-52-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03559, current rewards: 205.60360, mean: 0.10490
[32m[0906 13-52-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03561, current rewards: 211.20512, mean: 0.10508
[32m[0906 13-52-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03563, current rewards: 216.81055, mean: 0.10525
[32m[0906 13-52-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03564, current rewards: 222.41459, mean: 0.10541
[32m[0906 13-52-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03566, current rewards: 226.84960, mean: 0.10502
[32m[0906 13-52-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03567, current rewards: 232.37866, mean: 0.10515
[32m[0906 13-52-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03568, current rewards: 237.90993, mean: 0.10527
[32m[0906 13-52-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03569, current rewards: 243.44491, mean: 0.10539
[32m[0906 13-52-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03570, current rewards: 248.97315, mean: 0.10550
[32m[0906 13-52-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03571, current rewards: 254.50018, mean: 0.10560
[32m[0906 13-52-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03572, current rewards: 260.02683, mean: 0.10570
[32m[0906 13-52-52 @Agent.py:117][0m Average action selection time: 0.0357
[32m[0906 13-52-52 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-52-52 @MBExp.py:227][0m Rewards obtained: [264.4487735802917], Lows: [2], Highs: [6], Total time: 705.522742
[32m[0906 13-53-11 @MBExp.py:144][0m ####################################################################
[32m[0906 13-53-11 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 13-53-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03545, current rewards: -2.27060, mean: -0.22706
[32m[0906 13-53-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03576, current rewards: 3.41889, mean: 0.05698
[32m[0906 13-53-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03608, current rewards: 9.10372, mean: 0.08276
[32m[0906 13-53-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03613, current rewards: 14.78720, mean: 0.09242
[32m[0906 13-53-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03606, current rewards: 20.47310, mean: 0.09749
[32m[0906 13-53-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03593, current rewards: 26.16144, mean: 0.10062
[32m[0906 13-53-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03586, current rewards: 31.84757, mean: 0.10273
[32m[0906 13-53-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03575, current rewards: 37.53473, mean: 0.10426
[32m[0906 13-53-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03565, current rewards: 43.21786, mean: 0.10541
[32m[0906 13-53-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03552, current rewards: 48.90608, mean: 0.10632
[32m[0906 13-53-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03541, current rewards: 54.59284, mean: 0.10704
[32m[0906 13-53-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03535, current rewards: 59.14304, mean: 0.10561
[32m[0906 13-53-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03528, current rewards: 64.84470, mean: 0.10630
[32m[0906 13-53-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03522, current rewards: 70.70406, mean: 0.10713
[32m[0906 13-53-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03517, current rewards: 76.37764, mean: 0.10757
[32m[0906 13-53-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03517, current rewards: 82.04748, mean: 0.10796
[32m[0906 13-53-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03521, current rewards: 86.60331, mean: 0.10692
[32m[0906 13-53-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03522, current rewards: 92.29868, mean: 0.10732
[32m[0906 13-53-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03517, current rewards: 97.99067, mean: 0.10768
[32m[0906 13-53-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03515, current rewards: 103.68749, mean: 0.10801
[32m[0906 13-53-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03516, current rewards: 109.38250, mean: 0.10830
[32m[0906 13-53-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03516, current rewards: 114.89029, mean: 0.10839
[32m[0906 13-53-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03518, current rewards: 120.55221, mean: 0.10861
[32m[0906 13-53-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03519, current rewards: 126.21740, mean: 0.10881
[32m[0906 13-53-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03521, current rewards: 131.87806, mean: 0.10899
[32m[0906 13-53-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03520, current rewards: 137.54124, mean: 0.10916
[32m[0906 13-53-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03521, current rewards: 141.05196, mean: 0.10767
[32m[0906 13-53-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03522, current rewards: 146.67523, mean: 0.10785
[32m[0906 13-54-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03525, current rewards: 152.30346, mean: 0.10802
[32m[0906 13-54-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03528, current rewards: 157.93691, mean: 0.10818
[32m[0906 13-54-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03532, current rewards: 163.61481, mean: 0.10835
[32m[0906 13-54-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03535, current rewards: 169.22827, mean: 0.10848
[32m[0906 13-54-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03538, current rewards: 174.83762, mean: 0.10859
[32m[0906 13-54-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03541, current rewards: 180.44877, mean: 0.10870
[32m[0906 13-54-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03543, current rewards: 186.06327, mean: 0.10881
[32m[0906 13-54-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03545, current rewards: 191.68120, mean: 0.10891
[32m[0906 13-54-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03547, current rewards: 196.25393, mean: 0.10843
[32m[0906 13-54-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03549, current rewards: 201.89322, mean: 0.10854
[32m[0906 13-54-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03551, current rewards: 207.52724, mean: 0.10865
[32m[0906 13-54-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03553, current rewards: 213.16479, mean: 0.10876
[32m[0906 13-54-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03554, current rewards: 218.79999, mean: 0.10886
[32m[0906 13-54-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03556, current rewards: 224.43697, mean: 0.10895
[32m[0906 13-54-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03557, current rewards: 230.06760, mean: 0.10904
[32m[0906 13-54-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03559, current rewards: 231.49653, mean: 0.10717
[32m[0906 13-54-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03560, current rewards: 237.14483, mean: 0.10731
[32m[0906 13-54-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03562, current rewards: 242.79602, mean: 0.10743
[32m[0906 13-54-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03563, current rewards: 248.86023, mean: 0.10773
[32m[0906 13-54-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03565, current rewards: 254.90549, mean: 0.10801
[32m[0906 13-54-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03566, current rewards: 260.95076, mean: 0.10828
[32m[0906 13-54-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03567, current rewards: 266.99602, mean: 0.10853
[32m[0906 13-54-41 @Agent.py:117][0m Average action selection time: 0.0357
[32m[0906 13-54-41 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-54-41 @MBExp.py:227][0m Rewards obtained: [271.83223411327015], Lows: [3], Highs: [6], Total time: 795.351218
[32m[0906 13-55-02 @MBExp.py:144][0m ####################################################################
[32m[0906 13-55-02 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 13-55-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03621, current rewards: -1.11947, mean: -0.11195
[32m[0906 13-55-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03631, current rewards: 4.52664, mean: 0.07544
[32m[0906 13-55-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03628, current rewards: 10.17260, mean: 0.09248
[32m[0906 13-55-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03620, current rewards: 15.81304, mean: 0.09883
[32m[0906 13-55-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03598, current rewards: 19.14809, mean: 0.09118
[32m[0906 13-55-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03588, current rewards: 24.72679, mean: 0.09510
[32m[0906 13-55-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03579, current rewards: 30.30331, mean: 0.09775
[32m[0906 13-55-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03574, current rewards: 35.88073, mean: 0.09967
[32m[0906 13-55-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03564, current rewards: 41.45509, mean: 0.10111
[32m[0906 13-55-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03549, current rewards: 47.03346, mean: 0.10225
[32m[0906 13-55-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03541, current rewards: 52.61256, mean: 0.10316
[32m[0906 13-55-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03532, current rewards: 58.18386, mean: 0.10390
[32m[0906 13-55-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03527, current rewards: 63.64880, mean: 0.10434
[32m[0906 13-55-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03521, current rewards: 69.20042, mean: 0.10485
[32m[0906 13-55-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03516, current rewards: 74.75256, mean: 0.10529
[32m[0906 13-55-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03515, current rewards: 80.30267, mean: 0.10566
[32m[0906 13-55-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03513, current rewards: 85.85466, mean: 0.10599
[32m[0906 13-55-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03509, current rewards: 91.40333, mean: 0.10628
[32m[0906 13-55-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03507, current rewards: 96.95605, mean: 0.10655
[32m[0906 13-55-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03504, current rewards: 100.42676, mean: 0.10461
[32m[0906 13-55-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03502, current rewards: 105.98790, mean: 0.10494
[32m[0906 13-55-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03502, current rewards: 111.74700, mean: 0.10542
[32m[0906 13-55-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03504, current rewards: 117.35488, mean: 0.10573
[32m[0906 13-55-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03506, current rewards: 122.96256, mean: 0.10600
[32m[0906 13-55-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03506, current rewards: 128.56862, mean: 0.10626
[32m[0906 13-55-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03507, current rewards: 134.17897, mean: 0.10649
[32m[0906 13-55-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03508, current rewards: 138.51975, mean: 0.10574
[32m[0906 13-55-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03509, current rewards: 143.95914, mean: 0.10585
[32m[0906 13-55-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03512, current rewards: 149.39359, mean: 0.10595
[32m[0906 13-55-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03516, current rewards: 154.78146, mean: 0.10601
[32m[0906 13-55-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03519, current rewards: 160.17627, mean: 0.10608
[32m[0906 13-55-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03522, current rewards: 165.57671, mean: 0.10614
[32m[0906 13-55-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03526, current rewards: 170.97452, mean: 0.10620
[32m[0906 13-56-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03529, current rewards: 176.37364, mean: 0.10625
[32m[0906 13-56-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03531, current rewards: 181.77394, mean: 0.10630
[32m[0906 13-56-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03533, current rewards: 187.17893, mean: 0.10635
[32m[0906 13-56-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03535, current rewards: 190.46453, mean: 0.10523
[32m[0906 13-56-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03538, current rewards: 195.92209, mean: 0.10533
[32m[0906 13-56-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03540, current rewards: 201.38641, mean: 0.10544
[32m[0906 13-56-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03542, current rewards: 206.85588, mean: 0.10554
[32m[0906 13-56-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03544, current rewards: 212.32376, mean: 0.10563
[32m[0906 13-56-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03546, current rewards: 217.79018, mean: 0.10572
[32m[0906 13-56-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03549, current rewards: 223.25836, mean: 0.10581
[32m[0906 13-56-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03550, current rewards: 228.72087, mean: 0.10589
[32m[0906 13-56-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03552, current rewards: 234.19224, mean: 0.10597
[32m[0906 13-56-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03553, current rewards: 238.30349, mean: 0.10544
[32m[0906 13-56-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03555, current rewards: 243.99512, mean: 0.10563
[32m[0906 13-56-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03556, current rewards: 249.68666, mean: 0.10580
[32m[0906 13-56-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03558, current rewards: 255.37767, mean: 0.10597
[32m[0906 13-56-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03559, current rewards: 261.06894, mean: 0.10613
[32m[0906 13-56-31 @Agent.py:117][0m Average action selection time: 0.0356
[32m[0906 13-56-31 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-56-31 @MBExp.py:227][0m Rewards obtained: [265.62105974896673], Lows: [4], Highs: [3], Total time: 884.961148
[32m[0906 13-56-54 @MBExp.py:144][0m ####################################################################
[32m[0906 13-56-54 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 13-56-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03688, current rewards: 0.95846, mean: 0.09585
[32m[0906 13-56-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03617, current rewards: 6.40586, mean: 0.10676
[32m[0906 13-56-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03588, current rewards: 11.94856, mean: 0.10862
[32m[0906 13-57-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03574, current rewards: 17.49116, mean: 0.10932
[32m[0906 13-57-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03569, current rewards: 23.02987, mean: 0.10967
[32m[0906 13-57-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03563, current rewards: 28.57156, mean: 0.10989
[32m[0906 13-57-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03556, current rewards: 34.11408, mean: 0.11005
[32m[0906 13-57-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03556, current rewards: 39.65579, mean: 0.11015
[32m[0906 13-57-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03545, current rewards: 43.94284, mean: 0.10718
[32m[0906 13-57-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03534, current rewards: 49.58027, mean: 0.10778
[32m[0906 13-57-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03527, current rewards: 55.22108, mean: 0.10828
[32m[0906 13-57-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03521, current rewards: 60.86034, mean: 0.10868
[32m[0906 13-57-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03516, current rewards: 66.41880, mean: 0.10888
[32m[0906 13-57-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03512, current rewards: 72.10158, mean: 0.10924
[32m[0906 13-57-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03507, current rewards: 77.78209, mean: 0.10955
[32m[0906 13-57-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03502, current rewards: 81.21916, mean: 0.10687
[32m[0906 13-57-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03498, current rewards: 86.68834, mean: 0.10702
[32m[0906 13-57-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03495, current rewards: 92.15738, mean: 0.10716
[32m[0906 13-57-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03493, current rewards: 97.62415, mean: 0.10728
[32m[0906 13-57-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03491, current rewards: 103.09304, mean: 0.10739
[32m[0906 13-57-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03489, current rewards: 108.72826, mean: 0.10765
[32m[0906 13-57-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03487, current rewards: 114.23835, mean: 0.10777
[32m[0906 13-57-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03487, current rewards: 119.74976, mean: 0.10788
[32m[0906 13-57-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03489, current rewards: 123.12158, mean: 0.10614
[32m[0906 13-57-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03491, current rewards: 128.54765, mean: 0.10624
[32m[0906 13-57-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03493, current rewards: 133.97802, mean: 0.10633
[32m[0906 13-57-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03496, current rewards: 139.40966, mean: 0.10642
[32m[0906 13-57-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03497, current rewards: 142.84109, mean: 0.10503
[32m[0906 13-57-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03503, current rewards: 148.43212, mean: 0.10527
[32m[0906 13-57-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03507, current rewards: 153.99353, mean: 0.10548
[32m[0906 13-57-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03511, current rewards: 159.55978, mean: 0.10567
[32m[0906 13-57-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03515, current rewards: 165.12269, mean: 0.10585
[32m[0906 13-57-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03518, current rewards: 169.28912, mean: 0.10515
[32m[0906 13-57-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03522, current rewards: 174.39883, mean: 0.10506
[32m[0906 13-57-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03525, current rewards: 179.50631, mean: 0.10497
[32m[0906 13-57-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03527, current rewards: 184.61553, mean: 0.10490
[32m[0906 13-57-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03530, current rewards: 189.65576, mean: 0.10478
[32m[0906 13-58-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03532, current rewards: 194.96940, mean: 0.10482
[32m[0906 13-58-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03534, current rewards: 200.35526, mean: 0.10490
[32m[0906 13-58-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03537, current rewards: 205.73701, mean: 0.10497
[32m[0906 13-58-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03539, current rewards: 211.12232, mean: 0.10504
[32m[0906 13-58-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03541, current rewards: 214.65346, mean: 0.10420
[32m[0906 13-58-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03543, current rewards: 220.30254, mean: 0.10441
[32m[0906 13-58-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03545, current rewards: 225.95611, mean: 0.10461
[32m[0906 13-58-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03547, current rewards: 231.60933, mean: 0.10480
[32m[0906 13-58-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03548, current rewards: 237.22286, mean: 0.10497
[32m[0906 13-58-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03550, current rewards: 242.89809, mean: 0.10515
[32m[0906 13-58-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03552, current rewards: 248.56908, mean: 0.10533
[32m[0906 13-58-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03553, current rewards: 254.24340, mean: 0.10550
[32m[0906 13-58-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03552, current rewards: 259.91709, mean: 0.10566
[32m[0906 13-58-23 @Agent.py:117][0m Average action selection time: 0.0355
[32m[0906 13-58-23 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-58-23 @MBExp.py:227][0m Rewards obtained: [264.45556266540774], Lows: [4], Highs: [3], Total time: 974.389241
[32m[0906 13-58-48 @MBExp.py:144][0m ####################################################################
[32m[0906 13-58-48 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 13-58-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03561, current rewards: -1.09204, mean: -0.10920
[32m[0906 13-58-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03547, current rewards: 4.41442, mean: 0.07357
[32m[0906 13-58-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03540, current rewards: 9.91908, mean: 0.09017
[32m[0906 13-58-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03532, current rewards: 15.66973, mean: 0.09794
[32m[0906 13-58-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03534, current rewards: 21.19096, mean: 0.10091
[32m[0906 13-58-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03529, current rewards: 26.71521, mean: 0.10275
[32m[0906 13-58-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03528, current rewards: 32.23206, mean: 0.10397
[32m[0906 13-59-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03529, current rewards: 37.75613, mean: 0.10488
[32m[0906 13-59-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03524, current rewards: 41.18253, mean: 0.10045
[32m[0906 13-59-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03518, current rewards: 46.67225, mean: 0.10146
[32m[0906 13-59-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03510, current rewards: 52.16389, mean: 0.10228
[32m[0906 13-59-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03506, current rewards: 57.56870, mean: 0.10280
[32m[0906 13-59-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03501, current rewards: 63.04265, mean: 0.10335
[32m[0906 13-59-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03492, current rewards: 66.44144, mean: 0.10067
[32m[0906 13-59-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03483, current rewards: 71.94436, mean: 0.10133
[32m[0906 13-59-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03480, current rewards: 77.44301, mean: 0.10190
[32m[0906 13-59-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03478, current rewards: 82.94168, mean: 0.10240
[32m[0906 13-59-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03475, current rewards: 88.43839, mean: 0.10284
[32m[0906 13-59-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03473, current rewards: 93.93897, mean: 0.10323
[32m[0906 13-59-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03472, current rewards: 99.44212, mean: 0.10359
[32m[0906 13-59-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03471, current rewards: 102.89035, mean: 0.10187
[32m[0906 13-59-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03469, current rewards: 108.32588, mean: 0.10219
[32m[0906 13-59-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03469, current rewards: 113.75855, mean: 0.10249
[32m[0906 13-59-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03469, current rewards: 119.18781, mean: 0.10275
[32m[0906 13-59-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03471, current rewards: 124.62610, mean: 0.10300
[32m[0906 13-59-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03474, current rewards: 130.05727, mean: 0.10322
[32m[0906 13-59-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03476, current rewards: 135.49125, mean: 0.10343
[32m[0906 13-59-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03479, current rewards: 140.92575, mean: 0.10362
[32m[0906 13-59-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03486, current rewards: 146.33131, mean: 0.10378
[32m[0906 13-59-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03491, current rewards: 151.76367, mean: 0.10395
[32m[0906 13-59-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03495, current rewards: 155.57186, mean: 0.10303
[32m[0906 13-59-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03499, current rewards: 161.04922, mean: 0.10324
[32m[0906 13-59-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03503, current rewards: 166.52600, mean: 0.10343
[32m[0906 13-59-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03506, current rewards: 172.00298, mean: 0.10362
[32m[0906 13-59-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03509, current rewards: 177.48028, mean: 0.10379
[32m[0906 13-59-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03513, current rewards: 182.95820, mean: 0.10395
[32m[0906 13-59-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03516, current rewards: 188.36580, mean: 0.10407
[32m[0906 13-59-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03519, current rewards: 193.85807, mean: 0.10422
[32m[0906 13-59-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03522, current rewards: 199.35342, mean: 0.10437
[32m[0906 13-59-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03525, current rewards: 204.84638, mean: 0.10451
[32m[0906 14-00-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03527, current rewards: 210.33990, mean: 0.10465
[32m[0906 14-00-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03530, current rewards: 215.82982, mean: 0.10477
[32m[0906 14-00-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03533, current rewards: 221.32397, mean: 0.10489
[32m[0906 14-00-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03535, current rewards: 226.81981, mean: 0.10501
[32m[0906 14-00-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03538, current rewards: 232.31490, mean: 0.10512
[32m[0906 14-00-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03540, current rewards: 235.68863, mean: 0.10429
[32m[0906 14-00-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03542, current rewards: 241.21159, mean: 0.10442
[32m[0906 14-00-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03544, current rewards: 246.74032, mean: 0.10455
[32m[0906 14-00-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03544, current rewards: 252.26524, mean: 0.10467
[32m[0906 14-00-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03544, current rewards: 257.79244, mean: 0.10479
[32m[0906 14-00-18 @Agent.py:117][0m Average action selection time: 0.0354
[32m[0906 14-00-18 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-00-18 @MBExp.py:227][0m Rewards obtained: [262.21188923046043], Lows: [4], Highs: [4], Total time: 1063.603277
[32m[0906 14-00-45 @MBExp.py:144][0m ####################################################################
[32m[0906 14-00-45 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 14-00-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03522, current rewards: -0.08755, mean: -0.00875
[32m[0906 14-00-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03538, current rewards: 5.43497, mean: 0.09058
[32m[0906 14-00-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03542, current rewards: 10.92312, mean: 0.09930
[32m[0906 14-00-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03542, current rewards: 16.44790, mean: 0.10280
[32m[0906 14-00-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03542, current rewards: 21.97213, mean: 0.10463
[32m[0906 14-00-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03541, current rewards: 27.48829, mean: 0.10572
[32m[0906 14-00-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03539, current rewards: 33.01263, mean: 0.10649
[32m[0906 14-00-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03538, current rewards: 38.53488, mean: 0.10704
[32m[0906 14-00-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03531, current rewards: 44.05929, mean: 0.10746
[32m[0906 14-01-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03520, current rewards: 47.52836, mean: 0.10332
[32m[0906 14-01-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03514, current rewards: 53.02442, mean: 0.10397
[32m[0906 14-01-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03509, current rewards: 58.62941, mean: 0.10470
[32m[0906 14-01-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03495, current rewards: 64.23893, mean: 0.10531
[32m[0906 14-01-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03485, current rewards: 69.84713, mean: 0.10583
[32m[0906 14-01-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03477, current rewards: 73.34374, mean: 0.10330
[32m[0906 14-01-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03477, current rewards: 79.02127, mean: 0.10398
[32m[0906 14-01-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03476, current rewards: 84.63222, mean: 0.10448
[32m[0906 14-01-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03473, current rewards: 90.23979, mean: 0.10493
[32m[0906 14-01-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03472, current rewards: 95.99418, mean: 0.10549
[32m[0906 14-01-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03470, current rewards: 101.69503, mean: 0.10593
[32m[0906 14-01-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03468, current rewards: 107.30000, mean: 0.10624
[32m[0906 14-01-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03468, current rewards: 112.90581, mean: 0.10651
[32m[0906 14-01-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03467, current rewards: 117.39263, mean: 0.10576
[32m[0906 14-01-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03466, current rewards: 122.99885, mean: 0.10603
[32m[0906 14-01-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03466, current rewards: 128.60563, mean: 0.10629
[32m[0906 14-01-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03469, current rewards: 134.21611, mean: 0.10652
[32m[0906 14-01-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03472, current rewards: 139.82985, mean: 0.10674
[32m[0906 14-01-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03477, current rewards: 145.29334, mean: 0.10683
[32m[0906 14-01-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03483, current rewards: 150.88791, mean: 0.10701
[32m[0906 14-01-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03488, current rewards: 156.47649, mean: 0.10718
[32m[0906 14-01-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03493, current rewards: 162.06960, mean: 0.10733
[32m[0906 14-01-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03497, current rewards: 167.66304, mean: 0.10748
[32m[0906 14-01-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03501, current rewards: 171.29098, mean: 0.10639
[32m[0906 14-01-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03505, current rewards: 176.80998, mean: 0.10651
[32m[0906 14-01-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03508, current rewards: 182.32909, mean: 0.10663
[32m[0906 14-01-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03513, current rewards: 187.95080, mean: 0.10679
[32m[0906 14-01-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03515, current rewards: 193.47158, mean: 0.10689
[32m[0906 14-01-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03518, current rewards: 198.98886, mean: 0.10698
[32m[0906 14-01-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03520, current rewards: 204.51255, mean: 0.10707
[32m[0906 14-01-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03523, current rewards: 210.02948, mean: 0.10716
[32m[0906 14-01-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03526, current rewards: 213.33480, mean: 0.10614
[32m[0906 14-01-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03528, current rewards: 218.89332, mean: 0.10626
[32m[0906 14-02-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03531, current rewards: 224.45415, mean: 0.10638
[32m[0906 14-02-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03533, current rewards: 229.99409, mean: 0.10648
[32m[0906 14-02-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03535, current rewards: 235.54727, mean: 0.10658
[32m[0906 14-02-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03537, current rewards: 241.09970, mean: 0.10668
[32m[0906 14-02-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03538, current rewards: 246.65778, mean: 0.10678
[32m[0906 14-02-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03538, current rewards: 252.21196, mean: 0.10687
[32m[0906 14-02-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03538, current rewards: 257.76407, mean: 0.10696
[32m[0906 14-02-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03538, current rewards: 263.32038, mean: 0.10704
[32m[0906 14-02-14 @Agent.py:117][0m Average action selection time: 0.0354
[32m[0906 14-02-14 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-02-14 @MBExp.py:227][0m Rewards obtained: [267.76705350435486], Lows: [3], Highs: [4], Total time: 1152.665831
[32m[0906 14-02-43 @MBExp.py:144][0m ####################################################################
[32m[0906 14-02-43 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 14-02-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03469, current rewards: 1.20762, mean: 0.12076
[32m[0906 14-02-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03520, current rewards: 6.54891, mean: 0.10915
[32m[0906 14-02-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03536, current rewards: 12.25436, mean: 0.11140
[32m[0906 14-02-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03537, current rewards: 17.92312, mean: 0.11202
[32m[0906 14-02-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03537, current rewards: 23.59265, mean: 0.11235
[32m[0906 14-02-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03541, current rewards: 29.25884, mean: 0.11253
[32m[0906 14-02-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03537, current rewards: 34.92923, mean: 0.11267
[32m[0906 14-02-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03535, current rewards: 40.59426, mean: 0.11276
[32m[0906 14-02-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03531, current rewards: 46.26291, mean: 0.11284
[32m[0906 14-02-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03521, current rewards: 51.93168, mean: 0.11289
[32m[0906 14-03-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03511, current rewards: 57.67031, mean: 0.11308
[32m[0906 14-03-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03497, current rewards: 59.99668, mean: 0.10714
[32m[0906 14-03-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03485, current rewards: 65.61920, mean: 0.10757
[32m[0906 14-03-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03473, current rewards: 71.23847, mean: 0.10794
[32m[0906 14-03-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03465, current rewards: 76.85204, mean: 0.10824
[32m[0906 14-03-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03464, current rewards: 82.46879, mean: 0.10851
[32m[0906 14-03-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03464, current rewards: 88.07840, mean: 0.10874
[32m[0906 14-03-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03463, current rewards: 91.64595, mean: 0.10657
[32m[0906 14-03-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03461, current rewards: 97.31271, mean: 0.10694
[32m[0906 14-03-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03460, current rewards: 102.92831, mean: 0.10722
[32m[0906 14-03-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03459, current rewards: 108.53957, mean: 0.10746
[32m[0906 14-03-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03458, current rewards: 114.15287, mean: 0.10769
[32m[0906 14-03-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03457, current rewards: 119.76287, mean: 0.10789
[32m[0906 14-03-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03455, current rewards: 125.37696, mean: 0.10808
[32m[0906 14-03-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03454, current rewards: 130.89553, mean: 0.10818
[32m[0906 14-03-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03455, current rewards: 136.49129, mean: 0.10833
[32m[0906 14-03-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03457, current rewards: 142.04286, mean: 0.10843
[32m[0906 14-03-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03462, current rewards: 147.64857, mean: 0.10857
[32m[0906 14-03-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03469, current rewards: 153.25273, mean: 0.10869
[32m[0906 14-03-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03474, current rewards: 158.85342, mean: 0.10880
[32m[0906 14-03-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03479, current rewards: 164.45726, mean: 0.10891
[32m[0906 14-03-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03484, current rewards: 169.23797, mean: 0.10849
[32m[0906 14-03-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03489, current rewards: 174.89640, mean: 0.10863
[32m[0906 14-03-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03493, current rewards: 180.56246, mean: 0.10877
[32m[0906 14-03-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03496, current rewards: 186.08353, mean: 0.10882
[32m[0906 14-03-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03500, current rewards: 191.76050, mean: 0.10895
[32m[0906 14-03-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03503, current rewards: 195.25679, mean: 0.10788
[32m[0906 14-03-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03506, current rewards: 200.88877, mean: 0.10800
[32m[0906 14-03-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03510, current rewards: 206.51747, mean: 0.10812
[32m[0906 14-03-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03512, current rewards: 212.14930, mean: 0.10824
[32m[0906 14-03-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03515, current rewards: 217.77639, mean: 0.10835
[32m[0906 14-03-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03517, current rewards: 223.40555, mean: 0.10845
[32m[0906 14-03-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03520, current rewards: 229.03514, mean: 0.10855
[32m[0906 14-03-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03522, current rewards: 234.66540, mean: 0.10864
[32m[0906 14-04-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03524, current rewards: 240.29418, mean: 0.10873
[32m[0906 14-04-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03525, current rewards: 245.92827, mean: 0.10882
[32m[0906 14-04-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03525, current rewards: 251.55686, mean: 0.10890
[32m[0906 14-04-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03526, current rewards: 257.18892, mean: 0.10898
[32m[0906 14-04-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03526, current rewards: 261.71891, mean: 0.10860
[32m[0906 14-04-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03526, current rewards: 267.34765, mean: 0.10868
[32m[0906 14-04-11 @Agent.py:117][0m Average action selection time: 0.0353
[32m[0906 14-04-11 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-04-11 @MBExp.py:227][0m Rewards obtained: [271.8476059292111], Lows: [2], Highs: [5], Total time: 1241.4537950000001
[32m[0906 14-04-42 @MBExp.py:144][0m ####################################################################
[32m[0906 14-04-42 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 14-04-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03572, current rewards: -1.02927, mean: -0.10293
[32m[0906 14-04-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03547, current rewards: 4.61858, mean: 0.07698
[32m[0906 14-04-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03530, current rewards: 10.25234, mean: 0.09320
[32m[0906 14-04-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03524, current rewards: 15.88573, mean: 0.09929
[32m[0906 14-04-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03525, current rewards: 21.51280, mean: 0.10244
[32m[0906 14-04-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03527, current rewards: 27.15337, mean: 0.10444
[32m[0906 14-04-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03529, current rewards: 32.78576, mean: 0.10576
[32m[0906 14-04-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03529, current rewards: 38.42005, mean: 0.10672
[32m[0906 14-04-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03525, current rewards: 44.05207, mean: 0.10744
[32m[0906 14-04-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03509, current rewards: 48.04072, mean: 0.10444
[32m[0906 14-05-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03495, current rewards: 53.71005, mean: 0.10531
[32m[0906 14-05-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03483, current rewards: 59.37874, mean: 0.10603
[32m[0906 14-05-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03472, current rewards: 65.04565, mean: 0.10663
[32m[0906 14-05-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03465, current rewards: 70.71333, mean: 0.10714
[32m[0906 14-05-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03458, current rewards: 76.38111, mean: 0.10758
[32m[0906 14-05-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03459, current rewards: 82.04982, mean: 0.10796
[32m[0906 14-05-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03459, current rewards: 86.55363, mean: 0.10686
[32m[0906 14-05-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03459, current rewards: 92.28423, mean: 0.10731
[32m[0906 14-05-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03457, current rewards: 97.96275, mean: 0.10765
[32m[0906 14-05-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03456, current rewards: 103.63828, mean: 0.10796
[32m[0906 14-05-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03455, current rewards: 109.31635, mean: 0.10823
[32m[0906 14-05-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03455, current rewards: 113.93353, mean: 0.10748
[32m[0906 14-05-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03454, current rewards: 119.67880, mean: 0.10782
[32m[0906 14-05-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03454, current rewards: 125.42142, mean: 0.10812
[32m[0906 14-05-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03454, current rewards: 131.16749, mean: 0.10840
[32m[0906 14-05-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03454, current rewards: 136.97815, mean: 0.10871
[32m[0906 14-05-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03454, current rewards: 142.72689, mean: 0.10895
[32m[0906 14-05-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03457, current rewards: 148.47744, mean: 0.10917
[32m[0906 14-05-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03463, current rewards: 154.22839, mean: 0.10938
[32m[0906 14-05-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03468, current rewards: 159.97947, mean: 0.10957
[32m[0906 14-05-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03474, current rewards: 163.65708, mean: 0.10838
[32m[0906 14-05-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03479, current rewards: 169.30308, mean: 0.10853
[32m[0906 14-05-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03484, current rewards: 174.95100, mean: 0.10867
[32m[0906 14-05-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03488, current rewards: 180.48456, mean: 0.10873
[32m[0906 14-05-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03492, current rewards: 186.11720, mean: 0.10884
[32m[0906 14-05-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03496, current rewards: 190.67257, mean: 0.10834
[32m[0906 14-05-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03499, current rewards: 196.31347, mean: 0.10846
[32m[0906 14-05-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03503, current rewards: 201.94974, mean: 0.10858
[32m[0906 14-05-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03506, current rewards: 207.59086, mean: 0.10869
[32m[0906 14-05-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03508, current rewards: 213.22902, mean: 0.10879
[32m[0906 14-05-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03511, current rewards: 218.87116, mean: 0.10889
[32m[0906 14-05-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03513, current rewards: 224.54360, mean: 0.10900
[32m[0906 14-05-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03516, current rewards: 230.20627, mean: 0.10910
[32m[0906 14-05-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03518, current rewards: 235.85428, mean: 0.10919
[32m[0906 14-06-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03519, current rewards: 241.50030, mean: 0.10928
[32m[0906 14-06-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03520, current rewards: 247.14599, mean: 0.10936
[32m[0906 14-06-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03521, current rewards: 250.69029, mean: 0.10852
[32m[0906 14-06-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03521, current rewards: 256.36754, mean: 0.10863
[32m[0906 14-06-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03521, current rewards: 262.04310, mean: 0.10873
[32m[0906 14-06-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03521, current rewards: 267.71730, mean: 0.10883
[32m[0906 14-06-11 @Agent.py:117][0m Average action selection time: 0.0352
[32m[0906 14-06-11 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-06-11 @MBExp.py:227][0m Rewards obtained: [272.13717962084417], Lows: [3], Highs: [5], Total time: 1330.11931
[32m[0906 14-06-44 @MBExp.py:144][0m ####################################################################
[32m[0906 14-06-44 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 14-06-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03511, current rewards: -1.15730, mean: -0.11573
[32m[0906 14-06-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03539, current rewards: 4.31875, mean: 0.07198
[32m[0906 14-06-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03529, current rewards: 9.79569, mean: 0.08905
[32m[0906 14-06-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03534, current rewards: 15.26593, mean: 0.09541
[32m[0906 14-06-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03531, current rewards: 20.73547, mean: 0.09874
[32m[0906 14-06-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03533, current rewards: 26.20984, mean: 0.10081
[32m[0906 14-06-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03532, current rewards: 31.68301, mean: 0.10220
[32m[0906 14-06-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03532, current rewards: 37.15876, mean: 0.10322
[32m[0906 14-06-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03516, current rewards: 42.68153, mean: 0.10410
[32m[0906 14-07-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03498, current rewards: 48.16407, mean: 0.10470
[32m[0906 14-07-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03485, current rewards: 53.64782, mean: 0.10519
[32m[0906 14-07-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03476, current rewards: 59.13153, mean: 0.10559
[32m[0906 14-07-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03469, current rewards: 64.61156, mean: 0.10592
[32m[0906 14-07-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03462, current rewards: 70.08994, mean: 0.10620
[32m[0906 14-07-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03454, current rewards: 75.57429, mean: 0.10644
[32m[0906 14-07-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03453, current rewards: 81.07316, mean: 0.10668
[32m[0906 14-07-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03454, current rewards: 86.55761, mean: 0.10686
[32m[0906 14-07-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03454, current rewards: 92.05694, mean: 0.10704
[32m[0906 14-07-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03453, current rewards: 97.54876, mean: 0.10720
[32m[0906 14-07-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03454, current rewards: 103.03852, mean: 0.10733
[32m[0906 14-07-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03453, current rewards: 108.52419, mean: 0.10745
[32m[0906 14-07-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03453, current rewards: 114.01906, mean: 0.10757
[32m[0906 14-07-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03453, current rewards: 119.51325, mean: 0.10767
[32m[0906 14-07-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03454, current rewards: 125.00563, mean: 0.10776
[32m[0906 14-07-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03453, current rewards: 130.49695, mean: 0.10785
[32m[0906 14-07-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03453, current rewards: 135.98625, mean: 0.10793
[32m[0906 14-07-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03453, current rewards: 139.31493, mean: 0.10635
[32m[0906 14-07-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03456, current rewards: 144.82568, mean: 0.10649
[32m[0906 14-07-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03459, current rewards: 150.33801, mean: 0.10662
[32m[0906 14-07-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03465, current rewards: 155.84784, mean: 0.10675
[32m[0906 14-07-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03470, current rewards: 161.35455, mean: 0.10686
[32m[0906 14-07-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03475, current rewards: 166.86164, mean: 0.10696
[32m[0906 14-07-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03480, current rewards: 172.47570, mean: 0.10713
[32m[0906 14-07-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03484, current rewards: 177.99544, mean: 0.10723
[32m[0906 14-07-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03487, current rewards: 183.51581, mean: 0.10732
[32m[0906 14-07-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03491, current rewards: 189.03625, mean: 0.10741
[32m[0906 14-07-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03494, current rewards: 194.55530, mean: 0.10749
[32m[0906 14-07-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03498, current rewards: 200.07542, mean: 0.10757
[32m[0906 14-07-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03501, current rewards: 205.59378, mean: 0.10764
[32m[0906 14-07-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03504, current rewards: 211.11389, mean: 0.10771
[32m[0906 14-07-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03507, current rewards: 215.58461, mean: 0.10726
[32m[0906 14-07-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03510, current rewards: 221.19833, mean: 0.10738
[32m[0906 14-07-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03512, current rewards: 226.76145, mean: 0.10747
[32m[0906 14-08-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03513, current rewards: 232.32271, mean: 0.10756
[32m[0906 14-08-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03514, current rewards: 234.01672, mean: 0.10589
[32m[0906 14-08-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03515, current rewards: 242.32051, mean: 0.10722
[32m[0906 14-08-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03516, current rewards: 250.62063, mean: 0.10849
[32m[0906 14-08-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03516, current rewards: 258.92075, mean: 0.10971
[32m[0906 14-08-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03517, current rewards: 267.22087, mean: 0.11088
[32m[0906 14-08-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03517, current rewards: 251.31884, mean: 0.10216
[32m[0906 14-08-13 @Agent.py:117][0m Average action selection time: 0.0352
[32m[0906 14-08-13 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-08-13 @MBExp.py:227][0m Rewards obtained: [211.3188439154024], Lows: [3], Highs: [62], Total time: 1418.6945210000001
[32m[0906 14-08-48 @MBExp.py:144][0m ####################################################################
[32m[0906 14-08-48 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 14-08-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03535, current rewards: 0.01369, mean: 0.00137
[32m[0906 14-08-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03525, current rewards: 5.62583, mean: 0.09376
[32m[0906 14-08-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03528, current rewards: 11.12604, mean: 0.10115
[32m[0906 14-08-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03536, current rewards: 16.63095, mean: 0.10394
[32m[0906 14-08-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03543, current rewards: 22.13425, mean: 0.10540
[32m[0906 14-08-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03542, current rewards: 27.63955, mean: 0.10631
[32m[0906 14-08-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03535, current rewards: 33.14170, mean: 0.10691
[32m[0906 14-09-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03524, current rewards: 38.64676, mean: 0.10735
[32m[0906 14-09-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03510, current rewards: 41.78241, mean: 0.10191
[32m[0906 14-09-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03494, current rewards: 47.25408, mean: 0.10273
[32m[0906 14-09-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03482, current rewards: 52.72446, mean: 0.10338
[32m[0906 14-09-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03473, current rewards: 58.19081, mean: 0.10391
[32m[0906 14-09-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03465, current rewards: 63.65550, mean: 0.10435
[32m[0906 14-09-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03457, current rewards: 69.12684, mean: 0.10474
[32m[0906 14-09-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03452, current rewards: 74.59497, mean: 0.10506
[32m[0906 14-09-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03450, current rewards: 80.06852, mean: 0.10535
[32m[0906 14-09-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03450, current rewards: 85.62417, mean: 0.10571
[32m[0906 14-09-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03450, current rewards: 91.26853, mean: 0.10613
[32m[0906 14-09-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03449, current rewards: 96.77396, mean: 0.10635
[32m[0906 14-09-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03450, current rewards: 102.27474, mean: 0.10654
[32m[0906 14-09-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03450, current rewards: 107.78032, mean: 0.10671
[32m[0906 14-09-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03450, current rewards: 113.28993, mean: 0.10688
[32m[0906 14-09-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03451, current rewards: 117.70311, mean: 0.10604
[32m[0906 14-09-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03451, current rewards: 123.22775, mean: 0.10623
[32m[0906 14-09-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03451, current rewards: 128.74912, mean: 0.10640
[32m[0906 14-09-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03452, current rewards: 134.14224, mean: 0.10646
[32m[0906 14-09-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03452, current rewards: 139.66138, mean: 0.10661
[32m[0906 14-09-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03455, current rewards: 145.18307, mean: 0.10675
[32m[0906 14-09-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03457, current rewards: 150.70271, mean: 0.10688
[32m[0906 14-09-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03460, current rewards: 154.10631, mean: 0.10555
[32m[0906 14-09-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03466, current rewards: 159.63380, mean: 0.10572
[32m[0906 14-09-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03471, current rewards: 165.15687, mean: 0.10587
[32m[0906 14-09-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03476, current rewards: 170.68038, mean: 0.10601
[32m[0906 14-09-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03481, current rewards: 176.17613, mean: 0.10613
[32m[0906 14-09-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03485, current rewards: 181.69864, mean: 0.10626
[32m[0906 14-09-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03489, current rewards: 187.21466, mean: 0.10637
[32m[0906 14-09-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03493, current rewards: 192.73688, mean: 0.10648
[32m[0906 14-09-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03497, current rewards: 198.25574, mean: 0.10659
[32m[0906 14-09-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03500, current rewards: 203.77422, mean: 0.10669
[32m[0906 14-09-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03503, current rewards: 209.29327, mean: 0.10678
[32m[0906 14-09-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03506, current rewards: 214.81275, mean: 0.10687
[32m[0906 14-10-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03509, current rewards: 216.41057, mean: 0.10505
[32m[0906 14-10-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03509, current rewards: 222.97650, mean: 0.10568
[32m[0906 14-10-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03510, current rewards: 229.58473, mean: 0.10629
[32m[0906 14-10-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03511, current rewards: 236.19296, mean: 0.10687
[32m[0906 14-10-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03511, current rewards: 242.80120, mean: 0.10743
[32m[0906 14-10-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03512, current rewards: 249.40943, mean: 0.10797
[32m[0906 14-10-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03513, current rewards: 256.01766, mean: 0.10848
[32m[0906 14-10-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03514, current rewards: 249.03992, mean: 0.10334
[32m[0906 14-10-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03514, current rewards: 199.03992, mean: 0.08091
[32m[0906 14-10-16 @Agent.py:117][0m Average action selection time: 0.0351
[32m[0906 14-10-16 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-10-16 @MBExp.py:227][0m Rewards obtained: [159.03991800702136], Lows: [4], Highs: [104], Total time: 1507.180757
[32m[0906 14-10-53 @MBExp.py:144][0m ####################################################################
[32m[0906 14-10-53 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 14-10-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03519, current rewards: 0.92900, mean: 0.09290
[32m[0906 14-10-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03522, current rewards: 6.32734, mean: 0.10546
[32m[0906 14-10-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03531, current rewards: 11.82795, mean: 0.10753
[32m[0906 14-10-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03531, current rewards: 17.32777, mean: 0.10830
[32m[0906 14-11-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03530, current rewards: 22.82726, mean: 0.10870
[32m[0906 14-11-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03523, current rewards: 28.32597, mean: 0.10895
[32m[0906 14-11-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03512, current rewards: 33.82725, mean: 0.10912
[32m[0906 14-11-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03500, current rewards: 39.32312, mean: 0.10923
[32m[0906 14-11-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03495, current rewards: 44.82246, mean: 0.10932
[32m[0906 14-11-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03480, current rewards: 50.33228, mean: 0.10942
[32m[0906 14-11-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03470, current rewards: 55.80053, mean: 0.10941
[32m[0906 14-11-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03462, current rewards: 61.26828, mean: 0.10941
[32m[0906 14-11-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03454, current rewards: 66.73698, mean: 0.10940
[32m[0906 14-11-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03447, current rewards: 72.20759, mean: 0.10941
[32m[0906 14-11-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03442, current rewards: 77.67974, mean: 0.10941
[32m[0906 14-11-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03443, current rewards: 83.14840, mean: 0.10941
[32m[0906 14-11-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03445, current rewards: 88.61740, mean: 0.10940
[32m[0906 14-11-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03445, current rewards: 91.94458, mean: 0.10691
[32m[0906 14-11-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03446, current rewards: 97.35253, mean: 0.10698
[32m[0906 14-11-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03446, current rewards: 102.76613, mean: 0.10705
[32m[0906 14-11-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03447, current rewards: 108.17887, mean: 0.10711
[32m[0906 14-11-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03448, current rewards: 113.59249, mean: 0.10716
[32m[0906 14-11-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03448, current rewards: 119.00801, mean: 0.10721
[32m[0906 14-11-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03449, current rewards: 124.42463, mean: 0.10726
[32m[0906 14-11-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03449, current rewards: 129.83519, mean: 0.10730
[32m[0906 14-11-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03449, current rewards: 135.42185, mean: 0.10748
[32m[0906 14-11-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03448, current rewards: 140.84088, mean: 0.10751
[32m[0906 14-11-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03451, current rewards: 146.25409, mean: 0.10754
[32m[0906 14-11-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03455, current rewards: 149.57178, mean: 0.10608
[32m[0906 14-11-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03458, current rewards: 154.99393, mean: 0.10616
[32m[0906 14-11-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03460, current rewards: 160.41364, mean: 0.10623
[32m[0906 14-11-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03463, current rewards: 165.83029, mean: 0.10630
[32m[0906 14-11-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03468, current rewards: 171.25083, mean: 0.10637
[32m[0906 14-11-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03473, current rewards: 176.57942, mean: 0.10637
[32m[0906 14-11-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03477, current rewards: 181.86035, mean: 0.10635
[32m[0906 14-11-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03482, current rewards: 187.28418, mean: 0.10641
[32m[0906 14-11-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03486, current rewards: 192.71435, mean: 0.10647
[32m[0906 14-11-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03490, current rewards: 198.14179, mean: 0.10653
[32m[0906 14-12-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03493, current rewards: 203.57016, mean: 0.10658
[32m[0906 14-12-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03496, current rewards: 208.99256, mean: 0.10663
[32m[0906 14-12-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03499, current rewards: 214.41990, mean: 0.10668
[32m[0906 14-12-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03499, current rewards: 219.84912, mean: 0.10672
[32m[0906 14-12-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03500, current rewards: 224.67586, mean: 0.10648
[32m[0906 14-12-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03502, current rewards: 230.15073, mean: 0.10655
[32m[0906 14-12-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03502, current rewards: 235.58678, mean: 0.10660
[32m[0906 14-12-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03503, current rewards: 241.01879, mean: 0.10665
[32m[0906 14-12-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03503, current rewards: 244.41777, mean: 0.10581
[32m[0906 14-12-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03504, current rewards: 249.88558, mean: 0.10588
[32m[0906 14-12-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03505, current rewards: 255.35027, mean: 0.10595
[32m[0906 14-12-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03506, current rewards: 260.81746, mean: 0.10602
[32m[0906 14-12-22 @Agent.py:117][0m Average action selection time: 0.0351
[32m[0906 14-12-22 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-12-22 @MBExp.py:227][0m Rewards obtained: [265.192267337979], Lows: [2], Highs: [3], Total time: 1595.459791
[32m[0906 14-13-01 @MBExp.py:144][0m ####################################################################
[32m[0906 14-13-01 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 14-13-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03421, current rewards: -1.02497, mean: -0.10250
[32m[0906 14-13-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03524, current rewards: 4.58011, mean: 0.07634
[32m[0906 14-13-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03519, current rewards: 10.14089, mean: 0.09219
[32m[0906 14-13-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03523, current rewards: 15.70570, mean: 0.09816
[32m[0906 14-13-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03517, current rewards: 21.27081, mean: 0.10129
[32m[0906 14-13-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03502, current rewards: 26.83200, mean: 0.10320
[32m[0906 14-13-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03495, current rewards: 32.39415, mean: 0.10450
[32m[0906 14-13-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03487, current rewards: 37.95865, mean: 0.10544
[32m[0906 14-13-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03483, current rewards: 43.52399, mean: 0.10616
[32m[0906 14-13-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03469, current rewards: 49.10193, mean: 0.10674
[32m[0906 14-13-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03457, current rewards: 54.66131, mean: 0.10718
[32m[0906 14-13-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03451, current rewards: 60.22611, mean: 0.10755
[32m[0906 14-13-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03441, current rewards: 65.78531, mean: 0.10784
[32m[0906 14-13-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03435, current rewards: 69.20454, mean: 0.10486
[32m[0906 14-13-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03429, current rewards: 74.78824, mean: 0.10534
[32m[0906 14-13-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03428, current rewards: 80.37358, mean: 0.10575
[32m[0906 14-13-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03430, current rewards: 85.95460, mean: 0.10612
[32m[0906 14-13-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03430, current rewards: 91.70936, mean: 0.10664
[32m[0906 14-13-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03430, current rewards: 97.31604, mean: 0.10694
[32m[0906 14-13-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03431, current rewards: 102.92637, mean: 0.10721
[32m[0906 14-13-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03432, current rewards: 108.53387, mean: 0.10746
[32m[0906 14-13-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03432, current rewards: 112.19235, mean: 0.10584
[32m[0906 14-13-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03433, current rewards: 117.79033, mean: 0.10612
[32m[0906 14-13-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03435, current rewards: 123.38920, mean: 0.10637
[32m[0906 14-13-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03435, current rewards: 128.98853, mean: 0.10660
[32m[0906 14-13-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03436, current rewards: 130.69775, mean: 0.10373
[32m[0906 14-13-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03436, current rewards: 139.23567, mean: 0.10629
[32m[0906 14-13-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03440, current rewards: 147.77359, mean: 0.10866
[32m[0906 14-13-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03443, current rewards: 156.31151, mean: 0.11086
[32m[0906 14-13-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03447, current rewards: 164.84943, mean: 0.11291
[32m[0906 14-13-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03450, current rewards: 173.38735, mean: 0.11483
[32m[0906 14-13-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03453, current rewards: 181.92527, mean: 0.11662
[32m[0906 14-13-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03455, current rewards: 190.46319, mean: 0.11830
[32m[0906 14-13-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03461, current rewards: 198.20508, mean: 0.11940
[32m[0906 14-14-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03465, current rewards: 201.59678, mean: 0.11789
[32m[0906 14-14-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03469, current rewards: 180.42342, mean: 0.10251
[32m[0906 14-14-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03473, current rewards: 130.42342, mean: 0.07206
[32m[0906 14-14-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03479, current rewards: 80.42342, mean: 0.04324
[32m[0906 14-14-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03482, current rewards: 30.42342, mean: 0.01593
[32m[0906 14-14-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03484, current rewards: -19.57658, mean: -0.00999
[32m[0906 14-14-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03486, current rewards: -69.57658, mean: -0.03462
[32m[0906 14-14-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03487, current rewards: -119.57658, mean: -0.05805
[32m[0906 14-14-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03488, current rewards: -169.57658, mean: -0.08037
[32m[0906 14-14-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03489, current rewards: -219.57658, mean: -0.10166
[32m[0906 14-14-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03490, current rewards: -269.57658, mean: -0.12198
[32m[0906 14-14-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03491, current rewards: -319.57658, mean: -0.14141
[32m[0906 14-14-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03492, current rewards: -369.57658, mean: -0.15999
[32m[0906 14-14-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03494, current rewards: -419.57658, mean: -0.17779
[32m[0906 14-14-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03494, current rewards: -469.57658, mean: -0.19485
[32m[0906 14-14-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03496, current rewards: -519.57658, mean: -0.21121
[32m[0906 14-14-29 @Agent.py:117][0m Average action selection time: 0.0350
[32m[0906 14-14-29 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-14-29 @MBExp.py:227][0m Rewards obtained: [-559.5765753621251], Lows: [4], Highs: [765], Total time: 1683.506818
[32m[0906 14-15-10 @MBExp.py:144][0m ####################################################################
[32m[0906 14-15-10 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 14-15-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03516, current rewards: -1.07506, mean: -0.10751
[32m[0906 14-15-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03531, current rewards: 4.41768, mean: 0.07363
[32m[0906 14-15-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03530, current rewards: 9.91072, mean: 0.09010
[32m[0906 14-15-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03504, current rewards: 15.40173, mean: 0.09626
[32m[0906 14-15-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03491, current rewards: 20.89299, mean: 0.09949
[32m[0906 14-15-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03484, current rewards: 26.38732, mean: 0.10149
[32m[0906 14-15-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03476, current rewards: 31.88269, mean: 0.10285
[32m[0906 14-15-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03471, current rewards: 37.37557, mean: 0.10382
[32m[0906 14-15-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03465, current rewards: 43.14024, mean: 0.10522
[32m[0906 14-15-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03458, current rewards: 48.68271, mean: 0.10583
[32m[0906 14-15-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03450, current rewards: 54.22384, mean: 0.10632
[32m[0906 14-15-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03441, current rewards: 59.76648, mean: 0.10673
[32m[0906 14-15-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03435, current rewards: 65.30749, mean: 0.10706
[32m[0906 14-15-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03431, current rewards: 69.73766, mean: 0.10566
[32m[0906 14-15-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03428, current rewards: 75.25615, mean: 0.10599
[32m[0906 14-15-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03427, current rewards: 80.77671, mean: 0.10629
[32m[0906 14-15-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03429, current rewards: 86.26124, mean: 0.10650
[32m[0906 14-15-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03431, current rewards: 91.57076, mean: 0.10648
[32m[0906 14-15-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03431, current rewards: 97.05094, mean: 0.10665
[32m[0906 14-15-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03432, current rewards: 100.45989, mean: 0.10465
[32m[0906 14-15-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03433, current rewards: 105.97918, mean: 0.10493
[32m[0906 14-15-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03435, current rewards: 111.49696, mean: 0.10519
[32m[0906 14-15-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03436, current rewards: 117.01487, mean: 0.10542
[32m[0906 14-15-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03436, current rewards: 122.53221, mean: 0.10563
[32m[0906 14-15-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03438, current rewards: 128.04474, mean: 0.10582
[32m[0906 14-15-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03439, current rewards: 133.72788, mean: 0.10613
[32m[0906 14-15-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03440, current rewards: 139.27729, mean: 0.10632
[32m[0906 14-15-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03444, current rewards: 144.83222, mean: 0.10649
[32m[0906 14-15-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03447, current rewards: 150.38531, mean: 0.10666
[32m[0906 14-16-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03451, current rewards: 153.87703, mean: 0.10540
[32m[0906 14-16-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03455, current rewards: 159.45494, mean: 0.10560
[32m[0906 14-16-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03458, current rewards: 165.03371, mean: 0.10579
[32m[0906 14-16-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03461, current rewards: 170.60821, mean: 0.10597
[32m[0906 14-16-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03463, current rewards: 176.21087, mean: 0.10615
[32m[0906 14-16-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03468, current rewards: 180.75056, mean: 0.10570
[32m[0906 14-16-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03472, current rewards: 186.31519, mean: 0.10586
[32m[0906 14-16-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03476, current rewards: 191.88048, mean: 0.10601
[32m[0906 14-16-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03480, current rewards: 197.44954, mean: 0.10616
[32m[0906 14-16-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03482, current rewards: 203.01349, mean: 0.10629
[32m[0906 14-16-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03484, current rewards: 208.58339, mean: 0.10642
[32m[0906 14-16-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03485, current rewards: 214.14306, mean: 0.10654
[32m[0906 14-16-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03486, current rewards: 219.70579, mean: 0.10665
[32m[0906 14-16-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03487, current rewards: 225.14830, mean: 0.10671
[32m[0906 14-16-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03489, current rewards: 226.53356, mean: 0.10488
[32m[0906 14-16-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03490, current rewards: 232.11565, mean: 0.10503
[32m[0906 14-16-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03491, current rewards: 237.70023, mean: 0.10518
[32m[0906 14-16-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03492, current rewards: 243.28370, mean: 0.10532
[32m[0906 14-16-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03494, current rewards: 248.86803, mean: 0.10545
[32m[0906 14-16-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03494, current rewards: 254.45144, mean: 0.10558
[32m[0906 14-16-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03495, current rewards: 260.03493, mean: 0.10571
[32m[0906 14-16-38 @Agent.py:117][0m Average action selection time: 0.0350
[32m[0906 14-16-38 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-16-38 @MBExp.py:227][0m Rewards obtained: [264.7815014080219], Lows: [4], Highs: [4], Total time: 1771.548643
[32m[0906 14-17-21 @MBExp.py:144][0m ####################################################################
[32m[0906 14-17-21 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 14-17-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03468, current rewards: -1.90313, mean: -0.19031
[32m[0906 14-17-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03516, current rewards: 4.08026, mean: 0.06800
[32m[0906 14-17-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03494, current rewards: 9.95878, mean: 0.09053
[32m[0906 14-17-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03482, current rewards: 15.83777, mean: 0.09899
[32m[0906 14-17-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03473, current rewards: 21.72011, mean: 0.10343
[32m[0906 14-17-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03467, current rewards: 27.59167, mean: 0.10612
[32m[0906 14-17-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03462, current rewards: 33.46638, mean: 0.10796
[32m[0906 14-17-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03463, current rewards: 37.34891, mean: 0.10375
[32m[0906 14-17-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03460, current rewards: 43.02435, mean: 0.10494
[32m[0906 14-17-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03452, current rewards: 48.66100, mean: 0.10578
[32m[0906 14-17-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03443, current rewards: 54.32205, mean: 0.10651
[32m[0906 14-17-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03437, current rewards: 59.98460, mean: 0.10712
[32m[0906 14-17-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03435, current rewards: 65.64546, mean: 0.10762
[32m[0906 14-17-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03429, current rewards: 71.30761, mean: 0.10804
[32m[0906 14-17-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03425, current rewards: 76.97200, mean: 0.10841
[32m[0906 14-17-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03425, current rewards: 81.49950, mean: 0.10724
[32m[0906 14-17-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03427, current rewards: 87.13586, mean: 0.10758
[32m[0906 14-17-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03429, current rewards: 92.77346, mean: 0.10788
[32m[0906 14-17-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03431, current rewards: 98.40654, mean: 0.10814
[32m[0906 14-17-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03432, current rewards: 104.03741, mean: 0.10837
[32m[0906 14-17-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03432, current rewards: 109.67142, mean: 0.10859
[32m[0906 14-17-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03434, current rewards: 115.32235, mean: 0.10879
[32m[0906 14-18-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03435, current rewards: 120.95201, mean: 0.10897
[32m[0906 14-18-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03435, current rewards: 126.58630, mean: 0.10913
[32m[0906 14-18-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03436, current rewards: 132.21868, mean: 0.10927
[32m[0906 14-18-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03437, current rewards: 137.64751, mean: 0.10924
[32m[0906 14-18-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03438, current rewards: 143.06869, mean: 0.10921
[32m[0906 14-18-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03442, current rewards: 148.49122, mean: 0.10918
[32m[0906 14-18-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03445, current rewards: 153.91903, mean: 0.10916
[32m[0906 14-18-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03449, current rewards: 159.34128, mean: 0.10914
[32m[0906 14-18-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03451, current rewards: 162.67560, mean: 0.10773
[32m[0906 14-18-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03454, current rewards: 168.23877, mean: 0.10785
[32m[0906 14-18-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03457, current rewards: 173.79632, mean: 0.10795
[32m[0906 14-18-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03459, current rewards: 179.43629, mean: 0.10809
[32m[0906 14-18-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03461, current rewards: 185.00452, mean: 0.10819
[32m[0906 14-18-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03465, current rewards: 190.52115, mean: 0.10825
[32m[0906 14-18-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03470, current rewards: 196.04389, mean: 0.10831
[32m[0906 14-18-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03472, current rewards: 201.56242, mean: 0.10837
[32m[0906 14-18-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03473, current rewards: 207.08152, mean: 0.10842
[32m[0906 14-18-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03475, current rewards: 212.60099, mean: 0.10847
[32m[0906 14-18-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03477, current rewards: 213.84158, mean: 0.10639
[32m[0906 14-18-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03478, current rewards: 219.30816, mean: 0.10646
[32m[0906 14-18-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03480, current rewards: 224.75517, mean: 0.10652
[32m[0906 14-18-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03481, current rewards: 230.22356, mean: 0.10658
[32m[0906 14-18-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03482, current rewards: 233.53745, mean: 0.10567
[32m[0906 14-18-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03483, current rewards: 239.06762, mean: 0.10578
[32m[0906 14-18-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03484, current rewards: 244.59377, mean: 0.10588
[32m[0906 14-18-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03485, current rewards: 250.11262, mean: 0.10598
[32m[0906 14-18-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03486, current rewards: 255.63475, mean: 0.10607
[32m[0906 14-18-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03488, current rewards: 261.16275, mean: 0.10616
[32m[0906 14-18-49 @Agent.py:117][0m Average action selection time: 0.0349
[32m[0906 14-18-49 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-18-49 @MBExp.py:227][0m Rewards obtained: [263.45844633768695], Lows: [6], Highs: [4], Total time: 1859.398736
[32m[0906 14-19-35 @MBExp.py:144][0m ####################################################################
[32m[0906 14-19-35 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 14-19-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03393, current rewards: 0.04037, mean: 0.00404
[32m[0906 14-19-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03433, current rewards: 5.36915, mean: 0.08949
[32m[0906 14-19-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03438, current rewards: 10.76645, mean: 0.09788
[32m[0906 14-19-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03438, current rewards: 16.16454, mean: 0.10103
[32m[0906 14-19-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03440, current rewards: 21.56140, mean: 0.10267
[32m[0906 14-19-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03442, current rewards: 26.96024, mean: 0.10369
[32m[0906 14-19-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03441, current rewards: 32.35860, mean: 0.10438
[32m[0906 14-19-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03444, current rewards: 37.75837, mean: 0.10488
[32m[0906 14-19-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03444, current rewards: 43.24796, mean: 0.10548
[32m[0906 14-19-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03437, current rewards: 48.69386, mean: 0.10586
[32m[0906 14-19-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03430, current rewards: 54.14438, mean: 0.10617
[32m[0906 14-19-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03426, current rewards: 59.58310, mean: 0.10640
[32m[0906 14-19-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03421, current rewards: 65.03005, mean: 0.10661
[32m[0906 14-19-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03416, current rewards: 68.48032, mean: 0.10376
[32m[0906 14-19-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03413, current rewards: 74.07991, mean: 0.10434
[32m[0906 14-20-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03412, current rewards: 79.67470, mean: 0.10484
[32m[0906 14-20-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03417, current rewards: 85.29317, mean: 0.10530
[32m[0906 14-20-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03419, current rewards: 90.87977, mean: 0.10567
[32m[0906 14-20-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03421, current rewards: 96.45896, mean: 0.10600
[32m[0906 14-20-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03422, current rewards: 100.94873, mean: 0.10515
[32m[0906 14-20-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03424, current rewards: 106.69448, mean: 0.10564
[32m[0906 14-20-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03424, current rewards: 112.43596, mean: 0.10607
[32m[0906 14-20-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03425, current rewards: 118.18134, mean: 0.10647
[32m[0906 14-20-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03426, current rewards: 123.92790, mean: 0.10683
[32m[0906 14-20-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03427, current rewards: 125.57404, mean: 0.10378
[32m[0906 14-20-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03427, current rewards: 133.50407, mean: 0.10596
[32m[0906 14-20-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03428, current rewards: 141.57835, mean: 0.10808
[32m[0906 14-20-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03432, current rewards: 149.65264, mean: 0.11004
[32m[0906 14-20-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03436, current rewards: 157.72693, mean: 0.11186
[32m[0906 14-20-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03440, current rewards: 165.80121, mean: 0.11356
[32m[0906 14-20-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03443, current rewards: 173.87550, mean: 0.11515
[32m[0906 14-20-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03446, current rewards: 181.94978, mean: 0.11663
[32m[0906 14-20-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03449, current rewards: 190.02407, mean: 0.11803
[32m[0906 14-20-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03452, current rewards: 151.53080, mean: 0.09128
[32m[0906 14-20-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03454, current rewards: 101.53080, mean: 0.05937
[32m[0906 14-20-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03456, current rewards: 51.53080, mean: 0.02928
[32m[0906 14-20-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03457, current rewards: 1.53080, mean: 0.00085
[32m[0906 14-20-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03459, current rewards: -48.46920, mean: -0.02606
[32m[0906 14-20-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03461, current rewards: -98.46920, mean: -0.05155
[32m[0906 14-20-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03463, current rewards: -148.46920, mean: -0.07575
[32m[0906 14-20-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03464, current rewards: -198.46920, mean: -0.09874
[32m[0906 14-20-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03466, current rewards: -248.46920, mean: -0.12062
[32m[0906 14-20-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03467, current rewards: -298.46920, mean: -0.14145
[32m[0906 14-20-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03469, current rewards: -348.46920, mean: -0.16133
[32m[0906 14-20-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03470, current rewards: -398.46920, mean: -0.18030
[32m[0906 14-20-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03471, current rewards: -448.46920, mean: -0.19844
[32m[0906 14-20-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03473, current rewards: -498.46920, mean: -0.21579
[32m[0906 14-20-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03474, current rewards: -548.46920, mean: -0.23240
[32m[0906 14-20-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03475, current rewards: -598.46920, mean: -0.24833
[32m[0906 14-21-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03476, current rewards: -648.46920, mean: -0.26361
[32m[0906 14-21-02 @Agent.py:117][0m Average action selection time: 0.0348
[32m[0906 14-21-02 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-21-02 @MBExp.py:227][0m Rewards obtained: [-688.4691964364126], Lows: [3], Highs: [882], Total time: 1946.9793080000002
[32m[0906 14-21-50 @MBExp.py:144][0m ####################################################################
[32m[0906 14-21-50 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 14-21-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03351, current rewards: -1.10507, mean: -0.11051
[32m[0906 14-21-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03425, current rewards: 4.35920, mean: 0.07265
[32m[0906 14-21-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03433, current rewards: 9.81917, mean: 0.08927
[32m[0906 14-21-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03437, current rewards: 15.27428, mean: 0.09546
[32m[0906 14-21-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03439, current rewards: 20.73173, mean: 0.09872
[32m[0906 14-21-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03438, current rewards: 26.18588, mean: 0.10071
[32m[0906 14-22-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03436, current rewards: 31.64002, mean: 0.10206
[32m[0906 14-22-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03437, current rewards: 35.94778, mean: 0.09985
[32m[0906 14-22-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03436, current rewards: 41.38068, mean: 0.10093
[32m[0906 14-22-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03428, current rewards: 46.83984, mean: 0.10183
[32m[0906 14-22-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03421, current rewards: 52.29831, mean: 0.10255
[32m[0906 14-22-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03413, current rewards: 57.76225, mean: 0.10315
[32m[0906 14-22-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03411, current rewards: 63.22448, mean: 0.10365
[32m[0906 14-22-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03408, current rewards: 68.68227, mean: 0.10406
[32m[0906 14-22-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03405, current rewards: 74.14432, mean: 0.10443
[32m[0906 14-22-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03402, current rewards: 79.60902, mean: 0.10475
[32m[0906 14-22-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03405, current rewards: 85.14390, mean: 0.10512
[32m[0906 14-22-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03408, current rewards: 90.60782, mean: 0.10536
[32m[0906 14-22-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03410, current rewards: 94.94382, mean: 0.10433
[32m[0906 14-22-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03412, current rewards: 100.40127, mean: 0.10458
[32m[0906 14-22-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03414, current rewards: 105.85405, mean: 0.10481
[32m[0906 14-22-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03416, current rewards: 111.30347, mean: 0.10500
[32m[0906 14-22-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03418, current rewards: 116.75544, mean: 0.10519
[32m[0906 14-22-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03420, current rewards: 122.20334, mean: 0.10535
[32m[0906 14-22-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03422, current rewards: 126.73096, mean: 0.10474
[32m[0906 14-22-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03423, current rewards: 132.18567, mean: 0.10491
[32m[0906 14-22-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03425, current rewards: 137.63879, mean: 0.10507
[32m[0906 14-22-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03430, current rewards: 143.09137, mean: 0.10521
[32m[0906 14-22-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03433, current rewards: 148.54786, mean: 0.10535
[32m[0906 14-22-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03437, current rewards: 154.00576, mean: 0.10548
[32m[0906 14-22-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03439, current rewards: 160.20506, mean: 0.10610
[32m[0906 14-22-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03443, current rewards: 165.67929, mean: 0.10620
[32m[0906 14-22-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03445, current rewards: 171.08113, mean: 0.10626
[32m[0906 14-22-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03448, current rewards: 176.47171, mean: 0.10631
[32m[0906 14-22-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03450, current rewards: 181.93641, mean: 0.10640
[32m[0906 14-22-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03450, current rewards: 187.39847, mean: 0.10648
[32m[0906 14-22-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03450, current rewards: 192.86118, mean: 0.10655
[32m[0906 14-22-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03450, current rewards: 198.32399, mean: 0.10663
[32m[0906 14-22-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03453, current rewards: 203.79071, mean: 0.10670
[32m[0906 14-22-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03455, current rewards: 209.25667, mean: 0.10676
[32m[0906 14-23-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03458, current rewards: 214.71854, mean: 0.10683
[32m[0906 14-23-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03459, current rewards: 220.42229, mean: 0.10700
[32m[0906 14-23-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03461, current rewards: 223.87948, mean: 0.10610
[32m[0906 14-23-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03463, current rewards: 229.35599, mean: 0.10618
[32m[0906 14-23-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03465, current rewards: 234.83236, mean: 0.10626
[32m[0906 14-23-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03466, current rewards: 240.30732, mean: 0.10633
[32m[0906 14-23-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03468, current rewards: 245.77767, mean: 0.10640
[32m[0906 14-23-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03470, current rewards: 251.25053, mean: 0.10646
[32m[0906 14-23-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03471, current rewards: 255.75156, mean: 0.10612
[32m[0906 14-23-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03473, current rewards: 261.18683, mean: 0.10617
[32m[0906 14-23-17 @Agent.py:117][0m Average action selection time: 0.0347
[32m[0906 14-23-17 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-23-17 @MBExp.py:227][0m Rewards obtained: [265.3950951882315], Lows: [1], Highs: [6], Total time: 2034.4471200000003
[32m[0906 14-24-07 @MBExp.py:144][0m ####################################################################
[32m[0906 14-24-07 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 14-24-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03394, current rewards: -1.07609, mean: -0.10761
[32m[0906 14-24-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03432, current rewards: 4.94619, mean: 0.08244
[32m[0906 14-24-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03440, current rewards: 10.97111, mean: 0.09974
[32m[0906 14-24-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03444, current rewards: 16.99695, mean: 0.10623
[32m[0906 14-24-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03445, current rewards: 23.01989, mean: 0.10962
[32m[0906 14-24-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03445, current rewards: 29.04548, mean: 0.11171
[32m[0906 14-24-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03445, current rewards: 35.07180, mean: 0.11313
[32m[0906 14-24-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03442, current rewards: 41.09916, mean: 0.11416
[32m[0906 14-24-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03441, current rewards: 47.07117, mean: 0.11481
[32m[0906 14-24-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03433, current rewards: 53.12752, mean: 0.11549
[32m[0906 14-24-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03427, current rewards: 57.99878, mean: 0.11372
[32m[0906 14-24-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03422, current rewards: 63.75072, mean: 0.11384
[32m[0906 14-24-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03418, current rewards: 69.51199, mean: 0.11395
[32m[0906 14-24-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03414, current rewards: 75.26593, mean: 0.11404
[32m[0906 14-24-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03411, current rewards: 81.02215, mean: 0.11412
[32m[0906 14-24-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03408, current rewards: 86.78233, mean: 0.11419
[32m[0906 14-24-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03411, current rewards: 92.61566, mean: 0.11434
[32m[0906 14-24-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03413, current rewards: 98.38029, mean: 0.11440
[32m[0906 14-24-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03415, current rewards: 104.12476, mean: 0.11442
[32m[0906 14-24-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03416, current rewards: 109.87591, mean: 0.11445
[32m[0906 14-24-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03418, current rewards: 115.62306, mean: 0.11448
[32m[0906 14-24-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03420, current rewards: 121.37074, mean: 0.11450
[32m[0906 14-24-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03422, current rewards: 127.12542, mean: 0.11453
[32m[0906 14-24-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03423, current rewards: 132.88059, mean: 0.11455
[32m[0906 14-24-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03423, current rewards: 134.49637, mean: 0.11115
[32m[0906 14-24-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03424, current rewards: 140.32066, mean: 0.11137
[32m[0906 14-24-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03426, current rewards: 146.13433, mean: 0.11155
[32m[0906 14-24-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03430, current rewards: 151.94827, mean: 0.11173
[32m[0906 14-24-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03434, current rewards: 157.76045, mean: 0.11189
[32m[0906 14-24-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03438, current rewards: 163.57475, mean: 0.11204
[32m[0906 14-24-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03442, current rewards: 169.38895, mean: 0.11218
[32m[0906 14-25-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03446, current rewards: 175.20051, mean: 0.11231
[32m[0906 14-25-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03449, current rewards: 181.01374, mean: 0.11243
[32m[0906 14-25-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03449, current rewards: 186.75979, mean: 0.11251
[32m[0906 14-25-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03449, current rewards: 192.64805, mean: 0.11266
[32m[0906 14-25-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03449, current rewards: 197.16548, mean: 0.11203
[32m[0906 14-25-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03449, current rewards: 202.52897, mean: 0.11189
[32m[0906 14-25-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03450, current rewards: 207.89072, mean: 0.11177
[32m[0906 14-25-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03450, current rewards: 213.25338, mean: 0.11165
[32m[0906 14-25-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03452, current rewards: 218.61765, mean: 0.11154
[32m[0906 14-25-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03454, current rewards: 223.98437, mean: 0.11144
[32m[0906 14-25-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03457, current rewards: 229.53558, mean: 0.11143
[32m[0906 14-25-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03459, current rewards: 234.84910, mean: 0.11130
[32m[0906 14-25-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03461, current rewards: 240.15820, mean: 0.11118
[32m[0906 14-25-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03464, current rewards: 243.92938, mean: 0.11038
[32m[0906 14-25-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03465, current rewards: 249.66786, mean: 0.11047
[32m[0906 14-25-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03467, current rewards: 255.40488, mean: 0.11056
[32m[0906 14-25-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03469, current rewards: 261.14280, mean: 0.11065
[32m[0906 14-25-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03471, current rewards: 266.87912, mean: 0.11074
[32m[0906 14-25-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03472, current rewards: 271.46029, mean: 0.11035
[32m[0906 14-25-34 @Agent.py:117][0m Average action selection time: 0.0347
[32m[0906 14-25-34 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-25-34 @MBExp.py:227][0m Rewards obtained: [275.9439764532244], Lows: [3], Highs: [5], Total time: 2121.9289440000002
[32m[0906 14-26-26 @MBExp.py:144][0m ####################################################################
[32m[0906 14-26-26 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 14-26-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03430, current rewards: 0.10585, mean: 0.01059
[32m[0906 14-26-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03433, current rewards: 5.84467, mean: 0.09741
[32m[0906 14-26-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03441, current rewards: 11.49604, mean: 0.10451
[32m[0906 14-26-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03435, current rewards: 17.14562, mean: 0.10716
[32m[0906 14-26-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03438, current rewards: 22.79389, mean: 0.10854
[32m[0906 14-26-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03438, current rewards: 28.44286, mean: 0.10940
[32m[0906 14-26-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03442, current rewards: 34.09332, mean: 0.10998
[32m[0906 14-26-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03445, current rewards: 37.46934, mean: 0.10408
[32m[0906 14-26-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03444, current rewards: 42.94986, mean: 0.10476
[32m[0906 14-26-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03436, current rewards: 48.49930, mean: 0.10543
[32m[0906 14-26-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03429, current rewards: 54.03982, mean: 0.10596
[32m[0906 14-26-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03424, current rewards: 59.58701, mean: 0.10641
[32m[0906 14-26-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03420, current rewards: 65.13424, mean: 0.10678
[32m[0906 14-26-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03417, current rewards: 70.68132, mean: 0.10709
[32m[0906 14-26-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03412, current rewards: 76.22525, mean: 0.10736
[32m[0906 14-26-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03410, current rewards: 81.77302, mean: 0.10760
[32m[0906 14-26-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03412, current rewards: 87.40940, mean: 0.10791
[32m[0906 14-26-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03414, current rewards: 92.93870, mean: 0.10807
[32m[0906 14-26-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03416, current rewards: 98.54728, mean: 0.10829
[32m[0906 14-26-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03418, current rewards: 104.14720, mean: 0.10849
[32m[0906 14-27-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03420, current rewards: 109.74761, mean: 0.10866
[32m[0906 14-27-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03422, current rewards: 115.34279, mean: 0.10881
[32m[0906 14-27-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03424, current rewards: 120.93721, mean: 0.10895
[32m[0906 14-27-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03424, current rewards: 125.47379, mean: 0.10817
[32m[0906 14-27-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03425, current rewards: 131.04361, mean: 0.10830
[32m[0906 14-27-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03426, current rewards: 136.55043, mean: 0.10837
[32m[0906 14-27-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03429, current rewards: 142.10153, mean: 0.10847
[32m[0906 14-27-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03433, current rewards: 147.65273, mean: 0.10857
[32m[0906 14-27-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03437, current rewards: 153.20420, mean: 0.10866
[32m[0906 14-27-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03441, current rewards: 158.75871, mean: 0.10874
[32m[0906 14-27-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03445, current rewards: 164.31091, mean: 0.10882
[32m[0906 14-27-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03446, current rewards: 169.86658, mean: 0.10889
[32m[0906 14-27-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03447, current rewards: 176.13338, mean: 0.10940
[32m[0906 14-27-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03447, current rewards: 181.86706, mean: 0.10956
[32m[0906 14-27-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03447, current rewards: 187.49249, mean: 0.10964
[32m[0906 14-27-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03447, current rewards: 191.19122, mean: 0.10863
[32m[0906 14-27-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03447, current rewards: 196.84722, mean: 0.10876
[32m[0906 14-27-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03448, current rewards: 202.50328, mean: 0.10887
[32m[0906 14-27-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03448, current rewards: 208.15949, mean: 0.10898
[32m[0906 14-27-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03448, current rewards: 211.49937, mean: 0.10791
[32m[0906 14-27-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03450, current rewards: 220.03729, mean: 0.10947
[32m[0906 14-27-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03452, current rewards: 227.10191, mean: 0.11024
[32m[0906 14-27-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03454, current rewards: 232.64843, mean: 0.11026
[32m[0906 14-27-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03456, current rewards: 238.28059, mean: 0.11032
[32m[0906 14-27-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03458, current rewards: 243.91281, mean: 0.11037
[32m[0906 14-27-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03460, current rewards: 249.55083, mean: 0.11042
[32m[0906 14-27-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03462, current rewards: 255.18375, mean: 0.11047
[32m[0906 14-27-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03463, current rewards: 260.82153, mean: 0.11052
[32m[0906 14-27-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03464, current rewards: 265.24724, mean: 0.11006
[32m[0906 14-27-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03466, current rewards: 270.78949, mean: 0.11008
[32m[0906 14-27-53 @Agent.py:117][0m Average action selection time: 0.0347
[32m[0906 14-27-53 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-27-53 @MBExp.py:227][0m Rewards obtained: [275.38268064075083], Lows: [3], Highs: [5], Total time: 2209.2399880000003
[32m[0906 14-28-47 @MBExp.py:144][0m ####################################################################
[32m[0906 14-28-47 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 14-28-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03406, current rewards: -2.25626, mean: -0.22563
[32m[0906 14-28-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03443, current rewards: 3.23990, mean: 0.05400
[32m[0906 14-28-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03452, current rewards: 8.73651, mean: 0.07942
[32m[0906 14-28-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03452, current rewards: 14.23339, mean: 0.08896
[32m[0906 14-28-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03454, current rewards: 19.73049, mean: 0.09395
[32m[0906 14-28-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03454, current rewards: 25.22838, mean: 0.09703
[32m[0906 14-28-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03454, current rewards: 29.59064, mean: 0.09545
[32m[0906 14-28-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03457, current rewards: 35.06685, mean: 0.09741
[32m[0906 14-29-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03455, current rewards: 40.33510, mean: 0.09838
[32m[0906 14-29-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03445, current rewards: 45.79306, mean: 0.09955
[32m[0906 14-29-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03439, current rewards: 51.25683, mean: 0.10050
[32m[0906 14-29-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03432, current rewards: 56.71861, mean: 0.10128
[32m[0906 14-29-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03428, current rewards: 62.17930, mean: 0.10193
[32m[0906 14-29-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03423, current rewards: 67.63696, mean: 0.10248
[32m[0906 14-29-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03417, current rewards: 73.09447, mean: 0.10295
[32m[0906 14-29-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03413, current rewards: 78.55218, mean: 0.10336
[32m[0906 14-29-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03414, current rewards: 84.02841, mean: 0.10374
[32m[0906 14-29-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03416, current rewards: 89.55059, mean: 0.10413
[32m[0906 14-29-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03418, current rewards: 95.02215, mean: 0.10442
[32m[0906 14-29-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03420, current rewards: 100.49807, mean: 0.10469
[32m[0906 14-29-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03422, current rewards: 105.96893, mean: 0.10492
[32m[0906 14-29-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03422, current rewards: 111.44204, mean: 0.10513
[32m[0906 14-29-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03423, current rewards: 116.84244, mean: 0.10526
[32m[0906 14-29-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03425, current rewards: 122.32117, mean: 0.10545
[32m[0906 14-29-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03426, current rewards: 127.79376, mean: 0.10561
[32m[0906 14-29-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03427, current rewards: 133.51954, mean: 0.10597
[32m[0906 14-29-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03430, current rewards: 139.02724, mean: 0.10613
[32m[0906 14-29-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03435, current rewards: 144.53599, mean: 0.10628
[32m[0906 14-29-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03439, current rewards: 150.05138, mean: 0.10642
[32m[0906 14-29-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03443, current rewards: 155.49786, mean: 0.10651
[32m[0906 14-29-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03444, current rewards: 161.01118, mean: 0.10663
[32m[0906 14-29-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03444, current rewards: 166.52690, mean: 0.10675
[32m[0906 14-29-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03444, current rewards: 172.04241, mean: 0.10686
[32m[0906 14-29-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03445, current rewards: 173.47391, mean: 0.10450
[32m[0906 14-29-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03445, current rewards: 178.76870, mean: 0.10454
[32m[0906 14-29-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03445, current rewards: 184.45122, mean: 0.10480
[32m[0906 14-29-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03446, current rewards: 190.13365, mean: 0.10505
[32m[0906 14-29-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03447, current rewards: 195.81026, mean: 0.10527
[32m[0906 14-29-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03447, current rewards: 201.49279, mean: 0.10549
[32m[0906 14-29-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03447, current rewards: 207.17455, mean: 0.10570
[32m[0906 14-29-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03448, current rewards: 212.85780, mean: 0.10590
[32m[0906 14-29-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03449, current rewards: 218.53997, mean: 0.10609
[32m[0906 14-30-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03451, current rewards: 224.22882, mean: 0.10627
[32m[0906 14-30-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03453, current rewards: 229.94236, mean: 0.10645
[32m[0906 14-30-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03455, current rewards: 235.65632, mean: 0.10663
[32m[0906 14-30-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03457, current rewards: 241.36647, mean: 0.10680
[32m[0906 14-30-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03459, current rewards: 244.87087, mean: 0.10600
[32m[0906 14-30-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03461, current rewards: 250.34608, mean: 0.10608
[32m[0906 14-30-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03462, current rewards: 255.82978, mean: 0.10615
[32m[0906 14-30-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03464, current rewards: 261.30596, mean: 0.10622
[32m[0906 14-30-14 @Agent.py:117][0m Average action selection time: 0.0347
[32m[0906 14-30-14 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-30-14 @MBExp.py:227][0m Rewards obtained: [265.6708843172082], Lows: [2], Highs: [6], Total time: 2296.505105
[32m[0906 14-31-09 @MBExp.py:144][0m ####################################################################
[32m[0906 14-31-09 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 14-31-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03358, current rewards: -0.10800, mean: -0.01080
[32m[0906 14-31-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03406, current rewards: 5.40451, mean: 0.09008
[32m[0906 14-31-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03429, current rewards: 10.92017, mean: 0.09927
[32m[0906 14-31-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03432, current rewards: 16.43299, mean: 0.10271
[32m[0906 14-31-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03434, current rewards: 21.94301, mean: 0.10449
[32m[0906 14-31-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03434, current rewards: 27.45683, mean: 0.10560
[32m[0906 14-31-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03433, current rewards: 32.97048, mean: 0.10636
[32m[0906 14-31-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03434, current rewards: 38.48440, mean: 0.10690
[32m[0906 14-31-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03437, current rewards: 44.10559, mean: 0.10757
[32m[0906 14-31-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03434, current rewards: 49.62163, mean: 0.10787
[32m[0906 14-31-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03425, current rewards: 55.14235, mean: 0.10812
[32m[0906 14-31-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03420, current rewards: 60.66006, mean: 0.10832
[32m[0906 14-31-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03413, current rewards: 64.07255, mean: 0.10504
[32m[0906 14-31-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03410, current rewards: 69.59176, mean: 0.10544
[32m[0906 14-31-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03407, current rewards: 75.10722, mean: 0.10578
[32m[0906 14-31-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03404, current rewards: 80.62406, mean: 0.10608
[32m[0906 14-31-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03404, current rewards: 86.15891, mean: 0.10637
[32m[0906 14-31-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03406, current rewards: 91.67893, mean: 0.10660
[32m[0906 14-31-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03408, current rewards: 97.19569, mean: 0.10681
[32m[0906 14-31-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03410, current rewards: 102.71585, mean: 0.10700
[32m[0906 14-31-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03411, current rewards: 108.23428, mean: 0.10716
[32m[0906 14-31-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03413, current rewards: 113.75563, mean: 0.10732
[32m[0906 14-31-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03415, current rewards: 119.27520, mean: 0.10746
[32m[0906 14-31-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03417, current rewards: 122.72867, mean: 0.10580
[32m[0906 14-31-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03418, current rewards: 128.21902, mean: 0.10597
[32m[0906 14-31-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03419, current rewards: 133.74085, mean: 0.10614
[32m[0906 14-31-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03421, current rewards: 139.26138, mean: 0.10631
[32m[0906 14-31-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03426, current rewards: 144.78372, mean: 0.10646
[32m[0906 14-31-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03429, current rewards: 150.30460, mean: 0.10660
[32m[0906 14-32-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03430, current rewards: 155.82261, mean: 0.10673
[32m[0906 14-32-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03431, current rewards: 161.33938, mean: 0.10685
[32m[0906 14-32-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03432, current rewards: 166.85941, mean: 0.10696
[32m[0906 14-32-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03432, current rewards: 172.39489, mean: 0.10708
[32m[0906 14-32-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03433, current rewards: 177.91605, mean: 0.10718
[32m[0906 14-32-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03433, current rewards: 179.24519, mean: 0.10482
[32m[0906 14-32-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03434, current rewards: 184.73809, mean: 0.10496
[32m[0906 14-32-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03434, current rewards: 190.23023, mean: 0.10510
[32m[0906 14-32-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03434, current rewards: 195.72219, mean: 0.10523
[32m[0906 14-32-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03435, current rewards: 201.21743, mean: 0.10535
[32m[0906 14-32-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03435, current rewards: 206.70934, mean: 0.10546
[32m[0906 14-32-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03435, current rewards: 212.20186, mean: 0.10557
[32m[0906 14-32-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03435, current rewards: 217.69547, mean: 0.10568
[32m[0906 14-32-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03436, current rewards: 223.18898, mean: 0.10578
[32m[0906 14-32-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03438, current rewards: 228.68335, mean: 0.10587
[32m[0906 14-32-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03441, current rewards: 234.17834, mean: 0.10596
[32m[0906 14-32-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03443, current rewards: 239.67322, mean: 0.10605
[32m[0906 14-32-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03445, current rewards: 243.03254, mean: 0.10521
[32m[0906 14-32-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03447, current rewards: 248.58059, mean: 0.10533
[32m[0906 14-32-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03449, current rewards: 254.17028, mean: 0.10546
[32m[0906 14-32-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03451, current rewards: 259.75606, mean: 0.10559
[32m[0906 14-32-36 @Agent.py:117][0m Average action selection time: 0.0345
[32m[0906 14-32-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-32-36 @MBExp.py:227][0m Rewards obtained: [264.2044507128319], Lows: [4], Highs: [3], Total time: 2383.468202
[32m[0906 14-33-34 @MBExp.py:144][0m ####################################################################
[32m[0906 14-33-34 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 14-33-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03425, current rewards: -1.11472, mean: -0.11147
[32m[0906 14-33-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03438, current rewards: 4.40407, mean: 0.07340
[32m[0906 14-33-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03434, current rewards: 9.92825, mean: 0.09026
[32m[0906 14-33-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03434, current rewards: 15.45596, mean: 0.09660
[32m[0906 14-33-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03430, current rewards: 20.98292, mean: 0.09992
[32m[0906 14-33-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03432, current rewards: 26.50946, mean: 0.10196
[32m[0906 14-33-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03433, current rewards: 32.03626, mean: 0.10334
[32m[0906 14-33-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03434, current rewards: 37.52151, mean: 0.10423
[32m[0906 14-33-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03435, current rewards: 43.03815, mean: 0.10497
[32m[0906 14-33-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03431, current rewards: 46.69391, mean: 0.10151
[32m[0906 14-33-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03423, current rewards: 52.24934, mean: 0.10245
[32m[0906 14-33-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03416, current rewards: 57.80237, mean: 0.10322
[32m[0906 14-33-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03410, current rewards: 63.35835, mean: 0.10387
[32m[0906 14-33-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03408, current rewards: 68.91447, mean: 0.10442
[32m[0906 14-33-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03407, current rewards: 74.46742, mean: 0.10488
[32m[0906 14-34-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03405, current rewards: 80.27264, mean: 0.10562
[32m[0906 14-34-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03404, current rewards: 85.76929, mean: 0.10589
[32m[0906 14-34-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03406, current rewards: 91.26600, mean: 0.10612
[32m[0906 14-34-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03408, current rewards: 91.21920, mean: 0.10024
[32m[0906 14-34-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03409, current rewards: 96.75089, mean: 0.10078
[32m[0906 14-34-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03411, current rewards: 102.28281, mean: 0.10127
[32m[0906 14-34-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03413, current rewards: 107.81237, mean: 0.10171
[32m[0906 14-34-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03415, current rewards: 113.33937, mean: 0.10211
[32m[0906 14-34-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03416, current rewards: 118.82265, mean: 0.10243
[32m[0906 14-34-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03417, current rewards: 124.27563, mean: 0.10271
[32m[0906 14-34-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03418, current rewards: 129.78598, mean: 0.10300
[32m[0906 14-34-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03420, current rewards: 135.29587, mean: 0.10328
[32m[0906 14-34-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03422, current rewards: 138.71291, mean: 0.10199
[32m[0906 14-34-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03422, current rewards: 144.24397, mean: 0.10230
[32m[0906 14-34-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03423, current rewards: 149.77538, mean: 0.10259
[32m[0906 14-34-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03424, current rewards: 155.31248, mean: 0.10286
[32m[0906 14-34-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03424, current rewards: 160.84163, mean: 0.10310
[32m[0906 14-34-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03425, current rewards: 166.56548, mean: 0.10346
[32m[0906 14-34-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03425, current rewards: 170.17776, mean: 0.10252
[32m[0906 14-34-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03425, current rewards: 175.75172, mean: 0.10278
[32m[0906 14-34-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03427, current rewards: 181.32962, mean: 0.10303
[32m[0906 14-34-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03428, current rewards: 186.90664, mean: 0.10326
[32m[0906 14-34-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03428, current rewards: 192.48666, mean: 0.10349
[32m[0906 14-34-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03428, current rewards: 198.05945, mean: 0.10370
[32m[0906 14-34-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03429, current rewards: 203.63757, mean: 0.10390
[32m[0906 14-34-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03429, current rewards: 209.06414, mean: 0.10401
[32m[0906 14-34-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03430, current rewards: 213.42437, mean: 0.10360
[32m[0906 14-34-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03430, current rewards: 218.94782, mean: 0.10377
[32m[0906 14-34-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03431, current rewards: 224.46816, mean: 0.10392
[32m[0906 14-34-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03434, current rewards: 229.99603, mean: 0.10407
[32m[0906 14-34-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03436, current rewards: 235.51069, mean: 0.10421
[32m[0906 14-34-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03439, current rewards: 241.03400, mean: 0.10434
[32m[0906 14-34-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03441, current rewards: 246.55212, mean: 0.10447
[32m[0906 14-34-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03443, current rewards: 252.07433, mean: 0.10460
[32m[0906 14-34-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03445, current rewards: 257.75133, mean: 0.10478
[32m[0906 14-35-01 @Agent.py:117][0m Average action selection time: 0.0345
[32m[0906 14-35-01 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-35-01 @MBExp.py:227][0m Rewards obtained: [262.1843751476908], Lows: [3], Highs: [8], Total time: 2470.268758
[32m[0906 14-36-01 @MBExp.py:144][0m ####################################################################
[32m[0906 14-36-01 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 14-36-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03448, current rewards: -1.00743, mean: -0.10074
[32m[0906 14-36-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03451, current rewards: 4.70406, mean: 0.07840
[32m[0906 14-36-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03437, current rewards: 10.25031, mean: 0.09318
[32m[0906 14-36-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03429, current rewards: 15.79879, mean: 0.09874
[32m[0906 14-36-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03435, current rewards: 21.35089, mean: 0.10167
[32m[0906 14-36-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03439, current rewards: 26.90469, mean: 0.10348
[32m[0906 14-36-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03441, current rewards: 32.45734, mean: 0.10470
[32m[0906 14-36-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03440, current rewards: 38.01458, mean: 0.10560
[32m[0906 14-36-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03443, current rewards: 43.57446, mean: 0.10628
[32m[0906 14-36-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03436, current rewards: 47.08473, mean: 0.10236
[32m[0906 14-36-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03428, current rewards: 52.63571, mean: 0.10321
[32m[0906 14-36-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03423, current rewards: 58.18675, mean: 0.10390
[32m[0906 14-36-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03420, current rewards: 63.74324, mean: 0.10450
[32m[0906 14-36-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03415, current rewards: 69.29614, mean: 0.10499
[32m[0906 14-36-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03411, current rewards: 74.85279, mean: 0.10543
[32m[0906 14-36-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03409, current rewards: 80.40434, mean: 0.10580
[32m[0906 14-36-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03405, current rewards: 86.00774, mean: 0.10618
[32m[0906 14-36-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03407, current rewards: 90.52006, mean: 0.10526
[32m[0906 14-36-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03409, current rewards: 96.03157, mean: 0.10553
[32m[0906 14-36-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03411, current rewards: 101.54859, mean: 0.10578
[32m[0906 14-36-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03414, current rewards: 107.06246, mean: 0.10600
[32m[0906 14-36-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03415, current rewards: 112.57640, mean: 0.10620
[32m[0906 14-36-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03417, current rewards: 118.09537, mean: 0.10639
[32m[0906 14-36-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03418, current rewards: 123.61247, mean: 0.10656
[32m[0906 14-36-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03419, current rewards: 128.93656, mean: 0.10656
[32m[0906 14-36-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03420, current rewards: 134.44418, mean: 0.10670
[32m[0906 14-36-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03419, current rewards: 140.60281, mean: 0.10733
[32m[0906 14-36-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03421, current rewards: 146.12710, mean: 0.10745
[32m[0906 14-36-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03422, current rewards: 151.64517, mean: 0.10755
[32m[0906 14-36-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03423, current rewards: 157.17482, mean: 0.10765
[32m[0906 14-36-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03424, current rewards: 162.69620, mean: 0.10775
[32m[0906 14-36-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03425, current rewards: 168.21423, mean: 0.10783
[32m[0906 14-36-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03425, current rewards: 173.77718, mean: 0.10794
[32m[0906 14-36-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03426, current rewards: 179.40668, mean: 0.10808
[32m[0906 14-37-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03427, current rewards: 184.95020, mean: 0.10816
[32m[0906 14-37-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03427, current rewards: 190.48799, mean: 0.10823
[32m[0906 14-37-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03427, current rewards: 196.02414, mean: 0.10830
[32m[0906 14-37-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03428, current rewards: 199.56882, mean: 0.10730
[32m[0906 14-37-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03429, current rewards: 205.15032, mean: 0.10741
[32m[0906 14-37-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03429, current rewards: 210.73255, mean: 0.10752
[32m[0906 14-37-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03430, current rewards: 216.31540, mean: 0.10762
[32m[0906 14-37-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03430, current rewards: 221.88269, mean: 0.10771
[32m[0906 14-37-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03431, current rewards: 227.46247, mean: 0.10780
[32m[0906 14-37-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03432, current rewards: 233.04176, mean: 0.10789
[32m[0906 14-37-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03433, current rewards: 237.41405, mean: 0.10743
[32m[0906 14-37-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03435, current rewards: 242.99774, mean: 0.10752
[32m[0906 14-37-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03438, current rewards: 248.58017, mean: 0.10761
[32m[0906 14-37-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03440, current rewards: 254.16347, mean: 0.10770
[32m[0906 14-37-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03442, current rewards: 259.74676, mean: 0.10778
[32m[0906 14-37-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03444, current rewards: 265.17355, mean: 0.10779
[32m[0906 14-37-27 @Agent.py:117][0m Average action selection time: 0.0345
[32m[0906 14-37-27 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-37-27 @MBExp.py:227][0m Rewards obtained: [269.6047684802198], Lows: [3], Highs: [3], Total time: 2557.056137
[32m[0906 14-38-29 @MBExp.py:144][0m ####################################################################
[32m[0906 14-38-29 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 14-38-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03407, current rewards: 1.02948, mean: 0.10295
[32m[0906 14-38-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03442, current rewards: 6.50718, mean: 0.10845
[32m[0906 14-38-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03443, current rewards: 11.97996, mean: 0.10891
[32m[0906 14-38-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03442, current rewards: 17.45458, mean: 0.10909
[32m[0906 14-38-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03446, current rewards: 22.93161, mean: 0.10920
[32m[0906 14-38-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03444, current rewards: 28.40553, mean: 0.10925
[32m[0906 14-38-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03444, current rewards: 33.88127, mean: 0.10929
[32m[0906 14-38-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03445, current rewards: 38.22324, mean: 0.10618
[32m[0906 14-38-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03446, current rewards: 43.73427, mean: 0.10667
[32m[0906 14-38-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03440, current rewards: 49.24507, mean: 0.10705
[32m[0906 14-38-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03430, current rewards: 54.75851, mean: 0.10737
[32m[0906 14-38-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03423, current rewards: 60.26854, mean: 0.10762
[32m[0906 14-38-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03417, current rewards: 65.77917, mean: 0.10783
[32m[0906 14-38-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03412, current rewards: 71.28941, mean: 0.10801
[32m[0906 14-38-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03408, current rewards: 76.79622, mean: 0.10816
[32m[0906 14-38-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03406, current rewards: 82.25956, mean: 0.10824
[32m[0906 14-38-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03403, current rewards: 87.75494, mean: 0.10834
[32m[0906 14-38-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03404, current rewards: 93.25375, mean: 0.10843
[32m[0906 14-39-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03407, current rewards: 98.75673, mean: 0.10852
[32m[0906 14-39-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03409, current rewards: 103.11598, mean: 0.10741
[32m[0906 14-39-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03410, current rewards: 108.61228, mean: 0.10754
[32m[0906 14-39-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03412, current rewards: 114.10302, mean: 0.10764
[32m[0906 14-39-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03415, current rewards: 119.59894, mean: 0.10775
[32m[0906 14-39-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03417, current rewards: 125.14207, mean: 0.10788
[32m[0906 14-39-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03417, current rewards: 130.64458, mean: 0.10797
[32m[0906 14-39-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03415, current rewards: 136.14301, mean: 0.10805
[32m[0906 14-39-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03415, current rewards: 141.64886, mean: 0.10813
[32m[0906 14-39-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03417, current rewards: 147.14547, mean: 0.10820
[32m[0906 14-39-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03418, current rewards: 152.64664, mean: 0.10826
[32m[0906 14-39-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03419, current rewards: 158.15177, mean: 0.10832
[32m[0906 14-39-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03420, current rewards: 162.63629, mean: 0.10771
[32m[0906 14-39-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03421, current rewards: 168.04657, mean: 0.10772
[32m[0906 14-39-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03422, current rewards: 173.46559, mean: 0.10774
[32m[0906 14-39-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03423, current rewards: 178.88409, mean: 0.10776
[32m[0906 14-39-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03424, current rewards: 184.30324, mean: 0.10778
[32m[0906 14-39-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03425, current rewards: 189.71977, mean: 0.10780
[32m[0906 14-39-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03425, current rewards: 193.12905, mean: 0.10670
[32m[0906 14-39-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03426, current rewards: 198.61786, mean: 0.10678
[32m[0906 14-39-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03427, current rewards: 204.10889, mean: 0.10686
[32m[0906 14-39-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03428, current rewards: 209.51258, mean: 0.10689
[32m[0906 14-39-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03429, current rewards: 214.97355, mean: 0.10695
[32m[0906 14-39-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03430, current rewards: 220.44572, mean: 0.10701
[32m[0906 14-39-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03430, current rewards: 225.92260, mean: 0.10707
[32m[0906 14-39-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03431, current rewards: 231.39289, mean: 0.10713
[32m[0906 14-39-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03431, current rewards: 236.86300, mean: 0.10718
[32m[0906 14-39-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03432, current rewards: 242.33316, mean: 0.10723
[32m[0906 14-39-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03433, current rewards: 247.80522, mean: 0.10727
[32m[0906 14-39-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03435, current rewards: 253.27718, mean: 0.10732
[32m[0906 14-39-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03438, current rewards: 258.69542, mean: 0.10734
[32m[0906 14-39-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03440, current rewards: 264.18841, mean: 0.10739
[32m[0906 14-39-56 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 14-39-56 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-39-56 @MBExp.py:227][0m Rewards obtained: [268.57705575118854], Lows: [1], Highs: [3], Total time: 2643.722206
[32m[0906 14-41-00 @MBExp.py:144][0m ####################################################################
[32m[0906 14-41-00 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 14-41-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03393, current rewards: -0.99758, mean: -0.09976
[32m[0906 14-41-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03435, current rewards: 4.60404, mean: 0.07673
[32m[0906 14-41-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03446, current rewards: 10.08502, mean: 0.09168
[32m[0906 14-41-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03450, current rewards: 15.57346, mean: 0.09733
[32m[0906 14-41-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03452, current rewards: 21.05478, mean: 0.10026
[32m[0906 14-41-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03449, current rewards: 22.63784, mean: 0.08707
[32m[0906 14-41-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03451, current rewards: 28.01191, mean: 0.09036
[32m[0906 14-41-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03449, current rewards: 33.55236, mean: 0.09320
[32m[0906 14-41-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03449, current rewards: 39.12379, mean: 0.09542
[32m[0906 14-41-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03442, current rewards: 44.69689, mean: 0.09717
[32m[0906 14-41-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03435, current rewards: 50.26932, mean: 0.09857
[32m[0906 14-41-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03430, current rewards: 55.84250, mean: 0.09972
[32m[0906 14-41-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03424, current rewards: 61.41588, mean: 0.10068
[32m[0906 14-41-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03420, current rewards: 66.98731, mean: 0.10150
[32m[0906 14-41-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03415, current rewards: 72.64337, mean: 0.10231
[32m[0906 14-41-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03414, current rewards: 78.30844, mean: 0.10304
[32m[0906 14-41-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03411, current rewards: 82.66209, mean: 0.10205
[32m[0906 14-41-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03410, current rewards: 88.16121, mean: 0.10251
[32m[0906 14-41-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03412, current rewards: 93.66108, mean: 0.10292
[32m[0906 14-41-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03414, current rewards: 99.16194, mean: 0.10329
[32m[0906 14-41-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03416, current rewards: 104.66379, mean: 0.10363
[32m[0906 14-41-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03418, current rewards: 109.08622, mean: 0.10291
[32m[0906 14-41-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03421, current rewards: 114.56207, mean: 0.10321
[32m[0906 14-41-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03418, current rewards: 120.05238, mean: 0.10349
[32m[0906 14-41-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03415, current rewards: 125.54140, mean: 0.10375
[32m[0906 14-41-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03414, current rewards: 131.03687, mean: 0.10400
[32m[0906 14-41-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03412, current rewards: 136.52679, mean: 0.10422
[32m[0906 14-41-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03414, current rewards: 139.95687, mean: 0.10291
[32m[0906 14-41-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03416, current rewards: 145.45074, mean: 0.10316
[32m[0906 14-41-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03417, current rewards: 150.94785, mean: 0.10339
[32m[0906 14-41-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03419, current rewards: 156.43049, mean: 0.10360
[32m[0906 14-41-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03420, current rewards: 161.88522, mean: 0.10377
[32m[0906 14-41-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03422, current rewards: 167.38362, mean: 0.10396
[32m[0906 14-41-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03423, current rewards: 171.89798, mean: 0.10355
[32m[0906 14-41-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03424, current rewards: 177.39729, mean: 0.10374
[32m[0906 14-42-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03425, current rewards: 182.89121, mean: 0.10392
[32m[0906 14-42-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03425, current rewards: 188.39028, mean: 0.10408
[32m[0906 14-42-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03426, current rewards: 193.89419, mean: 0.10424
[32m[0906 14-42-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03427, current rewards: 199.39322, mean: 0.10439
[32m[0906 14-42-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03427, current rewards: 204.87074, mean: 0.10453
[32m[0906 14-42-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03427, current rewards: 210.36558, mean: 0.10466
[32m[0906 14-42-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03428, current rewards: 215.86995, mean: 0.10479
[32m[0906 14-42-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03428, current rewards: 221.36592, mean: 0.10491
[32m[0906 14-42-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03429, current rewards: 227.59856, mean: 0.10537
[32m[0906 14-42-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03430, current rewards: 233.08034, mean: 0.10547
[32m[0906 14-42-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03430, current rewards: 238.56690, mean: 0.10556
[32m[0906 14-42-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03431, current rewards: 244.04655, mean: 0.10565
[32m[0906 14-42-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03432, current rewards: 249.46946, mean: 0.10571
[32m[0906 14-42-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03434, current rewards: 254.94695, mean: 0.10579
[32m[0906 14-42-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03436, current rewards: 260.42096, mean: 0.10586
[32m[0906 14-42-26 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 14-42-26 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-42-26 @MBExp.py:227][0m Rewards obtained: [264.8017965371331], Lows: [3], Highs: [5], Total time: 2730.293378
[32m[0906 14-43-32 @MBExp.py:144][0m ####################################################################
[32m[0906 14-43-32 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 14-43-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03398, current rewards: -1.07297, mean: -0.10730
[32m[0906 14-43-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03428, current rewards: 4.29785, mean: 0.07163
[32m[0906 14-43-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03440, current rewards: 9.67389, mean: 0.08794
[32m[0906 14-43-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03443, current rewards: 15.05000, mean: 0.09406
[32m[0906 14-43-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03445, current rewards: 20.42857, mean: 0.09728
[32m[0906 14-43-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03445, current rewards: 25.99711, mean: 0.09999
[32m[0906 14-43-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03444, current rewards: 27.68296, mean: 0.08930
[32m[0906 14-43-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03443, current rewards: 34.77951, mean: 0.09661
[32m[0906 14-43-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03444, current rewards: 41.87606, mean: 0.10214
[32m[0906 14-43-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03440, current rewards: 48.97261, mean: 0.10646
[32m[0906 14-43-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03433, current rewards: 56.06916, mean: 0.10994
[32m[0906 14-43-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03425, current rewards: 63.16571, mean: 0.11280
[32m[0906 14-43-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03420, current rewards: 70.26226, mean: 0.11518
[32m[0906 14-43-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03416, current rewards: 77.34904, mean: 0.11720
[32m[0906 14-43-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03411, current rewards: 51.02381, mean: 0.07186
[32m[0906 14-43-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03410, current rewards: 1.02381, mean: 0.00135
[32m[0906 14-44-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03407, current rewards: -48.97619, mean: -0.06046
[32m[0906 14-44-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03405, current rewards: -98.97619, mean: -0.11509
[32m[0906 14-44-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03408, current rewards: -148.97619, mean: -0.16371
[32m[0906 14-44-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03410, current rewards: -198.97619, mean: -0.20727
[32m[0906 14-44-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03411, current rewards: -248.97619, mean: -0.24651
[32m[0906 14-44-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03413, current rewards: -298.97619, mean: -0.28205
[32m[0906 14-44-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03412, current rewards: -348.97619, mean: -0.31439
[32m[0906 14-44-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03410, current rewards: -398.97619, mean: -0.34394
[32m[0906 14-44-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03409, current rewards: -448.97619, mean: -0.37105
[32m[0906 14-44-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03406, current rewards: -498.97619, mean: -0.39601
[32m[0906 14-44-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03405, current rewards: -548.97619, mean: -0.41907
[32m[0906 14-44-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03407, current rewards: -598.97619, mean: -0.44042
[32m[0906 14-44-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03408, current rewards: -648.97619, mean: -0.46027
[32m[0906 14-44-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03410, current rewards: -698.97619, mean: -0.47875
[32m[0906 14-44-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03411, current rewards: -748.97619, mean: -0.49601
[32m[0906 14-44-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03412, current rewards: -798.97619, mean: -0.51216
[32m[0906 14-44-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03413, current rewards: -848.97619, mean: -0.52731
[32m[0906 14-44-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03414, current rewards: -898.97619, mean: -0.54155
[32m[0906 14-44-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03415, current rewards: -948.97619, mean: -0.55496
[32m[0906 14-44-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03417, current rewards: -998.97619, mean: -0.56760
[32m[0906 14-44-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03418, current rewards: -1048.97619, mean: -0.57954
[32m[0906 14-44-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03420, current rewards: -1098.97619, mean: -0.59085
[32m[0906 14-44-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03422, current rewards: -1148.97619, mean: -0.60156
[32m[0906 14-44-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03422, current rewards: -1198.97619, mean: -0.61172
[32m[0906 14-44-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03423, current rewards: -1248.97619, mean: -0.62138
[32m[0906 14-44-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03423, current rewards: -1298.97619, mean: -0.63057
[32m[0906 14-44-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03424, current rewards: -1348.97619, mean: -0.63933
[32m[0906 14-44-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03424, current rewards: -1398.97619, mean: -0.64767
[32m[0906 14-44-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03425, current rewards: -1448.97619, mean: -0.65565
[32m[0906 14-44-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03425, current rewards: -1498.97619, mean: -0.66326
[32m[0906 14-44-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03425, current rewards: -1548.97619, mean: -0.67055
[32m[0906 14-44-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03426, current rewards: -1598.97619, mean: -0.67753
[32m[0906 14-44-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03427, current rewards: -1648.97619, mean: -0.68422
[32m[0906 14-44-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03429, current rewards: -1698.97619, mean: -0.69064
[32m[0906 14-44-59 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 14-44-59 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-44-59 @MBExp.py:227][0m Rewards obtained: [-1738.9761910841162], Lows: [2], Highs: [1820], Total time: 2816.706758
[32m[0906 14-46-07 @MBExp.py:144][0m ####################################################################
[32m[0906 14-46-07 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 14-46-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03419, current rewards: -0.06353, mean: -0.00635
[32m[0906 14-46-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03424, current rewards: 5.48140, mean: 0.09136
[32m[0906 14-46-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03428, current rewards: 11.02320, mean: 0.10021
[32m[0906 14-46-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03430, current rewards: 16.56758, mean: 0.10355
[32m[0906 14-46-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03433, current rewards: 22.10893, mean: 0.10528
[32m[0906 14-46-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03433, current rewards: 27.65916, mean: 0.10638
[32m[0906 14-46-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03434, current rewards: 33.06583, mean: 0.10666
[32m[0906 14-46-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03434, current rewards: 38.63136, mean: 0.10731
[32m[0906 14-46-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03437, current rewards: 44.18834, mean: 0.10778
[32m[0906 14-46-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03434, current rewards: 49.74641, mean: 0.10814
[32m[0906 14-46-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03427, current rewards: 55.29973, mean: 0.10843
[32m[0906 14-46-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03422, current rewards: 60.84974, mean: 0.10866
[32m[0906 14-46-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03416, current rewards: 64.23352, mean: 0.10530
[32m[0906 14-46-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03413, current rewards: 69.78165, mean: 0.10573
[32m[0906 14-46-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03409, current rewards: 75.36760, mean: 0.10615
[32m[0906 14-46-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03406, current rewards: 80.91165, mean: 0.10646
[32m[0906 14-46-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03403, current rewards: 86.44846, mean: 0.10673
[32m[0906 14-46-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03401, current rewards: 91.98826, mean: 0.10696
[32m[0906 14-46-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03403, current rewards: 97.53286, mean: 0.10718
[32m[0906 14-46-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03406, current rewards: 103.07633, mean: 0.10737
[32m[0906 14-46-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03407, current rewards: 108.62016, mean: 0.10754
[32m[0906 14-46-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03405, current rewards: 114.15855, mean: 0.10770
[32m[0906 14-46-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03404, current rewards: 119.76965, mean: 0.10790
[32m[0906 14-46-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03402, current rewards: 125.30971, mean: 0.10803
[32m[0906 14-46-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03400, current rewards: 129.18948, mean: 0.10677
[32m[0906 14-46-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03399, current rewards: 134.53933, mean: 0.10678
[32m[0906 14-46-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03399, current rewards: 139.89068, mean: 0.10679
[32m[0906 14-46-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03399, current rewards: 145.24145, mean: 0.10680
[32m[0906 14-46-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03400, current rewards: 150.59038, mean: 0.10680
[32m[0906 14-46-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03402, current rewards: 155.94002, mean: 0.10681
[32m[0906 14-46-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03404, current rewards: 161.31297, mean: 0.10683
[32m[0906 14-47-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03405, current rewards: 166.67301, mean: 0.10684
[32m[0906 14-47-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03407, current rewards: 172.03131, mean: 0.10685
[32m[0906 14-47-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03408, current rewards: 177.39006, mean: 0.10686
[32m[0906 14-47-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03410, current rewards: 180.59112, mean: 0.10561
[32m[0906 14-47-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03411, current rewards: 186.13956, mean: 0.10576
[32m[0906 14-47-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03412, current rewards: 191.69108, mean: 0.10591
[32m[0906 14-47-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03413, current rewards: 197.24167, mean: 0.10604
[32m[0906 14-47-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03414, current rewards: 202.77798, mean: 0.10617
[32m[0906 14-47-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03415, current rewards: 208.74394, mean: 0.10650
[32m[0906 14-47-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03415, current rewards: 214.83032, mean: 0.10688
[32m[0906 14-47-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03416, current rewards: 220.90763, mean: 0.10724
[32m[0906 14-47-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03417, current rewards: 226.99081, mean: 0.10758
[32m[0906 14-47-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03418, current rewards: 233.07684, mean: 0.10791
[32m[0906 14-47-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03419, current rewards: 239.16144, mean: 0.10822
[32m[0906 14-47-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03419, current rewards: 245.24285, mean: 0.10851
[32m[0906 14-47-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03420, current rewards: 251.32699, mean: 0.10880
[32m[0906 14-47-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03421, current rewards: 257.42252, mean: 0.10908
[32m[0906 14-47-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03421, current rewards: 263.48144, mean: 0.10933
[32m[0906 14-47-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03422, current rewards: 269.53961, mean: 0.10957
[32m[0906 14-47-33 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 14-47-33 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-47-33 @MBExp.py:227][0m Rewards obtained: [274.3854048291242], Lows: [2], Highs: [3], Total time: 2902.9397839999997
[32m[0906 14-48-43 @MBExp.py:144][0m ####################################################################
[32m[0906 14-48-43 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 14-48-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03392, current rewards: -0.08856, mean: -0.00886
[32m[0906 14-48-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03443, current rewards: 5.45101, mean: 0.09085
[32m[0906 14-48-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03448, current rewards: 10.98778, mean: 0.09989
[32m[0906 14-48-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03442, current rewards: 16.52814, mean: 0.10330
[32m[0906 14-48-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03441, current rewards: 22.06457, mean: 0.10507
[32m[0906 14-48-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03443, current rewards: 27.77678, mean: 0.10683
[32m[0906 14-48-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03444, current rewards: 33.32241, mean: 0.10749
[32m[0906 14-48-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03445, current rewards: 38.86770, mean: 0.10797
[32m[0906 14-48-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03445, current rewards: 42.19905, mean: 0.10292
[32m[0906 14-48-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03447, current rewards: 47.70744, mean: 0.10371
[32m[0906 14-49-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03436, current rewards: 53.21254, mean: 0.10434
[32m[0906 14-49-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03427, current rewards: 58.72552, mean: 0.10487
[32m[0906 14-49-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03423, current rewards: 64.23962, mean: 0.10531
[32m[0906 14-49-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03420, current rewards: 69.74996, mean: 0.10568
[32m[0906 14-49-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03417, current rewards: 75.25589, mean: 0.10599
[32m[0906 14-49-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03412, current rewards: 80.75444, mean: 0.10626
[32m[0906 14-49-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03410, current rewards: 86.26175, mean: 0.10650
[32m[0906 14-49-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03407, current rewards: 91.76990, mean: 0.10671
[32m[0906 14-49-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03407, current rewards: 97.27771, mean: 0.10690
[32m[0906 14-49-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03407, current rewards: 102.78755, mean: 0.10707
[32m[0906 14-49-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03403, current rewards: 106.21876, mean: 0.10517
[32m[0906 14-49-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03401, current rewards: 111.84568, mean: 0.10551
[32m[0906 14-49-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03399, current rewards: 117.34740, mean: 0.10572
[32m[0906 14-49-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03398, current rewards: 122.85113, mean: 0.10591
[32m[0906 14-49-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03397, current rewards: 128.35304, mean: 0.10608
[32m[0906 14-49-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03396, current rewards: 133.85544, mean: 0.10623
[32m[0906 14-49-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03395, current rewards: 138.39933, mean: 0.10565
[32m[0906 14-49-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03395, current rewards: 143.92867, mean: 0.10583
[32m[0906 14-49-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03397, current rewards: 149.46528, mean: 0.10600
[32m[0906 14-49-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03399, current rewards: 154.98273, mean: 0.10615
[32m[0906 14-49-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03402, current rewards: 160.34036, mean: 0.10619
[32m[0906 14-49-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03404, current rewards: 165.88854, mean: 0.10634
[32m[0906 14-49-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03406, current rewards: 171.44241, mean: 0.10649
[32m[0906 14-49-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03407, current rewards: 174.83967, mean: 0.10533
[32m[0906 14-49-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03408, current rewards: 180.37643, mean: 0.10548
[32m[0906 14-49-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03409, current rewards: 185.91926, mean: 0.10564
[32m[0906 14-49-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03411, current rewards: 191.46303, mean: 0.10578
[32m[0906 14-49-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03413, current rewards: 197.00622, mean: 0.10592
[32m[0906 14-49-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03414, current rewards: 202.76039, mean: 0.10616
[32m[0906 14-49-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03415, current rewards: 208.30301, mean: 0.10628
[32m[0906 14-49-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03416, current rewards: 213.82556, mean: 0.10638
[32m[0906 14-49-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03417, current rewards: 217.30405, mean: 0.10549
[32m[0906 14-49-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03418, current rewards: 222.84126, mean: 0.10561
[32m[0906 14-49-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03418, current rewards: 228.37691, mean: 0.10573
[32m[0906 14-49-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03419, current rewards: 233.91395, mean: 0.10584
[32m[0906 14-50-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03420, current rewards: 239.45073, mean: 0.10595
[32m[0906 14-50-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03421, current rewards: 244.98368, mean: 0.10605
[32m[0906 14-50-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03422, current rewards: 250.52181, mean: 0.10615
[32m[0906 14-50-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03423, current rewards: 255.02277, mean: 0.10582
[32m[0906 14-50-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03423, current rewards: 260.55270, mean: 0.10592
[32m[0906 14-50-09 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 14-50-09 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-50-09 @MBExp.py:227][0m Rewards obtained: [264.9800106804805], Lows: [3], Highs: [5], Total time: 2989.1846069999997
[32m[0906 14-51-21 @MBExp.py:144][0m ####################################################################
[32m[0906 14-51-21 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 14-51-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03360, current rewards: -0.53978, mean: -0.05398
[32m[0906 14-51-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03436, current rewards: 5.00255, mean: 0.08338
[32m[0906 14-51-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03436, current rewards: 10.52458, mean: 0.09568
[32m[0906 14-51-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03436, current rewards: 16.04749, mean: 0.10030
[32m[0906 14-51-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03437, current rewards: 21.56510, mean: 0.10269
[32m[0906 14-51-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03440, current rewards: 27.08580, mean: 0.10418
[32m[0906 14-51-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03440, current rewards: 32.60756, mean: 0.10519
[32m[0906 14-51-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03439, current rewards: 38.12511, mean: 0.10590
[32m[0906 14-51-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03441, current rewards: 43.64753, mean: 0.10646
[32m[0906 14-51-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03442, current rewards: 49.17472, mean: 0.10690
[32m[0906 14-51-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03434, current rewards: 54.68920, mean: 0.10723
[32m[0906 14-51-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03428, current rewards: 60.21867, mean: 0.10753
[32m[0906 14-51-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03423, current rewards: 65.73211, mean: 0.10776
[32m[0906 14-51-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03417, current rewards: 71.27097, mean: 0.10799
[32m[0906 14-51-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03414, current rewards: 76.79729, mean: 0.10817
[32m[0906 14-51-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03411, current rewards: 80.18631, mean: 0.10551
[32m[0906 14-51-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03409, current rewards: 85.70615, mean: 0.10581
[32m[0906 14-51-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03406, current rewards: 91.23045, mean: 0.10608
[32m[0906 14-51-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03400, current rewards: 96.75699, mean: 0.10633
[32m[0906 14-51-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03398, current rewards: 102.27891, mean: 0.10654
[32m[0906 14-51-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03396, current rewards: 107.80199, mean: 0.10673
[32m[0906 14-51-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03395, current rewards: 113.36474, mean: 0.10695
[32m[0906 14-51-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03394, current rewards: 118.89366, mean: 0.10711
[32m[0906 14-52-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03392, current rewards: 124.42024, mean: 0.10726
[32m[0906 14-52-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03390, current rewards: 129.94899, mean: 0.10740
[32m[0906 14-52-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03389, current rewards: 135.47094, mean: 0.10752
[32m[0906 14-52-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03388, current rewards: 141.00061, mean: 0.10763
[32m[0906 14-52-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03387, current rewards: 146.51952, mean: 0.10773
[32m[0906 14-52-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03389, current rewards: 152.04819, mean: 0.10784
[32m[0906 14-52-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03392, current rewards: 157.77442, mean: 0.10806
[32m[0906 14-52-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03393, current rewards: 161.35916, mean: 0.10686
[32m[0906 14-52-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03395, current rewards: 166.93494, mean: 0.10701
[32m[0906 14-52-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03397, current rewards: 172.51011, mean: 0.10715
[32m[0906 14-52-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03398, current rewards: 178.08481, mean: 0.10728
[32m[0906 14-52-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03400, current rewards: 182.52744, mean: 0.10674
[32m[0906 14-52-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03401, current rewards: 188.08362, mean: 0.10687
[32m[0906 14-52-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03402, current rewards: 193.64405, mean: 0.10699
[32m[0906 14-52-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03404, current rewards: 199.20209, mean: 0.10710
[32m[0906 14-52-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03405, current rewards: 204.75883, mean: 0.10720
[32m[0906 14-52-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03405, current rewards: 210.31492, mean: 0.10730
[32m[0906 14-52-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03407, current rewards: 212.58949, mean: 0.10577
[32m[0906 14-52-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03408, current rewards: 219.68605, mean: 0.10664
[32m[0906 14-52-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03409, current rewards: 226.78260, mean: 0.10748
[32m[0906 14-52-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03410, current rewards: 233.87915, mean: 0.10828
[32m[0906 14-52-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03411, current rewards: 240.97570, mean: 0.10904
[32m[0906 14-52-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03412, current rewards: 247.61095, mean: 0.10956
[32m[0906 14-52-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03413, current rewards: 250.13255, mean: 0.10828
[32m[0906 14-52-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03414, current rewards: 252.52021, mean: 0.10700
[32m[0906 14-52-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03414, current rewards: 254.90787, mean: 0.10577
[32m[0906 14-52-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03415, current rewards: 257.29552, mean: 0.10459
[32m[0906 14-52-47 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 14-52-47 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-52-48 @MBExp.py:227][0m Rewards obtained: [250.82362331657276], Lows: [4], Highs: [11], Total time: 3075.2093349999996
[32m[0906 14-54-02 @MBExp.py:144][0m ####################################################################
[32m[0906 14-54-02 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 14-54-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03347, current rewards: -0.10938, mean: -0.01094
[32m[0906 14-54-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03442, current rewards: 5.37690, mean: 0.08961
[32m[0906 14-54-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03446, current rewards: 10.86790, mean: 0.09880
[32m[0906 14-54-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03451, current rewards: 16.34752, mean: 0.10217
[32m[0906 14-54-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03449, current rewards: 22.07102, mean: 0.10510
[32m[0906 14-54-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03447, current rewards: 27.64131, mean: 0.10631
[32m[0906 14-54-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03444, current rewards: 33.21467, mean: 0.10714
[32m[0906 14-54-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03445, current rewards: 38.78917, mean: 0.10775
[32m[0906 14-54-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03446, current rewards: 44.36055, mean: 0.10820
[32m[0906 14-54-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03446, current rewards: 49.93289, mean: 0.10855
[32m[0906 14-54-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03438, current rewards: 53.46549, mean: 0.10483
[32m[0906 14-54-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03430, current rewards: 58.99054, mean: 0.10534
[32m[0906 14-54-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03426, current rewards: 64.52044, mean: 0.10577
[32m[0906 14-54-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03422, current rewards: 70.04266, mean: 0.10613
[32m[0906 14-54-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03417, current rewards: 75.56777, mean: 0.10643
[32m[0906 14-54-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03412, current rewards: 81.09253, mean: 0.10670
[32m[0906 14-54-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03409, current rewards: 85.46646, mean: 0.10551
[32m[0906 14-54-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03401, current rewards: 91.03810, mean: 0.10586
[32m[0906 14-54-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03393, current rewards: 96.60265, mean: 0.10616
[32m[0906 14-54-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03391, current rewards: 102.16399, mean: 0.10642
[32m[0906 14-54-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03390, current rewards: 105.54123, mean: 0.10450
[32m[0906 14-54-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03389, current rewards: 110.97970, mean: 0.10470
[32m[0906 14-54-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03388, current rewards: 116.56992, mean: 0.10502
[32m[0906 14-54-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03388, current rewards: 122.15741, mean: 0.10531
[32m[0906 14-54-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03386, current rewards: 127.74672, mean: 0.10558
[32m[0906 14-54-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03385, current rewards: 133.33683, mean: 0.10582
[32m[0906 14-54-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03385, current rewards: 138.92730, mean: 0.10605
[32m[0906 14-54-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03384, current rewards: 144.51857, mean: 0.10626
[32m[0906 14-54-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03386, current rewards: 150.10611, mean: 0.10646
[32m[0906 14-54-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03388, current rewards: 155.90101, mean: 0.10678
[32m[0906 14-54-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03391, current rewards: 161.43418, mean: 0.10691
[32m[0906 14-54-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03392, current rewards: 166.97441, mean: 0.10703
[32m[0906 14-54-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03394, current rewards: 172.51688, mean: 0.10715
[32m[0906 14-54-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03395, current rewards: 174.10909, mean: 0.10488
[32m[0906 14-55-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03397, current rewards: 180.02697, mean: 0.10528
[32m[0906 14-55-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03398, current rewards: 185.94485, mean: 0.10565
[32m[0906 14-55-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03400, current rewards: 191.86272, mean: 0.10600
[32m[0906 14-55-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03401, current rewards: 197.65368, mean: 0.10627
[32m[0906 14-55-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03402, current rewards: 201.31359, mean: 0.10540
[32m[0906 14-55-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03403, current rewards: 206.93931, mean: 0.10558
[32m[0906 14-55-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03405, current rewards: 212.56534, mean: 0.10575
[32m[0906 14-55-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03406, current rewards: 218.19474, mean: 0.10592
[32m[0906 14-55-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03406, current rewards: 223.81979, mean: 0.10608
[32m[0906 14-55-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03407, current rewards: 229.44307, mean: 0.10622
[32m[0906 14-55-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03408, current rewards: 235.06749, mean: 0.10637
[32m[0906 14-55-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03409, current rewards: 237.31860, mean: 0.10501
[32m[0906 14-55-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03410, current rewards: 243.02976, mean: 0.10521
[32m[0906 14-55-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03411, current rewards: 248.63837, mean: 0.10536
[32m[0906 14-55-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03412, current rewards: 254.24390, mean: 0.10550
[32m[0906 14-55-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03413, current rewards: 259.86868, mean: 0.10564
[32m[0906 14-55-28 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 14-55-28 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-55-28 @MBExp.py:227][0m Rewards obtained: [260.26666980589346], Lows: [7], Highs: [4], Total time: 3161.1951809999996
[32m[0906 14-56-44 @MBExp.py:144][0m ####################################################################
[32m[0906 14-56-44 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 14-56-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03406, current rewards: -2.19751, mean: -0.21975
[32m[0906 14-56-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03422, current rewards: 3.30622, mean: 0.05510
[32m[0906 14-56-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03441, current rewards: 8.82543, mean: 0.08023
[32m[0906 14-56-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03447, current rewards: 14.34590, mean: 0.08966
[32m[0906 14-56-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03450, current rewards: 19.86217, mean: 0.09458
[32m[0906 14-56-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03448, current rewards: 25.42416, mean: 0.09779
[32m[0906 14-56-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03448, current rewards: 30.94969, mean: 0.09984
[32m[0906 14-56-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03449, current rewards: 36.47518, mean: 0.10132
[32m[0906 14-56-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03450, current rewards: 42.00504, mean: 0.10245
[32m[0906 14-57-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03448, current rewards: 47.52990, mean: 0.10333
[32m[0906 14-57-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03442, current rewards: 50.97227, mean: 0.09995
[32m[0906 14-57-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03434, current rewards: 56.51601, mean: 0.10092
[32m[0906 14-57-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03428, current rewards: 62.06044, mean: 0.10174
[32m[0906 14-57-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03424, current rewards: 67.60330, mean: 0.10243
[32m[0906 14-57-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03419, current rewards: 73.14247, mean: 0.10302
[32m[0906 14-57-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03414, current rewards: 78.68929, mean: 0.10354
[32m[0906 14-57-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03406, current rewards: 84.23418, mean: 0.10399
[32m[0906 14-57-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03398, current rewards: 89.77863, mean: 0.10439
[32m[0906 14-57-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03391, current rewards: 94.17678, mean: 0.10349
[32m[0906 14-57-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03388, current rewards: 99.68108, mean: 0.10383
[32m[0906 14-57-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03386, current rewards: 105.20490, mean: 0.10416
[32m[0906 14-57-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03387, current rewards: 110.56141, mean: 0.10430
[32m[0906 14-57-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03386, current rewards: 115.99673, mean: 0.10450
[32m[0906 14-57-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03386, current rewards: 121.43201, mean: 0.10468
[32m[0906 14-57-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03384, current rewards: 126.85606, mean: 0.10484
[32m[0906 14-57-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03385, current rewards: 131.27601, mean: 0.10419
[32m[0906 14-57-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03384, current rewards: 136.80878, mean: 0.10443
[32m[0906 14-57-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03383, current rewards: 142.33723, mean: 0.10466
[32m[0906 14-57-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03384, current rewards: 147.86868, mean: 0.10487
[32m[0906 14-57-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03387, current rewards: 153.43050, mean: 0.10509
[32m[0906 14-57-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03390, current rewards: 158.96043, mean: 0.10527
[32m[0906 14-57-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03392, current rewards: 164.48620, mean: 0.10544
[32m[0906 14-57-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03394, current rewards: 170.01821, mean: 0.10560
[32m[0906 14-57-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03396, current rewards: 175.54542, mean: 0.10575
[32m[0906 14-57-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03398, current rewards: 181.07646, mean: 0.10589
[32m[0906 14-57-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03399, current rewards: 182.36765, mean: 0.10362
[32m[0906 14-57-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03401, current rewards: 187.90908, mean: 0.10382
[32m[0906 14-57-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03402, current rewards: 193.40734, mean: 0.10398
[32m[0906 14-57-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03403, current rewards: 198.94210, mean: 0.10416
[32m[0906 14-57-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03404, current rewards: 204.47500, mean: 0.10432
[32m[0906 14-57-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03405, current rewards: 208.82330, mean: 0.10389
[32m[0906 14-57-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03406, current rewards: 214.34824, mean: 0.10405
[32m[0906 14-57-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03406, current rewards: 219.87760, mean: 0.10421
[32m[0906 14-57-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03408, current rewards: 225.40488, mean: 0.10435
[32m[0906 14-58-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03408, current rewards: 230.93458, mean: 0.10450
[32m[0906 14-58-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03409, current rewards: 236.52590, mean: 0.10466
[32m[0906 14-58-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03410, current rewards: 242.06319, mean: 0.10479
[32m[0906 14-58-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03411, current rewards: 246.45131, mean: 0.10443
[32m[0906 14-58-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03412, current rewards: 251.97237, mean: 0.10455
[32m[0906 14-58-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03413, current rewards: 257.49190, mean: 0.10467
[32m[0906 14-58-10 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 14-58-10 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-58-10 @MBExp.py:227][0m Rewards obtained: [261.9025087753209], Lows: [4], Highs: [5], Total time: 3247.1612419999997
[32m[0906 14-59-28 @MBExp.py:144][0m ####################################################################
[32m[0906 14-59-28 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 14-59-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03428, current rewards: -1.08428, mean: -0.10843
[32m[0906 14-59-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03453, current rewards: 4.46277, mean: 0.07438
[32m[0906 14-59-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03446, current rewards: 10.00528, mean: 0.09096
[32m[0906 14-59-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03454, current rewards: 15.56013, mean: 0.09725
[32m[0906 14-59-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03454, current rewards: 21.18281, mean: 0.10087
[32m[0906 14-59-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03451, current rewards: 26.73425, mean: 0.10282
[32m[0906 14-59-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03450, current rewards: 32.28084, mean: 0.10413
[32m[0906 14-59-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03451, current rewards: 37.82996, mean: 0.10508
[32m[0906 14-59-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03452, current rewards: 43.37860, mean: 0.10580
[32m[0906 14-59-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03453, current rewards: 48.92502, mean: 0.10636
[32m[0906 14-59-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03449, current rewards: 54.47577, mean: 0.10682
[32m[0906 14-59-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03442, current rewards: 60.02315, mean: 0.10718
[32m[0906 14-59-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03435, current rewards: 63.58625, mean: 0.10424
[32m[0906 14-59-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03431, current rewards: 69.14781, mean: 0.10477
[32m[0906 14-59-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03425, current rewards: 74.70739, mean: 0.10522
[32m[0906 14-59-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03416, current rewards: 80.26295, mean: 0.10561
[32m[0906 14-59-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03408, current rewards: 85.82482, mean: 0.10596
[32m[0906 14-59-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03400, current rewards: 91.38338, mean: 0.10626
[32m[0906 14-59-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03393, current rewards: 96.94389, mean: 0.10653
[32m[0906 15-00-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03389, current rewards: 102.50360, mean: 0.10677
[32m[0906 15-00-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03389, current rewards: 108.06759, mean: 0.10700
[32m[0906 15-00-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03387, current rewards: 109.60002, mean: 0.10340
[32m[0906 15-00-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03387, current rewards: 115.64529, mean: 0.10418
[32m[0906 15-00-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03386, current rewards: 121.69055, mean: 0.10491
[32m[0906 15-00-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03385, current rewards: 127.73582, mean: 0.10557
[32m[0906 15-00-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03384, current rewards: 133.78108, mean: 0.10618
[32m[0906 15-00-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03384, current rewards: 120.77096, mean: 0.09219
[32m[0906 15-00-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03382, current rewards: 70.77096, mean: 0.05204
[32m[0906 15-00-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03383, current rewards: 20.77096, mean: 0.01473
[32m[0906 15-00-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03386, current rewards: -29.22904, mean: -0.02002
[32m[0906 15-00-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03388, current rewards: -79.22904, mean: -0.05247
[32m[0906 15-00-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03390, current rewards: -129.22904, mean: -0.08284
[32m[0906 15-00-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03392, current rewards: -179.22904, mean: -0.11132
[32m[0906 15-00-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03394, current rewards: -229.22904, mean: -0.13809
[32m[0906 15-00-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03396, current rewards: -279.22904, mean: -0.16329
[32m[0906 15-00-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03397, current rewards: -329.22904, mean: -0.18706
[32m[0906 15-00-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03398, current rewards: -379.22904, mean: -0.20952
[32m[0906 15-00-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03399, current rewards: -429.22904, mean: -0.23077
[32m[0906 15-00-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03400, current rewards: -479.22904, mean: -0.25091
[32m[0906 15-00-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03401, current rewards: -529.22904, mean: -0.27001
[32m[0906 15-00-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03402, current rewards: -579.22904, mean: -0.28817
[32m[0906 15-00-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03403, current rewards: -629.22904, mean: -0.30545
[32m[0906 15-00-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03404, current rewards: -679.22904, mean: -0.32191
[32m[0906 15-00-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03405, current rewards: -729.22904, mean: -0.33761
[32m[0906 15-00-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03407, current rewards: -778.17849, mean: -0.35212
[32m[0906 15-00-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03408, current rewards: -775.73638, mean: -0.34325
[32m[0906 15-00-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03409, current rewards: -773.29427, mean: -0.33476
[32m[0906 15-00-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03409, current rewards: -770.85217, mean: -0.32663
[32m[0906 15-00-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03410, current rewards: -768.41006, mean: -0.31884
[32m[0906 15-00-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03411, current rewards: -765.96795, mean: -0.31137
[32m[0906 15-00-54 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-00-54 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-00-54 @MBExp.py:227][0m Rewards obtained: [-764.0142644393201], Lows: [3], Highs: [918], Total time: 3333.0945559999996
[32m[0906 15-02-14 @MBExp.py:144][0m ####################################################################
[32m[0906 15-02-14 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 15-02-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03446, current rewards: 1.12282, mean: 0.11228
[32m[0906 15-02-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03456, current rewards: 8.42144, mean: 0.14036
[32m[0906 15-02-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03443, current rewards: 15.88163, mean: 0.14438
[32m[0906 15-02-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03446, current rewards: 21.75779, mean: 0.13599
[32m[0906 15-02-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03446, current rewards: 26.29338, mean: 0.12521
[32m[0906 15-02-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03449, current rewards: 30.82897, mean: 0.11857
[32m[0906 15-02-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03448, current rewards: 34.27384, mean: 0.11056
[32m[0906 15-02-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03448, current rewards: -15.72616, mean: -0.04368
[32m[0906 15-02-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03449, current rewards: -65.72616, mean: -0.16031
[32m[0906 15-02-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03451, current rewards: -115.72616, mean: -0.25158
[32m[0906 15-02-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03448, current rewards: -165.72616, mean: -0.32495
[32m[0906 15-02-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03438, current rewards: -215.72616, mean: -0.38523
[32m[0906 15-02-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03432, current rewards: -265.72616, mean: -0.43562
[32m[0906 15-02-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03423, current rewards: -315.72616, mean: -0.47837
[32m[0906 15-02-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03410, current rewards: -365.72616, mean: -0.51511
[32m[0906 15-02-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03403, current rewards: -415.72616, mean: -0.54701
[32m[0906 15-02-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03393, current rewards: -465.72616, mean: -0.57497
[32m[0906 15-02-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03385, current rewards: -515.72616, mean: -0.59968
[32m[0906 15-02-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03380, current rewards: -565.72616, mean: -0.62168
[32m[0906 15-02-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03376, current rewards: -615.72616, mean: -0.64138
[32m[0906 15-02-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03376, current rewards: -665.72616, mean: -0.65913
[32m[0906 15-02-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03376, current rewards: -715.72616, mean: -0.67521
[32m[0906 15-02-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03376, current rewards: -765.72616, mean: -0.68984
[32m[0906 15-02-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03376, current rewards: -815.72616, mean: -0.70321
[32m[0906 15-02-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03375, current rewards: -865.72616, mean: -0.71548
[32m[0906 15-02-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03375, current rewards: -915.72616, mean: -0.72677
[32m[0906 15-02-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03375, current rewards: -965.72616, mean: -0.73720
[32m[0906 15-03-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03374, current rewards: -1015.72616, mean: -0.74686
[32m[0906 15-03-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03374, current rewards: -1065.72616, mean: -0.75583
[32m[0906 15-03-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03377, current rewards: -1115.72616, mean: -0.76420
[32m[0906 15-03-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03380, current rewards: -1165.72616, mean: -0.77200
[32m[0906 15-03-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03383, current rewards: -1215.72616, mean: -0.77931
[32m[0906 15-03-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03385, current rewards: -1265.72616, mean: -0.78617
[32m[0906 15-03-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03387, current rewards: -1315.72616, mean: -0.79261
[32m[0906 15-03-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03389, current rewards: -1365.72616, mean: -0.79867
[32m[0906 15-03-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03391, current rewards: -1415.72616, mean: -0.80439
[32m[0906 15-03-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03393, current rewards: -1465.72616, mean: -0.80979
[32m[0906 15-03-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03394, current rewards: -1515.72616, mean: -0.81491
[32m[0906 15-03-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03396, current rewards: -1565.72616, mean: -0.81975
[32m[0906 15-03-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03398, current rewards: -1615.72616, mean: -0.82435
[32m[0906 15-03-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03400, current rewards: -1665.72616, mean: -0.82872
[32m[0906 15-03-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03401, current rewards: -1715.72616, mean: -0.83288
[32m[0906 15-03-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03402, current rewards: -1765.72616, mean: -0.83684
[32m[0906 15-03-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03404, current rewards: -1815.72616, mean: -0.84061
[32m[0906 15-03-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03405, current rewards: -1865.72616, mean: -0.84422
[32m[0906 15-03-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03405, current rewards: -1915.72616, mean: -0.84767
[32m[0906 15-03-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03406, current rewards: -1965.72616, mean: -0.85096
[32m[0906 15-03-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03407, current rewards: -2015.72616, mean: -0.85412
[32m[0906 15-03-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03408, current rewards: -2065.72616, mean: -0.85715
[32m[0906 15-03-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03409, current rewards: -2115.72616, mean: -0.86005
[32m[0906 15-03-40 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-03-40 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-03-40 @MBExp.py:227][0m Rewards obtained: [-2155.7261567421992], Lows: [0], Highs: [2191], Total time: 3418.9802649999997
[32m[0906 15-05-03 @MBExp.py:144][0m ####################################################################
[32m[0906 15-05-03 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 15-05-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03456, current rewards: 0.04634, mean: 0.00463
[32m[0906 15-05-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03448, current rewards: 5.33974, mean: 0.08900
[32m[0906 15-05-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03433, current rewards: 10.82627, mean: 0.09842
[32m[0906 15-05-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03439, current rewards: 16.31246, mean: 0.10195
[32m[0906 15-05-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03446, current rewards: 22.04587, mean: 0.10498
[32m[0906 15-05-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03445, current rewards: 27.58571, mean: 0.10610
[32m[0906 15-05-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03448, current rewards: 33.12134, mean: 0.10684
[32m[0906 15-05-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03447, current rewards: 38.65875, mean: 0.10739
[32m[0906 15-05-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03453, current rewards: 44.19537, mean: 0.10779
[32m[0906 15-05-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03451, current rewards: 49.73677, mean: 0.10812
[32m[0906 15-05-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03451, current rewards: 53.19413, mean: 0.10430
[32m[0906 15-05-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03442, current rewards: 58.76185, mean: 0.10493
[32m[0906 15-05-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03431, current rewards: 64.33736, mean: 0.10547
[32m[0906 15-05-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03419, current rewards: 69.90185, mean: 0.10591
[32m[0906 15-05-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03409, current rewards: 75.46963, mean: 0.10630
[32m[0906 15-05-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03398, current rewards: 81.03763, mean: 0.10663
[32m[0906 15-05-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03390, current rewards: 86.60560, mean: 0.10692
[32m[0906 15-05-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03384, current rewards: 92.18080, mean: 0.10719
[32m[0906 15-05-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03376, current rewards: 97.74927, mean: 0.10742
[32m[0906 15-05-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03370, current rewards: 103.31756, mean: 0.10762
[32m[0906 15-05-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03372, current rewards: 106.69332, mean: 0.10564
[32m[0906 15-05-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03371, current rewards: 112.29074, mean: 0.10593
[32m[0906 15-05-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03372, current rewards: 117.88660, mean: 0.10620
[32m[0906 15-05-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03373, current rewards: 123.48529, mean: 0.10645
[32m[0906 15-05-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03373, current rewards: 129.08272, mean: 0.10668
[32m[0906 15-05-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03372, current rewards: 134.68135, mean: 0.10689
[32m[0906 15-05-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03372, current rewards: 139.21754, mean: 0.10627
[32m[0906 15-05-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03373, current rewards: 144.79102, mean: 0.10646
[32m[0906 15-05-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03374, current rewards: 150.44801, mean: 0.10670
[32m[0906 15-05-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03378, current rewards: 156.11174, mean: 0.10693
[32m[0906 15-05-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03380, current rewards: 161.67448, mean: 0.10707
[32m[0906 15-05-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03383, current rewards: 167.24705, mean: 0.10721
[32m[0906 15-05-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03385, current rewards: 172.81931, mean: 0.10734
[32m[0906 15-06-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03388, current rewards: 178.38837, mean: 0.10746
[32m[0906 15-06-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03390, current rewards: 183.96157, mean: 0.10758
[32m[0906 15-06-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03392, current rewards: 189.53270, mean: 0.10769
[32m[0906 15-06-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03394, current rewards: 195.10367, mean: 0.10779
[32m[0906 15-06-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03396, current rewards: 196.47896, mean: 0.10563
[32m[0906 15-06-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03397, current rewards: 202.14115, mean: 0.10583
[32m[0906 15-06-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03399, current rewards: 207.80741, mean: 0.10602
[32m[0906 15-06-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03400, current rewards: 213.47297, mean: 0.10621
[32m[0906 15-06-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03401, current rewards: 219.13622, mean: 0.10638
[32m[0906 15-06-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03402, current rewards: 224.79855, mean: 0.10654
[32m[0906 15-06-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03404, current rewards: 230.46261, mean: 0.10670
[32m[0906 15-06-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03405, current rewards: 236.12944, mean: 0.10685
[32m[0906 15-06-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03407, current rewards: 241.95185, mean: 0.10706
[32m[0906 15-06-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03408, current rewards: 247.67037, mean: 0.10722
[32m[0906 15-06-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03409, current rewards: 248.94105, mean: 0.10548
[32m[0906 15-06-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03410, current rewards: 254.51547, mean: 0.10561
[32m[0906 15-06-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03410, current rewards: 260.08353, mean: 0.10573
[32m[0906 15-06-29 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-06-29 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-06-29 @MBExp.py:227][0m Rewards obtained: [264.53983835753104], Lows: [4], Highs: [6], Total time: 3504.9038979999996
[32m[0906 15-07-53 @MBExp.py:144][0m ####################################################################
[32m[0906 15-07-53 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 15-07-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03404, current rewards: -1.14535, mean: -0.11453
[32m[0906 15-07-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03444, current rewards: 4.34975, mean: 0.07250
[32m[0906 15-07-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03448, current rewards: 9.84682, mean: 0.08952
[32m[0906 15-07-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03448, current rewards: 15.37409, mean: 0.09609
[32m[0906 15-08-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03445, current rewards: 20.87970, mean: 0.09943
[32m[0906 15-08-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03446, current rewards: 26.37626, mean: 0.10145
[32m[0906 15-08-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03445, current rewards: 31.88043, mean: 0.10284
[32m[0906 15-08-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03446, current rewards: 37.38237, mean: 0.10384
[32m[0906 15-08-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03443, current rewards: 42.88158, mean: 0.10459
[32m[0906 15-08-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03445, current rewards: 48.38435, mean: 0.10518
[32m[0906 15-08-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03446, current rewards: 51.82065, mean: 0.10161
[32m[0906 15-08-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03431, current rewards: 57.11867, mean: 0.10200
[32m[0906 15-08-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03419, current rewards: 62.57107, mean: 0.10258
[32m[0906 15-08-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03408, current rewards: 68.06376, mean: 0.10313
[32m[0906 15-08-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03397, current rewards: 73.54522, mean: 0.10358
[32m[0906 15-08-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03388, current rewards: 79.03017, mean: 0.10399
[32m[0906 15-08-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03379, current rewards: 82.26795, mean: 0.10157
[32m[0906 15-08-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03372, current rewards: 87.56191, mean: 0.10182
[32m[0906 15-08-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03366, current rewards: 92.85192, mean: 0.10204
[32m[0906 15-08-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03362, current rewards: 98.14124, mean: 0.10223
[32m[0906 15-08-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03362, current rewards: 103.43416, mean: 0.10241
[32m[0906 15-08-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03362, current rewards: 108.72628, mean: 0.10257
[32m[0906 15-08-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03361, current rewards: 114.01868, mean: 0.10272
[32m[0906 15-08-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03362, current rewards: 119.31155, mean: 0.10285
[32m[0906 15-08-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03362, current rewards: 124.60544, mean: 0.10298
[32m[0906 15-08-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03362, current rewards: 129.89588, mean: 0.10309
[32m[0906 15-08-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03362, current rewards: 135.19025, mean: 0.10320
[32m[0906 15-08-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03362, current rewards: 139.37641, mean: 0.10248
[32m[0906 15-08-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03362, current rewards: 145.08344, mean: 0.10290
[32m[0906 15-08-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03365, current rewards: 150.59376, mean: 0.10315
[32m[0906 15-08-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03368, current rewards: 156.09979, mean: 0.10338
[32m[0906 15-08-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03370, current rewards: 161.60699, mean: 0.10359
[32m[0906 15-08-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03372, current rewards: 167.11242, mean: 0.10380
[32m[0906 15-08-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03375, current rewards: 172.62295, mean: 0.10399
[32m[0906 15-08-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03377, current rewards: 178.12775, mean: 0.10417
[32m[0906 15-08-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03380, current rewards: 183.63503, mean: 0.10434
[32m[0906 15-08-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03382, current rewards: 189.13629, mean: 0.10450
[32m[0906 15-08-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03383, current rewards: 192.59184, mean: 0.10354
[32m[0906 15-08-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03385, current rewards: 198.09867, mean: 0.10372
[32m[0906 15-09-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03387, current rewards: 203.60429, mean: 0.10388
[32m[0906 15-09-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03388, current rewards: 207.08361, mean: 0.10303
[32m[0906 15-09-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03390, current rewards: 212.46304, mean: 0.10314
[32m[0906 15-09-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03391, current rewards: 217.84118, mean: 0.10324
[32m[0906 15-09-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03393, current rewards: 223.21917, mean: 0.10334
[32m[0906 15-09-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03394, current rewards: 228.57266, mean: 0.10343
[32m[0906 15-09-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03396, current rewards: 232.98970, mean: 0.10309
[32m[0906 15-09-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03397, current rewards: 238.49977, mean: 0.10325
[32m[0906 15-09-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03398, current rewards: 244.00341, mean: 0.10339
[32m[0906 15-09-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03399, current rewards: 249.51240, mean: 0.10353
[32m[0906 15-09-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03400, current rewards: 255.01460, mean: 0.10366
[32m[0906 15-09-19 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 15-09-19 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-09-19 @MBExp.py:227][0m Rewards obtained: [259.42355909182345], Lows: [4], Highs: [4], Total time: 3590.55655
[32m[0906 15-10-46 @MBExp.py:144][0m ####################################################################
[32m[0906 15-10-46 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 15-10-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03334, current rewards: -0.06066, mean: -0.00607
[32m[0906 15-10-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03409, current rewards: 5.38784, mean: 0.08980
[32m[0906 15-10-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03427, current rewards: 10.88693, mean: 0.09897
[32m[0906 15-10-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03428, current rewards: 16.53775, mean: 0.10336
[32m[0906 15-10-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03432, current rewards: 22.00642, mean: 0.10479
[32m[0906 15-10-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03438, current rewards: 27.47069, mean: 0.10566
[32m[0906 15-10-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03439, current rewards: 32.93528, mean: 0.10624
[32m[0906 15-10-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03440, current rewards: 38.40161, mean: 0.10667
[32m[0906 15-11-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03438, current rewards: 41.83138, mean: 0.10203
[32m[0906 15-11-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03440, current rewards: 47.34769, mean: 0.10293
[32m[0906 15-11-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03430, current rewards: 52.86063, mean: 0.10365
[32m[0906 15-11-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03418, current rewards: 58.23565, mean: 0.10399
[32m[0906 15-11-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03405, current rewards: 63.73532, mean: 0.10448
[32m[0906 15-11-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03395, current rewards: 69.23552, mean: 0.10490
[32m[0906 15-11-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03386, current rewards: 74.73998, mean: 0.10527
[32m[0906 15-11-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03379, current rewards: 80.23849, mean: 0.10558
[32m[0906 15-11-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03373, current rewards: 85.73983, mean: 0.10585
[32m[0906 15-11-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03367, current rewards: 91.24027, mean: 0.10609
[32m[0906 15-11-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03361, current rewards: 95.68943, mean: 0.10515
[32m[0906 15-11-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03357, current rewards: 101.30035, mean: 0.10552
[32m[0906 15-11-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03355, current rewards: 106.79312, mean: 0.10574
[32m[0906 15-11-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03356, current rewards: 112.28515, mean: 0.10593
[32m[0906 15-11-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03356, current rewards: 117.77856, mean: 0.10611
[32m[0906 15-11-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03356, current rewards: 123.27293, mean: 0.10627
[32m[0906 15-11-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03357, current rewards: 126.85029, mean: 0.10483
[32m[0906 15-11-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03358, current rewards: 132.38246, mean: 0.10507
[32m[0906 15-11-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03358, current rewards: 137.91584, mean: 0.10528
[32m[0906 15-11-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03358, current rewards: 143.43131, mean: 0.10546
[32m[0906 15-11-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03358, current rewards: 148.73255, mean: 0.10548
[32m[0906 15-11-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03361, current rewards: 154.24759, mean: 0.10565
[32m[0906 15-11-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03364, current rewards: 159.75443, mean: 0.10580
[32m[0906 15-11-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03368, current rewards: 165.26411, mean: 0.10594
[32m[0906 15-11-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03370, current rewards: 170.77916, mean: 0.10607
[32m[0906 15-11-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03372, current rewards: 176.29026, mean: 0.10620
[32m[0906 15-11-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03374, current rewards: 181.80243, mean: 0.10632
[32m[0906 15-11-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03377, current rewards: 187.31322, mean: 0.10643
[32m[0906 15-11-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03379, current rewards: 193.15668, mean: 0.10672
[32m[0906 15-11-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03381, current rewards: 198.32147, mean: 0.10662
[32m[0906 15-11-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03383, current rewards: 206.39576, mean: 0.10806
[32m[0906 15-11-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03385, current rewards: 214.47005, mean: 0.10942
[32m[0906 15-11-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03386, current rewards: 222.54433, mean: 0.11072
[32m[0906 15-11-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03388, current rewards: 230.61862, mean: 0.11195
[32m[0906 15-11-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03389, current rewards: 238.69291, mean: 0.11312
[32m[0906 15-11-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03391, current rewards: 246.76720, mean: 0.11424
[32m[0906 15-12-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03393, current rewards: 254.84149, mean: 0.11531
[32m[0906 15-12-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03394, current rewards: 257.70174, mean: 0.11403
[32m[0906 15-12-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03395, current rewards: 207.70174, mean: 0.08991
[32m[0906 15-12-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03397, current rewards: 157.70174, mean: 0.06682
[32m[0906 15-12-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03398, current rewards: 107.70174, mean: 0.04469
[32m[0906 15-12-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03399, current rewards: 57.70174, mean: 0.02346
[32m[0906 15-12-11 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 15-12-11 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-12-11 @MBExp.py:227][0m Rewards obtained: [17.701739994472007], Lows: [3], Highs: [244], Total time: 3676.1983339999997
[32m[0906 15-13-40 @MBExp.py:144][0m ####################################################################
[32m[0906 15-13-40 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 15-13-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03373, current rewards: 0.01037, mean: 0.00104
[32m[0906 15-13-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03430, current rewards: 5.39099, mean: 0.08985
[32m[0906 15-13-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03432, current rewards: 10.90007, mean: 0.09909
[32m[0906 15-13-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03443, current rewards: 16.45994, mean: 0.10287
[32m[0906 15-13-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03444, current rewards: 22.13869, mean: 0.10542
[32m[0906 15-13-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03441, current rewards: 27.65633, mean: 0.10637
[32m[0906 15-13-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03441, current rewards: 33.16879, mean: 0.10700
[32m[0906 15-13-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03441, current rewards: 34.63001, mean: 0.09619
[32m[0906 15-13-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03443, current rewards: 40.31867, mean: 0.09834
[32m[0906 15-13-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03433, current rewards: 46.00735, mean: 0.10002
[32m[0906 15-13-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03427, current rewards: 51.69601, mean: 0.10136
[32m[0906 15-13-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03417, current rewards: 57.38472, mean: 0.10247
[32m[0906 15-14-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03403, current rewards: 63.72037, mean: 0.10446
[32m[0906 15-14-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03391, current rewards: 70.48441, mean: 0.10679
[32m[0906 15-14-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03382, current rewards: 25.02553, mean: 0.03525
[32m[0906 15-14-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03376, current rewards: -24.97447, mean: -0.03286
[32m[0906 15-14-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03368, current rewards: -74.97447, mean: -0.09256
[32m[0906 15-14-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03364, current rewards: -124.97447, mean: -0.14532
[32m[0906 15-14-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03357, current rewards: -174.97447, mean: -0.19228
[32m[0906 15-14-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03351, current rewards: -224.97447, mean: -0.23435
[32m[0906 15-14-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03350, current rewards: -274.97447, mean: -0.27225
[32m[0906 15-14-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03351, current rewards: -324.97447, mean: -0.30658
[32m[0906 15-14-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03352, current rewards: -374.97447, mean: -0.33781
[32m[0906 15-14-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03353, current rewards: -424.97447, mean: -0.36636
[32m[0906 15-14-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03354, current rewards: -474.97447, mean: -0.39254
[32m[0906 15-14-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03354, current rewards: -524.97447, mean: -0.41665
[32m[0906 15-14-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03356, current rewards: -574.97447, mean: -0.43891
[32m[0906 15-14-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03356, current rewards: -624.97447, mean: -0.45954
[32m[0906 15-14-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03356, current rewards: -674.97447, mean: -0.47871
[32m[0906 15-14-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03358, current rewards: -724.97447, mean: -0.49656
[32m[0906 15-14-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03361, current rewards: -774.97447, mean: -0.51323
[32m[0906 15-14-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03364, current rewards: -824.97447, mean: -0.52883
[32m[0906 15-14-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03366, current rewards: -874.97447, mean: -0.54346
[32m[0906 15-14-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03368, current rewards: -924.97447, mean: -0.55721
[32m[0906 15-14-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03370, current rewards: -974.97447, mean: -0.57016
[32m[0906 15-14-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03372, current rewards: -1024.97447, mean: -0.58237
[32m[0906 15-14-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03374, current rewards: -1074.97447, mean: -0.59391
[32m[0906 15-14-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03376, current rewards: -1124.97447, mean: -0.60482
[32m[0906 15-14-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03378, current rewards: -1174.97447, mean: -0.61517
[32m[0906 15-14-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03380, current rewards: -1224.97447, mean: -0.62499
[32m[0906 15-14-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03382, current rewards: -1274.97447, mean: -0.63432
[32m[0906 15-14-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03384, current rewards: -1324.97447, mean: -0.64319
[32m[0906 15-14-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03386, current rewards: -1374.97447, mean: -0.65165
[32m[0906 15-14-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03388, current rewards: -1424.97447, mean: -0.65971
[32m[0906 15-14-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03389, current rewards: -1474.97447, mean: -0.66741
[32m[0906 15-14-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03391, current rewards: -1524.97447, mean: -0.67477
[32m[0906 15-14-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03392, current rewards: -1574.97447, mean: -0.68181
[32m[0906 15-15-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03393, current rewards: -1624.97447, mean: -0.68855
[32m[0906 15-15-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03395, current rewards: -1674.97447, mean: -0.69501
[32m[0906 15-15-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03397, current rewards: -1724.97447, mean: -0.70121
[32m[0906 15-15-05 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 15-15-05 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-15-05 @MBExp.py:227][0m Rewards obtained: [-1764.9744655305049], Lows: [2], Highs: [1837], Total time: 3761.773296
[32m[0906 15-16-36 @MBExp.py:144][0m ####################################################################
[32m[0906 15-16-36 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 15-16-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03403, current rewards: -1.06379, mean: -0.10638
[32m[0906 15-16-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03436, current rewards: 4.46979, mean: 0.07450
[32m[0906 15-16-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03443, current rewards: 10.01944, mean: 0.09109
[32m[0906 15-16-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03447, current rewards: 15.70968, mean: 0.09819
[32m[0906 15-16-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03445, current rewards: 21.37562, mean: 0.10179
[32m[0906 15-16-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03446, current rewards: 27.04126, mean: 0.10400
[32m[0906 15-16-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03445, current rewards: 30.45571, mean: 0.09824
[32m[0906 15-16-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03443, current rewards: 35.96582, mean: 0.09991
[32m[0906 15-16-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03431, current rewards: 41.48234, mean: 0.10118
[32m[0906 15-16-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03423, current rewards: 46.99712, mean: 0.10217
[32m[0906 15-16-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03416, current rewards: 52.48132, mean: 0.10290
[32m[0906 15-16-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03406, current rewards: 57.91556, mean: 0.10342
[32m[0906 15-16-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03394, current rewards: 63.31333, mean: 0.10379
[32m[0906 15-16-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03385, current rewards: 68.81458, mean: 0.10426
[32m[0906 15-17-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03376, current rewards: 74.30635, mean: 0.10466
[32m[0906 15-17-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03367, current rewards: 79.79839, mean: 0.10500
[32m[0906 15-17-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03361, current rewards: 85.29456, mean: 0.10530
[32m[0906 15-17-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03354, current rewards: 90.81687, mean: 0.10560
[32m[0906 15-17-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03350, current rewards: 96.32432, mean: 0.10585
[32m[0906 15-17-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03345, current rewards: 101.82385, mean: 0.10607
[32m[0906 15-17-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03341, current rewards: 107.34487, mean: 0.10628
[32m[0906 15-17-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03344, current rewards: 112.84402, mean: 0.10646
[32m[0906 15-17-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03343, current rewards: 118.34978, mean: 0.10662
[32m[0906 15-17-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03344, current rewards: 123.85353, mean: 0.10677
[32m[0906 15-17-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03345, current rewards: 129.35544, mean: 0.10691
[32m[0906 15-17-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03345, current rewards: 134.86126, mean: 0.10703
[32m[0906 15-17-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03345, current rewards: 140.36682, mean: 0.10715
[32m[0906 15-17-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03346, current rewards: 145.86737, mean: 0.10726
[32m[0906 15-17-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03346, current rewards: 151.45504, mean: 0.10741
[32m[0906 15-17-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03348, current rewards: 156.95999, mean: 0.10751
[32m[0906 15-17-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03352, current rewards: 162.47214, mean: 0.10760
[32m[0906 15-17-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03355, current rewards: 167.98698, mean: 0.10768
[32m[0906 15-17-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03358, current rewards: 173.49342, mean: 0.10776
[32m[0906 15-17-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03361, current rewards: 179.07329, mean: 0.10788
[32m[0906 15-17-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03363, current rewards: 184.59493, mean: 0.10795
[32m[0906 15-17-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03366, current rewards: 190.11079, mean: 0.10802
[32m[0906 15-17-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03368, current rewards: 195.58802, mean: 0.10806
[32m[0906 15-17-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03371, current rewards: 201.11226, mean: 0.10812
[32m[0906 15-17-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03373, current rewards: 206.63142, mean: 0.10818
[32m[0906 15-17-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03374, current rewards: 212.14814, mean: 0.10824
[32m[0906 15-17-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03376, current rewards: 217.66677, mean: 0.10829
[32m[0906 15-17-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03378, current rewards: 223.18621, mean: 0.10834
[32m[0906 15-17-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03380, current rewards: 226.53180, mean: 0.10736
[32m[0906 15-17-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03381, current rewards: 232.03835, mean: 0.10743
[32m[0906 15-17-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03383, current rewards: 237.75519, mean: 0.10758
[32m[0906 15-17-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03385, current rewards: 243.32265, mean: 0.10766
[32m[0906 15-17-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03386, current rewards: 248.84546, mean: 0.10773
[32m[0906 15-17-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03388, current rewards: 254.36827, mean: 0.10778
[32m[0906 15-17-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03389, current rewards: 258.27602, mean: 0.10717
[32m[0906 15-18-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03390, current rewards: 263.96414, mean: 0.10730
[32m[0906 15-18-01 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 15-18-01 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-18-01 @MBExp.py:227][0m Rewards obtained: [268.51831608152287], Lows: [3], Highs: [2], Total time: 3847.202069
[32m[0906 15-19-33 @MBExp.py:144][0m ####################################################################
[32m[0906 15-19-33 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 15-19-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03363, current rewards: 0.00668, mean: 0.00067
[32m[0906 15-19-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03428, current rewards: 5.63473, mean: 0.09391
[32m[0906 15-19-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03431, current rewards: 11.26705, mean: 0.10243
[32m[0906 15-19-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03437, current rewards: 16.91044, mean: 0.10569
[32m[0906 15-19-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03438, current rewards: 22.54561, mean: 0.10736
[32m[0906 15-19-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03440, current rewards: 28.17659, mean: 0.10837
[32m[0906 15-19-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03441, current rewards: 33.81564, mean: 0.10908
[32m[0906 15-19-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03426, current rewards: 39.44701, mean: 0.10958
[32m[0906 15-19-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03417, current rewards: 45.08479, mean: 0.10996
[32m[0906 15-19-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03414, current rewards: 50.72035, mean: 0.11026
[32m[0906 15-19-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03408, current rewards: 56.35258, mean: 0.11050
[32m[0906 15-19-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03400, current rewards: 59.50407, mean: 0.10626
[32m[0906 15-19-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03390, current rewards: 64.88237, mean: 0.10636
[32m[0906 15-19-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03382, current rewards: 70.25640, mean: 0.10645
[32m[0906 15-19-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03375, current rewards: 75.63248, mean: 0.10652
[32m[0906 15-19-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03367, current rewards: 81.01165, mean: 0.10659
[32m[0906 15-20-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03362, current rewards: 86.39027, mean: 0.10665
[32m[0906 15-20-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03357, current rewards: 91.76580, mean: 0.10670
[32m[0906 15-20-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03351, current rewards: 97.14116, mean: 0.10675
[32m[0906 15-20-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03345, current rewards: 102.55365, mean: 0.10683
[32m[0906 15-20-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03341, current rewards: 107.97105, mean: 0.10690
[32m[0906 15-20-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03341, current rewards: 113.38323, mean: 0.10697
[32m[0906 15-20-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03342, current rewards: 118.79813, mean: 0.10703
[32m[0906 15-20-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03343, current rewards: 124.20909, mean: 0.10708
[32m[0906 15-20-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03343, current rewards: 129.61802, mean: 0.10712
[32m[0906 15-20-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03343, current rewards: 135.03018, mean: 0.10717
[32m[0906 15-20-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03344, current rewards: 138.35663, mean: 0.10562
[32m[0906 15-20-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03344, current rewards: 144.04584, mean: 0.10592
[32m[0906 15-20-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03344, current rewards: 151.27124, mean: 0.10728
[32m[0906 15-20-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03346, current rewards: 158.92632, mean: 0.10885
[32m[0906 15-20-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03349, current rewards: 166.58140, mean: 0.11032
[32m[0906 15-20-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03352, current rewards: 174.23648, mean: 0.11169
[32m[0906 15-20-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03355, current rewards: 181.89157, mean: 0.11298
[32m[0906 15-20-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03358, current rewards: 189.54665, mean: 0.11418
[32m[0906 15-20-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03360, current rewards: 197.20173, mean: 0.11532
[32m[0906 15-20-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03363, current rewards: 197.93820, mean: 0.11246
[32m[0906 15-20-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03365, current rewards: 147.93820, mean: 0.08173
[32m[0906 15-20-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03367, current rewards: 97.93820, mean: 0.05265
[32m[0906 15-20-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03369, current rewards: 47.93820, mean: 0.02510
[32m[0906 15-20-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03371, current rewards: -2.06180, mean: -0.00105
[32m[0906 15-20-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03372, current rewards: -52.06180, mean: -0.02590
[32m[0906 15-20-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03374, current rewards: -102.06180, mean: -0.04954
[32m[0906 15-20-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03376, current rewards: -152.06180, mean: -0.07207
[32m[0906 15-20-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03377, current rewards: -202.06180, mean: -0.09355
[32m[0906 15-20-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03379, current rewards: -247.86599, mean: -0.11216
[32m[0906 15-20-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03380, current rewards: -245.41828, mean: -0.10859
[32m[0906 15-20-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03381, current rewards: -242.97058, mean: -0.10518
[32m[0906 15-20-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03382, current rewards: -240.52288, mean: -0.10192
[32m[0906 15-20-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03383, current rewards: -238.07518, mean: -0.09879
[32m[0906 15-20-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03384, current rewards: -282.83041, mean: -0.11497
[32m[0906 15-20-59 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 15-20-59 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-20-59 @MBExp.py:227][0m Rewards obtained: [-322.83040715916707], Lows: [2], Highs: [538], Total time: 3932.474724
[32m[0906 15-22-33 @MBExp.py:144][0m ####################################################################
[32m[0906 15-22-33 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 15-22-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03359, current rewards: 0.06722, mean: 0.00672
[32m[0906 15-22-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03427, current rewards: 5.61135, mean: 0.09352
[32m[0906 15-22-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03433, current rewards: 11.15777, mean: 0.10143
[32m[0906 15-22-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03434, current rewards: 16.83707, mean: 0.10523
[32m[0906 15-22-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03434, current rewards: 22.36789, mean: 0.10651
[32m[0906 15-22-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03436, current rewards: 27.90162, mean: 0.10731
[32m[0906 15-22-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03420, current rewards: 33.43289, mean: 0.10785
[32m[0906 15-22-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03413, current rewards: 38.96666, mean: 0.10824
[32m[0906 15-22-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03404, current rewards: 42.44004, mean: 0.10351
[32m[0906 15-22-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03402, current rewards: 47.87326, mean: 0.10407
[32m[0906 15-22-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03399, current rewards: 53.30986, mean: 0.10453
[32m[0906 15-22-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03395, current rewards: 58.60344, mean: 0.10465
[32m[0906 15-22-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03383, current rewards: 64.15403, mean: 0.10517
[32m[0906 15-22-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03375, current rewards: 69.69153, mean: 0.10559
[32m[0906 15-22-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03366, current rewards: 75.23258, mean: 0.10596
[32m[0906 15-22-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03360, current rewards: 80.77203, mean: 0.10628
[32m[0906 15-23-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03353, current rewards: 86.31573, mean: 0.10656
[32m[0906 15-23-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03349, current rewards: 91.84973, mean: 0.10680
[32m[0906 15-23-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03344, current rewards: 97.39099, mean: 0.10702
[32m[0906 15-23-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03341, current rewards: 103.07772, mean: 0.10737
[32m[0906 15-23-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03339, current rewards: 108.58539, mean: 0.10751
[32m[0906 15-23-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03338, current rewards: 113.06316, mean: 0.10666
[32m[0906 15-23-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03340, current rewards: 118.67707, mean: 0.10692
[32m[0906 15-23-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03340, current rewards: 124.29174, mean: 0.10715
[32m[0906 15-23-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03342, current rewards: 129.90916, mean: 0.10736
[32m[0906 15-23-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03343, current rewards: 135.52541, mean: 0.10756
[32m[0906 15-23-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03343, current rewards: 141.14709, mean: 0.10775
[32m[0906 15-23-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03344, current rewards: 146.76110, mean: 0.10791
[32m[0906 15-23-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03345, current rewards: 152.13610, mean: 0.10790
[32m[0906 15-23-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03347, current rewards: 157.68151, mean: 0.10800
[32m[0906 15-23-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03351, current rewards: 163.22269, mean: 0.10809
[32m[0906 15-23-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03354, current rewards: 168.76394, mean: 0.10818
[32m[0906 15-23-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03358, current rewards: 173.43137, mean: 0.10772
[32m[0906 15-23-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03361, current rewards: 179.03013, mean: 0.10785
[32m[0906 15-23-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03363, current rewards: 184.60697, mean: 0.10796
[32m[0906 15-23-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03366, current rewards: 190.18445, mean: 0.10806
[32m[0906 15-23-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03368, current rewards: 195.86299, mean: 0.10821
[32m[0906 15-23-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03371, current rewards: 201.59324, mean: 0.10838
[32m[0906 15-23-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03373, current rewards: 207.24933, mean: 0.10851
[32m[0906 15-23-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03375, current rewards: 212.90086, mean: 0.10862
[32m[0906 15-23-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03377, current rewards: 219.40097, mean: 0.10915
[32m[0906 15-23-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03379, current rewards: 224.98014, mean: 0.10921
[32m[0906 15-23-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03381, current rewards: 230.56201, mean: 0.10927
[32m[0906 15-23-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03383, current rewards: 236.14180, mean: 0.10932
[32m[0906 15-23-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03385, current rewards: 241.72203, mean: 0.10938
[32m[0906 15-23-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03386, current rewards: 247.15715, mean: 0.10936
[32m[0906 15-23-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03388, current rewards: 252.70573, mean: 0.10940
[32m[0906 15-23-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03389, current rewards: 258.25679, mean: 0.10943
[32m[0906 15-23-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03391, current rewards: 261.81700, mean: 0.10864
[32m[0906 15-23-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03392, current rewards: 267.35910, mean: 0.10868
[32m[0906 15-23-58 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 15-23-58 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-23-58 @MBExp.py:227][0m Rewards obtained: [271.7966735332334], Lows: [2], Highs: [3], Total time: 4017.9568790000003
[32m[0906 15-25-35 @MBExp.py:144][0m ####################################################################
[32m[0906 15-25-35 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 15-25-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03374, current rewards: 0.91490, mean: 0.09149
[32m[0906 15-25-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03438, current rewards: 5.79344, mean: 0.09656
[32m[0906 15-25-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03448, current rewards: 10.67249, mean: 0.09702
[32m[0906 15-25-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03446, current rewards: 15.61626, mean: 0.09760
[32m[0906 15-25-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03436, current rewards: 20.53487, mean: 0.09779
[32m[0906 15-25-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03424, current rewards: 25.45347, mean: 0.09790
[32m[0906 15-25-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03414, current rewards: 30.37232, mean: 0.09798
[32m[0906 15-25-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03405, current rewards: 35.29126, mean: 0.09803
[32m[0906 15-25-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03403, current rewards: 40.21037, mean: 0.09807
[32m[0906 15-25-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03398, current rewards: 42.51989, mean: 0.09243
[32m[0906 15-25-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03393, current rewards: 48.22337, mean: 0.09456
[32m[0906 15-25-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03391, current rewards: 53.88257, mean: 0.09622
[32m[0906 15-25-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03381, current rewards: 59.59957, mean: 0.09770
[32m[0906 15-25-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03373, current rewards: 63.10359, mean: 0.09561
[32m[0906 15-25-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03363, current rewards: 68.54894, mean: 0.09655
[32m[0906 15-26-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03356, current rewards: 73.99397, mean: 0.09736
[32m[0906 15-26-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03351, current rewards: 79.43837, mean: 0.09807
[32m[0906 15-26-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03347, current rewards: 84.88228, mean: 0.09870
[32m[0906 15-26-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03341, current rewards: 88.24764, mean: 0.09698
[32m[0906 15-26-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03337, current rewards: 93.63421, mean: 0.09754
[32m[0906 15-26-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03333, current rewards: 99.07550, mean: 0.09809
[32m[0906 15-26-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03329, current rewards: 104.56099, mean: 0.09864
[32m[0906 15-26-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03331, current rewards: 110.05044, mean: 0.09914
[32m[0906 15-26-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03333, current rewards: 115.54072, mean: 0.09960
[32m[0906 15-26-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03334, current rewards: 121.03054, mean: 0.10003
[32m[0906 15-26-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03336, current rewards: 126.52114, mean: 0.10041
[32m[0906 15-26-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03338, current rewards: 132.01091, mean: 0.10077
[32m[0906 15-26-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03339, current rewards: 137.49911, mean: 0.10110
[32m[0906 15-26-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03340, current rewards: 141.13496, mean: 0.10010
[32m[0906 15-26-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03341, current rewards: 146.28939, mean: 0.10020
[32m[0906 15-26-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03344, current rewards: 151.44657, mean: 0.10030
[32m[0906 15-26-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03348, current rewards: 156.60198, mean: 0.10039
[32m[0906 15-26-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03351, current rewards: 161.01844, mean: 0.10001
[32m[0906 15-26-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03355, current rewards: 166.54817, mean: 0.10033
[32m[0906 15-26-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03358, current rewards: 172.07764, mean: 0.10063
[32m[0906 15-26-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03361, current rewards: 177.60299, mean: 0.10091
[32m[0906 15-26-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03363, current rewards: 183.05834, mean: 0.10114
[32m[0906 15-26-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03366, current rewards: 188.57178, mean: 0.10138
[32m[0906 15-26-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03369, current rewards: 194.12960, mean: 0.10164
[32m[0906 15-26-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03372, current rewards: 199.68456, mean: 0.10188
[32m[0906 15-26-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03374, current rewards: 205.24004, mean: 0.10211
[32m[0906 15-26-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03376, current rewards: 210.79358, mean: 0.10233
[32m[0906 15-26-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03377, current rewards: 216.34873, mean: 0.10253
[32m[0906 15-26-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03380, current rewards: 219.61968, mean: 0.10168
[32m[0906 15-26-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03381, current rewards: 224.81384, mean: 0.10173
[32m[0906 15-26-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03383, current rewards: 229.95043, mean: 0.10175
[32m[0906 15-26-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03384, current rewards: 235.12509, mean: 0.10179
[32m[0906 15-26-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03386, current rewards: 240.29926, mean: 0.10182
[32m[0906 15-26-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03387, current rewards: 245.47648, mean: 0.10186
[32m[0906 15-26-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03388, current rewards: 249.80147, mean: 0.10155
[32m[0906 15-27-00 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 15-27-00 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-27-00 @MBExp.py:227][0m Rewards obtained: [254.16849114267634], Lows: [4], Highs: [5], Total time: 4103.345671
[32m[0906 15-28-39 @MBExp.py:144][0m ####################################################################
[32m[0906 15-28-39 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 15-28-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03399, current rewards: -0.02898, mean: -0.00290
[32m[0906 15-28-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03424, current rewards: 5.49159, mean: 0.09153
[32m[0906 15-28-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03436, current rewards: 11.00869, mean: 0.10008
[32m[0906 15-28-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03427, current rewards: 16.52918, mean: 0.10331
[32m[0906 15-28-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03412, current rewards: 22.04920, mean: 0.10500
[32m[0906 15-28-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03401, current rewards: 27.57041, mean: 0.10604
[32m[0906 15-28-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03398, current rewards: 33.08602, mean: 0.10673
[32m[0906 15-28-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03390, current rewards: 38.60578, mean: 0.10724
[32m[0906 15-28-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03388, current rewards: 44.12599, mean: 0.10762
[32m[0906 15-28-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03386, current rewards: 49.63857, mean: 0.10791
[32m[0906 15-28-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03383, current rewards: 55.15660, mean: 0.10815
[32m[0906 15-28-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03380, current rewards: 60.68931, mean: 0.10837
[32m[0906 15-28-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03373, current rewards: 66.88313, mean: 0.10964
[32m[0906 15-29-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03366, current rewards: 72.40510, mean: 0.10970
[32m[0906 15-29-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03360, current rewards: 77.92407, mean: 0.10975
[32m[0906 15-29-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03355, current rewards: 83.44686, mean: 0.10980
[32m[0906 15-29-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03350, current rewards: 88.97320, mean: 0.10984
[32m[0906 15-29-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03347, current rewards: 94.49149, mean: 0.10987
[32m[0906 15-29-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03342, current rewards: 97.98064, mean: 0.10767
[32m[0906 15-29-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03339, current rewards: 103.77785, mean: 0.10810
[32m[0906 15-29-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03336, current rewards: 109.42657, mean: 0.10834
[32m[0906 15-29-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03333, current rewards: 115.07533, mean: 0.10856
[32m[0906 15-29-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03333, current rewards: 120.72417, mean: 0.10876
[32m[0906 15-29-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03335, current rewards: 126.37296, mean: 0.10894
[32m[0906 15-29-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03336, current rewards: 132.02164, mean: 0.10911
[32m[0906 15-29-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03339, current rewards: 137.67051, mean: 0.10926
[32m[0906 15-29-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03340, current rewards: 143.31929, mean: 0.10940
[32m[0906 15-29-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03342, current rewards: 148.83585, mean: 0.10944
[32m[0906 15-29-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03342, current rewards: 154.41948, mean: 0.10952
[32m[0906 15-29-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03343, current rewards: 158.78887, mean: 0.10876
[32m[0906 15-29-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03345, current rewards: 164.31039, mean: 0.10881
[32m[0906 15-29-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03349, current rewards: 169.83489, mean: 0.10887
[32m[0906 15-29-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03352, current rewards: 175.35657, mean: 0.10892
[32m[0906 15-29-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03356, current rewards: 180.87608, mean: 0.10896
[32m[0906 15-29-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03359, current rewards: 186.39719, mean: 0.10900
[32m[0906 15-29-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03361, current rewards: 191.94718, mean: 0.10906
[32m[0906 15-29-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03364, current rewards: 197.46662, mean: 0.10910
[32m[0906 15-29-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03366, current rewards: 202.98774, mean: 0.10913
[32m[0906 15-29-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03368, current rewards: 208.46873, mean: 0.10915
[32m[0906 15-29-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03370, current rewards: 214.00038, mean: 0.10918
[32m[0906 15-29-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03372, current rewards: 219.53537, mean: 0.10922
[32m[0906 15-29-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03375, current rewards: 225.06825, mean: 0.10926
[32m[0906 15-29-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03377, current rewards: 230.59975, mean: 0.10929
[32m[0906 15-29-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03378, current rewards: 236.18000, mean: 0.10934
[32m[0906 15-29-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03380, current rewards: 241.71522, mean: 0.10937
[32m[0906 15-29-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03382, current rewards: 247.24553, mean: 0.10940
[32m[0906 15-29-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03382, current rewards: 250.73173, mean: 0.10854
[32m[0906 15-29-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03384, current rewards: 256.25908, mean: 0.10858
[32m[0906 15-30-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03385, current rewards: 261.79514, mean: 0.10863
[32m[0906 15-30-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03387, current rewards: 267.33471, mean: 0.10867
[32m[0906 15-30-04 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 15-30-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-30-04 @MBExp.py:227][0m Rewards obtained: [271.76309536742394], Lows: [2], Highs: [2], Total time: 4188.705492
[32m[0906 15-31-45 @MBExp.py:144][0m ####################################################################
[32m[0906 15-31-45 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 15-31-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03375, current rewards: -1.03094, mean: -0.10309
[32m[0906 15-31-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03426, current rewards: 4.55615, mean: 0.07594
[32m[0906 15-31-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03399, current rewards: 10.18234, mean: 0.09257
[32m[0906 15-31-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03390, current rewards: 15.73939, mean: 0.09837
[32m[0906 15-31-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03386, current rewards: 21.29384, mean: 0.10140
[32m[0906 15-31-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03383, current rewards: 26.85058, mean: 0.10327
[32m[0906 15-31-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03379, current rewards: 32.40272, mean: 0.10452
[32m[0906 15-31-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03379, current rewards: 37.95773, mean: 0.10544
[32m[0906 15-31-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03374, current rewards: 43.51396, mean: 0.10613
[32m[0906 15-32-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03371, current rewards: 49.07121, mean: 0.10668
[32m[0906 15-32-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03371, current rewards: 52.89058, mean: 0.10371
[32m[0906 15-32-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03370, current rewards: 56.63312, mean: 0.10113
[32m[0906 15-32-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03360, current rewards: 61.53213, mean: 0.10087
[32m[0906 15-32-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03352, current rewards: 67.10784, mean: 0.10168
[32m[0906 15-32-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03347, current rewards: 72.68352, mean: 0.10237
[32m[0906 15-32-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03342, current rewards: 78.26035, mean: 0.10297
[32m[0906 15-32-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03337, current rewards: 83.83766, mean: 0.10350
[32m[0906 15-32-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03334, current rewards: 89.41596, mean: 0.10397
[32m[0906 15-32-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03329, current rewards: 95.30692, mean: 0.10473
[32m[0906 15-32-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03326, current rewards: 104.09559, mean: 0.10843
[32m[0906 15-32-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03323, current rewards: 84.66569, mean: 0.08383
[32m[0906 15-32-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03321, current rewards: 34.66569, mean: 0.03270
[32m[0906 15-32-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03320, current rewards: -15.33431, mean: -0.01381
[32m[0906 15-32-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03322, current rewards: -65.33431, mean: -0.05632
[32m[0906 15-32-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03323, current rewards: -115.33431, mean: -0.09532
[32m[0906 15-32-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03324, current rewards: -165.33431, mean: -0.13122
[32m[0906 15-32-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03326, current rewards: -215.33431, mean: -0.16438
[32m[0906 15-32-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03327, current rewards: -265.33431, mean: -0.19510
[32m[0906 15-32-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03329, current rewards: -315.33431, mean: -0.22364
[32m[0906 15-32-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03331, current rewards: -365.33431, mean: -0.25023
[32m[0906 15-32-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03333, current rewards: -415.33431, mean: -0.27506
[32m[0906 15-32-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03336, current rewards: -465.33431, mean: -0.29829
[32m[0906 15-32-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03340, current rewards: -515.33431, mean: -0.32008
[32m[0906 15-32-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03344, current rewards: -565.33431, mean: -0.34056
[32m[0906 15-32-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03347, current rewards: -615.33431, mean: -0.35984
[32m[0906 15-32-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03350, current rewards: -665.33431, mean: -0.37803
[32m[0906 15-32-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03353, current rewards: -715.33431, mean: -0.39521
[32m[0906 15-32-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03357, current rewards: -765.33431, mean: -0.41147
[32m[0906 15-32-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03359, current rewards: -815.33431, mean: -0.42688
[32m[0906 15-32-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03362, current rewards: -865.33431, mean: -0.44150
[32m[0906 15-32-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03364, current rewards: -915.33431, mean: -0.45539
[32m[0906 15-32-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03366, current rewards: -965.33431, mean: -0.46861
[32m[0906 15-32-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03368, current rewards: -1015.33431, mean: -0.48120
[32m[0906 15-32-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03370, current rewards: -1065.33431, mean: -0.49321
[32m[0906 15-33-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03372, current rewards: -1115.33431, mean: -0.50468
[32m[0906 15-33-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03373, current rewards: -1165.33431, mean: -0.51563
[32m[0906 15-33-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03375, current rewards: -1215.33431, mean: -0.52612
[32m[0906 15-33-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03377, current rewards: -1265.33431, mean: -0.53616
[32m[0906 15-33-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03378, current rewards: -1315.33431, mean: -0.54578
[32m[0906 15-33-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03380, current rewards: -1365.33431, mean: -0.55501
[32m[0906 15-33-10 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 15-33-10 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-33-10 @MBExp.py:227][0m Rewards obtained: [-1405.3343100994061], Lows: [1], Highs: [1516], Total time: 4273.887888
[32m[0906 15-34-53 @MBExp.py:144][0m ####################################################################
[32m[0906 15-34-53 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 15-34-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03424, current rewards: -2.13726, mean: -0.21373
[32m[0906 15-34-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03395, current rewards: 3.36525, mean: 0.05609
[32m[0906 15-34-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03380, current rewards: 9.00393, mean: 0.08185
[32m[0906 15-34-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03374, current rewards: 14.49119, mean: 0.09057
[32m[0906 15-35-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03370, current rewards: 19.97424, mean: 0.09512
[32m[0906 15-35-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03370, current rewards: 25.45789, mean: 0.09791
[32m[0906 15-35-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03367, current rewards: 30.93879, mean: 0.09980
[32m[0906 15-35-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03365, current rewards: 34.82036, mean: 0.09672
[32m[0906 15-35-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03366, current rewards: 40.40870, mean: 0.09856
[32m[0906 15-35-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03366, current rewards: 45.99262, mean: 0.09998
[32m[0906 15-35-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03366, current rewards: 51.42248, mean: 0.10083
[32m[0906 15-35-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03363, current rewards: 56.88537, mean: 0.10158
[32m[0906 15-35-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03355, current rewards: 62.34816, mean: 0.10221
[32m[0906 15-35-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03349, current rewards: 67.81228, mean: 0.10275
[32m[0906 15-35-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03343, current rewards: 72.20532, mean: 0.10170
[32m[0906 15-35-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03339, current rewards: 77.64561, mean: 0.10217
[32m[0906 15-35-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03336, current rewards: 83.08148, mean: 0.10257
[32m[0906 15-35-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03331, current rewards: 88.52186, mean: 0.10293
[32m[0906 15-35-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03327, current rewards: 93.79540, mean: 0.10307
[32m[0906 15-35-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03324, current rewards: 99.19469, mean: 0.10333
[32m[0906 15-35-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03320, current rewards: 104.60369, mean: 0.10357
[32m[0906 15-35-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03316, current rewards: 110.01324, mean: 0.10379
[32m[0906 15-35-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03314, current rewards: 115.42442, mean: 0.10399
[32m[0906 15-35-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03315, current rewards: 120.81172, mean: 0.10415
[32m[0906 15-35-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03316, current rewards: 126.28518, mean: 0.10437
[32m[0906 15-35-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03319, current rewards: 131.75166, mean: 0.10456
[32m[0906 15-35-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03320, current rewards: 137.24549, mean: 0.10477
[32m[0906 15-35-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03322, current rewards: 142.71911, mean: 0.10494
[32m[0906 15-35-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03324, current rewards: 148.19113, mean: 0.10510
[32m[0906 15-35-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03326, current rewards: 153.66073, mean: 0.10525
[32m[0906 15-35-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03327, current rewards: 159.13166, mean: 0.10539
[32m[0906 15-35-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03331, current rewards: 164.59824, mean: 0.10551
[32m[0906 15-35-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03335, current rewards: 170.07204, mean: 0.10563
[32m[0906 15-35-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03338, current rewards: 175.53741, mean: 0.10575
[32m[0906 15-35-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03341, current rewards: 181.00709, mean: 0.10585
[32m[0906 15-35-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03344, current rewards: 186.52153, mean: 0.10598
[32m[0906 15-35-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03347, current rewards: 191.98942, mean: 0.10607
[32m[0906 15-35-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03350, current rewards: 195.90292, mean: 0.10532
[32m[0906 15-35-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03352, current rewards: 201.27525, mean: 0.10538
[32m[0906 15-35-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03355, current rewards: 206.64830, mean: 0.10543
[32m[0906 15-36-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03357, current rewards: 212.02155, mean: 0.10548
[32m[0906 15-36-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03359, current rewards: 217.39743, mean: 0.10553
[32m[0906 15-36-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03361, current rewards: 222.77446, mean: 0.10558
[32m[0906 15-36-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03363, current rewards: 228.21194, mean: 0.10565
[32m[0906 15-36-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03365, current rewards: 233.54605, mean: 0.10568
[32m[0906 15-36-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03367, current rewards: 236.71406, mean: 0.10474
[32m[0906 15-36-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03369, current rewards: 242.19694, mean: 0.10485
[32m[0906 15-36-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03370, current rewards: 247.68364, mean: 0.10495
[32m[0906 15-36-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03372, current rewards: 253.16878, mean: 0.10505
[32m[0906 15-36-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03373, current rewards: 258.65432, mean: 0.10514
[32m[0906 15-36-18 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 15-36-18 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-36-18 @MBExp.py:227][0m Rewards obtained: [263.03840931647136], Lows: [3], Highs: [4], Total time: 4358.914742
[32m[0906 15-38-02 @MBExp.py:144][0m ####################################################################
[32m[0906 15-38-02 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 15-38-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03271, current rewards: -1.07402, mean: -0.10740
[32m[0906 15-38-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03337, current rewards: 4.59636, mean: 0.07661
[32m[0906 15-38-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03348, current rewards: 10.13043, mean: 0.09209
[32m[0906 15-38-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03357, current rewards: 15.66557, mean: 0.09791
[32m[0906 15-38-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03361, current rewards: 21.19718, mean: 0.10094
[32m[0906 15-38-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03362, current rewards: 26.73325, mean: 0.10282
[32m[0906 15-38-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03364, current rewards: 32.26953, mean: 0.10410
[32m[0906 15-38-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03365, current rewards: 37.80428, mean: 0.10501
[32m[0906 15-38-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03362, current rewards: 43.33878, mean: 0.10570
[32m[0906 15-38-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03363, current rewards: 47.83412, mean: 0.10399
[32m[0906 15-38-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03363, current rewards: 53.32384, mean: 0.10456
[32m[0906 15-38-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03362, current rewards: 58.81777, mean: 0.10503
[32m[0906 15-38-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03353, current rewards: 64.31130, mean: 0.10543
[32m[0906 15-38-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03347, current rewards: 69.79320, mean: 0.10575
[32m[0906 15-38-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03341, current rewards: 76.03850, mean: 0.10710
[32m[0906 15-38-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03338, current rewards: 81.52469, mean: 0.10727
[32m[0906 15-38-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03334, current rewards: 87.00484, mean: 0.10741
[32m[0906 15-38-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03330, current rewards: 92.51267, mean: 0.10757
[32m[0906 15-38-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03327, current rewards: 96.12702, mean: 0.10563
[32m[0906 15-38-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03324, current rewards: 101.64346, mean: 0.10588
[32m[0906 15-38-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03320, current rewards: 107.16516, mean: 0.10610
[32m[0906 15-38-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03319, current rewards: 112.68392, mean: 0.10631
[32m[0906 15-38-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03317, current rewards: 118.20307, mean: 0.10649
[32m[0906 15-38-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03316, current rewards: 123.72450, mean: 0.10666
[32m[0906 15-38-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03319, current rewards: 129.24305, mean: 0.10681
[32m[0906 15-38-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03321, current rewards: 133.10130, mean: 0.10564
[32m[0906 15-38-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03323, current rewards: 139.64780, mean: 0.10660
[32m[0906 15-38-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03325, current rewards: 146.25604, mean: 0.10754
[32m[0906 15-38-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03327, current rewards: 152.86427, mean: 0.10841
[32m[0906 15-38-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03328, current rewards: 159.47250, mean: 0.10923
[32m[0906 15-38-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03329, current rewards: 166.08074, mean: 0.10999
[32m[0906 15-38-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03332, current rewards: 172.68897, mean: 0.11070
[32m[0906 15-38-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03335, current rewards: 138.53927, mean: 0.08605
[32m[0906 15-38-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03339, current rewards: 88.53927, mean: 0.05334
[32m[0906 15-39-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03343, current rewards: 38.53927, mean: 0.02254
[32m[0906 15-39-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03346, current rewards: -11.46073, mean: -0.00651
[32m[0906 15-39-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03349, current rewards: -61.46073, mean: -0.03396
[32m[0906 15-39-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03351, current rewards: -111.46073, mean: -0.05993
[32m[0906 15-39-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03353, current rewards: -161.46073, mean: -0.08453
[32m[0906 15-39-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03356, current rewards: -211.46073, mean: -0.10789
[32m[0906 15-39-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03358, current rewards: -261.46073, mean: -0.13008
[32m[0906 15-39-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03361, current rewards: -311.46073, mean: -0.15119
[32m[0906 15-39-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03363, current rewards: -323.59055, mean: -0.15336
[32m[0906 15-39-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03365, current rewards: -318.04643, mean: -0.14724
[32m[0906 15-39-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03367, current rewards: -312.50391, mean: -0.14140
[32m[0906 15-39-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03368, current rewards: -306.95618, mean: -0.13582
[32m[0906 15-39-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03370, current rewards: -301.40852, mean: -0.13048
[32m[0906 15-39-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03372, current rewards: -295.86105, mean: -0.12536
[32m[0906 15-39-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03374, current rewards: -292.34440, mean: -0.12130
[32m[0906 15-39-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03376, current rewards: -286.84224, mean: -0.11660
[32m[0906 15-39-27 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 15-39-27 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-39-27 @MBExp.py:227][0m Rewards obtained: [-282.43950013242943], Lows: [3], Highs: [505], Total time: 4444.008854
[32m[0906 15-41-14 @MBExp.py:144][0m ####################################################################
[32m[0906 15-41-14 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 15-41-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03249, current rewards: 0.02476, mean: 0.00248
[32m[0906 15-41-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03318, current rewards: 5.21522, mean: 0.08692
[32m[0906 15-41-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03341, current rewards: 10.53721, mean: 0.09579
[32m[0906 15-41-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03348, current rewards: 15.85537, mean: 0.09910
[32m[0906 15-41-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03352, current rewards: 21.17285, mean: 0.10082
[32m[0906 15-41-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03351, current rewards: 26.48974, mean: 0.10188
[32m[0906 15-41-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03354, current rewards: 31.80429, mean: 0.10259
[32m[0906 15-41-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03358, current rewards: 37.12174, mean: 0.10312
[32m[0906 15-41-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03359, current rewards: 42.43927, mean: 0.10351
[32m[0906 15-41-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03359, current rewards: 48.01681, mean: 0.10438
[32m[0906 15-41-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03361, current rewards: 53.37851, mean: 0.10466
[32m[0906 15-41-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03354, current rewards: 58.73935, mean: 0.10489
[32m[0906 15-41-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03347, current rewards: 64.09964, mean: 0.10508
[32m[0906 15-41-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03340, current rewards: 67.32001, mean: 0.10200
[32m[0906 15-41-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03335, current rewards: 72.79864, mean: 0.10253
[32m[0906 15-41-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03331, current rewards: 78.27428, mean: 0.10299
[32m[0906 15-41-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03328, current rewards: 83.74839, mean: 0.10339
[32m[0906 15-41-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03327, current rewards: 88.31817, mean: 0.10270
[32m[0906 15-41-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03324, current rewards: 93.84623, mean: 0.10313
[32m[0906 15-41-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03321, current rewards: 99.37096, mean: 0.10351
[32m[0906 15-41-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03318, current rewards: 104.89187, mean: 0.10385
[32m[0906 15-41-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03315, current rewards: 110.41538, mean: 0.10417
[32m[0906 15-41-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03313, current rewards: 115.93849, mean: 0.10445
[32m[0906 15-41-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03312, current rewards: 121.46073, mean: 0.10471
[32m[0906 15-41-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03313, current rewards: 126.96831, mean: 0.10493
[32m[0906 15-41-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03314, current rewards: 132.46043, mean: 0.10513
[32m[0906 15-41-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03316, current rewards: 137.95296, mean: 0.10531
[32m[0906 15-42-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03319, current rewards: 143.46070, mean: 0.10549
[32m[0906 15-42-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03321, current rewards: 146.96272, mean: 0.10423
[32m[0906 15-42-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03323, current rewards: 152.47767, mean: 0.10444
[32m[0906 15-42-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03325, current rewards: 157.99401, mean: 0.10463
[32m[0906 15-42-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03327, current rewards: 163.50676, mean: 0.10481
[32m[0906 15-42-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03331, current rewards: 169.02375, mean: 0.10498
[32m[0906 15-42-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03334, current rewards: 174.53369, mean: 0.10514
[32m[0906 15-42-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03338, current rewards: 178.81003, mean: 0.10457
[32m[0906 15-42-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03341, current rewards: 184.30197, mean: 0.10472
[32m[0906 15-42-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03344, current rewards: 189.81575, mean: 0.10487
[32m[0906 15-42-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03346, current rewards: 195.32260, mean: 0.10501
[32m[0906 15-42-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03349, current rewards: 200.83328, mean: 0.10515
[32m[0906 15-42-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03352, current rewards: 206.34212, mean: 0.10528
[32m[0906 15-42-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03354, current rewards: 211.85390, mean: 0.10540
[32m[0906 15-42-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03357, current rewards: 217.36352, mean: 0.10552
[32m[0906 15-42-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03359, current rewards: 223.08697, mean: 0.10573
[32m[0906 15-42-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03361, current rewards: 228.63153, mean: 0.10585
[32m[0906 15-42-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03363, current rewards: 234.12014, mean: 0.10594
[32m[0906 15-42-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03365, current rewards: 239.61348, mean: 0.10602
[32m[0906 15-42-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03367, current rewards: 245.10792, mean: 0.10611
[32m[0906 15-42-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03369, current rewards: 250.60260, mean: 0.10619
[32m[0906 15-42-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03371, current rewards: 256.08924, mean: 0.10626
[32m[0906 15-42-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03373, current rewards: 261.58437, mean: 0.10634
[32m[0906 15-42-39 @Agent.py:117][0m Average action selection time: 0.0337
[32m[0906 15-42-39 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-42-39 @MBExp.py:227][0m Rewards obtained: [265.30915511267085], Lows: [1], Highs: [6], Total time: 4529.014966
[32m[0906 15-44-28 @MBExp.py:144][0m ####################################################################
[32m[0906 15-44-28 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 15-44-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03273, current rewards: -0.97591, mean: -0.09759
[32m[0906 15-44-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03332, current rewards: 4.60672, mean: 0.07678
[32m[0906 15-44-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03344, current rewards: 10.14408, mean: 0.09222
[32m[0906 15-44-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03357, current rewards: 15.68282, mean: 0.09802
[32m[0906 15-44-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03362, current rewards: 21.21898, mean: 0.10104
[32m[0906 15-44-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03361, current rewards: 26.75594, mean: 0.10291
[32m[0906 15-44-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03362, current rewards: 32.30175, mean: 0.10420
[32m[0906 15-44-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03363, current rewards: 37.84246, mean: 0.10512
[32m[0906 15-44-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03362, current rewards: 43.35945, mean: 0.10575
[32m[0906 15-44-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03363, current rewards: 48.67076, mean: 0.10581
[32m[0906 15-44-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03361, current rewards: 54.20890, mean: 0.10629
[32m[0906 15-44-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03358, current rewards: 59.75405, mean: 0.10670
[32m[0906 15-44-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03352, current rewards: 65.30122, mean: 0.10705
[32m[0906 15-44-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03344, current rewards: 70.85233, mean: 0.10735
[32m[0906 15-44-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03339, current rewards: 76.39904, mean: 0.10760
[32m[0906 15-44-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03335, current rewards: 81.94553, mean: 0.10782
[32m[0906 15-44-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03332, current rewards: 87.49580, mean: 0.10802
[32m[0906 15-44-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03328, current rewards: 93.04424, mean: 0.10819
[32m[0906 15-44-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03325, current rewards: 98.78594, mean: 0.10856
[32m[0906 15-45-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03322, current rewards: 104.33511, mean: 0.10868
[32m[0906 15-45-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03319, current rewards: 109.87827, mean: 0.10879
[32m[0906 15-45-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03316, current rewards: 115.42873, mean: 0.10890
[32m[0906 15-45-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03313, current rewards: 120.99848, mean: 0.10901
[32m[0906 15-45-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03311, current rewards: 126.55094, mean: 0.10910
[32m[0906 15-45-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03310, current rewards: 132.10363, mean: 0.10918
[32m[0906 15-45-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03312, current rewards: 137.66016, mean: 0.10925
[32m[0906 15-45-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03315, current rewards: 143.12706, mean: 0.10926
[32m[0906 15-45-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03317, current rewards: 148.67903, mean: 0.10932
[32m[0906 15-45-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03318, current rewards: 154.23561, mean: 0.10939
[32m[0906 15-45-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03320, current rewards: 159.79379, mean: 0.10945
[32m[0906 15-45-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03321, current rewards: 165.34792, mean: 0.10950
[32m[0906 15-45-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03322, current rewards: 170.89919, mean: 0.10955
[32m[0906 15-45-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03326, current rewards: 176.44933, mean: 0.10960
[32m[0906 15-45-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03329, current rewards: 182.00430, mean: 0.10964
[32m[0906 15-45-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03332, current rewards: 187.51316, mean: 0.10966
[32m[0906 15-45-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03335, current rewards: 193.06499, mean: 0.10970
[32m[0906 15-45-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03338, current rewards: 196.41437, mean: 0.10852
[32m[0906 15-45-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03342, current rewards: 201.96789, mean: 0.10858
[32m[0906 15-45-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03345, current rewards: 207.51549, mean: 0.10865
[32m[0906 15-45-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03347, current rewards: 213.07288, mean: 0.10871
[32m[0906 15-45-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03350, current rewards: 218.62200, mean: 0.10877
[32m[0906 15-45-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03352, current rewards: 224.17561, mean: 0.10882
[32m[0906 15-45-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03355, current rewards: 229.80106, mean: 0.10891
[32m[0906 15-45-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03357, current rewards: 235.35349, mean: 0.10896
[32m[0906 15-45-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03359, current rewards: 240.90981, mean: 0.10901
[32m[0906 15-45-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03361, current rewards: 246.46847, mean: 0.10906
[32m[0906 15-45-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03363, current rewards: 252.02416, mean: 0.10910
[32m[0906 15-45-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03365, current rewards: 257.58148, mean: 0.10914
[32m[0906 15-45-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03366, current rewards: 263.13811, mean: 0.10919
[32m[0906 15-45-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03368, current rewards: 268.69281, mean: 0.10922
[32m[0906 15-45-53 @Agent.py:117][0m Average action selection time: 0.0337
[32m[0906 15-45-53 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-45-53 @MBExp.py:227][0m Rewards obtained: [273.13723689329146], Lows: [1], Highs: [2], Total time: 4613.906628
[32m[0906 15-47-44 @MBExp.py:144][0m ####################################################################
[32m[0906 15-47-44 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 15-47-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03329, current rewards: 0.05092, mean: 0.00509
[32m[0906 15-47-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03343, current rewards: 6.19801, mean: 0.10330
[32m[0906 15-47-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03342, current rewards: 12.51344, mean: 0.11376
[32m[0906 15-47-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03342, current rewards: 18.82886, mean: 0.11768
[32m[0906 15-47-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03342, current rewards: 25.14428, mean: 0.11973
[32m[0906 15-47-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03342, current rewards: 31.45971, mean: 0.12100
[32m[0906 15-47-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03339, current rewards: 25.38574, mean: 0.08189
[32m[0906 15-47-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03343, current rewards: -24.61426, mean: -0.06837
[32m[0906 15-47-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03344, current rewards: -74.61426, mean: -0.18199
[32m[0906 15-47-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03345, current rewards: -124.61426, mean: -0.27090
[32m[0906 15-48-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03346, current rewards: -174.61426, mean: -0.34238
[32m[0906 15-48-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03341, current rewards: -224.61426, mean: -0.40110
[32m[0906 15-48-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03335, current rewards: -274.61426, mean: -0.45019
[32m[0906 15-48-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03330, current rewards: -324.61426, mean: -0.49184
[32m[0906 15-48-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03327, current rewards: -374.61426, mean: -0.52763
[32m[0906 15-48-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03322, current rewards: -424.61426, mean: -0.55870
[32m[0906 15-48-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03318, current rewards: -474.61426, mean: -0.58594
[32m[0906 15-48-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03314, current rewards: -524.61426, mean: -0.61002
[32m[0906 15-48-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03312, current rewards: -574.61426, mean: -0.63144
[32m[0906 15-48-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03308, current rewards: -624.61426, mean: -0.65064
[32m[0906 15-48-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03305, current rewards: -674.61426, mean: -0.66793
[32m[0906 15-48-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03304, current rewards: -724.61426, mean: -0.68360
[32m[0906 15-48-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03303, current rewards: -774.61426, mean: -0.69785
[32m[0906 15-48-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03301, current rewards: -824.61426, mean: -0.71087
[32m[0906 15-48-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03298, current rewards: -874.61426, mean: -0.72282
[32m[0906 15-48-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03299, current rewards: -924.61426, mean: -0.73382
[32m[0906 15-48-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03303, current rewards: -974.61426, mean: -0.74398
[32m[0906 15-48-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03304, current rewards: -1024.61426, mean: -0.75339
[32m[0906 15-48-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03307, current rewards: -1074.61426, mean: -0.76214
[32m[0906 15-48-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03309, current rewards: -1124.61426, mean: -0.77028
[32m[0906 15-48-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03310, current rewards: -1174.61426, mean: -0.77789
[32m[0906 15-48-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03311, current rewards: -1224.61426, mean: -0.78501
[32m[0906 15-48-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03312, current rewards: -1274.61426, mean: -0.79169
[32m[0906 15-48-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03316, current rewards: -1324.61426, mean: -0.79796
[32m[0906 15-48-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03320, current rewards: -1374.61426, mean: -0.80387
[32m[0906 15-48-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03324, current rewards: -1424.61426, mean: -0.80944
[32m[0906 15-48-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03327, current rewards: -1474.61426, mean: -0.81470
[32m[0906 15-48-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03331, current rewards: -1524.61426, mean: -0.81969
[32m[0906 15-48-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03334, current rewards: -1574.61426, mean: -0.82441
[32m[0906 15-48-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03337, current rewards: -1624.61426, mean: -0.82888
[32m[0906 15-48-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03340, current rewards: -1674.61426, mean: -0.83314
[32m[0906 15-48-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03342, current rewards: -1724.61426, mean: -0.83719
[32m[0906 15-48-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03345, current rewards: -1774.61426, mean: -0.84105
[32m[0906 15-48-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03347, current rewards: -1824.61426, mean: -0.84473
[32m[0906 15-48-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03350, current rewards: -1874.61426, mean: -0.84824
[32m[0906 15-49-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03352, current rewards: -1924.61426, mean: -0.85160
[32m[0906 15-49-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03354, current rewards: -1974.61426, mean: -0.85481
[32m[0906 15-49-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03356, current rewards: -2024.61426, mean: -0.85789
[32m[0906 15-49-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03358, current rewards: -2074.61426, mean: -0.86084
[32m[0906 15-49-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03359, current rewards: -2124.61426, mean: -0.86366
[32m[0906 15-49-08 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 15-49-08 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-49-08 @MBExp.py:227][0m Rewards obtained: [-2164.614259262263], Lows: [0], Highs: [2202], Total time: 4698.598792
[32m[0906 15-51-01 @MBExp.py:144][0m ####################################################################
[32m[0906 15-51-01 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 15-51-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03308, current rewards: 1.11037, mean: 0.11104
[32m[0906 15-51-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03344, current rewards: 6.67218, mean: 0.11120
[32m[0906 15-51-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03356, current rewards: 12.23483, mean: 0.11123
[32m[0906 15-51-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03362, current rewards: 17.79558, mean: 0.11122
[32m[0906 15-51-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03364, current rewards: 23.35420, mean: 0.11121
[32m[0906 15-51-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03363, current rewards: 28.91520, mean: 0.11121
[32m[0906 15-51-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03360, current rewards: 34.47631, mean: 0.11121
[32m[0906 15-51-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03358, current rewards: 40.03639, mean: 0.11121
[32m[0906 15-51-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03360, current rewards: 43.10376, mean: 0.10513
[32m[0906 15-51-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03358, current rewards: 48.17821, mean: 0.10474
[32m[0906 15-51-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03357, current rewards: 53.26459, mean: 0.10444
[32m[0906 15-51-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03349, current rewards: 58.35346, mean: 0.10420
[32m[0906 15-51-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03344, current rewards: 63.44246, mean: 0.10400
[32m[0906 15-51-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03337, current rewards: 68.52871, mean: 0.10383
[32m[0906 15-51-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03333, current rewards: 73.61622, mean: 0.10368
[32m[0906 15-51-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03329, current rewards: 77.05337, mean: 0.10139
[32m[0906 15-51-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03326, current rewards: 82.56499, mean: 0.10193
[32m[0906 15-51-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03322, current rewards: 88.27631, mean: 0.10265
[32m[0906 15-51-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03319, current rewards: 92.73112, mean: 0.10190
[32m[0906 15-51-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03317, current rewards: 97.74851, mean: 0.10182
[32m[0906 15-51-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03314, current rewards: 102.76938, mean: 0.10175
[32m[0906 15-51-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03313, current rewards: 107.79197, mean: 0.10169
[32m[0906 15-51-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03310, current rewards: 112.81470, mean: 0.10163
[32m[0906 15-51-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03308, current rewards: 117.83322, mean: 0.10158
[32m[0906 15-51-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03307, current rewards: 122.85331, mean: 0.10153
[32m[0906 15-51-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03306, current rewards: 128.27764, mean: 0.10181
[32m[0906 15-51-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03308, current rewards: 133.44928, mean: 0.10187
[32m[0906 15-51-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03309, current rewards: 138.62268, mean: 0.10193
[32m[0906 15-51-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03310, current rewards: 143.79765, mean: 0.10198
[32m[0906 15-51-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03312, current rewards: 146.91182, mean: 0.10062
[32m[0906 15-51-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03314, current rewards: 152.35478, mean: 0.10090
[32m[0906 15-51-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03315, current rewards: 157.78998, mean: 0.10115
[32m[0906 15-51-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03316, current rewards: 163.23302, mean: 0.10139
[32m[0906 15-51-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03319, current rewards: 168.67290, mean: 0.10161
[32m[0906 15-51-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03323, current rewards: 174.11204, mean: 0.10182
[32m[0906 15-52-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03327, current rewards: 179.55289, mean: 0.10202
[32m[0906 15-52-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03330, current rewards: 184.99464, mean: 0.10221
[32m[0906 15-52-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03333, current rewards: 190.43478, mean: 0.10238
[32m[0906 15-52-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03335, current rewards: 195.87427, mean: 0.10255
[32m[0906 15-52-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03338, current rewards: 201.31288, mean: 0.10271
[32m[0906 15-52-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03341, current rewards: 206.75166, mean: 0.10286
[32m[0906 15-52-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03343, current rewards: 212.10088, mean: 0.10296
[32m[0906 15-52-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03346, current rewards: 217.45274, mean: 0.10306
[32m[0906 15-52-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03348, current rewards: 222.80270, mean: 0.10315
[32m[0906 15-52-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03350, current rewards: 228.15301, mean: 0.10324
[32m[0906 15-52-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03353, current rewards: 233.50231, mean: 0.10332
[32m[0906 15-52-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03355, current rewards: 238.85352, mean: 0.10340
[32m[0906 15-52-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03357, current rewards: 244.19926, mean: 0.10347
[32m[0906 15-52-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03359, current rewards: 249.54537, mean: 0.10355
[32m[0906 15-52-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03360, current rewards: 254.95664, mean: 0.10364
[32m[0906 15-52-26 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 15-52-26 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-52-26 @MBExp.py:227][0m Rewards obtained: [259.42261647471196], Lows: [2], Highs: [3], Total time: 4783.307435
[32m[0906 15-54-21 @MBExp.py:144][0m ####################################################################
[32m[0906 15-54-21 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 15-54-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03288, current rewards: 0.00842, mean: 0.00084
[32m[0906 15-54-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03345, current rewards: 5.59693, mean: 0.09328
[32m[0906 15-54-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03363, current rewards: 11.18657, mean: 0.10170
[32m[0906 15-54-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03367, current rewards: 16.77901, mean: 0.10487
[32m[0906 15-54-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03363, current rewards: 22.36880, mean: 0.10652
[32m[0906 15-54-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03360, current rewards: 27.95217, mean: 0.10751
[32m[0906 15-54-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03359, current rewards: 29.37956, mean: 0.09477
[32m[0906 15-54-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03359, current rewards: 35.13044, mean: 0.09758
[32m[0906 15-54-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03358, current rewards: 40.63524, mean: 0.09911
[32m[0906 15-54-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03357, current rewards: 46.34906, mean: 0.10076
[32m[0906 15-54-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03357, current rewards: 52.06359, mean: 0.10209
[32m[0906 15-54-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03350, current rewards: 57.77883, mean: 0.10318
[32m[0906 15-54-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03343, current rewards: 63.49346, mean: 0.10409
[32m[0906 15-54-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03336, current rewards: 69.20661, mean: 0.10486
[32m[0906 15-54-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03331, current rewards: 74.92647, mean: 0.10553
[32m[0906 15-54-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03328, current rewards: 80.64121, mean: 0.10611
[32m[0906 15-54-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03324, current rewards: 86.38717, mean: 0.10665
[32m[0906 15-54-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03321, current rewards: 91.01228, mean: 0.10583
[32m[0906 15-54-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03318, current rewards: 97.06260, mean: 0.10666
[32m[0906 15-54-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03314, current rewards: 102.48162, mean: 0.10675
[32m[0906 15-54-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03312, current rewards: 107.90049, mean: 0.10683
[32m[0906 15-54-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03310, current rewards: 113.31852, mean: 0.10690
[32m[0906 15-54-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03308, current rewards: 118.73641, mean: 0.10697
[32m[0906 15-54-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03306, current rewards: 124.14908, mean: 0.10703
[32m[0906 15-55-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03304, current rewards: 129.56716, mean: 0.10708
[32m[0906 15-55-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03302, current rewards: 134.98940, mean: 0.10713
[32m[0906 15-55-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03306, current rewards: 140.40438, mean: 0.10718
[32m[0906 15-55-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03308, current rewards: 145.81691, mean: 0.10722
[32m[0906 15-55-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03310, current rewards: 147.13345, mean: 0.10435
[32m[0906 15-55-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03312, current rewards: 152.62237, mean: 0.10454
[32m[0906 15-55-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03314, current rewards: 158.10949, mean: 0.10471
[32m[0906 15-55-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03316, current rewards: 163.59842, mean: 0.10487
[32m[0906 15-55-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03317, current rewards: 169.18411, mean: 0.10508
[32m[0906 15-55-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03319, current rewards: 175.73889, mean: 0.10587
[32m[0906 15-55-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03323, current rewards: 131.39971, mean: 0.07684
[32m[0906 15-55-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03326, current rewards: 81.39971, mean: 0.04625
[32m[0906 15-55-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03331, current rewards: 31.39971, mean: 0.01735
[32m[0906 15-55-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03334, current rewards: -18.60029, mean: -0.01000
[32m[0906 15-55-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03336, current rewards: -68.60029, mean: -0.03592
[32m[0906 15-55-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03339, current rewards: -118.60029, mean: -0.06051
[32m[0906 15-55-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03342, current rewards: -168.60029, mean: -0.08388
[32m[0906 15-55-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03344, current rewards: -218.60029, mean: -0.10612
[32m[0906 15-55-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03347, current rewards: -268.60029, mean: -0.12730
[32m[0906 15-55-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03349, current rewards: -318.60029, mean: -0.14750
[32m[0906 15-55-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03351, current rewards: -368.60029, mean: -0.16679
[32m[0906 15-55-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03353, current rewards: -418.60029, mean: -0.18522
[32m[0906 15-55-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03355, current rewards: -468.60029, mean: -0.20286
[32m[0906 15-55-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03357, current rewards: -518.60029, mean: -0.21975
[32m[0906 15-55-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03359, current rewards: -568.60029, mean: -0.23593
[32m[0906 15-55-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03360, current rewards: -618.60029, mean: -0.25146
[32m[0906 15-55-45 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 15-55-45 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-55-45 @MBExp.py:227][0m Rewards obtained: [-658.6002896475865], Lows: [4], Highs: [837], Total time: 4868.013899
[32m[0906 15-57-42 @MBExp.py:144][0m ####################################################################
[32m[0906 15-57-42 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 15-57-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03268, current rewards: -0.03348, mean: -0.00335
[32m[0906 15-57-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03339, current rewards: 5.58491, mean: 0.09308
[32m[0906 15-57-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03341, current rewards: 11.20776, mean: 0.10189
[32m[0906 15-57-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03350, current rewards: 16.83176, mean: 0.10520
[32m[0906 15-57-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03353, current rewards: 22.45043, mean: 0.10691
[32m[0906 15-57-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03356, current rewards: 28.07320, mean: 0.10797
[32m[0906 15-57-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03355, current rewards: 33.70746, mean: 0.10873
[32m[0906 15-57-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03354, current rewards: 39.26810, mean: 0.10908
[32m[0906 15-57-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03356, current rewards: 44.89207, mean: 0.10949
[32m[0906 15-57-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03357, current rewards: 50.52989, mean: 0.10985
[32m[0906 15-57-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03354, current rewards: 56.16574, mean: 0.11013
[32m[0906 15-58-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03349, current rewards: 59.60297, mean: 0.10643
[32m[0906 15-58-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03339, current rewards: 65.16359, mean: 0.10683
[32m[0906 15-58-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03334, current rewards: 70.72609, mean: 0.10716
[32m[0906 15-58-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03330, current rewards: 76.28361, mean: 0.10744
[32m[0906 15-58-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03326, current rewards: 81.84172, mean: 0.10769
[32m[0906 15-58-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03322, current rewards: 87.57150, mean: 0.10811
[32m[0906 15-58-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03320, current rewards: 93.09102, mean: 0.10825
[32m[0906 15-58-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03318, current rewards: 98.61058, mean: 0.10836
[32m[0906 15-58-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03316, current rewards: 104.13256, mean: 0.10847
[32m[0906 15-58-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03312, current rewards: 109.65394, mean: 0.10857
[32m[0906 15-58-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03310, current rewards: 115.17536, mean: 0.10866
[32m[0906 15-58-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03309, current rewards: 119.77664, mean: 0.10791
[32m[0906 15-58-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03308, current rewards: 125.30905, mean: 0.10803
[32m[0906 15-58-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03307, current rewards: 130.86655, mean: 0.10815
[32m[0906 15-58-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03304, current rewards: 136.39525, mean: 0.10825
[32m[0906 15-58-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03304, current rewards: 141.92112, mean: 0.10834
[32m[0906 15-58-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03307, current rewards: 147.44818, mean: 0.10842
[32m[0906 15-58-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03309, current rewards: 152.97213, mean: 0.10849
[32m[0906 15-58-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03311, current rewards: 158.49466, mean: 0.10856
[32m[0906 15-58-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03314, current rewards: 161.95108, mean: 0.10725
[32m[0906 15-58-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03315, current rewards: 167.55609, mean: 0.10741
[32m[0906 15-58-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03317, current rewards: 173.04203, mean: 0.10748
[32m[0906 15-58-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03318, current rewards: 178.65204, mean: 0.10762
[32m[0906 15-58-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03321, current rewards: 184.26620, mean: 0.10776
[32m[0906 15-58-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03325, current rewards: 189.88106, mean: 0.10789
[32m[0906 15-58-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03329, current rewards: 195.49871, mean: 0.10801
[32m[0906 15-58-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03332, current rewards: 201.11255, mean: 0.10813
[32m[0906 15-58-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03334, current rewards: 206.72987, mean: 0.10824
[32m[0906 15-58-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03337, current rewards: 212.34249, mean: 0.10834
[32m[0906 15-58-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03340, current rewards: 217.94120, mean: 0.10843
[32m[0906 15-58-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03343, current rewards: 221.44894, mean: 0.10750
[32m[0906 15-58-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03346, current rewards: 226.99611, mean: 0.10758
[32m[0906 15-58-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03349, current rewards: 232.54289, mean: 0.10766
[32m[0906 15-58-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03352, current rewards: 238.08987, mean: 0.10773
[32m[0906 15-58-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03354, current rewards: 243.64084, mean: 0.10781
[32m[0906 15-59-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03357, current rewards: 249.18632, mean: 0.10787
[32m[0906 15-59-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03359, current rewards: 254.73139, mean: 0.10794
[32m[0906 15-59-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03361, current rewards: 260.35159, mean: 0.10803
[32m[0906 15-59-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03363, current rewards: 264.09886, mean: 0.10736
[32m[0906 15-59-07 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 15-59-07 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-59-07 @MBExp.py:227][0m Rewards obtained: [271.1297847587086], Lows: [5], Highs: [2], Total time: 4952.788613999999
[32m[0906 16-01-06 @MBExp.py:144][0m ####################################################################
[32m[0906 16-01-06 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 16-01-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03262, current rewards: 0.01758, mean: 0.00176
[32m[0906 16-01-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03348, current rewards: 5.63581, mean: 0.09393
[32m[0906 16-01-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03349, current rewards: 11.20507, mean: 0.10186
[32m[0906 16-01-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03361, current rewards: 16.80254, mean: 0.10502
[32m[0906 16-01-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03360, current rewards: 22.39579, mean: 0.10665
[32m[0906 16-01-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03363, current rewards: 27.97903, mean: 0.10761
[32m[0906 16-01-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03363, current rewards: 33.55775, mean: 0.10825
[32m[0906 16-01-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03360, current rewards: 39.13706, mean: 0.10871
[32m[0906 16-01-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03361, current rewards: 44.54239, mean: 0.10864
[32m[0906 16-01-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03363, current rewards: 49.94847, mean: 0.10858
[32m[0906 16-01-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03363, current rewards: 55.35079, mean: 0.10853
[32m[0906 16-01-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03354, current rewards: 60.71959, mean: 0.10843
[32m[0906 16-01-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03347, current rewards: 66.08751, mean: 0.10834
[32m[0906 16-01-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03340, current rewards: 71.45432, mean: 0.10826
[32m[0906 16-01-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03336, current rewards: 76.82068, mean: 0.10820
[32m[0906 16-01-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03331, current rewards: 82.16201, mean: 0.10811
[32m[0906 16-01-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03327, current rewards: 87.76257, mean: 0.10835
[32m[0906 16-01-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03324, current rewards: 93.38311, mean: 0.10859
[32m[0906 16-01-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03320, current rewards: 99.00649, mean: 0.10880
[32m[0906 16-01-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03316, current rewards: 104.64070, mean: 0.10900
[32m[0906 16-01-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03312, current rewards: 110.27139, mean: 0.10918
[32m[0906 16-01-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03310, current rewards: 115.89168, mean: 0.10933
[32m[0906 16-01-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03309, current rewards: 121.65669, mean: 0.10960
[32m[0906 16-01-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03308, current rewards: 127.06279, mean: 0.10954
[32m[0906 16-01-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03306, current rewards: 132.43312, mean: 0.10945
[32m[0906 16-01-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03304, current rewards: 137.78643, mean: 0.10935
[32m[0906 16-01-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03302, current rewards: 143.13964, mean: 0.10927
[32m[0906 16-01-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03304, current rewards: 148.49143, mean: 0.10918
[32m[0906 16-01-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03306, current rewards: 153.84028, mean: 0.10911
[32m[0906 16-01-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03309, current rewards: 159.19351, mean: 0.10904
[32m[0906 16-01-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03311, current rewards: 164.54441, mean: 0.10897
[32m[0906 16-01-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03313, current rewards: 169.89503, mean: 0.10891
[32m[0906 16-02-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03314, current rewards: 173.18975, mean: 0.10757
[32m[0906 16-02-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03316, current rewards: 178.69366, mean: 0.10765
[32m[0906 16-02-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03317, current rewards: 184.19650, mean: 0.10772
[32m[0906 16-02-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03321, current rewards: 189.69814, mean: 0.10778
[32m[0906 16-02-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03324, current rewards: 195.19683, mean: 0.10784
[32m[0906 16-02-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03327, current rewards: 200.69456, mean: 0.10790
[32m[0906 16-02-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03331, current rewards: 206.19448, mean: 0.10796
[32m[0906 16-02-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03334, current rewards: 211.69733, mean: 0.10801
[32m[0906 16-02-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03337, current rewards: 217.51979, mean: 0.10822
[32m[0906 16-02-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03339, current rewards: 223.08215, mean: 0.10829
[32m[0906 16-02-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03342, current rewards: 228.64332, mean: 0.10836
[32m[0906 16-02-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03345, current rewards: 233.01628, mean: 0.10788
[32m[0906 16-02-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03347, current rewards: 238.41174, mean: 0.10788
[32m[0906 16-02-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03350, current rewards: 243.80458, mean: 0.10788
[32m[0906 16-02-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03352, current rewards: 249.19745, mean: 0.10788
[32m[0906 16-02-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03354, current rewards: 254.58998, mean: 0.10788
[32m[0906 16-02-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03356, current rewards: 259.90599, mean: 0.10784
[32m[0906 16-02-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03358, current rewards: 265.13611, mean: 0.10778
[32m[0906 16-02-31 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 16-02-31 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-02-31 @MBExp.py:227][0m Rewards obtained: [269.41852922621274], Lows: [1], Highs: [2], Total time: 5037.4694899999995
[32m[0906 16-04-32 @MBExp.py:144][0m ####################################################################
[32m[0906 16-04-32 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 16-04-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03343, current rewards: -0.02318, mean: -0.00232
[32m[0906 16-04-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03344, current rewards: 5.54321, mean: 0.09239
[32m[0906 16-04-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03356, current rewards: 11.10689, mean: 0.10097
[32m[0906 16-04-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03362, current rewards: 16.67611, mean: 0.10423
[32m[0906 16-04-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03359, current rewards: 22.24084, mean: 0.10591
[32m[0906 16-04-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03357, current rewards: 27.80430, mean: 0.10694
[32m[0906 16-04-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03354, current rewards: 33.36622, mean: 0.10763
[32m[0906 16-04-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03350, current rewards: 38.85594, mean: 0.10793
[32m[0906 16-04-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03353, current rewards: 44.42094, mean: 0.10834
[32m[0906 16-04-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03355, current rewards: 49.98674, mean: 0.10867
[32m[0906 16-04-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03354, current rewards: 55.55425, mean: 0.10893
[32m[0906 16-04-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03345, current rewards: 61.11439, mean: 0.10913
[32m[0906 16-04-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03338, current rewards: 66.67457, mean: 0.10930
[32m[0906 16-04-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03332, current rewards: 72.23026, mean: 0.10944
[32m[0906 16-04-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03328, current rewards: 77.79055, mean: 0.10956
[32m[0906 16-04-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03325, current rewards: 81.18857, mean: 0.10683
[32m[0906 16-04-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03321, current rewards: 86.73707, mean: 0.10708
[32m[0906 16-05-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03317, current rewards: 92.29476, mean: 0.10732
[32m[0906 16-05-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03315, current rewards: 97.84221, mean: 0.10752
[32m[0906 16-05-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03313, current rewards: 103.39887, mean: 0.10771
[32m[0906 16-05-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03309, current rewards: 108.94808, mean: 0.10787
[32m[0906 16-05-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03309, current rewards: 114.49553, mean: 0.10801
[32m[0906 16-05-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03307, current rewards: 120.04268, mean: 0.10815
[32m[0906 16-05-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03305, current rewards: 125.76514, mean: 0.10842
[32m[0906 16-05-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03304, current rewards: 131.28239, mean: 0.10850
[32m[0906 16-05-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03302, current rewards: 135.86794, mean: 0.10783
[32m[0906 16-05-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03300, current rewards: 141.45176, mean: 0.10798
[32m[0906 16-05-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03301, current rewards: 147.04712, mean: 0.10812
[32m[0906 16-05-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03304, current rewards: 152.64077, mean: 0.10826
[32m[0906 16-05-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03306, current rewards: 158.23738, mean: 0.10838
[32m[0906 16-05-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03308, current rewards: 163.82552, mean: 0.10849
[32m[0906 16-05-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03310, current rewards: 167.33056, mean: 0.10726
[32m[0906 16-05-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03312, current rewards: 172.90549, mean: 0.10739
[32m[0906 16-05-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03314, current rewards: 178.48170, mean: 0.10752
[32m[0906 16-05-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03315, current rewards: 184.05785, mean: 0.10764
[32m[0906 16-05-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03319, current rewards: 189.62987, mean: 0.10774
[32m[0906 16-05-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03323, current rewards: 195.20368, mean: 0.10785
[32m[0906 16-05-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03327, current rewards: 200.78114, mean: 0.10795
[32m[0906 16-05-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03330, current rewards: 206.35939, mean: 0.10804
[32m[0906 16-05-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03334, current rewards: 208.14220, mean: 0.10619
[32m[0906 16-05-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03337, current rewards: 213.77918, mean: 0.10636
[32m[0906 16-05-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03340, current rewards: 219.72987, mean: 0.10666
[32m[0906 16-05-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03343, current rewards: 225.68089, mean: 0.10696
[32m[0906 16-05-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03345, current rewards: 231.63080, mean: 0.10724
[32m[0906 16-05-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03348, current rewards: 237.58021, mean: 0.10750
[32m[0906 16-05-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03350, current rewards: 243.53350, mean: 0.10776
[32m[0906 16-05-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03352, current rewards: 248.04738, mean: 0.10738
[32m[0906 16-05-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03354, current rewards: 253.59916, mean: 0.10746
[32m[0906 16-05-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03357, current rewards: 259.14491, mean: 0.10753
[32m[0906 16-05-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03358, current rewards: 264.69709, mean: 0.10760
[32m[0906 16-05-57 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 16-05-57 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-05-57 @MBExp.py:227][0m Rewards obtained: [269.1376536484808], Lows: [4], Highs: [3], Total time: 5122.135316999999
[32m[0906 16-08-00 @MBExp.py:144][0m ####################################################################
[32m[0906 16-08-00 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 16-08-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03256, current rewards: -0.97228, mean: -0.09723
[32m[0906 16-08-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03344, current rewards: 4.62199, mean: 0.07703
[32m[0906 16-08-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03351, current rewards: 10.21062, mean: 0.09282
[32m[0906 16-08-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03352, current rewards: 15.79960, mean: 0.09875
[32m[0906 16-08-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03352, current rewards: 21.39217, mean: 0.10187
[32m[0906 16-08-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03356, current rewards: 26.97876, mean: 0.10376
[32m[0906 16-08-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03357, current rewards: 32.55055, mean: 0.10500
[32m[0906 16-08-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03356, current rewards: 38.13624, mean: 0.10593
[32m[0906 16-08-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03356, current rewards: 43.72208, mean: 0.10664
[32m[0906 16-08-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03356, current rewards: 46.22829, mean: 0.10050
[32m[0906 16-08-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03352, current rewards: 51.72878, mean: 0.10143
[32m[0906 16-08-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03347, current rewards: 57.23801, mean: 0.10221
[32m[0906 16-08-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03342, current rewards: 62.73688, mean: 0.10285
[32m[0906 16-08-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03337, current rewards: 68.24103, mean: 0.10340
[32m[0906 16-08-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03332, current rewards: 73.79624, mean: 0.10394
[32m[0906 16-08-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03327, current rewards: 79.43553, mean: 0.10452
[32m[0906 16-08-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03324, current rewards: 84.97273, mean: 0.10490
[32m[0906 16-08-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03320, current rewards: 88.54328, mean: 0.10296
[32m[0906 16-08-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03317, current rewards: 94.09928, mean: 0.10341
[32m[0906 16-08-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03315, current rewards: 99.65348, mean: 0.10381
[32m[0906 16-08-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03312, current rewards: 105.21177, mean: 0.10417
[32m[0906 16-08-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03311, current rewards: 110.77228, mean: 0.10450
[32m[0906 16-08-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03308, current rewards: 112.44331, mean: 0.10130
[32m[0906 16-08-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03306, current rewards: 117.82578, mean: 0.10157
[32m[0906 16-08-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03303, current rewards: 123.89797, mean: 0.10240
[32m[0906 16-08-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03301, current rewards: 129.96190, mean: 0.10314
[32m[0906 16-08-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03299, current rewards: 136.01776, mean: 0.10383
[32m[0906 16-08-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03298, current rewards: 142.08421, mean: 0.10447
[32m[0906 16-08-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03300, current rewards: 148.13818, mean: 0.10506
[32m[0906 16-08-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03302, current rewards: 154.19290, mean: 0.10561
[32m[0906 16-08-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03304, current rewards: 160.24200, mean: 0.10612
[32m[0906 16-08-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03306, current rewards: 166.30379, mean: 0.10660
[32m[0906 16-08-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03308, current rewards: 172.32867, mean: 0.10704
[32m[0906 16-08-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03310, current rewards: 178.35936, mean: 0.10745
[32m[0906 16-08-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03311, current rewards: 184.37426, mean: 0.10782
[32m[0906 16-08-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03314, current rewards: 190.39760, mean: 0.10818
[32m[0906 16-09-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03318, current rewards: 196.42001, mean: 0.10852
[32m[0906 16-09-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03321, current rewards: 201.07142, mean: 0.10810
[32m[0906 16-09-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03325, current rewards: 206.66060, mean: 0.10820
[32m[0906 16-09-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03328, current rewards: 212.32217, mean: 0.10833
[32m[0906 16-09-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03331, current rewards: 217.94571, mean: 0.10843
[32m[0906 16-09-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03334, current rewards: 223.44025, mean: 0.10847
[32m[0906 16-09-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03336, current rewards: 228.92809, mean: 0.10850
[32m[0906 16-09-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03339, current rewards: 234.42175, mean: 0.10853
[32m[0906 16-09-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03341, current rewards: 238.94533, mean: 0.10812
[32m[0906 16-09-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03344, current rewards: 244.46514, mean: 0.10817
[32m[0906 16-09-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03346, current rewards: 249.98658, mean: 0.10822
[32m[0906 16-09-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03348, current rewards: 255.51868, mean: 0.10827
[32m[0906 16-09-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03350, current rewards: 260.97341, mean: 0.10829
[32m[0906 16-09-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03352, current rewards: 266.49333, mean: 0.10833
[32m[0906 16-09-24 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 16-09-24 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-09-25 @MBExp.py:227][0m Rewards obtained: [270.9056179560926], Lows: [4], Highs: [5], Total time: 5206.641240999999
[32m[0906 16-11-30 @MBExp.py:144][0m ####################################################################
[32m[0906 16-11-30 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 16-11-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03272, current rewards: -1.11788, mean: -0.11179
[32m[0906 16-11-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03344, current rewards: 4.45690, mean: 0.07428
[32m[0906 16-11-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03344, current rewards: 10.02813, mean: 0.09116
[32m[0906 16-11-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03347, current rewards: 15.59473, mean: 0.09747
[32m[0906 16-11-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03350, current rewards: 21.16690, mean: 0.10079
[32m[0906 16-11-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03351, current rewards: 26.73401, mean: 0.10282
[32m[0906 16-11-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03352, current rewards: 32.46955, mean: 0.10474
[32m[0906 16-11-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03353, current rewards: 38.05223, mean: 0.10570
[32m[0906 16-11-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03355, current rewards: 43.63362, mean: 0.10642
[32m[0906 16-11-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03359, current rewards: 49.21472, mean: 0.10699
[32m[0906 16-11-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03351, current rewards: 54.79555, mean: 0.10744
[32m[0906 16-11-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03339, current rewards: 60.37843, mean: 0.10782
[32m[0906 16-11-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03334, current rewards: 65.96192, mean: 0.10813
[32m[0906 16-11-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03328, current rewards: 71.54418, mean: 0.10840
[32m[0906 16-11-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03322, current rewards: 77.04285, mean: 0.10851
[32m[0906 16-11-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03318, current rewards: 80.43871, mean: 0.10584
[32m[0906 16-11-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03314, current rewards: 85.68654, mean: 0.10579
[32m[0906 16-11-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03310, current rewards: 90.93215, mean: 0.10574
[32m[0906 16-12-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03307, current rewards: 96.18141, mean: 0.10569
[32m[0906 16-12-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03303, current rewards: 101.43121, mean: 0.10566
[32m[0906 16-12-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03300, current rewards: 106.68006, mean: 0.10562
[32m[0906 16-12-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03298, current rewards: 111.93138, mean: 0.10560
[32m[0906 16-12-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03297, current rewards: 117.21001, mean: 0.10559
[32m[0906 16-12-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03296, current rewards: 121.78996, mean: 0.10499
[32m[0906 16-12-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03295, current rewards: 127.39079, mean: 0.10528
[32m[0906 16-12-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03293, current rewards: 132.99632, mean: 0.10555
[32m[0906 16-12-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03293, current rewards: 138.59533, mean: 0.10580
[32m[0906 16-12-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03292, current rewards: 144.19295, mean: 0.10602
[32m[0906 16-12-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03291, current rewards: 149.79566, mean: 0.10624
[32m[0906 16-12-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03294, current rewards: 155.39522, mean: 0.10644
[32m[0906 16-12-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03296, current rewards: 160.99497, mean: 0.10662
[32m[0906 16-12-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03298, current rewards: 166.45900, mean: 0.10670
[32m[0906 16-12-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03300, current rewards: 171.99413, mean: 0.10683
[32m[0906 16-12-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03301, current rewards: 177.53343, mean: 0.10695
[32m[0906 16-12-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03303, current rewards: 183.07075, mean: 0.10706
[32m[0906 16-12-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03305, current rewards: 188.61230, mean: 0.10717
[32m[0906 16-12-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03310, current rewards: 192.10237, mean: 0.10613
[32m[0906 16-12-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03313, current rewards: 197.68797, mean: 0.10628
[32m[0906 16-12-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03316, current rewards: 203.28242, mean: 0.10643
[32m[0906 16-12-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03320, current rewards: 208.93888, mean: 0.10660
[32m[0906 16-12-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03323, current rewards: 214.53708, mean: 0.10673
[32m[0906 16-12-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03326, current rewards: 220.13281, mean: 0.10686
[32m[0906 16-12-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03329, current rewards: 225.72530, mean: 0.10698
[32m[0906 16-12-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03332, current rewards: 231.32077, mean: 0.10709
[32m[0906 16-12-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03334, current rewards: 237.08343, mean: 0.10728
[32m[0906 16-12-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03337, current rewards: 242.73917, mean: 0.10741
[32m[0906 16-12-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03340, current rewards: 248.39953, mean: 0.10753
[32m[0906 16-12-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03342, current rewards: 254.30527, mean: 0.10776
[32m[0906 16-12-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03344, current rewards: 260.00155, mean: 0.10788
[32m[0906 16-12-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03347, current rewards: 264.12900, mean: 0.10737
[32m[0906 16-12-54 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 16-12-54 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-12-54 @MBExp.py:227][0m Rewards obtained: [268.7651859353742], Lows: [3], Highs: [3], Total time: 5291.014729999999
[32m[0906 16-15-01 @MBExp.py:144][0m ####################################################################
[32m[0906 16-15-01 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 16-15-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03279, current rewards: 0.44345, mean: 0.04434
[32m[0906 16-15-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03340, current rewards: 5.90285, mean: 0.09838
[32m[0906 16-15-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03350, current rewards: 11.35532, mean: 0.10323
[32m[0906 16-15-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03349, current rewards: 16.80542, mean: 0.10503
[32m[0906 16-15-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03348, current rewards: 22.25690, mean: 0.10599
[32m[0906 16-15-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03351, current rewards: 27.79130, mean: 0.10689
[32m[0906 16-15-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03353, current rewards: 33.49781, mean: 0.10806
[32m[0906 16-15-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03355, current rewards: 39.19598, mean: 0.10888
[32m[0906 16-15-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03355, current rewards: 44.89859, mean: 0.10951
[32m[0906 16-15-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03355, current rewards: 50.60160, mean: 0.11000
[32m[0906 16-15-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03349, current rewards: 56.30326, mean: 0.11040
[32m[0906 16-15-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03342, current rewards: 62.00402, mean: 0.11072
[32m[0906 16-15-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03335, current rewards: 65.03773, mean: 0.10662
[32m[0906 16-15-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03331, current rewards: 72.86366, mean: 0.11040
[32m[0906 16-15-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03326, current rewards: 76.07797, mean: 0.10715
[32m[0906 16-15-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03321, current rewards: 78.75902, mean: 0.10363
[32m[0906 16-15-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03315, current rewards: 81.44007, mean: 0.10054
[32m[0906 16-15-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03311, current rewards: 84.12112, mean: 0.09782
[32m[0906 16-15-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03310, current rewards: 86.80218, mean: 0.09539
[32m[0906 16-15-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03307, current rewards: 89.48323, mean: 0.09321
[32m[0906 16-15-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03305, current rewards: 92.16428, mean: 0.09125
[32m[0906 16-15-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03302, current rewards: 94.84533, mean: 0.08948
[32m[0906 16-15-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03298, current rewards: 58.54240, mean: 0.05274
[32m[0906 16-15-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03296, current rewards: 8.54240, mean: 0.00736
[32m[0906 16-15-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03294, current rewards: -41.45760, mean: -0.03426
[32m[0906 16-15-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03293, current rewards: -91.45760, mean: -0.07259
[32m[0906 16-15-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03293, current rewards: -141.45760, mean: -0.10798
[32m[0906 16-15-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03293, current rewards: -191.45760, mean: -0.14078
[32m[0906 16-15-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03292, current rewards: -241.45760, mean: -0.17125
[32m[0906 16-15-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03293, current rewards: -291.45760, mean: -0.19963
[32m[0906 16-15-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03295, current rewards: -341.45760, mean: -0.22613
[32m[0906 16-15-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03297, current rewards: -391.45760, mean: -0.25093
[32m[0906 16-15-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03299, current rewards: -441.45760, mean: -0.27420
[32m[0906 16-15-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03301, current rewards: -491.45760, mean: -0.29606
[32m[0906 16-15-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03303, current rewards: -541.45760, mean: -0.31664
[32m[0906 16-16-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03305, current rewards: -591.45760, mean: -0.33606
[32m[0906 16-16-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03308, current rewards: -641.45760, mean: -0.35440
[32m[0906 16-16-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03313, current rewards: -691.45760, mean: -0.37175
[32m[0906 16-16-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03316, current rewards: -741.45760, mean: -0.38820
[32m[0906 16-16-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03320, current rewards: -791.45760, mean: -0.40380
[32m[0906 16-16-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03323, current rewards: -841.45760, mean: -0.41864
[32m[0906 16-16-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03326, current rewards: -891.45760, mean: -0.43275
[32m[0906 16-16-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03329, current rewards: -941.45760, mean: -0.44619
[32m[0906 16-16-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03332, current rewards: -991.45760, mean: -0.45901
[32m[0906 16-16-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03335, current rewards: -1041.45760, mean: -0.47125
[32m[0906 16-16-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03337, current rewards: -1091.45760, mean: -0.48295
[32m[0906 16-16-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03340, current rewards: -1141.45760, mean: -0.49414
[32m[0906 16-16-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03342, current rewards: -1191.45760, mean: -0.50485
[32m[0906 16-16-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03344, current rewards: -1241.45760, mean: -0.51513
[32m[0906 16-16-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03347, current rewards: -1291.45760, mean: -0.52498
[32m[0906 16-16-25 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 16-16-25 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-16-25 @MBExp.py:227][0m Rewards obtained: [-1331.4575970449023], Lows: [2], Highs: [1428], Total time: 5375.395521999999
[32m[0906 16-18-34 @MBExp.py:144][0m ####################################################################
[32m[0906 16-18-34 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 16-18-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03267, current rewards: -0.92216, mean: -0.09222
[32m[0906 16-18-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03343, current rewards: 5.15046, mean: 0.08584
[32m[0906 16-18-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03349, current rewards: 11.02828, mean: 0.10026
[32m[0906 16-18-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03350, current rewards: 16.90504, mean: 0.10566
[32m[0906 16-18-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03352, current rewards: 22.78658, mean: 0.10851
[32m[0906 16-18-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03356, current rewards: 28.66698, mean: 0.11026
[32m[0906 16-18-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03357, current rewards: 34.47288, mean: 0.11120
[32m[0906 16-18-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03357, current rewards: 39.20937, mean: 0.10891
[32m[0906 16-18-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03360, current rewards: 44.78073, mean: 0.10922
[32m[0906 16-18-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03358, current rewards: 50.34629, mean: 0.10945
[32m[0906 16-18-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03352, current rewards: 55.91579, mean: 0.10964
[32m[0906 16-18-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03343, current rewards: 61.48768, mean: 0.10980
[32m[0906 16-18-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03336, current rewards: 67.05197, mean: 0.10992
[32m[0906 16-18-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03332, current rewards: 72.62571, mean: 0.11004
[32m[0906 16-18-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03327, current rewards: 76.05640, mean: 0.10712
[32m[0906 16-19-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03323, current rewards: 81.62365, mean: 0.10740
[32m[0906 16-19-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03321, current rewards: 87.19643, mean: 0.10765
[32m[0906 16-19-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03318, current rewards: 92.76451, mean: 0.10787
[32m[0906 16-19-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03315, current rewards: 98.33171, mean: 0.10806
[32m[0906 16-19-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03314, current rewards: 101.31695, mean: 0.10554
[32m[0906 16-19-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03311, current rewards: 106.84337, mean: 0.10579
[32m[0906 16-19-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03309, current rewards: 112.36679, mean: 0.10601
[32m[0906 16-19-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03306, current rewards: 117.82523, mean: 0.10615
[32m[0906 16-19-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03306, current rewards: 123.33132, mean: 0.10632
[32m[0906 16-19-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03304, current rewards: 128.84212, mean: 0.10648
[32m[0906 16-19-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03303, current rewards: 130.17346, mean: 0.10331
[32m[0906 16-19-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03302, current rewards: 135.87545, mean: 0.10372
[32m[0906 16-19-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03300, current rewards: 141.57720, mean: 0.10410
[32m[0906 16-19-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03299, current rewards: 147.27587, mean: 0.10445
[32m[0906 16-19-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03297, current rewards: 152.97796, mean: 0.10478
[32m[0906 16-19-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03298, current rewards: 158.67670, mean: 0.10508
[32m[0906 16-19-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03300, current rewards: 164.52631, mean: 0.10547
[32m[0906 16-19-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03302, current rewards: 170.25357, mean: 0.10575
[32m[0906 16-19-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03304, current rewards: 175.98405, mean: 0.10601
[32m[0906 16-19-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03306, current rewards: 181.71023, mean: 0.10626
[32m[0906 16-19-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03308, current rewards: 187.44046, mean: 0.10650
[32m[0906 16-19-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03310, current rewards: 193.17469, mean: 0.10673
[32m[0906 16-19-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03313, current rewards: 198.90657, mean: 0.10694
[32m[0906 16-19-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03317, current rewards: 202.40313, mean: 0.10597
[32m[0906 16-19-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03320, current rewards: 207.91204, mean: 0.10608
[32m[0906 16-19-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03324, current rewards: 213.47617, mean: 0.10621
[32m[0906 16-19-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03327, current rewards: 219.04205, mean: 0.10633
[32m[0906 16-19-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03329, current rewards: 224.60897, mean: 0.10645
[32m[0906 16-19-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03332, current rewards: 230.16940, mean: 0.10656
[32m[0906 16-19-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03334, current rewards: 235.73269, mean: 0.10667
[32m[0906 16-19-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03337, current rewards: 241.29646, mean: 0.10677
[32m[0906 16-19-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03339, current rewards: 246.85999, mean: 0.10687
[32m[0906 16-19-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03342, current rewards: 252.41862, mean: 0.10696
[32m[0906 16-19-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03344, current rewards: 257.98481, mean: 0.10705
[32m[0906 16-19-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03346, current rewards: 263.54381, mean: 0.10713
[32m[0906 16-19-59 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 16-19-59 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-19-59 @MBExp.py:227][0m Rewards obtained: [267.9938385440368], Lows: [4], Highs: [6], Total time: 5459.779373999999
[32m[0906 16-22-10 @MBExp.py:144][0m ####################################################################
[32m[0906 16-22-10 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 16-22-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03262, current rewards: -0.05833, mean: -0.00583
[32m[0906 16-22-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03335, current rewards: 5.48830, mean: 0.09147
[32m[0906 16-22-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03338, current rewards: 11.03266, mean: 0.10030
[32m[0906 16-22-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03341, current rewards: 16.57984, mean: 0.10362
[32m[0906 16-22-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03348, current rewards: 22.12667, mean: 0.10537
[32m[0906 16-22-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03347, current rewards: 27.62452, mean: 0.10625
[32m[0906 16-22-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03351, current rewards: 33.15293, mean: 0.10694
[32m[0906 16-22-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03352, current rewards: 38.68729, mean: 0.10746
[32m[0906 16-22-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03351, current rewards: 44.21673, mean: 0.10785
[32m[0906 16-22-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03350, current rewards: 49.74882, mean: 0.10815
[32m[0906 16-22-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03338, current rewards: 55.28338, mean: 0.10840
[32m[0906 16-22-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03333, current rewards: 60.82037, mean: 0.10861
[32m[0906 16-22-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03326, current rewards: 66.35129, mean: 0.10877
[32m[0906 16-22-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03321, current rewards: 71.87230, mean: 0.10890
[32m[0906 16-22-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03316, current rewards: 77.40027, mean: 0.10901
[32m[0906 16-22-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03311, current rewards: 82.92929, mean: 0.10912
[32m[0906 16-22-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03309, current rewards: 88.45778, mean: 0.10921
[32m[0906 16-22-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03307, current rewards: 88.64559, mean: 0.10308
[32m[0906 16-22-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03304, current rewards: 94.10023, mean: 0.10341
[32m[0906 16-22-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03304, current rewards: 99.56756, mean: 0.10372
[32m[0906 16-22-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03302, current rewards: 105.02045, mean: 0.10398
[32m[0906 16-22-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03299, current rewards: 110.68531, mean: 0.10442
[32m[0906 16-22-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03298, current rewards: 116.24354, mean: 0.10472
[32m[0906 16-22-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03298, current rewards: 121.75886, mean: 0.10496
[32m[0906 16-22-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03296, current rewards: 127.26764, mean: 0.10518
[32m[0906 16-22-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03295, current rewards: 132.77893, mean: 0.10538
[32m[0906 16-22-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03293, current rewards: 138.30232, mean: 0.10557
[32m[0906 16-22-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03292, current rewards: 143.81325, mean: 0.10575
[32m[0906 16-22-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03292, current rewards: 149.32032, mean: 0.10590
[32m[0906 16-22-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03291, current rewards: 152.93904, mean: 0.10475
[32m[0906 16-23-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03292, current rewards: 158.57325, mean: 0.10502
[32m[0906 16-23-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03294, current rewards: 164.22959, mean: 0.10528
[32m[0906 16-23-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03296, current rewards: 169.88500, mean: 0.10552
[32m[0906 16-23-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03298, current rewards: 175.53895, mean: 0.10575
[32m[0906 16-23-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03300, current rewards: 181.19911, mean: 0.10596
[32m[0906 16-23-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03302, current rewards: 184.77359, mean: 0.10498
[32m[0906 16-23-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03304, current rewards: 190.34558, mean: 0.10516
[32m[0906 16-23-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03309, current rewards: 195.90870, mean: 0.10533
[32m[0906 16-23-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03313, current rewards: 201.22275, mean: 0.10535
[32m[0906 16-23-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03317, current rewards: 206.76226, mean: 0.10549
[32m[0906 16-23-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03320, current rewards: 208.44049, mean: 0.10370
[32m[0906 16-23-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03323, current rewards: 214.21084, mean: 0.10399
[32m[0906 16-23-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03327, current rewards: 219.97977, mean: 0.10426
[32m[0906 16-23-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03330, current rewards: 225.74699, mean: 0.10451
[32m[0906 16-23-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03332, current rewards: 231.51613, mean: 0.10476
[32m[0906 16-23-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03335, current rewards: 237.28935, mean: 0.10500
[32m[0906 16-23-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03338, current rewards: 243.35727, mean: 0.10535
[32m[0906 16-23-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03340, current rewards: 249.19194, mean: 0.10559
[32m[0906 16-23-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03342, current rewards: 254.85358, mean: 0.10575
[32m[0906 16-23-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03344, current rewards: 260.51552, mean: 0.10590
[32m[0906 16-23-34 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 16-23-34 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-23-34 @MBExp.py:227][0m Rewards obtained: [260.5196036543093], Lows: [6], Highs: [6], Total time: 5544.107436999999
[32m[0906 16-25-47 @MBExp.py:144][0m ####################################################################
[32m[0906 16-25-47 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 16-25-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03325, current rewards: -5.24955, mean: -0.52495
[32m[0906 16-25-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03359, current rewards: 0.50587, mean: 0.00843
[32m[0906 16-25-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03363, current rewards: 6.18820, mean: 0.05626
[32m[0906 16-25-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03365, current rewards: 11.86098, mean: 0.07413
[32m[0906 16-25-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03363, current rewards: 17.54439, mean: 0.08354
[32m[0906 16-25-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03358, current rewards: 21.05104, mean: 0.08097
[32m[0906 16-25-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03359, current rewards: 26.60059, mean: 0.08581
[32m[0906 16-26-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03361, current rewards: 32.15292, mean: 0.08931
[32m[0906 16-26-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03363, current rewards: 37.70702, mean: 0.09197
[32m[0906 16-26-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03359, current rewards: 43.25906, mean: 0.09404
[32m[0906 16-26-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03349, current rewards: 48.81131, mean: 0.09571
[32m[0906 16-26-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03341, current rewards: 54.36112, mean: 0.09707
[32m[0906 16-26-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03335, current rewards: 59.90649, mean: 0.09821
[32m[0906 16-26-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03329, current rewards: 65.32339, mean: 0.09897
[32m[0906 16-26-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03326, current rewards: 70.84331, mean: 0.09978
[32m[0906 16-26-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03324, current rewards: 74.28581, mean: 0.09774
[32m[0906 16-26-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03320, current rewards: 79.84188, mean: 0.09857
[32m[0906 16-26-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03316, current rewards: 85.39871, mean: 0.09930
[32m[0906 16-26-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03314, current rewards: 90.95725, mean: 0.09995
[32m[0906 16-26-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03312, current rewards: 96.51898, mean: 0.10054
[32m[0906 16-26-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03309, current rewards: 102.08085, mean: 0.10107
[32m[0906 16-26-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03306, current rewards: 107.71806, mean: 0.10162
[32m[0906 16-26-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03304, current rewards: 113.48556, mean: 0.10224
[32m[0906 16-26-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03303, current rewards: 117.91478, mean: 0.10165
[32m[0906 16-26-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03300, current rewards: 123.46634, mean: 0.10204
[32m[0906 16-26-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03299, current rewards: 129.02561, mean: 0.10240
[32m[0906 16-26-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03298, current rewards: 131.06856, mean: 0.10005
[32m[0906 16-26-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03295, current rewards: 137.38398, mean: 0.10102
[32m[0906 16-26-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03293, current rewards: 143.69941, mean: 0.10191
[32m[0906 16-26-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03291, current rewards: 150.01483, mean: 0.10275
[32m[0906 16-26-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03291, current rewards: 157.19223, mean: 0.10410
[32m[0906 16-26-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03292, current rewards: 165.05177, mean: 0.10580
[32m[0906 16-26-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03294, current rewards: 172.91130, mean: 0.10740
[32m[0906 16-26-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03296, current rewards: 174.98489, mean: 0.10541
[32m[0906 16-26-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03297, current rewards: 124.98489, mean: 0.07309
[32m[0906 16-26-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03299, current rewards: 74.98489, mean: 0.04261
[32m[0906 16-26-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03300, current rewards: 24.98489, mean: 0.01380
[32m[0906 16-26-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03303, current rewards: -25.01511, mean: -0.01345
[32m[0906 16-26-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03307, current rewards: -75.01511, mean: -0.03927
[32m[0906 16-26-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03311, current rewards: -125.01511, mean: -0.06378
[32m[0906 16-26-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03314, current rewards: -175.01511, mean: -0.08707
[32m[0906 16-26-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03318, current rewards: -225.01511, mean: -0.10923
[32m[0906 16-26-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03321, current rewards: -275.01511, mean: -0.13034
[32m[0906 16-27-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03324, current rewards: -325.01511, mean: -0.15047
[32m[0906 16-27-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03327, current rewards: -375.01511, mean: -0.16969
[32m[0906 16-27-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03330, current rewards: -425.01511, mean: -0.18806
[32m[0906 16-27-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03332, current rewards: -475.01511, mean: -0.20563
[32m[0906 16-27-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03334, current rewards: -525.01511, mean: -0.22246
[32m[0906 16-27-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03337, current rewards: -575.01511, mean: -0.23860
[32m[0906 16-27-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03338, current rewards: -625.01511, mean: -0.25407
[32m[0906 16-27-11 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 16-27-11 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-27-12 @MBExp.py:227][0m Rewards obtained: [-665.0151103167146], Lows: [6], Highs: [848], Total time: 5628.314186999999
[32m[0906 16-29-27 @MBExp.py:144][0m ####################################################################
[32m[0906 16-29-27 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 16-29-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03247, current rewards: -1.44789, mean: -0.14479
[32m[0906 16-29-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03327, current rewards: 4.21144, mean: 0.07019
[32m[0906 16-29-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03338, current rewards: 9.87182, mean: 0.08974
[32m[0906 16-29-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03338, current rewards: 15.52789, mean: 0.09705
[32m[0906 16-29-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03343, current rewards: 21.19623, mean: 0.10093
[32m[0906 16-29-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03343, current rewards: 27.67604, mean: 0.10645
[32m[0906 16-29-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03347, current rewards: 33.34725, mean: 0.10757
[32m[0906 16-29-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03347, current rewards: 39.01450, mean: 0.10837
[32m[0906 16-29-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03347, current rewards: 44.68168, mean: 0.10898
[32m[0906 16-29-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03338, current rewards: 50.34939, mean: 0.10946
[32m[0906 16-29-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03329, current rewards: 56.00890, mean: 0.10982
[32m[0906 16-29-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03322, current rewards: 61.68321, mean: 0.11015
[32m[0906 16-29-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03315, current rewards: 67.35165, mean: 0.11041
[32m[0906 16-29-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03308, current rewards: 71.13168, mean: 0.10778
[32m[0906 16-29-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03306, current rewards: 76.91252, mean: 0.10833
[32m[0906 16-29-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03304, current rewards: 82.69092, mean: 0.10880
[32m[0906 16-29-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03301, current rewards: 88.46758, mean: 0.10922
[32m[0906 16-29-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03298, current rewards: 94.24751, mean: 0.10959
[32m[0906 16-29-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03297, current rewards: 100.02760, mean: 0.10992
[32m[0906 16-29-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03295, current rewards: 105.80794, mean: 0.11022
[32m[0906 16-30-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03294, current rewards: 111.58789, mean: 0.11048
[32m[0906 16-30-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03292, current rewards: 117.17787, mean: 0.11055
[32m[0906 16-30-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03290, current rewards: 122.90915, mean: 0.11073
[32m[0906 16-30-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03290, current rewards: 128.64420, mean: 0.11090
[32m[0906 16-30-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03288, current rewards: 132.08127, mean: 0.10916
[32m[0906 16-30-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03287, current rewards: 137.49834, mean: 0.10913
[32m[0906 16-30-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03286, current rewards: 142.91313, mean: 0.10909
[32m[0906 16-30-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03284, current rewards: 148.33104, mean: 0.10907
[32m[0906 16-30-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03284, current rewards: 152.15903, mean: 0.10791
[32m[0906 16-30-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03282, current rewards: 158.10540, mean: 0.10829
[32m[0906 16-30-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03282, current rewards: 166.29581, mean: 0.11013
[32m[0906 16-30-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03281, current rewards: 174.83373, mean: 0.11207
[32m[0906 16-30-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03283, current rewards: 183.37165, mean: 0.11390
[32m[0906 16-30-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03286, current rewards: 191.90958, mean: 0.11561
[32m[0906 16-30-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03288, current rewards: 192.25219, mean: 0.11243
[32m[0906 16-30-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03290, current rewards: 192.77435, mean: 0.10953
[32m[0906 16-30-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03293, current rewards: 198.41675, mean: 0.10962
[32m[0906 16-30-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03296, current rewards: 204.05215, mean: 0.10971
[32m[0906 16-30-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03299, current rewards: 209.41761, mean: 0.10964
[32m[0906 16-30-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03303, current rewards: 215.02394, mean: 0.10971
[32m[0906 16-30-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03306, current rewards: 220.62677, mean: 0.10976
[32m[0906 16-30-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03310, current rewards: 226.23960, mean: 0.10983
[32m[0906 16-30-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03313, current rewards: 231.84630, mean: 0.10988
[32m[0906 16-30-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03316, current rewards: 237.45584, mean: 0.10993
[32m[0906 16-30-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03319, current rewards: 243.06795, mean: 0.10999
[32m[0906 16-30-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03323, current rewards: 248.67696, mean: 0.11003
[32m[0906 16-30-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03325, current rewards: 254.35484, mean: 0.11011
[32m[0906 16-30-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03328, current rewards: 260.09110, mean: 0.11021
[32m[0906 16-30-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03330, current rewards: 265.37537, mean: 0.11011
[32m[0906 16-30-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03333, current rewards: 271.03798, mean: 0.11018
[32m[0906 16-30-51 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 16-30-51 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-30-51 @MBExp.py:227][0m Rewards obtained: [275.56883432215335], Lows: [4], Highs: [14], Total time: 5712.377887999999
[32m[0906 16-33-08 @MBExp.py:144][0m ####################################################################
[32m[0906 16-33-08 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 16-33-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03273, current rewards: -1.01398, mean: -0.10140
[32m[0906 16-33-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03328, current rewards: 5.00207, mean: 0.08337
[32m[0906 16-33-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03351, current rewards: 10.80634, mean: 0.09824
[32m[0906 16-33-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03351, current rewards: 16.61064, mean: 0.10382
[32m[0906 16-33-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03347, current rewards: 22.40901, mean: 0.10671
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03344, current rewards: 28.23824, mean: 0.10861
[32m[0906 16-33-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03346, current rewards: 32.76924, mean: 0.10571
[32m[0906 16-33-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03347, current rewards: 38.26638, mean: 0.10630
[32m[0906 16-33-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03348, current rewards: 43.76451, mean: 0.10674
[32m[0906 16-33-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03335, current rewards: 49.97651, mean: 0.10864
[32m[0906 16-33-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03329, current rewards: 55.49625, mean: 0.10882
[32m[0906 16-33-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03324, current rewards: 61.02605, mean: 0.10898
[32m[0906 16-33-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03320, current rewards: 66.55173, mean: 0.10910
[32m[0906 16-33-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03317, current rewards: 70.00610, mean: 0.10607
[32m[0906 16-33-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03313, current rewards: 75.43877, mean: 0.10625
[32m[0906 16-33-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03310, current rewards: 80.97910, mean: 0.10655
[32m[0906 16-33-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03305, current rewards: 86.51455, mean: 0.10681
[32m[0906 16-33-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03303, current rewards: 92.05107, mean: 0.10704
[32m[0906 16-33-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03302, current rewards: 97.59047, mean: 0.10724
[32m[0906 16-33-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03300, current rewards: 103.12698, mean: 0.10742
[32m[0906 16-33-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03298, current rewards: 108.66831, mean: 0.10759
[32m[0906 16-33-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03294, current rewards: 114.21457, mean: 0.10775
[32m[0906 16-33-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03292, current rewards: 119.72643, mean: 0.10786
[32m[0906 16-33-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03292, current rewards: 125.26776, mean: 0.10799
[32m[0906 16-33-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03292, current rewards: 130.80945, mean: 0.10811
[32m[0906 16-33-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03290, current rewards: 136.34720, mean: 0.10821
[32m[0906 16-33-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03289, current rewards: 141.88891, mean: 0.10831
[32m[0906 16-33-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03288, current rewards: 147.43134, mean: 0.10841
[32m[0906 16-33-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03286, current rewards: 152.91612, mean: 0.10845
[32m[0906 16-33-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03287, current rewards: 158.45860, mean: 0.10853
[32m[0906 16-33-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03286, current rewards: 164.00228, mean: 0.10861
[32m[0906 16-34-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03285, current rewards: 169.54224, mean: 0.10868
[32m[0906 16-34-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03286, current rewards: 175.08232, mean: 0.10875
[32m[0906 16-34-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03288, current rewards: 180.62519, mean: 0.10881
[32m[0906 16-34-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03291, current rewards: 186.16755, mean: 0.10887
[32m[0906 16-34-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03294, current rewards: 191.70925, mean: 0.10893
[32m[0906 16-34-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03296, current rewards: 197.24781, mean: 0.10898
[32m[0906 16-34-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03298, current rewards: 202.78540, mean: 0.10902
[32m[0906 16-34-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03301, current rewards: 208.53479, mean: 0.10918
[32m[0906 16-34-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03305, current rewards: 210.39131, mean: 0.10734
[32m[0906 16-34-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03309, current rewards: 217.31797, mean: 0.10812
[32m[0906 16-34-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03312, current rewards: 224.24463, mean: 0.10886
[32m[0906 16-34-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03315, current rewards: 231.17129, mean: 0.10956
[32m[0906 16-34-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03318, current rewards: 221.74624, mean: 0.10266
[32m[0906 16-34-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03321, current rewards: 227.55182, mean: 0.10296
[32m[0906 16-34-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03324, current rewards: 233.35386, mean: 0.10325
[32m[0906 16-34-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03327, current rewards: 239.03763, mean: 0.10348
[32m[0906 16-34-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03330, current rewards: 244.74487, mean: 0.10371
[32m[0906 16-34-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03332, current rewards: 250.50132, mean: 0.10394
[32m[0906 16-34-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03334, current rewards: 256.25328, mean: 0.10417
[32m[0906 16-34-32 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 16-34-32 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-34-32 @MBExp.py:227][0m Rewards obtained: [260.8593981552456], Lows: [3], Highs: [17], Total time: 5796.488793999999
[32m[0906 16-36-51 @MBExp.py:144][0m ####################################################################
[32m[0906 16-36-51 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 16-36-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03375, current rewards: -1.23628, mean: -0.12363
[32m[0906 16-36-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03364, current rewards: 4.12400, mean: 0.06873
[32m[0906 16-36-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03365, current rewards: 9.49428, mean: 0.08631
[32m[0906 16-36-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03362, current rewards: 14.85653, mean: 0.09285
[32m[0906 16-36-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03359, current rewards: 20.21901, mean: 0.09628
[32m[0906 16-37-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03359, current rewards: 25.94513, mean: 0.09979
[32m[0906 16-37-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03359, current rewards: 31.39634, mean: 0.10128
[32m[0906 16-37-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03358, current rewards: 36.85259, mean: 0.10237
[32m[0906 16-37-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03353, current rewards: 38.18217, mean: 0.09313
[32m[0906 16-37-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03341, current rewards: 44.49765, mean: 0.09673
[32m[0906 16-37-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03333, current rewards: 50.81308, mean: 0.09963
[32m[0906 16-37-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03327, current rewards: 57.12850, mean: 0.10202
[32m[0906 16-37-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03320, current rewards: 63.44392, mean: 0.10401
[32m[0906 16-37-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03318, current rewards: 69.66394, mean: 0.10555
[32m[0906 16-37-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03316, current rewards: 75.58181, mean: 0.10645
[32m[0906 16-37-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03312, current rewards: 81.49969, mean: 0.10724
[32m[0906 16-37-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03308, current rewards: 87.41756, mean: 0.10792
[32m[0906 16-37-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03305, current rewards: 77.55338, mean: 0.09018
[32m[0906 16-37-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03303, current rewards: 82.96753, mean: 0.09117
[32m[0906 16-37-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03301, current rewards: 88.38252, mean: 0.09207
[32m[0906 16-37-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03300, current rewards: 93.79936, mean: 0.09287
[32m[0906 16-37-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03297, current rewards: 99.12647, mean: 0.09352
[32m[0906 16-37-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03295, current rewards: 104.33782, mean: 0.09400
[32m[0906 16-37-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03294, current rewards: 109.68360, mean: 0.09455
[32m[0906 16-37-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03292, current rewards: 115.03234, mean: 0.09507
[32m[0906 16-37-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03290, current rewards: 120.38105, mean: 0.09554
[32m[0906 16-37-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03288, current rewards: 125.72725, mean: 0.09598
[32m[0906 16-37-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03287, current rewards: 131.06854, mean: 0.09637
[32m[0906 16-37-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03288, current rewards: 136.52560, mean: 0.09683
[32m[0906 16-37-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03287, current rewards: 141.96631, mean: 0.09724
[32m[0906 16-37-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03287, current rewards: 147.39052, mean: 0.09761
[32m[0906 16-37-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03286, current rewards: 152.82614, mean: 0.09797
[32m[0906 16-37-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03286, current rewards: 158.26359, mean: 0.09830
[32m[0906 16-37-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03288, current rewards: 163.70108, mean: 0.09862
[32m[0906 16-37-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03290, current rewards: 169.14321, mean: 0.09891
[32m[0906 16-37-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03293, current rewards: 172.49705, mean: 0.09801
[32m[0906 16-37-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03295, current rewards: 178.05523, mean: 0.09837
[32m[0906 16-37-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03296, current rewards: 183.61997, mean: 0.09872
[32m[0906 16-37-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03299, current rewards: 189.38550, mean: 0.09915
[32m[0906 16-37-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03303, current rewards: 194.96352, mean: 0.09947
[32m[0906 16-37-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03307, current rewards: 200.54088, mean: 0.09977
[32m[0906 16-38-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03311, current rewards: 206.11747, mean: 0.10006
[32m[0906 16-38-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03314, current rewards: 210.68467, mean: 0.09985
[32m[0906 16-38-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03317, current rewards: 216.20052, mean: 0.10009
[32m[0906 16-38-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03320, current rewards: 221.71247, mean: 0.10032
[32m[0906 16-38-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03323, current rewards: 227.22542, mean: 0.10054
[32m[0906 16-38-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03326, current rewards: 232.74269, mean: 0.10075
[32m[0906 16-38-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03328, current rewards: 238.26179, mean: 0.10096
[32m[0906 16-38-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03331, current rewards: 243.77598, mean: 0.10115
[32m[0906 16-38-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03333, current rewards: 249.29179, mean: 0.10134
[32m[0906 16-38-15 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 16-38-15 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-38-16 @MBExp.py:227][0m Rewards obtained: [253.70280122815106], Lows: [3], Highs: [17], Total time: 5880.5521039999985
[32m[0906 16-40-36 @MBExp.py:144][0m ####################################################################
[32m[0906 16-40-36 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 16-40-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03327, current rewards: -1.48804, mean: -0.14880
[32m[0906 16-40-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03335, current rewards: 4.17099, mean: 0.06952
[32m[0906 16-40-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03331, current rewards: 9.84511, mean: 0.08950
[32m[0906 16-40-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03340, current rewards: 15.52487, mean: 0.09703
[32m[0906 16-40-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03344, current rewards: 21.19488, mean: 0.10093
[32m[0906 16-40-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03344, current rewards: 26.77931, mean: 0.10300
[32m[0906 16-40-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03344, current rewards: 32.49151, mean: 0.10481
[32m[0906 16-40-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03349, current rewards: 38.19863, mean: 0.10611
[32m[0906 16-40-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03340, current rewards: 43.90816, mean: 0.10709
[32m[0906 16-40-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03331, current rewards: 49.62765, mean: 0.10789
[32m[0906 16-40-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03324, current rewards: 53.21048, mean: 0.10433
[32m[0906 16-40-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03321, current rewards: 58.80164, mean: 0.10500
[32m[0906 16-40-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03317, current rewards: 64.39081, mean: 0.10556
[32m[0906 16-40-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03314, current rewards: 69.89298, mean: 0.10590
[32m[0906 16-41-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03310, current rewards: 75.46084, mean: 0.10628
[32m[0906 16-41-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03307, current rewards: 81.03119, mean: 0.10662
[32m[0906 16-41-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03302, current rewards: 86.60316, mean: 0.10692
[32m[0906 16-41-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03299, current rewards: 92.17754, mean: 0.10718
[32m[0906 16-41-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03296, current rewards: 97.74691, mean: 0.10741
[32m[0906 16-41-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03294, current rewards: 103.31769, mean: 0.10762
[32m[0906 16-41-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03291, current rewards: 108.88652, mean: 0.10781
[32m[0906 16-41-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03288, current rewards: 113.05102, mean: 0.10665
[32m[0906 16-41-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03287, current rewards: 118.87659, mean: 0.10710
[32m[0906 16-41-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03285, current rewards: 124.51058, mean: 0.10734
[32m[0906 16-41-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03285, current rewards: 130.14641, mean: 0.10756
[32m[0906 16-41-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03284, current rewards: 135.78234, mean: 0.10776
[32m[0906 16-41-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03284, current rewards: 141.41767, mean: 0.10795
[32m[0906 16-41-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03283, current rewards: 147.05160, mean: 0.10813
[32m[0906 16-41-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03282, current rewards: 152.68447, mean: 0.10829
[32m[0906 16-41-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03282, current rewards: 158.32531, mean: 0.10844
[32m[0906 16-41-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03282, current rewards: 164.53559, mean: 0.10896
[32m[0906 16-41-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03282, current rewards: 173.58902, mean: 0.11128
[32m[0906 16-41-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03281, current rewards: 182.64246, mean: 0.11344
[32m[0906 16-41-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03280, current rewards: 191.69589, mean: 0.11548
[32m[0906 16-41-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03282, current rewards: 200.74932, mean: 0.11740
[32m[0906 16-41-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03285, current rewards: 209.80275, mean: 0.11921
[32m[0906 16-41-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03287, current rewards: 218.85619, mean: 0.12092
[32m[0906 16-41-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03290, current rewards: 227.90962, mean: 0.12253
[32m[0906 16-41-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03291, current rewards: 236.96305, mean: 0.12406
[32m[0906 16-41-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03296, current rewards: 214.12763, mean: 0.10925
[32m[0906 16-41-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03300, current rewards: 164.12763, mean: 0.08166
[32m[0906 16-41-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03304, current rewards: 114.12763, mean: 0.05540
[32m[0906 16-41-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03307, current rewards: 64.12763, mean: 0.03039
[32m[0906 16-41-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03311, current rewards: 14.12763, mean: 0.00654
[32m[0906 16-41-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03314, current rewards: -35.87237, mean: -0.01623
[32m[0906 16-41-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03317, current rewards: -85.87237, mean: -0.03800
[32m[0906 16-41-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03320, current rewards: -135.87237, mean: -0.05882
[32m[0906 16-41-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03322, current rewards: -154.28901, mean: -0.06538
[32m[0906 16-41-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03325, current rewards: -148.79932, mean: -0.06174
[32m[0906 16-41-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03328, current rewards: -143.13325, mean: -0.05818
[32m[0906 16-42-00 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 16-42-00 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-42-00 @MBExp.py:227][0m Rewards obtained: [-138.65283475993837], Lows: [4], Highs: [400], Total time: 5964.516969999999
[32m[0906 16-44-24 @MBExp.py:144][0m ####################################################################
[32m[0906 16-44-24 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 16-44-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03467, current rewards: -1.97835, mean: -0.19783
[32m[0906 16-44-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03381, current rewards: 3.56702, mean: 0.05945
[32m[0906 16-44-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03375, current rewards: 9.02539, mean: 0.08205
[32m[0906 16-44-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03371, current rewards: 14.48137, mean: 0.09051
[32m[0906 16-44-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03367, current rewards: 19.94017, mean: 0.09495
[32m[0906 16-44-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03371, current rewards: 25.39309, mean: 0.09767
[32m[0906 16-44-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03364, current rewards: 30.84981, mean: 0.09952
[32m[0906 16-44-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03361, current rewards: 36.30802, mean: 0.10086
[32m[0906 16-44-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03346, current rewards: 41.76679, mean: 0.10187
[32m[0906 16-44-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03339, current rewards: 47.22295, mean: 0.10266
[32m[0906 16-44-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03328, current rewards: 51.26108, mean: 0.10051
[32m[0906 16-44-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03321, current rewards: 56.29816, mean: 0.10053
[32m[0906 16-44-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03313, current rewards: 61.33324, mean: 0.10055
[32m[0906 16-44-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03309, current rewards: 66.39618, mean: 0.10060
[32m[0906 16-44-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03305, current rewards: 71.44616, mean: 0.10063
[32m[0906 16-44-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03301, current rewards: 76.50025, mean: 0.10066
[32m[0906 16-44-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03298, current rewards: 79.57688, mean: 0.09824
[32m[0906 16-44-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03295, current rewards: 84.84851, mean: 0.09866
[32m[0906 16-44-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03293, current rewards: 90.11557, mean: 0.09903
[32m[0906 16-44-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03293, current rewards: 95.37731, mean: 0.09935
[32m[0906 16-44-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03291, current rewards: 100.64729, mean: 0.09965
[32m[0906 16-44-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03289, current rewards: 105.86136, mean: 0.09987
[32m[0906 16-45-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03289, current rewards: 111.10918, mean: 0.10010
[32m[0906 16-45-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03287, current rewards: 114.44788, mean: 0.09866
[32m[0906 16-45-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03287, current rewards: 119.92090, mean: 0.09911
[32m[0906 16-45-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03285, current rewards: 125.39358, mean: 0.09952
[32m[0906 16-45-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03285, current rewards: 130.86100, mean: 0.09989
[32m[0906 16-45-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03285, current rewards: 136.32783, mean: 0.10024
[32m[0906 16-45-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03285, current rewards: 141.79777, mean: 0.10057
[32m[0906 16-45-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03284, current rewards: 147.24572, mean: 0.10085
[32m[0906 16-45-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03285, current rewards: 152.70450, mean: 0.10113
[32m[0906 16-45-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03284, current rewards: 158.16712, mean: 0.10139
[32m[0906 16-45-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03284, current rewards: 163.62367, mean: 0.10163
[32m[0906 16-45-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03284, current rewards: 169.07943, mean: 0.10186
[32m[0906 16-45-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03285, current rewards: 170.47116, mean: 0.09969
[32m[0906 16-45-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03288, current rewards: 175.97590, mean: 0.09999
[32m[0906 16-45-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03290, current rewards: 181.48000, mean: 0.10027
[32m[0906 16-45-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03291, current rewards: 186.76601, mean: 0.10041
[32m[0906 16-45-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03293, current rewards: 192.17763, mean: 0.10062
[32m[0906 16-45-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03297, current rewards: 197.58568, mean: 0.10081
[32m[0906 16-45-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03301, current rewards: 202.99665, mean: 0.10099
[32m[0906 16-45-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03305, current rewards: 208.40674, mean: 0.10117
[32m[0906 16-45-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03308, current rewards: 213.81549, mean: 0.10133
[32m[0906 16-45-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03311, current rewards: 219.22342, mean: 0.10149
[32m[0906 16-45-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03315, current rewards: 224.63325, mean: 0.10164
[32m[0906 16-45-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03318, current rewards: 230.09463, mean: 0.10181
[32m[0906 16-45-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03321, current rewards: 235.71264, mean: 0.10204
[32m[0906 16-45-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03324, current rewards: 238.78829, mean: 0.10118
[32m[0906 16-45-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03327, current rewards: 244.03691, mean: 0.10126
[32m[0906 16-45-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03329, current rewards: 249.29103, mean: 0.10134
[32m[0906 16-45-48 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 16-45-48 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-45-48 @MBExp.py:227][0m Rewards obtained: [253.4935219880956], Lows: [5], Highs: [4], Total time: 6048.502732999998
[32m[0906 16-48-13 @MBExp.py:144][0m ####################################################################
[32m[0906 16-48-13 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 16-48-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03342, current rewards: -0.04632, mean: -0.00463
[32m[0906 16-48-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03363, current rewards: 5.51833, mean: 0.09197
[32m[0906 16-48-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03359, current rewards: 11.08705, mean: 0.10079
[32m[0906 16-48-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03363, current rewards: 16.65199, mean: 0.10407
[32m[0906 16-48-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03355, current rewards: 22.22051, mean: 0.10581
[32m[0906 16-48-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03353, current rewards: 27.78736, mean: 0.10687
[32m[0906 16-48-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03353, current rewards: 33.34991, mean: 0.10758
[32m[0906 16-48-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03355, current rewards: 38.91667, mean: 0.10810
[32m[0906 16-48-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03339, current rewards: 42.45261, mean: 0.10354
[32m[0906 16-48-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03330, current rewards: 48.01485, mean: 0.10438
[32m[0906 16-48-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03323, current rewards: 53.57638, mean: 0.10505
[32m[0906 16-48-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03319, current rewards: 59.13715, mean: 0.10560
[32m[0906 16-48-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03315, current rewards: 63.62815, mean: 0.10431
[32m[0906 16-48-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03311, current rewards: 69.25041, mean: 0.10492
[32m[0906 16-48-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03306, current rewards: 74.86981, mean: 0.10545
[32m[0906 16-48-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03303, current rewards: 80.49049, mean: 0.10591
[32m[0906 16-48-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03298, current rewards: 86.11133, mean: 0.10631
[32m[0906 16-48-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03295, current rewards: 91.73443, mean: 0.10667
[32m[0906 16-48-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03294, current rewards: 97.35130, mean: 0.10698
[32m[0906 16-48-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03292, current rewards: 102.96955, mean: 0.10726
[32m[0906 16-48-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03291, current rewards: 108.70871, mean: 0.10763
[32m[0906 16-48-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03289, current rewards: 115.17096, mean: 0.10865
[32m[0906 16-48-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03288, current rewards: 120.79765, mean: 0.10883
[32m[0906 16-48-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03286, current rewards: 126.42252, mean: 0.10898
[32m[0906 16-48-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03285, current rewards: 132.05036, mean: 0.10913
[32m[0906 16-48-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03283, current rewards: 137.67085, mean: 0.10926
[32m[0906 16-48-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03283, current rewards: 143.29880, mean: 0.10939
[32m[0906 16-48-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03283, current rewards: 146.05961, mean: 0.10740
[32m[0906 16-48-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03282, current rewards: 153.19517, mean: 0.10865
[32m[0906 16-49-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03282, current rewards: 158.15238, mean: 0.10832
[32m[0906 16-49-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03282, current rewards: 163.10959, mean: 0.10802
[32m[0906 16-49-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03281, current rewards: 129.59676, mean: 0.08307
[32m[0906 16-49-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03281, current rewards: 79.59676, mean: 0.04944
[32m[0906 16-49-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03280, current rewards: 29.59676, mean: 0.01783
[32m[0906 16-49-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03281, current rewards: -20.40324, mean: -0.01193
[32m[0906 16-49-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03282, current rewards: -70.40324, mean: -0.04000
[32m[0906 16-49-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03284, current rewards: -120.40324, mean: -0.06652
[32m[0906 16-49-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03286, current rewards: -170.40324, mean: -0.09161
[32m[0906 16-49-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03288, current rewards: -220.40324, mean: -0.11539
[32m[0906 16-49-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03291, current rewards: -270.40324, mean: -0.13796
[32m[0906 16-49-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03294, current rewards: -320.40324, mean: -0.15940
[32m[0906 16-49-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03298, current rewards: -370.40324, mean: -0.17981
[32m[0906 16-49-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03302, current rewards: -420.40324, mean: -0.19924
[32m[0906 16-49-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03305, current rewards: -470.40324, mean: -0.21778
[32m[0906 16-49-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03308, current rewards: -520.40324, mean: -0.23548
[32m[0906 16-49-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03312, current rewards: -570.40324, mean: -0.25239
[32m[0906 16-49-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03315, current rewards: -620.40324, mean: -0.26857
[32m[0906 16-49-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03318, current rewards: -670.40324, mean: -0.28407
[32m[0906 16-49-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03321, current rewards: -720.40324, mean: -0.29892
[32m[0906 16-49-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03323, current rewards: -770.40324, mean: -0.31317
[32m[0906 16-49-36 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 16-49-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-49-37 @MBExp.py:227][0m Rewards obtained: [-810.403244158287], Lows: [3], Highs: [977], Total time: 6132.353732999998
[32m[0906 16-52-04 @MBExp.py:144][0m ####################################################################
[32m[0906 16-52-04 @MBExp.py:145][0m Starting training iteration 72.
[32m[0906 16-52-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03274, current rewards: -0.68527, mean: -0.06853
[32m[0906 16-52-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03352, current rewards: 4.37720, mean: 0.07295
[32m[0906 16-52-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03354, current rewards: 9.58417, mean: 0.08713
[32m[0906 16-52-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03358, current rewards: 15.04400, mean: 0.09402
[32m[0906 16-52-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03348, current rewards: 20.32501, mean: 0.09679
[32m[0906 16-52-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03354, current rewards: 25.60291, mean: 0.09847
[32m[0906 16-52-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03355, current rewards: 29.77670, mean: 0.09605
[32m[0906 16-52-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03349, current rewards: 34.18193, mean: 0.09495
[32m[0906 16-52-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03337, current rewards: 39.70841, mean: 0.09685
[32m[0906 16-52-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03331, current rewards: 45.23163, mean: 0.09833
[32m[0906 16-52-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03326, current rewards: 50.75610, mean: 0.09952
[32m[0906 16-52-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03321, current rewards: 56.26270, mean: 0.10047
[32m[0906 16-52-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03317, current rewards: 61.68087, mean: 0.10112
[32m[0906 16-52-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03314, current rewards: 67.18380, mean: 0.10179
[32m[0906 16-52-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03308, current rewards: 72.68869, mean: 0.10238
[32m[0906 16-52-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03304, current rewards: 78.14624, mean: 0.10282
[32m[0906 16-52-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03303, current rewards: 83.62989, mean: 0.10325
[32m[0906 16-52-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03299, current rewards: 89.10560, mean: 0.10361
[32m[0906 16-52-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03297, current rewards: 94.57575, mean: 0.10393
[32m[0906 16-52-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03296, current rewards: 100.05370, mean: 0.10422
[32m[0906 16-52-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03294, current rewards: 105.66642, mean: 0.10462
[32m[0906 16-52-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03294, current rewards: 111.19646, mean: 0.10490
[32m[0906 16-52-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03292, current rewards: 116.72750, mean: 0.10516
[32m[0906 16-52-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03293, current rewards: 122.25929, mean: 0.10540
[32m[0906 16-52-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03292, current rewards: 127.79130, mean: 0.10561
[32m[0906 16-52-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03291, current rewards: 131.38665, mean: 0.10428
[32m[0906 16-52-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03290, current rewards: 136.83147, mean: 0.10445
[32m[0906 16-52-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03288, current rewards: 142.27602, mean: 0.10461
[32m[0906 16-52-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03287, current rewards: 147.59319, mean: 0.10468
[32m[0906 16-52-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03286, current rewards: 152.94119, mean: 0.10475
[32m[0906 16-52-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03285, current rewards: 158.28723, mean: 0.10483
[32m[0906 16-52-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03283, current rewards: 163.63501, mean: 0.10489
[32m[0906 16-52-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03282, current rewards: 168.97829, mean: 0.10496
[32m[0906 16-52-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03283, current rewards: 174.32905, mean: 0.10502
[32m[0906 16-53-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03282, current rewards: 179.67759, mean: 0.10507
[32m[0906 16-53-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03282, current rewards: 185.02112, mean: 0.10513
[32m[0906 16-53-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03285, current rewards: 190.30558, mean: 0.10514
[32m[0906 16-53-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03287, current rewards: 195.58637, mean: 0.10515
[32m[0906 16-53-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03289, current rewards: 200.86437, mean: 0.10516
[32m[0906 16-53-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03292, current rewards: 206.14046, mean: 0.10517
[32m[0906 16-53-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03295, current rewards: 209.53202, mean: 0.10424
[32m[0906 16-53-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03299, current rewards: 214.89872, mean: 0.10432
[32m[0906 16-53-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03303, current rewards: 220.26941, mean: 0.10439
[32m[0906 16-53-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03305, current rewards: 225.63818, mean: 0.10446
[32m[0906 16-53-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03308, current rewards: 231.00806, mean: 0.10453
[32m[0906 16-53-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03312, current rewards: 236.76374, mean: 0.10476
[32m[0906 16-53-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03315, current rewards: 242.27053, mean: 0.10488
[32m[0906 16-53-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03318, current rewards: 247.77600, mean: 0.10499
[32m[0906 16-53-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03321, current rewards: 251.45493, mean: 0.10434
[32m[0906 16-53-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03323, current rewards: 256.93042, mean: 0.10444
[32m[0906 16-53-28 @Agent.py:117][0m Average action selection time: 0.0332
[32m[0906 16-53-28 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-53-28 @MBExp.py:227][0m Rewards obtained: [261.3148772694849], Lows: [4], Highs: [2], Total time: 6216.181773999998
[32m[0906 16-55-57 @MBExp.py:144][0m ####################################################################
[32m[0906 16-55-57 @MBExp.py:145][0m Starting training iteration 73.
[32m[0906 16-55-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03329, current rewards: 1.25489, mean: 0.12549
[32m[0906 16-55-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03334, current rewards: 7.30533, mean: 0.12176
[32m[0906 16-56-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03345, current rewards: 13.22321, mean: 0.12021
[32m[0906 16-56-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03352, current rewards: 19.14108, mean: 0.11963
[32m[0906 16-56-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03352, current rewards: -9.40151, mean: -0.04477
[32m[0906 16-56-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03349, current rewards: -59.40151, mean: -0.22847
[32m[0906 16-56-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03350, current rewards: -109.40151, mean: -0.35291
[32m[0906 16-56-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03351, current rewards: -159.40151, mean: -0.44278
[32m[0906 16-56-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03341, current rewards: -209.40151, mean: -0.51074
[32m[0906 16-56-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03332, current rewards: -259.40151, mean: -0.56392
[32m[0906 16-56-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03324, current rewards: -309.40151, mean: -0.60667
[32m[0906 16-56-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03318, current rewards: -359.40151, mean: -0.64179
[32m[0906 16-56-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03313, current rewards: -409.40151, mean: -0.67115
[32m[0906 16-56-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03310, current rewards: -459.40151, mean: -0.69606
[32m[0906 16-56-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03308, current rewards: -509.40151, mean: -0.71747
[32m[0906 16-56-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03306, current rewards: -559.40151, mean: -0.73605
[32m[0906 16-56-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03305, current rewards: -609.40151, mean: -0.75235
[32m[0906 16-56-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03305, current rewards: -659.40151, mean: -0.76675
[32m[0906 16-56-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03303, current rewards: -709.40151, mean: -0.77956
[32m[0906 16-56-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03301, current rewards: -759.40151, mean: -0.79104
[32m[0906 16-56-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03301, current rewards: -809.40151, mean: -0.80139
[32m[0906 16-56-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03298, current rewards: -859.40151, mean: -0.81076
[32m[0906 16-56-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03297, current rewards: -909.40151, mean: -0.81928
[32m[0906 16-56-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03295, current rewards: -959.40151, mean: -0.82707
[32m[0906 16-56-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03294, current rewards: -1009.40151, mean: -0.83422
[32m[0906 16-56-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03292, current rewards: -1059.40151, mean: -0.84079
[32m[0906 16-56-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03292, current rewards: -1109.40151, mean: -0.84687
[32m[0906 16-56-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03290, current rewards: -1159.40151, mean: -0.85250
[32m[0906 16-56-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03290, current rewards: -1209.40151, mean: -0.85773
[32m[0906 16-56-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03288, current rewards: -1259.40151, mean: -0.86260
[32m[0906 16-56-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03289, current rewards: -1309.40151, mean: -0.86715
[32m[0906 16-56-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03288, current rewards: -1359.40151, mean: -0.87141
[32m[0906 16-56-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03286, current rewards: -1409.40151, mean: -0.87540
[32m[0906 16-56-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03285, current rewards: -1459.40151, mean: -0.87916
[32m[0906 16-56-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03284, current rewards: -1509.40151, mean: -0.88269
[32m[0906 16-56-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03283, current rewards: -1559.40151, mean: -0.88602
[32m[0906 16-56-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03282, current rewards: -1609.40151, mean: -0.88917
[32m[0906 16-56-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03285, current rewards: -1659.40151, mean: -0.89215
[32m[0906 16-57-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03287, current rewards: -1709.40151, mean: -0.89497
[32m[0906 16-57-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03289, current rewards: -1759.40151, mean: -0.89765
[32m[0906 16-57-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03291, current rewards: -1809.40151, mean: -0.90020
[32m[0906 16-57-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03295, current rewards: -1859.40151, mean: -0.90262
[32m[0906 16-57-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03298, current rewards: -1909.40151, mean: -0.90493
[32m[0906 16-57-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03302, current rewards: -1959.40151, mean: -0.90713
[32m[0906 16-57-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03305, current rewards: -2009.40151, mean: -0.90923
[32m[0906 16-57-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03308, current rewards: -2059.40151, mean: -0.91124
[32m[0906 16-57-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03311, current rewards: -2109.40151, mean: -0.91316
[32m[0906 16-57-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03314, current rewards: -2159.40151, mean: -0.91500
[32m[0906 16-57-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03317, current rewards: -2209.40151, mean: -0.91676
[32m[0906 16-57-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03320, current rewards: -2259.40151, mean: -0.91846
[32m[0906 16-57-21 @Agent.py:117][0m Average action selection time: 0.0332
[32m[0906 16-57-21 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-57-21 @MBExp.py:227][0m Rewards obtained: [-2299.4015145560907], Lows: [0], Highs: [2320], Total time: 6299.945221999998
[32m[0906 16-59-53 @MBExp.py:144][0m ####################################################################
[32m[0906 16-59-53 @MBExp.py:145][0m Starting training iteration 74.
[32m[0906 16-59-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03309, current rewards: -0.06842, mean: -0.00684
[32m[0906 16-59-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03346, current rewards: 5.43506, mean: 0.09058
[32m[0906 16-59-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03364, current rewards: 10.94121, mean: 0.09947
[32m[0906 16-59-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03363, current rewards: 16.44456, mean: 0.10278
[32m[0906 17-00-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03362, current rewards: 22.00227, mean: 0.10477
[32m[0906 17-00-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03357, current rewards: 27.51032, mean: 0.10581
[32m[0906 17-00-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03356, current rewards: 33.02114, mean: 0.10652
[32m[0906 17-00-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03357, current rewards: 38.53050, mean: 0.10703
[32m[0906 17-00-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03345, current rewards: 42.90185, mean: 0.10464
[32m[0906 17-00-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03339, current rewards: 48.42340, mean: 0.10527
[32m[0906 17-00-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03333, current rewards: 53.94346, mean: 0.10577
[32m[0906 17-00-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03326, current rewards: 59.46669, mean: 0.10619
[32m[0906 17-00-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03321, current rewards: 65.05436, mean: 0.10665
[32m[0906 17-00-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03315, current rewards: 70.58170, mean: 0.10694
[32m[0906 17-00-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03310, current rewards: 76.11281, mean: 0.10720
[32m[0906 17-00-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03307, current rewards: 81.64197, mean: 0.10742
[32m[0906 17-00-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03306, current rewards: 87.17681, mean: 0.10763
[32m[0906 17-00-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03305, current rewards: 92.70530, mean: 0.10780
[32m[0906 17-00-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03303, current rewards: 98.23638, mean: 0.10795
[32m[0906 17-00-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03301, current rewards: 102.67334, mean: 0.10695
[32m[0906 17-00-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03299, current rewards: 108.07153, mean: 0.10700
[32m[0906 17-00-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03297, current rewards: 113.60637, mean: 0.10718
[32m[0906 17-00-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03296, current rewards: 119.13648, mean: 0.10733
[32m[0906 17-00-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03294, current rewards: 124.66103, mean: 0.10747
[32m[0906 17-00-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03292, current rewards: 130.19158, mean: 0.10760
[32m[0906 17-00-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03292, current rewards: 135.71828, mean: 0.10771
[32m[0906 17-00-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03289, current rewards: 141.24759, mean: 0.10782
[32m[0906 17-00-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03289, current rewards: 146.77920, mean: 0.10793
[32m[0906 17-00-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03288, current rewards: 152.30443, mean: 0.10802
[32m[0906 17-00-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03287, current rewards: 157.84643, mean: 0.10811
[32m[0906 17-00-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03286, current rewards: 163.39769, mean: 0.10821
[32m[0906 17-00-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03285, current rewards: 168.94191, mean: 0.10830
[32m[0906 17-00-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03285, current rewards: 174.48960, mean: 0.10838
[32m[0906 17-00-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03284, current rewards: 180.03449, mean: 0.10845
[32m[0906 17-00-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03285, current rewards: 185.57373, mean: 0.10852
[32m[0906 17-00-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03284, current rewards: 189.03709, mean: 0.10741
[32m[0906 17-00-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03284, current rewards: 194.68494, mean: 0.10756
[32m[0906 17-00-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03284, current rewards: 200.36355, mean: 0.10772
[32m[0906 17-00-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03287, current rewards: 205.89943, mean: 0.10780
[32m[0906 17-00-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03289, current rewards: 211.43662, mean: 0.10788
[32m[0906 17-01-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03291, current rewards: 216.97418, mean: 0.10795
[32m[0906 17-01-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03294, current rewards: 222.50908, mean: 0.10801
[32m[0906 17-01-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03297, current rewards: 228.04245, mean: 0.10808
[32m[0906 17-01-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03301, current rewards: 233.57531, mean: 0.10814
[32m[0906 17-01-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03304, current rewards: 237.07804, mean: 0.10728
[32m[0906 17-01-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03307, current rewards: 241.98523, mean: 0.10707
[32m[0906 17-01-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03311, current rewards: 247.56094, mean: 0.10717
[32m[0906 17-01-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03314, current rewards: 253.13465, mean: 0.10726
[32m[0906 17-01-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03317, current rewards: 258.71080, mean: 0.10735
[32m[0906 17-01-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03319, current rewards: 263.10900, mean: 0.10695
[32m[0906 17-01-17 @Agent.py:117][0m Average action selection time: 0.0332
[32m[0906 17-01-17 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-01-17 @MBExp.py:227][0m Rewards obtained: [267.50953656132015], Lows: [3], Highs: [4], Total time: 6383.682498999998
[32m[0906 17-03-50 @MBExp.py:144][0m ####################################################################
[32m[0906 17-03-50 @MBExp.py:145][0m Starting training iteration 75.
[32m[0906 17-03-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03254, current rewards: 1.29126, mean: 0.12913
[32m[0906 17-03-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03320, current rewards: 6.83085, mean: 0.11385
[32m[0906 17-03-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03334, current rewards: 12.77354, mean: 0.11612
[32m[0906 17-03-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03341, current rewards: 18.71720, mean: 0.11698
[32m[0906 17-03-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03346, current rewards: 24.64741, mean: 0.11737
[32m[0906 17-03-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03350, current rewards: 30.59195, mean: 0.11766
[32m[0906 17-04-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03349, current rewards: 36.53281, mean: 0.11785
[32m[0906 17-04-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03351, current rewards: 42.47931, mean: 0.11800
[32m[0906 17-04-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03338, current rewards: 48.42875, mean: 0.11812
[32m[0906 17-04-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03328, current rewards: 54.37172, mean: 0.11820
[32m[0906 17-04-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03325, current rewards: 60.31240, mean: 0.11826
[32m[0906 17-04-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03319, current rewards: 66.25863, mean: 0.11832
[32m[0906 17-04-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03313, current rewards: 69.22553, mean: 0.11348
[32m[0906 17-04-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03310, current rewards: 74.75715, mean: 0.11327
[32m[0906 17-04-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03307, current rewards: 80.29025, mean: 0.11308
[32m[0906 17-04-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03303, current rewards: 85.82148, mean: 0.11292
[32m[0906 17-04-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03300, current rewards: 91.35609, mean: 0.11279
[32m[0906 17-04-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03298, current rewards: 96.89465, mean: 0.11267
[32m[0906 17-04-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03295, current rewards: 102.43219, mean: 0.11256
[32m[0906 17-04-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03292, current rewards: 105.96257, mean: 0.11038
[32m[0906 17-04-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03290, current rewards: 111.39128, mean: 0.11029
[32m[0906 17-04-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03289, current rewards: 116.78450, mean: 0.11017
[32m[0906 17-04-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03288, current rewards: 122.28167, mean: 0.11016
[32m[0906 17-04-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03286, current rewards: 127.78159, mean: 0.11016
[32m[0906 17-04-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03285, current rewards: 130.09868, mean: 0.10752
[32m[0906 17-04-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03284, current rewards: 135.62709, mean: 0.10764
[32m[0906 17-04-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03283, current rewards: 141.15600, mean: 0.10775
[32m[0906 17-04-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03282, current rewards: 146.68465, mean: 0.10786
[32m[0906 17-04-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03281, current rewards: 152.21172, mean: 0.10795
[32m[0906 17-04-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03281, current rewards: 157.75276, mean: 0.10805
[32m[0906 17-04-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03281, current rewards: 163.27992, mean: 0.10813
[32m[0906 17-04-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03280, current rewards: 168.80541, mean: 0.10821
[32m[0906 17-04-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03279, current rewards: 172.20981, mean: 0.10696
[32m[0906 17-04-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03278, current rewards: 177.73116, mean: 0.10707
[32m[0906 17-04-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03277, current rewards: 183.25891, mean: 0.10717
[32m[0906 17-04-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03278, current rewards: 188.78335, mean: 0.10726
[32m[0906 17-04-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03277, current rewards: 194.30595, mean: 0.10735
[32m[0906 17-04-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03277, current rewards: 199.84572, mean: 0.10744
[32m[0906 17-04-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03276, current rewards: 205.36698, mean: 0.10752
[32m[0906 17-04-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03279, current rewards: 210.88955, mean: 0.10760
[32m[0906 17-04-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03281, current rewards: 216.41323, mean: 0.10767
[32m[0906 17-04-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03283, current rewards: 221.94019, mean: 0.10774
[32m[0906 17-05-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03286, current rewards: 227.46784, mean: 0.10780
[32m[0906 17-05-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03289, current rewards: 230.78720, mean: 0.10685
[32m[0906 17-05-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03293, current rewards: 235.95230, mean: 0.10677
[32m[0906 17-05-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03296, current rewards: 241.24105, mean: 0.10674
[32m[0906 17-05-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03300, current rewards: 246.35458, mean: 0.10665
[32m[0906 17-05-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03303, current rewards: 251.46968, mean: 0.10655
[32m[0906 17-05-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03306, current rewards: 256.58551, mean: 0.10647
[32m[0906 17-05-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03309, current rewards: 261.70088, mean: 0.10638
[32m[0906 17-05-14 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 17-05-14 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-05-14 @MBExp.py:227][0m Rewards obtained: [265.7956033838899], Lows: [4], Highs: [4], Total time: 6467.177454999997
[32m[0906 17-07-50 @MBExp.py:144][0m ####################################################################
[32m[0906 17-07-50 @MBExp.py:145][0m Starting training iteration 76.
[32m[0906 17-07-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03247, current rewards: -0.05139, mean: -0.00514
[32m[0906 17-07-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03370, current rewards: 5.57063, mean: 0.09284
[32m[0906 17-07-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03361, current rewards: 11.19346, mean: 0.10176
[32m[0906 17-07-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03362, current rewards: 16.97233, mean: 0.10608
[32m[0906 17-07-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03362, current rewards: 22.62715, mean: 0.10775
[32m[0906 17-07-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03363, current rewards: 28.24931, mean: 0.10865
[32m[0906 17-08-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03359, current rewards: 33.87035, mean: 0.10926
[32m[0906 17-08-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03348, current rewards: 39.50020, mean: 0.10972
[32m[0906 17-08-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03338, current rewards: 45.12400, mean: 0.11006
[32m[0906 17-08-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03330, current rewards: 50.75051, mean: 0.11033
[32m[0906 17-08-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03321, current rewards: 56.37725, mean: 0.11054
[32m[0906 17-08-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03316, current rewards: 61.95778, mean: 0.11064
[32m[0906 17-08-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03313, current rewards: 67.67942, mean: 0.11095
[32m[0906 17-08-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03306, current rewards: 73.49553, mean: 0.11136
[32m[0906 17-08-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03301, current rewards: 79.30709, mean: 0.11170
[32m[0906 17-08-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03301, current rewards: 85.10743, mean: 0.11198
[32m[0906 17-08-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03298, current rewards: 90.91645, mean: 0.11224
[32m[0906 17-08-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03296, current rewards: 96.72515, mean: 0.11247
[32m[0906 17-08-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03295, current rewards: 102.52707, mean: 0.11267
[32m[0906 17-08-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03293, current rewards: 108.33557, mean: 0.11285
[32m[0906 17-08-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03293, current rewards: 114.02404, mean: 0.11290
[32m[0906 17-08-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03291, current rewards: 119.83334, mean: 0.11305
[32m[0906 17-08-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03292, current rewards: 125.63450, mean: 0.11318
[32m[0906 17-08-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03290, current rewards: 131.43381, mean: 0.11331
[32m[0906 17-08-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03288, current rewards: 137.23430, mean: 0.11342
[32m[0906 17-08-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03288, current rewards: 142.87060, mean: 0.11339
[32m[0906 17-08-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03288, current rewards: 148.51312, mean: 0.11337
[32m[0906 17-08-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03286, current rewards: 154.15926, mean: 0.11335
[32m[0906 17-08-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03286, current rewards: 159.92581, mean: 0.11342
[32m[0906 17-08-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03285, current rewards: 165.57622, mean: 0.11341
[32m[0906 17-08-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03285, current rewards: 171.22282, mean: 0.11339
[32m[0906 17-08-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03285, current rewards: 176.86523, mean: 0.11338
[32m[0906 17-08-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03284, current rewards: 182.51139, mean: 0.11336
[32m[0906 17-08-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03285, current rewards: 186.06119, mean: 0.11209
[32m[0906 17-08-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03285, current rewards: 191.56847, mean: 0.11203
[32m[0906 17-08-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03284, current rewards: 197.07806, mean: 0.11198
[32m[0906 17-08-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03284, current rewards: 202.52005, mean: 0.11189
[32m[0906 17-08-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03283, current rewards: 208.06317, mean: 0.11186
[32m[0906 17-08-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03283, current rewards: 213.67446, mean: 0.11187
[32m[0906 17-08-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03283, current rewards: 219.28452, mean: 0.11188
[32m[0906 17-08-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03285, current rewards: 219.99095, mean: 0.10945
[32m[0906 17-08-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03287, current rewards: 225.55199, mean: 0.10949
[32m[0906 17-08-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03288, current rewards: 231.12254, mean: 0.10954
[32m[0906 17-09-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03292, current rewards: 236.68764, mean: 0.10958
[32m[0906 17-09-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03296, current rewards: 242.24947, mean: 0.10962
[32m[0906 17-09-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03299, current rewards: 247.99771, mean: 0.10973
[32m[0906 17-09-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03302, current rewards: 253.63760, mean: 0.10980
[32m[0906 17-09-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03306, current rewards: 259.27066, mean: 0.10986
[32m[0906 17-09-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03309, current rewards: 264.90456, mean: 0.10992
[32m[0906 17-09-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03312, current rewards: 270.53364, mean: 0.10997
[32m[0906 17-09-13 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 17-09-13 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-09-13 @MBExp.py:227][0m Rewards obtained: [275.0398812955277], Lows: [3], Highs: [2], Total time: 6550.753387999997
[32m[0906 17-11-51 @MBExp.py:144][0m ####################################################################
[32m[0906 17-11-51 @MBExp.py:145][0m Starting training iteration 77.
[32m[0906 17-11-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03248, current rewards: 1.14853, mean: 0.11485
[32m[0906 17-11-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03345, current rewards: 6.77578, mean: 0.11293
[32m[0906 17-11-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03350, current rewards: 12.48282, mean: 0.11348
[32m[0906 17-11-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03354, current rewards: 18.19104, mean: 0.11369
[32m[0906 17-11-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03360, current rewards: 23.89537, mean: 0.11379
[32m[0906 17-12-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03359, current rewards: 28.49170, mean: 0.10958
[32m[0906 17-12-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03358, current rewards: 32.82768, mean: 0.10590
[32m[0906 17-12-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03345, current rewards: 38.28230, mean: 0.10634
[32m[0906 17-12-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03339, current rewards: 43.74774, mean: 0.10670
[32m[0906 17-12-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03330, current rewards: 49.21095, mean: 0.10698
[32m[0906 17-12-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03325, current rewards: 54.66754, mean: 0.10719
[32m[0906 17-12-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03321, current rewards: 60.12647, mean: 0.10737
[32m[0906 17-12-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03315, current rewards: 65.58721, mean: 0.10752
[32m[0906 17-12-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03310, current rewards: 71.04571, mean: 0.10765
[32m[0906 17-12-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03307, current rewards: 76.50651, mean: 0.10776
[32m[0906 17-12-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03304, current rewards: 81.96538, mean: 0.10785
[32m[0906 17-12-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03302, current rewards: 87.42390, mean: 0.10793
[32m[0906 17-12-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03300, current rewards: 92.88480, mean: 0.10801
[32m[0906 17-12-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03298, current rewards: 96.27045, mean: 0.10579
[32m[0906 17-12-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03297, current rewards: 101.87604, mean: 0.10612
[32m[0906 17-12-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03295, current rewards: 107.40815, mean: 0.10634
[32m[0906 17-12-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03293, current rewards: 112.91605, mean: 0.10652
[32m[0906 17-12-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03294, current rewards: 118.42815, mean: 0.10669
[32m[0906 17-12-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03291, current rewards: 123.93800, mean: 0.10684
[32m[0906 17-12-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03290, current rewards: 129.44263, mean: 0.10698
[32m[0906 17-12-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03289, current rewards: 134.95316, mean: 0.10711
[32m[0906 17-12-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03288, current rewards: 140.45923, mean: 0.10722
[32m[0906 17-12-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03287, current rewards: 145.97009, mean: 0.10733
[32m[0906 17-12-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03286, current rewards: 151.44450, mean: 0.10741
[32m[0906 17-12-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03286, current rewards: 155.79209, mean: 0.10671
[32m[0906 17-12-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03286, current rewards: 161.33235, mean: 0.10684
[32m[0906 17-12-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03285, current rewards: 166.85936, mean: 0.10696
[32m[0906 17-12-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03285, current rewards: 172.38679, mean: 0.10707
[32m[0906 17-12-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03285, current rewards: 177.91608, mean: 0.10718
[32m[0906 17-12-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03285, current rewards: 183.44499, mean: 0.10728
[32m[0906 17-12-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03285, current rewards: 188.97741, mean: 0.10737
[32m[0906 17-12-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03284, current rewards: 194.54711, mean: 0.10748
[32m[0906 17-12-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03284, current rewards: 200.07666, mean: 0.10757
[32m[0906 17-12-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03285, current rewards: 205.49899, mean: 0.10759
[32m[0906 17-12-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03285, current rewards: 210.97511, mean: 0.10764
[32m[0906 17-12-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03285, current rewards: 216.45113, mean: 0.10769
[32m[0906 17-12-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03287, current rewards: 221.93038, mean: 0.10773
[32m[0906 17-13-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03290, current rewards: 227.39965, mean: 0.10777
[32m[0906 17-13-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03292, current rewards: 231.75876, mean: 0.10730
[32m[0906 17-13-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03296, current rewards: 237.20211, mean: 0.10733
[32m[0906 17-13-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03299, current rewards: 242.64960, mean: 0.10737
[32m[0906 17-13-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03303, current rewards: 248.09024, mean: 0.10740
[32m[0906 17-13-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03306, current rewards: 253.53715, mean: 0.10743
[32m[0906 17-13-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03309, current rewards: 258.97876, mean: 0.10746
[32m[0906 17-13-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03311, current rewards: 264.41783, mean: 0.10749
[32m[0906 17-13-14 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 17-13-14 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-13-14 @MBExp.py:227][0m Rewards obtained: [268.7717257819318], Lows: [1], Highs: [4], Total time: 6634.318336999997
[32m[0906 17-15-54 @MBExp.py:144][0m ####################################################################
[32m[0906 17-15-54 @MBExp.py:145][0m Starting training iteration 78.
[32m[0906 17-15-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03228, current rewards: -2.15046, mean: -0.21505
[32m[0906 17-15-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03317, current rewards: 3.41863, mean: 0.05698
[32m[0906 17-15-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03340, current rewards: 9.23449, mean: 0.08395
[32m[0906 17-16-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03339, current rewards: 14.93196, mean: 0.09332
[32m[0906 17-16-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03355, current rewards: 20.61001, mean: 0.09814
[32m[0906 17-16-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03354, current rewards: 22.23345, mean: 0.08551
[32m[0906 17-16-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03356, current rewards: 29.33000, mean: 0.09461
[32m[0906 17-16-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03338, current rewards: 36.42655, mean: 0.10118
[32m[0906 17-16-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03333, current rewards: 43.52310, mean: 0.10615
[32m[0906 17-16-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03323, current rewards: 50.61965, mean: 0.11004
[32m[0906 17-16-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03317, current rewards: 57.71620, mean: 0.11317
[32m[0906 17-16-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03312, current rewards: 34.80699, mean: 0.06216
[32m[0906 17-16-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03308, current rewards: -15.19301, mean: -0.02491
[32m[0906 17-16-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03303, current rewards: -65.19301, mean: -0.09878
[32m[0906 17-16-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03301, current rewards: -115.19301, mean: -0.16224
[32m[0906 17-16-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03298, current rewards: -165.19301, mean: -0.21736
[32m[0906 17-16-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03298, current rewards: -215.19301, mean: -0.26567
[32m[0906 17-16-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03295, current rewards: -265.19301, mean: -0.30836
[32m[0906 17-16-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03292, current rewards: -315.19301, mean: -0.34637
[32m[0906 17-16-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03291, current rewards: -365.19301, mean: -0.38041
[32m[0906 17-16-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03289, current rewards: -415.19301, mean: -0.41108
[32m[0906 17-16-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03289, current rewards: -465.19301, mean: -0.43886
[32m[0906 17-16-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03287, current rewards: -515.19301, mean: -0.46414
[32m[0906 17-16-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03286, current rewards: -565.19301, mean: -0.48724
[32m[0906 17-16-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03285, current rewards: -615.19301, mean: -0.50842
[32m[0906 17-16-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03285, current rewards: -665.19301, mean: -0.52793
[32m[0906 17-16-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03282, current rewards: -715.19301, mean: -0.54595
[32m[0906 17-16-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03281, current rewards: -765.19301, mean: -0.56264
[32m[0906 17-16-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03280, current rewards: -815.19301, mean: -0.57815
[32m[0906 17-16-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03278, current rewards: -865.19301, mean: -0.59260
[32m[0906 17-16-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03277, current rewards: -915.19301, mean: -0.60609
[32m[0906 17-16-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03277, current rewards: -965.19301, mean: -0.61871
[32m[0906 17-16-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03276, current rewards: -1015.19301, mean: -0.63055
[32m[0906 17-16-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03276, current rewards: -1065.19301, mean: -0.64168
[32m[0906 17-16-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03276, current rewards: -1115.19301, mean: -0.65216
[32m[0906 17-16-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03276, current rewards: -1165.19301, mean: -0.66204
[32m[0906 17-16-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03275, current rewards: -1215.19301, mean: -0.67138
[32m[0906 17-16-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03275, current rewards: -1265.19301, mean: -0.68021
[32m[0906 17-16-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03275, current rewards: -1315.19301, mean: -0.68858
[32m[0906 17-16-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03275, current rewards: -1365.19301, mean: -0.69653
[32m[0906 17-17-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03274, current rewards: -1415.19301, mean: -0.70408
[32m[0906 17-17-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03276, current rewards: -1465.19301, mean: -0.71126
[32m[0906 17-17-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03277, current rewards: -1515.19301, mean: -0.71810
[32m[0906 17-17-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03279, current rewards: -1565.19301, mean: -0.72463
[32m[0906 17-17-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03281, current rewards: -1615.19301, mean: -0.73086
[32m[0906 17-17-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03284, current rewards: -1665.19301, mean: -0.73681
[32m[0906 17-17-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03287, current rewards: -1715.19301, mean: -0.74251
[32m[0906 17-17-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03291, current rewards: -1765.19301, mean: -0.74796
[32m[0906 17-17-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03294, current rewards: -1815.19301, mean: -0.75319
[32m[0906 17-17-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03297, current rewards: -1865.19301, mean: -0.75821
[32m[0906 17-17-17 @Agent.py:117][0m Average action selection time: 0.0330
[32m[0906 17-17-17 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-17-18 @MBExp.py:227][0m Rewards obtained: [-1905.193006527611], Lows: [3], Highs: [1966], Total time: 6717.525985999997
[32m[0906 17-19-59 @MBExp.py:144][0m ####################################################################
[32m[0906 17-19-59 @MBExp.py:145][0m Starting training iteration 79.
[32m[0906 17-19-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03234, current rewards: -0.15772, mean: -0.01577
[32m[0906 17-20-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03353, current rewards: 5.37661, mean: 0.08961
[32m[0906 17-20-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03360, current rewards: 10.94316, mean: 0.09948
[32m[0906 17-20-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03357, current rewards: 16.46954, mean: 0.10293
[32m[0906 17-20-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03354, current rewards: 22.02956, mean: 0.10490
[32m[0906 17-20-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03357, current rewards: 27.59235, mean: 0.10612
[32m[0906 17-20-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03357, current rewards: 33.15214, mean: 0.10694
[32m[0906 17-20-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03344, current rewards: 37.71996, mean: 0.10478
[32m[0906 17-20-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03327, current rewards: 43.30118, mean: 0.10561
[32m[0906 17-20-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03321, current rewards: 48.88318, mean: 0.10627
[32m[0906 17-20-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03316, current rewards: 54.45742, mean: 0.10678
[32m[0906 17-20-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03311, current rewards: 57.88405, mean: 0.10336
[32m[0906 17-20-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03308, current rewards: 63.43953, mean: 0.10400
[32m[0906 17-20-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03303, current rewards: 68.99014, mean: 0.10453
[32m[0906 17-20-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03300, current rewards: 74.54554, mean: 0.10499
[32m[0906 17-20-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03297, current rewards: 80.09719, mean: 0.10539
[32m[0906 17-20-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03295, current rewards: 85.65020, mean: 0.10574
[32m[0906 17-20-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03292, current rewards: 91.20267, mean: 0.10605
[32m[0906 17-20-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03289, current rewards: 95.17626, mean: 0.10459
[32m[0906 17-20-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03288, current rewards: 100.88745, mean: 0.10509
[32m[0906 17-20-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03286, current rewards: 107.91014, mean: 0.10684
[32m[0906 17-20-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03284, current rewards: 115.00669, mean: 0.10850
[32m[0906 17-20-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03283, current rewards: 122.10324, mean: 0.11000
[32m[0906 17-20-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03281, current rewards: 129.19979, mean: 0.11138
[32m[0906 17-20-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03280, current rewards: 136.29634, mean: 0.11264
[32m[0906 17-20-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03280, current rewards: 93.14793, mean: 0.07393
[32m[0906 17-20-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03279, current rewards: 43.14793, mean: 0.03294
[32m[0906 17-20-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03278, current rewards: -6.85207, mean: -0.00504
[32m[0906 17-20-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03277, current rewards: -56.85207, mean: -0.04032
[32m[0906 17-20-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03277, current rewards: -106.85207, mean: -0.07319
[32m[0906 17-20-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03276, current rewards: -156.85207, mean: -0.10388
[32m[0906 17-20-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03276, current rewards: -206.85207, mean: -0.13260
[32m[0906 17-20-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03276, current rewards: -256.85207, mean: -0.15954
[32m[0906 17-20-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03275, current rewards: -306.85207, mean: -0.18485
[32m[0906 17-20-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03275, current rewards: -356.85207, mean: -0.20869
[32m[0906 17-20-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03275, current rewards: -406.85207, mean: -0.23117
[32m[0906 17-20-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03274, current rewards: -456.85207, mean: -0.25240
[32m[0906 17-21-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03274, current rewards: -506.85207, mean: -0.27250
[32m[0906 17-21-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03273, current rewards: -556.85207, mean: -0.29155
[32m[0906 17-21-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03273, current rewards: -606.85207, mean: -0.30962
[32m[0906 17-21-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03272, current rewards: -656.85207, mean: -0.32679
[32m[0906 17-21-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03272, current rewards: -706.85207, mean: -0.34313
[32m[0906 17-21-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03272, current rewards: -756.85207, mean: -0.35870
[32m[0906 17-21-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03275, current rewards: -806.85207, mean: -0.37354
[32m[0906 17-21-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03277, current rewards: -855.78249, mean: -0.38723
[32m[0906 17-21-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03279, current rewards: -853.17949, mean: -0.37751
[32m[0906 17-21-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03281, current rewards: -850.70941, mean: -0.36827
[32m[0906 17-21-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03283, current rewards: -848.23934, mean: -0.35942
[32m[0906 17-21-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03286, current rewards: -845.76926, mean: -0.35094
[32m[0906 17-21-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03290, current rewards: -843.29918, mean: -0.34280
[32m[0906 17-21-22 @Agent.py:117][0m Average action selection time: 0.0329
[32m[0906 17-21-22 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-21-22 @MBExp.py:227][0m Rewards obtained: [-848.6689331018046], Lows: [2], Highs: [1002], Total time: 6800.568725999997
[32m[0906 17-24-06 @MBExp.py:144][0m ####################################################################
[32m[0906 17-24-06 @MBExp.py:145][0m Starting training iteration 80.
[32m[0906 17-24-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03340, current rewards: 0.10412, mean: 0.01041
[32m[0906 17-24-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03363, current rewards: 5.65302, mean: 0.09422
[32m[0906 17-24-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03358, current rewards: 11.19206, mean: 0.10175
[32m[0906 17-24-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03361, current rewards: 16.55428, mean: 0.10346
[32m[0906 17-24-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03356, current rewards: 20.00698, mean: 0.09527
[32m[0906 17-24-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03356, current rewards: 25.02095, mean: 0.09623
[32m[0906 17-24-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03357, current rewards: 30.03539, mean: 0.09689
[32m[0906 17-24-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03341, current rewards: 35.04937, mean: 0.09736
[32m[0906 17-24-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03331, current rewards: 40.06435, mean: 0.09772
[32m[0906 17-24-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03326, current rewards: 45.07676, mean: 0.09799
[32m[0906 17-24-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03319, current rewards: 50.09286, mean: 0.09822
[32m[0906 17-24-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03315, current rewards: 55.10891, mean: 0.09841
[32m[0906 17-24-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03311, current rewards: 60.12573, mean: 0.09857
[32m[0906 17-24-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03307, current rewards: 65.13816, mean: 0.09869
[32m[0906 17-24-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03304, current rewards: 70.15467, mean: 0.09881
[32m[0906 17-24-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03301, current rewards: 75.16634, mean: 0.09890
[32m[0906 17-24-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03299, current rewards: 79.37842, mean: 0.09800
[32m[0906 17-24-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03298, current rewards: 84.86713, mean: 0.09868
[32m[0906 17-24-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03294, current rewards: 90.35941, mean: 0.09930
[32m[0906 17-24-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03293, current rewards: 95.85794, mean: 0.09985
[32m[0906 17-24-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03292, current rewards: 101.35336, mean: 0.10035
[32m[0906 17-24-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03290, current rewards: 106.84579, mean: 0.10080
[32m[0906 17-24-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03289, current rewards: 112.34307, mean: 0.10121
[32m[0906 17-24-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03288, current rewards: 117.83868, mean: 0.10159
[32m[0906 17-24-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03287, current rewards: 123.33403, mean: 0.10193
[32m[0906 17-24-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03285, current rewards: 128.82733, mean: 0.10224
[32m[0906 17-24-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03285, current rewards: 134.32229, mean: 0.10254
[32m[0906 17-24-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03284, current rewards: 139.84934, mean: 0.10283
[32m[0906 17-24-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03283, current rewards: 145.34634, mean: 0.10308
[32m[0906 17-24-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03282, current rewards: 150.84409, mean: 0.10332
[32m[0906 17-24-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03282, current rewards: 156.33928, mean: 0.10354
[32m[0906 17-24-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03281, current rewards: 158.93080, mean: 0.10188
[32m[0906 17-24-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03280, current rewards: 164.46527, mean: 0.10215
[32m[0906 17-25-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03280, current rewards: 169.99392, mean: 0.10241
[32m[0906 17-25-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03279, current rewards: 175.53214, mean: 0.10265
[32m[0906 17-25-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03279, current rewards: 181.06497, mean: 0.10288
[32m[0906 17-25-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03278, current rewards: 186.55823, mean: 0.10307
[32m[0906 17-25-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03279, current rewards: 192.81119, mean: 0.10366
[32m[0906 17-25-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03279, current rewards: 198.35719, mean: 0.10385
[32m[0906 17-25-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03279, current rewards: 203.90465, mean: 0.10403
[32m[0906 17-25-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03278, current rewards: 209.44988, mean: 0.10420
[32m[0906 17-25-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03278, current rewards: 214.99402, mean: 0.10437
[32m[0906 17-25-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03278, current rewards: 220.53737, mean: 0.10452
[32m[0906 17-25-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03278, current rewards: 226.08338, mean: 0.10467
[32m[0906 17-25-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03280, current rewards: 231.71414, mean: 0.10485
[32m[0906 17-25-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03282, current rewards: 235.13833, mean: 0.10404
[32m[0906 17-25-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03284, current rewards: 240.65773, mean: 0.10418
[32m[0906 17-25-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03285, current rewards: 246.17670, mean: 0.10431
[32m[0906 17-25-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03289, current rewards: 251.69842, mean: 0.10444
[32m[0906 17-25-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03292, current rewards: 257.22098, mean: 0.10456
[32m[0906 17-25-29 @Agent.py:117][0m Average action selection time: 0.0329
[32m[0906 17-25-29 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-25-29 @MBExp.py:227][0m Rewards obtained: [261.63989608782583], Lows: [3], Highs: [3], Total time: 6883.647684999997
[32m[0906 17-28-15 @MBExp.py:144][0m ####################################################################
[32m[0906 17-28-15 @MBExp.py:145][0m Starting training iteration 81.
[32m[0906 17-28-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03196, current rewards: -1.87900, mean: -0.18790
[32m[0906 17-28-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03334, current rewards: 3.57205, mean: 0.05953
[32m[0906 17-28-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03345, current rewards: 9.16127, mean: 0.08328
[32m[0906 17-28-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03341, current rewards: 14.61495, mean: 0.09134
[32m[0906 17-28-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03341, current rewards: 20.07217, mean: 0.09558
[32m[0906 17-28-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03345, current rewards: 25.52790, mean: 0.09818
[32m[0906 17-28-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03345, current rewards: 30.98197, mean: 0.09994
[32m[0906 17-28-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03333, current rewards: 36.43732, mean: 0.10121
[32m[0906 17-28-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03329, current rewards: 41.88880, mean: 0.10217
[32m[0906 17-28-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03320, current rewards: 43.15028, mean: 0.09380
[32m[0906 17-28-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03315, current rewards: 48.50349, mean: 0.09510
[32m[0906 17-28-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03310, current rewards: 53.99742, mean: 0.09642
[32m[0906 17-28-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03307, current rewards: 59.50723, mean: 0.09755
[32m[0906 17-28-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03300, current rewards: 65.01454, mean: 0.09851
[32m[0906 17-28-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03297, current rewards: 70.52509, mean: 0.09933
[32m[0906 17-28-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03292, current rewards: 76.03052, mean: 0.10004
[32m[0906 17-28-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03289, current rewards: 81.53469, mean: 0.10066
[32m[0906 17-28-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03287, current rewards: 87.04248, mean: 0.10121
[32m[0906 17-28-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03285, current rewards: 91.23753, mean: 0.10026
[32m[0906 17-28-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03284, current rewards: 97.50727, mean: 0.10157
[32m[0906 17-28-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03284, current rewards: 103.53238, mean: 0.10251
[32m[0906 17-28-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03284, current rewards: 109.56644, mean: 0.10336
[32m[0906 17-28-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03282, current rewards: 113.20108, mean: 0.10198
[32m[0906 17-28-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03281, current rewards: 118.68993, mean: 0.10232
[32m[0906 17-28-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03281, current rewards: 124.17455, mean: 0.10262
[32m[0906 17-28-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03280, current rewards: 129.65864, mean: 0.10290
[32m[0906 17-28-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03280, current rewards: 135.14249, mean: 0.10316
[32m[0906 17-29-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03279, current rewards: 140.63013, mean: 0.10340
[32m[0906 17-29-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03279, current rewards: 146.11222, mean: 0.10363
[32m[0906 17-29-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03280, current rewards: 147.37553, mean: 0.10094
[32m[0906 17-29-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03279, current rewards: 152.85141, mean: 0.10123
[32m[0906 17-29-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03279, current rewards: 158.32655, mean: 0.10149
[32m[0906 17-29-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03278, current rewards: 163.79884, mean: 0.10174
[32m[0906 17-29-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03277, current rewards: 169.27140, mean: 0.10197
[32m[0906 17-29-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03276, current rewards: 174.73771, mean: 0.10219
[32m[0906 17-29-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03276, current rewards: 180.26303, mean: 0.10242
[32m[0906 17-29-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03275, current rewards: 185.74616, mean: 0.10262
[32m[0906 17-29-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03275, current rewards: 191.23546, mean: 0.10281
[32m[0906 17-29-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03276, current rewards: 196.72215, mean: 0.10300
[32m[0906 17-29-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03276, current rewards: 201.07863, mean: 0.10259
[32m[0906 17-29-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03276, current rewards: 206.58802, mean: 0.10278
[32m[0906 17-29-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03275, current rewards: 212.10169, mean: 0.10296
[32m[0906 17-29-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03275, current rewards: 217.62008, mean: 0.10314
[32m[0906 17-29-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03275, current rewards: 223.11953, mean: 0.10330
[32m[0906 17-29-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03275, current rewards: 228.63783, mean: 0.10346
[32m[0906 17-29-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03277, current rewards: 234.15099, mean: 0.10361
[32m[0906 17-29-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03280, current rewards: 237.63182, mean: 0.10287
[32m[0906 17-29-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03281, current rewards: 243.14367, mean: 0.10303
[32m[0906 17-29-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03282, current rewards: 248.65604, mean: 0.10318
[32m[0906 17-29-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03286, current rewards: 254.16453, mean: 0.10332
[32m[0906 17-29-38 @Agent.py:117][0m Average action selection time: 0.0329
[32m[0906 17-29-38 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-29-38 @MBExp.py:227][0m Rewards obtained: [258.57331925687015], Lows: [7], Highs: [4], Total time: 6966.594358999997
[32m[0906 17-32-26 @MBExp.py:144][0m ####################################################################
[32m[0906 17-32-26 @MBExp.py:145][0m Starting training iteration 82.
[32m[0906 17-32-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03266, current rewards: -0.11402, mean: -0.01140
[32m[0906 17-32-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03338, current rewards: 5.63026, mean: 0.09384
[32m[0906 17-32-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03347, current rewards: 11.39731, mean: 0.10361
[32m[0906 17-32-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03346, current rewards: 17.21023, mean: 0.10756
[32m[0906 17-32-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03349, current rewards: 22.97687, mean: 0.10941
[32m[0906 17-32-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03344, current rewards: 28.75379, mean: 0.11059
[32m[0906 17-32-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03346, current rewards: 32.48569, mean: 0.10479
[32m[0906 17-32-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03333, current rewards: 38.87402, mean: 0.10798
[32m[0906 17-32-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03325, current rewards: 44.37317, mean: 0.10823
[32m[0906 17-32-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03317, current rewards: 49.85471, mean: 0.10838
[32m[0906 17-32-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03311, current rewards: 53.29744, mean: 0.10450
[32m[0906 17-32-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03305, current rewards: 58.65144, mean: 0.10473
[32m[0906 17-32-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03303, current rewards: 64.01215, mean: 0.10494
[32m[0906 17-32-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03298, current rewards: 69.36877, mean: 0.10510
[32m[0906 17-32-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03296, current rewards: 74.73165, mean: 0.10526
[32m[0906 17-32-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03295, current rewards: 80.09093, mean: 0.10538
[32m[0906 17-32-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03291, current rewards: 85.45158, mean: 0.10550
[32m[0906 17-32-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03289, current rewards: 90.68313, mean: 0.10545
[32m[0906 17-32-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03288, current rewards: 95.92338, mean: 0.10541
[32m[0906 17-32-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03287, current rewards: 101.18260, mean: 0.10540
[32m[0906 17-32-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03285, current rewards: 106.42448, mean: 0.10537
[32m[0906 17-33-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03283, current rewards: 111.67673, mean: 0.10536
[32m[0906 17-33-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03282, current rewards: 111.98604, mean: 0.10089
[32m[0906 17-33-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03282, current rewards: 118.39103, mean: 0.10206
[32m[0906 17-33-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03282, current rewards: 124.83520, mean: 0.10317
[32m[0906 17-33-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03281, current rewards: 131.31269, mean: 0.10422
[32m[0906 17-33-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03280, current rewards: 137.40490, mean: 0.10489
[32m[0906 17-33-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03280, current rewards: 143.46694, mean: 0.10549
[32m[0906 17-33-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03279, current rewards: 149.52417, mean: 0.10605
[32m[0906 17-33-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03278, current rewards: 155.59341, mean: 0.10657
[32m[0906 17-33-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03279, current rewards: 156.95536, mean: 0.10394
[32m[0906 17-33-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03277, current rewards: 162.31137, mean: 0.10405
[32m[0906 17-33-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03277, current rewards: 167.66651, mean: 0.10414
[32m[0906 17-33-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03276, current rewards: 173.01969, mean: 0.10423
[32m[0906 17-33-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03276, current rewards: 178.29706, mean: 0.10427
[32m[0906 17-33-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03275, current rewards: 183.89218, mean: 0.10448
[32m[0906 17-33-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03275, current rewards: 189.48642, mean: 0.10469
[32m[0906 17-33-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03275, current rewards: 195.08487, mean: 0.10488
[32m[0906 17-33-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03275, current rewards: 200.67867, mean: 0.10507
[32m[0906 17-33-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03275, current rewards: 206.27459, mean: 0.10524
[32m[0906 17-33-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03275, current rewards: 211.87216, mean: 0.10541
[32m[0906 17-33-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03275, current rewards: 217.47094, mean: 0.10557
[32m[0906 17-33-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03276, current rewards: 223.31734, mean: 0.10584
[32m[0906 17-33-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03276, current rewards: 231.75899, mean: 0.10730
[32m[0906 17-33-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03276, current rewards: 238.25638, mean: 0.10781
[32m[0906 17-33-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03277, current rewards: 240.68039, mean: 0.10650
[32m[0906 17-33-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03279, current rewards: 243.10440, mean: 0.10524
[32m[0906 17-33-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03282, current rewards: 245.52841, mean: 0.10404
[32m[0906 17-33-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03284, current rewards: 247.95242, mean: 0.10288
[32m[0906 17-33-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03285, current rewards: 250.37643, mean: 0.10178
[32m[0906 17-33-48 @Agent.py:117][0m Average action selection time: 0.0329
[32m[0906 17-33-48 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-33-48 @MBExp.py:227][0m Rewards obtained: [252.31563395902813], Lows: [6], Highs: [2], Total time: 7049.471254999997
[32m[0906 17-36-38 @MBExp.py:144][0m ####################################################################
[32m[0906 17-36-38 @MBExp.py:145][0m Starting training iteration 83.
[32m[0906 17-36-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03335, current rewards: -1.09201, mean: -0.10920
[32m[0906 17-36-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03341, current rewards: 4.50050, mean: 0.07501
[32m[0906 17-36-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03339, current rewards: 10.00645, mean: 0.09097
[32m[0906 17-36-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03347, current rewards: 15.51344, mean: 0.09696
[32m[0906 17-36-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03352, current rewards: 21.02065, mean: 0.10010
[32m[0906 17-36-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03355, current rewards: 26.52586, mean: 0.10202
[32m[0906 17-36-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03356, current rewards: 32.03396, mean: 0.10334
[32m[0906 17-36-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03345, current rewards: 37.54026, mean: 0.10428
[32m[0906 17-36-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03334, current rewards: 43.04669, mean: 0.10499
[32m[0906 17-36-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03324, current rewards: 48.55358, mean: 0.10555
[32m[0906 17-36-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03315, current rewards: 54.05629, mean: 0.10599
[32m[0906 17-36-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03313, current rewards: 59.56204, mean: 0.10636
[32m[0906 17-36-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03306, current rewards: 65.14251, mean: 0.10679
[32m[0906 17-37-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03300, current rewards: 71.02867, mean: 0.10762
[32m[0906 17-37-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03298, current rewards: 76.91772, mean: 0.10833
[32m[0906 17-37-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03296, current rewards: 82.80025, mean: 0.10895
[32m[0906 17-37-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03294, current rewards: 88.68444, mean: 0.10949
[32m[0906 17-37-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03292, current rewards: 94.59908, mean: 0.11000
[32m[0906 17-37-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03291, current rewards: 100.46153, mean: 0.11040
[32m[0906 17-37-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03288, current rewards: 106.32831, mean: 0.11076
[32m[0906 17-37-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03287, current rewards: 107.67113, mean: 0.10661
[32m[0906 17-37-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03287, current rewards: 113.16981, mean: 0.10676
[32m[0906 17-37-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03286, current rewards: 118.67596, mean: 0.10692
[32m[0906 17-37-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03285, current rewards: 124.17834, mean: 0.10705
[32m[0906 17-37-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03285, current rewards: 129.68036, mean: 0.10717
[32m[0906 17-37-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03282, current rewards: 135.23007, mean: 0.10733
[32m[0906 17-37-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03281, current rewards: 140.97917, mean: 0.10762
[32m[0906 17-37-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03281, current rewards: 146.94112, mean: 0.10804
[32m[0906 17-37-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03279, current rewards: 152.89614, mean: 0.10844
[32m[0906 17-37-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03279, current rewards: 158.85922, mean: 0.10881
[32m[0906 17-37-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03278, current rewards: 164.81620, mean: 0.10915
[32m[0906 17-37-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03277, current rewards: 170.58210, mean: 0.10935
[32m[0906 17-37-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03276, current rewards: 175.88597, mean: 0.10925
[32m[0906 17-37-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03276, current rewards: 181.12872, mean: 0.10911
[32m[0906 17-37-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03275, current rewards: 186.57761, mean: 0.10911
[32m[0906 17-37-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03274, current rewards: 192.11901, mean: 0.10916
[32m[0906 17-37-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03274, current rewards: 197.66369, mean: 0.10921
[32m[0906 17-37-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03274, current rewards: 203.21027, mean: 0.10925
[32m[0906 17-37-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03274, current rewards: 208.75750, mean: 0.10930
[32m[0906 17-37-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03274, current rewards: 214.30761, mean: 0.10934
[32m[0906 17-37-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03274, current rewards: 219.85154, mean: 0.10938
[32m[0906 17-37-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03274, current rewards: 225.39292, mean: 0.10941
[32m[0906 17-37-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03274, current rewards: 231.10691, mean: 0.10953
[32m[0906 17-37-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03273, current rewards: 236.41849, mean: 0.10945
[32m[0906 17-37-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03273, current rewards: 237.88875, mean: 0.10764
[32m[0906 17-37-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03273, current rewards: 244.49698, mean: 0.10818
[32m[0906 17-37-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03274, current rewards: 251.10521, mean: 0.10870
[32m[0906 17-37-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03277, current rewards: 257.71345, mean: 0.10920
[32m[0906 17-37-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03278, current rewards: 264.32168, mean: 0.10968
[32m[0906 17-37-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03280, current rewards: 270.92991, mean: 0.11013
[32m[0906 17-38-00 @Agent.py:117][0m Average action selection time: 0.0328
[32m[0906 17-38-00 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-38-01 @MBExp.py:227][0m Rewards obtained: [276.2164988086448], Lows: [4], Highs: [3], Total time: 7132.234745999996
[32m[0906 17-40-53 @MBExp.py:144][0m ####################################################################
[32m[0906 17-40-53 @MBExp.py:145][0m Starting training iteration 84.
[32m[0906 17-40-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03260, current rewards: 0.04606, mean: 0.00461
[32m[0906 17-40-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03320, current rewards: 6.47805, mean: 0.10797
[32m[0906 17-40-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03336, current rewards: 12.90589, mean: 0.11733
[32m[0906 17-40-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03343, current rewards: 19.33349, mean: 0.12083
[32m[0906 17-41-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03337, current rewards: 25.76344, mean: 0.12268
[32m[0906 17-41-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03336, current rewards: 32.18453, mean: 0.12379
[32m[0906 17-41-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03338, current rewards: 38.60746, mean: 0.12454
[32m[0906 17-41-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03326, current rewards: 45.03262, mean: 0.12509
[32m[0906 17-41-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03319, current rewards: 51.44628, mean: 0.12548
[32m[0906 17-41-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03310, current rewards: 57.99001, mean: 0.12607
[32m[0906 17-41-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03305, current rewards: 64.61196, mean: 0.12669
[32m[0906 17-41-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03300, current rewards: 71.21942, mean: 0.12718
[32m[0906 17-41-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03296, current rewards: 77.83740, mean: 0.12760
[32m[0906 17-41-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03291, current rewards: 84.46809, mean: 0.12798
[32m[0906 17-41-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03290, current rewards: 91.07645, mean: 0.12828
[32m[0906 17-41-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03288, current rewards: 96.45450, mean: 0.12691
[32m[0906 17-41-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03287, current rewards: 102.00256, mean: 0.12593
[32m[0906 17-41-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03286, current rewards: 107.72314, mean: 0.12526
[32m[0906 17-41-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03285, current rewards: 113.29874, mean: 0.12450
[32m[0906 17-41-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03284, current rewards: 118.87437, mean: 0.12383
[32m[0906 17-41-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03285, current rewards: 124.45049, mean: 0.12322
[32m[0906 17-41-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03283, current rewards: 130.02727, mean: 0.12267
[32m[0906 17-41-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03281, current rewards: 135.60220, mean: 0.12216
[32m[0906 17-41-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03279, current rewards: 139.10909, mean: 0.11992
[32m[0906 17-41-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03278, current rewards: 144.73829, mean: 0.11962
[32m[0906 17-41-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03277, current rewards: 150.30603, mean: 0.11929
[32m[0906 17-41-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03276, current rewards: 155.93440, mean: 0.11903
[32m[0906 17-41-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03276, current rewards: 161.55917, mean: 0.11879
[32m[0906 17-41-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03275, current rewards: 167.18568, mean: 0.11857
[32m[0906 17-41-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03274, current rewards: 169.06581, mean: 0.11580
[32m[0906 17-41-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03274, current rewards: 176.74078, mean: 0.11705
[32m[0906 17-41-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03273, current rewards: 184.42927, mean: 0.11822
[32m[0906 17-41-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03272, current rewards: 192.10342, mean: 0.11932
[32m[0906 17-41-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03272, current rewards: 200.16487, mean: 0.12058
[32m[0906 17-41-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03270, current rewards: 207.94587, mean: 0.12161
[32m[0906 17-41-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03270, current rewards: 215.73769, mean: 0.12258
[32m[0906 17-41-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03270, current rewards: 223.52881, mean: 0.12350
[32m[0906 17-41-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03269, current rewards: 231.32590, mean: 0.12437
[32m[0906 17-41-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03269, current rewards: 230.79165, mean: 0.12083
[32m[0906 17-41-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03269, current rewards: 236.33521, mean: 0.12058
[32m[0906 17-41-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03269, current rewards: 241.88999, mean: 0.12034
[32m[0906 17-42-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03269, current rewards: 247.49842, mean: 0.12014
[32m[0906 17-42-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03269, current rewards: 253.90362, mean: 0.12033
[32m[0906 17-42-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03269, current rewards: 259.43306, mean: 0.12011
[32m[0906 17-42-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03268, current rewards: 264.96982, mean: 0.11990
[32m[0906 17-42-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03268, current rewards: 270.50920, mean: 0.11969
[32m[0906 17-42-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03268, current rewards: 276.04605, mean: 0.11950
[32m[0906 17-42-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03270, current rewards: 281.58172, mean: 0.11931
[32m[0906 17-42-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03272, current rewards: 287.12129, mean: 0.11914
[32m[0906 17-42-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03274, current rewards: 292.68801, mean: 0.11898
[32m[0906 17-42-15 @Agent.py:117][0m Average action selection time: 0.0328
[32m[0906 17-42-15 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-42-15 @MBExp.py:227][0m Rewards obtained: [297.1171828264392], Lows: [5], Highs: [4], Total time: 7214.832814999996
[32m[0906 17-45-09 @MBExp.py:144][0m ####################################################################
[32m[0906 17-45-09 @MBExp.py:145][0m Starting training iteration 85.
[32m[0906 17-45-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03347, current rewards: -0.18174, mean: -0.01817
[32m[0906 17-45-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03337, current rewards: 5.45572, mean: 0.09093
[32m[0906 17-45-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03345, current rewards: 11.17272, mean: 0.10157
[32m[0906 17-45-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03349, current rewards: 16.89303, mean: 0.10558
[32m[0906 17-45-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03349, current rewards: 22.61178, mean: 0.10768
[32m[0906 17-45-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03348, current rewards: 28.33341, mean: 0.10897
[32m[0906 17-45-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03346, current rewards: 34.05849, mean: 0.10987
[32m[0906 17-45-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03337, current rewards: 39.77817, mean: 0.11049
[32m[0906 17-45-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03329, current rewards: 43.41632, mean: 0.10589
[32m[0906 17-45-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03321, current rewards: 49.10123, mean: 0.10674
[32m[0906 17-45-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03314, current rewards: 54.78333, mean: 0.10742
[32m[0906 17-45-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03312, current rewards: 60.46768, mean: 0.10798
[32m[0906 17-45-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03311, current rewards: 66.15100, mean: 0.10844
[32m[0906 17-45-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03308, current rewards: 71.82851, mean: 0.10883
[32m[0906 17-45-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03304, current rewards: 77.50987, mean: 0.10917
[32m[0906 17-45-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03301, current rewards: 83.18959, mean: 0.10946
[32m[0906 17-45-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03299, current rewards: 88.91846, mean: 0.10978
[32m[0906 17-45-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03297, current rewards: 94.62717, mean: 0.11003
[32m[0906 17-45-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03297, current rewards: 100.34046, mean: 0.11026
[32m[0906 17-45-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03295, current rewards: 106.04975, mean: 0.11047
[32m[0906 17-45-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03293, current rewards: 111.75752, mean: 0.11065
[32m[0906 17-45-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03291, current rewards: 117.46405, mean: 0.11082
[32m[0906 17-45-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03291, current rewards: 123.16792, mean: 0.11096
[32m[0906 17-45-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03289, current rewards: 126.74424, mean: 0.10926
[32m[0906 17-45-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03288, current rewards: 132.47359, mean: 0.10948
[32m[0906 17-45-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03288, current rewards: 138.09541, mean: 0.10960
[32m[0906 17-45-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03287, current rewards: 143.65605, mean: 0.10966
[32m[0906 17-45-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03285, current rewards: 149.21344, mean: 0.10972
[32m[0906 17-45-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03285, current rewards: 150.97509, mean: 0.10707
[32m[0906 17-45-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03284, current rewards: 159.51301, mean: 0.10926
[32m[0906 17-45-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03283, current rewards: 168.05093, mean: 0.11129
[32m[0906 17-46-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03282, current rewards: 176.58885, mean: 0.11320
[32m[0906 17-46-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03281, current rewards: 185.12677, mean: 0.11499
[32m[0906 17-46-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03281, current rewards: 189.36674, mean: 0.11408
[32m[0906 17-46-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03280, current rewards: 192.14724, mean: 0.11237
[32m[0906 17-46-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03279, current rewards: 194.92774, mean: 0.11075
[32m[0906 17-46-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03278, current rewards: 197.70824, mean: 0.10923
[32m[0906 17-46-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03278, current rewards: 200.48874, mean: 0.10779
[32m[0906 17-46-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03277, current rewards: 150.48874, mean: 0.07879
[32m[0906 17-46-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03275, current rewards: 100.48874, mean: 0.05127
[32m[0906 17-46-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03275, current rewards: 50.48874, mean: 0.02512
[32m[0906 17-46-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03275, current rewards: 0.48874, mean: 0.00024
[32m[0906 17-46-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03274, current rewards: -49.51126, mean: -0.02347
[32m[0906 17-46-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03274, current rewards: -99.51126, mean: -0.04607
[32m[0906 17-46-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03273, current rewards: -149.51126, mean: -0.06765
[32m[0906 17-46-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03273, current rewards: -199.51126, mean: -0.08828
[32m[0906 17-46-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03273, current rewards: -249.51126, mean: -0.10801
[32m[0906 17-46-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03274, current rewards: -299.51126, mean: -0.12691
[32m[0906 17-46-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03276, current rewards: -349.51126, mean: -0.14503
[32m[0906 17-46-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03277, current rewards: -399.51126, mean: -0.16240
[32m[0906 17-46-31 @Agent.py:117][0m Average action selection time: 0.0328
[32m[0906 17-46-31 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-46-31 @MBExp.py:227][0m Rewards obtained: [-439.5112637449829], Lows: [4], Highs: [641], Total time: 7297.523790999996
[32m[0906 17-49-27 @MBExp.py:144][0m ####################################################################
[32m[0906 17-49-27 @MBExp.py:145][0m Starting training iteration 86.
[32m[0906 17-49-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03272, current rewards: -2.03561, mean: -0.20356
[32m[0906 17-49-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03340, current rewards: 3.55007, mean: 0.05917
[32m[0906 17-49-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03346, current rewards: 9.10917, mean: 0.08281
[32m[0906 17-49-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03349, current rewards: 14.66627, mean: 0.09166
[32m[0906 17-49-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03350, current rewards: 20.22852, mean: 0.09633
[32m[0906 17-49-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03349, current rewards: 25.78693, mean: 0.09918
[32m[0906 17-49-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03347, current rewards: 31.34485, mean: 0.10111
[32m[0906 17-49-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03338, current rewards: 36.90154, mean: 0.10250
[32m[0906 17-49-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03329, current rewards: 42.40368, mean: 0.10342
[32m[0906 17-49-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03323, current rewards: 46.06880, mean: 0.10015
[32m[0906 17-49-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03316, current rewards: 51.53619, mean: 0.10105
[32m[0906 17-49-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03312, current rewards: 57.00295, mean: 0.10179
[32m[0906 17-49-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03307, current rewards: 62.46677, mean: 0.10240
[32m[0906 17-49-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03304, current rewards: 67.93216, mean: 0.10293
[32m[0906 17-49-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03299, current rewards: 73.39251, mean: 0.10337
[32m[0906 17-49-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03298, current rewards: 77.72659, mean: 0.10227
[32m[0906 17-49-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03297, current rewards: 83.42085, mean: 0.10299
[32m[0906 17-49-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03294, current rewards: 88.97843, mean: 0.10346
[32m[0906 17-49-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03293, current rewards: 94.53307, mean: 0.10388
[32m[0906 17-49-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03291, current rewards: 100.09713, mean: 0.10427
[32m[0906 17-50-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03290, current rewards: 105.65734, mean: 0.10461
[32m[0906 17-50-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03289, current rewards: 111.21596, mean: 0.10492
[32m[0906 17-50-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03288, current rewards: 116.77383, mean: 0.10520
[32m[0906 17-50-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03286, current rewards: 118.42158, mean: 0.10209
[32m[0906 17-50-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03285, current rewards: 122.79823, mean: 0.10149
[32m[0906 17-50-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03285, current rewards: 127.82715, mean: 0.10145
[32m[0906 17-50-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03284, current rewards: 133.22307, mean: 0.10170
[32m[0906 17-50-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03283, current rewards: 138.61544, mean: 0.10192
[32m[0906 17-50-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03282, current rewards: 144.00682, mean: 0.10213
[32m[0906 17-50-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03281, current rewards: 149.39709, mean: 0.10233
[32m[0906 17-50-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03281, current rewards: 154.78859, mean: 0.10251
[32m[0906 17-50-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03280, current rewards: 160.18085, mean: 0.10268
[32m[0906 17-50-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03280, current rewards: 165.59026, mean: 0.10285
[32m[0906 17-50-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03280, current rewards: 169.08320, mean: 0.10186
[32m[0906 17-50-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03279, current rewards: 174.63592, mean: 0.10213
[32m[0906 17-50-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03278, current rewards: 180.18937, mean: 0.10238
[32m[0906 17-50-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03277, current rewards: 185.74841, mean: 0.10262
[32m[0906 17-50-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03277, current rewards: 191.30007, mean: 0.10285
[32m[0906 17-50-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03277, current rewards: 197.61076, mean: 0.10346
[32m[0906 17-50-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03277, current rewards: 203.16812, mean: 0.10366
[32m[0906 17-50-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03276, current rewards: 208.78343, mean: 0.10387
[32m[0906 17-50-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03276, current rewards: 214.33474, mean: 0.10405
[32m[0906 17-50-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03276, current rewards: 219.87775, mean: 0.10421
[32m[0906 17-50-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03276, current rewards: 225.42872, mean: 0.10437
[32m[0906 17-50-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03276, current rewards: 230.98533, mean: 0.10452
[32m[0906 17-50-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03276, current rewards: 236.53626, mean: 0.10466
[32m[0906 17-50-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03276, current rewards: 242.08503, mean: 0.10480
[32m[0906 17-50-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03275, current rewards: 247.63395, mean: 0.10493
[32m[0906 17-50-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03276, current rewards: 253.10182, mean: 0.10502
[32m[0906 17-50-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03278, current rewards: 258.64530, mean: 0.10514
[32m[0906 17-50-50 @Agent.py:117][0m Average action selection time: 0.0328
[32m[0906 17-50-50 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-50-50 @MBExp.py:227][0m Rewards obtained: [263.080436451467], Lows: [4], Highs: [4], Total time: 7380.241537999996
[32m[0906 17-53-48 @MBExp.py:144][0m ####################################################################
[32m[0906 17-53-48 @MBExp.py:145][0m Starting training iteration 87.
[32m[0906 17-53-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03292, current rewards: -0.72093, mean: -0.07209
[32m[0906 17-53-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03351, current rewards: 5.33199, mean: 0.08887
[32m[0906 17-53-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03356, current rewards: 11.38463, mean: 0.10350
[32m[0906 17-53-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03361, current rewards: 17.43295, mean: 0.10896
[32m[0906 17-53-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03364, current rewards: 23.48263, mean: 0.11182
[32m[0906 17-53-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03363, current rewards: 29.53176, mean: 0.11358
[32m[0906 17-53-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03359, current rewards: 35.58372, mean: 0.11479
[32m[0906 17-54-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03349, current rewards: 41.38765, mean: 0.11497
[32m[0906 17-54-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03339, current rewards: 45.92755, mean: 0.11202
[32m[0906 17-54-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03332, current rewards: 51.44378, mean: 0.11183
[32m[0906 17-54-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03326, current rewards: 56.96276, mean: 0.11169
[32m[0906 17-54-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03321, current rewards: 62.48710, mean: 0.11158
[32m[0906 17-54-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03318, current rewards: 68.01332, mean: 0.11150
[32m[0906 17-54-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03315, current rewards: 73.53450, mean: 0.11142
[32m[0906 17-54-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03310, current rewards: 79.05996, mean: 0.11135
[32m[0906 17-54-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03307, current rewards: 84.70910, mean: 0.11146
[32m[0906 17-54-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03303, current rewards: 90.23642, mean: 0.11140
[32m[0906 17-54-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03302, current rewards: 95.76346, mean: 0.11135
[32m[0906 17-54-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03298, current rewards: 101.29221, mean: 0.11131
[32m[0906 17-54-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03296, current rewards: 106.75225, mean: 0.11120
[32m[0906 17-54-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03295, current rewards: 112.28433, mean: 0.11117
[32m[0906 17-54-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03294, current rewards: 117.80914, mean: 0.11114
[32m[0906 17-54-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03294, current rewards: 123.33481, mean: 0.11111
[32m[0906 17-54-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03291, current rewards: 129.02149, mean: 0.11123
[32m[0906 17-54-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03290, current rewards: 134.56683, mean: 0.11121
[32m[0906 17-54-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03288, current rewards: 138.25444, mean: 0.10973
[32m[0906 17-54-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03286, current rewards: 143.83327, mean: 0.10980
[32m[0906 17-54-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03286, current rewards: 149.40620, mean: 0.10986
[32m[0906 17-54-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03284, current rewards: 154.98122, mean: 0.10992
[32m[0906 17-54-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03282, current rewards: 160.56092, mean: 0.10997
[32m[0906 17-54-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03282, current rewards: 164.12598, mean: 0.10869
[32m[0906 17-54-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03282, current rewards: 169.59766, mean: 0.10872
[32m[0906 17-54-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03281, current rewards: 175.09344, mean: 0.10875
[32m[0906 17-54-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03281, current rewards: 180.59087, mean: 0.10879
[32m[0906 17-54-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03280, current rewards: 186.09056, mean: 0.10882
[32m[0906 17-54-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03279, current rewards: 191.58735, mean: 0.10886
[32m[0906 17-54-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03279, current rewards: 197.08779, mean: 0.10889
[32m[0906 17-54-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03278, current rewards: 201.49749, mean: 0.10833
[32m[0906 17-54-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03279, current rewards: 207.18978, mean: 0.10848
[32m[0906 17-54-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03278, current rewards: 212.88176, mean: 0.10861
[32m[0906 17-54-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03277, current rewards: 218.46085, mean: 0.10869
[32m[0906 17-54-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03278, current rewards: 224.18621, mean: 0.10883
[32m[0906 17-54-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03278, current rewards: 226.53615, mean: 0.10736
[32m[0906 17-54-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03277, current rewards: 232.55974, mean: 0.10767
[32m[0906 17-55-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03277, current rewards: 238.58194, mean: 0.10796
[32m[0906 17-55-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03277, current rewards: 244.60496, mean: 0.10823
[32m[0906 17-55-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03276, current rewards: 250.62939, mean: 0.10850
[32m[0906 17-55-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03276, current rewards: 256.64866, mean: 0.10875
[32m[0906 17-55-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03276, current rewards: 262.87239, mean: 0.10908
[32m[0906 17-55-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03277, current rewards: 266.66003, mean: 0.10840
[32m[0906 17-55-11 @Agent.py:117][0m Average action selection time: 0.0328
[32m[0906 17-55-11 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-55-11 @MBExp.py:227][0m Rewards obtained: [271.22394464487974], Lows: [5], Highs: [4], Total time: 7462.939715999995
[32m[0906 17-58-11 @MBExp.py:144][0m ####################################################################
[32m[0906 17-58-11 @MBExp.py:145][0m Starting training iteration 88.
[32m[0906 17-58-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03275, current rewards: -0.10892, mean: -0.01089
[32m[0906 17-58-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03347, current rewards: 5.47438, mean: 0.09124
[32m[0906 17-58-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03349, current rewards: 10.99544, mean: 0.09996
[32m[0906 17-58-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03349, current rewards: 16.51639, mean: 0.10323
[32m[0906 17-58-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03347, current rewards: 22.03877, mean: 0.10495
[32m[0906 17-58-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03351, current rewards: 27.56045, mean: 0.10600
[32m[0906 17-58-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03351, current rewards: 33.02510, mean: 0.10653
[32m[0906 17-58-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03341, current rewards: 38.51977, mean: 0.10700
[32m[0906 17-58-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03327, current rewards: 44.05947, mean: 0.10746
[32m[0906 17-58-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03323, current rewards: 49.59527, mean: 0.10782
[32m[0906 17-58-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03317, current rewards: 55.13446, mean: 0.10811
[32m[0906 17-58-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03314, current rewards: 60.67447, mean: 0.10835
[32m[0906 17-58-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03310, current rewards: 66.21342, mean: 0.10855
[32m[0906 17-58-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03306, current rewards: 71.75085, mean: 0.10871
[32m[0906 17-58-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03303, current rewards: 76.15135, mean: 0.10726
[32m[0906 17-58-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03299, current rewards: 81.72091, mean: 0.10753
[32m[0906 17-58-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03295, current rewards: 87.27300, mean: 0.10774
[32m[0906 17-58-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03292, current rewards: 92.82758, mean: 0.10794
[32m[0906 17-58-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03289, current rewards: 98.37712, mean: 0.10811
[32m[0906 17-58-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03289, current rewards: 103.92788, mean: 0.10826
[32m[0906 17-58-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03289, current rewards: 109.48078, mean: 0.10840
[32m[0906 17-58-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03287, current rewards: 115.03118, mean: 0.10852
[32m[0906 17-58-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03286, current rewards: 120.58353, mean: 0.10863
[32m[0906 17-58-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03285, current rewards: 126.25284, mean: 0.10884
[32m[0906 17-58-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03284, current rewards: 131.82426, mean: 0.10895
[32m[0906 17-58-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03283, current rewards: 137.38937, mean: 0.10904
[32m[0906 17-58-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03281, current rewards: 142.94791, mean: 0.10912
[32m[0906 17-58-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03283, current rewards: 142.44059, mean: 0.10474
[32m[0906 17-58-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03281, current rewards: 147.63348, mean: 0.10470
[32m[0906 17-58-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03278, current rewards: 152.82896, mean: 0.10468
[32m[0906 17-59-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03278, current rewards: 158.02217, mean: 0.10465
[32m[0906 17-59-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03278, current rewards: 163.12935, mean: 0.10457
[32m[0906 17-59-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03277, current rewards: 168.35113, mean: 0.10457
[32m[0906 17-59-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03277, current rewards: 172.42619, mean: 0.10387
[32m[0906 17-59-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03277, current rewards: 177.93012, mean: 0.10405
[32m[0906 17-59-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03277, current rewards: 183.45559, mean: 0.10424
[32m[0906 17-59-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03276, current rewards: 188.97691, mean: 0.10441
[32m[0906 17-59-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03276, current rewards: 194.50259, mean: 0.10457
[32m[0906 17-59-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03276, current rewards: 200.02521, mean: 0.10473
[32m[0906 17-59-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03276, current rewards: 205.72380, mean: 0.10496
[32m[0906 17-59-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03275, current rewards: 211.25508, mean: 0.10510
[32m[0906 17-59-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03274, current rewards: 215.63208, mean: 0.10468
[32m[0906 17-59-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03274, current rewards: 221.25061, mean: 0.10486
[32m[0906 17-59-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03274, current rewards: 226.87437, mean: 0.10503
[32m[0906 17-59-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03274, current rewards: 232.48759, mean: 0.10520
[32m[0906 17-59-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03273, current rewards: 238.10382, mean: 0.10536
[32m[0906 17-59-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03273, current rewards: 243.71843, mean: 0.10551
[32m[0906 17-59-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03273, current rewards: 249.33762, mean: 0.10565
[32m[0906 17-59-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03272, current rewards: 253.00843, mean: 0.10498
[32m[0906 17-59-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03272, current rewards: 258.64664, mean: 0.10514
[32m[0906 17-59-34 @Agent.py:117][0m Average action selection time: 0.0327
[32m[0906 17-59-34 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-59-34 @MBExp.py:227][0m Rewards obtained: [263.15945375985405], Lows: [4], Highs: [4], Total time: 7545.475958999995
[32m[0906 18-02-36 @MBExp.py:144][0m ####################################################################
[32m[0906 18-02-36 @MBExp.py:145][0m Starting training iteration 89.
[32m[0906 18-02-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03258, current rewards: 0.96327, mean: 0.09633
[32m[0906 18-02-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03333, current rewards: 6.42002, mean: 0.10700
[32m[0906 18-02-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03342, current rewards: 11.91652, mean: 0.10833
[32m[0906 18-02-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03347, current rewards: 17.41530, mean: 0.10885
[32m[0906 18-02-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03346, current rewards: 22.91409, mean: 0.10911
[32m[0906 18-02-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03346, current rewards: 28.41350, mean: 0.10928
[32m[0906 18-02-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03343, current rewards: 31.84357, mean: 0.10272
[32m[0906 18-02-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03339, current rewards: 37.65893, mean: 0.10461
[32m[0906 18-02-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03327, current rewards: 43.46813, mean: 0.10602
[32m[0906 18-02-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03318, current rewards: 49.27548, mean: 0.10712
[32m[0906 18-02-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03312, current rewards: 55.08665, mean: 0.10801
[32m[0906 18-02-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03305, current rewards: 60.89704, mean: 0.10874
[32m[0906 18-02-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03303, current rewards: 66.69914, mean: 0.10934
[32m[0906 18-02-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03300, current rewards: 69.52502, mean: 0.10534
[32m[0906 18-02-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03298, current rewards: 75.11428, mean: 0.10579
[32m[0906 18-03-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03295, current rewards: 80.70993, mean: 0.10620
[32m[0906 18-03-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03294, current rewards: 86.30162, mean: 0.10655
[32m[0906 18-03-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03291, current rewards: 91.89483, mean: 0.10685
[32m[0906 18-03-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03291, current rewards: 97.48582, mean: 0.10713
[32m[0906 18-03-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03289, current rewards: 103.08380, mean: 0.10738
[32m[0906 18-03-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03286, current rewards: 106.56512, mean: 0.10551
[32m[0906 18-03-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03285, current rewards: 112.16976, mean: 0.10582
[32m[0906 18-03-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03284, current rewards: 117.93175, mean: 0.10624
[32m[0906 18-03-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03284, current rewards: 123.53553, mean: 0.10650
[32m[0906 18-03-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03283, current rewards: 129.13037, mean: 0.10672
[32m[0906 18-03-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03282, current rewards: 134.72707, mean: 0.10693
[32m[0906 18-03-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03281, current rewards: 138.29143, mean: 0.10557
[32m[0906 18-03-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03281, current rewards: 143.93626, mean: 0.10584
[32m[0906 18-03-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03280, current rewards: 149.58225, mean: 0.10609
[32m[0906 18-03-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03279, current rewards: 155.22451, mean: 0.10632
[32m[0906 18-03-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03278, current rewards: 160.86522, mean: 0.10653
[32m[0906 18-03-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03277, current rewards: 166.39720, mean: 0.10666
[32m[0906 18-03-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03277, current rewards: 172.03184, mean: 0.10685
[32m[0906 18-03-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03277, current rewards: 177.66493, mean: 0.10703
[32m[0906 18-03-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03278, current rewards: 183.29914, mean: 0.10719
[32m[0906 18-03-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03278, current rewards: 188.93309, mean: 0.10735
[32m[0906 18-03-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03278, current rewards: 191.40505, mean: 0.10575
[32m[0906 18-03-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03278, current rewards: 196.96485, mean: 0.10590
[32m[0906 18-03-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03278, current rewards: 202.51958, mean: 0.10603
[32m[0906 18-03-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03278, current rewards: 208.20043, mean: 0.10622
[32m[0906 18-03-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03278, current rewards: 213.77337, mean: 0.10635
[32m[0906 18-03-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03277, current rewards: 219.33647, mean: 0.10647
[32m[0906 18-03-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03277, current rewards: 224.90102, mean: 0.10659
[32m[0906 18-03-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03277, current rewards: 230.46092, mean: 0.10669
[32m[0906 18-03-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03277, current rewards: 236.02083, mean: 0.10680
[32m[0906 18-03-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03277, current rewards: 241.58395, mean: 0.10690
[32m[0906 18-03-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03276, current rewards: 247.14237, mean: 0.10699
[32m[0906 18-03-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03276, current rewards: 252.90463, mean: 0.10716
[32m[0906 18-03-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03276, current rewards: 258.99473, mean: 0.10747
[32m[0906 18-03-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03276, current rewards: 265.09176, mean: 0.10776
[32m[0906 18-03-58 @Agent.py:117][0m Average action selection time: 0.0328
[32m[0906 18-03-58 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-03-58 @MBExp.py:227][0m Rewards obtained: [269.9760831747773], Lows: [4], Highs: [4], Total time: 7628.111091999995
[32m[0906 18-07-03 @MBExp.py:144][0m ####################################################################
[32m[0906 18-07-03 @MBExp.py:145][0m Starting training iteration 90.
[32m[0906 18-07-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03478, current rewards: -0.07302, mean: -0.00730
[32m[0906 18-07-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03369, current rewards: 5.62897, mean: 0.09382
[32m[0906 18-07-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03361, current rewards: 11.33425, mean: 0.10304
[32m[0906 18-07-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03370, current rewards: 17.03857, mean: 0.10649
[32m[0906 18-07-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03364, current rewards: 22.74903, mean: 0.10833
[32m[0906 18-07-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03364, current rewards: 28.30066, mean: 0.10885
[32m[0906 18-07-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03363, current rewards: 33.94894, mean: 0.10951
[32m[0906 18-07-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03359, current rewards: 39.59713, mean: 0.10999
[32m[0906 18-07-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03343, current rewards: 45.19613, mean: 0.11023
[32m[0906 18-07-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03333, current rewards: 50.88226, mean: 0.11061
[32m[0906 18-07-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03325, current rewards: 56.57117, mean: 0.11092
[32m[0906 18-07-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03320, current rewards: 62.25957, mean: 0.11118
[32m[0906 18-07-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03314, current rewards: 67.94954, mean: 0.11139
[32m[0906 18-07-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03315, current rewards: 69.35775, mean: 0.10509
[32m[0906 18-07-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03311, current rewards: 74.61327, mean: 0.10509
[32m[0906 18-07-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03309, current rewards: 79.86905, mean: 0.10509
[32m[0906 18-07-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03306, current rewards: 85.12405, mean: 0.10509
[32m[0906 18-07-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03305, current rewards: 90.37738, mean: 0.10509
[32m[0906 18-07-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03301, current rewards: 95.63257, mean: 0.10509
[32m[0906 18-07-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03299, current rewards: 100.88643, mean: 0.10509
[32m[0906 18-07-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03298, current rewards: 106.14090, mean: 0.10509
[32m[0906 18-07-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03297, current rewards: 111.49378, mean: 0.10518
[32m[0906 18-07-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03296, current rewards: 117.20541, mean: 0.10559
[32m[0906 18-07-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03296, current rewards: 122.60927, mean: 0.10570
[32m[0906 18-07-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03295, current rewards: 124.65334, mean: 0.10302
[32m[0906 18-07-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03294, current rewards: 130.37191, mean: 0.10347
[32m[0906 18-07-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03293, current rewards: 136.09378, mean: 0.10389
[32m[0906 18-07-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03293, current rewards: 141.81052, mean: 0.10427
[32m[0906 18-07-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03293, current rewards: 146.36830, mean: 0.10381
[32m[0906 18-07-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03292, current rewards: 152.13191, mean: 0.10420
[32m[0906 18-07-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03290, current rewards: 157.72156, mean: 0.10445
[32m[0906 18-07-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03288, current rewards: 163.45274, mean: 0.10478
[32m[0906 18-07-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03287, current rewards: 169.17156, mean: 0.10508
[32m[0906 18-07-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03286, current rewards: 174.90840, mean: 0.10537
[32m[0906 18-07-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03286, current rewards: 180.63518, mean: 0.10563
[32m[0906 18-08-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03286, current rewards: 186.35077, mean: 0.10588
[32m[0906 18-08-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03286, current rewards: 192.07326, mean: 0.10612
[32m[0906 18-08-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03286, current rewards: 197.79897, mean: 0.10634
[32m[0906 18-08-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03285, current rewards: 203.58905, mean: 0.10659
[32m[0906 18-08-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03285, current rewards: 209.39192, mean: 0.10683
[32m[0906 18-08-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03284, current rewards: 215.64676, mean: 0.10729
[32m[0906 18-08-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03284, current rewards: 221.46975, mean: 0.10751
[32m[0906 18-08-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03282, current rewards: 227.28387, mean: 0.10772
[32m[0906 18-08-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03282, current rewards: 233.09803, mean: 0.10792
[32m[0906 18-08-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03282, current rewards: 238.92177, mean: 0.10811
[32m[0906 18-08-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03281, current rewards: 244.73267, mean: 0.10829
[32m[0906 18-08-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03281, current rewards: 250.54581, mean: 0.10846
[32m[0906 18-08-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03280, current rewards: 256.23853, mean: 0.10858
[32m[0906 18-08-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03280, current rewards: 262.04993, mean: 0.10873
[32m[0906 18-08-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03280, current rewards: 267.86888, mean: 0.10889
[32m[0906 18-08-25 @Agent.py:117][0m Average action selection time: 0.0328
[32m[0906 18-08-25 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-08-25 @MBExp.py:227][0m Rewards obtained: [272.51900270063067], Lows: [2], Highs: [5], Total time: 7710.826271999995
[32m[0906 18-11-31 @MBExp.py:144][0m ####################################################################
[32m[0906 18-11-31 @MBExp.py:145][0m Starting training iteration 91.
[32m[0906 18-11-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03306, current rewards: -9.68455, mean: -0.96846
[32m[0906 18-11-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03413, current rewards: -59.14893, mean: -0.98582
[32m[0906 18-11-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03453, current rewards: -105.89854, mean: -0.96271
[32m[0906 18-11-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03422, current rewards: -152.67285, mean: -0.95421
[32m[0906 18-11-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03401, current rewards: -200.20517, mean: -0.95336
[32m[0906 18-11-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03395, current rewards: -247.64868, mean: -0.95249
[32m[0906 18-11-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03393, current rewards: -295.34145, mean: -0.95271
[32m[0906 18-11-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03389, current rewards: -342.86116, mean: -0.95239
[32m[0906 18-11-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03368, current rewards: -390.47988, mean: -0.95239
[32m[0906 18-11-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03360, current rewards: -437.99618, mean: -0.95217
[32m[0906 18-11-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03351, current rewards: -485.61685, mean: -0.95219
[32m[0906 18-11-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03359, current rewards: -508.66919, mean: -0.90834
[32m[0906 18-11-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03389, current rewards: -532.15115, mean: -0.87238
[32m[0906 18-11-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03390, current rewards: -544.82117, mean: -0.82549
[32m[0906 18-11-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03400, current rewards: -561.52449, mean: -0.79088
[32m[0906 18-11-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03412, current rewards: -587.01466, mean: -0.77239
[32m[0906 18-11-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03414, current rewards: -633.43479, mean: -0.78202
[32m[0906 18-12-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03422, current rewards: -674.03362, mean: -0.78376
[32m[0906 18-12-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03423, current rewards: -687.15220, mean: -0.75511
[32m[0906 18-12-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03417, current rewards: -675.12595, mean: -0.70326
[32m[0906 18-12-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03410, current rewards: -662.56150, mean: -0.65600
[32m[0906 18-12-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03402, current rewards: -653.39655, mean: -0.61641
[32m[0906 18-12-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03395, current rewards: -647.61883, mean: -0.58344
[32m[0906 18-12-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03389, current rewards: -642.03411, mean: -0.55348
[32m[0906 18-12-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03383, current rewards: -636.40574, mean: -0.52596
[32m[0906 18-12-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03379, current rewards: -630.77341, mean: -0.50061
[32m[0906 18-12-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03374, current rewards: -625.18816, mean: -0.47724
[32m[0906 18-12-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03397, current rewards: -653.79486, mean: -0.48073
[32m[0906 18-12-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03420, current rewards: -690.21942, mean: -0.48952
[32m[0906 18-12-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03436, current rewards: -730.92340, mean: -0.50063
[32m[0906 18-12-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03447, current rewards: -760.01154, mean: -0.50332
[32m[0906 18-12-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03446, current rewards: -787.98035, mean: -0.50512
[32m[0906 18-12-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03445, current rewards: -815.72050, mean: -0.50666
[32m[0906 18-12-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03444, current rewards: -846.96385, mean: -0.51022
[32m[0906 18-12-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03445, current rewards: -874.98438, mean: -0.51169
[32m[0906 18-12-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03445, current rewards: -907.23231, mean: -0.51547
[32m[0906 18-12-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03444, current rewards: -943.95231, mean: -0.52152
[32m[0906 18-12-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03440, current rewards: -993.95231, mean: -0.53438
[32m[0906 18-12-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03435, current rewards: -1043.95231, mean: -0.54657
[32m[0906 18-12-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03430, current rewards: -1093.95231, mean: -0.55814
[32m[0906 18-12-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03426, current rewards: -1143.95231, mean: -0.56913
[32m[0906 18-12-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03422, current rewards: -1193.95231, mean: -0.57959
[32m[0906 18-12-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03419, current rewards: -1243.95231, mean: -0.58955
[32m[0906 18-12-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03414, current rewards: -1293.95231, mean: -0.59905
[32m[0906 18-12-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03412, current rewards: -1343.95231, mean: -0.60812
[32m[0906 18-12-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03409, current rewards: -1393.95231, mean: -0.61679
[32m[0906 18-12-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03406, current rewards: -1443.95231, mean: -0.62509
[32m[0906 18-12-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03403, current rewards: -1493.95231, mean: -0.63303
[32m[0906 18-12-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03400, current rewards: -1543.95231, mean: -0.64064
[32m[0906 18-12-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03398, current rewards: -1593.95231, mean: -0.64795
[32m[0906 18-12-56 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 18-12-56 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-12-57 @MBExp.py:227][0m Rewards obtained: [-1633.9523115514096], Lows: [473], Highs: [850], Total time: 7796.438445999995
[32m[0906 18-16-05 @MBExp.py:144][0m ####################################################################
[32m[0906 18-16-05 @MBExp.py:145][0m Starting training iteration 92.
[32m[0906 18-16-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03266, current rewards: 0.08251, mean: 0.00825
[32m[0906 18-16-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03339, current rewards: 5.59907, mean: 0.09332
[32m[0906 18-16-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03358, current rewards: 11.11606, mean: 0.10106
[32m[0906 18-16-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03356, current rewards: 16.63137, mean: 0.10395
[32m[0906 18-16-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03356, current rewards: 22.14906, mean: 0.10547
[32m[0906 18-16-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03357, current rewards: 27.72222, mean: 0.10662
[32m[0906 18-16-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03336, current rewards: 33.24167, mean: 0.10723
[32m[0906 18-16-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03327, current rewards: 36.64505, mean: 0.10179
[32m[0906 18-16-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03319, current rewards: 42.15802, mean: 0.10282
[32m[0906 18-16-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03314, current rewards: 47.66509, mean: 0.10362
[32m[0906 18-16-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03307, current rewards: 53.17116, mean: 0.10426
[32m[0906 18-16-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03302, current rewards: 58.67991, mean: 0.10479
[32m[0906 18-16-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03299, current rewards: 63.07812, mean: 0.10341
[32m[0906 18-16-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03295, current rewards: 68.77490, mean: 0.10420
[32m[0906 18-16-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03292, current rewards: 74.32869, mean: 0.10469
[32m[0906 18-16-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03288, current rewards: 79.88564, mean: 0.10511
[32m[0906 18-16-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03287, current rewards: 85.40215, mean: 0.10543
[32m[0906 18-16-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03285, current rewards: 90.92863, mean: 0.10573
[32m[0906 18-16-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03284, current rewards: 96.45098, mean: 0.10599
[32m[0906 18-16-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03283, current rewards: 101.97026, mean: 0.10622
[32m[0906 18-16-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03282, current rewards: 107.48413, mean: 0.10642
[32m[0906 18-16-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03279, current rewards: 108.33599, mean: 0.10220
[32m[0906 18-16-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03279, current rewards: 112.57727, mean: 0.10142
[32m[0906 18-16-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03279, current rewards: 116.81854, mean: 0.10071
[32m[0906 18-16-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03279, current rewards: 121.05982, mean: 0.10005
[32m[0906 18-16-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03279, current rewards: 125.30110, mean: 0.09945
[32m[0906 18-16-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03278, current rewards: 129.54237, mean: 0.09889
[32m[0906 18-16-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03276, current rewards: 133.78365, mean: 0.09837
[32m[0906 18-16-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03276, current rewards: 138.02492, mean: 0.09789
[32m[0906 18-16-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03274, current rewards: 118.40003, mean: 0.08110
[32m[0906 18-16-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03274, current rewards: 68.40003, mean: 0.04530
[32m[0906 18-16-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03274, current rewards: 18.40003, mean: 0.01179
[32m[0906 18-16-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03275, current rewards: -31.59997, mean: -0.01963
[32m[0906 18-16-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03274, current rewards: -81.59997, mean: -0.04916
[32m[0906 18-17-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03274, current rewards: -131.59997, mean: -0.07696
[32m[0906 18-17-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03273, current rewards: -181.59997, mean: -0.10318
[32m[0906 18-17-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03273, current rewards: -231.59997, mean: -0.12796
[32m[0906 18-17-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03274, current rewards: -281.59997, mean: -0.15140
[32m[0906 18-17-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03273, current rewards: -331.59997, mean: -0.17361
[32m[0906 18-17-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03272, current rewards: -381.59997, mean: -0.19469
[32m[0906 18-17-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03271, current rewards: -431.59997, mean: -0.21473
[32m[0906 18-17-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03271, current rewards: -481.59997, mean: -0.23379
[32m[0906 18-17-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03271, current rewards: -531.59997, mean: -0.25194
[32m[0906 18-17-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03270, current rewards: -581.59997, mean: -0.26926
[32m[0906 18-17-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03270, current rewards: -631.59997, mean: -0.28579
[32m[0906 18-17-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03270, current rewards: -681.59997, mean: -0.30159
[32m[0906 18-17-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03270, current rewards: -731.59997, mean: -0.31671
[32m[0906 18-17-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03270, current rewards: -781.59997, mean: -0.33119
[32m[0906 18-17-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03270, current rewards: -831.59997, mean: -0.34506
[32m[0906 18-17-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03269, current rewards: -881.59997, mean: -0.35837
[32m[0906 18-17-27 @Agent.py:117][0m Average action selection time: 0.0327
[32m[0906 18-17-27 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-17-27 @MBExp.py:227][0m Rewards obtained: [-904.7720535579106], Lows: [3], Highs: [1048], Total time: 7878.880516999995
[32m[0906 18-20-37 @MBExp.py:144][0m ####################################################################
[32m[0906 18-20-37 @MBExp.py:145][0m Starting training iteration 93.
[32m[0906 18-20-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03225, current rewards: 1.12940, mean: 0.11294
[32m[0906 18-20-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03316, current rewards: -0.98407, mean: -0.01640
[32m[0906 18-20-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03335, current rewards: 4.20705, mean: 0.03825
[32m[0906 18-20-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03333, current rewards: 9.40067, mean: 0.05875
[32m[0906 18-20-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03342, current rewards: 14.59035, mean: 0.06948
[32m[0906 18-20-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03349, current rewards: 19.80109, mean: 0.07616
[32m[0906 18-20-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03347, current rewards: 24.99754, mean: 0.08064
[32m[0906 18-20-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03342, current rewards: 30.19538, mean: 0.08388
[32m[0906 18-20-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03334, current rewards: 35.39692, mean: 0.08633
[32m[0906 18-20-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03326, current rewards: 40.59852, mean: 0.08826
[32m[0906 18-20-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03319, current rewards: 45.80173, mean: 0.08981
[32m[0906 18-20-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03317, current rewards: 51.00185, mean: 0.09107
[32m[0906 18-20-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03315, current rewards: 56.19946, mean: 0.09213
[32m[0906 18-20-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03310, current rewards: 62.98009, mean: 0.09542
[32m[0906 18-21-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03307, current rewards: 51.16739, mean: 0.07207
[32m[0906 18-21-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03304, current rewards: 1.16739, mean: 0.00154
[32m[0906 18-21-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03302, current rewards: -48.83261, mean: -0.06029
[32m[0906 18-21-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03300, current rewards: -98.83261, mean: -0.11492
[32m[0906 18-21-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03298, current rewards: -148.83261, mean: -0.16355
[32m[0906 18-21-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03297, current rewards: -198.83261, mean: -0.20712
[32m[0906 18-21-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03294, current rewards: -248.83261, mean: -0.24637
[32m[0906 18-21-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03291, current rewards: -298.83261, mean: -0.28192
[32m[0906 18-21-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03290, current rewards: -348.83261, mean: -0.31426
[32m[0906 18-21-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03288, current rewards: -398.83261, mean: -0.34382
[32m[0906 18-21-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03287, current rewards: -448.83261, mean: -0.37094
[32m[0906 18-21-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03286, current rewards: -498.83261, mean: -0.39590
[32m[0906 18-21-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03285, current rewards: -548.83261, mean: -0.41896
[32m[0906 18-21-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03284, current rewards: -598.83261, mean: -0.44032
[32m[0906 18-21-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03283, current rewards: -648.83261, mean: -0.46016
[32m[0906 18-21-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03282, current rewards: -698.83261, mean: -0.47865
[32m[0906 18-21-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03281, current rewards: -748.83261, mean: -0.49592
[32m[0906 18-21-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03279, current rewards: -798.83261, mean: -0.51207
[32m[0906 18-21-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03279, current rewards: -848.83261, mean: -0.52723
[32m[0906 18-21-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03278, current rewards: -898.83261, mean: -0.54147
[32m[0906 18-21-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03278, current rewards: -948.83261, mean: -0.55487
[32m[0906 18-21-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03277, current rewards: -998.83261, mean: -0.56752
[32m[0906 18-21-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03278, current rewards: -1048.83261, mean: -0.57947
[32m[0906 18-21-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03279, current rewards: -1098.83261, mean: -0.59077
[32m[0906 18-21-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03279, current rewards: -1148.83261, mean: -0.60148
[32m[0906 18-21-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03278, current rewards: -1198.83261, mean: -0.61165
[32m[0906 18-21-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03278, current rewards: -1248.83261, mean: -0.62131
[32m[0906 18-21-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03278, current rewards: -1298.83261, mean: -0.63050
[32m[0906 18-21-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03278, current rewards: -1348.83261, mean: -0.63926
[32m[0906 18-21-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03277, current rewards: -1398.83261, mean: -0.64761
[32m[0906 18-21-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03277, current rewards: -1448.83261, mean: -0.65558
[32m[0906 18-21-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03276, current rewards: -1498.83261, mean: -0.66320
[32m[0906 18-21-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03276, current rewards: -1548.83261, mean: -0.67049
[32m[0906 18-21-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03276, current rewards: -1598.83261, mean: -0.67747
[32m[0906 18-21-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03277, current rewards: -1648.83261, mean: -0.68416
[32m[0906 18-21-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03277, current rewards: -1698.83261, mean: -0.69058
[32m[0906 18-21-59 @Agent.py:117][0m Average action selection time: 0.0328
[32m[0906 18-21-59 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-21-59 @MBExp.py:227][0m Rewards obtained: [-1738.8326106603267], Lows: [0], Highs: [1813], Total time: 7961.514045999995
[32m[0906 18-25-13 @MBExp.py:144][0m ####################################################################
[32m[0906 18-25-13 @MBExp.py:145][0m Starting training iteration 94.
[32m[0906 18-25-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03214, current rewards: -5.32957, mean: -0.53296
[32m[0906 18-25-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03558, current rewards: -25.19927, mean: -0.41999
[32m[0906 18-25-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03661, current rewards: -26.46934, mean: -0.24063
[32m[0906 18-25-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03679, current rewards: -36.42487, mean: -0.22766
[32m[0906 18-25-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03735, current rewards: -40.17046, mean: -0.19129
[32m[0906 18-25-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03739, current rewards: -45.76632, mean: -0.17602
[32m[0906 18-25-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03715, current rewards: -58.73948, mean: -0.18948
[32m[0906 18-25-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03680, current rewards: -73.88772, mean: -0.20524
[32m[0906 18-25-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03666, current rewards: -83.37345, mean: -0.20335
[32m[0906 18-25-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03656, current rewards: -100.43840, mean: -0.21834
[32m[0906 18-25-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03639, current rewards: -104.46219, mean: -0.20483
[32m[0906 18-25-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03629, current rewards: -104.85045, mean: -0.18723
[32m[0906 18-25-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03618, current rewards: -103.13783, mean: -0.16908
[32m[0906 18-25-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03600, current rewards: -105.43070, mean: -0.15974
[32m[0906 18-25-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03573, current rewards: -99.99163, mean: -0.14083
[32m[0906 18-25-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03562, current rewards: -98.46068, mean: -0.12955
[32m[0906 18-25-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03559, current rewards: -97.65927, mean: -0.12057
[32m[0906 18-25-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03563, current rewards: -109.11540, mean: -0.12688
[32m[0906 18-25-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03546, current rewards: -103.54141, mean: -0.11378
[32m[0906 18-25-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03530, current rewards: -98.27339, mean: -0.10237
[32m[0906 18-25-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03516, current rewards: -93.01995, mean: -0.09210
[32m[0906 18-25-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03503, current rewards: -87.70370, mean: -0.08274
[32m[0906 18-25-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03492, current rewards: -82.35869, mean: -0.07420
[32m[0906 18-25-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03480, current rewards: -77.02017, mean: -0.06640
[32m[0906 18-25-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03471, current rewards: -71.68149, mean: -0.05924
[32m[0906 18-25-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03468, current rewards: -78.56729, mean: -0.06235
[32m[0906 18-25-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03460, current rewards: -92.01653, mean: -0.07024
[32m[0906 18-26-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03452, current rewards: -104.29234, mean: -0.07669
[32m[0906 18-26-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03444, current rewards: -117.61520, mean: -0.08342
[32m[0906 18-26-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03447, current rewards: -113.00962, mean: -0.07740
[32m[0906 18-26-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03443, current rewards: -106.97955, mean: -0.07085
[32m[0906 18-26-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03439, current rewards: -100.96270, mean: -0.06472
[32m[0906 18-26-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03434, current rewards: -94.96295, mean: -0.05898
[32m[0906 18-26-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03435, current rewards: -90.55047, mean: -0.05455
[32m[0906 18-26-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03432, current rewards: -85.12821, mean: -0.04978
[32m[0906 18-26-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03426, current rewards: -79.54626, mean: -0.04520
[32m[0906 18-26-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03421, current rewards: -73.95789, mean: -0.04086
[32m[0906 18-26-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03417, current rewards: -68.26383, mean: -0.03670
[32m[0906 18-26-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03412, current rewards: -62.65201, mean: -0.03280
[32m[0906 18-26-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03408, current rewards: -57.03956, mean: -0.02910
[32m[0906 18-26-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03404, current rewards: -56.83091, mean: -0.02827
[32m[0906 18-26-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03402, current rewards: -55.16787, mean: -0.02678
[32m[0906 18-26-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03401, current rewards: -55.39702, mean: -0.02625
[32m[0906 18-26-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03401, current rewards: -51.88534, mean: -0.02402
[32m[0906 18-26-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03399, current rewards: -52.01348, mean: -0.02354
[32m[0906 18-26-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03400, current rewards: -51.80565, mean: -0.02292
[32m[0906 18-26-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03399, current rewards: -50.91452, mean: -0.02204
[32m[0906 18-26-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03397, current rewards: -58.37823, mean: -0.02474
[32m[0906 18-26-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03394, current rewards: -53.03586, mean: -0.02201
[32m[0906 18-26-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03391, current rewards: -47.70174, mean: -0.01939
[32m[0906 18-26-38 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 18-26-38 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-26-38 @MBExp.py:227][0m Rewards obtained: [-43.43199923999226], Lows: [137], Highs: [82], Total time: 8046.9646529999945
[32m[0906 18-29-51 @MBExp.py:144][0m ####################################################################
[32m[0906 18-29-51 @MBExp.py:145][0m Starting training iteration 95.
[32m[0906 18-29-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03290, current rewards: -6.23697, mean: -0.62370
[32m[0906 18-29-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03332, current rewards: -1.24000, mean: -0.02067
[32m[0906 18-29-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03338, current rewards: 3.76538, mean: 0.03423
[32m[0906 18-29-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03346, current rewards: 8.76786, mean: 0.05480
[32m[0906 18-29-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03338, current rewards: 13.94767, mean: 0.06642
[32m[0906 18-30-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03317, current rewards: 18.96390, mean: 0.07294
[32m[0906 18-30-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03303, current rewards: 24.64750, mean: 0.07951
[32m[0906 18-30-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03294, current rewards: 29.82540, mean: 0.08285
[32m[0906 18-30-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03292, current rewards: 35.00405, mean: 0.08538
[32m[0906 18-30-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03288, current rewards: 40.18221, mean: 0.08735
[32m[0906 18-30-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03288, current rewards: 45.35520, mean: 0.08893
[32m[0906 18-30-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03284, current rewards: 50.53148, mean: 0.09023
[32m[0906 18-30-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03280, current rewards: 55.59439, mean: 0.09114
[32m[0906 18-30-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03277, current rewards: 60.76810, mean: 0.09207
[32m[0906 18-30-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03276, current rewards: 65.94470, mean: 0.09288
[32m[0906 18-30-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03274, current rewards: 71.12674, mean: 0.09359
[32m[0906 18-30-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03273, current rewards: 72.45559, mean: 0.08945
[32m[0906 18-30-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03270, current rewards: 78.04716, mean: 0.09075
[32m[0906 18-30-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03268, current rewards: 83.61109, mean: 0.09188
[32m[0906 18-30-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03265, current rewards: 89.18899, mean: 0.09291
[32m[0906 18-30-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03266, current rewards: 94.81920, mean: 0.09388
[32m[0906 18-30-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03265, current rewards: 100.68843, mean: 0.09499
[32m[0906 18-30-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03266, current rewards: 106.50292, mean: 0.09595
[32m[0906 18-30-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03265, current rewards: 112.36656, mean: 0.09687
[32m[0906 18-30-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03265, current rewards: 118.18134, mean: 0.09767
[32m[0906 18-30-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03264, current rewards: 124.00276, mean: 0.09841
[32m[0906 18-30-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03263, current rewards: 129.61514, mean: 0.09894
[32m[0906 18-30-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03264, current rewards: 134.79825, mean: 0.09912
[32m[0906 18-30-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03263, current rewards: 139.97843, mean: 0.09928
[32m[0906 18-30-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03262, current rewards: 145.11582, mean: 0.09939
[32m[0906 18-30-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03261, current rewards: 150.36665, mean: 0.09958
[32m[0906 18-30-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03261, current rewards: 155.62025, mean: 0.09976
[32m[0906 18-30-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03261, current rewards: 160.86924, mean: 0.09992
[32m[0906 18-30-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03262, current rewards: 166.12311, mean: 0.10007
[32m[0906 18-30-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03262, current rewards: 171.37112, mean: 0.10022
[32m[0906 18-30-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03263, current rewards: 176.62152, mean: 0.10035
[32m[0906 18-30-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03262, current rewards: 181.87249, mean: 0.10048
[32m[0906 18-30-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03263, current rewards: 187.12944, mean: 0.10061
[32m[0906 18-30-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03262, current rewards: 192.37302, mean: 0.10072
[32m[0906 18-30-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03262, current rewards: 196.33223, mean: 0.10017
[32m[0906 18-30-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03261, current rewards: 201.44704, mean: 0.10022
[32m[0906 18-30-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03261, current rewards: 206.56910, mean: 0.10028
[32m[0906 18-31-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03261, current rewards: 211.69198, mean: 0.10033
[32m[0906 18-31-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03261, current rewards: 216.82647, mean: 0.10038
[32m[0906 18-31-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03260, current rewards: 221.94624, mean: 0.10043
[32m[0906 18-31-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03260, current rewards: 227.06532, mean: 0.10047
[32m[0906 18-31-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03260, current rewards: 232.16937, mean: 0.10051
[32m[0906 18-31-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03261, current rewards: 237.28935, mean: 0.10055
[32m[0906 18-31-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03261, current rewards: 242.40963, mean: 0.10058
[32m[0906 18-31-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03261, current rewards: 247.51803, mean: 0.10062
[32m[0906 18-31-13 @Agent.py:117][0m Average action selection time: 0.0326
[32m[0906 18-31-13 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-31-14 @MBExp.py:227][0m Rewards obtained: [251.6183336963175], Lows: [6], Highs: [1], Total time: 8129.2281339999945
[32m[0906 18-34-29 @MBExp.py:144][0m ####################################################################
[32m[0906 18-34-29 @MBExp.py:145][0m Starting training iteration 96.
[32m[0906 18-34-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03269, current rewards: -4.56263, mean: -0.45626
[32m[0906 18-34-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03326, current rewards: 0.93556, mean: 0.01559
[32m[0906 18-34-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03321, current rewards: 6.43354, mean: 0.05849
[32m[0906 18-34-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03332, current rewards: 12.09754, mean: 0.07561
[32m[0906 18-34-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03332, current rewards: 17.62241, mean: 0.08392
[32m[0906 18-34-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03315, current rewards: 23.14975, mean: 0.08904
[32m[0906 18-34-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03302, current rewards: 28.67648, mean: 0.09250
[32m[0906 18-34-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03293, current rewards: 34.19965, mean: 0.09500
[32m[0906 18-34-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03289, current rewards: 39.72460, mean: 0.09689
[32m[0906 18-34-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03283, current rewards: 45.24773, mean: 0.09836
[32m[0906 18-34-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03280, current rewards: 50.77398, mean: 0.09956
[32m[0906 18-34-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03277, current rewards: 56.27120, mean: 0.10048
[32m[0906 18-34-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03273, current rewards: 58.27066, mean: 0.09553
[32m[0906 18-34-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03274, current rewards: 63.63831, mean: 0.09642
[32m[0906 18-34-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03274, current rewards: 69.00497, mean: 0.09719
[32m[0906 18-34-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03271, current rewards: 74.37072, mean: 0.09786
[32m[0906 18-34-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03271, current rewards: 79.73948, mean: 0.09844
[32m[0906 18-34-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03269, current rewards: 85.11396, mean: 0.09897
[32m[0906 18-34-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03268, current rewards: 90.48130, mean: 0.09943
[32m[0906 18-35-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03268, current rewards: 95.85210, mean: 0.09985
[32m[0906 18-35-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03266, current rewards: 101.37381, mean: 0.10037
[32m[0906 18-35-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03266, current rewards: 106.75071, mean: 0.10071
[32m[0906 18-35-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03267, current rewards: 110.16110, mean: 0.09924
[32m[0906 18-35-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03266, current rewards: 115.70464, mean: 0.09975
[32m[0906 18-35-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03267, current rewards: 121.24598, mean: 0.10020
[32m[0906 18-35-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03267, current rewards: 126.79066, mean: 0.10063
[32m[0906 18-35-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03267, current rewards: 132.33497, mean: 0.10102
[32m[0906 18-35-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03267, current rewards: 133.69096, mean: 0.09830
[32m[0906 18-35-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03266, current rewards: 139.01883, mean: 0.09859
[32m[0906 18-35-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03265, current rewards: 144.42775, mean: 0.09892
[32m[0906 18-35-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03266, current rewards: 149.83491, mean: 0.09923
[32m[0906 18-35-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03266, current rewards: 155.24396, mean: 0.09952
[32m[0906 18-35-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03265, current rewards: 160.65207, mean: 0.09978
[32m[0906 18-35-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03265, current rewards: 164.41526, mean: 0.09905
[32m[0906 18-35-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03265, current rewards: 169.94608, mean: 0.09938
[32m[0906 18-35-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03265, current rewards: 175.47562, mean: 0.09970
[32m[0906 18-35-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03265, current rewards: 181.07247, mean: 0.10004
[32m[0906 18-35-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03264, current rewards: 187.70458, mean: 0.10092
[32m[0906 18-35-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03264, current rewards: 194.63124, mean: 0.10190
[32m[0906 18-35-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03264, current rewards: 165.12483, mean: 0.08425
[32m[0906 18-35-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03264, current rewards: 115.12483, mean: 0.05728
[32m[0906 18-35-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03264, current rewards: 65.12483, mean: 0.03161
[32m[0906 18-35-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03265, current rewards: 15.12483, mean: 0.00717
[32m[0906 18-35-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03264, current rewards: -34.87517, mean: -0.01615
[32m[0906 18-35-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03263, current rewards: -84.87517, mean: -0.03841
[32m[0906 18-35-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03263, current rewards: -134.87517, mean: -0.05968
[32m[0906 18-35-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03263, current rewards: -184.87517, mean: -0.08003
[32m[0906 18-35-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03263, current rewards: -234.87517, mean: -0.09952
[32m[0906 18-35-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03263, current rewards: -284.87517, mean: -0.11821
[32m[0906 18-35-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03262, current rewards: -334.87517, mean: -0.13613
[32m[0906 18-35-52 @Agent.py:117][0m Average action selection time: 0.0326
[32m[0906 18-35-52 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-35-52 @MBExp.py:227][0m Rewards obtained: [-374.87516674906294], Lows: [5], Highs: [578], Total time: 8211.512705999994
[32m[0906 18-39-09 @MBExp.py:144][0m ####################################################################
[32m[0906 18-39-09 @MBExp.py:145][0m Starting training iteration 97.
[32m[0906 18-39-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03237, current rewards: -5.29372, mean: -0.52937
[32m[0906 18-39-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03319, current rewards: 0.70401, mean: 0.01173
[32m[0906 18-39-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03335, current rewards: 6.69283, mean: 0.06084
[32m[0906 18-39-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03337, current rewards: 12.66363, mean: 0.07915
[32m[0906 18-39-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03335, current rewards: 18.66849, mean: 0.08890
[32m[0906 18-39-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03318, current rewards: 24.68894, mean: 0.09496
[32m[0906 18-39-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03311, current rewards: 30.70001, mean: 0.09903
[32m[0906 18-39-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03301, current rewards: 36.70668, mean: 0.10196
[32m[0906 18-39-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03298, current rewards: 39.44465, mean: 0.09621
[32m[0906 18-39-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03293, current rewards: 45.44775, mean: 0.09880
[32m[0906 18-39-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03289, current rewards: 51.45662, mean: 0.10090
[32m[0906 18-39-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03284, current rewards: 57.35984, mean: 0.10243
[32m[0906 18-39-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03281, current rewards: 63.44398, mean: 0.10401
[32m[0906 18-39-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03279, current rewards: 69.52245, mean: 0.10534
[32m[0906 18-39-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03278, current rewards: 75.60034, mean: 0.10648
[32m[0906 18-39-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03276, current rewards: 81.68341, mean: 0.10748
[32m[0906 18-39-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03275, current rewards: 87.76363, mean: 0.10835
[32m[0906 18-39-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03275, current rewards: 91.48292, mean: 0.10638
[32m[0906 18-39-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03276, current rewards: 97.27017, mean: 0.10689
[32m[0906 18-39-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03276, current rewards: 103.16774, mean: 0.10747
[32m[0906 18-39-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03275, current rewards: 108.95389, mean: 0.10788
[32m[0906 18-39-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03274, current rewards: 114.56712, mean: 0.10808
[32m[0906 18-39-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03275, current rewards: 116.68961, mean: 0.10513
[32m[0906 18-39-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03274, current rewards: 123.78616, mean: 0.10671
[32m[0906 18-39-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03273, current rewards: 130.88272, mean: 0.10817
[32m[0906 18-39-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03272, current rewards: 137.97927, mean: 0.10951
[32m[0906 18-39-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03271, current rewards: 102.82437, mean: 0.07849
[32m[0906 18-39-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03270, current rewards: 52.82437, mean: 0.03884
[32m[0906 18-39-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03270, current rewards: 2.82437, mean: 0.00200
[32m[0906 18-39-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03269, current rewards: -47.17563, mean: -0.03231
[32m[0906 18-39-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03270, current rewards: -97.17563, mean: -0.06435
[32m[0906 18-40-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03270, current rewards: -147.17563, mean: -0.09434
[32m[0906 18-40-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03270, current rewards: -197.17563, mean: -0.12247
[32m[0906 18-40-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03270, current rewards: -247.17563, mean: -0.14890
[32m[0906 18-40-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03269, current rewards: -297.17563, mean: -0.17379
[32m[0906 18-40-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03270, current rewards: -347.17563, mean: -0.19726
[32m[0906 18-40-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03268, current rewards: -397.17563, mean: -0.21943
[32m[0906 18-40-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03268, current rewards: -447.17563, mean: -0.24042
[32m[0906 18-40-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03268, current rewards: -497.17563, mean: -0.26030
[32m[0906 18-40-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03267, current rewards: -547.17563, mean: -0.27917
[32m[0906 18-40-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03267, current rewards: -597.17563, mean: -0.29710
[32m[0906 18-40-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03267, current rewards: -647.17563, mean: -0.31416
[32m[0906 18-40-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03267, current rewards: -697.17563, mean: -0.33041
[32m[0906 18-40-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03267, current rewards: -747.17563, mean: -0.34591
[32m[0906 18-40-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03266, current rewards: -797.17563, mean: -0.36071
[32m[0906 18-40-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03266, current rewards: -847.17563, mean: -0.37486
[32m[0906 18-40-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03266, current rewards: -897.17563, mean: -0.38839
[32m[0906 18-40-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03266, current rewards: -947.17563, mean: -0.40135
[32m[0906 18-40-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03266, current rewards: -997.17563, mean: -0.41377
[32m[0906 18-40-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03265, current rewards: -1047.17563, mean: -0.42568
[32m[0906 18-40-31 @Agent.py:117][0m Average action selection time: 0.0327
[32m[0906 18-40-31 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-40-32 @MBExp.py:227][0m Rewards obtained: [-1087.1756306200698], Lows: [6], Highs: [1230], Total time: 8293.889750999993
[32m[0906 18-43-51 @MBExp.py:144][0m ####################################################################
[32m[0906 18-43-51 @MBExp.py:145][0m Starting training iteration 98.
[32m[0906 18-43-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03345, current rewards: -6.54662, mean: -0.65466
[32m[0906 18-43-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03333, current rewards: -26.40638, mean: -0.44011
[32m[0906 18-43-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03336, current rewards: -20.88373, mean: -0.18985
[32m[0906 18-43-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03340, current rewards: -15.46446, mean: -0.09665
[32m[0906 18-43-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03339, current rewards: -9.94851, mean: -0.04737
[32m[0906 18-44-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03321, current rewards: -4.43296, mean: -0.01705
[32m[0906 18-44-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03311, current rewards: 1.08099, mean: 0.00349
[32m[0906 18-44-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03306, current rewards: 6.60790, mean: 0.01836
[32m[0906 18-44-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03300, current rewards: 12.12865, mean: 0.02958
[32m[0906 18-44-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03294, current rewards: 17.64782, mean: 0.03836
[32m[0906 18-44-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03292, current rewards: 23.16738, mean: 0.04543
[32m[0906 18-44-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03288, current rewards: 28.89943, mean: 0.05161
[32m[0906 18-44-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03284, current rewards: 34.41559, mean: 0.05642
[32m[0906 18-44-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03284, current rewards: 39.93850, mean: 0.06051
[32m[0906 18-44-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03282, current rewards: 45.35789, mean: 0.06388
[32m[0906 18-44-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03280, current rewards: 50.57993, mean: 0.06655
[32m[0906 18-44-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03279, current rewards: 55.80097, mean: 0.06889
[32m[0906 18-44-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03278, current rewards: 61.02396, mean: 0.07096
[32m[0906 18-44-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03274, current rewards: 66.24232, mean: 0.07279
[32m[0906 18-44-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03271, current rewards: 71.52280, mean: 0.07450
[32m[0906 18-44-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03268, current rewards: 76.80369, mean: 0.07604
[32m[0906 18-44-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03268, current rewards: 82.03665, mean: 0.07739
[32m[0906 18-44-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03267, current rewards: 86.50574, mean: 0.07793
[32m[0906 18-44-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03265, current rewards: 95.29441, mean: 0.08215
[32m[0906 18-44-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03265, current rewards: 104.08307, mean: 0.08602
[32m[0906 18-44-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03264, current rewards: 112.87173, mean: 0.08958
[32m[0906 18-44-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03263, current rewards: 121.66039, mean: 0.09287
[32m[0906 18-44-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03263, current rewards: 130.44905, mean: 0.09592
[32m[0906 18-44-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03263, current rewards: 134.77198, mean: 0.09558
[32m[0906 18-44-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03262, current rewards: 129.13657, mean: 0.08845
[32m[0906 18-44-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03261, current rewards: 79.13657, mean: 0.05241
[32m[0906 18-44-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03260, current rewards: 29.13657, mean: 0.01868
[32m[0906 18-44-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03260, current rewards: -20.86343, mean: -0.01296
[32m[0906 18-44-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03260, current rewards: -70.86343, mean: -0.04269
[32m[0906 18-44-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03260, current rewards: -120.86343, mean: -0.07068
[32m[0906 18-44-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03259, current rewards: -170.86343, mean: -0.09708
[32m[0906 18-44-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03259, current rewards: -220.86343, mean: -0.12202
[32m[0906 18-44-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03259, current rewards: -270.86343, mean: -0.14563
[32m[0906 18-44-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03258, current rewards: -320.86343, mean: -0.16799
[32m[0906 18-44-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03259, current rewards: -370.86343, mean: -0.18922
[32m[0906 18-44-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03258, current rewards: -420.86343, mean: -0.20938
[32m[0906 18-44-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03258, current rewards: -470.86343, mean: -0.22857
[32m[0906 18-45-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03257, current rewards: -520.86343, mean: -0.24685
[32m[0906 18-45-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03257, current rewards: -570.86343, mean: -0.26429
[32m[0906 18-45-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03256, current rewards: -620.86343, mean: -0.28093
[32m[0906 18-45-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03256, current rewards: -670.86343, mean: -0.29684
[32m[0906 18-45-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03257, current rewards: -720.86343, mean: -0.31206
[32m[0906 18-45-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03257, current rewards: -770.86343, mean: -0.32664
[32m[0906 18-45-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03257, current rewards: -820.86343, mean: -0.34061
[32m[0906 18-45-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03257, current rewards: -870.86343, mean: -0.35401
[32m[0906 18-45-13 @Agent.py:117][0m Average action selection time: 0.0326
[32m[0906 18-45-13 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-45-13 @MBExp.py:227][0m Rewards obtained: [-910.8634328536831], Lows: [12], Highs: [1059], Total time: 8376.051083999993
[32m[0906 18-48-34 @MBExp.py:144][0m ####################################################################
[32m[0906 18-48-34 @MBExp.py:145][0m Starting training iteration 99.
[32m[0906 18-48-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03266, current rewards: -0.95617, mean: -0.09562
[32m[0906 18-48-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03333, current rewards: 4.62726, mean: 0.07712
[32m[0906 18-48-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03350, current rewards: 10.17726, mean: 0.09252
[32m[0906 18-48-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03352, current rewards: 15.56262, mean: 0.09727
[32m[0906 18-48-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03356, current rewards: 21.15551, mean: 0.10074
[32m[0906 18-48-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03350, current rewards: 26.75165, mean: 0.10289
[32m[0906 18-48-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03327, current rewards: 32.34541, mean: 0.10434
[32m[0906 18-48-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03316, current rewards: 37.94217, mean: 0.10539
[32m[0906 18-48-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03309, current rewards: 43.54517, mean: 0.10621
[32m[0906 18-48-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03301, current rewards: 49.14323, mean: 0.10683
[32m[0906 18-48-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03296, current rewards: 54.73772, mean: 0.10733
[32m[0906 18-48-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03293, current rewards: 60.36835, mean: 0.10780
[32m[0906 18-48-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03290, current rewards: 65.96518, mean: 0.10814
[32m[0906 18-48-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03289, current rewards: 71.55723, mean: 0.10842
[32m[0906 18-48-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03287, current rewards: 77.14607, mean: 0.10866
[32m[0906 18-48-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03286, current rewards: 82.73747, mean: 0.10887
[32m[0906 18-49-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03284, current rewards: 86.18706, mean: 0.10640
[32m[0906 18-49-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03283, current rewards: 91.77518, mean: 0.10672
[32m[0906 18-49-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03280, current rewards: 97.36352, mean: 0.10699
[32m[0906 18-49-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03280, current rewards: 102.95952, mean: 0.10725
[32m[0906 18-49-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03279, current rewards: 108.54909, mean: 0.10747
[32m[0906 18-49-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03279, current rewards: 114.13483, mean: 0.10767
[32m[0906 18-49-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03278, current rewards: 119.72619, mean: 0.10786
[32m[0906 18-49-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03278, current rewards: 125.31890, mean: 0.10803
[32m[0906 18-49-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03278, current rewards: 130.91231, mean: 0.10819
[32m[0906 18-49-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03279, current rewards: 136.50009, mean: 0.10833
[32m[0906 18-49-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03279, current rewards: 142.09312, mean: 0.10847
[32m[0906 18-49-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03277, current rewards: 147.89982, mean: 0.10875
[32m[0906 18-49-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03277, current rewards: 149.45466, mean: 0.10600
[32m[0906 18-49-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03275, current rewards: 155.04882, mean: 0.10620
[32m[0906 18-49-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03274, current rewards: 160.64342, mean: 0.10639
[32m[0906 18-49-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03273, current rewards: 166.23797, mean: 0.10656
[32m[0906 18-49-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03272, current rewards: 171.83329, mean: 0.10673
[32m[0906 18-49-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03272, current rewards: 177.42815, mean: 0.10688
[32m[0906 18-49-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03271, current rewards: 183.02345, mean: 0.10703
[32m[0906 18-49-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03271, current rewards: 182.15359, mean: 0.10350
[32m[0906 18-49-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03271, current rewards: 187.52960, mean: 0.10361
[32m[0906 18-49-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03271, current rewards: 193.11495, mean: 0.10383
[32m[0906 18-49-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03271, current rewards: 198.68441, mean: 0.10402
[32m[0906 18-49-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03271, current rewards: 204.25932, mean: 0.10421
[32m[0906 18-49-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03271, current rewards: 209.83439, mean: 0.10440
[32m[0906 18-49-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03271, current rewards: 215.41042, mean: 0.10457
[32m[0906 18-49-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03271, current rewards: 220.98333, mean: 0.10473
[32m[0906 18-49-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03269, current rewards: 226.55649, mean: 0.10489
[32m[0906 18-49-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03269, current rewards: 232.23904, mean: 0.10509
[32m[0906 18-49-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03268, current rewards: 235.71046, mean: 0.10430
[32m[0906 18-49-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03268, current rewards: 241.29187, mean: 0.10446
[32m[0906 18-49-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03268, current rewards: 246.87193, mean: 0.10461
[32m[0906 18-49-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03268, current rewards: 252.45631, mean: 0.10475
[32m[0906 18-49-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03269, current rewards: 258.03197, mean: 0.10489
[32m[0906 18-49-56 @Agent.py:117][0m Average action selection time: 0.0327
[32m[0906 18-49-56 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-49-57 @MBExp.py:227][0m Rewards obtained: [262.49571154560135], Lows: [5], Highs: [6], Total time: 8458.501428999993
[32m[0906 18-53-20 @MBExp.py:144][0m ####################################################################
[32m[0906 18-53-20 @MBExp.py:145][0m Starting training iteration 100.
[32m[0906 18-53-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03255, current rewards: -2.24200, mean: -0.22420
[32m[0906 18-53-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03328, current rewards: 3.37939, mean: 0.05632
[32m[0906 18-53-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03337, current rewards: 8.97447, mean: 0.08159
[32m[0906 18-53-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03333, current rewards: 14.42095, mean: 0.09013
[32m[0906 18-53-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03336, current rewards: 19.96600, mean: 0.09508
[32m[0906 18-53-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03335, current rewards: 23.46304, mean: 0.09024
[32m[0906 18-53-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03336, current rewards: 29.07770, mean: 0.09380
[32m[0906 18-53-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03319, current rewards: 34.69262, mean: 0.09637
[32m[0906 18-53-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03312, current rewards: 40.30288, mean: 0.09830
[32m[0906 18-53-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03307, current rewards: 45.91806, mean: 0.09982
[32m[0906 18-53-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03303, current rewards: 51.52763, mean: 0.10103
[32m[0906 18-53-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03302, current rewards: 57.18251, mean: 0.10211
[32m[0906 18-53-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03298, current rewards: 62.78422, mean: 0.10292
[32m[0906 18-53-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03294, current rewards: 68.38544, mean: 0.10361
[32m[0906 18-53-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03290, current rewards: 73.98777, mean: 0.10421
[32m[0906 18-53-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03289, current rewards: 79.59179, mean: 0.10473
[32m[0906 18-53-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03287, current rewards: 85.19027, mean: 0.10517
[32m[0906 18-53-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03285, current rewards: 90.30499, mean: 0.10501
[32m[0906 18-53-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03283, current rewards: 95.79809, mean: 0.10527
[32m[0906 18-53-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03281, current rewards: 101.29640, mean: 0.10552
[32m[0906 18-53-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03279, current rewards: 106.79460, mean: 0.10574
[32m[0906 18-53-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03277, current rewards: 112.29145, mean: 0.10594
[32m[0906 18-53-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03276, current rewards: 117.78698, mean: 0.10611
[32m[0906 18-53-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03275, current rewards: 123.28521, mean: 0.10628
[32m[0906 18-54-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03275, current rewards: 128.80655, mean: 0.10645
[32m[0906 18-54-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03274, current rewards: 134.39314, mean: 0.10666
[32m[0906 18-54-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03273, current rewards: 139.97812, mean: 0.10685
[32m[0906 18-54-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03272, current rewards: 145.47681, mean: 0.10697
[32m[0906 18-54-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03272, current rewards: 151.06868, mean: 0.10714
[32m[0906 18-54-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03271, current rewards: 156.66184, mean: 0.10730
[32m[0906 18-54-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03271, current rewards: 162.24677, mean: 0.10745
[32m[0906 18-54-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03270, current rewards: 167.82594, mean: 0.10758
[32m[0906 18-54-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03269, current rewards: 173.41077, mean: 0.10771
[32m[0906 18-54-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03269, current rewards: 178.99289, mean: 0.10783
[32m[0906 18-54-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03269, current rewards: 184.57689, mean: 0.10794
[32m[0906 18-54-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03269, current rewards: 190.26509, mean: 0.10811
[32m[0906 18-54-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03269, current rewards: 195.85407, mean: 0.10821
[32m[0906 18-54-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03269, current rewards: 198.21065, mean: 0.10656
[32m[0906 18-54-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03269, current rewards: 203.94286, mean: 0.10678
[32m[0906 18-54-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03269, current rewards: 209.68426, mean: 0.10698
[32m[0906 18-54-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03268, current rewards: 215.42442, mean: 0.10718
[32m[0906 18-54-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03268, current rewards: 221.16179, mean: 0.10736
[32m[0906 18-54-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03268, current rewards: 226.89372, mean: 0.10753
[32m[0906 18-54-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03268, current rewards: 228.32136, mean: 0.10570
[32m[0906 18-54-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03268, current rewards: 233.77161, mean: 0.10578
[32m[0906 18-54-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03267, current rewards: 239.18453, mean: 0.10583
[32m[0906 18-54-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03267, current rewards: 244.59827, mean: 0.10589
[32m[0906 18-54-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03267, current rewards: 250.01281, mean: 0.10594
[32m[0906 18-54-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03267, current rewards: 253.32714, mean: 0.10511
[32m[0906 18-54-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03267, current rewards: 258.92927, mean: 0.10526
[32m[0906 18-54-43 @Agent.py:117][0m Average action selection time: 0.0327
[32m[0906 18-54-43 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-54-43 @MBExp.py:227][0m Rewards obtained: [263.40851412367755], Lows: [4], Highs: [7], Total time: 8540.916156999992
[32m[0906 18-58-07 @MBExp.py:144][0m ####################################################################
[32m[0906 18-58-07 @MBExp.py:145][0m Starting training iteration 101.
[32m[0906 18-58-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03268, current rewards: -3.56240, mean: -0.35624
[32m[0906 18-58-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03328, current rewards: 3.74621, mean: 0.06244
[32m[0906 18-58-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03333, current rewards: 9.57164, mean: 0.08701
[32m[0906 18-58-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03345, current rewards: 15.45988, mean: 0.09662
[32m[0906 18-58-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03345, current rewards: 21.35673, mean: 0.10170
[32m[0906 18-58-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03340, current rewards: 27.24407, mean: 0.10478
[32m[0906 18-58-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03340, current rewards: 33.13662, mean: 0.10689
[32m[0906 18-58-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03327, current rewards: 39.03953, mean: 0.10844
[32m[0906 18-58-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03318, current rewards: 44.94746, mean: 0.10963
[32m[0906 18-58-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03312, current rewards: 50.84163, mean: 0.11053
[32m[0906 18-58-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03306, current rewards: 53.89209, mean: 0.10567
[32m[0906 18-58-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03303, current rewards: 60.58893, mean: 0.10819
[32m[0906 18-58-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03299, current rewards: 67.26209, mean: 0.11027
[32m[0906 18-58-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03297, current rewards: 73.57057, mean: 0.11147
[32m[0906 18-58-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03294, current rewards: 80.56519, mean: 0.11347
[32m[0906 18-58-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03294, current rewards: 87.60077, mean: 0.11526
[32m[0906 18-58-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03291, current rewards: 93.51780, mean: 0.11545
[32m[0906 18-58-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03288, current rewards: 100.35700, mean: 0.11669
[32m[0906 18-58-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03286, current rewards: 106.40708, mean: 0.11693
[32m[0906 18-58-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03284, current rewards: 112.04574, mean: 0.11671
[32m[0906 18-58-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03282, current rewards: 109.45692, mean: 0.10837
[32m[0906 18-58-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03281, current rewards: 115.72148, mean: 0.10917
[32m[0906 18-58-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03279, current rewards: 121.99258, mean: 0.10990
[32m[0906 18-58-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03278, current rewards: 128.26724, mean: 0.11058
[32m[0906 18-58-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03276, current rewards: 134.54107, mean: 0.11119
[32m[0906 18-58-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03277, current rewards: 140.81418, mean: 0.11176
[32m[0906 18-58-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03276, current rewards: 147.08494, mean: 0.11228
[32m[0906 18-58-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03275, current rewards: 136.47847, mean: 0.10035
[32m[0906 18-58-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03274, current rewards: 86.47847, mean: 0.06133
[32m[0906 18-58-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03272, current rewards: 36.47847, mean: 0.02499
[32m[0906 18-58-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03272, current rewards: -13.52153, mean: -0.00895
[32m[0906 18-58-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03271, current rewards: -63.52153, mean: -0.04072
[32m[0906 18-59-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03269, current rewards: -113.52153, mean: -0.07051
[32m[0906 18-59-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03268, current rewards: -163.52153, mean: -0.09851
[32m[0906 18-59-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03268, current rewards: -213.52153, mean: -0.12487
[32m[0906 18-59-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03267, current rewards: -263.52153, mean: -0.14973
[32m[0906 18-59-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03267, current rewards: -313.52153, mean: -0.17322
[32m[0906 18-59-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03267, current rewards: -363.52153, mean: -0.19544
[32m[0906 18-59-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03266, current rewards: -413.52153, mean: -0.21650
[32m[0906 18-59-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03266, current rewards: -463.52153, mean: -0.23649
[32m[0906 18-59-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03266, current rewards: -513.52153, mean: -0.25548
[32m[0906 18-59-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03265, current rewards: -563.52153, mean: -0.27355
[32m[0906 18-59-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03266, current rewards: -613.52153, mean: -0.29077
[32m[0906 18-59-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03265, current rewards: -663.52153, mean: -0.30719
[32m[0906 18-59-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03265, current rewards: -713.52153, mean: -0.32286
[32m[0906 18-59-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03265, current rewards: -763.52153, mean: -0.33784
[32m[0906 18-59-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03264, current rewards: -813.52153, mean: -0.35217
[32m[0906 18-59-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03264, current rewards: -863.52153, mean: -0.36590
[32m[0906 18-59-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03264, current rewards: -913.52153, mean: -0.37905
[32m[0906 18-59-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03264, current rewards: -963.52153, mean: -0.39168
[32m[0906 18-59-29 @Agent.py:117][0m Average action selection time: 0.0326
[32m[0906 18-59-29 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-59-30 @MBExp.py:227][0m Rewards obtained: [-1003.5215332942219], Lows: [7], Highs: [1156], Total time: 8623.249854999993
[32m[0906 19-02-57 @MBExp.py:144][0m ####################################################################
[32m[0906 19-02-57 @MBExp.py:145][0m Starting training iteration 102.
[32m[0906 19-02-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03270, current rewards: 0.00296, mean: 0.00030
[32m[0906 19-02-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03327, current rewards: 5.45650, mean: 0.09094
[32m[0906 19-03-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03338, current rewards: 11.00037, mean: 0.10000
[32m[0906 19-03-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03335, current rewards: 16.52956, mean: 0.10331
[32m[0906 19-03-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03335, current rewards: 22.06095, mean: 0.10505
[32m[0906 19-03-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03339, current rewards: 27.58935, mean: 0.10611
[32m[0906 19-03-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03342, current rewards: 33.11870, mean: 0.10683
[32m[0906 19-03-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03325, current rewards: 38.64601, mean: 0.10735
[32m[0906 19-03-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03315, current rewards: 44.17911, mean: 0.10775
[32m[0906 19-03-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03308, current rewards: 49.70873, mean: 0.10806
[32m[0906 19-03-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03302, current rewards: 55.19474, mean: 0.10822
[32m[0906 19-03-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03296, current rewards: 60.71608, mean: 0.10842
[32m[0906 19-03-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03293, current rewards: 66.23893, mean: 0.10859
[32m[0906 19-03-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03291, current rewards: 71.77016, mean: 0.10874
[32m[0906 19-03-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03288, current rewards: 77.29073, mean: 0.10886
[32m[0906 19-03-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03287, current rewards: 82.81245, mean: 0.10896
[32m[0906 19-03-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03285, current rewards: 88.33324, mean: 0.10905
[32m[0906 19-03-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03284, current rewards: 93.85228, mean: 0.10913
[32m[0906 19-03-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03281, current rewards: 99.45473, mean: 0.10929
[32m[0906 19-03-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03280, current rewards: 105.04074, mean: 0.10942
[32m[0906 19-03-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03279, current rewards: 108.50628, mean: 0.10743
[32m[0906 19-03-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03279, current rewards: 113.86637, mean: 0.10742
[32m[0906 19-03-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03276, current rewards: 119.22225, mean: 0.10741
[32m[0906 19-03-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03275, current rewards: 124.57790, mean: 0.10739
[32m[0906 19-03-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03275, current rewards: 129.93328, mean: 0.10738
[32m[0906 19-03-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03275, current rewards: 129.95140, mean: 0.10314
[32m[0906 19-03-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03274, current rewards: 135.45296, mean: 0.10340
[32m[0906 19-03-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03274, current rewards: 140.91163, mean: 0.10361
[32m[0906 19-03-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03273, current rewards: 146.41797, mean: 0.10384
[32m[0906 19-03-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03273, current rewards: 151.92523, mean: 0.10406
[32m[0906 19-03-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03272, current rewards: 157.43139, mean: 0.10426
[32m[0906 19-03-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03271, current rewards: 162.93223, mean: 0.10444
[32m[0906 19-03-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03271, current rewards: 168.44163, mean: 0.10462
[32m[0906 19-03-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03269, current rewards: 173.93724, mean: 0.10478
[32m[0906 19-03-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03268, current rewards: 179.44052, mean: 0.10494
[32m[0906 19-03-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03269, current rewards: 184.94836, mean: 0.10508
[32m[0906 19-03-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03268, current rewards: 190.45711, mean: 0.10522
[32m[0906 19-03-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03268, current rewards: 185.52501, mean: 0.09974
[32m[0906 19-04-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03268, current rewards: 191.05772, mean: 0.10003
[32m[0906 19-04-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03267, current rewards: 196.59667, mean: 0.10030
[32m[0906 19-04-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03267, current rewards: 202.13456, mean: 0.10056
[32m[0906 19-04-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03267, current rewards: 207.67273, mean: 0.10081
[32m[0906 19-04-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03267, current rewards: 213.21394, mean: 0.10105
[32m[0906 19-04-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03267, current rewards: 218.73674, mean: 0.10127
[32m[0906 19-04-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03267, current rewards: 224.27367, mean: 0.10148
[32m[0906 19-04-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03266, current rewards: 229.80926, mean: 0.10169
[32m[0906 19-04-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03266, current rewards: 235.34656, mean: 0.10188
[32m[0906 19-04-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03266, current rewards: 239.72401, mean: 0.10158
[32m[0906 19-04-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03266, current rewards: 245.21614, mean: 0.10175
[32m[0906 19-04-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03266, current rewards: 250.70044, mean: 0.10191
[32m[0906 19-04-19 @Agent.py:117][0m Average action selection time: 0.0327
[32m[0906 19-04-19 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-04-19 @MBExp.py:227][0m Rewards obtained: [255.09100984956095], Lows: [8], Highs: [3], Total time: 8705.639648999993
[32m[0906 19-07-47 @MBExp.py:144][0m ####################################################################
[32m[0906 19-07-47 @MBExp.py:145][0m Starting training iteration 103.
[32m[0906 19-07-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03411, current rewards: -4.41302, mean: -0.44130
[32m[0906 19-07-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03356, current rewards: 1.48050, mean: 0.02468
[32m[0906 19-07-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03355, current rewards: 7.20208, mean: 0.06547
[32m[0906 19-07-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03356, current rewards: 12.89875, mean: 0.08062
[32m[0906 19-07-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03355, current rewards: 12.35279, mean: 0.05882
[32m[0906 19-07-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03351, current rewards: 18.04267, mean: 0.06939
[32m[0906 19-07-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03351, current rewards: 23.73652, mean: 0.07657
[32m[0906 19-08-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03340, current rewards: 29.42914, mean: 0.08175
[32m[0906 19-08-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03326, current rewards: 33.95979, mean: 0.08283
[32m[0906 19-08-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03318, current rewards: 41.87741, mean: 0.09104
[32m[0906 19-08-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03311, current rewards: 49.33760, mean: 0.09674
[32m[0906 19-08-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03305, current rewards: 56.79780, mean: 0.10142
[32m[0906 19-08-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03299, current rewards: 64.25800, mean: 0.10534
[32m[0906 19-08-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03295, current rewards: 71.71819, mean: 0.10866
[32m[0906 19-08-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03292, current rewards: 79.17838, mean: 0.11152
[32m[0906 19-08-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03289, current rewards: 72.34117, mean: 0.09519
[32m[0906 19-08-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03288, current rewards: 77.73085, mean: 0.09596
[32m[0906 19-08-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03285, current rewards: 83.00097, mean: 0.09651
[32m[0906 19-08-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03283, current rewards: 88.04093, mean: 0.09675
[32m[0906 19-08-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03280, current rewards: 93.07282, mean: 0.09695
[32m[0906 19-08-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03279, current rewards: 98.10073, mean: 0.09713
[32m[0906 19-08-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03277, current rewards: 103.13760, mean: 0.09730
[32m[0906 19-08-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03275, current rewards: 108.17836, mean: 0.09746
[32m[0906 19-08-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03273, current rewards: 113.21645, mean: 0.09760
[32m[0906 19-08-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03273, current rewards: 118.25589, mean: 0.09773
[32m[0906 19-08-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03272, current rewards: 118.18205, mean: 0.09380
[32m[0906 19-08-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03273, current rewards: 124.64451, mean: 0.09515
[32m[0906 19-08-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03273, current rewards: 130.98342, mean: 0.09631
[32m[0906 19-08-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03273, current rewards: 137.36370, mean: 0.09742
[32m[0906 19-08-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03272, current rewards: 143.93865, mean: 0.09859
[32m[0906 19-08-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03271, current rewards: 150.41586, mean: 0.09961
[32m[0906 19-08-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03270, current rewards: 153.95931, mean: 0.09869
[32m[0906 19-08-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03269, current rewards: 159.44869, mean: 0.09904
[32m[0906 19-08-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03268, current rewards: 164.93484, mean: 0.09936
[32m[0906 19-08-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03268, current rewards: 170.32437, mean: 0.09960
[32m[0906 19-08-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03268, current rewards: 175.83045, mean: 0.09990
[32m[0906 19-08-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03269, current rewards: 181.34448, mean: 0.10019
[32m[0906 19-08-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03269, current rewards: 186.84732, mean: 0.10046
[32m[0906 19-08-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03269, current rewards: 192.35874, mean: 0.10071
[32m[0906 19-08-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03269, current rewards: 197.86428, mean: 0.10095
[32m[0906 19-08-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03268, current rewards: 203.37516, mean: 0.10118
[32m[0906 19-08-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03269, current rewards: 208.88249, mean: 0.10140
[32m[0906 19-08-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03268, current rewards: 214.27401, mean: 0.10155
[32m[0906 19-08-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03268, current rewards: 219.81360, mean: 0.10177
[32m[0906 19-09-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03267, current rewards: 225.34720, mean: 0.10197
[32m[0906 19-09-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03267, current rewards: 230.88691, mean: 0.10216
[32m[0906 19-09-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03267, current rewards: 236.41831, mean: 0.10235
[32m[0906 19-09-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03267, current rewards: 241.95091, mean: 0.10252
[32m[0906 19-09-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03267, current rewards: 247.49196, mean: 0.10269
[32m[0906 19-09-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03266, current rewards: 253.02385, mean: 0.10286
[32m[0906 19-09-10 @Agent.py:117][0m Average action selection time: 0.0327
[32m[0906 19-09-10 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-09-10 @MBExp.py:227][0m Rewards obtained: [257.37728048488214], Lows: [7], Highs: [18], Total time: 8788.033338999994
[32m[0906 19-12-41 @MBExp.py:144][0m ####################################################################
[32m[0906 19-12-41 @MBExp.py:145][0m Starting training iteration 104.
[32m[0906 19-12-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03232, current rewards: -4.89347, mean: -0.48935
[32m[0906 19-12-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03343, current rewards: 1.06515, mean: 0.01775
[32m[0906 19-12-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03345, current rewards: 7.02029, mean: 0.06382
[32m[0906 19-12-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03343, current rewards: 12.97759, mean: 0.08111
[32m[0906 19-12-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03344, current rewards: 18.93130, mean: 0.09015
[32m[0906 19-12-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03341, current rewards: 24.88589, mean: 0.09571
[32m[0906 19-12-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03340, current rewards: 30.84298, mean: 0.09949
[32m[0906 19-12-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03327, current rewards: 36.79989, mean: 0.10222
[32m[0906 19-12-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03315, current rewards: 42.64799, mean: 0.10402
[32m[0906 19-12-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03307, current rewards: 48.59017, mean: 0.10563
[32m[0906 19-12-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03302, current rewards: 54.52684, mean: 0.10692
[32m[0906 19-13-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03298, current rewards: 50.70593, mean: 0.09055
[32m[0906 19-13-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03294, current rewards: 56.26085, mean: 0.09223
[32m[0906 19-13-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03291, current rewards: 61.81849, mean: 0.09366
[32m[0906 19-13-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03289, current rewards: 67.36616, mean: 0.09488
[32m[0906 19-13-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03289, current rewards: 72.91253, mean: 0.09594
[32m[0906 19-13-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03285, current rewards: 78.46649, mean: 0.09687
[32m[0906 19-13-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03282, current rewards: 84.31038, mean: 0.09804
[32m[0906 19-13-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03278, current rewards: 89.86111, mean: 0.09875
[32m[0906 19-13-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03278, current rewards: 95.41245, mean: 0.09939
[32m[0906 19-13-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03277, current rewards: 100.96219, mean: 0.09996
[32m[0906 19-13-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03276, current rewards: 107.24066, mean: 0.10117
[32m[0906 19-13-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03275, current rewards: 112.79837, mean: 0.10162
[32m[0906 19-13-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03274, current rewards: 118.36256, mean: 0.10204
[32m[0906 19-13-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03273, current rewards: 123.92367, mean: 0.10242
[32m[0906 19-13-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03272, current rewards: 129.49332, mean: 0.10277
[32m[0906 19-13-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03270, current rewards: 135.05424, mean: 0.10309
[32m[0906 19-13-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03270, current rewards: 138.76108, mean: 0.10203
[32m[0906 19-13-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03270, current rewards: 144.29584, mean: 0.10234
[32m[0906 19-13-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03270, current rewards: 149.82722, mean: 0.10262
[32m[0906 19-13-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03270, current rewards: 148.40796, mean: 0.09828
[32m[0906 19-13-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03270, current rewards: 156.26750, mean: 0.10017
[32m[0906 19-13-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03269, current rewards: 164.12704, mean: 0.10194
[32m[0906 19-13-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03268, current rewards: 170.51840, mean: 0.10272
[32m[0906 19-13-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03267, current rewards: 123.66841, mean: 0.07232
[32m[0906 19-13-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03267, current rewards: 73.66841, mean: 0.04186
[32m[0906 19-13-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03267, current rewards: 23.66841, mean: 0.01308
[32m[0906 19-13-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03266, current rewards: -26.33159, mean: -0.01416
[32m[0906 19-13-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03265, current rewards: -76.33159, mean: -0.03996
[32m[0906 19-13-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03265, current rewards: -126.33159, mean: -0.06445
[32m[0906 19-13-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03265, current rewards: -176.33159, mean: -0.08773
[32m[0906 19-13-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03264, current rewards: -226.33159, mean: -0.10987
[32m[0906 19-13-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03264, current rewards: -276.33159, mean: -0.13096
[32m[0906 19-13-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03265, current rewards: -326.33159, mean: -0.15108
[32m[0906 19-13-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03264, current rewards: -376.33159, mean: -0.17029
[32m[0906 19-13-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03264, current rewards: -426.33159, mean: -0.18864
[32m[0906 19-13-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03265, current rewards: -476.33159, mean: -0.20620
[32m[0906 19-13-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03265, current rewards: -526.33159, mean: -0.22302
[32m[0906 19-14-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03264, current rewards: -576.33159, mean: -0.23914
[32m[0906 19-14-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03264, current rewards: -626.33159, mean: -0.25461
[32m[0906 19-14-03 @Agent.py:117][0m Average action selection time: 0.0326
[32m[0906 19-14-03 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-14-04 @MBExp.py:227][0m Rewards obtained: [-666.3315924839917], Lows: [11], Highs: [840], Total time: 8870.370976999995
[32m[0906 19-17-36 @MBExp.py:144][0m ####################################################################
[32m[0906 19-17-36 @MBExp.py:145][0m Starting training iteration 105.
[32m[0906 19-17-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03244, current rewards: -2.24068, mean: -0.22407
[32m[0906 19-17-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03346, current rewards: 3.49943, mean: 0.05832
[32m[0906 19-17-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03337, current rewards: 9.10108, mean: 0.08274
[32m[0906 19-17-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03340, current rewards: 14.71667, mean: 0.09198
[32m[0906 19-17-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03345, current rewards: 20.33295, mean: 0.09682
[32m[0906 19-17-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03343, current rewards: 25.94490, mean: 0.09979
[32m[0906 19-17-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03342, current rewards: 31.55812, mean: 0.10180
[32m[0906 19-17-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03326, current rewards: 37.17299, mean: 0.10326
[32m[0906 19-17-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03317, current rewards: 42.78512, mean: 0.10435
[32m[0906 19-17-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03311, current rewards: 46.22528, mean: 0.10049
[32m[0906 19-17-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03307, current rewards: 51.70344, mean: 0.10138
[32m[0906 19-17-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03304, current rewards: 57.17978, mean: 0.10211
[32m[0906 19-17-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03299, current rewards: 62.65826, mean: 0.10272
[32m[0906 19-17-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03297, current rewards: 68.13679, mean: 0.10324
[32m[0906 19-18-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03295, current rewards: 73.61356, mean: 0.10368
[32m[0906 19-18-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03291, current rewards: 79.09435, mean: 0.10407
[32m[0906 19-18-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03288, current rewards: 84.57080, mean: 0.10441
[32m[0906 19-18-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03285, current rewards: 89.03167, mean: 0.10353
[32m[0906 19-18-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03281, current rewards: 94.58725, mean: 0.10394
[32m[0906 19-18-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03278, current rewards: 100.14755, mean: 0.10432
[32m[0906 19-18-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03279, current rewards: 105.71157, mean: 0.10466
[32m[0906 19-18-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03277, current rewards: 111.27110, mean: 0.10497
[32m[0906 19-18-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03277, current rewards: 116.83509, mean: 0.10526
[32m[0906 19-18-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03276, current rewards: 123.10598, mean: 0.10613
[32m[0906 19-18-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03275, current rewards: 128.66350, mean: 0.10633
[32m[0906 19-18-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03274, current rewards: 134.15631, mean: 0.10647
[32m[0906 19-18-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03274, current rewards: 139.70236, mean: 0.10664
[32m[0906 19-18-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03273, current rewards: 145.23852, mean: 0.10679
[32m[0906 19-18-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03273, current rewards: 150.78943, mean: 0.10694
[32m[0906 19-18-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03271, current rewards: 156.32619, mean: 0.10707
[32m[0906 19-18-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03271, current rewards: 161.86706, mean: 0.10720
[32m[0906 19-18-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03270, current rewards: 163.19791, mean: 0.10461
[32m[0906 19-18-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03270, current rewards: 168.71174, mean: 0.10479
[32m[0906 19-18-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03268, current rewards: 173.91437, mean: 0.10477
[32m[0906 19-18-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03268, current rewards: 179.25333, mean: 0.10483
[32m[0906 19-18-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03269, current rewards: 184.59000, mean: 0.10488
[32m[0906 19-18-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03269, current rewards: 189.92652, mean: 0.10493
[32m[0906 19-18-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03269, current rewards: 195.26261, mean: 0.10498
[32m[0906 19-18-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03269, current rewards: 200.60324, mean: 0.10503
[32m[0906 19-18-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03269, current rewards: 205.94110, mean: 0.10507
[32m[0906 19-18-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03269, current rewards: 211.28143, mean: 0.10512
[32m[0906 19-18-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03270, current rewards: 215.67771, mean: 0.10470
[32m[0906 19-18-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03269, current rewards: 221.33398, mean: 0.10490
[32m[0906 19-18-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03269, current rewards: 226.89190, mean: 0.10504
[32m[0906 19-18-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03269, current rewards: 232.45194, mean: 0.10518
[32m[0906 19-18-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03269, current rewards: 238.01226, mean: 0.10532
[32m[0906 19-18-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03270, current rewards: 243.57705, mean: 0.10544
[32m[0906 19-18-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03269, current rewards: 249.13356, mean: 0.10557
[32m[0906 19-18-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03269, current rewards: 252.98435, mean: 0.10497
[32m[0906 19-18-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03268, current rewards: 258.35765, mean: 0.10502
[32m[0906 19-18-59 @Agent.py:117][0m Average action selection time: 0.0327
[32m[0906 19-18-59 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-18-59 @MBExp.py:227][0m Rewards obtained: [262.5744830185049], Lows: [4], Highs: [5], Total time: 8952.826377999994
[32m[0906 19-22-33 @MBExp.py:144][0m ####################################################################
[32m[0906 19-22-33 @MBExp.py:145][0m Starting training iteration 106.
[32m[0906 19-22-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03302, current rewards: -0.10846, mean: -0.01085
[32m[0906 19-22-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03339, current rewards: 5.46492, mean: 0.09108
[32m[0906 19-22-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03332, current rewards: 11.04011, mean: 0.10036
[32m[0906 19-22-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03335, current rewards: 16.61506, mean: 0.10384
[32m[0906 19-22-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03333, current rewards: 22.18996, mean: 0.10567
[32m[0906 19-22-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03333, current rewards: 25.74768, mean: 0.09903
[32m[0906 19-22-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03335, current rewards: 31.16424, mean: 0.10053
[32m[0906 19-22-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03336, current rewards: 36.58231, mean: 0.10162
[32m[0906 19-22-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03321, current rewards: 41.95719, mean: 0.10233
[32m[0906 19-22-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03312, current rewards: 47.35019, mean: 0.10294
[32m[0906 19-22-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03304, current rewards: 52.74117, mean: 0.10341
[32m[0906 19-22-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03302, current rewards: 58.13253, mean: 0.10381
[32m[0906 19-22-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03297, current rewards: 57.21825, mean: 0.09380
[32m[0906 19-22-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03294, current rewards: 62.87862, mean: 0.09527
[32m[0906 19-22-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03291, current rewards: 68.53068, mean: 0.09652
[32m[0906 19-22-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03290, current rewards: 74.17872, mean: 0.09760
[32m[0906 19-23-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03285, current rewards: 79.82366, mean: 0.09855
[32m[0906 19-23-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03283, current rewards: 85.46911, mean: 0.09938
[32m[0906 19-23-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03281, current rewards: 91.95703, mean: 0.10105
[32m[0906 19-23-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03280, current rewards: 97.48014, mean: 0.10154
[32m[0906 19-23-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03279, current rewards: 103.00553, mean: 0.10199
[32m[0906 19-23-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03277, current rewards: 108.53053, mean: 0.10239
[32m[0906 19-23-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03277, current rewards: 114.05631, mean: 0.10275
[32m[0906 19-23-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03276, current rewards: 119.58217, mean: 0.10309
[32m[0906 19-23-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03276, current rewards: 125.00552, mean: 0.10331
[32m[0906 19-23-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03275, current rewards: 128.40192, mean: 0.10191
[32m[0906 19-23-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03274, current rewards: 133.93549, mean: 0.10224
[32m[0906 19-23-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03275, current rewards: 139.46843, mean: 0.10255
[32m[0906 19-23-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03275, current rewards: 144.99823, mean: 0.10284
[32m[0906 19-23-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03274, current rewards: 150.52874, mean: 0.10310
[32m[0906 19-23-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03274, current rewards: 156.06607, mean: 0.10336
[32m[0906 19-23-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03272, current rewards: 161.58997, mean: 0.10358
[32m[0906 19-23-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03271, current rewards: 167.25703, mean: 0.10389
[32m[0906 19-23-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03271, current rewards: 172.78564, mean: 0.10409
[32m[0906 19-23-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03270, current rewards: 176.22055, mean: 0.10305
[32m[0906 19-23-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03270, current rewards: 181.70606, mean: 0.10324
[32m[0906 19-23-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03270, current rewards: 187.18546, mean: 0.10342
[32m[0906 19-23-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03270, current rewards: 192.66640, mean: 0.10358
[32m[0906 19-23-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03270, current rewards: 198.15167, mean: 0.10374
[32m[0906 19-23-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03270, current rewards: 203.62998, mean: 0.10389
[32m[0906 19-23-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03270, current rewards: 209.11092, mean: 0.10404
[32m[0906 19-23-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03270, current rewards: 214.70420, mean: 0.10423
[32m[0906 19-23-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03269, current rewards: 220.20056, mean: 0.10436
[32m[0906 19-23-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03269, current rewards: 225.70067, mean: 0.10449
[32m[0906 19-23-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03268, current rewards: 231.19737, mean: 0.10461
[32m[0906 19-23-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03268, current rewards: 236.70056, mean: 0.10473
[32m[0906 19-23-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03267, current rewards: 242.19379, mean: 0.10485
[32m[0906 19-23-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03266, current rewards: 244.42968, mean: 0.10357
[32m[0906 19-23-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03267, current rewards: 249.96048, mean: 0.10372
[32m[0906 19-23-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03266, current rewards: 255.37607, mean: 0.10381
[32m[0906 19-23-56 @Agent.py:117][0m Average action selection time: 0.0327
[32m[0906 19-23-56 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-23-56 @MBExp.py:227][0m Rewards obtained: [259.7932120953869], Lows: [6], Highs: [4], Total time: 9035.240027999995
[32m[0906 19-27-32 @MBExp.py:144][0m ####################################################################
[32m[0906 19-27-32 @MBExp.py:145][0m Starting training iteration 107.
[32m[0906 19-27-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03315, current rewards: -0.05872, mean: -0.00587
[32m[0906 19-27-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03316, current rewards: 5.33160, mean: 0.08886
[32m[0906 19-27-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03330, current rewards: 10.73303, mean: 0.09757
[32m[0906 19-27-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03335, current rewards: 16.13419, mean: 0.10084
[32m[0906 19-27-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03336, current rewards: 21.53357, mean: 0.10254
[32m[0906 19-27-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03335, current rewards: 24.98909, mean: 0.09611
[32m[0906 19-27-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03337, current rewards: 30.33300, mean: 0.09785
[32m[0906 19-27-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03340, current rewards: 35.60746, mean: 0.09891
[32m[0906 19-27-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03325, current rewards: 40.98632, mean: 0.09997
[32m[0906 19-27-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03313, current rewards: 46.36901, mean: 0.10080
[32m[0906 19-27-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03308, current rewards: 51.75116, mean: 0.10147
[32m[0906 19-27-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03303, current rewards: 57.13538, mean: 0.10203
[32m[0906 19-27-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03298, current rewards: 59.47389, mean: 0.09750
[32m[0906 19-27-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03296, current rewards: 64.93986, mean: 0.09839
[32m[0906 19-27-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03293, current rewards: 70.40650, mean: 0.09916
[32m[0906 19-27-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03290, current rewards: 75.85327, mean: 0.09981
[32m[0906 19-27-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03287, current rewards: 81.31480, mean: 0.10039
[32m[0906 19-28-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03285, current rewards: 86.75147, mean: 0.10087
[32m[0906 19-28-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03285, current rewards: 92.21680, mean: 0.10134
[32m[0906 19-28-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03282, current rewards: 97.68196, mean: 0.10175
[32m[0906 19-28-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03281, current rewards: 103.15219, mean: 0.10213
[32m[0906 19-28-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03278, current rewards: 108.63021, mean: 0.10248
[32m[0906 19-28-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03277, current rewards: 114.10327, mean: 0.10280
[32m[0906 19-28-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03275, current rewards: 119.57703, mean: 0.10308
[32m[0906 19-28-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03274, current rewards: 125.04874, mean: 0.10335
[32m[0906 19-28-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03273, current rewards: 130.51234, mean: 0.10358
[32m[0906 19-28-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03271, current rewards: 131.93710, mean: 0.10072
[32m[0906 19-28-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03270, current rewards: 137.48078, mean: 0.10109
[32m[0906 19-28-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03269, current rewards: 143.02162, mean: 0.10143
[32m[0906 19-28-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03268, current rewards: 148.56370, mean: 0.10176
[32m[0906 19-28-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03268, current rewards: 154.10395, mean: 0.10206
[32m[0906 19-28-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03266, current rewards: 159.58425, mean: 0.10230
[32m[0906 19-28-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03266, current rewards: 165.12834, mean: 0.10256
[32m[0906 19-28-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03266, current rewards: 170.67437, mean: 0.10282
[32m[0906 19-28-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03265, current rewards: 176.21819, mean: 0.10305
[32m[0906 19-28-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03264, current rewards: 181.76150, mean: 0.10327
[32m[0906 19-28-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03264, current rewards: 187.30550, mean: 0.10348
[32m[0906 19-28-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03265, current rewards: 192.84885, mean: 0.10368
[32m[0906 19-28-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03264, current rewards: 198.38862, mean: 0.10387
[32m[0906 19-28-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03264, current rewards: 203.95608, mean: 0.10406
[32m[0906 19-28-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03264, current rewards: 184.23957, mean: 0.09166
[32m[0906 19-28-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03264, current rewards: 134.23957, mean: 0.06516
[32m[0906 19-28-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03265, current rewards: 84.23957, mean: 0.03992
[32m[0906 19-28-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03265, current rewards: 34.23957, mean: 0.01585
[32m[0906 19-28-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03264, current rewards: -15.76043, mean: -0.00713
[32m[0906 19-28-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03265, current rewards: -65.76043, mean: -0.02910
[32m[0906 19-28-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03265, current rewards: -115.76043, mean: -0.05011
[32m[0906 19-28-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03265, current rewards: -165.76043, mean: -0.07024
[32m[0906 19-28-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03264, current rewards: -215.76043, mean: -0.08953
[32m[0906 19-28-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03264, current rewards: -265.76043, mean: -0.10803
[32m[0906 19-28-54 @Agent.py:117][0m Average action selection time: 0.0326
[32m[0906 19-28-54 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-28-54 @MBExp.py:227][0m Rewards obtained: [-305.76043283700915], Lows: [4], Highs: [515], Total time: 9117.565052999995
[32m[0906 19-32-33 @MBExp.py:144][0m ####################################################################
[32m[0906 19-32-33 @MBExp.py:145][0m Starting training iteration 108.
[32m[0906 19-32-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03274, current rewards: 0.08568, mean: 0.00857
[32m[0906 19-32-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03327, current rewards: 5.73785, mean: 0.09563
[32m[0906 19-32-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03343, current rewards: 11.35328, mean: 0.10321
[32m[0906 19-32-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03335, current rewards: 16.97103, mean: 0.10607
[32m[0906 19-32-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03332, current rewards: 22.58759, mean: 0.10756
[32m[0906 19-32-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03336, current rewards: 28.20265, mean: 0.10847
[32m[0906 19-32-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03339, current rewards: 33.81645, mean: 0.10909
[32m[0906 19-32-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03340, current rewards: 39.57837, mean: 0.10994
[32m[0906 19-32-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03332, current rewards: 43.15554, mean: 0.10526
[32m[0906 19-32-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03324, current rewards: 48.92607, mean: 0.10636
[32m[0906 19-32-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03315, current rewards: 54.64682, mean: 0.10715
[32m[0906 19-32-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03309, current rewards: 60.30360, mean: 0.10768
[32m[0906 19-32-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03302, current rewards: 65.96012, mean: 0.10813
[32m[0906 19-32-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03299, current rewards: 71.64143, mean: 0.10855
[32m[0906 19-32-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03297, current rewards: 76.13008, mean: 0.10723
[32m[0906 19-32-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03295, current rewards: 81.65311, mean: 0.10744
[32m[0906 19-33-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03293, current rewards: 87.17209, mean: 0.10762
[32m[0906 19-33-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03293, current rewards: 92.69548, mean: 0.10779
[32m[0906 19-33-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03293, current rewards: 98.21030, mean: 0.10792
[32m[0906 19-33-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03292, current rewards: 103.72853, mean: 0.10805
[32m[0906 19-33-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03290, current rewards: 109.25296, mean: 0.10817
[32m[0906 19-33-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03290, current rewards: 113.34135, mean: 0.10693
[32m[0906 19-33-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03296, current rewards: 119.01795, mean: 0.10722
[32m[0906 19-33-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03299, current rewards: 121.20060, mean: 0.10448
[32m[0906 19-33-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03299, current rewards: 127.71361, mean: 0.10555
[32m[0906 19-33-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03298, current rewards: 133.37717, mean: 0.10585
[32m[0906 19-33-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03298, current rewards: 136.48357, mean: 0.10419
[32m[0906 19-33-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03296, current rewards: 141.87228, mean: 0.10432
[32m[0906 19-33-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03294, current rewards: 147.25391, mean: 0.10444
[32m[0906 19-33-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03293, current rewards: 152.64417, mean: 0.10455
[32m[0906 19-33-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03293, current rewards: 158.02209, mean: 0.10465
[32m[0906 19-33-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03291, current rewards: 163.40297, mean: 0.10475
[32m[0906 19-33-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03291, current rewards: 160.77324, mean: 0.09986
[32m[0906 19-33-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03290, current rewards: 166.68214, mean: 0.10041
[32m[0906 19-33-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03289, current rewards: 172.59409, mean: 0.10093
[32m[0906 19-33-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03287, current rewards: 178.50381, mean: 0.10142
[32m[0906 19-33-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03287, current rewards: 184.41187, mean: 0.10189
[32m[0906 19-33-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03285, current rewards: 190.32459, mean: 0.10233
[32m[0906 19-33-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03285, current rewards: 196.23151, mean: 0.10274
[32m[0906 19-33-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03284, current rewards: 202.14524, mean: 0.10314
[32m[0906 19-33-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03284, current rewards: 207.96427, mean: 0.10346
[32m[0906 19-33-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03283, current rewards: 213.86305, mean: 0.10382
[32m[0906 19-33-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03283, current rewards: 217.36427, mean: 0.10302
[32m[0906 19-33-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03282, current rewards: 222.93664, mean: 0.10321
[32m[0906 19-33-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03281, current rewards: 228.50894, mean: 0.10340
[32m[0906 19-33-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03281, current rewards: 234.07635, mean: 0.10357
[32m[0906 19-33-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03281, current rewards: 239.66218, mean: 0.10375
[32m[0906 19-33-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03280, current rewards: 245.23160, mean: 0.10391
[32m[0906 19-33-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03279, current rewards: 250.89207, mean: 0.10410
[32m[0906 19-33-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03279, current rewards: 256.61437, mean: 0.10431
[32m[0906 19-33-55 @Agent.py:117][0m Average action selection time: 0.0328
[32m[0906 19-33-55 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-33-55 @MBExp.py:227][0m Rewards obtained: [261.2297942570587], Lows: [8], Highs: [9], Total time: 9200.272838999996
[32m[0906 19-37-35 @MBExp.py:144][0m ####################################################################
[32m[0906 19-37-35 @MBExp.py:145][0m Starting training iteration 109.
[32m[0906 19-37-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03232, current rewards: -5.22587, mean: -0.52259
[32m[0906 19-37-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03345, current rewards: 0.46678, mean: 0.00778
[32m[0906 19-37-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03349, current rewards: 6.16307, mean: 0.05603
[32m[0906 19-37-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03354, current rewards: 11.86176, mean: 0.07414
[32m[0906 19-37-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03347, current rewards: 17.55862, mean: 0.08361
[32m[0906 19-37-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03348, current rewards: 23.25422, mean: 0.08944
[32m[0906 19-37-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03350, current rewards: 28.96298, mean: 0.09343
[32m[0906 19-37-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03348, current rewards: 34.67066, mean: 0.09631
[32m[0906 19-37-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03330, current rewards: 39.66569, mean: 0.09675
[32m[0906 19-37-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03323, current rewards: 49.29886, mean: 0.10717
[32m[0906 19-37-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03314, current rewards: 59.02431, mean: 0.11573
[32m[0906 19-37-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03310, current rewards: 68.75106, mean: 0.12277
[32m[0906 19-37-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03307, current rewards: 78.40980, mean: 0.12854
[32m[0906 19-37-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03304, current rewards: 88.10197, mean: 0.13349
[32m[0906 19-37-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03302, current rewards: 97.84042, mean: 0.13780
[32m[0906 19-38-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03298, current rewards: 93.00863, mean: 0.12238
[32m[0906 19-38-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03296, current rewards: 56.95840, mean: 0.07032
[32m[0906 19-38-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03294, current rewards: 20.89511, mean: 0.02430
[32m[0906 19-38-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03292, current rewards: -1.10365, mean: -0.00121
[32m[0906 19-38-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03290, current rewards: 4.59625, mean: 0.00479
[32m[0906 19-38-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03289, current rewards: 10.29491, mean: 0.01019
[32m[0906 19-38-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03288, current rewards: 16.01065, mean: 0.01510
[32m[0906 19-38-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03286, current rewards: 21.66205, mean: 0.01952
[32m[0906 19-38-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03287, current rewards: 27.48768, mean: 0.02370
[32m[0906 19-38-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03284, current rewards: 35.39249, mean: 0.02925
[32m[0906 19-38-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03281, current rewards: 12.31994, mean: 0.00978
[32m[0906 19-38-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03281, current rewards: -37.68006, mean: -0.02876
[32m[0906 19-38-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03279, current rewards: -87.68006, mean: -0.06447
[32m[0906 19-38-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03279, current rewards: -137.68006, mean: -0.09765
[32m[0906 19-38-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03279, current rewards: -187.68006, mean: -0.12855
[32m[0906 19-38-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03279, current rewards: -237.68006, mean: -0.15740
[32m[0906 19-38-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03277, current rewards: -287.68006, mean: -0.18441
[32m[0906 19-38-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03277, current rewards: -337.68006, mean: -0.20974
[32m[0906 19-38-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03276, current rewards: -347.46717, mean: -0.20932
[32m[0906 19-38-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03275, current rewards: -341.68580, mean: -0.19982
[32m[0906 19-38-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03275, current rewards: -335.89868, mean: -0.19085
[32m[0906 19-38-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03275, current rewards: -330.12437, mean: -0.18239
[32m[0906 19-38-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03274, current rewards: -324.34836, mean: -0.17438
[32m[0906 19-38-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03274, current rewards: -318.56873, mean: -0.16679
[32m[0906 19-38-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03273, current rewards: -312.78587, mean: -0.15958
[32m[0906 19-38-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03272, current rewards: -307.00975, mean: -0.15274
[32m[0906 19-38-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03272, current rewards: -302.10890, mean: -0.14665
[32m[0906 19-38-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03272, current rewards: -295.73988, mean: -0.14016
[32m[0906 19-38-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03271, current rewards: -289.42127, mean: -0.13399
[32m[0906 19-38-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03270, current rewards: -283.09528, mean: -0.12810
[32m[0906 19-38-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03271, current rewards: -276.75008, mean: -0.12246
[32m[0906 19-38-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03271, current rewards: -270.42058, mean: -0.11707
[32m[0906 19-38-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03271, current rewards: -264.05362, mean: -0.11189
[32m[0906 19-38-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03270, current rewards: -257.70185, mean: -0.10693
[32m[0906 19-38-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03271, current rewards: -250.16520, mean: -0.10169
[32m[0906 19-38-58 @Agent.py:117][0m Average action selection time: 0.0327
[32m[0906 19-38-58 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-38-58 @MBExp.py:227][0m Rewards obtained: [-245.37566987629003], Lows: [69], Highs: [388], Total time: 9282.825544999996
[32m[0906 19-42-41 @MBExp.py:144][0m ####################################################################
[32m[0906 19-42-41 @MBExp.py:145][0m Starting training iteration 110.
[32m[0906 19-42-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03305, current rewards: -11.71861, mean: -1.17186
[32m[0906 19-42-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03337, current rewards: -87.95415, mean: -1.46590
[32m[0906 19-42-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03351, current rewards: -169.74985, mean: -1.54318
[32m[0906 19-42-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03350, current rewards: -257.03623, mean: -1.60648
[32m[0906 19-42-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03350, current rewards: -266.82845, mean: -1.27061
[32m[0906 19-42-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03350, current rewards: -260.79596, mean: -1.00306
[32m[0906 19-42-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03365, current rewards: -333.28111, mean: -1.07510
[32m[0906 19-42-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03383, current rewards: -413.34365, mean: -1.14818
[32m[0906 19-42-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03374, current rewards: -407.75104, mean: -0.99451
[32m[0906 19-42-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03375, current rewards: -401.95215, mean: -0.87381
[32m[0906 19-42-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03371, current rewards: -396.11757, mean: -0.77670
[32m[0906 19-43-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03365, current rewards: -390.32570, mean: -0.69701
[32m[0906 19-43-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03360, current rewards: -384.52733, mean: -0.63037
[32m[0906 19-43-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03353, current rewards: -378.74090, mean: -0.57385
[32m[0906 19-43-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03349, current rewards: -372.96854, mean: -0.52531
[32m[0906 19-43-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03343, current rewards: -367.21212, mean: -0.48317
[32m[0906 19-43-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03341, current rewards: -361.44122, mean: -0.44622
[32m[0906 19-43-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03337, current rewards: -355.74662, mean: -0.41366
[32m[0906 19-43-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03334, current rewards: -350.02768, mean: -0.38465
[32m[0906 19-43-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03331, current rewards: -358.21218, mean: -0.37314
[32m[0906 19-43-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03342, current rewards: -416.16572, mean: -0.41205
[32m[0906 19-43-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03347, current rewards: -474.07801, mean: -0.44724
[32m[0906 19-43-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03355, current rewards: -531.50419, mean: -0.47883
[32m[0906 19-43-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03360, current rewards: -582.77477, mean: -0.50239
[32m[0906 19-43-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03360, current rewards: -638.66541, mean: -0.52782
[32m[0906 19-43-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03358, current rewards: -686.56492, mean: -0.54489
[32m[0906 19-43-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03360, current rewards: -734.46457, mean: -0.56066
[32m[0906 19-43-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03358, current rewards: -782.36204, mean: -0.57527
[32m[0906 19-43-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03359, current rewards: -830.25814, mean: -0.58884
[32m[0906 19-43-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03358, current rewards: -878.15824, mean: -0.60148
[32m[0906 19-43-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03355, current rewards: -890.64550, mean: -0.58983
[32m[0906 19-43-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03352, current rewards: -885.10363, mean: -0.56737
[32m[0906 19-43-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03348, current rewards: -879.56822, mean: -0.54632
[32m[0906 19-43-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03346, current rewards: -874.02959, mean: -0.52652
[32m[0906 19-43-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03343, current rewards: -868.48879, mean: -0.50789
[32m[0906 19-43-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03339, current rewards: -862.94889, mean: -0.49031
[32m[0906 19-43-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03337, current rewards: -857.40697, mean: -0.47371
[32m[0906 19-43-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03335, current rewards: -851.87383, mean: -0.45800
[32m[0906 19-43-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03333, current rewards: -846.33057, mean: -0.44311
[32m[0906 19-43-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03332, current rewards: -851.17763, mean: -0.43427
[32m[0906 19-43-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03334, current rewards: -843.60777, mean: -0.41971
[32m[0906 19-43-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03332, current rewards: -836.62288, mean: -0.40613
[32m[0906 19-43-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03331, current rewards: -828.78077, mean: -0.39279
[32m[0906 19-43-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03330, current rewards: -821.70430, mean: -0.38042
[32m[0906 19-43-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03331, current rewards: -813.64091, mean: -0.36816
[32m[0906 19-43-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03332, current rewards: -806.43924, mean: -0.35683
[32m[0906 19-43-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03330, current rewards: -799.20458, mean: -0.34598
[32m[0906 19-44-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03331, current rewards: -791.84954, mean: -0.33553
[32m[0906 19-44-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03331, current rewards: -813.71217, mean: -0.33764
[32m[0906 19-44-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03331, current rewards: -868.82593, mean: -0.35318
[32m[0906 19-44-05 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 19-44-05 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-44-05 @MBExp.py:227][0m Rewards obtained: [-913.0615373782406], Lows: [570], Highs: [8], Total time: 9366.857365999997
[32m[0906 19-47-49 @MBExp.py:144][0m ####################################################################
[32m[0906 19-47-49 @MBExp.py:145][0m Starting training iteration 111.
[32m[0906 19-47-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03475, current rewards: -8.80666, mean: -0.88067
[32m[0906 19-47-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03589, current rewards: -69.49582, mean: -1.15826
[32m[0906 19-47-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03541, current rewards: -144.49582, mean: -1.31360
[32m[0906 19-47-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03522, current rewards: -219.49582, mean: -1.37185
[32m[0906 19-47-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03506, current rewards: -294.49582, mean: -1.40236
[32m[0906 19-47-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03503, current rewards: -369.49582, mean: -1.42114
[32m[0906 19-48-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03503, current rewards: -444.49582, mean: -1.43386
[32m[0906 19-48-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03482, current rewards: -519.49582, mean: -1.44304
[32m[0906 19-48-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03529, current rewards: -550.22912, mean: -1.34202
[32m[0906 19-48-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03601, current rewards: -553.46100, mean: -1.20318
[32m[0906 19-48-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03662, current rewards: -553.18037, mean: -1.08467
[32m[0906 19-48-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03703, current rewards: -554.40614, mean: -0.99001
[32m[0906 19-48-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03721, current rewards: -559.60597, mean: -0.91739
[32m[0906 19-48-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03763, current rewards: -560.15576, mean: -0.84872
[32m[0906 19-48-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03792, current rewards: -566.83978, mean: -0.79837
[32m[0906 19-48-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03812, current rewards: -563.91259, mean: -0.74199
[32m[0906 19-48-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03820, current rewards: -575.72249, mean: -0.71077
[32m[0906 19-48-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03797, current rewards: -581.04444, mean: -0.67563
[32m[0906 19-48-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03774, current rewards: -585.85880, mean: -0.64380
[32m[0906 19-48-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03748, current rewards: -599.69515, mean: -0.62468
[32m[0906 19-48-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03731, current rewards: -605.61628, mean: -0.59962
[32m[0906 19-48-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03718, current rewards: -608.75227, mean: -0.57429
[32m[0906 19-48-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03703, current rewards: -612.61291, mean: -0.55190
[32m[0906 19-48-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03692, current rewards: -611.36930, mean: -0.52704
[32m[0906 19-48-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03682, current rewards: -616.13862, mean: -0.50921
[32m[0906 19-48-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03673, current rewards: -618.55535, mean: -0.49092
[32m[0906 19-48-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03669, current rewards: -622.34518, mean: -0.47507
[32m[0906 19-48-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03662, current rewards: -621.16181, mean: -0.45674
[32m[0906 19-48-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03654, current rewards: -629.66641, mean: -0.44657
[32m[0906 19-48-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03645, current rewards: -631.55666, mean: -0.43257
[32m[0906 19-48-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03633, current rewards: -626.20160, mean: -0.41470
[32m[0906 19-48-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03622, current rewards: -620.60519, mean: -0.39782
[32m[0906 19-48-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03610, current rewards: -614.90162, mean: -0.38193
[32m[0906 19-48-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03600, current rewards: -609.33071, mean: -0.36707
[32m[0906 19-48-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03593, current rewards: -606.08904, mean: -0.35444
[32m[0906 19-48-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03611, current rewards: -629.51149, mean: -0.35768
[32m[0906 19-48-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03627, current rewards: -651.68883, mean: -0.36005
[32m[0906 19-48-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03642, current rewards: -676.32902, mean: -0.36362
[32m[0906 19-48-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03656, current rewards: -698.78803, mean: -0.36586
[32m[0906 19-49-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03667, current rewards: -725.43676, mean: -0.37012
[32m[0906 19-49-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03683, current rewards: -745.79240, mean: -0.37104
[32m[0906 19-49-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03697, current rewards: -770.84433, mean: -0.37420
[32m[0906 19-49-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03710, current rewards: -790.34465, mean: -0.37457
[32m[0906 19-49-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03701, current rewards: -865.34465, mean: -0.40062
[32m[0906 19-49-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03703, current rewards: -905.35808, mean: -0.40966
[32m[0906 19-49-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03718, current rewards: -904.19172, mean: -0.40008
[32m[0906 19-49-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03728, current rewards: -898.91981, mean: -0.38914
[32m[0906 19-49-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03734, current rewards: -900.91562, mean: -0.38174
[32m[0906 19-49-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03743, current rewards: -896.92097, mean: -0.37217
[32m[0906 19-49-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03752, current rewards: -890.77901, mean: -0.36211
[32m[0906 19-49-24 @Agent.py:117][0m Average action selection time: 0.0376
[32m[0906 19-49-24 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-49-24 @MBExp.py:227][0m Rewards obtained: [-885.8811652167883], Lows: [367], Highs: [436], Total time: 9461.529889999996
[32m[0906 19-53-12 @MBExp.py:144][0m ####################################################################
[32m[0906 19-53-12 @MBExp.py:145][0m Starting training iteration 112.
[32m[0906 19-53-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03561, current rewards: -12.79670, mean: -1.27967
[32m[0906 19-53-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03331, current rewards: -5.58237, mean: -0.09304
[32m[0906 19-53-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03292, current rewards: 0.34967, mean: 0.00318
[32m[0906 19-53-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03304, current rewards: 4.92758, mean: 0.03080
[32m[0906 19-53-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03305, current rewards: -30.15363, mean: -0.14359
[32m[0906 19-53-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03295, current rewards: -58.54421, mean: -0.22517
[32m[0906 19-53-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03301, current rewards: -76.04894, mean: -0.24532
[32m[0906 19-53-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03322, current rewards: -98.13025, mean: -0.27258
[32m[0906 19-53-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03360, current rewards: -104.37968, mean: -0.25458
[32m[0906 19-53-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03349, current rewards: -167.51823, mean: -0.36417
[32m[0906 19-53-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03340, current rewards: -234.59550, mean: -0.45999
[32m[0906 19-53-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03333, current rewards: -298.88658, mean: -0.53373
[32m[0906 19-53-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03329, current rewards: -360.52537, mean: -0.59103
[32m[0906 19-53-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03322, current rewards: -430.86251, mean: -0.65282
[32m[0906 19-53-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03318, current rewards: -491.67070, mean: -0.69249
[32m[0906 19-53-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03313, current rewards: -559.53963, mean: -0.73624
[32m[0906 19-53-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03310, current rewards: -620.72210, mean: -0.76632
[32m[0906 19-53-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03310, current rewards: -677.01453, mean: -0.78723
[32m[0906 19-53-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03309, current rewards: -719.53218, mean: -0.79069
[32m[0906 19-53-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03308, current rewards: -736.41906, mean: -0.76710
[32m[0906 19-53-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03308, current rewards: -748.63233, mean: -0.74122
[32m[0906 19-53-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03307, current rewards: -771.73126, mean: -0.72805
[32m[0906 19-53-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03304, current rewards: -779.94806, mean: -0.70266
[32m[0906 19-53-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03309, current rewards: -790.54038, mean: -0.68150
[32m[0906 19-53-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03309, current rewards: -791.65057, mean: -0.65426
[32m[0906 19-53-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03309, current rewards: -786.29088, mean: -0.62404
[32m[0906 19-53-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03307, current rewards: -780.92142, mean: -0.59612
[32m[0906 19-53-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03304, current rewards: -775.55753, mean: -0.57026
[32m[0906 19-53-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03303, current rewards: -770.20696, mean: -0.54625
[32m[0906 19-54-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03301, current rewards: -764.84204, mean: -0.52386
[32m[0906 19-54-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03299, current rewards: -759.47649, mean: -0.50296
[32m[0906 19-54-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03298, current rewards: -754.09463, mean: -0.48339
[32m[0906 19-54-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03297, current rewards: -748.85796, mean: -0.46513
[32m[0906 19-54-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03295, current rewards: -743.62570, mean: -0.44797
[32m[0906 19-54-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03295, current rewards: -738.38812, mean: -0.43181
[32m[0906 19-54-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03293, current rewards: -733.15699, mean: -0.41657
[32m[0906 19-54-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03293, current rewards: -734.69831, mean: -0.40591
[32m[0906 19-54-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03293, current rewards: -732.89462, mean: -0.39403
[32m[0906 19-54-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03293, current rewards: -727.39422, mean: -0.38083
[32m[0906 19-54-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03293, current rewards: -721.89738, mean: -0.36831
[32m[0906 19-54-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03292, current rewards: -716.19949, mean: -0.35632
[32m[0906 19-54-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03291, current rewards: -710.56675, mean: -0.34494
[32m[0906 19-54-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03290, current rewards: -704.94251, mean: -0.33410
[32m[0906 19-54-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03289, current rewards: -699.31620, mean: -0.32376
[32m[0906 19-54-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03288, current rewards: -693.68473, mean: -0.31388
[32m[0906 19-54-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03287, current rewards: -688.05330, mean: -0.30445
[32m[0906 19-54-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03288, current rewards: -731.85597, mean: -0.31682
[32m[0906 19-54-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03287, current rewards: -778.37721, mean: -0.32982
[32m[0906 19-54-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03288, current rewards: -825.62080, mean: -0.34258
[32m[0906 19-54-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03287, current rewards: -880.62564, mean: -0.35798
[32m[0906 19-54-35 @Agent.py:117][0m Average action selection time: 0.0329
[32m[0906 19-54-35 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-54-35 @MBExp.py:227][0m Rewards obtained: [-926.0272672278658], Lows: [513], Highs: [163], Total time: 9544.515935999996
[32m[0906 19-58-25 @MBExp.py:144][0m ####################################################################
[32m[0906 19-58-25 @MBExp.py:145][0m Starting training iteration 113.
[32m[0906 19-58-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03301, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-58-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03250, current rewards: -60.00000, mean: -1.00000
[32m[0906 19-58-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03260, current rewards: -110.00000, mean: -1.00000
[32m[0906 19-58-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03262, current rewards: -160.00000, mean: -1.00000
[32m[0906 19-58-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03262, current rewards: -210.00000, mean: -1.00000
[32m[0906 19-58-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03260, current rewards: -260.00000, mean: -1.00000
[32m[0906 19-58-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03267, current rewards: -311.67905, mean: -1.00542
[32m[0906 19-58-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03428, current rewards: -336.47226, mean: -0.93465
[32m[0906 19-58-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03585, current rewards: -347.37368, mean: -0.84725
[32m[0906 19-58-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03703, current rewards: -351.33583, mean: -0.76377
[32m[0906 19-58-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03723, current rewards: -412.92945, mean: -0.80967
[32m[0906 19-58-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03767, current rewards: -429.67857, mean: -0.76728
[32m[0906 19-58-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03724, current rewards: -423.36315, mean: -0.69404
[32m[0906 19-58-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03688, current rewards: -417.04772, mean: -0.63189
[32m[0906 19-58-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03658, current rewards: -410.73230, mean: -0.57850
[32m[0906 19-58-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03630, current rewards: -403.77510, mean: -0.53128
[32m[0906 19-58-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03607, current rewards: -396.50089, mean: -0.48951
[32m[0906 19-58-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03587, current rewards: -389.22667, mean: -0.45259
[32m[0906 19-58-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03569, current rewards: -415.17151, mean: -0.45623
[32m[0906 19-58-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03553, current rewards: -465.17151, mean: -0.48455
[32m[0906 19-59-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03538, current rewards: -515.17151, mean: -0.51007
[32m[0906 19-59-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03525, current rewards: -565.17151, mean: -0.53318
[32m[0906 19-59-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03514, current rewards: -615.17151, mean: -0.55421
[32m[0906 19-59-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03503, current rewards: -665.17151, mean: -0.57342
[32m[0906 19-59-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03493, current rewards: -715.17151, mean: -0.59105
[32m[0906 19-59-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03483, current rewards: -765.17151, mean: -0.60728
[32m[0906 19-59-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03473, current rewards: -815.17151, mean: -0.62227
[32m[0906 19-59-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03466, current rewards: -865.17151, mean: -0.63616
[32m[0906 19-59-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03459, current rewards: -915.17151, mean: -0.64906
[32m[0906 19-59-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03453, current rewards: -965.17151, mean: -0.66108
[32m[0906 19-59-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03447, current rewards: -1015.17151, mean: -0.67230
[32m[0906 19-59-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03440, current rewards: -1065.17151, mean: -0.68280
[32m[0906 19-59-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03435, current rewards: -1115.17151, mean: -0.69265
[32m[0906 19-59-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03430, current rewards: -1165.17151, mean: -0.70191
[32m[0906 19-59-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03425, current rewards: -1215.17151, mean: -0.71063
[32m[0906 19-59-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03421, current rewards: -1265.17151, mean: -0.71885
[32m[0906 19-59-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03417, current rewards: -1315.17151, mean: -0.72661
[32m[0906 19-59-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03414, current rewards: -1365.17151, mean: -0.73396
[32m[0906 19-59-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03410, current rewards: -1415.17151, mean: -0.74093
[32m[0906 19-59-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03406, current rewards: -1465.17151, mean: -0.74754
[32m[0906 19-59-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03402, current rewards: -1515.17151, mean: -0.75382
[32m[0906 19-59-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03399, current rewards: -1565.17151, mean: -0.75979
[32m[0906 19-59-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03396, current rewards: -1615.17151, mean: -0.76548
[32m[0906 19-59-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03391, current rewards: -1665.17151, mean: -0.77091
[32m[0906 19-59-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03388, current rewards: -1715.17151, mean: -0.77610
[32m[0906 19-59-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03384, current rewards: -1765.17151, mean: -0.78105
[32m[0906 19-59-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03382, current rewards: -1815.17151, mean: -0.78579
[32m[0906 19-59-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03379, current rewards: -1865.17151, mean: -0.79033
[32m[0906 19-59-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03378, current rewards: -1915.17151, mean: -0.79468
[32m[0906 19-59-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03377, current rewards: -1965.17151, mean: -0.79885
[32m[0906 19-59-50 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 19-59-50 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-59-50 @MBExp.py:227][0m Rewards obtained: [-2005.171505018875], Lows: [80], Highs: [1919], Total time: 9629.720049999996
[32m[0906 20-03-42 @MBExp.py:144][0m ####################################################################
[32m[0906 20-03-42 @MBExp.py:145][0m Starting training iteration 114.
[32m[0906 20-03-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03188, current rewards: -3.26341, mean: -0.32634
[32m[0906 20-03-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03228, current rewards: 2.24732, mean: 0.03746
[32m[0906 20-03-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03249, current rewards: 7.80145, mean: 0.07092
[32m[0906 20-03-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03257, current rewards: 13.35850, mean: 0.08349
[32m[0906 20-03-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03259, current rewards: 18.91313, mean: 0.09006
[32m[0906 20-03-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03256, current rewards: 24.47093, mean: 0.09412
[32m[0906 20-03-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03259, current rewards: 30.09132, mean: 0.09707
[32m[0906 20-03-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03257, current rewards: 35.69144, mean: 0.09914
[32m[0906 20-03-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03256, current rewards: 41.28405, mean: 0.10069
[32m[0906 20-03-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03257, current rewards: 46.87980, mean: 0.10191
[32m[0906 20-03-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03257, current rewards: 52.47030, mean: 0.10288
[32m[0906 20-04-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03256, current rewards: 58.06083, mean: 0.10368
[32m[0906 20-04-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03256, current rewards: 59.32461, mean: 0.09725
[32m[0906 20-04-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03256, current rewards: 64.76185, mean: 0.09812
[32m[0906 20-04-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03256, current rewards: 70.06323, mean: 0.09868
[32m[0906 20-04-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03255, current rewards: 75.42850, mean: 0.09925
[32m[0906 20-04-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03253, current rewards: 80.79351, mean: 0.09975
[32m[0906 20-04-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03252, current rewards: 86.15615, mean: 0.10018
[32m[0906 20-04-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03252, current rewards: 91.52282, mean: 0.10057
[32m[0906 20-04-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03253, current rewards: 96.88882, mean: 0.10093
[32m[0906 20-04-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03251, current rewards: 102.25833, mean: 0.10125
[32m[0906 20-04-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03252, current rewards: 105.54194, mean: 0.09957
[32m[0906 20-04-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03252, current rewards: 110.55090, mean: 0.09960
[32m[0906 20-04-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03252, current rewards: 115.63646, mean: 0.09969
[32m[0906 20-04-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03253, current rewards: 120.72498, mean: 0.09977
[32m[0906 20-04-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03252, current rewards: 125.81181, mean: 0.09985
[32m[0906 20-04-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03252, current rewards: 130.89898, mean: 0.09992
[32m[0906 20-04-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03251, current rewards: 135.98938, mean: 0.09999
[32m[0906 20-04-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03252, current rewards: 141.07416, mean: 0.10005
[32m[0906 20-04-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03252, current rewards: 146.15662, mean: 0.10011
[32m[0906 20-04-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03252, current rewards: 151.30004, mean: 0.10020
[32m[0906 20-04-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03251, current rewards: 156.46221, mean: 0.10030
[32m[0906 20-04-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03252, current rewards: 161.51907, mean: 0.10032
[32m[0906 20-04-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03252, current rewards: 166.57371, mean: 0.10035
[32m[0906 20-04-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03252, current rewards: 171.62969, mean: 0.10037
[32m[0906 20-04-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03253, current rewards: 176.31054, mean: 0.10018
[32m[0906 20-04-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03253, current rewards: 181.86288, mean: 0.10048
[32m[0906 20-04-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03254, current rewards: 187.40760, mean: 0.10076
[32m[0906 20-04-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03255, current rewards: 192.95354, mean: 0.10102
[32m[0906 20-04-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03255, current rewards: 198.32818, mean: 0.10119
[32m[0906 20-04-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03256, current rewards: 203.79219, mean: 0.10139
[32m[0906 20-04-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03256, current rewards: 209.26306, mean: 0.10158
[32m[0906 20-04-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03256, current rewards: 214.72772, mean: 0.10177
[32m[0906 20-04-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03256, current rewards: 220.18782, mean: 0.10194
[32m[0906 20-04-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03255, current rewards: 225.65149, mean: 0.10210
[32m[0906 20-04-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03255, current rewards: 231.12096, mean: 0.10227
[32m[0906 20-04-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03254, current rewards: 231.92524, mean: 0.10040
[32m[0906 20-04-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03255, current rewards: 236.58974, mean: 0.10025
[32m[0906 20-05-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03256, current rewards: 241.14403, mean: 0.10006
[32m[0906 20-05-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03258, current rewards: 245.70516, mean: 0.09988
[32m[0906 20-05-04 @Agent.py:117][0m Average action selection time: 0.0326
[32m[0906 20-05-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-05-04 @MBExp.py:227][0m Rewards obtained: [249.35121168655704], Lows: [6], Highs: [4], Total time: 9711.986588999996
[32m[0906 20-08-57 @MBExp.py:144][0m ####################################################################
[32m[0906 20-08-57 @MBExp.py:145][0m Starting training iteration 115.
[32m[0906 20-08-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03239, current rewards: -5.33524, mean: -0.53352
[32m[0906 20-08-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03231, current rewards: 0.42421, mean: 0.00707
[32m[0906 20-09-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03247, current rewards: 6.10075, mean: 0.05546
[32m[0906 20-09-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03249, current rewards: 11.77822, mean: 0.07361
[32m[0906 20-09-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03249, current rewards: 18.43482, mean: 0.08778
[32m[0906 20-09-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03250, current rewards: 23.95598, mean: 0.09214
[32m[0906 20-09-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03252, current rewards: 29.32922, mean: 0.09461
[32m[0906 20-09-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03251, current rewards: 34.84988, mean: 0.09681
[32m[0906 20-09-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03248, current rewards: 40.36762, mean: 0.09846
[32m[0906 20-09-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03250, current rewards: 45.88753, mean: 0.09976
[32m[0906 20-09-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03247, current rewards: 51.40725, mean: 0.10080
[32m[0906 20-09-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03246, current rewards: 56.92174, mean: 0.10165
[32m[0906 20-09-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03247, current rewards: 62.43332, mean: 0.10235
[32m[0906 20-09-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03248, current rewards: 67.94819, mean: 0.10295
[32m[0906 20-09-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03251, current rewards: 71.70892, mean: 0.10100
[32m[0906 20-09-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03252, current rewards: 77.47156, mean: 0.10194
[32m[0906 20-09-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03248, current rewards: 83.23535, mean: 0.10276
[32m[0906 20-09-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03249, current rewards: 88.99954, mean: 0.10349
[32m[0906 20-09-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03250, current rewards: 94.75712, mean: 0.10413
[32m[0906 20-09-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03251, current rewards: 100.52008, mean: 0.10471
[32m[0906 20-09-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03251, current rewards: 106.28299, mean: 0.10523
[32m[0906 20-09-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03252, current rewards: 111.96467, mean: 0.10563
[32m[0906 20-09-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03252, current rewards: 117.49806, mean: 0.10585
[32m[0906 20-09-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03252, current rewards: 123.02679, mean: 0.10606
[32m[0906 20-09-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03253, current rewards: 128.55546, mean: 0.10624
[32m[0906 20-09-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03252, current rewards: 134.08467, mean: 0.10642
[32m[0906 20-09-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03252, current rewards: 133.51794, mean: 0.10192
[32m[0906 20-09-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03252, current rewards: 139.83337, mean: 0.10282
[32m[0906 20-09-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03251, current rewards: 146.14880, mean: 0.10365
[32m[0906 20-09-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03251, current rewards: 152.46422, mean: 0.10443
[32m[0906 20-09-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03253, current rewards: 158.59707, mean: 0.10503
[32m[0906 20-09-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03253, current rewards: 163.66262, mean: 0.10491
[32m[0906 20-09-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03252, current rewards: 169.38818, mean: 0.10521
[32m[0906 20-09-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03252, current rewards: 175.11322, mean: 0.10549
[32m[0906 20-09-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03253, current rewards: 180.83992, mean: 0.10575
[32m[0906 20-09-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03253, current rewards: 186.56740, mean: 0.10600
[32m[0906 20-09-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03254, current rewards: 192.29224, mean: 0.10624
[32m[0906 20-09-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03255, current rewards: 198.01966, mean: 0.10646
[32m[0906 20-10-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03255, current rewards: 200.48575, mean: 0.10497
[32m[0906 20-10-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03255, current rewards: 206.08331, mean: 0.10514
[32m[0906 20-10-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03254, current rewards: 211.61590, mean: 0.10528
[32m[0906 20-10-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03254, current rewards: 217.15426, mean: 0.10541
[32m[0906 20-10-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03254, current rewards: 222.68576, mean: 0.10554
[32m[0906 20-10-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03254, current rewards: 228.22070, mean: 0.10566
[32m[0906 20-10-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03253, current rewards: 233.76406, mean: 0.10578
[32m[0906 20-10-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03253, current rewards: 239.29732, mean: 0.10588
[32m[0906 20-10-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03253, current rewards: 244.83691, mean: 0.10599
[32m[0906 20-10-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03252, current rewards: 250.43036, mean: 0.10611
[32m[0906 20-10-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03253, current rewards: 255.97181, mean: 0.10621
[32m[0906 20-10-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03256, current rewards: 256.12948, mean: 0.10412
[32m[0906 20-10-19 @Agent.py:117][0m Average action selection time: 0.0326
[32m[0906 20-10-19 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-10-20 @MBExp.py:227][0m Rewards obtained: [260.70259029992064], Lows: [9], Highs: [5], Total time: 9794.193146999996
[32m[0906 20-14-15 @MBExp.py:144][0m ####################################################################
[32m[0906 20-14-15 @MBExp.py:145][0m Starting training iteration 116.
[32m[0906 20-14-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03217, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-14-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03248, current rewards: -60.00000, mean: -1.00000
[32m[0906 20-14-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03236, current rewards: -110.00000, mean: -1.00000
[32m[0906 20-14-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03252, current rewards: -160.00000, mean: -1.00000
[32m[0906 20-14-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03257, current rewards: -210.00000, mean: -1.00000
[32m[0906 20-14-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03255, current rewards: -260.00000, mean: -1.00000
[32m[0906 20-14-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03253, current rewards: -310.00000, mean: -1.00000
[32m[0906 20-14-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03254, current rewards: -360.00000, mean: -1.00000
[32m[0906 20-14-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03254, current rewards: -410.00000, mean: -1.00000
[32m[0906 20-14-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03253, current rewards: -460.00000, mean: -1.00000
[32m[0906 20-14-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03267, current rewards: -510.00000, mean: -1.00000
[32m[0906 20-14-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03277, current rewards: -560.00000, mean: -1.00000
[32m[0906 20-14-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03275, current rewards: -610.00000, mean: -1.00000
[32m[0906 20-14-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03282, current rewards: -660.00000, mean: -1.00000
[32m[0906 20-14-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03290, current rewards: -710.00000, mean: -1.00000
[32m[0906 20-14-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03296, current rewards: -758.94452, mean: -0.99861
[32m[0906 20-14-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03297, current rewards: -808.94452, mean: -0.99870
[32m[0906 20-14-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03301, current rewards: -858.94452, mean: -0.99877
[32m[0906 20-14-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03302, current rewards: -908.94452, mean: -0.99884
[32m[0906 20-14-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03300, current rewards: -957.88544, mean: -0.99780
[32m[0906 20-14-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03297, current rewards: -1007.88544, mean: -0.99791
[32m[0906 20-14-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03296, current rewards: -1057.88544, mean: -0.99801
[32m[0906 20-14-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03294, current rewards: -1107.88544, mean: -0.99809
[32m[0906 20-14-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03293, current rewards: -1157.88544, mean: -0.99818
[32m[0906 20-14-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03292, current rewards: -1207.88544, mean: -0.99825
[32m[0906 20-14-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03291, current rewards: -1211.66118, mean: -0.96164
[32m[0906 20-14-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03288, current rewards: -1209.13361, mean: -0.92300
[32m[0906 20-15-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03287, current rewards: -1206.60605, mean: -0.88721
[32m[0906 20-15-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03286, current rewards: -1204.07848, mean: -0.85396
[32m[0906 20-15-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03285, current rewards: -1201.55091, mean: -0.82298
[32m[0906 20-15-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03284, current rewards: -1197.71346, mean: -0.79319
[32m[0906 20-15-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03283, current rewards: -1192.66358, mean: -0.76453
[32m[0906 20-15-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03282, current rewards: -1187.61370, mean: -0.73765
[32m[0906 20-15-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03281, current rewards: -1182.56383, mean: -0.71239
[32m[0906 20-15-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03281, current rewards: -1177.51395, mean: -0.68860
[32m[0906 20-15-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03281, current rewards: -1182.37305, mean: -0.67180
[32m[0906 20-15-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03280, current rewards: -1232.37305, mean: -0.68087
[32m[0906 20-15-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03280, current rewards: -1282.37305, mean: -0.68945
[32m[0906 20-15-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03279, current rewards: -1332.37305, mean: -0.69758
[32m[0906 20-15-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03279, current rewards: -1382.37305, mean: -0.70529
[32m[0906 20-15-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03278, current rewards: -1432.37305, mean: -0.71262
[32m[0906 20-15-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03278, current rewards: -1482.37305, mean: -0.71960
[32m[0906 20-15-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03278, current rewards: -1532.37305, mean: -0.72624
[32m[0906 20-15-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03276, current rewards: -1582.37305, mean: -0.73258
[32m[0906 20-15-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03276, current rewards: -1632.37305, mean: -0.73863
[32m[0906 20-15-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03274, current rewards: -1682.37305, mean: -0.74441
[32m[0906 20-15-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03275, current rewards: -1732.37305, mean: -0.74995
[32m[0906 20-15-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03275, current rewards: -1782.37305, mean: -0.75524
[32m[0906 20-15-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03276, current rewards: -1832.37305, mean: -0.76032
[32m[0906 20-15-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03277, current rewards: -1882.37305, mean: -0.76519
[32m[0906 20-15-38 @Agent.py:117][0m Average action selection time: 0.0328
[32m[0906 20-15-38 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-15-38 @MBExp.py:227][0m Rewards obtained: [-1922.3730538024447], Lows: [0], Highs: [1963], Total time: 9876.913202999996
[32m[0906 20-19-35 @MBExp.py:144][0m ####################################################################
[32m[0906 20-19-35 @MBExp.py:145][0m Starting training iteration 117.
[32m[0906 20-19-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03215, current rewards: -5.14532, mean: -0.51453
[32m[0906 20-19-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03243, current rewards: -0.26081, mean: -0.00435
[32m[0906 20-19-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03252, current rewards: 4.65670, mean: 0.04233
[32m[0906 20-19-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03257, current rewards: 9.57665, mean: 0.05985
[32m[0906 20-19-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03255, current rewards: 14.49248, mean: 0.06901
[32m[0906 20-19-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03257, current rewards: 19.67258, mean: 0.07566
[32m[0906 20-19-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03257, current rewards: 24.63074, mean: 0.07945
[32m[0906 20-19-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03254, current rewards: 29.58999, mean: 0.08219
[32m[0906 20-19-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03253, current rewards: 34.55148, mean: 0.08427
[32m[0906 20-19-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03256, current rewards: 39.50957, mean: 0.08589
[32m[0906 20-19-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03255, current rewards: 44.47225, mean: 0.08720
[32m[0906 20-19-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03257, current rewards: 49.43089, mean: 0.08827
[32m[0906 20-19-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03258, current rewards: 50.23571, mean: 0.08235
[32m[0906 20-19-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03257, current rewards: 55.45052, mean: 0.08402
[32m[0906 20-19-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03255, current rewards: 60.42275, mean: 0.08510
[32m[0906 20-20-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03252, current rewards: 65.49468, mean: 0.08618
[32m[0906 20-20-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03254, current rewards: 70.56202, mean: 0.08711
[32m[0906 20-20-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03251, current rewards: 75.63039, mean: 0.08794
[32m[0906 20-20-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03252, current rewards: 80.70072, mean: 0.08868
[32m[0906 20-20-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03251, current rewards: 85.76993, mean: 0.08934
[32m[0906 20-20-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03252, current rewards: 90.83909, mean: 0.08994
[32m[0906 20-20-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03252, current rewards: 95.90843, mean: 0.09048
[32m[0906 20-20-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03253, current rewards: 100.97721, mean: 0.09097
[32m[0906 20-20-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03254, current rewards: 106.04716, mean: 0.09142
[32m[0906 20-20-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03253, current rewards: 111.11713, mean: 0.09183
[32m[0906 20-20-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03254, current rewards: 116.18914, mean: 0.09221
[32m[0906 20-20-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03253, current rewards: 121.26141, mean: 0.09257
[32m[0906 20-20-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03253, current rewards: 126.32578, mean: 0.09289
[32m[0906 20-20-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03254, current rewards: 127.33202, mean: 0.09031
[32m[0906 20-20-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03255, current rewards: 132.76871, mean: 0.09094
[32m[0906 20-20-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03255, current rewards: 138.22362, mean: 0.09154
[32m[0906 20-20-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03256, current rewards: 143.67058, mean: 0.09210
[32m[0906 20-20-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03256, current rewards: 149.11770, mean: 0.09262
[32m[0906 20-20-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03256, current rewards: 154.56259, mean: 0.09311
[32m[0906 20-20-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03256, current rewards: 160.01143, mean: 0.09357
[32m[0906 20-20-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03257, current rewards: 165.45804, mean: 0.09401
[32m[0906 20-20-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03257, current rewards: 170.90546, mean: 0.09442
[32m[0906 20-20-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03258, current rewards: 176.35143, mean: 0.09481
[32m[0906 20-20-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03258, current rewards: 181.69019, mean: 0.09513
[32m[0906 20-20-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03258, current rewards: 187.09032, mean: 0.09545
[32m[0906 20-20-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03258, current rewards: 192.49034, mean: 0.09577
[32m[0906 20-20-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03258, current rewards: 197.89066, mean: 0.09606
[32m[0906 20-20-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03258, current rewards: 203.28971, mean: 0.09635
[32m[0906 20-20-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03258, current rewards: 208.69063, mean: 0.09662
[32m[0906 20-20-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03258, current rewards: 214.09121, mean: 0.09687
[32m[0906 20-20-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03257, current rewards: 213.03471, mean: 0.09426
[32m[0906 20-20-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03257, current rewards: 218.07615, mean: 0.09441
[32m[0906 20-20-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03256, current rewards: 222.76582, mean: 0.09439
[32m[0906 20-20-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03257, current rewards: 227.44899, mean: 0.09438
[32m[0906 20-20-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03259, current rewards: 232.13381, mean: 0.09436
[32m[0906 20-20-57 @Agent.py:117][0m Average action selection time: 0.0326
[32m[0906 20-20-57 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-20-58 @MBExp.py:227][0m Rewards obtained: [235.8771363368351], Lows: [8], Highs: [4], Total time: 9959.207082999996
[32m[0906 20-24-57 @MBExp.py:144][0m ####################################################################
[32m[0906 20-24-57 @MBExp.py:145][0m Starting training iteration 118.
[32m[0906 20-24-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03203, current rewards: 1.13494, mean: 0.11349
[32m[0906 20-24-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03265, current rewards: 6.73538, mean: 0.11226
[32m[0906 20-25-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03264, current rewards: 12.32746, mean: 0.11207
[32m[0906 20-25-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03263, current rewards: 17.92241, mean: 0.11202
[32m[0906 20-25-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03264, current rewards: 23.51965, mean: 0.11200
[32m[0906 20-25-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03262, current rewards: 29.23650, mean: 0.11245
[32m[0906 20-25-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03259, current rewards: 34.84595, mean: 0.11241
[32m[0906 20-25-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03261, current rewards: 40.45783, mean: 0.11238
[32m[0906 20-25-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03258, current rewards: 44.66160, mean: 0.10893
[32m[0906 20-25-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03259, current rewards: 50.19723, mean: 0.10912
[32m[0906 20-25-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03259, current rewards: 55.73176, mean: 0.10928
[32m[0906 20-25-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03259, current rewards: 61.26927, mean: 0.10941
[32m[0906 20-25-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03257, current rewards: 66.80998, mean: 0.10952
[32m[0906 20-25-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03259, current rewards: 69.39932, mean: 0.10515
[32m[0906 20-25-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03257, current rewards: 74.94140, mean: 0.10555
[32m[0906 20-25-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03255, current rewards: 80.47687, mean: 0.10589
[32m[0906 20-25-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03256, current rewards: 86.01708, mean: 0.10619
[32m[0906 20-25-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03254, current rewards: 91.56073, mean: 0.10647
[32m[0906 20-25-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03254, current rewards: 97.09948, mean: 0.10670
[32m[0906 20-25-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03254, current rewards: 102.63670, mean: 0.10691
[32m[0906 20-25-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03255, current rewards: 108.11131, mean: 0.10704
[32m[0906 20-25-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03256, current rewards: 113.48282, mean: 0.10706
[32m[0906 20-25-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03257, current rewards: 118.98780, mean: 0.10720
[32m[0906 20-25-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03256, current rewards: 124.49747, mean: 0.10733
[32m[0906 20-25-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03259, current rewards: 130.00505, mean: 0.10744
[32m[0906 20-25-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03259, current rewards: 135.50500, mean: 0.10754
[32m[0906 20-25-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03259, current rewards: 141.01479, mean: 0.10764
[32m[0906 20-25-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03259, current rewards: 146.51970, mean: 0.10774
[32m[0906 20-25-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03260, current rewards: 147.88931, mean: 0.10489
[32m[0906 20-25-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03258, current rewards: 153.30394, mean: 0.10500
[32m[0906 20-25-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03259, current rewards: 158.85643, mean: 0.10520
[32m[0906 20-25-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03259, current rewards: 164.41087, mean: 0.10539
[32m[0906 20-25-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03259, current rewards: 169.96274, mean: 0.10557
[32m[0906 20-25-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03259, current rewards: 175.52074, mean: 0.10574
[32m[0906 20-25-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03259, current rewards: 181.07660, mean: 0.10589
[32m[0906 20-25-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03258, current rewards: 186.63086, mean: 0.10604
[32m[0906 20-25-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03258, current rewards: 192.19063, mean: 0.10618
[32m[0906 20-25-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03259, current rewards: 197.74486, mean: 0.10631
[32m[0906 20-26-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03259, current rewards: 203.30204, mean: 0.10644
[32m[0906 20-26-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03259, current rewards: 204.65477, mean: 0.10442
[32m[0906 20-26-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03259, current rewards: 210.17193, mean: 0.10456
[32m[0906 20-26-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03259, current rewards: 215.69312, mean: 0.10471
[32m[0906 20-26-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03260, current rewards: 221.21498, mean: 0.10484
[32m[0906 20-26-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03260, current rewards: 226.73823, mean: 0.10497
[32m[0906 20-26-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03259, current rewards: 232.26305, mean: 0.10510
[32m[0906 20-26-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03259, current rewards: 237.82456, mean: 0.10523
[32m[0906 20-26-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03259, current rewards: 231.64668, mean: 0.10028
[32m[0906 20-26-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03259, current rewards: 237.15423, mean: 0.10049
[32m[0906 20-26-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03259, current rewards: 242.66010, mean: 0.10069
[32m[0906 20-26-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03261, current rewards: 248.17318, mean: 0.10088
[32m[0906 20-26-20 @Agent.py:117][0m Average action selection time: 0.0326
[32m[0906 20-26-20 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-26-20 @MBExp.py:227][0m Rewards obtained: [252.58078119410595], Lows: [10], Highs: [4], Total time: 10041.546692999997
[32m[0906 20-30-21 @MBExp.py:144][0m ####################################################################
[32m[0906 20-30-21 @MBExp.py:145][0m Starting training iteration 119.
[32m[0906 20-30-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03173, current rewards: -3.18654, mean: -0.31865
[32m[0906 20-30-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03219, current rewards: 1.99011, mean: 0.03317
[32m[0906 20-30-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03228, current rewards: 7.07479, mean: 0.06432
[32m[0906 20-30-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03242, current rewards: 12.15942, mean: 0.07600
[32m[0906 20-30-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03242, current rewards: 17.23226, mean: 0.08206
[32m[0906 20-30-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03243, current rewards: 20.57376, mean: 0.07913
[32m[0906 20-30-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03246, current rewards: 26.33063, mean: 0.08494
[32m[0906 20-30-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03245, current rewards: 32.08232, mean: 0.08912
[32m[0906 20-30-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03246, current rewards: 37.83667, mean: 0.09228
[32m[0906 20-30-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03246, current rewards: 40.47467, mean: 0.08799
[32m[0906 20-30-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03246, current rewards: 47.40421, mean: 0.09295
[32m[0906 20-30-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03245, current rewards: 54.33383, mean: 0.09702
[32m[0906 20-30-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03245, current rewards: 60.80899, mean: 0.09969
[32m[0906 20-30-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03244, current rewards: 67.09646, mean: 0.10166
[32m[0906 20-30-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03245, current rewards: 73.38852, mean: 0.10336
[32m[0906 20-30-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03244, current rewards: 79.68439, mean: 0.10485
[32m[0906 20-30-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03246, current rewards: 85.97406, mean: 0.10614
[32m[0906 20-30-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03256, current rewards: 88.51591, mean: 0.10293
[32m[0906 20-30-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03331, current rewards: 93.42783, mean: 0.10267
[32m[0906 20-30-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03411, current rewards: 98.24183, mean: 0.10234
[32m[0906 20-30-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03470, current rewards: 102.71611, mean: 0.10170
[32m[0906 20-30-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03526, current rewards: 107.49307, mean: 0.10141
[32m[0906 20-31-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03574, current rewards: 112.37545, mean: 0.10124
[32m[0906 20-31-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03617, current rewards: 117.23923, mean: 0.10107
[32m[0906 20-31-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03656, current rewards: 122.22394, mean: 0.10101
[32m[0906 20-31-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03692, current rewards: 126.76322, mean: 0.10061
[32m[0906 20-31-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03720, current rewards: 131.48548, mean: 0.10037
[32m[0906 20-31-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03742, current rewards: 135.66222, mean: 0.09975
[32m[0906 20-31-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03746, current rewards: 140.76733, mean: 0.09983
[32m[0906 20-31-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03728, current rewards: 146.05008, mean: 0.10003
[32m[0906 20-31-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03713, current rewards: 151.46834, mean: 0.10031
[32m[0906 20-31-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03698, current rewards: 156.88689, mean: 0.10057
[32m[0906 20-31-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03685, current rewards: 162.30370, mean: 0.10081
[32m[0906 20-31-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03671, current rewards: 167.71932, mean: 0.10104
[32m[0906 20-31-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03659, current rewards: 173.13110, mean: 0.10125
[32m[0906 20-31-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03648, current rewards: 178.54532, mean: 0.10145
[32m[0906 20-31-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03637, current rewards: 183.95958, mean: 0.10164
[32m[0906 20-31-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03627, current rewards: 185.80748, mean: 0.09990
[32m[0906 20-31-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03617, current rewards: 190.40992, mean: 0.09969
[32m[0906 20-31-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03608, current rewards: 195.01931, mean: 0.09950
[32m[0906 20-31-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03597, current rewards: 199.62522, mean: 0.09932
[32m[0906 20-31-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03589, current rewards: 204.23002, mean: 0.09914
[32m[0906 20-31-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03581, current rewards: 208.83921, mean: 0.09898
[32m[0906 20-31-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03573, current rewards: 213.44189, mean: 0.09882
[32m[0906 20-31-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03565, current rewards: 218.05129, mean: 0.09867
[32m[0906 20-31-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03559, current rewards: 222.76482, mean: 0.09857
[32m[0906 20-31-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03562, current rewards: 228.29138, mean: 0.09883
[32m[0906 20-31-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03569, current rewards: 233.98421, mean: 0.09915
[32m[0906 20-31-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03575, current rewards: 239.66877, mean: 0.09945
[32m[0906 20-31-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03586, current rewards: 244.87644, mean: 0.09954
[32m[0906 20-31-51 @Agent.py:117][0m Average action selection time: 0.0359
[32m[0906 20-31-51 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-31-52 @MBExp.py:227][0m Rewards obtained: [248.23991122016736], Lows: [6], Highs: [5], Total time: 10132.143209999997
[32m[0906 20-35-54 @MBExp.py:144][0m ####################################################################
[32m[0906 20-35-54 @MBExp.py:145][0m Starting training iteration 120.
[32m[0906 20-35-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03227, current rewards: -2.14596, mean: -0.21460
[32m[0906 20-35-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02974, current rewards: 3.33658, mean: 0.05561
[32m[0906 20-35-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02946, current rewards: 8.91402, mean: 0.08104
[32m[0906 20-35-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02928, current rewards: 14.48930, mean: 0.09056
[32m[0906 20-36-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02918, current rewards: 20.11644, mean: 0.09579
[32m[0906 20-36-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02922, current rewards: 25.68729, mean: 0.09880
[32m[0906 20-36-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02922, current rewards: 31.25941, mean: 0.10084
[32m[0906 20-36-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02917, current rewards: 36.84146, mean: 0.10234
[32m[0906 20-36-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02915, current rewards: 42.41814, mean: 0.10346
[32m[0906 20-36-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02915, current rewards: 47.99152, mean: 0.10433
[32m[0906 20-36-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02912, current rewards: 53.56811, mean: 0.10504
[32m[0906 20-36-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02912, current rewards: 59.14796, mean: 0.10562
[32m[0906 20-36-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02909, current rewards: 64.86989, mean: 0.10634
[32m[0906 20-36-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02909, current rewards: 71.01466, mean: 0.10760
[32m[0906 20-36-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02909, current rewards: 76.47978, mean: 0.10772
[32m[0906 20-36-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02907, current rewards: 81.94100, mean: 0.10782
[32m[0906 20-36-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02907, current rewards: 87.40278, mean: 0.10790
[32m[0906 20-36-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02907, current rewards: 92.86439, mean: 0.10798
[32m[0906 20-36-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02908, current rewards: 96.26888, mean: 0.10579
[32m[0906 20-36-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02908, current rewards: 101.74909, mean: 0.10599
[32m[0906 20-36-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02907, current rewards: 107.20759, mean: 0.10615
[32m[0906 20-36-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02907, current rewards: 112.55958, mean: 0.10619
[32m[0906 20-36-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02907, current rewards: 118.01960, mean: 0.10632
[32m[0906 20-36-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02906, current rewards: 123.48319, mean: 0.10645
[32m[0906 20-36-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02907, current rewards: 128.94929, mean: 0.10657
[32m[0906 20-36-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02907, current rewards: 134.41186, mean: 0.10668
[32m[0906 20-36-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02907, current rewards: 139.87788, mean: 0.10678
[32m[0906 20-36-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02906, current rewards: 145.34388, mean: 0.10687
[32m[0906 20-36-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02907, current rewards: 150.80321, mean: 0.10695
[32m[0906 20-36-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02906, current rewards: 156.28326, mean: 0.10704
[32m[0906 20-36-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02907, current rewards: 159.63955, mean: 0.10572
[32m[0906 20-36-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02907, current rewards: 165.11634, mean: 0.10584
[32m[0906 20-36-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02906, current rewards: 170.59118, mean: 0.10596
[32m[0906 20-36-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02906, current rewards: 176.05980, mean: 0.10606
[32m[0906 20-36-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02907, current rewards: 181.53814, mean: 0.10616
[32m[0906 20-36-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02907, current rewards: 187.00800, mean: 0.10625
[32m[0906 20-36-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02907, current rewards: 192.48244, mean: 0.10634
[32m[0906 20-36-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02907, current rewards: 197.84108, mean: 0.10637
[32m[0906 20-36-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02906, current rewards: 203.30315, mean: 0.10644
[32m[0906 20-36-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02906, current rewards: 208.76771, mean: 0.10651
[32m[0906 20-36-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02905, current rewards: 214.22851, mean: 0.10658
[32m[0906 20-36-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02905, current rewards: 219.69496, mean: 0.10665
[32m[0906 20-36-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02905, current rewards: 223.11558, mean: 0.10574
[32m[0906 20-36-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02905, current rewards: 228.63696, mean: 0.10585
[32m[0906 20-36-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02905, current rewards: 234.16515, mean: 0.10596
[32m[0906 20-37-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02905, current rewards: 239.95145, mean: 0.10617
[32m[0906 20-37-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02908, current rewards: 245.48777, mean: 0.10627
[32m[0906 20-37-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02910, current rewards: 251.02324, mean: 0.10637
[32m[0906 20-37-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02913, current rewards: 256.55964, mean: 0.10646
[32m[0906 20-37-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02915, current rewards: 262.09484, mean: 0.10654
[32m[0906 20-37-07 @Agent.py:117][0m Average action selection time: 0.0292
[32m[0906 20-37-07 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-37-07 @MBExp.py:227][0m Rewards obtained: [266.5217219853597], Lows: [4], Highs: [1], Total time: 10205.798124999996
