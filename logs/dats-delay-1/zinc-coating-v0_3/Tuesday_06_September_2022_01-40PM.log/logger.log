[32m[0906 13-40-31 @logger.py:99][0m Log file set to /app/logs/dats-delay-1/zinc-coating-v0_3/Tuesday_06_September_2022_01-40PM.log
[32m[0906 13-40-31 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00003, current rewards: -13.92126, mean: -1.39213
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -65.72169, mean: -1.09536
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -120.69495, mean: -1.09723
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -180.30981, mean: -1.12694
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -236.67073, mean: -1.12700
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -286.13488, mean: -1.10052
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -345.96453, mean: -1.11601
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -402.78235, mean: -1.11884
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -452.11817, mean: -1.10273
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -507.36005, mean: -1.10296
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -572.64123, mean: -1.12283
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -619.81783, mean: -1.10682
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -684.72749, mean: -1.12250
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -743.90874, mean: -1.12713
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -792.42916, mean: -1.11610
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -842.70838, mean: -1.10883
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -886.07494, mean: -1.09392
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -939.93322, mean: -1.09295
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -1004.24373, mean: -1.10356
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -1073.84716, mean: -1.11859
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1133.11823, mean: -1.12190
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1192.18035, mean: -1.12470
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1254.51492, mean: -1.13019
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1319.78368, mean: -1.13774
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1386.71943, mean: -1.14605
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1445.98201, mean: -1.14760
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1499.87444, mean: -1.14494
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1557.42444, mean: -1.14517
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1624.38263, mean: -1.15204
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1684.05034, mean: -1.15346
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1739.63507, mean: -1.15208
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -1790.93720, mean: -1.14804
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -1844.24897, mean: -1.14550
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -1900.22445, mean: -1.14471
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -1954.21480, mean: -1.14282
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -2012.46754, mean: -1.14345
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -2063.73116, mean: -1.14018
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2118.50415, mean: -1.13898
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2163.74439, mean: -1.13285
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2218.92200, mean: -1.13210
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2269.10410, mean: -1.12891
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2313.32637, mean: -1.12297
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2364.81154, mean: -1.12076
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2443.54105, mean: -1.13127
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2519.06473, mean: -1.13985
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2581.87583, mean: -1.14242
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2660.31364, mean: -1.15165
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2745.51819, mean: -1.16336
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2812.54679, mean: -1.16703
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2895.13070, mean: -1.17688
[32m[0906 13-40-31 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-40-31 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-40-34 @MBExp.py:144][0m ####################################################################
[32m[0906 13-40-34 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.04812, current rewards: 0.37791, mean: 0.03779
[32m[0906 13-40-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03546, current rewards: -32.90922, mean: -0.54849
[32m[0906 13-40-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03426, current rewards: -71.27228, mean: -0.64793
[32m[0906 13-40-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03378, current rewards: -104.45009, mean: -0.65281
[32m[0906 13-40-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03353, current rewards: -142.74335, mean: -0.67973
[32m[0906 13-40-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03336, current rewards: -175.97482, mean: -0.67683
[32m[0906 13-40-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03331, current rewards: -182.61107, mean: -0.58907
[32m[0906 13-40-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03324, current rewards: -157.77627, mean: -0.43827
[32m[0906 13-40-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03321, current rewards: -132.84708, mean: -0.32402
[32m[0906 13-40-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03316, current rewards: -106.48920, mean: -0.23150
[32m[0906 13-40-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03314, current rewards: -79.41280, mean: -0.15571
[32m[0906 13-40-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03312, current rewards: -69.68902, mean: -0.12444
[32m[0906 13-40-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03308, current rewards: -60.90036, mean: -0.09984
[32m[0906 13-40-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03305, current rewards: -52.11169, mean: -0.07896
[32m[0906 13-40-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03302, current rewards: -43.32303, mean: -0.06102
[32m[0906 13-40-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03299, current rewards: -34.53436, mean: -0.04544
[32m[0906 13-41-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03298, current rewards: -83.35859, mean: -0.10291
[32m[0906 13-41-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03297, current rewards: -133.35859, mean: -0.15507
[32m[0906 13-41-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03296, current rewards: -183.35859, mean: -0.20149
[32m[0906 13-41-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03297, current rewards: -192.66888, mean: -0.20070
[32m[0906 13-41-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03296, current rewards: -183.33876, mean: -0.18152
[32m[0906 13-41-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03290, current rewards: -174.00457, mean: -0.16416
[32m[0906 13-41-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03284, current rewards: -164.68372, mean: -0.14836
[32m[0906 13-41-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03278, current rewards: -155.33514, mean: -0.13391
[32m[0906 13-41-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03280, current rewards: -135.37273, mean: -0.11188
[32m[0906 13-41-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03279, current rewards: -106.95184, mean: -0.08488
[32m[0906 13-41-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03284, current rewards: -91.49650, mean: -0.06984
[32m[0906 13-41-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03285, current rewards: -76.00821, mean: -0.05589
[32m[0906 13-41-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03286, current rewards: -60.52395, mean: -0.04292
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03288, current rewards: -45.04269, mean: -0.03085
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03295, current rewards: -29.56609, mean: -0.01958
[32m[0906 13-41-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03305, current rewards: -14.14815, mean: -0.00907
[32m[0906 13-41-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03313, current rewards: 1.30318, mean: 0.00081
[32m[0906 13-41-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03322, current rewards: 17.41837, mean: 0.01049
[32m[0906 13-41-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03329, current rewards: 52.98440, mean: 0.03099
[32m[0906 13-41-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03338, current rewards: 88.56583, mean: 0.05032
[32m[0906 13-41-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03345, current rewards: 130.78669, mean: 0.07226
[32m[0906 13-41-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03351, current rewards: 172.79301, mean: 0.09290
[32m[0906 13-41-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03358, current rewards: 214.63024, mean: 0.11237
[32m[0906 13-41-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03365, current rewards: 256.67356, mean: 0.13096
[32m[0906 13-41-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03372, current rewards: 298.49900, mean: 0.14851
[32m[0906 13-41-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03379, current rewards: 340.31226, mean: 0.16520
[32m[0906 13-41-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03385, current rewards: 358.17279, mean: 0.16975
[32m[0906 13-41-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03391, current rewards: 368.52340, mean: 0.17061
[32m[0906 13-41-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03397, current rewards: 380.40130, mean: 0.17213
[32m[0906 13-41-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03403, current rewards: 392.26818, mean: 0.17357
[32m[0906 13-41-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03408, current rewards: 404.15076, mean: 0.17496
[32m[0906 13-41-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03413, current rewards: 416.02026, mean: 0.17628
[32m[0906 13-41-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03419, current rewards: 427.88296, mean: 0.17754
[32m[0906 13-41-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03423, current rewards: 439.73721, mean: 0.17875
[32m[0906 13-42-00 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 13-42-00 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-42-00 @MBExp.py:227][0m Rewards obtained: [451.3448768960928], Lows: [144], Highs: [170], Total time: 86.319208
[32m[0906 13-42-04 @MBExp.py:144][0m ####################################################################
[32m[0906 13-42-04 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-42-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03649, current rewards: 1.14152, mean: 0.11415
[32m[0906 13-42-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03636, current rewards: 7.59278, mean: 0.12655
[32m[0906 13-42-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03621, current rewards: 13.96827, mean: 0.12698
[32m[0906 13-42-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03620, current rewards: 20.34189, mean: 0.12714
[32m[0906 13-42-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03614, current rewards: 26.71501, mean: 0.12721
[32m[0906 13-42-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03617, current rewards: 33.08956, mean: 0.12727
[32m[0906 13-42-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03616, current rewards: 38.29065, mean: 0.12352
[32m[0906 13-42-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03615, current rewards: 45.49997, mean: 0.12639
[32m[0906 13-42-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03615, current rewards: 52.70554, mean: 0.12855
[32m[0906 13-42-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03616, current rewards: 59.20805, mean: 0.12871
[32m[0906 13-42-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03616, current rewards: 65.72024, mean: 0.12886
[32m[0906 13-42-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03614, current rewards: 72.27486, mean: 0.12906
[32m[0906 13-42-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03615, current rewards: 79.11558, mean: 0.12970
[32m[0906 13-42-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03612, current rewards: 85.95727, mean: 0.13024
[32m[0906 13-42-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03613, current rewards: 92.80698, mean: 0.13071
[32m[0906 13-42-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03613, current rewards: 99.65161, mean: 0.13112
[32m[0906 13-42-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03613, current rewards: 106.50683, mean: 0.13149
[32m[0906 13-42-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03613, current rewards: 111.32537, mean: 0.12945
[32m[0906 13-42-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03613, current rewards: 117.62559, mean: 0.12926
[32m[0906 13-42-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03613, current rewards: 123.93353, mean: 0.12910
[32m[0906 13-42-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03613, current rewards: 130.24356, mean: 0.12895
[32m[0906 13-42-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03611, current rewards: 136.54613, mean: 0.12882
[32m[0906 13-42-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03608, current rewards: 140.61194, mean: 0.12668
[32m[0906 13-42-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03604, current rewards: 149.62066, mean: 0.12898
[32m[0906 13-42-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03601, current rewards: 158.64363, mean: 0.13111
[32m[0906 13-42-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03602, current rewards: 168.52587, mean: 0.13375
[32m[0906 13-42-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03603, current rewards: 178.62093, mean: 0.13635
[32m[0906 13-42-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03603, current rewards: 188.69454, mean: 0.13875
[32m[0906 13-42-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03603, current rewards: 198.79627, mean: 0.14099
[32m[0906 13-42-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03602, current rewards: 205.47666, mean: 0.14074
[32m[0906 13-42-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03600, current rewards: 211.33421, mean: 0.13996
[32m[0906 13-43-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03598, current rewards: 217.19694, mean: 0.13923
[32m[0906 13-43-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03597, current rewards: 223.06064, mean: 0.13855
[32m[0906 13-43-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03595, current rewards: 229.16491, mean: 0.13805
[32m[0906 13-43-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03593, current rewards: 235.36527, mean: 0.13764
[32m[0906 13-43-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03592, current rewards: 241.55209, mean: 0.13725
[32m[0906 13-43-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03589, current rewards: 247.74494, mean: 0.13688
[32m[0906 13-43-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03586, current rewards: 253.93929, mean: 0.13653
[32m[0906 13-43-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03584, current rewards: 259.00190, mean: 0.13560
[32m[0906 13-43-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03583, current rewards: 266.25642, mean: 0.13585
[32m[0906 13-43-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03584, current rewards: 273.51022, mean: 0.13607
[32m[0906 13-43-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03584, current rewards: 280.08795, mean: 0.13597
[32m[0906 13-43-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03585, current rewards: 285.08938, mean: 0.13511
[32m[0906 13-43-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03586, current rewards: 290.10075, mean: 0.13431
[32m[0906 13-43-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03586, current rewards: 295.11515, mean: 0.13354
[32m[0906 13-43-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03587, current rewards: 300.13625, mean: 0.13280
[32m[0906 13-43-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03587, current rewards: 305.15484, mean: 0.13210
[32m[0906 13-43-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03587, current rewards: 310.17503, mean: 0.13143
[32m[0906 13-43-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03588, current rewards: 315.19254, mean: 0.13079
[32m[0906 13-43-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03588, current rewards: 320.20482, mean: 0.13016
[32m[0906 13-43-35 @Agent.py:117][0m Average action selection time: 0.0359
[32m[0906 13-43-35 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-43-35 @MBExp.py:227][0m Rewards obtained: [324.7536247431351], Lows: [3], Highs: [4], Total time: 176.650732
[32m[0906 13-43-41 @MBExp.py:144][0m ####################################################################
[32m[0906 13-43-41 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-43-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03666, current rewards: -2.29607, mean: -0.22961
[32m[0906 13-43-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03606, current rewards: 2.65765, mean: 0.04429
[32m[0906 13-43-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03618, current rewards: 7.61287, mean: 0.06921
[32m[0906 13-43-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03613, current rewards: 12.56999, mean: 0.07856
[32m[0906 13-43-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03608, current rewards: 17.52411, mean: 0.08345
[32m[0906 13-43-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03607, current rewards: 22.48056, mean: 0.08646
[32m[0906 13-43-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03605, current rewards: 27.43557, mean: 0.08850
[32m[0906 13-43-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03605, current rewards: 32.39182, mean: 0.08998
[32m[0906 13-43-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03607, current rewards: 38.10321, mean: 0.09293
[32m[0906 13-43-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03608, current rewards: 44.72913, mean: 0.09724
[32m[0906 13-44-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03607, current rewards: 51.35587, mean: 0.10070
[32m[0906 13-44-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03606, current rewards: 57.98261, mean: 0.10354
[32m[0906 13-44-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03608, current rewards: 64.36501, mean: 0.10552
[32m[0906 13-44-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03609, current rewards: 70.86199, mean: 0.10737
[32m[0906 13-44-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03610, current rewards: 77.34677, mean: 0.10894
[32m[0906 13-44-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03610, current rewards: 83.83409, mean: 0.11031
[32m[0906 13-44-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03610, current rewards: 90.31449, mean: 0.11150
[32m[0906 13-44-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03608, current rewards: 95.38936, mean: 0.11092
[32m[0906 13-44-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03608, current rewards: 100.42627, mean: 0.11036
[32m[0906 13-44-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03608, current rewards: 105.46451, mean: 0.10986
[32m[0906 13-44-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03608, current rewards: 110.50202, mean: 0.10941
[32m[0906 13-44-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03606, current rewards: 115.53971, mean: 0.10900
[32m[0906 13-44-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03601, current rewards: 120.58110, mean: 0.10863
[32m[0906 13-44-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03598, current rewards: 120.52975, mean: 0.10390
[32m[0906 13-44-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03594, current rewards: 124.60897, mean: 0.10298
[32m[0906 13-44-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03592, current rewards: 129.17825, mean: 0.10252
[32m[0906 13-44-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03591, current rewards: 134.32390, mean: 0.10254
[32m[0906 13-44-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03592, current rewards: 139.46955, mean: 0.10255
[32m[0906 13-44-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03592, current rewards: 144.61520, mean: 0.10256
[32m[0906 13-44-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03590, current rewards: 149.76085, mean: 0.10258
[32m[0906 13-44-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03588, current rewards: 154.90650, mean: 0.10259
[32m[0906 13-44-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03586, current rewards: 123.65602, mean: 0.07927
[32m[0906 13-44-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03585, current rewards: 73.65602, mean: 0.04575
[32m[0906 13-44-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03586, current rewards: 64.52525, mean: 0.03887
[32m[0906 13-44-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03584, current rewards: 68.95524, mean: 0.04032
[32m[0906 13-44-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03583, current rewards: 73.39873, mean: 0.04170
[32m[0906 13-44-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03581, current rewards: 77.84684, mean: 0.04301
[32m[0906 13-44-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03577, current rewards: 81.78884, mean: 0.04397
[32m[0906 13-44-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03575, current rewards: 86.86001, mean: 0.04548
[32m[0906 13-44-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03572, current rewards: 91.93669, mean: 0.04691
[32m[0906 13-44-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03571, current rewards: 97.01031, mean: 0.04826
[32m[0906 13-44-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03571, current rewards: 102.08411, mean: 0.04956
[32m[0906 13-44-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03572, current rewards: 107.42696, mean: 0.05091
[32m[0906 13-44-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03573, current rewards: 112.80609, mean: 0.05223
[32m[0906 13-45-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03574, current rewards: 118.95672, mean: 0.05383
[32m[0906 13-45-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03575, current rewards: 124.45879, mean: 0.05507
[32m[0906 13-45-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03575, current rewards: 129.96201, mean: 0.05626
[32m[0906 13-45-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03576, current rewards: 135.46569, mean: 0.05740
[32m[0906 13-45-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03577, current rewards: 140.97254, mean: 0.05849
[32m[0906 13-45-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03578, current rewards: 146.47287, mean: 0.05954
[32m[0906 13-45-11 @Agent.py:117][0m Average action selection time: 0.0358
[32m[0906 13-45-11 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-45-11 @MBExp.py:227][0m Rewards obtained: [150.76806565770514], Lows: [2], Highs: [100], Total time: 266.728757
[32m[0906 13-45-20 @MBExp.py:144][0m ####################################################################
[32m[0906 13-45-20 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 13-45-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03619, current rewards: -1.03023, mean: -0.10302
[32m[0906 13-45-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03600, current rewards: 5.86953, mean: 0.09783
[32m[0906 13-45-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03598, current rewards: 12.76361, mean: 0.11603
[32m[0906 13-45-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03596, current rewards: 19.64813, mean: 0.12280
[32m[0906 13-45-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03597, current rewards: 26.54718, mean: 0.12642
[32m[0906 13-45-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03598, current rewards: 33.45430, mean: 0.12867
[32m[0906 13-45-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03599, current rewards: 40.34607, mean: 0.13015
[32m[0906 13-45-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03602, current rewards: 47.22748, mean: 0.13119
[32m[0906 13-45-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03606, current rewards: 54.06019, mean: 0.13185
[32m[0906 13-45-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03607, current rewards: 58.24183, mean: 0.12661
[32m[0906 13-45-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03607, current rewards: 64.54745, mean: 0.12656
[32m[0906 13-45-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03606, current rewards: 70.84648, mean: 0.12651
[32m[0906 13-45-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03606, current rewards: 77.14563, mean: 0.12647
[32m[0906 13-45-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03607, current rewards: 83.44240, mean: 0.12643
[32m[0906 13-45-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03607, current rewards: 89.75901, mean: 0.12642
[32m[0906 13-45-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03607, current rewards: 96.06297, mean: 0.12640
[32m[0906 13-45-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03606, current rewards: 102.36855, mean: 0.12638
[32m[0906 13-45-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03606, current rewards: 107.86594, mean: 0.12543
[32m[0906 13-45-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03607, current rewards: 114.04812, mean: 0.12533
[32m[0906 13-45-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03607, current rewards: 120.22334, mean: 0.12523
[32m[0906 13-45-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03606, current rewards: 126.39777, mean: 0.12515
[32m[0906 13-45-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03605, current rewards: 132.58527, mean: 0.12508
[32m[0906 13-46-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03601, current rewards: 138.75876, mean: 0.12501
[32m[0906 13-46-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03598, current rewards: 144.94097, mean: 0.12495
[32m[0906 13-46-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03595, current rewards: 151.11442, mean: 0.12489
[32m[0906 13-46-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03592, current rewards: 157.29295, mean: 0.12484
[32m[0906 13-46-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03590, current rewards: 163.46577, mean: 0.12478
[32m[0906 13-46-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03588, current rewards: 165.57338, mean: 0.12175
[32m[0906 13-46-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03586, current rewards: 171.96776, mean: 0.12196
[32m[0906 13-46-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03584, current rewards: 178.36448, mean: 0.12217
[32m[0906 13-46-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03582, current rewards: 184.75715, mean: 0.12236
[32m[0906 13-46-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03580, current rewards: 191.14910, mean: 0.12253
[32m[0906 13-46-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03579, current rewards: 193.47502, mean: 0.12017
[32m[0906 13-46-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03580, current rewards: 199.61322, mean: 0.12025
[32m[0906 13-46-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03581, current rewards: 205.70329, mean: 0.12029
[32m[0906 13-46-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03580, current rewards: 211.79268, mean: 0.12034
[32m[0906 13-46-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03577, current rewards: 217.88520, mean: 0.12038
[32m[0906 13-46-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03574, current rewards: 223.97418, mean: 0.12042
[32m[0906 13-46-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03571, current rewards: 230.06277, mean: 0.12045
[32m[0906 13-46-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03567, current rewards: 235.01920, mean: 0.11991
[32m[0906 13-46-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03565, current rewards: 240.93909, mean: 0.11987
[32m[0906 13-46-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03563, current rewards: 246.72775, mean: 0.11977
[32m[0906 13-46-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03562, current rewards: 252.50700, mean: 0.11967
[32m[0906 13-46-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03562, current rewards: 258.28657, mean: 0.11958
[32m[0906 13-46-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03563, current rewards: 264.07049, mean: 0.11949
[32m[0906 13-46-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03565, current rewards: 269.85696, mean: 0.11941
[32m[0906 13-46-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03565, current rewards: 275.63843, mean: 0.11932
[32m[0906 13-46-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03566, current rewards: 281.42532, mean: 0.11925
[32m[0906 13-46-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03567, current rewards: 287.21134, mean: 0.11917
[32m[0906 13-46-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03569, current rewards: 292.99846, mean: 0.11911
[32m[0906 13-46-50 @Agent.py:117][0m Average action selection time: 0.0357
[32m[0906 13-46-50 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-46-50 @MBExp.py:227][0m Rewards obtained: [297.6283535484515], Lows: [5], Highs: [4], Total time: 356.58580199999994
[32m[0906 13-47-00 @MBExp.py:144][0m ####################################################################
[32m[0906 13-47-00 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 13-47-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03626, current rewards: -3.33439, mean: -0.33344
[32m[0906 13-47-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03593, current rewards: 1.71910, mean: 0.02865
[32m[0906 13-47-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03589, current rewards: 6.79784, mean: 0.06180
[32m[0906 13-47-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03592, current rewards: 11.87855, mean: 0.07424
[32m[0906 13-47-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03592, current rewards: 16.96195, mean: 0.08077
[32m[0906 13-47-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03596, current rewards: 22.04534, mean: 0.08479
[32m[0906 13-47-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03597, current rewards: 27.11821, mean: 0.08748
[32m[0906 13-47-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03598, current rewards: 32.19660, mean: 0.08943
[32m[0906 13-47-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03597, current rewards: 37.40778, mean: 0.09124
[32m[0906 13-47-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03595, current rewards: 42.52140, mean: 0.09244
[32m[0906 13-47-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03594, current rewards: 48.13628, mean: 0.09438
[32m[0906 13-47-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03594, current rewards: 53.42761, mean: 0.09541
[32m[0906 13-47-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03593, current rewards: 58.72131, mean: 0.09626
[32m[0906 13-47-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03593, current rewards: 64.01812, mean: 0.09700
[32m[0906 13-47-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03592, current rewards: 69.31598, mean: 0.09763
[32m[0906 13-47-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03592, current rewards: 74.60876, mean: 0.09817
[32m[0906 13-47-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03592, current rewards: 80.03039, mean: 0.09880
[32m[0906 13-47-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03593, current rewards: 85.35295, mean: 0.09925
[32m[0906 13-47-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03592, current rewards: 90.67063, mean: 0.09964
[32m[0906 13-47-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03592, current rewards: 95.99537, mean: 0.10000
[32m[0906 13-47-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03592, current rewards: 101.31681, mean: 0.10031
[32m[0906 13-47-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03591, current rewards: 104.50111, mean: 0.09859
[32m[0906 13-47-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03589, current rewards: 109.74394, mean: 0.09887
[32m[0906 13-47-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03587, current rewards: 114.98622, mean: 0.09913
[32m[0906 13-47-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03584, current rewards: 120.08364, mean: 0.09924
[32m[0906 13-47-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03581, current rewards: 125.29693, mean: 0.09944
[32m[0906 13-47-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03579, current rewards: 130.51319, mean: 0.09963
[32m[0906 13-47-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03574, current rewards: 135.73095, mean: 0.09980
[32m[0906 13-47-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03569, current rewards: 139.75527, mean: 0.09912
[32m[0906 13-47-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03567, current rewards: 144.74906, mean: 0.09914
[32m[0906 13-47-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03566, current rewards: 149.75084, mean: 0.09917
[32m[0906 13-47-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03565, current rewards: 154.75568, mean: 0.09920
[32m[0906 13-47-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03563, current rewards: 159.86889, mean: 0.09930
[32m[0906 13-48-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03564, current rewards: 165.00422, mean: 0.09940
[32m[0906 13-48-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03565, current rewards: 170.00488, mean: 0.09942
[32m[0906 13-48-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03566, current rewards: 175.00562, mean: 0.09944
[32m[0906 13-48-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03566, current rewards: 180.00465, mean: 0.09945
[32m[0906 13-48-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03563, current rewards: 185.00814, mean: 0.09947
[32m[0906 13-48-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03560, current rewards: 191.20801, mean: 0.10011
[32m[0906 13-48-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03556, current rewards: 199.50813, mean: 0.10179
[32m[0906 13-48-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03554, current rewards: 207.80825, mean: 0.10339
[32m[0906 13-48-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03551, current rewards: 198.90224, mean: 0.09655
[32m[0906 13-48-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03549, current rewards: 148.90224, mean: 0.07057
[32m[0906 13-48-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03546, current rewards: 98.90224, mean: 0.04579
[32m[0906 13-48-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03546, current rewards: 48.90224, mean: 0.02213
[32m[0906 13-48-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03547, current rewards: -1.09776, mean: -0.00049
[32m[0906 13-48-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03549, current rewards: -51.09776, mean: -0.02212
[32m[0906 13-48-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03551, current rewards: -101.09776, mean: -0.04284
[32m[0906 13-48-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03552, current rewards: -151.09776, mean: -0.06270
[32m[0906 13-48-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03552, current rewards: -201.09776, mean: -0.08175
[32m[0906 13-48-30 @Agent.py:117][0m Average action selection time: 0.0355
[32m[0906 13-48-30 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-48-30 @MBExp.py:227][0m Rewards obtained: [-241.0977588616157], Lows: [2], Highs: [458], Total time: 446.03775199999995
[32m[0906 13-48-42 @MBExp.py:144][0m ####################################################################
[32m[0906 13-48-42 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 13-48-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03584, current rewards: -2.15915, mean: -0.21592
[32m[0906 13-48-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03593, current rewards: 3.53532, mean: 0.05892
[32m[0906 13-48-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03609, current rewards: 9.13721, mean: 0.08307
[32m[0906 13-48-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03598, current rewards: 14.74711, mean: 0.09217
[32m[0906 13-48-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03596, current rewards: 20.35675, mean: 0.09694
[32m[0906 13-48-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03596, current rewards: 25.96811, mean: 0.09988
[32m[0906 13-48-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03596, current rewards: 31.58323, mean: 0.10188
[32m[0906 13-48-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03599, current rewards: 37.19120, mean: 0.10331
[32m[0906 13-48-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03600, current rewards: 42.90074, mean: 0.10464
[32m[0906 13-48-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03599, current rewards: 46.55905, mean: 0.10122
[32m[0906 13-49-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03598, current rewards: 51.83381, mean: 0.10163
[32m[0906 13-49-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03597, current rewards: 57.11247, mean: 0.10199
[32m[0906 13-49-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03598, current rewards: 62.38620, mean: 0.10227
[32m[0906 13-49-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03598, current rewards: 65.60339, mean: 0.09940
[32m[0906 13-49-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03600, current rewards: 70.73860, mean: 0.09963
[32m[0906 13-49-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03602, current rewards: 75.87200, mean: 0.09983
[32m[0906 13-49-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03601, current rewards: 81.00317, mean: 0.10000
[32m[0906 13-49-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03602, current rewards: 86.11770, mean: 0.10014
[32m[0906 13-49-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03604, current rewards: 89.97778, mean: 0.09888
[32m[0906 13-49-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03604, current rewards: 96.43660, mean: 0.10045
[32m[0906 13-49-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03604, current rewards: 102.89543, mean: 0.10188
[32m[0906 13-49-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03604, current rewards: 109.35425, mean: 0.10316
[32m[0906 13-49-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03600, current rewards: 115.81308, mean: 0.10434
[32m[0906 13-49-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03597, current rewards: 122.27190, mean: 0.10541
[32m[0906 13-49-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03593, current rewards: 128.73072, mean: 0.10639
[32m[0906 13-49-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03590, current rewards: 110.36515, mean: 0.08759
[32m[0906 13-49-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03584, current rewards: 60.36515, mean: 0.04608
[32m[0906 13-49-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03578, current rewards: 10.36515, mean: 0.00762
[32m[0906 13-49-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03573, current rewards: -39.63485, mean: -0.02811
[32m[0906 13-49-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03568, current rewards: -89.63485, mean: -0.06139
[32m[0906 13-49-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03565, current rewards: -139.63485, mean: -0.09247
[32m[0906 13-49-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03563, current rewards: -189.63485, mean: -0.12156
[32m[0906 13-49-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03562, current rewards: -239.63485, mean: -0.14884
[32m[0906 13-49-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03561, current rewards: -289.63485, mean: -0.17448
[32m[0906 13-49-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03563, current rewards: -339.63485, mean: -0.19862
[32m[0906 13-49-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03564, current rewards: -389.63485, mean: -0.22138
[32m[0906 13-49-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03565, current rewards: -439.63485, mean: -0.24289
[32m[0906 13-49-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03563, current rewards: -489.63485, mean: -0.26324
[32m[0906 13-49-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03561, current rewards: -539.63485, mean: -0.28253
[32m[0906 13-49-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03557, current rewards: -589.63485, mean: -0.30083
[32m[0906 13-49-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03554, current rewards: -639.63485, mean: -0.31823
[32m[0906 13-49-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03552, current rewards: -689.63485, mean: -0.33477
[32m[0906 13-49-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03550, current rewards: -739.63485, mean: -0.35054
[32m[0906 13-49-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03547, current rewards: -789.63485, mean: -0.36557
[32m[0906 13-50-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03545, current rewards: -839.63485, mean: -0.37993
[32m[0906 13-50-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03544, current rewards: -889.63485, mean: -0.39364
[32m[0906 13-50-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03543, current rewards: -939.63485, mean: -0.40677
[32m[0906 13-50-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03543, current rewards: -989.63485, mean: -0.41934
[32m[0906 13-50-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03544, current rewards: -1039.63485, mean: -0.43138
[32m[0906 13-50-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03546, current rewards: -1089.63485, mean: -0.44294
[32m[0906 13-50-12 @Agent.py:117][0m Average action selection time: 0.0355
[32m[0906 13-50-12 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-50-12 @MBExp.py:227][0m Rewards obtained: [-1129.634849021666], Lows: [3], Highs: [1264], Total time: 535.3312199999999
[32m[0906 13-50-26 @MBExp.py:144][0m ####################################################################
[32m[0906 13-50-26 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 13-50-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03605, current rewards: 0.00216, mean: 0.00022
[32m[0906 13-50-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03597, current rewards: 5.84462, mean: 0.09741
[32m[0906 13-50-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03597, current rewards: 11.66939, mean: 0.10609
[32m[0906 13-50-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03599, current rewards: 17.49272, mean: 0.10933
[32m[0906 13-50-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03600, current rewards: 23.31437, mean: 0.11102
[32m[0906 13-50-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03599, current rewards: 29.13807, mean: 0.11207
[32m[0906 13-50-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03604, current rewards: 34.96062, mean: 0.11278
[32m[0906 13-50-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03602, current rewards: 40.78296, mean: 0.11329
[32m[0906 13-50-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03600, current rewards: 46.31715, mean: 0.11297
[32m[0906 13-50-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03600, current rewards: 51.72817, mean: 0.11245
[32m[0906 13-50-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03600, current rewards: 57.13631, mean: 0.11203
[32m[0906 13-50-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03602, current rewards: 62.54333, mean: 0.11168
[32m[0906 13-50-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03602, current rewards: 67.95082, mean: 0.11139
[32m[0906 13-50-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03601, current rewards: 71.88175, mean: 0.10891
[32m[0906 13-50-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03603, current rewards: 76.59289, mean: 0.10788
[32m[0906 13-50-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03602, current rewards: 81.31024, mean: 0.10699
[32m[0906 13-50-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03603, current rewards: 86.05373, mean: 0.10624
[32m[0906 13-50-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03602, current rewards: 90.84323, mean: 0.10563
[32m[0906 13-50-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03603, current rewards: 95.63652, mean: 0.10510
[32m[0906 13-51-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03604, current rewards: 100.42889, mean: 0.10461
[32m[0906 13-51-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03604, current rewards: 105.21686, mean: 0.10418
[32m[0906 13-51-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03604, current rewards: 110.00734, mean: 0.10378
[32m[0906 13-51-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03601, current rewards: 114.80326, mean: 0.10343
[32m[0906 13-51-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03598, current rewards: 119.59457, mean: 0.10310
[32m[0906 13-51-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03595, current rewards: 124.36885, mean: 0.10278
[32m[0906 13-51-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03591, current rewards: 129.12610, mean: 0.10248
[32m[0906 13-51-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03586, current rewards: 133.87724, mean: 0.10220
[32m[0906 13-51-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03580, current rewards: 138.62493, mean: 0.10193
[32m[0906 13-51-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03575, current rewards: 143.37931, mean: 0.10169
[32m[0906 13-51-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03569, current rewards: 146.32612, mean: 0.10022
[32m[0906 13-51-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03565, current rewards: 151.88125, mean: 0.10058
[32m[0906 13-51-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03561, current rewards: 157.43536, mean: 0.10092
[32m[0906 13-51-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03560, current rewards: 162.99110, mean: 0.10124
[32m[0906 13-51-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03559, current rewards: 168.54597, mean: 0.10153
[32m[0906 13-51-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03561, current rewards: 174.10174, mean: 0.10181
[32m[0906 13-51-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03563, current rewards: 179.66158, mean: 0.10208
[32m[0906 13-51-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03564, current rewards: 185.21584, mean: 0.10233
[32m[0906 13-51-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03563, current rewards: 190.77670, mean: 0.10257
[32m[0906 13-51-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03563, current rewards: 196.32932, mean: 0.10279
[32m[0906 13-51-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03561, current rewards: 201.88663, mean: 0.10300
[32m[0906 13-51-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03559, current rewards: 207.49953, mean: 0.10323
[32m[0906 13-51-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03556, current rewards: 212.98256, mean: 0.10339
[32m[0906 13-51-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03553, current rewards: 217.90090, mean: 0.10327
[32m[0906 13-51-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03550, current rewards: 224.04534, mean: 0.10372
[32m[0906 13-51-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03547, current rewards: 230.18854, mean: 0.10416
[32m[0906 13-51-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03545, current rewards: 236.33284, mean: 0.10457
[32m[0906 13-51-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03543, current rewards: 242.47956, mean: 0.10497
[32m[0906 13-51-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03543, current rewards: 248.62592, mean: 0.10535
[32m[0906 13-51-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03543, current rewards: 253.82424, mean: 0.10532
[32m[0906 13-51-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03543, current rewards: 259.00674, mean: 0.10529
[32m[0906 13-51-56 @Agent.py:117][0m Average action selection time: 0.0354
[32m[0906 13-51-56 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-51-56 @MBExp.py:227][0m Rewards obtained: [263.15164873473844], Lows: [1], Highs: [3], Total time: 624.5358419999999
[32m[0906 13-52-12 @MBExp.py:144][0m ####################################################################
[32m[0906 13-52-12 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 13-52-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03622, current rewards: -2.24777, mean: -0.22478
[32m[0906 13-52-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03635, current rewards: 3.44833, mean: 0.05747
[32m[0906 13-52-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03617, current rewards: 9.14841, mean: 0.08317
[32m[0906 13-52-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03616, current rewards: 14.84275, mean: 0.09277
[32m[0906 13-52-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03612, current rewards: 20.53548, mean: 0.09779
[32m[0906 13-52-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03610, current rewards: 26.23216, mean: 0.10089
[32m[0906 13-52-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03610, current rewards: 31.92861, mean: 0.10300
[32m[0906 13-52-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03608, current rewards: 37.94814, mean: 0.10541
[32m[0906 13-52-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03607, current rewards: 42.75050, mean: 0.10427
[32m[0906 13-52-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03605, current rewards: 48.75994, mean: 0.10600
[32m[0906 13-52-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03604, current rewards: 54.76153, mean: 0.10738
[32m[0906 13-52-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03605, current rewards: 60.77458, mean: 0.10853
[32m[0906 13-52-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03607, current rewards: 66.78071, mean: 0.10948
[32m[0906 13-52-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03608, current rewards: 72.78491, mean: 0.11028
[32m[0906 13-52-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03607, current rewards: 78.78793, mean: 0.11097
[32m[0906 13-52-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03608, current rewards: 84.59940, mean: 0.11131
[32m[0906 13-52-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03608, current rewards: 90.56161, mean: 0.11180
[32m[0906 13-52-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03607, current rewards: 96.52109, mean: 0.11223
[32m[0906 13-52-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03606, current rewards: 102.48000, mean: 0.11262
[32m[0906 13-52-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03606, current rewards: 106.27445, mean: 0.11070
[32m[0906 13-52-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03605, current rewards: 112.14712, mean: 0.11104
[32m[0906 13-52-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03607, current rewards: 118.02331, mean: 0.11134
[32m[0906 13-52-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03607, current rewards: 123.90160, mean: 0.11162
[32m[0906 13-52-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03602, current rewards: 129.87959, mean: 0.11197
[32m[0906 13-52-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03597, current rewards: 135.78093, mean: 0.11222
[32m[0906 13-52-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03591, current rewards: 139.58461, mean: 0.11078
[32m[0906 13-53-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03585, current rewards: 145.51763, mean: 0.11108
[32m[0906 13-53-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03579, current rewards: 151.44515, mean: 0.11136
[32m[0906 13-53-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03574, current rewards: 157.37530, mean: 0.11161
[32m[0906 13-53-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03569, current rewards: 163.30744, mean: 0.11185
[32m[0906 13-53-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03565, current rewards: 169.23674, mean: 0.11208
[32m[0906 13-53-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03561, current rewards: 174.06563, mean: 0.11158
[32m[0906 13-53-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03557, current rewards: 180.02612, mean: 0.11182
[32m[0906 13-53-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03555, current rewards: 185.87671, mean: 0.11197
[32m[0906 13-53-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03556, current rewards: 191.72847, mean: 0.11212
[32m[0906 13-53-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03557, current rewards: 197.58037, mean: 0.11226
[32m[0906 13-53-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03558, current rewards: 203.43274, mean: 0.11239
[32m[0906 13-53-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03558, current rewards: 207.82262, mean: 0.11173
[32m[0906 13-53-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03557, current rewards: 213.27789, mean: 0.11166
[32m[0906 13-53-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03556, current rewards: 218.73411, mean: 0.11160
[32m[0906 13-53-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03555, current rewards: 224.01410, mean: 0.11145
[32m[0906 13-53-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03553, current rewards: 229.51404, mean: 0.11141
[32m[0906 13-53-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03551, current rewards: 235.01848, mean: 0.11138
[32m[0906 13-53-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03548, current rewards: 238.44940, mean: 0.11039
[32m[0906 13-53-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03545, current rewards: 244.28231, mean: 0.11053
[32m[0906 13-53-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03543, current rewards: 250.11249, mean: 0.11067
[32m[0906 13-53-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03541, current rewards: 255.94143, mean: 0.11080
[32m[0906 13-53-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03539, current rewards: 261.77248, mean: 0.11092
[32m[0906 13-53-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03539, current rewards: 267.60228, mean: 0.11104
[32m[0906 13-53-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03539, current rewards: 273.43293, mean: 0.11115
[32m[0906 13-53-41 @Agent.py:117][0m Average action selection time: 0.0354
[32m[0906 13-53-41 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-53-41 @MBExp.py:227][0m Rewards obtained: [278.0953669547079], Lows: [3], Highs: [6], Total time: 713.6280579999999
[32m[0906 13-54-00 @MBExp.py:144][0m ####################################################################
[32m[0906 13-54-00 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 13-54-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03616, current rewards: -1.03213, mean: -0.10321
[32m[0906 13-54-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03606, current rewards: 4.52870, mean: 0.07548
[32m[0906 13-54-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03598, current rewards: 10.09253, mean: 0.09175
[32m[0906 13-54-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03600, current rewards: 15.65990, mean: 0.09787
[32m[0906 13-54-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03601, current rewards: 21.22369, mean: 0.10107
[32m[0906 13-54-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03600, current rewards: 26.79367, mean: 0.10305
[32m[0906 13-54-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03599, current rewards: 32.54080, mean: 0.10497
[32m[0906 13-54-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03598, current rewards: 38.14421, mean: 0.10596
[32m[0906 13-54-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03600, current rewards: 43.75611, mean: 0.10672
[32m[0906 13-54-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03602, current rewards: 49.36015, mean: 0.10730
[32m[0906 13-54-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03603, current rewards: 52.97971, mean: 0.10388
[32m[0906 13-54-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03605, current rewards: 58.64098, mean: 0.10472
[32m[0906 13-54-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03605, current rewards: 64.29751, mean: 0.10541
[32m[0906 13-54-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03606, current rewards: 69.95607, mean: 0.10599
[32m[0906 13-54-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03605, current rewards: 75.61696, mean: 0.10650
[32m[0906 13-54-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03603, current rewards: 80.30285, mean: 0.10566
[32m[0906 13-54-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03603, current rewards: 85.99862, mean: 0.10617
[32m[0906 13-54-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03603, current rewards: 91.69670, mean: 0.10662
[32m[0906 13-54-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03604, current rewards: 97.39879, mean: 0.10703
[32m[0906 13-54-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03603, current rewards: 103.09949, mean: 0.10740
[32m[0906 13-54-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03602, current rewards: 108.80415, mean: 0.10773
[32m[0906 13-54-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03603, current rewards: 114.50354, mean: 0.10802
[32m[0906 13-54-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03603, current rewards: 120.20516, mean: 0.10829
[32m[0906 13-54-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03600, current rewards: 121.60393, mean: 0.10483
[32m[0906 13-54-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03593, current rewards: 127.26453, mean: 0.10518
[32m[0906 13-54-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03587, current rewards: 132.92356, mean: 0.10549
[32m[0906 13-54-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03581, current rewards: 138.58372, mean: 0.10579
[32m[0906 13-54-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03576, current rewards: 144.24641, mean: 0.10606
[32m[0906 13-54-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03571, current rewards: 149.91184, mean: 0.10632
[32m[0906 13-54-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03566, current rewards: 153.71895, mean: 0.10529
[32m[0906 13-54-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03561, current rewards: 159.42573, mean: 0.10558
[32m[0906 13-54-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03557, current rewards: 165.36042, mean: 0.10600
[32m[0906 13-54-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03553, current rewards: 170.96870, mean: 0.10619
[32m[0906 13-55-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03550, current rewards: 176.57704, mean: 0.10637
[32m[0906 13-55-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03547, current rewards: 182.18538, mean: 0.10654
[32m[0906 13-55-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03549, current rewards: 187.79370, mean: 0.10670
[32m[0906 13-55-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03551, current rewards: 193.40191, mean: 0.10685
[32m[0906 13-55-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03551, current rewards: 199.00999, mean: 0.10699
[32m[0906 13-55-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03550, current rewards: 204.61813, mean: 0.10713
[32m[0906 13-55-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03549, current rewards: 210.72416, mean: 0.10751
[32m[0906 13-55-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03548, current rewards: 192.08428, mean: 0.09556
[32m[0906 13-55-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03547, current rewards: 181.04192, mean: 0.08788
[32m[0906 13-55-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03546, current rewards: 186.65057, mean: 0.08846
[32m[0906 13-55-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03543, current rewards: 192.25688, mean: 0.08901
[32m[0906 13-55-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03540, current rewards: 197.86572, mean: 0.08953
[32m[0906 13-55-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03538, current rewards: 203.47025, mean: 0.09003
[32m[0906 13-55-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03535, current rewards: 209.07666, mean: 0.09051
[32m[0906 13-55-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03533, current rewards: 214.61173, mean: 0.09094
[32m[0906 13-55-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03531, current rewards: 220.20735, mean: 0.09137
[32m[0906 13-55-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03529, current rewards: 225.90386, mean: 0.09183
[32m[0906 13-55-29 @Agent.py:117][0m Average action selection time: 0.0353
[32m[0906 13-55-29 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-55-29 @MBExp.py:227][0m Rewards obtained: [230.46250551441304], Lows: [4], Highs: [41], Total time: 802.4831159999999
[32m[0906 13-55-50 @MBExp.py:144][0m ####################################################################
[32m[0906 13-55-50 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 13-55-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03570, current rewards: -1.03173, mean: -0.10317
[32m[0906 13-55-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03614, current rewards: 4.61954, mean: 0.07699
[32m[0906 13-55-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03609, current rewards: 10.27565, mean: 0.09341
[32m[0906 13-55-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03612, current rewards: 15.92935, mean: 0.09956
[32m[0906 13-55-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03606, current rewards: 21.58005, mean: 0.10276
[32m[0906 13-55-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03607, current rewards: 27.22659, mean: 0.10472
[32m[0906 13-56-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03608, current rewards: 33.04795, mean: 0.10661
[32m[0906 13-56-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03610, current rewards: 36.65435, mean: 0.10182
[32m[0906 13-56-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03608, current rewards: 42.28477, mean: 0.10313
[32m[0906 13-56-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03609, current rewards: 47.91282, mean: 0.10416
[32m[0906 13-56-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03608, current rewards: 53.53834, mean: 0.10498
[32m[0906 13-56-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03608, current rewards: 59.16061, mean: 0.10564
[32m[0906 13-56-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03607, current rewards: 64.78931, mean: 0.10621
[32m[0906 13-56-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03606, current rewards: 70.41735, mean: 0.10669
[32m[0906 13-56-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03606, current rewards: 75.91301, mean: 0.10692
[32m[0906 13-56-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03606, current rewards: 81.44024, mean: 0.10716
[32m[0906 13-56-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03604, current rewards: 84.94141, mean: 0.10487
[32m[0906 13-56-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03604, current rewards: 90.55332, mean: 0.10529
[32m[0906 13-56-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03604, current rewards: 96.16648, mean: 0.10568
[32m[0906 13-56-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03603, current rewards: 101.77614, mean: 0.10602
[32m[0906 13-56-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03602, current rewards: 107.38711, mean: 0.10632
[32m[0906 13-56-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03601, current rewards: 112.99428, mean: 0.10660
[32m[0906 13-56-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03601, current rewards: 116.82028, mean: 0.10524
[32m[0906 13-56-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03596, current rewards: 123.30423, mean: 0.10630
[32m[0906 13-56-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03588, current rewards: 129.59635, mean: 0.10710
[32m[0906 13-56-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03582, current rewards: 135.88058, mean: 0.10784
[32m[0906 13-56-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03577, current rewards: 142.16755, mean: 0.10852
[32m[0906 13-56-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03572, current rewards: 148.45183, mean: 0.10916
[32m[0906 13-56-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03567, current rewards: 154.74608, mean: 0.10975
[32m[0906 13-56-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03563, current rewards: 161.03318, mean: 0.11030
[32m[0906 13-56-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03559, current rewards: 165.94018, mean: 0.10989
[32m[0906 13-56-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03554, current rewards: 172.43019, mean: 0.11053
[32m[0906 13-56-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03550, current rewards: 175.04797, mean: 0.10873
[32m[0906 13-56-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03546, current rewards: 177.63520, mean: 0.10701
[32m[0906 13-56-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03542, current rewards: 180.22242, mean: 0.10539
[32m[0906 13-56-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03542, current rewards: 182.80965, mean: 0.10387
[32m[0906 13-56-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03542, current rewards: 160.15500, mean: 0.08848
[32m[0906 13-56-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03544, current rewards: 128.00548, mean: 0.06882
[32m[0906 13-56-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03544, current rewards: 133.71675, mean: 0.07001
[32m[0906 13-57-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03543, current rewards: 139.43005, mean: 0.07114
[32m[0906 13-57-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03542, current rewards: 145.30202, mean: 0.07229
[32m[0906 13-57-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03542, current rewards: 151.03698, mean: 0.07332
[32m[0906 13-57-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03541, current rewards: 152.91448, mean: 0.07247
[32m[0906 13-57-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03541, current rewards: 158.93431, mean: 0.07358
[32m[0906 13-57-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03540, current rewards: 164.94853, mean: 0.07464
[32m[0906 13-57-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03538, current rewards: 170.96442, mean: 0.07565
[32m[0906 13-57-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03536, current rewards: 176.98501, mean: 0.07662
[32m[0906 13-57-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03534, current rewards: 183.00977, mean: 0.07755
[32m[0906 13-57-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03532, current rewards: 188.70885, mean: 0.07830
[32m[0906 13-57-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03530, current rewards: 194.64250, mean: 0.07912
[32m[0906 13-57-19 @Agent.py:117][0m Average action selection time: 0.0353
[32m[0906 13-57-19 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-57-19 @MBExp.py:227][0m Rewards obtained: [199.3936030496606], Lows: [6], Highs: [60], Total time: 891.3363849999998
[32m[0906 13-57-42 @MBExp.py:144][0m ####################################################################
[32m[0906 13-57-42 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 13-57-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03605, current rewards: -1.17142, mean: -0.11714
[32m[0906 13-57-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03616, current rewards: 4.33952, mean: 0.07233
[32m[0906 13-57-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03610, current rewards: 9.85178, mean: 0.08956
[32m[0906 13-57-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03602, current rewards: 15.35423, mean: 0.09596
[32m[0906 13-57-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03598, current rewards: 20.85549, mean: 0.09931
[32m[0906 13-57-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03600, current rewards: 26.36260, mean: 0.10139
[32m[0906 13-57-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03600, current rewards: 31.86825, mean: 0.10280
[32m[0906 13-57-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03598, current rewards: 37.37901, mean: 0.10383
[32m[0906 13-57-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03597, current rewards: 42.88660, mean: 0.10460
[32m[0906 13-57-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03595, current rewards: 48.39510, mean: 0.10521
[32m[0906 13-58-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03595, current rewards: 53.90460, mean: 0.10570
[32m[0906 13-58-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03595, current rewards: 59.41157, mean: 0.10609
[32m[0906 13-58-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03596, current rewards: 59.61142, mean: 0.09772
[32m[0906 13-58-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03597, current rewards: 65.19505, mean: 0.09878
[32m[0906 13-58-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03597, current rewards: 70.80109, mean: 0.09972
[32m[0906 13-58-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03597, current rewards: 76.62559, mean: 0.10082
[32m[0906 13-58-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03597, current rewards: 82.22863, mean: 0.10152
[32m[0906 13-58-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03597, current rewards: 87.83283, mean: 0.10213
[32m[0906 13-58-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03596, current rewards: 93.43565, mean: 0.10268
[32m[0906 13-58-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03595, current rewards: 99.03956, mean: 0.10317
[32m[0906 13-58-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03596, current rewards: 100.11242, mean: 0.09912
[32m[0906 13-58-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03596, current rewards: 107.97196, mean: 0.10186
[32m[0906 13-58-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03593, current rewards: 115.83149, mean: 0.10435
[32m[0906 13-58-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03590, current rewards: 122.32642, mean: 0.10545
[32m[0906 13-58-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03584, current rewards: 76.53005, mean: 0.06325
[32m[0906 13-58-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03576, current rewards: 26.53005, mean: 0.02106
[32m[0906 13-58-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03571, current rewards: -23.46995, mean: -0.01792
[32m[0906 13-58-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03566, current rewards: -73.46995, mean: -0.05402
[32m[0906 13-58-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03561, current rewards: -123.46995, mean: -0.08757
[32m[0906 13-58-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03557, current rewards: -173.46995, mean: -0.11882
[32m[0906 13-58-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03552, current rewards: -223.46995, mean: -0.14799
[32m[0906 13-58-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03548, current rewards: -273.46995, mean: -0.17530
[32m[0906 13-58-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03545, current rewards: -323.46995, mean: -0.20091
[32m[0906 13-58-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03542, current rewards: -373.46995, mean: -0.22498
[32m[0906 13-58-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03538, current rewards: -423.46995, mean: -0.24764
[32m[0906 13-58-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03537, current rewards: -473.46995, mean: -0.26902
[32m[0906 13-58-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03536, current rewards: -523.46995, mean: -0.28921
[32m[0906 13-58-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03536, current rewards: -573.46995, mean: -0.30832
[32m[0906 13-58-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03536, current rewards: -623.46995, mean: -0.32642
[32m[0906 13-58-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03536, current rewards: -673.46995, mean: -0.34361
[32m[0906 13-58-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03535, current rewards: -723.46995, mean: -0.35994
[32m[0906 13-58-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03535, current rewards: -773.46995, mean: -0.37547
[32m[0906 13-58-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03535, current rewards: -823.46995, mean: -0.39027
[32m[0906 13-58-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03534, current rewards: -873.46995, mean: -0.40438
[32m[0906 13-59-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03533, current rewards: -923.46995, mean: -0.41786
[32m[0906 13-59-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03532, current rewards: -973.46995, mean: -0.43074
[32m[0906 13-59-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03531, current rewards: -1023.46995, mean: -0.44306
[32m[0906 13-59-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03529, current rewards: -1073.46995, mean: -0.45486
[32m[0906 13-59-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03527, current rewards: -1123.46995, mean: -0.46617
[32m[0906 13-59-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03526, current rewards: -1173.46995, mean: -0.47702
[32m[0906 13-59-11 @Agent.py:117][0m Average action selection time: 0.0352
[32m[0906 13-59-11 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-59-11 @MBExp.py:227][0m Rewards obtained: [-1213.4699469543536], Lows: [5], Highs: [1339], Total time: 980.0647669999998
[32m[0906 13-59-35 @MBExp.py:144][0m ####################################################################
[32m[0906 13-59-35 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 13-59-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03658, current rewards: -0.07961, mean: -0.00796
[32m[0906 13-59-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03624, current rewards: 5.48910, mean: 0.09148
[32m[0906 13-59-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03619, current rewards: 11.05542, mean: 0.10050
[32m[0906 13-59-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03613, current rewards: 16.62870, mean: 0.10393
[32m[0906 13-59-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03610, current rewards: 22.19933, mean: 0.10571
[32m[0906 13-59-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03608, current rewards: 27.76681, mean: 0.10680
[32m[0906 13-59-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03607, current rewards: 33.34310, mean: 0.10756
[32m[0906 13-59-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03609, current rewards: 39.11718, mean: 0.10866
[32m[0906 13-59-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03608, current rewards: 44.67663, mean: 0.10897
[32m[0906 13-59-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03607, current rewards: 50.24181, mean: 0.10922
[32m[0906 13-59-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03605, current rewards: 55.80116, mean: 0.10941
[32m[0906 13-59-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03605, current rewards: 61.36538, mean: 0.10958
[32m[0906 13-59-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03605, current rewards: 63.39735, mean: 0.10393
[32m[0906 13-59-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03608, current rewards: 69.49157, mean: 0.10529
[32m[0906 14-00-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03607, current rewards: 75.58222, mean: 0.10645
[32m[0906 14-00-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03606, current rewards: 81.35862, mean: 0.10705
[32m[0906 14-00-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03606, current rewards: 87.10626, mean: 0.10754
[32m[0906 14-00-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03605, current rewards: 90.58892, mean: 0.10534
[32m[0906 14-00-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03606, current rewards: 96.03518, mean: 0.10553
[32m[0906 14-00-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03606, current rewards: 101.48225, mean: 0.10571
[32m[0906 14-00-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03606, current rewards: 106.93766, mean: 0.10588
[32m[0906 14-00-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03604, current rewards: 112.38897, mean: 0.10603
[32m[0906 14-00-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03600, current rewards: 117.83833, mean: 0.10616
[32m[0906 14-00-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03596, current rewards: 123.29225, mean: 0.10629
[32m[0906 14-00-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03589, current rewards: 128.74445, mean: 0.10640
[32m[0906 14-00-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03583, current rewards: 134.19407, mean: 0.10650
[32m[0906 14-00-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03576, current rewards: 139.64889, mean: 0.10660
[32m[0906 14-00-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03571, current rewards: 141.91223, mean: 0.10435
[32m[0906 14-00-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03566, current rewards: 147.46134, mean: 0.10458
[32m[0906 14-00-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03561, current rewards: 153.01195, mean: 0.10480
[32m[0906 14-00-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03557, current rewards: 158.55812, mean: 0.10501
[32m[0906 14-00-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03553, current rewards: 164.11039, mean: 0.10520
[32m[0906 14-00-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03549, current rewards: 169.89058, mean: 0.10552
[32m[0906 14-00-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03546, current rewards: 175.42376, mean: 0.10568
[32m[0906 14-00-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03543, current rewards: 180.95731, mean: 0.10582
[32m[0906 14-00-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03540, current rewards: 186.48603, mean: 0.10596
[32m[0906 14-00-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03539, current rewards: 192.01611, mean: 0.10609
[32m[0906 14-00-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03539, current rewards: 197.54519, mean: 0.10621
[32m[0906 14-00-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03538, current rewards: 203.86697, mean: 0.10674
[32m[0906 14-00-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03536, current rewards: 209.51648, mean: 0.10690
[32m[0906 14-00-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03536, current rewards: 215.13776, mean: 0.10703
[32m[0906 14-00-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03536, current rewards: 220.77610, mean: 0.10717
[32m[0906 14-00-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03536, current rewards: 226.42535, mean: 0.10731
[32m[0906 14-00-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03536, current rewards: 232.07534, mean: 0.10744
[32m[0906 14-00-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03536, current rewards: 237.72336, mean: 0.10757
[32m[0906 14-00-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03536, current rewards: 239.23626, mean: 0.10586
[32m[0906 14-00-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03535, current rewards: 244.81586, mean: 0.10598
[32m[0906 14-00-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03533, current rewards: 250.39501, mean: 0.10610
[32m[0906 14-01-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03531, current rewards: 255.86459, mean: 0.10617
[32m[0906 14-01-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03529, current rewards: 261.42543, mean: 0.10627
[32m[0906 14-01-04 @Agent.py:117][0m Average action selection time: 0.0353
[32m[0906 14-01-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-01-04 @MBExp.py:227][0m Rewards obtained: [265.8962971524491], Lows: [6], Highs: [2], Total time: 1068.8928689999998
[32m[0906 14-01-31 @MBExp.py:144][0m ####################################################################
[32m[0906 14-01-31 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 14-01-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03662, current rewards: -0.68700, mean: -0.06870
[32m[0906 14-01-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03620, current rewards: 4.61163, mean: 0.07686
[32m[0906 14-01-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03601, current rewards: 9.91533, mean: 0.09014
[32m[0906 14-01-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03597, current rewards: 15.21108, mean: 0.09507
[32m[0906 14-01-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03600, current rewards: 20.50996, mean: 0.09767
[32m[0906 14-01-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03602, current rewards: 25.81141, mean: 0.09927
[32m[0906 14-01-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03601, current rewards: 31.11215, mean: 0.10036
[32m[0906 14-01-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03598, current rewards: 36.36731, mean: 0.10102
[32m[0906 14-01-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03600, current rewards: 41.67681, mean: 0.10165
[32m[0906 14-01-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03601, current rewards: 46.97494, mean: 0.10212
[32m[0906 14-01-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03605, current rewards: 50.17610, mean: 0.09838
[32m[0906 14-01-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03604, current rewards: 55.58704, mean: 0.09926
[32m[0906 14-01-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03605, current rewards: 60.98991, mean: 0.09998
[32m[0906 14-01-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03605, current rewards: 66.39899, mean: 0.10060
[32m[0906 14-01-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03605, current rewards: 71.80786, mean: 0.10114
[32m[0906 14-01-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03605, current rewards: 77.28346, mean: 0.10169
[32m[0906 14-02-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03605, current rewards: 82.66078, mean: 0.10205
[32m[0906 14-02-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03605, current rewards: 88.04056, mean: 0.10237
[32m[0906 14-02-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03606, current rewards: 93.42036, mean: 0.10266
[32m[0906 14-02-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03607, current rewards: 98.80286, mean: 0.10292
[32m[0906 14-02-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03603, current rewards: 103.25107, mean: 0.10223
[32m[0906 14-02-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03599, current rewards: 108.79412, mean: 0.10264
[32m[0906 14-02-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03595, current rewards: 114.33314, mean: 0.10300
[32m[0906 14-02-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03593, current rewards: 119.94127, mean: 0.10340
[32m[0906 14-02-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03587, current rewards: 125.50775, mean: 0.10373
[32m[0906 14-02-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03580, current rewards: 131.07765, mean: 0.10403
[32m[0906 14-02-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03576, current rewards: 134.38442, mean: 0.10258
[32m[0906 14-02-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03570, current rewards: 139.73825, mean: 0.10275
[32m[0906 14-02-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03565, current rewards: 145.09597, mean: 0.10290
[32m[0906 14-02-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03561, current rewards: 150.44930, mean: 0.10305
[32m[0906 14-02-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03557, current rewards: 155.80187, mean: 0.10318
[32m[0906 14-02-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03552, current rewards: 161.10371, mean: 0.10327
[32m[0906 14-02-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03548, current rewards: 166.45821, mean: 0.10339
[32m[0906 14-02-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03545, current rewards: 171.81696, mean: 0.10350
[32m[0906 14-02-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03541, current rewards: 177.17410, mean: 0.10361
[32m[0906 14-02-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03538, current rewards: 182.52633, mean: 0.10371
[32m[0906 14-02-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03538, current rewards: 185.96046, mean: 0.10274
[32m[0906 14-02-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03538, current rewards: 191.28497, mean: 0.10284
[32m[0906 14-02-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03536, current rewards: 196.61413, mean: 0.10294
[32m[0906 14-02-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03533, current rewards: 202.11746, mean: 0.10312
[32m[0906 14-02-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03531, current rewards: 207.47687, mean: 0.10322
[32m[0906 14-02-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03531, current rewards: 212.81540, mean: 0.10331
[32m[0906 14-02-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03531, current rewards: 218.15778, mean: 0.10339
[32m[0906 14-02-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03531, current rewards: 223.49467, mean: 0.10347
[32m[0906 14-02-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03531, current rewards: 227.31737, mean: 0.10286
[32m[0906 14-02-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03530, current rewards: 232.82782, mean: 0.10302
[32m[0906 14-02-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03531, current rewards: 238.33836, mean: 0.10318
[32m[0906 14-02-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03531, current rewards: 243.84887, mean: 0.10333
[32m[0906 14-02-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03530, current rewards: 249.22784, mean: 0.10341
[32m[0906 14-02-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03529, current rewards: 254.70912, mean: 0.10354
[32m[0906 14-03-00 @Agent.py:117][0m Average action selection time: 0.0353
[32m[0906 14-03-00 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-03-00 @MBExp.py:227][0m Rewards obtained: [259.091749813547], Lows: [4], Highs: [3], Total time: 1157.7051669999998
[32m[0906 14-03-29 @MBExp.py:144][0m ####################################################################
[32m[0906 14-03-29 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 14-03-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03743, current rewards: 0.00888, mean: 0.00089
[32m[0906 14-03-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03618, current rewards: 5.71816, mean: 0.09530
[32m[0906 14-03-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03618, current rewards: 11.43131, mean: 0.10392
[32m[0906 14-03-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03623, current rewards: 17.14579, mean: 0.10716
[32m[0906 14-03-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03624, current rewards: 22.86063, mean: 0.10886
[32m[0906 14-03-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03623, current rewards: 28.57244, mean: 0.10989
[32m[0906 14-03-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03618, current rewards: 34.68075, mean: 0.11187
[32m[0906 14-03-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03615, current rewards: 40.44125, mean: 0.11234
[32m[0906 14-03-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03615, current rewards: 46.20181, mean: 0.11269
[32m[0906 14-03-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03612, current rewards: 51.96246, mean: 0.11296
[32m[0906 14-03-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03612, current rewards: 57.72274, mean: 0.11318
[32m[0906 14-03-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03611, current rewards: 63.48336, mean: 0.11336
[32m[0906 14-03-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03612, current rewards: 65.80975, mean: 0.10788
[32m[0906 14-03-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03613, current rewards: 71.39953, mean: 0.10818
[32m[0906 14-03-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03613, current rewards: 76.94110, mean: 0.10837
[32m[0906 14-03-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03612, current rewards: 82.52418, mean: 0.10858
[32m[0906 14-03-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03611, current rewards: 88.10027, mean: 0.10877
[32m[0906 14-04-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03611, current rewards: 92.95980, mean: 0.10809
[32m[0906 14-04-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03611, current rewards: 98.47948, mean: 0.10822
[32m[0906 14-04-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03606, current rewards: 103.99979, mean: 0.10833
[32m[0906 14-04-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03602, current rewards: 109.51881, mean: 0.10843
[32m[0906 14-04-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03598, current rewards: 115.03690, mean: 0.10853
[32m[0906 14-04-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03596, current rewards: 120.52792, mean: 0.10858
[32m[0906 14-04-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03592, current rewards: 125.93650, mean: 0.10857
[32m[0906 14-04-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03586, current rewards: 131.43218, mean: 0.10862
[32m[0906 14-04-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03580, current rewards: 136.92273, mean: 0.10867
[32m[0906 14-04-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03574, current rewards: 142.41175, mean: 0.10871
[32m[0906 14-04-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03570, current rewards: 145.81231, mean: 0.10721
[32m[0906 14-04-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03564, current rewards: 151.28975, mean: 0.10730
[32m[0906 14-04-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03560, current rewards: 156.76331, mean: 0.10737
[32m[0906 14-04-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03556, current rewards: 162.24117, mean: 0.10744
[32m[0906 14-04-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03552, current rewards: 167.71928, mean: 0.10751
[32m[0906 14-04-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03548, current rewards: 173.19449, mean: 0.10757
[32m[0906 14-04-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03545, current rewards: 178.67005, mean: 0.10763
[32m[0906 14-04-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03542, current rewards: 184.14578, mean: 0.10769
[32m[0906 14-04-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03540, current rewards: 189.17718, mean: 0.10749
[32m[0906 14-04-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03540, current rewards: 194.69016, mean: 0.10756
[32m[0906 14-04-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03540, current rewards: 200.19823, mean: 0.10763
[32m[0906 14-04-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03539, current rewards: 205.71063, mean: 0.10770
[32m[0906 14-04-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03536, current rewards: 211.35772, mean: 0.10784
[32m[0906 14-04-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03533, current rewards: 216.91014, mean: 0.10792
[32m[0906 14-04-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03531, current rewards: 222.42820, mean: 0.10797
[32m[0906 14-04-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03530, current rewards: 227.90363, mean: 0.10801
[32m[0906 14-04-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03531, current rewards: 233.39232, mean: 0.10805
[32m[0906 14-04-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03531, current rewards: 238.87823, mean: 0.10809
[32m[0906 14-04-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03531, current rewards: 244.36441, mean: 0.10813
[32m[0906 14-04-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03532, current rewards: 249.85413, mean: 0.10816
[32m[0906 14-04-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03532, current rewards: 251.16903, mean: 0.10643
[32m[0906 14-04-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03531, current rewards: 257.05844, mean: 0.10666
[32m[0906 14-04-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03531, current rewards: 262.77027, mean: 0.10682
[32m[0906 14-04-58 @Agent.py:117][0m Average action selection time: 0.0353
[32m[0906 14-04-58 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-04-58 @MBExp.py:227][0m Rewards obtained: [267.33845614664267], Lows: [3], Highs: [6], Total time: 1246.5570619999999
[32m[0906 14-05-29 @MBExp.py:144][0m ####################################################################
[32m[0906 14-05-29 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 14-05-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03510, current rewards: -2.07828, mean: -0.20783
[32m[0906 14-05-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03593, current rewards: 3.46425, mean: 0.05774
[32m[0906 14-05-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03592, current rewards: 9.00490, mean: 0.08186
[32m[0906 14-05-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03591, current rewards: 14.54144, mean: 0.09088
[32m[0906 14-05-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03596, current rewards: 20.08024, mean: 0.09562
[32m[0906 14-05-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03597, current rewards: 25.68565, mean: 0.09879
[32m[0906 14-05-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03600, current rewards: 31.25258, mean: 0.10081
[32m[0906 14-05-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03601, current rewards: 36.83152, mean: 0.10231
[32m[0906 14-05-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03601, current rewards: 42.40182, mean: 0.10342
[32m[0906 14-05-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03600, current rewards: 47.96621, mean: 0.10427
[32m[0906 14-05-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03600, current rewards: 52.38032, mean: 0.10271
[32m[0906 14-05-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03602, current rewards: 57.89816, mean: 0.10339
[32m[0906 14-05-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03604, current rewards: 63.42070, mean: 0.10397
[32m[0906 14-05-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03604, current rewards: 68.93922, mean: 0.10445
[32m[0906 14-05-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03604, current rewards: 73.39807, mean: 0.10338
[32m[0906 14-05-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03604, current rewards: 78.99016, mean: 0.10393
[32m[0906 14-05-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03603, current rewards: 84.58445, mean: 0.10443
[32m[0906 14-06-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03603, current rewards: 90.17502, mean: 0.10485
[32m[0906 14-06-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03597, current rewards: 95.76759, mean: 0.10524
[32m[0906 14-06-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03592, current rewards: 101.35835, mean: 0.10558
[32m[0906 14-06-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03588, current rewards: 106.95389, mean: 0.10589
[32m[0906 14-06-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03584, current rewards: 112.48516, mean: 0.10612
[32m[0906 14-06-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03583, current rewards: 117.96288, mean: 0.10627
[32m[0906 14-06-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03580, current rewards: 123.57194, mean: 0.10653
[32m[0906 14-06-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03574, current rewards: 129.18216, mean: 0.10676
[32m[0906 14-06-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03568, current rewards: 134.79518, mean: 0.10698
[32m[0906 14-06-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03562, current rewards: 138.29085, mean: 0.10557
[32m[0906 14-06-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03557, current rewards: 141.64151, mean: 0.10415
[32m[0906 14-06-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03552, current rewards: 147.12408, mean: 0.10434
[32m[0906 14-06-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03548, current rewards: 152.60783, mean: 0.10453
[32m[0906 14-06-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03544, current rewards: 158.28238, mean: 0.10482
[32m[0906 14-06-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03540, current rewards: 163.79982, mean: 0.10500
[32m[0906 14-06-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03536, current rewards: 169.31508, mean: 0.10516
[32m[0906 14-06-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03533, current rewards: 174.83035, mean: 0.10532
[32m[0906 14-06-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03529, current rewards: 180.34503, mean: 0.10546
[32m[0906 14-06-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03527, current rewards: 185.86365, mean: 0.10560
[32m[0906 14-06-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03527, current rewards: 191.38103, mean: 0.10574
[32m[0906 14-06-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03528, current rewards: 196.89894, mean: 0.10586
[32m[0906 14-06-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03527, current rewards: 202.39877, mean: 0.10597
[32m[0906 14-06-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03524, current rewards: 207.91031, mean: 0.10608
[32m[0906 14-06-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03522, current rewards: 211.27847, mean: 0.10511
[32m[0906 14-06-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03519, current rewards: 216.82709, mean: 0.10526
[32m[0906 14-06-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03518, current rewards: 222.37289, mean: 0.10539
[32m[0906 14-06-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03517, current rewards: 227.92101, mean: 0.10552
[32m[0906 14-06-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03518, current rewards: 233.46457, mean: 0.10564
[32m[0906 14-06-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03518, current rewards: 239.00850, mean: 0.10576
[32m[0906 14-06-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03518, current rewards: 242.41977, mean: 0.10494
[32m[0906 14-06-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03518, current rewards: 247.95684, mean: 0.10507
[32m[0906 14-06-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03519, current rewards: 253.49593, mean: 0.10519
[32m[0906 14-06-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03518, current rewards: 259.03413, mean: 0.10530
[32m[0906 14-06-57 @Agent.py:117][0m Average action selection time: 0.0352
[32m[0906 14-06-57 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-06-57 @MBExp.py:227][0m Rewards obtained: [263.4678361920257], Lows: [4], Highs: [5], Total time: 1335.158606
[32m[0906 14-07-30 @MBExp.py:144][0m ####################################################################
[32m[0906 14-07-30 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 14-07-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03465, current rewards: -2.21473, mean: -0.22147
[32m[0906 14-07-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03504, current rewards: 3.33261, mean: 0.05554
[32m[0906 14-07-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03526, current rewards: 8.79937, mean: 0.07999
[32m[0906 14-07-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03548, current rewards: 14.26327, mean: 0.08915
[32m[0906 14-07-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03565, current rewards: 19.72789, mean: 0.09394
[32m[0906 14-07-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03570, current rewards: 25.16427, mean: 0.09679
[32m[0906 14-07-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03575, current rewards: 30.62164, mean: 0.09878
[32m[0906 14-07-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03578, current rewards: 36.07789, mean: 0.10022
[32m[0906 14-07-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03583, current rewards: 41.53366, mean: 0.10130
[32m[0906 14-07-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03586, current rewards: 46.99174, mean: 0.10216
[32m[0906 14-07-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03587, current rewards: 52.44652, mean: 0.10284
[32m[0906 14-07-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03589, current rewards: 57.90439, mean: 0.10340
[32m[0906 14-07-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03592, current rewards: 63.23473, mean: 0.10366
[32m[0906 14-07-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03593, current rewards: 68.74830, mean: 0.10416
[32m[0906 14-07-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03593, current rewards: 74.26054, mean: 0.10459
[32m[0906 14-07-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03594, current rewards: 79.76883, mean: 0.10496
[32m[0906 14-07-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03593, current rewards: 85.27884, mean: 0.10528
[32m[0906 14-08-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03588, current rewards: 86.54986, mean: 0.10064
[32m[0906 14-08-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03584, current rewards: 91.98563, mean: 0.10108
[32m[0906 14-08-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03582, current rewards: 97.42180, mean: 0.10148
[32m[0906 14-08-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03578, current rewards: 102.85361, mean: 0.10184
[32m[0906 14-08-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03576, current rewards: 108.53675, mean: 0.10239
[32m[0906 14-08-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03573, current rewards: 114.21382, mean: 0.10290
[32m[0906 14-08-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03570, current rewards: 119.89089, mean: 0.10335
[32m[0906 14-08-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03566, current rewards: 125.56796, mean: 0.10378
[32m[0906 14-08-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03560, current rewards: 131.24502, mean: 0.10416
[32m[0906 14-08-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03555, current rewards: 136.92209, mean: 0.10452
[32m[0906 14-08-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03551, current rewards: 111.42000, mean: 0.08193
[32m[0906 14-08-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03547, current rewards: 61.42000, mean: 0.04356
[32m[0906 14-08-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03543, current rewards: 11.42000, mean: 0.00782
[32m[0906 14-08-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03540, current rewards: -38.58000, mean: -0.02555
[32m[0906 14-08-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03536, current rewards: -88.58000, mean: -0.05678
[32m[0906 14-08-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03533, current rewards: -138.58000, mean: -0.08607
[32m[0906 14-08-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03529, current rewards: -188.58000, mean: -0.11360
[32m[0906 14-08-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03526, current rewards: -238.58000, mean: -0.13952
[32m[0906 14-08-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03524, current rewards: -288.58000, mean: -0.16397
[32m[0906 14-08-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03523, current rewards: -338.58000, mean: -0.18706
[32m[0906 14-08-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03524, current rewards: -388.58000, mean: -0.20891
[32m[0906 14-08-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03523, current rewards: -438.58000, mean: -0.22962
[32m[0906 14-08-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03521, current rewards: -488.58000, mean: -0.24928
[32m[0906 14-08-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03518, current rewards: -538.58000, mean: -0.26795
[32m[0906 14-08-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03516, current rewards: -588.58000, mean: -0.28572
[32m[0906 14-08-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03514, current rewards: -638.58000, mean: -0.30264
[32m[0906 14-08-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03512, current rewards: -688.58000, mean: -0.31879
[32m[0906 14-08-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03511, current rewards: -738.58000, mean: -0.33420
[32m[0906 14-08-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03512, current rewards: -788.58000, mean: -0.34893
[32m[0906 14-08-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03512, current rewards: -838.58000, mean: -0.36302
[32m[0906 14-08-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03512, current rewards: -888.58000, mean: -0.37652
[32m[0906 14-08-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03513, current rewards: -938.58000, mean: -0.38945
[32m[0906 14-08-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03513, current rewards: -988.58000, mean: -0.40186
[32m[0906 14-08-59 @Agent.py:117][0m Average action selection time: 0.0351
[32m[0906 14-08-59 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-08-59 @MBExp.py:227][0m Rewards obtained: [-1028.580000911623], Lows: [2], Highs: [1172], Total time: 1423.626755
[32m[0906 14-09-34 @MBExp.py:144][0m ####################################################################
[32m[0906 14-09-34 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 14-09-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03455, current rewards: -0.83570, mean: -0.08357
[32m[0906 14-09-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03496, current rewards: 4.90496, mean: 0.08175
[32m[0906 14-09-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03507, current rewards: 10.64585, mean: 0.09678
[32m[0906 14-09-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03522, current rewards: 16.38642, mean: 0.10242
[32m[0906 14-09-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03545, current rewards: 22.13701, mean: 0.10541
[32m[0906 14-09-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03556, current rewards: 27.87471, mean: 0.10721
[32m[0906 14-09-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03566, current rewards: 33.61233, mean: 0.10843
[32m[0906 14-09-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03571, current rewards: 39.35029, mean: 0.10931
[32m[0906 14-09-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03574, current rewards: 45.08826, mean: 0.10997
[32m[0906 14-09-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03578, current rewards: 49.53221, mean: 0.10768
[32m[0906 14-09-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03581, current rewards: 55.14836, mean: 0.10813
[32m[0906 14-09-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03582, current rewards: 60.76470, mean: 0.10851
[32m[0906 14-09-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03585, current rewards: 66.24460, mean: 0.10860
[32m[0906 14-09-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03585, current rewards: 71.82519, mean: 0.10883
[32m[0906 14-09-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03586, current rewards: 77.40929, mean: 0.10903
[32m[0906 14-10-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03588, current rewards: 82.99291, mean: 0.10920
[32m[0906 14-10-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03584, current rewards: 88.57406, mean: 0.10935
[32m[0906 14-10-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03580, current rewards: 94.15465, mean: 0.10948
[32m[0906 14-10-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03577, current rewards: 99.73575, mean: 0.10960
[32m[0906 14-10-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03575, current rewards: 105.31497, mean: 0.10970
[32m[0906 14-10-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03572, current rewards: 110.84851, mean: 0.10975
[32m[0906 14-10-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03569, current rewards: 113.31315, mean: 0.10690
[32m[0906 14-10-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03566, current rewards: 118.58760, mean: 0.10684
[32m[0906 14-10-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03565, current rewards: 123.86715, mean: 0.10678
[32m[0906 14-10-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03561, current rewards: 129.14410, mean: 0.10673
[32m[0906 14-10-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03556, current rewards: 134.41604, mean: 0.10668
[32m[0906 14-10-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03551, current rewards: 139.69251, mean: 0.10664
[32m[0906 14-10-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03546, current rewards: 144.96926, mean: 0.10660
[32m[0906 14-10-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03543, current rewards: 150.39171, mean: 0.10666
[32m[0906 14-10-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03540, current rewards: 155.67746, mean: 0.10663
[32m[0906 14-10-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03536, current rewards: 160.96368, mean: 0.10660
[32m[0906 14-10-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03532, current rewards: 166.24947, mean: 0.10657
[32m[0906 14-10-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03530, current rewards: 169.79562, mean: 0.10546
[32m[0906 14-10-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03527, current rewards: 175.21833, mean: 0.10555
[32m[0906 14-10-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03524, current rewards: 180.64436, mean: 0.10564
[32m[0906 14-10-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03521, current rewards: 186.06780, mean: 0.10572
[32m[0906 14-10-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03522, current rewards: 191.39577, mean: 0.10574
[32m[0906 14-10-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03522, current rewards: 196.68624, mean: 0.10575
[32m[0906 14-10-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03521, current rewards: 202.07586, mean: 0.10580
[32m[0906 14-10-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03519, current rewards: 207.46273, mean: 0.10585
[32m[0906 14-10-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03518, current rewards: 212.84966, mean: 0.10590
[32m[0906 14-10-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03516, current rewards: 218.24294, mean: 0.10594
[32m[0906 14-10-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03514, current rewards: 223.63225, mean: 0.10599
[32m[0906 14-10-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03512, current rewards: 228.28406, mean: 0.10569
[32m[0906 14-10-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03510, current rewards: 233.75918, mean: 0.10577
[32m[0906 14-10-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03509, current rewards: 239.38554, mean: 0.10592
[32m[0906 14-10-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03509, current rewards: 244.87282, mean: 0.10601
[32m[0906 14-10-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03510, current rewards: 250.35657, mean: 0.10608
[32m[0906 14-10-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03510, current rewards: 255.84464, mean: 0.10616
[32m[0906 14-11-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03511, current rewards: 261.33477, mean: 0.10623
[32m[0906 14-11-02 @Agent.py:117][0m Average action selection time: 0.0351
[32m[0906 14-11-02 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-11-02 @MBExp.py:227][0m Rewards obtained: [265.7212010659996], Lows: [3], Highs: [3], Total time: 1512.03806
[32m[0906 14-11-39 @MBExp.py:144][0m ####################################################################
[32m[0906 14-11-39 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 14-11-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03521, current rewards: -0.01749, mean: -0.00175
[32m[0906 14-11-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03507, current rewards: 5.57495, mean: 0.09292
[32m[0906 14-11-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03525, current rewards: 11.16942, mean: 0.10154
[32m[0906 14-11-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03523, current rewards: 16.59694, mean: 0.10373
[32m[0906 14-11-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03525, current rewards: 22.11223, mean: 0.10530
[32m[0906 14-11-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03539, current rewards: 27.67527, mean: 0.10644
[32m[0906 14-11-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03550, current rewards: 33.24189, mean: 0.10723
[32m[0906 14-11-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03557, current rewards: 38.80987, mean: 0.10781
[32m[0906 14-11-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03564, current rewards: 44.37770, mean: 0.10824
[32m[0906 14-11-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03567, current rewards: 48.77139, mean: 0.10602
[32m[0906 14-11-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03572, current rewards: 54.26260, mean: 0.10640
[32m[0906 14-11-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03572, current rewards: 59.75323, mean: 0.10670
[32m[0906 14-12-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03574, current rewards: 65.20042, mean: 0.10689
[32m[0906 14-12-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03576, current rewards: 70.69056, mean: 0.10711
[32m[0906 14-12-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03574, current rewards: 76.17657, mean: 0.10729
[32m[0906 14-12-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03570, current rewards: 81.66447, mean: 0.10745
[32m[0906 14-12-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03567, current rewards: 87.15044, mean: 0.10759
[32m[0906 14-12-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03564, current rewards: 92.63486, mean: 0.10771
[32m[0906 14-12-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03561, current rewards: 98.12231, mean: 0.10783
[32m[0906 14-12-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03561, current rewards: 103.60439, mean: 0.10792
[32m[0906 14-12-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03559, current rewards: 109.04812, mean: 0.10797
[32m[0906 14-12-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03558, current rewards: 114.53462, mean: 0.10805
[32m[0906 14-12-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03557, current rewards: 120.01965, mean: 0.10813
[32m[0906 14-12-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03555, current rewards: 125.50255, mean: 0.10819
[32m[0906 14-12-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03551, current rewards: 130.98669, mean: 0.10825
[32m[0906 14-12-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03547, current rewards: 136.46991, mean: 0.10831
[32m[0906 14-12-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03543, current rewards: 141.95819, mean: 0.10837
[32m[0906 14-12-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03538, current rewards: 146.53948, mean: 0.10775
[32m[0906 14-12-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03535, current rewards: 152.02245, mean: 0.10782
[32m[0906 14-12-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03531, current rewards: 157.47678, mean: 0.10786
[32m[0906 14-12-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03527, current rewards: 162.92889, mean: 0.10790
[32m[0906 14-12-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03524, current rewards: 168.37875, mean: 0.10794
[32m[0906 14-12-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03521, current rewards: 173.82335, mean: 0.10796
[32m[0906 14-12-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03519, current rewards: 179.27734, mean: 0.10800
[32m[0906 14-12-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03517, current rewards: 184.72844, mean: 0.10803
[32m[0906 14-12-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03515, current rewards: 190.17558, mean: 0.10805
[32m[0906 14-12-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03515, current rewards: 195.56098, mean: 0.10804
[32m[0906 14-12-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03515, current rewards: 201.00260, mean: 0.10807
[32m[0906 14-12-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03515, current rewards: 206.44185, mean: 0.10808
[32m[0906 14-12-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03513, current rewards: 211.88174, mean: 0.10810
[32m[0906 14-12-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03510, current rewards: 215.97963, mean: 0.10745
[32m[0906 14-12-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03509, current rewards: 221.49265, mean: 0.10752
[32m[0906 14-12-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03507, current rewards: 227.00441, mean: 0.10759
[32m[0906 14-12-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03505, current rewards: 232.51806, mean: 0.10765
[32m[0906 14-12-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03503, current rewards: 237.98784, mean: 0.10769
[32m[0906 14-12-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03501, current rewards: 243.49216, mean: 0.10774
[32m[0906 14-13-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03499, current rewards: 248.99623, mean: 0.10779
[32m[0906 14-13-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03500, current rewards: 254.49961, mean: 0.10784
[32m[0906 14-13-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03500, current rewards: 260.00321, mean: 0.10789
[32m[0906 14-13-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03501, current rewards: 265.50608, mean: 0.10793
[32m[0906 14-13-07 @Agent.py:117][0m Average action selection time: 0.0350
[32m[0906 14-13-07 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-13-07 @MBExp.py:227][0m Rewards obtained: [269.9090523310485], Lows: [1], Highs: [3], Total time: 1600.203753
[32m[0906 14-13-46 @MBExp.py:144][0m ####################################################################
[32m[0906 14-13-46 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 14-13-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03453, current rewards: 1.02442, mean: 0.10244
[32m[0906 14-13-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03505, current rewards: 6.40676, mean: 0.10678
[32m[0906 14-13-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03504, current rewards: 11.70431, mean: 0.10640
[32m[0906 14-13-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03509, current rewards: 17.07302, mean: 0.10671
[32m[0906 14-13-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03507, current rewards: 22.43817, mean: 0.10685
[32m[0906 14-13-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03506, current rewards: 27.80030, mean: 0.10692
[32m[0906 14-13-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03511, current rewards: 31.02324, mean: 0.10007
[32m[0906 14-13-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03526, current rewards: 36.48782, mean: 0.10136
[32m[0906 14-14-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03537, current rewards: 41.94746, mean: 0.10231
[32m[0906 14-14-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03545, current rewards: 47.41256, mean: 0.10307
[32m[0906 14-14-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03553, current rewards: 52.87461, mean: 0.10368
[32m[0906 14-14-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03558, current rewards: 58.37889, mean: 0.10425
[32m[0906 14-14-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03564, current rewards: 63.84786, mean: 0.10467
[32m[0906 14-14-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03562, current rewards: 69.31005, mean: 0.10502
[32m[0906 14-14-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03558, current rewards: 74.77298, mean: 0.10531
[32m[0906 14-14-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03555, current rewards: 80.23838, mean: 0.10558
[32m[0906 14-14-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03553, current rewards: 85.70494, mean: 0.10581
[32m[0906 14-14-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03552, current rewards: 91.16729, mean: 0.10601
[32m[0906 14-14-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03548, current rewards: 96.63305, mean: 0.10619
[32m[0906 14-14-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03547, current rewards: 102.02023, mean: 0.10627
[32m[0906 14-14-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03546, current rewards: 107.42298, mean: 0.10636
[32m[0906 14-14-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03544, current rewards: 112.88436, mean: 0.10649
[32m[0906 14-14-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03544, current rewards: 118.34447, mean: 0.10662
[32m[0906 14-14-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03543, current rewards: 123.80345, mean: 0.10673
[32m[0906 14-14-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03539, current rewards: 129.26457, mean: 0.10683
[32m[0906 14-14-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03534, current rewards: 134.72518, mean: 0.10692
[32m[0906 14-14-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03530, current rewards: 140.18693, mean: 0.10701
[32m[0906 14-14-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03525, current rewards: 145.53040, mean: 0.10701
[32m[0906 14-14-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03523, current rewards: 150.89256, mean: 0.10702
[32m[0906 14-14-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03520, current rewards: 156.25174, mean: 0.10702
[32m[0906 14-14-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03517, current rewards: 161.61106, mean: 0.10703
[32m[0906 14-14-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03514, current rewards: 166.96826, mean: 0.10703
[32m[0906 14-14-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03511, current rewards: 172.33067, mean: 0.10704
[32m[0906 14-14-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03509, current rewards: 177.69135, mean: 0.10704
[32m[0906 14-14-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03507, current rewards: 183.05667, mean: 0.10705
[32m[0906 14-14-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03505, current rewards: 188.38552, mean: 0.10704
[32m[0906 14-14-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03506, current rewards: 193.73631, mean: 0.10704
[32m[0906 14-14-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03506, current rewards: 199.09195, mean: 0.10704
[32m[0906 14-14-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03507, current rewards: 202.45664, mean: 0.10600
[32m[0906 14-14-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03505, current rewards: 207.91375, mean: 0.10608
[32m[0906 14-14-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03503, current rewards: 213.37621, mean: 0.10616
[32m[0906 14-14-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03502, current rewards: 218.83041, mean: 0.10623
[32m[0906 14-15-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03501, current rewards: 224.29516, mean: 0.10630
[32m[0906 14-15-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03499, current rewards: 229.83511, mean: 0.10641
[32m[0906 14-15-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03497, current rewards: 235.29689, mean: 0.10647
[32m[0906 14-15-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03496, current rewards: 240.76056, mean: 0.10653
[32m[0906 14-15-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03495, current rewards: 246.22362, mean: 0.10659
[32m[0906 14-15-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03493, current rewards: 251.68209, mean: 0.10664
[32m[0906 14-15-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03494, current rewards: 257.14678, mean: 0.10670
[32m[0906 14-15-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03494, current rewards: 262.60912, mean: 0.10675
[32m[0906 14-15-14 @Agent.py:117][0m Average action selection time: 0.0349
[32m[0906 14-15-14 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-15-14 @MBExp.py:227][0m Rewards obtained: [266.9787333258007], Lows: [1], Highs: [2], Total time: 1688.206762
[32m[0906 14-15-56 @MBExp.py:144][0m ####################################################################
[32m[0906 14-15-56 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 14-15-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03558, current rewards: -1.14161, mean: -0.11416
[32m[0906 14-15-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03531, current rewards: 4.42092, mean: 0.07368
[32m[0906 14-16-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03514, current rewards: 10.32095, mean: 0.09383
[32m[0906 14-16-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03507, current rewards: 16.01426, mean: 0.10009
[32m[0906 14-16-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03507, current rewards: 21.70631, mean: 0.10336
[32m[0906 14-16-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03509, current rewards: 27.39917, mean: 0.10538
[32m[0906 14-16-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03511, current rewards: 33.08619, mean: 0.10673
[32m[0906 14-16-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03511, current rewards: 38.77914, mean: 0.10772
[32m[0906 14-16-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03524, current rewards: 42.57444, mean: 0.10384
[32m[0906 14-16-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03529, current rewards: 48.28000, mean: 0.10496
[32m[0906 14-16-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03537, current rewards: 53.79688, mean: 0.10548
[32m[0906 14-16-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03542, current rewards: 59.45498, mean: 0.10617
[32m[0906 14-16-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03540, current rewards: 65.14988, mean: 0.10680
[32m[0906 14-16-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03539, current rewards: 70.85134, mean: 0.10735
[32m[0906 14-16-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03537, current rewards: 76.55221, mean: 0.10782
[32m[0906 14-16-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03536, current rewards: 80.35385, mean: 0.10573
[32m[0906 14-16-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03534, current rewards: 86.19025, mean: 0.10641
[32m[0906 14-16-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03532, current rewards: 92.02739, mean: 0.10701
[32m[0906 14-16-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03533, current rewards: 97.86001, mean: 0.10754
[32m[0906 14-16-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03533, current rewards: 103.66881, mean: 0.10799
[32m[0906 14-16-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03534, current rewards: 109.49624, mean: 0.10841
[32m[0906 14-16-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03533, current rewards: 115.32753, mean: 0.10880
[32m[0906 14-16-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03535, current rewards: 121.15349, mean: 0.10915
[32m[0906 14-16-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03535, current rewards: 126.98313, mean: 0.10947
[32m[0906 14-16-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03532, current rewards: 132.81581, mean: 0.10977
[32m[0906 14-16-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03528, current rewards: 138.64231, mean: 0.11003
[32m[0906 14-16-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03525, current rewards: 144.46579, mean: 0.11028
[32m[0906 14-16-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03521, current rewards: 150.43401, mean: 0.11061
[32m[0906 14-16-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03518, current rewards: 156.27701, mean: 0.11083
[32m[0906 14-16-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03515, current rewards: 162.11593, mean: 0.11104
[32m[0906 14-16-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03513, current rewards: 166.37166, mean: 0.11018
[32m[0906 14-16-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03510, current rewards: 172.16440, mean: 0.11036
[32m[0906 14-16-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03508, current rewards: 177.95892, mean: 0.11053
[32m[0906 14-16-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03506, current rewards: 183.75467, mean: 0.11070
[32m[0906 14-16-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03504, current rewards: 189.54860, mean: 0.11085
[32m[0906 14-16-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03501, current rewards: 195.34302, mean: 0.11099
[32m[0906 14-16-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03502, current rewards: 201.13296, mean: 0.11112
[32m[0906 14-17-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03502, current rewards: 206.92675, mean: 0.11125
[32m[0906 14-17-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03502, current rewards: 212.72119, mean: 0.11137
[32m[0906 14-17-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03501, current rewards: 216.27168, mean: 0.11034
[32m[0906 14-17-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03499, current rewards: 221.58075, mean: 0.11024
[32m[0906 14-17-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03497, current rewards: 226.88504, mean: 0.11014
[32m[0906 14-17-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03495, current rewards: 232.20132, mean: 0.11005
[32m[0906 14-17-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03494, current rewards: 237.64071, mean: 0.11002
[32m[0906 14-17-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03493, current rewards: 242.95798, mean: 0.10994
[32m[0906 14-17-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03492, current rewards: 248.27080, mean: 0.10985
[32m[0906 14-17-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03491, current rewards: 254.29130, mean: 0.11008
[32m[0906 14-17-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03490, current rewards: 259.93369, mean: 0.11014
[32m[0906 14-17-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03488, current rewards: 265.57025, mean: 0.11020
[32m[0906 14-17-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03488, current rewards: 271.21833, mean: 0.11025
[32m[0906 14-17-23 @Agent.py:117][0m Average action selection time: 0.0349
[32m[0906 14-17-23 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-17-23 @MBExp.py:227][0m Rewards obtained: [275.72947019147097], Lows: [3], Highs: [4], Total time: 1776.055
[32m[0906 14-18-07 @MBExp.py:144][0m ####################################################################
[32m[0906 14-18-07 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 14-18-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03473, current rewards: 0.97062, mean: 0.09706
[32m[0906 14-18-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03521, current rewards: 6.54428, mean: 0.10907
[32m[0906 14-18-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03519, current rewards: 12.13391, mean: 0.11031
[32m[0906 14-18-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03521, current rewards: 17.72182, mean: 0.11076
[32m[0906 14-18-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03520, current rewards: 23.31184, mean: 0.11101
[32m[0906 14-18-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03519, current rewards: 28.89998, mean: 0.11115
[32m[0906 14-18-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03517, current rewards: 34.49168, mean: 0.11126
[32m[0906 14-18-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03516, current rewards: 38.99633, mean: 0.10832
[32m[0906 14-18-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03515, current rewards: 44.60570, mean: 0.10879
[32m[0906 14-18-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03526, current rewards: 50.29669, mean: 0.10934
[32m[0906 14-18-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03532, current rewards: 55.92547, mean: 0.10966
[32m[0906 14-18-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03531, current rewards: 61.55376, mean: 0.10992
[32m[0906 14-18-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03529, current rewards: 67.18051, mean: 0.11013
[32m[0906 14-18-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03526, current rewards: 72.80592, mean: 0.11031
[32m[0906 14-18-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03524, current rewards: 78.43022, mean: 0.11047
[32m[0906 14-18-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03522, current rewards: 84.05258, mean: 0.11060
[32m[0906 14-18-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03524, current rewards: 88.63189, mean: 0.10942
[32m[0906 14-18-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03524, current rewards: 94.11515, mean: 0.10944
[32m[0906 14-18-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03525, current rewards: 99.50579, mean: 0.10935
[32m[0906 14-18-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03524, current rewards: 104.97658, mean: 0.10935
[32m[0906 14-18-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03524, current rewards: 110.45205, mean: 0.10936
[32m[0906 14-18-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03523, current rewards: 115.92007, mean: 0.10936
[32m[0906 14-18-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03523, current rewards: 121.39409, mean: 0.10936
[32m[0906 14-18-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03524, current rewards: 126.86251, mean: 0.10936
[32m[0906 14-18-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03522, current rewards: 132.33585, mean: 0.10937
[32m[0906 14-18-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03518, current rewards: 137.80084, mean: 0.10937
[32m[0906 14-18-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03514, current rewards: 143.50546, mean: 0.10955
[32m[0906 14-18-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03511, current rewards: 149.05399, mean: 0.10960
[32m[0906 14-18-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03508, current rewards: 154.60266, mean: 0.10965
[32m[0906 14-18-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03506, current rewards: 160.14411, mean: 0.10969
[32m[0906 14-19-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03503, current rewards: 163.66438, mean: 0.10839
[32m[0906 14-19-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03501, current rewards: 169.27640, mean: 0.10851
[32m[0906 14-19-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03498, current rewards: 174.88834, mean: 0.10863
[32m[0906 14-19-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03496, current rewards: 180.50792, mean: 0.10874
[32m[0906 14-19-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03495, current rewards: 185.66356, mean: 0.10858
[32m[0906 14-19-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03493, current rewards: 191.05498, mean: 0.10855
[32m[0906 14-19-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03494, current rewards: 196.44571, mean: 0.10853
[32m[0906 14-19-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03495, current rewards: 201.84178, mean: 0.10852
[32m[0906 14-19-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03496, current rewards: 205.27743, mean: 0.10748
[32m[0906 14-19-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03495, current rewards: 210.91912, mean: 0.10761
[32m[0906 14-19-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03494, current rewards: 216.55819, mean: 0.10774
[32m[0906 14-19-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03492, current rewards: 222.19891, mean: 0.10786
[32m[0906 14-19-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03490, current rewards: 227.83902, mean: 0.10798
[32m[0906 14-19-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03489, current rewards: 233.48109, mean: 0.10809
[32m[0906 14-19-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03488, current rewards: 239.12802, mean: 0.10820
[32m[0906 14-19-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03487, current rewards: 244.77220, mean: 0.10831
[32m[0906 14-19-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03485, current rewards: 250.41706, mean: 0.10841
[32m[0906 14-19-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03484, current rewards: 256.05920, mean: 0.10850
[32m[0906 14-19-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03483, current rewards: 261.70189, mean: 0.10859
[32m[0906 14-19-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03482, current rewards: 263.14116, mean: 0.10697
[32m[0906 14-19-34 @Agent.py:117][0m Average action selection time: 0.0348
[32m[0906 14-19-34 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-19-34 @MBExp.py:227][0m Rewards obtained: [267.57941220911846], Lows: [4], Highs: [3], Total time: 1863.724295
[32m[0906 14-20-20 @MBExp.py:144][0m ####################################################################
[32m[0906 14-20-20 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 14-20-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03578, current rewards: 0.06892, mean: 0.00689
[32m[0906 14-20-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03529, current rewards: 5.69476, mean: 0.09491
[32m[0906 14-20-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03528, current rewards: 11.32366, mean: 0.10294
[32m[0906 14-20-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03531, current rewards: 16.94350, mean: 0.10590
[32m[0906 14-20-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03526, current rewards: 22.56714, mean: 0.10746
[32m[0906 14-20-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03525, current rewards: 28.19132, mean: 0.10843
[32m[0906 14-20-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03526, current rewards: 33.81541, mean: 0.10908
[32m[0906 14-20-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03527, current rewards: 39.44040, mean: 0.10956
[32m[0906 14-20-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03525, current rewards: 45.04005, mean: 0.10985
[32m[0906 14-20-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03522, current rewards: 50.64751, mean: 0.11010
[32m[0906 14-20-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03519, current rewards: 56.26937, mean: 0.11033
[32m[0906 14-20-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03520, current rewards: 60.00259, mean: 0.10715
[32m[0906 14-20-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03521, current rewards: 65.86084, mean: 0.10797
[32m[0906 14-20-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03522, current rewards: 71.72041, mean: 0.10867
[32m[0906 14-20-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03522, current rewards: 77.57579, mean: 0.10926
[32m[0906 14-20-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03521, current rewards: 83.42817, mean: 0.10977
[32m[0906 14-20-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03520, current rewards: 89.27841, mean: 0.11022
[32m[0906 14-20-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03521, current rewards: 95.08428, mean: 0.11056
[32m[0906 14-20-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03521, current rewards: 100.99752, mean: 0.11099
[32m[0906 14-20-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03521, current rewards: 106.91258, mean: 0.11137
[32m[0906 14-20-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03521, current rewards: 112.82838, mean: 0.11171
[32m[0906 14-20-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03521, current rewards: 117.59294, mean: 0.11094
[32m[0906 14-20-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03521, current rewards: 123.27269, mean: 0.11106
[32m[0906 14-21-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03521, current rewards: 128.94986, mean: 0.11116
[32m[0906 14-21-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03519, current rewards: 134.62757, mean: 0.11126
[32m[0906 14-21-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03515, current rewards: 140.31332, mean: 0.11136
[32m[0906 14-21-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03512, current rewards: 145.99292, mean: 0.11144
[32m[0906 14-21-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03509, current rewards: 151.67127, mean: 0.11152
[32m[0906 14-21-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03506, current rewards: 157.34705, mean: 0.11159
[32m[0906 14-21-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03503, current rewards: 161.74652, mean: 0.11079
[32m[0906 14-21-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03501, current rewards: 167.02417, mean: 0.11061
[32m[0906 14-21-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03500, current rewards: 172.31264, mean: 0.11046
[32m[0906 14-21-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03497, current rewards: 177.59509, mean: 0.11031
[32m[0906 14-21-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03495, current rewards: 182.88290, mean: 0.11017
[32m[0906 14-21-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03493, current rewards: 188.16876, mean: 0.11004
[32m[0906 14-21-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03492, current rewards: 193.45657, mean: 0.10992
[32m[0906 14-21-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03493, current rewards: 198.74795, mean: 0.10981
[32m[0906 14-21-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03494, current rewards: 204.03209, mean: 0.10969
[32m[0906 14-21-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03495, current rewards: 209.31840, mean: 0.10959
[32m[0906 14-21-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03494, current rewards: 214.59784, mean: 0.10949
[32m[0906 14-21-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03492, current rewards: 219.88145, mean: 0.10939
[32m[0906 14-21-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03491, current rewards: 225.37236, mean: 0.10940
[32m[0906 14-21-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03490, current rewards: 230.76997, mean: 0.10937
[32m[0906 14-21-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03489, current rewards: 236.50366, mean: 0.10949
[32m[0906 14-21-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03488, current rewards: 242.22269, mean: 0.10960
[32m[0906 14-21-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03486, current rewards: 247.94014, mean: 0.10971
[32m[0906 14-21-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03485, current rewards: 253.66118, mean: 0.10981
[32m[0906 14-21-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03484, current rewards: 259.38062, mean: 0.10991
[32m[0906 14-21-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03484, current rewards: 260.90567, mean: 0.10826
[32m[0906 14-21-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03483, current rewards: 266.25090, mean: 0.10823
[32m[0906 14-21-47 @Agent.py:117][0m Average action selection time: 0.0348
[32m[0906 14-21-47 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-21-47 @MBExp.py:227][0m Rewards obtained: [270.60376945634897], Lows: [3], Highs: [3], Total time: 1951.40732
[32m[0906 14-22-35 @MBExp.py:144][0m ####################################################################
[32m[0906 14-22-35 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 14-22-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03445, current rewards: 1.09587, mean: 0.10959
[32m[0906 14-22-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03496, current rewards: 7.94208, mean: 0.13237
[32m[0906 14-22-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03510, current rewards: 15.03864, mean: 0.13671
[32m[0906 14-22-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03515, current rewards: 22.13519, mean: 0.13834
[32m[0906 14-22-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03517, current rewards: 29.23174, mean: 0.13920
[32m[0906 14-22-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03515, current rewards: 36.32829, mean: 0.13972
[32m[0906 14-22-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03516, current rewards: 43.42484, mean: 0.14008
[32m[0906 14-22-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03514, current rewards: 50.52139, mean: 0.14034
[32m[0906 14-22-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03507, current rewards: 57.97540, mean: 0.14140
[32m[0906 14-22-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03497, current rewards: 63.32428, mean: 0.13766
[32m[0906 14-22-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03491, current rewards: 13.32428, mean: 0.02613
[32m[0906 14-22-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03486, current rewards: -36.67572, mean: -0.06549
[32m[0906 14-22-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03489, current rewards: -86.67572, mean: -0.14209
[32m[0906 14-22-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03492, current rewards: -136.67572, mean: -0.20708
[32m[0906 14-23-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03494, current rewards: -186.67572, mean: -0.26292
[32m[0906 14-23-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03494, current rewards: -236.67572, mean: -0.31142
[32m[0906 14-23-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03496, current rewards: -286.67572, mean: -0.35392
[32m[0906 14-23-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03497, current rewards: -336.67572, mean: -0.39148
[32m[0906 14-23-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03498, current rewards: -386.67572, mean: -0.42492
[32m[0906 14-23-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03499, current rewards: -436.67572, mean: -0.45487
[32m[0906 14-23-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03500, current rewards: -486.67572, mean: -0.48186
[32m[0906 14-23-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03501, current rewards: -536.67572, mean: -0.50630
[32m[0906 14-23-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03502, current rewards: -586.67572, mean: -0.52854
[32m[0906 14-23-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03503, current rewards: -636.67572, mean: -0.54886
[32m[0906 14-23-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03502, current rewards: -686.67572, mean: -0.56750
[32m[0906 14-23-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03499, current rewards: -736.67572, mean: -0.58466
[32m[0906 14-23-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03496, current rewards: -786.67572, mean: -0.60052
[32m[0906 14-23-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03493, current rewards: -836.67572, mean: -0.61520
[32m[0906 14-23-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03491, current rewards: -886.67572, mean: -0.62885
[32m[0906 14-23-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03488, current rewards: -936.67572, mean: -0.64156
[32m[0906 14-23-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03487, current rewards: -986.67572, mean: -0.65343
[32m[0906 14-23-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03485, current rewards: -1036.67572, mean: -0.66454
[32m[0906 14-23-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03483, current rewards: -1086.67572, mean: -0.67495
[32m[0906 14-23-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03482, current rewards: -1136.67572, mean: -0.68474
[32m[0906 14-23-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03480, current rewards: -1186.67572, mean: -0.69396
[32m[0906 14-23-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03479, current rewards: -1236.67572, mean: -0.70266
[32m[0906 14-23-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03481, current rewards: -1286.67572, mean: -0.71087
[32m[0906 14-23-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03481, current rewards: -1336.67572, mean: -0.71864
[32m[0906 14-23-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03483, current rewards: -1386.67572, mean: -0.72601
[32m[0906 14-23-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03484, current rewards: -1436.67572, mean: -0.73300
[32m[0906 14-23-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03482, current rewards: -1486.67572, mean: -0.73964
[32m[0906 14-23-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03481, current rewards: -1536.67572, mean: -0.74596
[32m[0906 14-23-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03481, current rewards: -1586.67572, mean: -0.75198
[32m[0906 14-23-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03479, current rewards: -1636.67572, mean: -0.75772
[32m[0906 14-23-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03479, current rewards: -1686.67572, mean: -0.76320
[32m[0906 14-23-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03478, current rewards: -1736.67572, mean: -0.76844
[32m[0906 14-23-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03477, current rewards: -1786.67572, mean: -0.77345
[32m[0906 14-23-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03476, current rewards: -1836.67572, mean: -0.77825
[32m[0906 14-23-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03476, current rewards: -1886.67572, mean: -0.78285
[32m[0906 14-24-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03475, current rewards: -1936.67572, mean: -0.78727
[32m[0906 14-24-02 @Agent.py:117][0m Average action selection time: 0.0347
[32m[0906 14-24-02 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-24-02 @MBExp.py:227][0m Rewards obtained: [-1976.6757230691248], Lows: [0], Highs: [2042], Total time: 2038.916851
[32m[0906 14-24-51 @MBExp.py:144][0m ####################################################################
[32m[0906 14-24-51 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 14-24-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03462, current rewards: 0.16053, mean: 0.01605
[32m[0906 14-24-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03519, current rewards: 5.83047, mean: 0.09717
[32m[0906 14-24-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03520, current rewards: 11.39362, mean: 0.10358
[32m[0906 14-24-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03519, current rewards: 16.95677, mean: 0.10598
[32m[0906 14-24-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03522, current rewards: 22.51992, mean: 0.10724
[32m[0906 14-25-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03520, current rewards: -0.80977, mean: -0.00311
[32m[0906 14-25-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03524, current rewards: -50.80977, mean: -0.16390
[32m[0906 14-25-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03513, current rewards: -100.80977, mean: -0.28003
[32m[0906 14-25-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03503, current rewards: -150.80977, mean: -0.36783
[32m[0906 14-25-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03495, current rewards: -200.80977, mean: -0.43654
[32m[0906 14-25-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03490, current rewards: -250.80977, mean: -0.49178
[32m[0906 14-25-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03485, current rewards: -300.80977, mean: -0.53716
[32m[0906 14-25-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03481, current rewards: -350.80977, mean: -0.57510
[32m[0906 14-25-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03485, current rewards: -400.80977, mean: -0.60729
[32m[0906 14-25-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03488, current rewards: -450.80977, mean: -0.63494
[32m[0906 14-25-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03491, current rewards: -500.80977, mean: -0.65896
[32m[0906 14-25-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03492, current rewards: -550.80977, mean: -0.68001
[32m[0906 14-25-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03493, current rewards: -600.80977, mean: -0.69862
[32m[0906 14-25-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03493, current rewards: -650.80977, mean: -0.71518
[32m[0906 14-25-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03494, current rewards: -700.80977, mean: -0.73001
[32m[0906 14-25-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03495, current rewards: -750.80977, mean: -0.74338
[32m[0906 14-25-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03496, current rewards: -800.80977, mean: -0.75548
[32m[0906 14-25-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03498, current rewards: -850.80977, mean: -0.76650
[32m[0906 14-25-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03499, current rewards: -900.80977, mean: -0.77656
[32m[0906 14-25-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03499, current rewards: -950.80977, mean: -0.78579
[32m[0906 14-25-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03497, current rewards: -1000.80977, mean: -0.79429
[32m[0906 14-25-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03495, current rewards: -1050.80977, mean: -0.80214
[32m[0906 14-25-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03493, current rewards: -1100.80977, mean: -0.80942
[32m[0906 14-25-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03491, current rewards: -1150.80977, mean: -0.81618
[32m[0906 14-25-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03489, current rewards: -1200.80977, mean: -0.82247
[32m[0906 14-25-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03487, current rewards: -1250.80977, mean: -0.82835
[32m[0906 14-25-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03485, current rewards: -1300.80977, mean: -0.83385
[32m[0906 14-25-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03484, current rewards: -1350.80977, mean: -0.83901
[32m[0906 14-25-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03483, current rewards: -1400.80977, mean: -0.84386
[32m[0906 14-25-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03481, current rewards: -1450.80977, mean: -0.84843
[32m[0906 14-25-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03481, current rewards: -1500.80977, mean: -0.85273
[32m[0906 14-25-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03483, current rewards: -1550.80977, mean: -0.85680
[32m[0906 14-25-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03485, current rewards: -1600.80977, mean: -0.86065
[32m[0906 14-25-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03486, current rewards: -1650.80977, mean: -0.86430
[32m[0906 14-26-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03487, current rewards: -1700.80977, mean: -0.86776
[32m[0906 14-26-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03486, current rewards: -1750.80977, mean: -0.87105
[32m[0906 14-26-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03485, current rewards: -1800.80977, mean: -0.87418
[32m[0906 14-26-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03484, current rewards: -1850.80977, mean: -0.87716
[32m[0906 14-26-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03483, current rewards: -1900.80977, mean: -0.88000
[32m[0906 14-26-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03482, current rewards: -1950.80977, mean: -0.88272
[32m[0906 14-26-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03482, current rewards: -2000.80977, mean: -0.88531
[32m[0906 14-26-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03481, current rewards: -2050.80977, mean: -0.88780
[32m[0906 14-26-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03480, current rewards: -2100.80977, mean: -0.89017
[32m[0906 14-26-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03478, current rewards: -2150.80977, mean: -0.89245
[32m[0906 14-26-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03478, current rewards: -2200.80977, mean: -0.89464
[32m[0906 14-26-19 @Agent.py:117][0m Average action selection time: 0.0348
[32m[0906 14-26-19 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-26-19 @MBExp.py:227][0m Rewards obtained: [-2240.809773245016], Lows: [0], Highs: [2267], Total time: 2126.472408
[32m[0906 14-27-10 @MBExp.py:144][0m ####################################################################
[32m[0906 14-27-10 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 14-27-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03499, current rewards: 0.15925, mean: 0.01592
[32m[0906 14-27-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03518, current rewards: 6.85187, mean: 0.11420
[32m[0906 14-27-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03509, current rewards: 13.94842, mean: 0.12680
[32m[0906 14-27-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03515, current rewards: 21.04497, mean: 0.13153
[32m[0906 14-27-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03514, current rewards: 28.14152, mean: 0.13401
[32m[0906 14-27-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03510, current rewards: 10.11559, mean: 0.03891
[32m[0906 14-27-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03497, current rewards: -39.88441, mean: -0.12866
[32m[0906 14-27-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03490, current rewards: -89.88441, mean: -0.24968
[32m[0906 14-27-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03482, current rewards: -139.88441, mean: -0.34118
[32m[0906 14-27-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03477, current rewards: -189.88441, mean: -0.41279
[32m[0906 14-27-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03473, current rewards: -239.88441, mean: -0.47036
[32m[0906 14-27-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03469, current rewards: -289.88441, mean: -0.51765
[32m[0906 14-27-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03467, current rewards: -339.88441, mean: -0.55719
[32m[0906 14-27-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03463, current rewards: -389.88441, mean: -0.59073
[32m[0906 14-27-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03467, current rewards: -439.88441, mean: -0.61956
[32m[0906 14-27-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03470, current rewards: -489.88441, mean: -0.64458
[32m[0906 14-27-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03473, current rewards: -539.88441, mean: -0.66652
[32m[0906 14-27-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03476, current rewards: -589.88441, mean: -0.68591
[32m[0906 14-27-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03480, current rewards: -639.88441, mean: -0.70317
[32m[0906 14-27-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03483, current rewards: -689.88441, mean: -0.71863
[32m[0906 14-27-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03484, current rewards: -739.88441, mean: -0.73256
[32m[0906 14-27-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03486, current rewards: -789.88441, mean: -0.74517
[32m[0906 14-27-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03487, current rewards: -839.88441, mean: -0.75665
[32m[0906 14-27-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03488, current rewards: -889.88441, mean: -0.76714
[32m[0906 14-27-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03489, current rewards: -939.88441, mean: -0.77676
[32m[0906 14-27-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03486, current rewards: -989.88441, mean: -0.78562
[32m[0906 14-27-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03486, current rewards: -1039.88441, mean: -0.79380
[32m[0906 14-27-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03484, current rewards: -1089.88441, mean: -0.80139
[32m[0906 14-28-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03481, current rewards: -1139.88441, mean: -0.80843
[32m[0906 14-28-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03480, current rewards: -1189.88441, mean: -0.81499
[32m[0906 14-28-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03478, current rewards: -1239.88441, mean: -0.82112
[32m[0906 14-28-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03477, current rewards: -1289.88441, mean: -0.82685
[32m[0906 14-28-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03475, current rewards: -1339.88441, mean: -0.83223
[32m[0906 14-28-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03474, current rewards: -1389.88441, mean: -0.83728
[32m[0906 14-28-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03473, current rewards: -1439.88441, mean: -0.84204
[32m[0906 14-28-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03473, current rewards: -1489.88441, mean: -0.84653
[32m[0906 14-28-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03474, current rewards: -1539.88441, mean: -0.85076
[32m[0906 14-28-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03476, current rewards: -1589.88441, mean: -0.85478
[32m[0906 14-28-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03477, current rewards: -1639.88441, mean: -0.85858
[32m[0906 14-28-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03478, current rewards: -1689.88441, mean: -0.86219
[32m[0906 14-28-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03477, current rewards: -1739.88441, mean: -0.86561
[32m[0906 14-28-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03476, current rewards: -1789.88441, mean: -0.86888
[32m[0906 14-28-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03475, current rewards: -1839.88441, mean: -0.87198
[32m[0906 14-28-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03474, current rewards: -1889.88441, mean: -0.87495
[32m[0906 14-28-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03473, current rewards: -1939.88441, mean: -0.87778
[32m[0906 14-28-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03472, current rewards: -1989.88441, mean: -0.88048
[32m[0906 14-28-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03471, current rewards: -2039.88441, mean: -0.88307
[32m[0906 14-28-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03470, current rewards: -2089.88441, mean: -0.88554
[32m[0906 14-28-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03469, current rewards: -2139.88441, mean: -0.88792
[32m[0906 14-28-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03468, current rewards: -2189.88441, mean: -0.89020
[32m[0906 14-28-38 @Agent.py:117][0m Average action selection time: 0.0347
[32m[0906 14-28-38 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-28-38 @MBExp.py:227][0m Rewards obtained: [-2229.884409312464], Lows: [0], Highs: [2263], Total time: 2213.80861
[32m[0906 14-29-31 @MBExp.py:144][0m ####################################################################
[32m[0906 14-29-31 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 14-29-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03476, current rewards: -2.93406, mean: -0.29341
[32m[0906 14-29-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03504, current rewards: 2.45665, mean: 0.04094
[32m[0906 14-29-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03510, current rewards: 7.71761, mean: 0.07016
[32m[0906 14-29-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03508, current rewards: 12.98773, mean: 0.08117
[32m[0906 14-29-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03494, current rewards: 18.25173, mean: 0.08691
[32m[0906 14-29-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03486, current rewards: 23.51784, mean: 0.09045
[32m[0906 14-29-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03480, current rewards: 26.67705, mean: 0.08605
[32m[0906 14-29-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03476, current rewards: 32.27892, mean: 0.08966
[32m[0906 14-29-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03472, current rewards: 37.68970, mean: 0.09193
[32m[0906 14-29-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03468, current rewards: 43.23429, mean: 0.09399
[32m[0906 14-29-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03465, current rewards: 48.78168, mean: 0.09565
[32m[0906 14-29-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03463, current rewards: 54.32905, mean: 0.09702
[32m[0906 14-29-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03462, current rewards: 59.87730, mean: 0.09816
[32m[0906 14-29-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03460, current rewards: 65.42266, mean: 0.09913
[32m[0906 14-29-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03458, current rewards: 70.96476, mean: 0.09995
[32m[0906 14-29-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03459, current rewards: 76.51743, mean: 0.10068
[32m[0906 14-29-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03463, current rewards: 82.15043, mean: 0.10142
[32m[0906 14-30-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03466, current rewards: 87.78742, mean: 0.10208
[32m[0906 14-30-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03469, current rewards: 93.33378, mean: 0.10256
[32m[0906 14-30-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03473, current rewards: 96.94520, mean: 0.10098
[32m[0906 14-30-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03477, current rewards: 102.45447, mean: 0.10144
[32m[0906 14-30-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03478, current rewards: 107.95788, mean: 0.10185
[32m[0906 14-30-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03479, current rewards: 113.46690, mean: 0.10222
[32m[0906 14-30-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03482, current rewards: 118.97324, mean: 0.10256
[32m[0906 14-30-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03483, current rewards: 124.47487, mean: 0.10287
[32m[0906 14-30-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03481, current rewards: 129.75822, mean: 0.10298
[32m[0906 14-30-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03479, current rewards: 132.44411, mean: 0.10110
[32m[0906 14-30-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03477, current rewards: 137.85022, mean: 0.10136
[32m[0906 14-30-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03476, current rewards: 143.25992, mean: 0.10160
[32m[0906 14-30-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03474, current rewards: 148.67084, mean: 0.10183
[32m[0906 14-30-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03472, current rewards: 154.08618, mean: 0.10204
[32m[0906 14-30-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03470, current rewards: 159.49170, mean: 0.10224
[32m[0906 14-30-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03468, current rewards: 164.90427, mean: 0.10243
[32m[0906 14-30-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03467, current rewards: 170.40807, mean: 0.10266
[32m[0906 14-30-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03466, current rewards: 175.89700, mean: 0.10286
[32m[0906 14-30-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03468, current rewards: 181.29278, mean: 0.10301
[32m[0906 14-30-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03469, current rewards: 186.68386, mean: 0.10314
[32m[0906 14-30-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03471, current rewards: 192.07296, mean: 0.10327
[32m[0906 14-30-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03472, current rewards: 197.46281, mean: 0.10338
[32m[0906 14-30-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03473, current rewards: 202.85896, mean: 0.10350
[32m[0906 14-30-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03474, current rewards: 204.24416, mean: 0.10161
[32m[0906 14-30-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03472, current rewards: 209.73453, mean: 0.10181
[32m[0906 14-30-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03471, current rewards: 214.99540, mean: 0.10189
[32m[0906 14-30-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03470, current rewards: 220.47464, mean: 0.10207
[32m[0906 14-30-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03470, current rewards: 225.95341, mean: 0.10224
[32m[0906 14-30-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03469, current rewards: 231.42810, mean: 0.10240
[32m[0906 14-30-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03468, current rewards: 236.90447, mean: 0.10256
[32m[0906 14-30-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03467, current rewards: 241.23872, mean: 0.10222
[32m[0906 14-30-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03467, current rewards: 246.61284, mean: 0.10233
[32m[0906 14-30-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03466, current rewards: 251.99405, mean: 0.10244
[32m[0906 14-30-58 @Agent.py:117][0m Average action selection time: 0.0347
[32m[0906 14-30-58 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-30-59 @MBExp.py:227][0m Rewards obtained: [256.31752589283855], Lows: [6], Highs: [4], Total time: 2301.097973
[32m[0906 14-31-54 @MBExp.py:144][0m ####################################################################
[32m[0906 14-31-54 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 14-31-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03494, current rewards: 1.52455, mean: 0.15246
[32m[0906 14-31-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03521, current rewards: 5.14039, mean: 0.08567
[32m[0906 14-31-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03524, current rewards: 8.72112, mean: 0.07928
[32m[0906 14-32-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03486, current rewards: 12.30186, mean: 0.07689
[32m[0906 14-32-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03474, current rewards: 15.88260, mean: 0.07563
[32m[0906 14-32-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03465, current rewards: 19.46334, mean: 0.07486
[32m[0906 14-32-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03458, current rewards: 19.82923, mean: 0.06397
[32m[0906 14-32-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03456, current rewards: -30.17077, mean: -0.08381
[32m[0906 14-32-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03452, current rewards: -80.17077, mean: -0.19554
[32m[0906 14-32-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03450, current rewards: -130.17077, mean: -0.28298
[32m[0906 14-32-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03448, current rewards: -180.17077, mean: -0.35328
[32m[0906 14-32-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03445, current rewards: -230.17077, mean: -0.41102
[32m[0906 14-32-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03442, current rewards: -280.17077, mean: -0.45930
[32m[0906 14-32-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03442, current rewards: -330.17077, mean: -0.50026
[32m[0906 14-32-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03441, current rewards: -380.17077, mean: -0.53545
[32m[0906 14-32-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03440, current rewards: -430.17077, mean: -0.56601
[32m[0906 14-32-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03439, current rewards: -480.17077, mean: -0.59280
[32m[0906 14-32-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03445, current rewards: -530.17077, mean: -0.61648
[32m[0906 14-32-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03449, current rewards: -580.17077, mean: -0.63755
[32m[0906 14-32-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03453, current rewards: -630.17077, mean: -0.65643
[32m[0906 14-32-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03456, current rewards: -680.17077, mean: -0.67344
[32m[0906 14-32-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03460, current rewards: -730.17077, mean: -0.68884
[32m[0906 14-32-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03462, current rewards: -780.17077, mean: -0.70286
[32m[0906 14-32-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03465, current rewards: -830.17077, mean: -0.71566
[32m[0906 14-32-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03467, current rewards: -880.17077, mean: -0.72741
[32m[0906 14-32-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03465, current rewards: -930.17077, mean: -0.73823
[32m[0906 14-32-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03463, current rewards: -980.17077, mean: -0.74822
[32m[0906 14-32-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03461, current rewards: -1030.17077, mean: -0.75748
[32m[0906 14-32-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03460, current rewards: -1080.17077, mean: -0.76608
[32m[0906 14-32-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03458, current rewards: -1130.17077, mean: -0.77409
[32m[0906 14-32-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03458, current rewards: -1180.17077, mean: -0.78157
[32m[0906 14-32-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03458, current rewards: -1230.17077, mean: -0.78857
[32m[0906 14-32-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03457, current rewards: -1280.17077, mean: -0.79514
[32m[0906 14-32-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03456, current rewards: -1330.17077, mean: -0.80131
[32m[0906 14-32-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03455, current rewards: -1380.17077, mean: -0.80712
[32m[0906 14-32-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03456, current rewards: -1430.17077, mean: -0.81260
[32m[0906 14-32-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03458, current rewards: -1480.17077, mean: -0.81777
[32m[0906 14-32-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03460, current rewards: -1530.17077, mean: -0.82267
[32m[0906 14-33-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03461, current rewards: -1580.17077, mean: -0.82731
[32m[0906 14-33-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03462, current rewards: -1630.17077, mean: -0.83172
[32m[0906 14-33-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03464, current rewards: -1680.17077, mean: -0.83591
[32m[0906 14-33-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03463, current rewards: -1730.17077, mean: -0.83989
[32m[0906 14-33-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03462, current rewards: -1780.17077, mean: -0.84368
[32m[0906 14-33-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03461, current rewards: -1830.17077, mean: -0.84730
[32m[0906 14-33-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03461, current rewards: -1880.17077, mean: -0.85076
[32m[0906 14-33-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03460, current rewards: -1930.17077, mean: -0.85406
[32m[0906 14-33-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03459, current rewards: -1980.17077, mean: -0.85722
[32m[0906 14-33-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03459, current rewards: -2030.17077, mean: -0.86024
[32m[0906 14-33-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03459, current rewards: -2080.17077, mean: -0.86314
[32m[0906 14-33-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03458, current rewards: -2130.17077, mean: -0.86592
[32m[0906 14-33-21 @Agent.py:117][0m Average action selection time: 0.0346
[32m[0906 14-33-21 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-33-21 @MBExp.py:227][0m Rewards obtained: [-2170.170767261868], Lows: [0], Highs: [2193], Total time: 2388.170417
[32m[0906 14-34-19 @MBExp.py:144][0m ####################################################################
[32m[0906 14-34-19 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 14-34-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03484, current rewards: 0.11315, mean: 0.01132
[32m[0906 14-34-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03479, current rewards: 5.75040, mean: 0.09584
[32m[0906 14-34-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03443, current rewards: 11.38634, mean: 0.10351
[32m[0906 14-34-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03446, current rewards: 17.01888, mean: 0.10637
[32m[0906 14-34-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03442, current rewards: 22.65366, mean: 0.10787
[32m[0906 14-34-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03440, current rewards: 28.29003, mean: 0.10881
[32m[0906 14-34-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03438, current rewards: 33.92024, mean: 0.10942
[32m[0906 14-34-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03437, current rewards: 39.55582, mean: 0.10988
[32m[0906 14-34-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03433, current rewards: 45.35426, mean: 0.11062
[32m[0906 14-34-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03434, current rewards: 51.11682, mean: 0.11112
[32m[0906 14-34-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03433, current rewards: 56.84946, mean: 0.11147
[32m[0906 14-34-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03432, current rewards: 62.58216, mean: 0.11175
[32m[0906 14-34-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03432, current rewards: 63.81251, mean: 0.10461
[32m[0906 14-34-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03431, current rewards: 69.40129, mean: 0.10515
[32m[0906 14-34-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03431, current rewards: 74.98557, mean: 0.10561
[32m[0906 14-34-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03429, current rewards: 80.57295, mean: 0.10602
[32m[0906 14-34-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03429, current rewards: 84.25144, mean: 0.10401
[32m[0906 14-34-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03429, current rewards: 89.82658, mean: 0.10445
[32m[0906 14-34-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03434, current rewards: 95.42082, mean: 0.10486
[32m[0906 14-34-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03439, current rewards: 101.01283, mean: 0.10522
[32m[0906 14-34-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03443, current rewards: 106.60494, mean: 0.10555
[32m[0906 14-34-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03447, current rewards: 112.19987, mean: 0.10585
[32m[0906 14-34-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03450, current rewards: 117.79228, mean: 0.10612
[32m[0906 14-34-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03453, current rewards: 123.38299, mean: 0.10636
[32m[0906 14-35-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03456, current rewards: 128.97752, mean: 0.10659
[32m[0906 14-35-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03455, current rewards: 134.46464, mean: 0.10672
[32m[0906 14-35-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03453, current rewards: 139.25521, mean: 0.10630
[32m[0906 14-35-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03452, current rewards: 145.37929, mean: 0.10690
[32m[0906 14-35-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03451, current rewards: 151.50165, mean: 0.10745
[32m[0906 14-35-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03450, current rewards: 157.62544, mean: 0.10796
[32m[0906 14-35-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03450, current rewards: 163.75138, mean: 0.10844
[32m[0906 14-35-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03450, current rewards: 169.87619, mean: 0.10889
[32m[0906 14-35-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03449, current rewards: 175.99878, mean: 0.10932
[32m[0906 14-35-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03448, current rewards: 182.30182, mean: 0.10982
[32m[0906 14-35-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03449, current rewards: 188.44365, mean: 0.11020
[32m[0906 14-35-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03451, current rewards: 192.40152, mean: 0.10932
[32m[0906 14-35-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03453, current rewards: 198.06418, mean: 0.10943
[32m[0906 14-35-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03455, current rewards: 203.72482, mean: 0.10953
[32m[0906 14-35-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03457, current rewards: 209.38642, mean: 0.10963
[32m[0906 14-35-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03459, current rewards: 215.04985, mean: 0.10972
[32m[0906 14-35-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03460, current rewards: 220.71204, mean: 0.10981
[32m[0906 14-35-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03460, current rewards: 226.31844, mean: 0.10986
[32m[0906 14-35-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03459, current rewards: 231.95217, mean: 0.10993
[32m[0906 14-35-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03458, current rewards: 237.62134, mean: 0.11001
[32m[0906 14-35-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03457, current rewards: 243.29354, mean: 0.11009
[32m[0906 14-35-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03457, current rewards: 248.96758, mean: 0.11016
[32m[0906 14-35-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03456, current rewards: 253.78919, mean: 0.10987
[32m[0906 14-35-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03456, current rewards: 259.91232, mean: 0.11013
[32m[0906 14-35-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03455, current rewards: 266.04145, mean: 0.11039
[32m[0906 14-35-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03455, current rewards: 272.17345, mean: 0.11064
[32m[0906 14-35-46 @Agent.py:117][0m Average action selection time: 0.0345
[32m[0906 14-35-46 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-35-46 @MBExp.py:227][0m Rewards obtained: [277.09544364363876], Lows: [2], Highs: [7], Total time: 2475.181134
[32m[0906 14-36-45 @MBExp.py:144][0m ####################################################################
[32m[0906 14-36-45 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 14-36-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03456, current rewards: -1.02672, mean: -0.10267
[32m[0906 14-36-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03443, current rewards: 4.61188, mean: 0.07686
[32m[0906 14-36-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03435, current rewards: 10.21409, mean: 0.09286
[32m[0906 14-36-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03436, current rewards: 15.81819, mean: 0.09886
[32m[0906 14-36-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03434, current rewards: 21.42407, mean: 0.10202
[32m[0906 14-36-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03432, current rewards: 27.02395, mean: 0.10394
[32m[0906 14-36-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03431, current rewards: 32.62547, mean: 0.10524
[32m[0906 14-36-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03431, current rewards: 38.23483, mean: 0.10621
[32m[0906 14-36-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03432, current rewards: 43.77933, mean: 0.10678
[32m[0906 14-37-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03433, current rewards: 48.22320, mean: 0.10483
[32m[0906 14-37-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03435, current rewards: 53.61323, mean: 0.10512
[32m[0906 14-37-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03435, current rewards: 59.00007, mean: 0.10536
[32m[0906 14-37-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03434, current rewards: 64.38916, mean: 0.10556
[32m[0906 14-37-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03434, current rewards: 69.77464, mean: 0.10572
[32m[0906 14-37-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03433, current rewards: 75.16308, mean: 0.10586
[32m[0906 14-37-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03435, current rewards: 80.54880, mean: 0.10599
[32m[0906 14-37-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03434, current rewards: 86.13840, mean: 0.10634
[32m[0906 14-37-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03434, current rewards: 91.62115, mean: 0.10654
[32m[0906 14-37-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03435, current rewards: 97.09071, mean: 0.10669
[32m[0906 14-37-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03439, current rewards: 102.55880, mean: 0.10683
[32m[0906 14-37-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03443, current rewards: 108.03021, mean: 0.10696
[32m[0906 14-37-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03447, current rewards: 113.50324, mean: 0.10708
[32m[0906 14-37-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03450, current rewards: 117.55596, mean: 0.10591
[32m[0906 14-37-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03453, current rewards: 123.35118, mean: 0.10634
[32m[0906 14-37-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03456, current rewards: 129.14641, mean: 0.10673
[32m[0906 14-37-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03453, current rewards: 136.66544, mean: 0.10846
[32m[0906 14-37-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03452, current rewards: 136.24881, mean: 0.10401
[32m[0906 14-37-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03451, current rewards: 86.24881, mean: 0.06342
[32m[0906 14-37-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03451, current rewards: 36.24881, mean: 0.02571
[32m[0906 14-37-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03450, current rewards: -13.75119, mean: -0.00942
[32m[0906 14-37-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03450, current rewards: -63.75119, mean: -0.04222
[32m[0906 14-37-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03450, current rewards: -113.75119, mean: -0.07292
[32m[0906 14-37-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03449, current rewards: -163.75119, mean: -0.10171
[32m[0906 14-37-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03448, current rewards: -181.48893, mean: -0.10933
[32m[0906 14-37-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03449, current rewards: -175.86629, mean: -0.10285
[32m[0906 14-37-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03451, current rewards: -170.25174, mean: -0.09673
[32m[0906 14-37-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03454, current rewards: -164.62436, mean: -0.09095
[32m[0906 14-37-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03456, current rewards: -159.00765, mean: -0.08549
[32m[0906 14-37-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03458, current rewards: -153.38629, mean: -0.08031
[32m[0906 14-37-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03461, current rewards: -147.76708, mean: -0.07539
[32m[0906 14-37-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03462, current rewards: -143.16323, mean: -0.07123
[32m[0906 14-37-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03462, current rewards: -137.67916, mean: -0.06683
[32m[0906 14-37-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03461, current rewards: -132.05801, mean: -0.06259
[32m[0906 14-38-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03461, current rewards: -126.43379, mean: -0.05853
[32m[0906 14-38-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03461, current rewards: -120.81647, mean: -0.05467
[32m[0906 14-38-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03460, current rewards: -115.19683, mean: -0.05097
[32m[0906 14-38-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03459, current rewards: -109.57835, mean: -0.04744
[32m[0906 14-38-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03459, current rewards: -103.95675, mean: -0.04405
[32m[0906 14-38-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03458, current rewards: -98.33186, mean: -0.04080
[32m[0906 14-38-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03458, current rewards: -94.74436, mean: -0.03851
[32m[0906 14-38-12 @Agent.py:117][0m Average action selection time: 0.0346
[32m[0906 14-38-12 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-38-12 @MBExp.py:227][0m Rewards obtained: [-90.26683189577298], Lows: [2], Highs: [332], Total time: 2562.263103
[32m[0906 14-39-14 @MBExp.py:144][0m ####################################################################
[32m[0906 14-39-14 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 14-39-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03376, current rewards: -0.06000, mean: -0.00600
[32m[0906 14-39-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03417, current rewards: 5.37365, mean: 0.08956
[32m[0906 14-39-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03422, current rewards: 10.80847, mean: 0.09826
[32m[0906 14-39-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03420, current rewards: 16.24408, mean: 0.10153
[32m[0906 14-39-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03422, current rewards: 21.68130, mean: 0.10324
[32m[0906 14-39-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03425, current rewards: 27.11248, mean: 0.10428
[32m[0906 14-39-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03429, current rewards: 32.54911, mean: 0.10500
[32m[0906 14-39-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03428, current rewards: 37.98342, mean: 0.10551
[32m[0906 14-39-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03429, current rewards: 43.41540, mean: 0.10589
[32m[0906 14-39-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03430, current rewards: 48.88545, mean: 0.10627
[32m[0906 14-39-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03429, current rewards: 54.42358, mean: 0.10671
[32m[0906 14-39-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03430, current rewards: 59.96468, mean: 0.10708
[32m[0906 14-39-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03431, current rewards: 65.50856, mean: 0.10739
[32m[0906 14-39-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03432, current rewards: 71.05615, mean: 0.10766
[32m[0906 14-39-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03432, current rewards: 76.59534, mean: 0.10788
[32m[0906 14-39-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03433, current rewards: 80.42505, mean: 0.10582
[32m[0906 14-39-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03435, current rewards: 86.01174, mean: 0.10619
[32m[0906 14-39-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03435, current rewards: 91.59652, mean: 0.10651
[32m[0906 14-39-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03435, current rewards: 97.18329, mean: 0.10679
[32m[0906 14-39-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03435, current rewards: 101.62177, mean: 0.10586
[32m[0906 14-39-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03438, current rewards: 107.18384, mean: 0.10612
[32m[0906 14-39-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03443, current rewards: 112.74108, mean: 0.10636
[32m[0906 14-39-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03446, current rewards: 118.30003, mean: 0.10658
[32m[0906 14-39-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03451, current rewards: 123.80055, mean: 0.10672
[32m[0906 14-39-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03454, current rewards: 129.19476, mean: 0.10677
[32m[0906 14-39-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03453, current rewards: 134.75383, mean: 0.10695
[32m[0906 14-39-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03452, current rewards: 140.31345, mean: 0.10711
[32m[0906 14-40-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03451, current rewards: 145.86449, mean: 0.10725
[32m[0906 14-40-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03450, current rewards: 151.41961, mean: 0.10739
[32m[0906 14-40-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03449, current rewards: 157.67072, mean: 0.10799
[32m[0906 14-40-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03449, current rewards: 163.39476, mean: 0.10821
[32m[0906 14-40-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03449, current rewards: 169.07107, mean: 0.10838
[32m[0906 14-40-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03449, current rewards: 174.74824, mean: 0.10854
[32m[0906 14-40-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03448, current rewards: 180.35777, mean: 0.10865
[32m[0906 14-40-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03449, current rewards: 185.96653, mean: 0.10875
[32m[0906 14-40-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03452, current rewards: 191.58153, mean: 0.10885
[32m[0906 14-40-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03455, current rewards: 192.95665, mean: 0.10661
[32m[0906 14-40-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03457, current rewards: 198.56719, mean: 0.10676
[32m[0906 14-40-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03459, current rewards: 204.17362, mean: 0.10690
[32m[0906 14-40-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03461, current rewards: 209.78207, mean: 0.10703
[32m[0906 14-40-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03463, current rewards: 215.53051, mean: 0.10723
[32m[0906 14-40-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03463, current rewards: 221.15284, mean: 0.10736
[32m[0906 14-40-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03462, current rewards: 226.77334, mean: 0.10748
[32m[0906 14-40-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03462, current rewards: 232.39498, mean: 0.10759
[32m[0906 14-40-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03461, current rewards: 238.01667, mean: 0.10770
[32m[0906 14-40-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03461, current rewards: 243.63816, mean: 0.10780
[32m[0906 14-40-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03460, current rewards: 249.26025, mean: 0.10790
[32m[0906 14-40-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03460, current rewards: 253.08451, mean: 0.10724
[32m[0906 14-40-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03459, current rewards: 258.63500, mean: 0.10732
[32m[0906 14-40-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03459, current rewards: 264.22128, mean: 0.10741
[32m[0906 14-40-41 @Agent.py:117][0m Average action selection time: 0.0346
[32m[0906 14-40-41 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-40-41 @MBExp.py:227][0m Rewards obtained: [268.69857552166604], Lows: [3], Highs: [4], Total time: 2649.392011
[32m[0906 14-41-45 @MBExp.py:144][0m ####################################################################
[32m[0906 14-41-45 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 14-41-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03415, current rewards: -1.04106, mean: -0.10411
[32m[0906 14-41-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03428, current rewards: 4.64739, mean: 0.07746
[32m[0906 14-41-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03418, current rewards: 10.32858, mean: 0.09390
[32m[0906 14-41-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03424, current rewards: 16.01263, mean: 0.10008
[32m[0906 14-41-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03424, current rewards: 21.69644, mean: 0.10332
[32m[0906 14-41-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03429, current rewards: 27.37068, mean: 0.10527
[32m[0906 14-41-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03429, current rewards: 31.05976, mean: 0.10019
[32m[0906 14-41-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03430, current rewards: 36.67285, mean: 0.10187
[32m[0906 14-41-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03432, current rewards: 42.39005, mean: 0.10339
[32m[0906 14-42-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03433, current rewards: 48.10969, mean: 0.10459
[32m[0906 14-42-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03432, current rewards: 52.82306, mean: 0.10357
[32m[0906 14-42-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03432, current rewards: 58.44395, mean: 0.10436
[32m[0906 14-42-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03433, current rewards: 64.06559, mean: 0.10503
[32m[0906 14-42-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03433, current rewards: 69.68653, mean: 0.10559
[32m[0906 14-42-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03433, current rewards: 75.30884, mean: 0.10607
[32m[0906 14-42-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03433, current rewards: 80.79378, mean: 0.10631
[32m[0906 14-42-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03432, current rewards: 86.34865, mean: 0.10660
[32m[0906 14-42-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03433, current rewards: 91.90371, mean: 0.10686
[32m[0906 14-42-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03434, current rewards: 97.45689, mean: 0.10710
[32m[0906 14-42-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03433, current rewards: 103.00798, mean: 0.10730
[32m[0906 14-42-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03432, current rewards: 108.55362, mean: 0.10748
[32m[0906 14-42-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03434, current rewards: 114.09998, mean: 0.10764
[32m[0906 14-42-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03438, current rewards: 119.64736, mean: 0.10779
[32m[0906 14-42-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03442, current rewards: 123.21137, mean: 0.10622
[32m[0906 14-42-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03443, current rewards: 128.92286, mean: 0.10655
[32m[0906 14-42-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03442, current rewards: 134.55942, mean: 0.10679
[32m[0906 14-42-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03441, current rewards: 140.19676, mean: 0.10702
[32m[0906 14-42-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03441, current rewards: 145.83338, mean: 0.10723
[32m[0906 14-42-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03441, current rewards: 149.99826, mean: 0.10638
[32m[0906 14-42-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03441, current rewards: 155.71454, mean: 0.10665
[32m[0906 14-42-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03441, current rewards: 161.43243, mean: 0.10691
[32m[0906 14-42-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03440, current rewards: 167.14892, mean: 0.10715
[32m[0906 14-42-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03440, current rewards: 172.64857, mean: 0.10724
[32m[0906 14-42-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03440, current rewards: 178.34622, mean: 0.10744
[32m[0906 14-42-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03443, current rewards: 184.04155, mean: 0.10763
[32m[0906 14-42-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03445, current rewards: 189.74451, mean: 0.10781
[32m[0906 14-42-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03448, current rewards: 195.44237, mean: 0.10798
[32m[0906 14-42-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03451, current rewards: 201.13794, mean: 0.10814
[32m[0906 14-42-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03453, current rewards: 206.83892, mean: 0.10829
[32m[0906 14-42-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03455, current rewards: 212.53683, mean: 0.10844
[32m[0906 14-42-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03456, current rewards: 217.33894, mean: 0.10813
[32m[0906 14-42-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03456, current rewards: 223.06817, mean: 0.10829
[32m[0906 14-42-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03456, current rewards: 228.71419, mean: 0.10840
[32m[0906 14-43-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03455, current rewards: 234.36008, mean: 0.10850
[32m[0906 14-43-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03455, current rewards: 240.01026, mean: 0.10860
[32m[0906 14-43-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03454, current rewards: 245.65284, mean: 0.10870
[32m[0906 14-43-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03453, current rewards: 251.29852, mean: 0.10879
[32m[0906 14-43-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03453, current rewards: 256.94797, mean: 0.10888
[32m[0906 14-43-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03452, current rewards: 262.59826, mean: 0.10896
[32m[0906 14-43-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03452, current rewards: 268.24512, mean: 0.10904
[32m[0906 14-43-12 @Agent.py:117][0m Average action selection time: 0.0345
[32m[0906 14-43-12 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-43-12 @MBExp.py:227][0m Rewards obtained: [271.6525600269639], Lows: [3], Highs: [5], Total time: 2736.334109
[32m[0906 14-44-18 @MBExp.py:144][0m ####################################################################
[32m[0906 14-44-18 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 14-44-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03308, current rewards: 0.98041, mean: 0.09804
[32m[0906 14-44-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03410, current rewards: 6.50494, mean: 0.10842
[32m[0906 14-44-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03409, current rewards: 12.03401, mean: 0.10940
[32m[0906 14-44-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03418, current rewards: 17.56205, mean: 0.10976
[32m[0906 14-44-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03416, current rewards: 23.09280, mean: 0.10997
[32m[0906 14-44-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03420, current rewards: 28.62215, mean: 0.11009
[32m[0906 14-44-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03423, current rewards: 34.15220, mean: 0.11017
[32m[0906 14-44-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03424, current rewards: 39.78073, mean: 0.11050
[32m[0906 14-44-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03426, current rewards: 45.33221, mean: 0.11057
[32m[0906 14-44-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03429, current rewards: 48.66046, mean: 0.10578
[32m[0906 14-44-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03431, current rewards: 54.27489, mean: 0.10642
[32m[0906 14-44-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03430, current rewards: 59.75389, mean: 0.10670
[32m[0906 14-44-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03429, current rewards: 65.22372, mean: 0.10692
[32m[0906 14-44-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03429, current rewards: 70.69605, mean: 0.10712
[32m[0906 14-44-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03430, current rewards: 76.17422, mean: 0.10729
[32m[0906 14-44-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03430, current rewards: 81.69001, mean: 0.10749
[32m[0906 14-44-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03430, current rewards: 87.16757, mean: 0.10761
[32m[0906 14-44-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03431, current rewards: 89.88626, mean: 0.10452
[32m[0906 14-44-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03431, current rewards: 95.40232, mean: 0.10484
[32m[0906 14-44-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03431, current rewards: 100.91510, mean: 0.10512
[32m[0906 14-44-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03431, current rewards: 106.43361, mean: 0.10538
[32m[0906 14-44-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03431, current rewards: 109.90206, mean: 0.10368
[32m[0906 14-44-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03432, current rewards: 115.35825, mean: 0.10393
[32m[0906 14-44-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03437, current rewards: 120.85159, mean: 0.10418
[32m[0906 14-44-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03439, current rewards: 126.30840, mean: 0.10439
[32m[0906 14-45-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03439, current rewards: 131.77013, mean: 0.10458
[32m[0906 14-45-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03444, current rewards: 137.22551, mean: 0.10475
[32m[0906 14-45-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03448, current rewards: 142.68709, mean: 0.10492
[32m[0906 14-45-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03451, current rewards: 148.14783, mean: 0.10507
[32m[0906 14-45-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03456, current rewards: 152.74758, mean: 0.10462
[32m[0906 14-45-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03458, current rewards: 158.30637, mean: 0.10484
[32m[0906 14-45-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03461, current rewards: 163.80755, mean: 0.10500
[32m[0906 14-45-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03464, current rewards: 169.23617, mean: 0.10512
[32m[0906 14-45-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03467, current rewards: 174.73700, mean: 0.10526
[32m[0906 14-45-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03472, current rewards: 180.23939, mean: 0.10540
[32m[0906 14-45-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03476, current rewards: 185.74527, mean: 0.10554
[32m[0906 14-45-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03477, current rewards: 191.24920, mean: 0.10566
[32m[0906 14-45-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03478, current rewards: 196.75085, mean: 0.10578
[32m[0906 14-45-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03479, current rewards: 202.25333, mean: 0.10589
[32m[0906 14-45-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03480, current rewards: 207.75661, mean: 0.10600
[32m[0906 14-45-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03481, current rewards: 213.26002, mean: 0.10610
[32m[0906 14-45-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03481, current rewards: 216.66826, mean: 0.10518
[32m[0906 14-45-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03480, current rewards: 222.14677, mean: 0.10528
[32m[0906 14-45-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03478, current rewards: 227.63037, mean: 0.10538
[32m[0906 14-45-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03478, current rewards: 233.11286, mean: 0.10548
[32m[0906 14-45-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03477, current rewards: 238.59416, mean: 0.10557
[32m[0906 14-45-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03475, current rewards: 244.07292, mean: 0.10566
[32m[0906 14-45-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03475, current rewards: 249.55521, mean: 0.10574
[32m[0906 14-45-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03474, current rewards: 255.03834, mean: 0.10583
[32m[0906 14-45-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03474, current rewards: 260.51837, mean: 0.10590
[32m[0906 14-45-45 @Agent.py:117][0m Average action selection time: 0.0347
[32m[0906 14-45-45 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-45-45 @MBExp.py:227][0m Rewards obtained: [264.9044573281872], Lows: [3], Highs: [4], Total time: 2823.8049619999997
[32m[0906 14-46-53 @MBExp.py:144][0m ####################################################################
[32m[0906 14-46-53 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 14-46-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03348, current rewards: 0.06070, mean: 0.00607
[32m[0906 14-46-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03403, current rewards: 5.72154, mean: 0.09536
[32m[0906 14-46-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03415, current rewards: 11.28930, mean: 0.10263
[32m[0906 14-46-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03425, current rewards: 16.85550, mean: 0.10535
[32m[0906 14-47-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03422, current rewards: 22.42618, mean: 0.10679
[32m[0906 14-47-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03424, current rewards: 27.99133, mean: 0.10766
[32m[0906 14-47-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03422, current rewards: 33.47310, mean: 0.10798
[32m[0906 14-47-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03423, current rewards: 39.03852, mean: 0.10844
[32m[0906 14-47-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03424, current rewards: 42.84725, mean: 0.10451
[32m[0906 14-47-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03427, current rewards: 48.31047, mean: 0.10502
[32m[0906 14-47-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03428, current rewards: 53.76738, mean: 0.10543
[32m[0906 14-47-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03429, current rewards: 59.22500, mean: 0.10576
[32m[0906 14-47-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03430, current rewards: 64.68223, mean: 0.10604
[32m[0906 14-47-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03430, current rewards: 69.18666, mean: 0.10483
[32m[0906 14-47-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03431, current rewards: 74.85411, mean: 0.10543
[32m[0906 14-47-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03430, current rewards: 80.49836, mean: 0.10592
[32m[0906 14-47-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03429, current rewards: 86.13834, mean: 0.10634
[32m[0906 14-47-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03428, current rewards: 91.78370, mean: 0.10673
[32m[0906 14-47-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03426, current rewards: 97.42911, mean: 0.10706
[32m[0906 14-47-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03427, current rewards: 103.07258, mean: 0.10737
[32m[0906 14-47-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03427, current rewards: 108.71623, mean: 0.10764
[32m[0906 14-47-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03426, current rewards: 114.35751, mean: 0.10788
[32m[0906 14-47-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03427, current rewards: 119.96560, mean: 0.10808
[32m[0906 14-47-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03427, current rewards: 125.53683, mean: 0.10822
[32m[0906 14-47-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03428, current rewards: 127.00371, mean: 0.10496
[32m[0906 14-47-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03428, current rewards: 132.54855, mean: 0.10520
[32m[0906 14-47-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03428, current rewards: 138.09132, mean: 0.10541
[32m[0906 14-47-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03428, current rewards: 143.63432, mean: 0.10561
[32m[0906 14-47-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03427, current rewards: 149.17807, mean: 0.10580
[32m[0906 14-47-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03427, current rewards: 154.72314, mean: 0.10597
[32m[0906 14-47-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03427, current rewards: 160.26677, mean: 0.10614
[32m[0906 14-47-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03427, current rewards: 165.97599, mean: 0.10639
[32m[0906 14-47-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03427, current rewards: 171.53916, mean: 0.10655
[32m[0906 14-47-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03428, current rewards: 177.10232, mean: 0.10669
[32m[0906 14-47-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03431, current rewards: 182.66548, mean: 0.10682
[32m[0906 14-47-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03433, current rewards: 177.09620, mean: 0.10062
[32m[0906 14-47-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03436, current rewards: 182.65020, mean: 0.10091
[32m[0906 14-47-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03438, current rewards: 188.20209, mean: 0.10118
[32m[0906 14-47-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03440, current rewards: 193.75620, mean: 0.10144
[32m[0906 14-48-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03443, current rewards: 199.33850, mean: 0.10170
[32m[0906 14-48-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03444, current rewards: 204.89273, mean: 0.10194
[32m[0906 14-48-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03445, current rewards: 210.43005, mean: 0.10215
[32m[0906 14-48-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03444, current rewards: 215.94117, mean: 0.10234
[32m[0906 14-48-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03444, current rewards: 221.44991, mean: 0.10252
[32m[0906 14-48-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03444, current rewards: 226.96017, mean: 0.10270
[32m[0906 14-48-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03443, current rewards: 232.46862, mean: 0.10286
[32m[0906 14-48-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03443, current rewards: 237.97869, mean: 0.10302
[32m[0906 14-48-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03442, current rewards: 243.35781, mean: 0.10312
[32m[0906 14-48-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03442, current rewards: 248.79081, mean: 0.10323
[32m[0906 14-48-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03441, current rewards: 254.30355, mean: 0.10338
[32m[0906 14-48-19 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 14-48-19 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-48-19 @MBExp.py:227][0m Rewards obtained: [258.7124253078242], Lows: [3], Highs: [12], Total time: 2910.4720249999996
[32m[0906 14-49-29 @MBExp.py:144][0m ####################################################################
[32m[0906 14-49-29 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 14-49-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03455, current rewards: -1.07124, mean: -0.10712
[32m[0906 14-49-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03425, current rewards: 4.62169, mean: 0.07703
[32m[0906 14-49-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03429, current rewards: 10.18564, mean: 0.09260
[32m[0906 14-49-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03443, current rewards: 15.74373, mean: 0.09840
[32m[0906 14-49-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03439, current rewards: 21.30393, mean: 0.10145
[32m[0906 14-49-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03434, current rewards: 26.86725, mean: 0.10334
[32m[0906 14-49-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03436, current rewards: 32.36626, mean: 0.10441
[32m[0906 14-49-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03435, current rewards: 37.91467, mean: 0.10532
[32m[0906 14-49-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03431, current rewards: 43.45826, mean: 0.10600
[32m[0906 14-49-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03432, current rewards: 49.00454, mean: 0.10653
[32m[0906 14-49-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03435, current rewards: 53.47570, mean: 0.10485
[32m[0906 14-49-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03435, current rewards: 59.00345, mean: 0.10536
[32m[0906 14-49-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03435, current rewards: 64.53272, mean: 0.10579
[32m[0906 14-49-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03435, current rewards: 70.06459, mean: 0.10616
[32m[0906 14-49-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03435, current rewards: 75.52845, mean: 0.10638
[32m[0906 14-49-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03435, current rewards: 81.03507, mean: 0.10663
[32m[0906 14-49-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03434, current rewards: 86.54265, mean: 0.10684
[32m[0906 14-49-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03433, current rewards: 92.05021, mean: 0.10704
[32m[0906 14-50-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03432, current rewards: 97.56023, mean: 0.10721
[32m[0906 14-50-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03433, current rewards: 100.92644, mean: 0.10513
[32m[0906 14-50-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03433, current rewards: 106.59600, mean: 0.10554
[32m[0906 14-50-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03434, current rewards: 112.26499, mean: 0.10591
[32m[0906 14-50-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03433, current rewards: 117.93798, mean: 0.10625
[32m[0906 14-50-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03433, current rewards: 124.22129, mean: 0.10709
[32m[0906 14-50-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03429, current rewards: 130.53671, mean: 0.10788
[32m[0906 14-50-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03429, current rewards: 136.85214, mean: 0.10861
[32m[0906 14-50-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03429, current rewards: 143.16757, mean: 0.10929
[32m[0906 14-50-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03430, current rewards: 149.48299, mean: 0.10991
[32m[0906 14-50-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03430, current rewards: 155.79842, mean: 0.11050
[32m[0906 14-50-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03430, current rewards: 119.31412, mean: 0.08172
[32m[0906 14-50-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03430, current rewards: 69.31412, mean: 0.04590
[32m[0906 14-50-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03430, current rewards: 19.31412, mean: 0.01238
[32m[0906 14-50-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03430, current rewards: -30.68588, mean: -0.01906
[32m[0906 14-50-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03432, current rewards: -80.68588, mean: -0.04861
[32m[0906 14-50-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03434, current rewards: -130.68588, mean: -0.07642
[32m[0906 14-50-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03437, current rewards: -180.68588, mean: -0.10266
[32m[0906 14-50-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03440, current rewards: -230.68588, mean: -0.12745
[32m[0906 14-50-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03442, current rewards: -280.68588, mean: -0.15091
[32m[0906 14-50-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03444, current rewards: -330.68588, mean: -0.17313
[32m[0906 14-50-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03447, current rewards: -380.68588, mean: -0.19423
[32m[0906 14-50-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03449, current rewards: -430.68588, mean: -0.21427
[32m[0906 14-50-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03449, current rewards: -480.68588, mean: -0.23334
[32m[0906 14-50-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03450, current rewards: -530.68588, mean: -0.25151
[32m[0906 14-50-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03450, current rewards: -580.68588, mean: -0.26884
[32m[0906 14-50-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03450, current rewards: -630.68588, mean: -0.28538
[32m[0906 14-50-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03449, current rewards: -680.68588, mean: -0.30119
[32m[0906 14-50-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03449, current rewards: -730.68588, mean: -0.31631
[32m[0906 14-50-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03449, current rewards: -780.68588, mean: -0.33080
[32m[0906 14-50-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03449, current rewards: -830.68588, mean: -0.34468
[32m[0906 14-50-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03449, current rewards: -880.68588, mean: -0.35800
[32m[0906 14-50-56 @Agent.py:117][0m Average action selection time: 0.0345
[32m[0906 14-50-56 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-50-56 @MBExp.py:227][0m Rewards obtained: [-920.6858807362244], Lows: [1], Highs: [1081], Total time: 2997.3297409999996
[32m[0906 14-52-08 @MBExp.py:144][0m ####################################################################
[32m[0906 14-52-08 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 14-52-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03346, current rewards: 0.08315, mean: 0.00831
[32m[0906 14-52-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03399, current rewards: 5.72651, mean: 0.09544
[32m[0906 14-52-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03414, current rewards: 11.36793, mean: 0.10334
[32m[0906 14-52-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03416, current rewards: 17.00961, mean: 0.10631
[32m[0906 14-52-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03414, current rewards: 22.65026, mean: 0.10786
[32m[0906 14-52-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03417, current rewards: 28.28852, mean: 0.10880
[32m[0906 14-52-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03419, current rewards: 33.92582, mean: 0.10944
[32m[0906 14-52-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03419, current rewards: 39.38959, mean: 0.10942
[32m[0906 14-52-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03419, current rewards: 44.98673, mean: 0.10972
[32m[0906 14-52-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03417, current rewards: 50.58619, mean: 0.10997
[32m[0906 14-52-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03417, current rewards: 56.18567, mean: 0.11017
[32m[0906 14-52-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03418, current rewards: 60.83684, mean: 0.10864
[32m[0906 14-52-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03419, current rewards: 66.29586, mean: 0.10868
[32m[0906 14-52-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03421, current rewards: 71.75998, mean: 0.10873
[32m[0906 14-52-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03423, current rewards: 77.22137, mean: 0.10876
[32m[0906 14-52-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03424, current rewards: 82.99511, mean: 0.10920
[32m[0906 14-52-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03426, current rewards: 88.51362, mean: 0.10928
[32m[0906 14-52-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03427, current rewards: 94.03602, mean: 0.10934
[32m[0906 14-52-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03428, current rewards: 99.55184, mean: 0.10940
[32m[0906 14-52-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03428, current rewards: 105.15569, mean: 0.10954
[32m[0906 14-52-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03430, current rewards: 110.82679, mean: 0.10973
[32m[0906 14-52-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03431, current rewards: 116.49624, mean: 0.10990
[32m[0906 14-52-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03431, current rewards: 122.16758, mean: 0.11006
[32m[0906 14-52-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03430, current rewards: 124.33629, mean: 0.10719
[32m[0906 14-52-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03427, current rewards: 129.00991, mean: 0.10662
[32m[0906 14-52-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03424, current rewards: 134.48291, mean: 0.10673
[32m[0906 14-52-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03424, current rewards: 139.95902, mean: 0.10684
[32m[0906 14-52-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03424, current rewards: 145.43707, mean: 0.10694
[32m[0906 14-52-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03423, current rewards: 148.73179, mean: 0.10548
[32m[0906 14-52-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03424, current rewards: 154.23753, mean: 0.10564
[32m[0906 14-53-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03424, current rewards: 159.74096, mean: 0.10579
[32m[0906 14-53-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03424, current rewards: 165.25026, mean: 0.10593
[32m[0906 14-53-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03424, current rewards: 170.82288, mean: 0.10610
[32m[0906 14-53-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03428, current rewards: 173.92996, mean: 0.10478
[32m[0906 14-53-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03431, current rewards: 179.04007, mean: 0.10470
[32m[0906 14-53-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03434, current rewards: 184.09021, mean: 0.10460
[32m[0906 14-53-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03436, current rewards: 189.20025, mean: 0.10453
[32m[0906 14-53-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03439, current rewards: 194.24726, mean: 0.10443
[32m[0906 14-53-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03441, current rewards: 199.35713, mean: 0.10438
[32m[0906 14-53-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03444, current rewards: 204.40539, mean: 0.10429
[32m[0906 14-53-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03447, current rewards: 209.53214, mean: 0.10424
[32m[0906 14-53-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03448, current rewards: 214.58760, mean: 0.10417
[32m[0906 14-53-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03447, current rewards: 219.70599, mean: 0.10413
[32m[0906 14-53-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03447, current rewards: 224.75846, mean: 0.10405
[32m[0906 14-53-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03446, current rewards: 229.87716, mean: 0.10402
[32m[0906 14-53-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03446, current rewards: 230.98660, mean: 0.10221
[32m[0906 14-53-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03446, current rewards: 236.50278, mean: 0.10238
[32m[0906 14-53-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03446, current rewards: 242.01844, mean: 0.10255
[32m[0906 14-53-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03445, current rewards: 247.49342, mean: 0.10269
[32m[0906 14-53-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03444, current rewards: 252.98487, mean: 0.10284
[32m[0906 14-53-34 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 14-53-34 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-53-34 @MBExp.py:227][0m Rewards obtained: [256.2484850832523], Lows: [5], Highs: [5], Total time: 3084.0909549999997
[32m[0906 14-54-48 @MBExp.py:144][0m ####################################################################
[32m[0906 14-54-48 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 14-54-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03368, current rewards: -1.21562, mean: -0.12156
[32m[0906 14-54-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03417, current rewards: 4.39139, mean: 0.07319
[32m[0906 14-54-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03424, current rewards: 9.98908, mean: 0.09081
[32m[0906 14-54-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03428, current rewards: 15.59324, mean: 0.09746
[32m[0906 14-54-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03423, current rewards: 21.19745, mean: 0.10094
[32m[0906 14-54-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03423, current rewards: 26.79418, mean: 0.10305
[32m[0906 14-54-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03420, current rewards: 32.58955, mean: 0.10513
[32m[0906 14-55-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03422, current rewards: 38.37592, mean: 0.10660
[32m[0906 14-55-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03422, current rewards: 44.04211, mean: 0.10742
[32m[0906 14-55-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03424, current rewards: 49.71080, mean: 0.10807
[32m[0906 14-55-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03425, current rewards: 55.38359, mean: 0.10860
[32m[0906 14-55-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03425, current rewards: 59.96895, mean: 0.10709
[32m[0906 14-55-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03424, current rewards: 66.13515, mean: 0.10842
[32m[0906 14-55-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03423, current rewards: 72.29814, mean: 0.10954
[32m[0906 14-55-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03423, current rewards: 78.45991, mean: 0.11051
[32m[0906 14-55-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03423, current rewards: 84.74186, mean: 0.11150
[32m[0906 14-55-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03423, current rewards: 90.97831, mean: 0.11232
[32m[0906 14-55-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03425, current rewards: 97.21386, mean: 0.11304
[32m[0906 14-55-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03426, current rewards: 103.44530, mean: 0.11368
[32m[0906 14-55-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03427, current rewards: 107.09896, mean: 0.11156
[32m[0906 14-55-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03427, current rewards: 112.78099, mean: 0.11166
[32m[0906 14-55-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03427, current rewards: 118.46500, mean: 0.11176
[32m[0906 14-55-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03426, current rewards: 124.08409, mean: 0.11179
[32m[0906 14-55-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03423, current rewards: 129.60806, mean: 0.11173
[32m[0906 14-55-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03420, current rewards: 135.23673, mean: 0.11177
[32m[0906 14-55-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03417, current rewards: 140.86268, mean: 0.11180
[32m[0906 14-55-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03414, current rewards: 146.49169, mean: 0.11183
[32m[0906 14-55-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03413, current rewards: 152.10930, mean: 0.11185
[32m[0906 14-55-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03413, current rewards: 157.73840, mean: 0.11187
[32m[0906 14-55-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03414, current rewards: 163.36686, mean: 0.11190
[32m[0906 14-55-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03415, current rewards: 168.98071, mean: 0.11191
[32m[0906 14-55-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03416, current rewards: 174.60392, mean: 0.11193
[32m[0906 14-55-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03416, current rewards: 180.22689, mean: 0.11194
[32m[0906 14-55-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03419, current rewards: 185.85208, mean: 0.11196
[32m[0906 14-55-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03422, current rewards: 191.47788, mean: 0.11198
[32m[0906 14-55-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03424, current rewards: 195.18955, mean: 0.11090
[32m[0906 14-55-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03427, current rewards: 200.74504, mean: 0.11091
[32m[0906 14-55-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03430, current rewards: 206.29885, mean: 0.11091
[32m[0906 14-55-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03433, current rewards: 211.85110, mean: 0.11092
[32m[0906 14-55-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03435, current rewards: 217.55497, mean: 0.11100
[32m[0906 14-55-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03438, current rewards: 223.51445, mean: 0.11120
[32m[0906 14-56-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03440, current rewards: 229.43233, mean: 0.11137
[32m[0906 14-56-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03440, current rewards: 235.35021, mean: 0.11154
[32m[0906 14-56-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03439, current rewards: 241.26808, mean: 0.11170
[32m[0906 14-56-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03439, current rewards: 234.67528, mean: 0.10619
[32m[0906 14-56-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03439, current rewards: 240.40227, mean: 0.10637
[32m[0906 14-56-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03438, current rewards: 246.13275, mean: 0.10655
[32m[0906 14-56-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03438, current rewards: 251.86411, mean: 0.10672
[32m[0906 14-56-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03438, current rewards: 257.66099, mean: 0.10691
[32m[0906 14-56-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03438, current rewards: 263.41480, mean: 0.10708
[32m[0906 14-56-15 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 14-56-15 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-56-15 @MBExp.py:227][0m Rewards obtained: [268.01630444903645], Lows: [2], Highs: [14], Total time: 3170.6958959999997
[32m[0906 14-57-31 @MBExp.py:144][0m ####################################################################
[32m[0906 14-57-31 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 14-57-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03399, current rewards: -1.03683, mean: -0.10368
[32m[0906 14-57-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03427, current rewards: 4.62371, mean: 0.07706
[32m[0906 14-57-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03429, current rewards: 10.16208, mean: 0.09238
[32m[0906 14-57-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03422, current rewards: 15.69833, mean: 0.09811
[32m[0906 14-57-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03426, current rewards: 21.23464, mean: 0.10112
[32m[0906 14-57-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03427, current rewards: 26.77025, mean: 0.10296
[32m[0906 14-57-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03427, current rewards: 32.27120, mean: 0.10410
[32m[0906 14-57-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03425, current rewards: 37.81616, mean: 0.10504
[32m[0906 14-57-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03423, current rewards: 43.35839, mean: 0.10575
[32m[0906 14-57-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03424, current rewards: 48.90137, mean: 0.10631
[32m[0906 14-57-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03424, current rewards: 53.44419, mean: 0.10479
[32m[0906 14-57-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03425, current rewards: 58.95298, mean: 0.10527
[32m[0906 14-57-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03427, current rewards: 64.45457, mean: 0.10566
[32m[0906 14-57-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03428, current rewards: 69.95654, mean: 0.10599
[32m[0906 14-57-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03428, current rewards: 75.53119, mean: 0.10638
[32m[0906 14-57-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03428, current rewards: 81.02618, mean: 0.10661
[32m[0906 14-57-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03428, current rewards: 86.51885, mean: 0.10681
[32m[0906 14-58-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03427, current rewards: 92.01715, mean: 0.10700
[32m[0906 14-58-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03426, current rewards: 97.51319, mean: 0.10716
[32m[0906 14-58-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03426, current rewards: 103.00598, mean: 0.10730
[32m[0906 14-58-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03426, current rewards: 106.47897, mean: 0.10542
[32m[0906 14-58-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03426, current rewards: 112.01705, mean: 0.10568
[32m[0906 14-58-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03426, current rewards: 117.51493, mean: 0.10587
[32m[0906 14-58-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03423, current rewards: 122.98497, mean: 0.10602
[32m[0906 14-58-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03420, current rewards: 128.53587, mean: 0.10623
[32m[0906 14-58-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03417, current rewards: 134.08548, mean: 0.10642
[32m[0906 14-58-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03414, current rewards: 139.63325, mean: 0.10659
[32m[0906 14-58-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03413, current rewards: 145.18027, mean: 0.10675
[32m[0906 14-58-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03411, current rewards: 150.73244, mean: 0.10690
[32m[0906 14-58-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03412, current rewards: 156.28371, mean: 0.10704
[32m[0906 14-58-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03413, current rewards: 160.07068, mean: 0.10601
[32m[0906 14-58-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03414, current rewards: 165.59549, mean: 0.10615
[32m[0906 14-58-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03416, current rewards: 171.22278, mean: 0.10635
[32m[0906 14-58-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03419, current rewards: 176.84834, mean: 0.10654
[32m[0906 14-58-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03422, current rewards: 182.46804, mean: 0.10671
[32m[0906 14-58-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03425, current rewards: 188.09261, mean: 0.10687
[32m[0906 14-58-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03428, current rewards: 193.71873, mean: 0.10703
[32m[0906 14-58-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03431, current rewards: 199.34096, mean: 0.10717
[32m[0906 14-58-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03434, current rewards: 204.96158, mean: 0.10731
[32m[0906 14-58-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03436, current rewards: 210.78255, mean: 0.10754
[32m[0906 14-58-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03438, current rewards: 216.38807, mean: 0.10766
[32m[0906 14-58-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03440, current rewards: 222.00113, mean: 0.10777
[32m[0906 14-58-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03439, current rewards: 227.60950, mean: 0.10787
[32m[0906 14-58-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03439, current rewards: 232.11011, mean: 0.10746
[32m[0906 14-58-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03440, current rewards: 237.61640, mean: 0.10752
[32m[0906 14-58-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03440, current rewards: 243.12253, mean: 0.10758
[32m[0906 14-58-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03439, current rewards: 248.62953, mean: 0.10763
[32m[0906 14-58-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03439, current rewards: 254.05082, mean: 0.10765
[32m[0906 14-58-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03439, current rewards: 259.60378, mean: 0.10772
[32m[0906 14-58-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03439, current rewards: 263.23155, mean: 0.10700
[32m[0906 14-58-57 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 14-58-57 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-58-57 @MBExp.py:227][0m Rewards obtained: [267.78402919287356], Lows: [3], Highs: [4], Total time: 3257.3149919999996
[32m[0906 15-00-15 @MBExp.py:144][0m ####################################################################
[32m[0906 15-00-15 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 15-00-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03360, current rewards: -0.02579, mean: -0.00258
[32m[0906 15-00-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03418, current rewards: 5.58500, mean: 0.09308
[32m[0906 15-00-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03429, current rewards: 11.19091, mean: 0.10174
[32m[0906 15-00-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03425, current rewards: 16.79196, mean: 0.10495
[32m[0906 15-00-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03431, current rewards: 22.39511, mean: 0.10664
[32m[0906 15-00-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03429, current rewards: 27.99922, mean: 0.10769
[32m[0906 15-00-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03431, current rewards: 33.58620, mean: 0.10834
[32m[0906 15-00-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03433, current rewards: 39.19806, mean: 0.10888
[32m[0906 15-00-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03432, current rewards: 44.80812, mean: 0.10929
[32m[0906 15-00-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03434, current rewards: 48.43939, mean: 0.10530
[32m[0906 15-00-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03433, current rewards: 54.01566, mean: 0.10591
[32m[0906 15-00-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03432, current rewards: 59.59997, mean: 0.10643
[32m[0906 15-00-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03432, current rewards: 65.18508, mean: 0.10686
[32m[0906 15-00-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03433, current rewards: 70.76650, mean: 0.10722
[32m[0906 15-00-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03431, current rewards: 74.82734, mean: 0.10539
[32m[0906 15-00-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03431, current rewards: 80.42545, mean: 0.10582
[32m[0906 15-00-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03431, current rewards: 86.02009, mean: 0.10620
[32m[0906 15-00-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03431, current rewards: 91.61694, mean: 0.10653
[32m[0906 15-00-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03430, current rewards: 97.21390, mean: 0.10683
[32m[0906 15-00-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03431, current rewards: 102.81106, mean: 0.10709
[32m[0906 15-00-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03432, current rewards: 108.40432, mean: 0.10733
[32m[0906 15-00-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03431, current rewards: 113.99825, mean: 0.10755
[32m[0906 15-00-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03431, current rewards: 119.61823, mean: 0.10776
[32m[0906 15-00-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03427, current rewards: 124.24921, mean: 0.10711
[32m[0906 15-00-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03424, current rewards: 129.85938, mean: 0.10732
[32m[0906 15-00-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03421, current rewards: 135.46390, mean: 0.10751
[32m[0906 15-01-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03419, current rewards: 141.07011, mean: 0.10769
[32m[0906 15-01-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03415, current rewards: 146.66949, mean: 0.10785
[32m[0906 15-01-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03412, current rewards: 152.27772, mean: 0.10800
[32m[0906 15-01-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03411, current rewards: 155.96176, mean: 0.10682
[32m[0906 15-01-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03411, current rewards: 161.47020, mean: 0.10693
[32m[0906 15-01-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03412, current rewards: 167.02335, mean: 0.10707
[32m[0906 15-01-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03414, current rewards: 172.57754, mean: 0.10719
[32m[0906 15-01-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03417, current rewards: 178.12971, mean: 0.10731
[32m[0906 15-01-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03420, current rewards: 183.68160, mean: 0.10742
[32m[0906 15-01-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03422, current rewards: 185.38737, mean: 0.10533
[32m[0906 15-01-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03424, current rewards: 191.06444, mean: 0.10556
[32m[0906 15-01-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03427, current rewards: 196.74151, mean: 0.10578
[32m[0906 15-01-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03429, current rewards: 202.04934, mean: 0.10578
[32m[0906 15-01-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03431, current rewards: 205.47977, mean: 0.10484
[32m[0906 15-01-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03433, current rewards: 208.91020, mean: 0.10394
[32m[0906 15-01-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03435, current rewards: 212.34063, mean: 0.10308
[32m[0906 15-01-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03434, current rewards: 215.77106, mean: 0.10226
[32m[0906 15-01-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03434, current rewards: 219.20150, mean: 0.10148
[32m[0906 15-01-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03433, current rewards: 195.91671, mean: 0.08865
[32m[0906 15-01-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03433, current rewards: 145.91671, mean: 0.06456
[32m[0906 15-01-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03433, current rewards: 95.91671, mean: 0.04152
[32m[0906 15-01-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03434, current rewards: 45.91671, mean: 0.01946
[32m[0906 15-01-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03433, current rewards: -4.08329, mean: -0.00169
[32m[0906 15-01-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03433, current rewards: -54.08329, mean: -0.02199
[32m[0906 15-01-42 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 15-01-42 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-01-42 @MBExp.py:227][0m Rewards obtained: [-94.0832882377428], Lows: [5], Highs: [317], Total time: 3343.7828709999994
[32m[0906 15-03-02 @MBExp.py:144][0m ####################################################################
[32m[0906 15-03-02 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 15-03-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03383, current rewards: 0.14988, mean: 0.01499
[32m[0906 15-03-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03426, current rewards: 5.88581, mean: 0.09810
[32m[0906 15-03-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03430, current rewards: 11.49981, mean: 0.10454
[32m[0906 15-03-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03433, current rewards: 17.11385, mean: 0.10696
[32m[0906 15-03-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03435, current rewards: 22.72774, mean: 0.10823
[32m[0906 15-03-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03433, current rewards: 28.13710, mean: 0.10822
[32m[0906 15-03-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03432, current rewards: 33.81972, mean: 0.10910
[32m[0906 15-03-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03432, current rewards: 39.49624, mean: 0.10971
[32m[0906 15-03-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03433, current rewards: 45.17779, mean: 0.11019
[32m[0906 15-03-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03434, current rewards: 50.85634, mean: 0.11056
[32m[0906 15-03-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03435, current rewards: 56.53378, mean: 0.11085
[32m[0906 15-03-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03434, current rewards: 62.21137, mean: 0.11109
[32m[0906 15-03-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03445, current rewards: 66.32619, mean: 0.10873
[32m[0906 15-03-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03446, current rewards: 72.00065, mean: 0.10909
[32m[0906 15-03-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03445, current rewards: 77.78252, mean: 0.10955
[32m[0906 15-03-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03444, current rewards: 83.51674, mean: 0.10989
[32m[0906 15-03-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03443, current rewards: 89.24152, mean: 0.11017
[32m[0906 15-03-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03443, current rewards: 94.97584, mean: 0.11044
[32m[0906 15-03-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03442, current rewards: 100.71232, mean: 0.11067
[32m[0906 15-03-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03442, current rewards: 106.44891, mean: 0.11088
[32m[0906 15-03-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03440, current rewards: 112.18511, mean: 0.11107
[32m[0906 15-03-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03440, current rewards: 117.91923, mean: 0.11124
[32m[0906 15-03-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03439, current rewards: 123.71340, mean: 0.11145
[32m[0906 15-03-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03435, current rewards: 129.47534, mean: 0.11162
[32m[0906 15-03-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03431, current rewards: 136.18363, mean: 0.11255
[32m[0906 15-03-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03427, current rewards: 142.27166, mean: 0.11291
[32m[0906 15-03-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03424, current rewards: 148.35914, mean: 0.11325
[32m[0906 15-03-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03422, current rewards: 154.44541, mean: 0.11356
[32m[0906 15-03-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03420, current rewards: 158.68729, mean: 0.11254
[32m[0906 15-03-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03418, current rewards: 164.44692, mean: 0.11263
[32m[0906 15-03-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03416, current rewards: 170.27080, mean: 0.11276
[32m[0906 15-03-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03415, current rewards: 176.01776, mean: 0.11283
[32m[0906 15-03-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03417, current rewards: 181.76216, mean: 0.11290
[32m[0906 15-03-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03420, current rewards: 187.50492, mean: 0.11295
[32m[0906 15-04-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03424, current rewards: 193.24985, mean: 0.11301
[32m[0906 15-04-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03427, current rewards: 198.99045, mean: 0.11306
[32m[0906 15-04-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03431, current rewards: 204.73465, mean: 0.11311
[32m[0906 15-04-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03433, current rewards: 210.47844, mean: 0.11316
[32m[0906 15-04-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03436, current rewards: 214.06931, mean: 0.11208
[32m[0906 15-04-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03439, current rewards: 219.74557, mean: 0.11212
[32m[0906 15-04-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03441, current rewards: 225.41915, mean: 0.11215
[32m[0906 15-04-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03443, current rewards: 231.10008, mean: 0.11218
[32m[0906 15-04-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03443, current rewards: 236.78186, mean: 0.11222
[32m[0906 15-04-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03442, current rewards: 242.46388, mean: 0.11225
[32m[0906 15-04-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03442, current rewards: 248.14355, mean: 0.11228
[32m[0906 15-04-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03442, current rewards: 253.82091, mean: 0.11231
[32m[0906 15-04-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03442, current rewards: 259.37866, mean: 0.11229
[32m[0906 15-04-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03442, current rewards: 264.90849, mean: 0.11225
[32m[0906 15-04-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03442, current rewards: 270.43630, mean: 0.11221
[32m[0906 15-04-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03442, current rewards: 275.96398, mean: 0.11218
[32m[0906 15-04-28 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 15-04-28 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-04-29 @MBExp.py:227][0m Rewards obtained: [277.2593146313623], Lows: [3], Highs: [4], Total time: 3430.4892899999995
[32m[0906 15-05-51 @MBExp.py:144][0m ####################################################################
[32m[0906 15-05-51 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 15-05-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03354, current rewards: 1.44359, mean: 0.14436
[32m[0906 15-05-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03417, current rewards: 8.20763, mean: 0.13679
[32m[0906 15-05-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03430, current rewards: 14.97167, mean: 0.13611
[32m[0906 15-05-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03425, current rewards: 21.73571, mean: 0.13585
[32m[0906 15-05-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03426, current rewards: 28.49077, mean: 0.13567
[32m[0906 15-06-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03430, current rewards: 33.03123, mean: 0.12704
[32m[0906 15-06-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03433, current rewards: 37.48998, mean: 0.12094
[32m[0906 15-06-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03435, current rewards: 41.94872, mean: 0.11652
[32m[0906 15-06-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03437, current rewards: 46.40747, mean: 0.11319
[32m[0906 15-06-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03436, current rewards: 50.86621, mean: 0.11058
[32m[0906 15-06-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03435, current rewards: 27.00641, mean: 0.05295
[32m[0906 15-06-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03434, current rewards: -22.99359, mean: -0.04106
[32m[0906 15-06-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03434, current rewards: -72.99359, mean: -0.11966
[32m[0906 15-06-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03433, current rewards: -122.99359, mean: -0.18635
[32m[0906 15-06-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03432, current rewards: -161.75880, mean: -0.22783
[32m[0906 15-06-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03433, current rewards: -156.18966, mean: -0.20551
[32m[0906 15-06-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03433, current rewards: -150.61884, mean: -0.18595
[32m[0906 15-06-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03433, current rewards: -145.04981, mean: -0.16866
[32m[0906 15-06-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03434, current rewards: -139.47818, mean: -0.15327
[32m[0906 15-06-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03433, current rewards: -133.90907, mean: -0.13949
[32m[0906 15-06-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03432, current rewards: -128.34038, mean: -0.12707
[32m[0906 15-06-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03434, current rewards: -124.94998, mean: -0.11788
[32m[0906 15-06-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03432, current rewards: -119.42745, mean: -0.10759
[32m[0906 15-06-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03429, current rewards: -113.90580, mean: -0.09819
[32m[0906 15-06-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03425, current rewards: -108.38263, mean: -0.08957
[32m[0906 15-06-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03423, current rewards: -102.85962, mean: -0.08163
[32m[0906 15-06-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03420, current rewards: -97.33283, mean: -0.07430
[32m[0906 15-06-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03417, current rewards: -91.80969, mean: -0.06751
[32m[0906 15-06-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03416, current rewards: -86.28967, mean: -0.06120
[32m[0906 15-06-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03414, current rewards: -80.81096, mean: -0.05535
[32m[0906 15-06-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03411, current rewards: -75.29193, mean: -0.04986
[32m[0906 15-06-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03409, current rewards: -69.77349, mean: -0.04473
[32m[0906 15-06-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03410, current rewards: -64.25117, mean: -0.03991
[32m[0906 15-06-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03414, current rewards: -58.72582, mean: -0.03538
[32m[0906 15-06-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03418, current rewards: -54.12561, mean: -0.03165
[32m[0906 15-06-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03421, current rewards: -48.53418, mean: -0.02758
[32m[0906 15-06-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03424, current rewards: -42.93162, mean: -0.02372
[32m[0906 15-06-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03426, current rewards: -37.22005, mean: -0.02001
[32m[0906 15-06-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03429, current rewards: -31.60994, mean: -0.01655
[32m[0906 15-06-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03431, current rewards: -25.98836, mean: -0.01326
[32m[0906 15-07-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03434, current rewards: -20.36536, mean: -0.01013
[32m[0906 15-07-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03436, current rewards: -14.74665, mean: -0.00716
[32m[0906 15-07-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03436, current rewards: -9.13077, mean: -0.00433
[32m[0906 15-07-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03436, current rewards: -2.62248, mean: -0.00121
[32m[0906 15-07-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03436, current rewards: 2.98646, mean: 0.00135
[32m[0906 15-07-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03437, current rewards: 8.47339, mean: 0.00375
[32m[0906 15-07-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03436, current rewards: 13.99818, mean: 0.00606
[32m[0906 15-07-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03436, current rewards: 19.52256, mean: 0.00827
[32m[0906 15-07-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03436, current rewards: 22.94087, mean: 0.00952
[32m[0906 15-07-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03436, current rewards: 28.53888, mean: 0.01160
[32m[0906 15-07-17 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 15-07-17 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-07-17 @MBExp.py:227][0m Rewards obtained: [33.01870146471885], Lows: [2], Highs: [217], Total time: 3517.0345469999997
[32m[0906 15-08-41 @MBExp.py:144][0m ####################################################################
[32m[0906 15-08-41 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 15-08-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03401, current rewards: 0.00636, mean: 0.00064
[32m[0906 15-08-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03422, current rewards: 5.53025, mean: 0.09217
[32m[0906 15-08-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03420, current rewards: 11.04739, mean: 0.10043
[32m[0906 15-08-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03420, current rewards: 16.55724, mean: 0.10348
[32m[0906 15-08-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03422, current rewards: 22.02186, mean: 0.10487
[32m[0906 15-08-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03426, current rewards: 27.52356, mean: 0.10586
[32m[0906 15-08-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03426, current rewards: 30.91411, mean: 0.09972
[32m[0906 15-08-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03428, current rewards: 34.46093, mean: 0.09572
[32m[0906 15-08-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03431, current rewards: 40.09779, mean: 0.09780
[32m[0906 15-08-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03429, current rewards: 45.73542, mean: 0.09942
[32m[0906 15-08-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03429, current rewards: 51.37355, mean: 0.10073
[32m[0906 15-09-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03431, current rewards: 57.01218, mean: 0.10181
[32m[0906 15-09-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03433, current rewards: 62.64973, mean: 0.10270
[32m[0906 15-09-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03432, current rewards: 68.28864, mean: 0.10347
[32m[0906 15-09-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03432, current rewards: 73.92729, mean: 0.10412
[32m[0906 15-09-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03433, current rewards: 79.56476, mean: 0.10469
[32m[0906 15-09-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03433, current rewards: 85.20251, mean: 0.10519
[32m[0906 15-09-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03433, current rewards: 89.68121, mean: 0.10428
[32m[0906 15-09-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03433, current rewards: 95.30555, mean: 0.10473
[32m[0906 15-09-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03432, current rewards: 100.93313, mean: 0.10514
[32m[0906 15-09-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03431, current rewards: 106.44251, mean: 0.10539
[32m[0906 15-09-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03431, current rewards: 112.08873, mean: 0.10574
[32m[0906 15-09-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03430, current rewards: 117.72717, mean: 0.10606
[32m[0906 15-09-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03425, current rewards: 123.36620, mean: 0.10635
[32m[0906 15-09-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03423, current rewards: 127.83421, mean: 0.10565
[32m[0906 15-09-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03420, current rewards: 133.33562, mean: 0.10582
[32m[0906 15-09-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03417, current rewards: 138.83245, mean: 0.10598
[32m[0906 15-09-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03414, current rewards: 144.32925, mean: 0.10612
[32m[0906 15-09-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03412, current rewards: 149.84386, mean: 0.10627
[32m[0906 15-09-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03410, current rewards: 155.34964, mean: 0.10640
[32m[0906 15-09-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03408, current rewards: 160.85480, mean: 0.10653
[32m[0906 15-09-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03406, current rewards: 166.35820, mean: 0.10664
[32m[0906 15-09-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03405, current rewards: 171.87102, mean: 0.10675
[32m[0906 15-09-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03406, current rewards: 175.29270, mean: 0.10560
[32m[0906 15-09-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03410, current rewards: 180.89308, mean: 0.10579
[32m[0906 15-09-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03414, current rewards: 186.48000, mean: 0.10595
[32m[0906 15-09-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03417, current rewards: 192.08765, mean: 0.10613
[32m[0906 15-09-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03420, current rewards: 197.67304, mean: 0.10628
[32m[0906 15-09-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03424, current rewards: 203.25552, mean: 0.10642
[32m[0906 15-09-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03426, current rewards: 208.84468, mean: 0.10655
[32m[0906 15-09-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03428, current rewards: 212.34426, mean: 0.10564
[32m[0906 15-09-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03430, current rewards: 217.94516, mean: 0.10580
[32m[0906 15-09-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03430, current rewards: 223.55009, mean: 0.10595
[32m[0906 15-09-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03430, current rewards: 229.15413, mean: 0.10609
[32m[0906 15-09-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03429, current rewards: 234.77744, mean: 0.10623
[32m[0906 15-09-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03430, current rewards: 240.38093, mean: 0.10636
[32m[0906 15-10-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03430, current rewards: 245.98593, mean: 0.10649
[32m[0906 15-10-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03430, current rewards: 250.45194, mean: 0.10612
[32m[0906 15-10-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03430, current rewards: 255.98399, mean: 0.10622
[32m[0906 15-10-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03431, current rewards: 261.50507, mean: 0.10630
[32m[0906 15-10-07 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 15-10-07 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-10-08 @MBExp.py:227][0m Rewards obtained: [265.9265520813043], Lows: [4], Highs: [4], Total time: 3603.4608299999995
[32m[0906 15-11-33 @MBExp.py:144][0m ####################################################################
[32m[0906 15-11-33 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 15-11-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03374, current rewards: -0.10485, mean: -0.01049
[32m[0906 15-11-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03411, current rewards: 5.19771, mean: 0.08663
[32m[0906 15-11-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03412, current rewards: 10.74938, mean: 0.09772
[32m[0906 15-11-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03420, current rewards: 16.80363, mean: 0.10502
[32m[0906 15-11-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03424, current rewards: 22.38091, mean: 0.10658
[32m[0906 15-11-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03422, current rewards: 27.95899, mean: 0.10753
[32m[0906 15-11-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03423, current rewards: 33.53909, mean: 0.10819
[32m[0906 15-11-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03424, current rewards: 39.11649, mean: 0.10866
[32m[0906 15-11-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03426, current rewards: 44.69144, mean: 0.10900
[32m[0906 15-11-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03424, current rewards: 50.27146, mean: 0.10929
[32m[0906 15-11-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03426, current rewards: 54.78688, mean: 0.10743
[32m[0906 15-11-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03426, current rewards: 60.31664, mean: 0.10771
[32m[0906 15-11-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03427, current rewards: 65.84679, mean: 0.10795
[32m[0906 15-11-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03427, current rewards: 71.41435, mean: 0.10820
[32m[0906 15-11-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03427, current rewards: 76.98192, mean: 0.10843
[32m[0906 15-12-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03427, current rewards: 82.54968, mean: 0.10862
[32m[0906 15-12-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03427, current rewards: 86.09671, mean: 0.10629
[32m[0906 15-12-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03427, current rewards: 91.63775, mean: 0.10656
[32m[0906 15-12-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03427, current rewards: 97.17678, mean: 0.10679
[32m[0906 15-12-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03428, current rewards: 102.71695, mean: 0.10700
[32m[0906 15-12-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03429, current rewards: 108.25908, mean: 0.10719
[32m[0906 15-12-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03429, current rewards: 113.80123, mean: 0.10736
[32m[0906 15-12-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03428, current rewards: 119.33898, mean: 0.10751
[32m[0906 15-12-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03424, current rewards: 124.88157, mean: 0.10766
[32m[0906 15-12-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03420, current rewards: 130.42651, mean: 0.10779
[32m[0906 15-12-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03418, current rewards: 135.96740, mean: 0.10791
[32m[0906 15-12-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03415, current rewards: 139.30623, mean: 0.10634
[32m[0906 15-12-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03413, current rewards: 144.88232, mean: 0.10653
[32m[0906 15-12-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03411, current rewards: 150.36146, mean: 0.10664
[32m[0906 15-12-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03409, current rewards: 155.88835, mean: 0.10677
[32m[0906 15-12-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03407, current rewards: 161.41638, mean: 0.10690
[32m[0906 15-12-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03405, current rewards: 166.94539, mean: 0.10702
[32m[0906 15-12-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03405, current rewards: 172.48191, mean: 0.10713
[32m[0906 15-12-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03407, current rewards: 178.01240, mean: 0.10724
[32m[0906 15-12-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03407, current rewards: 183.54445, mean: 0.10734
[32m[0906 15-12-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03409, current rewards: 189.07182, mean: 0.10743
[32m[0906 15-12-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03414, current rewards: 193.41654, mean: 0.10686
[32m[0906 15-12-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03416, current rewards: 198.52923, mean: 0.10674
[32m[0906 15-12-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03419, current rewards: 203.64714, mean: 0.10662
[32m[0906 15-12-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03422, current rewards: 208.76225, mean: 0.10651
[32m[0906 15-12-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03424, current rewards: 213.87450, mean: 0.10641
[32m[0906 15-12-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03427, current rewards: 218.98645, mean: 0.10630
[32m[0906 15-12-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03427, current rewards: 224.10221, mean: 0.10621
[32m[0906 15-12-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03427, current rewards: 229.21972, mean: 0.10612
[32m[0906 15-12-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03428, current rewards: 234.33768, mean: 0.10604
[32m[0906 15-12-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03428, current rewards: 239.51165, mean: 0.10598
[32m[0906 15-12-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03428, current rewards: 245.55548, mean: 0.10630
[32m[0906 15-12-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03428, current rewards: 251.26672, mean: 0.10647
[32m[0906 15-12-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03428, current rewards: 256.97380, mean: 0.10663
[32m[0906 15-12-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03428, current rewards: 262.68372, mean: 0.10678
[32m[0906 15-13-00 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 15-13-00 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-13-00 @MBExp.py:227][0m Rewards obtained: [267.2452896198367], Lows: [1], Highs: [5], Total time: 3689.8276989999995
[32m[0906 15-14-28 @MBExp.py:144][0m ####################################################################
[32m[0906 15-14-28 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 15-14-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03327, current rewards: -5.28442, mean: -0.52844
[32m[0906 15-14-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03414, current rewards: 0.34723, mean: 0.00579
[32m[0906 15-14-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03419, current rewards: 5.88862, mean: 0.05353
[32m[0906 15-14-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03435, current rewards: 11.36309, mean: 0.07102
[32m[0906 15-14-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03430, current rewards: 16.94743, mean: 0.08070
[32m[0906 15-14-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03432, current rewards: 22.53021, mean: 0.08665
[32m[0906 15-14-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03434, current rewards: 28.11888, mean: 0.09071
[32m[0906 15-14-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03436, current rewards: 33.70339, mean: 0.09362
[32m[0906 15-14-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03436, current rewards: 39.28945, mean: 0.09583
[32m[0906 15-14-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03434, current rewards: 44.87175, mean: 0.09755
[32m[0906 15-14-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03433, current rewards: 50.44959, mean: 0.09892
[32m[0906 15-14-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03432, current rewards: 56.02026, mean: 0.10004
[32m[0906 15-14-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03432, current rewards: 61.60151, mean: 0.10099
[32m[0906 15-14-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03429, current rewards: 67.19527, mean: 0.10181
[32m[0906 15-14-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03431, current rewards: 72.77607, mean: 0.10250
[32m[0906 15-14-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03431, current rewards: 74.05106, mean: 0.09744
[32m[0906 15-14-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03432, current rewards: 79.62733, mean: 0.09831
[32m[0906 15-14-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03432, current rewards: 85.20089, mean: 0.09907
[32m[0906 15-14-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03434, current rewards: 90.78037, mean: 0.09976
[32m[0906 15-15-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03433, current rewards: 96.50249, mean: 0.10052
[32m[0906 15-15-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03433, current rewards: 102.06267, mean: 0.10105
[32m[0906 15-15-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03433, current rewards: 106.47091, mean: 0.10044
[32m[0906 15-15-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03430, current rewards: 112.06394, mean: 0.10096
[32m[0906 15-15-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03426, current rewards: 117.66475, mean: 0.10144
[32m[0906 15-15-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03423, current rewards: 123.26054, mean: 0.10187
[32m[0906 15-15-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03420, current rewards: 128.85254, mean: 0.10226
[32m[0906 15-15-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03417, current rewards: 134.44819, mean: 0.10263
[32m[0906 15-15-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03414, current rewards: 138.95616, mean: 0.10217
[32m[0906 15-15-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03412, current rewards: 144.73255, mean: 0.10265
[32m[0906 15-15-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03410, current rewards: 150.50811, mean: 0.10309
[32m[0906 15-15-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03409, current rewards: 156.28640, mean: 0.10350
[32m[0906 15-15-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03407, current rewards: 162.06557, mean: 0.10389
[32m[0906 15-15-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03406, current rewards: 167.83626, mean: 0.10425
[32m[0906 15-15-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03408, current rewards: 173.61603, mean: 0.10459
[32m[0906 15-15-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03408, current rewards: 177.17643, mean: 0.10361
[32m[0906 15-15-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03409, current rewards: 182.61609, mean: 0.10376
[32m[0906 15-15-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03411, current rewards: 188.22797, mean: 0.10399
[32m[0906 15-15-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03414, current rewards: 193.88165, mean: 0.10424
[32m[0906 15-15-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03418, current rewards: 199.54036, mean: 0.10447
[32m[0906 15-15-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03421, current rewards: 205.19750, mean: 0.10469
[32m[0906 15-15-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03423, current rewards: 210.84714, mean: 0.10490
[32m[0906 15-15-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03426, current rewards: 216.50515, mean: 0.10510
[32m[0906 15-15-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03427, current rewards: 222.20281, mean: 0.10531
[32m[0906 15-15-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03427, current rewards: 227.96949, mean: 0.10554
[32m[0906 15-15-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03427, current rewards: 233.91441, mean: 0.10584
[32m[0906 15-15-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03427, current rewards: 239.64622, mean: 0.10604
[32m[0906 15-15-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03427, current rewards: 245.38123, mean: 0.10623
[32m[0906 15-15-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03427, current rewards: 251.11379, mean: 0.10640
[32m[0906 15-15-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03426, current rewards: 256.84398, mean: 0.10657
[32m[0906 15-15-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03427, current rewards: 260.33204, mean: 0.10583
[32m[0906 15-15-54 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 15-15-54 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-15-54 @MBExp.py:227][0m Rewards obtained: [264.80590445094555], Lows: [6], Highs: [4], Total time: 3776.1420289999996
[32m[0906 15-17-24 @MBExp.py:144][0m ####################################################################
[32m[0906 15-17-24 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 15-17-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03312, current rewards: -1.17370, mean: -0.11737
[32m[0906 15-17-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03388, current rewards: 4.09579, mean: 0.06826
[32m[0906 15-17-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03404, current rewards: 9.22315, mean: 0.08385
[32m[0906 15-17-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03409, current rewards: 14.62265, mean: 0.09139
[32m[0906 15-17-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03415, current rewards: 20.06257, mean: 0.09554
[32m[0906 15-17-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03420, current rewards: 25.49600, mean: 0.09806
[32m[0906 15-17-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03421, current rewards: 30.93049, mean: 0.09978
[32m[0906 15-17-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03422, current rewards: 36.37490, mean: 0.10104
[32m[0906 15-17-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03424, current rewards: 41.81643, mean: 0.10199
[32m[0906 15-17-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03425, current rewards: 45.25465, mean: 0.09838
[32m[0906 15-17-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03424, current rewards: 50.85672, mean: 0.09972
[32m[0906 15-17-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03424, current rewards: 56.51910, mean: 0.10093
[32m[0906 15-17-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03425, current rewards: 62.12745, mean: 0.10185
[32m[0906 15-17-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03425, current rewards: 67.73401, mean: 0.10263
[32m[0906 15-17-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03427, current rewards: 73.34365, mean: 0.10330
[32m[0906 15-17-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03428, current rewards: 78.95278, mean: 0.10389
[32m[0906 15-17-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03428, current rewards: 83.41643, mean: 0.10298
[32m[0906 15-17-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03429, current rewards: 88.85617, mean: 0.10332
[32m[0906 15-17-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03427, current rewards: 94.24793, mean: 0.10357
[32m[0906 15-17-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03427, current rewards: 99.65284, mean: 0.10381
[32m[0906 15-17-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03428, current rewards: 105.03582, mean: 0.10400
[32m[0906 15-18-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03428, current rewards: 110.45170, mean: 0.10420
[32m[0906 15-18-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03424, current rewards: 115.83921, mean: 0.10436
[32m[0906 15-18-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03421, current rewards: 121.25996, mean: 0.10453
[32m[0906 15-18-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03419, current rewards: 126.65354, mean: 0.10467
[32m[0906 15-18-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03416, current rewards: 132.05668, mean: 0.10481
[32m[0906 15-18-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03414, current rewards: 137.44603, mean: 0.10492
[32m[0906 15-18-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03412, current rewards: 138.94903, mean: 0.10217
[32m[0906 15-18-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03409, current rewards: 144.62978, mean: 0.10257
[32m[0906 15-18-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03406, current rewards: 150.30267, mean: 0.10295
[32m[0906 15-18-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03404, current rewards: 155.97395, mean: 0.10329
[32m[0906 15-18-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03403, current rewards: 161.64835, mean: 0.10362
[32m[0906 15-18-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03402, current rewards: 167.32747, mean: 0.10393
[32m[0906 15-18-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03402, current rewards: 171.79523, mean: 0.10349
[32m[0906 15-18-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03403, current rewards: 177.25966, mean: 0.10366
[32m[0906 15-18-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03403, current rewards: 182.70619, mean: 0.10381
[32m[0906 15-18-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03404, current rewards: 188.16930, mean: 0.10396
[32m[0906 15-18-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03407, current rewards: 193.63020, mean: 0.10410
[32m[0906 15-18-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03410, current rewards: 199.08909, mean: 0.10424
[32m[0906 15-18-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03412, current rewards: 204.54800, mean: 0.10436
[32m[0906 15-18-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03414, current rewards: 210.00125, mean: 0.10448
[32m[0906 15-18-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03417, current rewards: 213.41859, mean: 0.10360
[32m[0906 15-18-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03418, current rewards: 218.98739, mean: 0.10379
[32m[0906 15-18-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03418, current rewards: 224.60626, mean: 0.10398
[32m[0906 15-18-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03418, current rewards: 230.16398, mean: 0.10415
[32m[0906 15-18-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03418, current rewards: 235.72153, mean: 0.10430
[32m[0906 15-18-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03418, current rewards: 241.27988, mean: 0.10445
[32m[0906 15-18-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03418, current rewards: 246.83729, mean: 0.10459
[32m[0906 15-18-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03418, current rewards: 252.39378, mean: 0.10473
[32m[0906 15-18-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03420, current rewards: 256.58896, mean: 0.10430
[32m[0906 15-18-50 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-18-50 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-18-50 @MBExp.py:227][0m Rewards obtained: [260.80304038494273], Lows: [4], Highs: [5], Total time: 3862.292052
[32m[0906 15-20-22 @MBExp.py:144][0m ####################################################################
[32m[0906 15-20-22 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 15-20-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03330, current rewards: -1.11111, mean: -0.11111
[32m[0906 15-20-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03396, current rewards: 4.50464, mean: 0.07508
[32m[0906 15-20-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03413, current rewards: 10.03036, mean: 0.09119
[32m[0906 15-20-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03421, current rewards: 15.58782, mean: 0.09742
[32m[0906 15-20-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03423, current rewards: 21.15252, mean: 0.10073
[32m[0906 15-20-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03423, current rewards: 26.71268, mean: 0.10274
[32m[0906 15-20-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03423, current rewards: 32.27220, mean: 0.10410
[32m[0906 15-20-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03421, current rewards: 37.84601, mean: 0.10513
[32m[0906 15-20-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03421, current rewards: 43.42971, mean: 0.10593
[32m[0906 15-20-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03423, current rewards: 49.00590, mean: 0.10653
[32m[0906 15-20-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03424, current rewards: 54.44032, mean: 0.10675
[32m[0906 15-20-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03425, current rewards: 60.05098, mean: 0.10723
[32m[0906 15-20-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03425, current rewards: 65.66078, mean: 0.10764
[32m[0906 15-20-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03423, current rewards: 71.27772, mean: 0.10800
[32m[0906 15-20-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03423, current rewards: 76.89510, mean: 0.10830
[32m[0906 15-20-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03423, current rewards: 82.50346, mean: 0.10856
[32m[0906 15-20-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03422, current rewards: 88.11104, mean: 0.10878
[32m[0906 15-20-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03423, current rewards: 93.71850, mean: 0.10897
[32m[0906 15-20-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03423, current rewards: 99.34440, mean: 0.10917
[32m[0906 15-20-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03423, current rewards: 104.95688, mean: 0.10933
[32m[0906 15-20-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03424, current rewards: 108.37316, mean: 0.10730
[32m[0906 15-20-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03423, current rewards: 113.90863, mean: 0.10746
[32m[0906 15-21-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03419, current rewards: 119.44094, mean: 0.10760
[32m[0906 15-21-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03416, current rewards: 124.97228, mean: 0.10773
[32m[0906 15-21-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03413, current rewards: 130.49870, mean: 0.10785
[32m[0906 15-21-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03411, current rewards: 136.03387, mean: 0.10796
[32m[0906 15-21-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03409, current rewards: 141.74519, mean: 0.10820
[32m[0906 15-21-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03407, current rewards: 147.30486, mean: 0.10831
[32m[0906 15-21-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03405, current rewards: 152.86536, mean: 0.10842
[32m[0906 15-21-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03402, current rewards: 156.54808, mean: 0.10722
[32m[0906 15-21-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03400, current rewards: 162.07728, mean: 0.10734
[32m[0906 15-21-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03398, current rewards: 167.60257, mean: 0.10744
[32m[0906 15-21-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03398, current rewards: 173.12938, mean: 0.10753
[32m[0906 15-21-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03399, current rewards: 178.65749, mean: 0.10762
[32m[0906 15-21-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03399, current rewards: 184.15294, mean: 0.10769
[32m[0906 15-21-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03401, current rewards: 189.53634, mean: 0.10769
[32m[0906 15-21-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03401, current rewards: 195.03176, mean: 0.10775
[32m[0906 15-21-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03402, current rewards: 199.39346, mean: 0.10720
[32m[0906 15-21-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03404, current rewards: 204.91706, mean: 0.10729
[32m[0906 15-21-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03407, current rewards: 210.43284, mean: 0.10736
[32m[0906 15-21-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03409, current rewards: 215.95688, mean: 0.10744
[32m[0906 15-21-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03412, current rewards: 221.47668, mean: 0.10751
[32m[0906 15-21-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03413, current rewards: 226.99600, mean: 0.10758
[32m[0906 15-21-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03413, current rewards: 232.49544, mean: 0.10764
[32m[0906 15-21-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03413, current rewards: 238.00782, mean: 0.10770
[32m[0906 15-21-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03414, current rewards: 243.51958, mean: 0.10775
[32m[0906 15-21-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03414, current rewards: 249.03235, mean: 0.10781
[32m[0906 15-21-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03414, current rewards: 254.54451, mean: 0.10786
[32m[0906 15-21-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03415, current rewards: 260.05996, mean: 0.10791
[32m[0906 15-21-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03415, current rewards: 265.57479, mean: 0.10796
[32m[0906 15-21-48 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-21-48 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-21-48 @MBExp.py:227][0m Rewards obtained: [269.984375432019], Lows: [2], Highs: [3], Total time: 3948.341345
[32m[0906 15-23-22 @MBExp.py:144][0m ####################################################################
[32m[0906 15-23-22 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 15-23-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03328, current rewards: -1.14953, mean: -0.11495
[32m[0906 15-23-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03413, current rewards: 4.43224, mean: 0.07387
[32m[0906 15-23-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03426, current rewards: 9.97779, mean: 0.09071
[32m[0906 15-23-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03430, current rewards: 15.52554, mean: 0.09703
[32m[0906 15-23-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03428, current rewards: 21.06685, mean: 0.10032
[32m[0906 15-23-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03425, current rewards: 26.61425, mean: 0.10236
[32m[0906 15-23-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03425, current rewards: 32.15902, mean: 0.10374
[32m[0906 15-23-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03429, current rewards: 37.69603, mean: 0.10471
[32m[0906 15-23-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03431, current rewards: 43.24425, mean: 0.10547
[32m[0906 15-23-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03432, current rewards: 48.82489, mean: 0.10614
[32m[0906 15-23-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03432, current rewards: 54.37430, mean: 0.10662
[32m[0906 15-23-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03433, current rewards: 59.92459, mean: 0.10701
[32m[0906 15-23-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03433, current rewards: 65.82780, mean: 0.10791
[32m[0906 15-23-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03432, current rewards: 72.04545, mean: 0.10916
[32m[0906 15-23-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03434, current rewards: 78.26058, mean: 0.11023
[32m[0906 15-23-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03434, current rewards: 84.46349, mean: 0.11114
[32m[0906 15-23-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03433, current rewards: 90.67368, mean: 0.11194
[32m[0906 15-23-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03432, current rewards: 96.92759, mean: 0.11271
[32m[0906 15-23-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03432, current rewards: 103.13142, mean: 0.11333
[32m[0906 15-23-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03432, current rewards: 109.31741, mean: 0.11387
[32m[0906 15-23-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03432, current rewards: 115.51210, mean: 0.11437
[32m[0906 15-23-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03431, current rewards: 121.71388, mean: 0.11482
[32m[0906 15-24-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03427, current rewards: 127.91328, mean: 0.11524
[32m[0906 15-24-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03423, current rewards: 134.11869, mean: 0.11562
[32m[0906 15-24-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03421, current rewards: 140.30813, mean: 0.11596
[32m[0906 15-24-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03418, current rewards: 146.69684, mean: 0.11643
[32m[0906 15-24-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03415, current rewards: 152.64940, mean: 0.11653
[32m[0906 15-24-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03413, current rewards: 158.51722, mean: 0.11656
[32m[0906 15-24-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03411, current rewards: 164.37049, mean: 0.11657
[32m[0906 15-24-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03408, current rewards: 170.22778, mean: 0.11659
[32m[0906 15-24-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03406, current rewards: 176.08492, mean: 0.11661
[32m[0906 15-24-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03403, current rewards: 181.94189, mean: 0.11663
[32m[0906 15-24-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03402, current rewards: 187.79781, mean: 0.11664
[32m[0906 15-24-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03403, current rewards: 191.47715, mean: 0.11535
[32m[0906 15-24-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03404, current rewards: 196.99839, mean: 0.11520
[32m[0906 15-24-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03404, current rewards: 202.51784, mean: 0.11507
[32m[0906 15-24-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03406, current rewards: 208.03597, mean: 0.11494
[32m[0906 15-24-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03407, current rewards: 213.55844, mean: 0.11482
[32m[0906 15-24-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03407, current rewards: 219.07837, mean: 0.11470
[32m[0906 15-24-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03408, current rewards: 224.59913, mean: 0.11459
[32m[0906 15-24-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03412, current rewards: 230.11556, mean: 0.11449
[32m[0906 15-24-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03415, current rewards: 235.56895, mean: 0.11435
[32m[0906 15-24-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03416, current rewards: 239.00495, mean: 0.11327
[32m[0906 15-24-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03417, current rewards: 244.48622, mean: 0.11319
[32m[0906 15-24-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03418, current rewards: 249.95842, mean: 0.11310
[32m[0906 15-24-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03418, current rewards: 255.42908, mean: 0.11302
[32m[0906 15-24-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03419, current rewards: 260.90196, mean: 0.11294
[32m[0906 15-24-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03419, current rewards: 266.37124, mean: 0.11287
[32m[0906 15-24-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03419, current rewards: 271.84299, mean: 0.11280
[32m[0906 15-24-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03419, current rewards: 277.31525, mean: 0.11273
[32m[0906 15-24-48 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-24-48 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-24-48 @MBExp.py:227][0m Rewards obtained: [281.541864251244], Lows: [2], Highs: [2], Total time: 4034.496745
[32m[0906 15-26-24 @MBExp.py:144][0m ####################################################################
[32m[0906 15-26-24 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 15-26-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03340, current rewards: 0.00624, mean: 0.00062
[32m[0906 15-26-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03425, current rewards: 5.49134, mean: 0.09152
[32m[0906 15-26-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03430, current rewards: 10.97465, mean: 0.09977
[32m[0906 15-26-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03430, current rewards: 16.46258, mean: 0.10289
[32m[0906 15-26-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03427, current rewards: 21.94189, mean: 0.10449
[32m[0906 15-26-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03427, current rewards: 27.42185, mean: 0.10547
[32m[0906 15-26-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03427, current rewards: 32.90188, mean: 0.10614
[32m[0906 15-26-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03430, current rewards: 38.38902, mean: 0.10664
[32m[0906 15-26-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03433, current rewards: 43.77488, mean: 0.10677
[32m[0906 15-26-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03433, current rewards: 49.20912, mean: 0.10698
[32m[0906 15-26-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03433, current rewards: 52.65379, mean: 0.10324
[32m[0906 15-26-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03433, current rewards: 58.28400, mean: 0.10408
[32m[0906 15-26-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03433, current rewards: 63.91421, mean: 0.10478
[32m[0906 15-26-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03433, current rewards: 69.54103, mean: 0.10537
[32m[0906 15-26-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03433, current rewards: 75.17219, mean: 0.10588
[32m[0906 15-26-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03432, current rewards: 80.79964, mean: 0.10632
[32m[0906 15-26-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03434, current rewards: 86.69795, mean: 0.10703
[32m[0906 15-26-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03434, current rewards: 92.47106, mean: 0.10752
[32m[0906 15-26-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03435, current rewards: 98.11576, mean: 0.10782
[32m[0906 15-26-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03435, current rewards: 103.75792, mean: 0.10808
[32m[0906 15-26-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03434, current rewards: 109.40071, mean: 0.10832
[32m[0906 15-27-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03432, current rewards: 115.04559, mean: 0.10853
[32m[0906 15-27-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03428, current rewards: 119.02699, mean: 0.10723
[32m[0906 15-27-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03424, current rewards: 127.35750, mean: 0.10979
[32m[0906 15-27-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03421, current rewards: 135.65763, mean: 0.11211
[32m[0906 15-27-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03418, current rewards: 143.95776, mean: 0.11425
[32m[0906 15-27-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03415, current rewards: 152.25788, mean: 0.11623
[32m[0906 15-27-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03413, current rewards: 160.55800, mean: 0.11806
[32m[0906 15-27-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03410, current rewards: 116.38801, mean: 0.08254
[32m[0906 15-27-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03409, current rewards: 66.38801, mean: 0.04547
[32m[0906 15-27-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03407, current rewards: 16.38801, mean: 0.01085
[32m[0906 15-27-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03405, current rewards: -33.61199, mean: -0.02155
[32m[0906 15-27-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03405, current rewards: -83.61199, mean: -0.05193
[32m[0906 15-27-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03406, current rewards: -133.61199, mean: -0.08049
[32m[0906 15-27-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03407, current rewards: -183.61199, mean: -0.10738
[32m[0906 15-27-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03409, current rewards: -233.61199, mean: -0.13273
[32m[0906 15-27-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03410, current rewards: -283.61199, mean: -0.15669
[32m[0906 15-27-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03410, current rewards: -333.61199, mean: -0.17936
[32m[0906 15-27-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03411, current rewards: -383.61199, mean: -0.20084
[32m[0906 15-27-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03412, current rewards: -433.61199, mean: -0.22123
[32m[0906 15-27-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03414, current rewards: -483.61199, mean: -0.24060
[32m[0906 15-27-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03417, current rewards: -533.61199, mean: -0.25903
[32m[0906 15-27-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03418, current rewards: -583.61199, mean: -0.27659
[32m[0906 15-27-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03418, current rewards: -633.61199, mean: -0.29334
[32m[0906 15-27-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03418, current rewards: -683.61199, mean: -0.30933
[32m[0906 15-27-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03418, current rewards: -733.61199, mean: -0.32461
[32m[0906 15-27-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03419, current rewards: -783.61199, mean: -0.33923
[32m[0906 15-27-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03419, current rewards: -833.61199, mean: -0.35323
[32m[0906 15-27-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03419, current rewards: -883.61199, mean: -0.36664
[32m[0906 15-27-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03419, current rewards: -933.61199, mean: -0.37952
[32m[0906 15-27-50 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-27-50 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-27-50 @MBExp.py:227][0m Rewards obtained: [-973.6119901307592], Lows: [2], Highs: [1136], Total time: 4120.645097
[32m[0906 15-29-29 @MBExp.py:144][0m ####################################################################
[32m[0906 15-29-29 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 15-29-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03342, current rewards: -0.03352, mean: -0.00335
[32m[0906 15-29-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03422, current rewards: 5.36986, mean: 0.08950
[32m[0906 15-29-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03426, current rewards: 10.78817, mean: 0.09807
[32m[0906 15-29-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03423, current rewards: 16.20712, mean: 0.10129
[32m[0906 15-29-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03426, current rewards: 21.62830, mean: 0.10299
[32m[0906 15-29-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03426, current rewards: 27.04931, mean: 0.10404
[32m[0906 15-29-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03426, current rewards: 32.47234, mean: 0.10475
[32m[0906 15-29-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03428, current rewards: 37.89564, mean: 0.10527
[32m[0906 15-29-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03430, current rewards: 43.23207, mean: 0.10544
[32m[0906 15-29-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03432, current rewards: 48.61459, mean: 0.10568
[32m[0906 15-29-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03432, current rewards: 53.99903, mean: 0.10588
[32m[0906 15-29-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03434, current rewards: 57.31062, mean: 0.10234
[32m[0906 15-29-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03433, current rewards: 62.99181, mean: 0.10327
[32m[0906 15-29-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03433, current rewards: 68.67036, mean: 0.10405
[32m[0906 15-29-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03433, current rewards: 74.35485, mean: 0.10473
[32m[0906 15-29-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03434, current rewards: 80.03589, mean: 0.10531
[32m[0906 15-29-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03433, current rewards: 86.04244, mean: 0.10623
[32m[0906 15-29-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03433, current rewards: 91.72861, mean: 0.10666
[32m[0906 15-30-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03433, current rewards: 93.14230, mean: 0.10235
[32m[0906 15-30-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03435, current rewards: 98.74450, mean: 0.10286
[32m[0906 15-30-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03436, current rewards: 104.34624, mean: 0.10331
[32m[0906 15-30-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03432, current rewards: 109.95302, mean: 0.10373
[32m[0906 15-30-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03428, current rewards: 115.55987, mean: 0.10411
[32m[0906 15-30-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03426, current rewards: 121.16513, mean: 0.10445
[32m[0906 15-30-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03422, current rewards: 126.73186, mean: 0.10474
[32m[0906 15-30-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03420, current rewards: 132.29190, mean: 0.10499
[32m[0906 15-30-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03416, current rewards: 135.80409, mean: 0.10367
[32m[0906 15-30-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03415, current rewards: 141.59046, mean: 0.10411
[32m[0906 15-30-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03413, current rewards: 147.18996, mean: 0.10439
[32m[0906 15-30-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03411, current rewards: 152.78832, mean: 0.10465
[32m[0906 15-30-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03408, current rewards: 158.38522, mean: 0.10489
[32m[0906 15-30-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03407, current rewards: 163.98539, mean: 0.10512
[32m[0906 15-30-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03407, current rewards: 169.58361, mean: 0.10533
[32m[0906 15-30-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03409, current rewards: 175.22124, mean: 0.10555
[32m[0906 15-30-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03409, current rewards: 180.82176, mean: 0.10574
[32m[0906 15-30-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03410, current rewards: 186.42278, mean: 0.10592
[32m[0906 15-30-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03411, current rewards: 190.76386, mean: 0.10539
[32m[0906 15-30-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03412, current rewards: 196.22008, mean: 0.10549
[32m[0906 15-30-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03413, current rewards: 201.68065, mean: 0.10559
[32m[0906 15-30-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03413, current rewards: 207.13850, mean: 0.10568
[32m[0906 15-30-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03414, current rewards: 212.59301, mean: 0.10577
[32m[0906 15-30-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03415, current rewards: 218.06517, mean: 0.10586
[32m[0906 15-30-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03418, current rewards: 222.39623, mean: 0.10540
[32m[0906 15-30-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03419, current rewards: 227.50310, mean: 0.10533
[32m[0906 15-30-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03419, current rewards: 232.59592, mean: 0.10525
[32m[0906 15-30-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03420, current rewards: 237.68859, mean: 0.10517
[32m[0906 15-30-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03420, current rewards: 242.77615, mean: 0.10510
[32m[0906 15-30-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03420, current rewards: 247.86917, mean: 0.10503
[32m[0906 15-30-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03420, current rewards: 252.96637, mean: 0.10497
[32m[0906 15-30-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03421, current rewards: 258.13637, mean: 0.10493
[32m[0906 15-30-55 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-30-55 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-30-55 @MBExp.py:227][0m Rewards obtained: [262.1966698298421], Lows: [4], Highs: [3], Total time: 4206.836574
[32m[0906 15-32-35 @MBExp.py:144][0m ####################################################################
[32m[0906 15-32-35 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 15-32-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03337, current rewards: 1.04950, mean: 0.10495
[32m[0906 15-32-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03419, current rewards: 6.68730, mean: 0.11145
[32m[0906 15-32-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03423, current rewards: 12.27525, mean: 0.11159
[32m[0906 15-32-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03427, current rewards: 17.86342, mean: 0.11165
[32m[0906 15-32-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03431, current rewards: 23.45425, mean: 0.11169
[32m[0906 15-32-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03433, current rewards: 26.92096, mean: 0.10354
[32m[0906 15-32-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03431, current rewards: 32.30985, mean: 0.10423
[32m[0906 15-32-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03432, current rewards: 37.63202, mean: 0.10453
[32m[0906 15-32-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03434, current rewards: 42.97948, mean: 0.10483
[32m[0906 15-32-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03434, current rewards: 48.33235, mean: 0.10507
[32m[0906 15-32-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03434, current rewards: 53.69148, mean: 0.10528
[32m[0906 15-32-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03433, current rewards: 57.12787, mean: 0.10201
[32m[0906 15-32-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03431, current rewards: 62.62419, mean: 0.10266
[32m[0906 15-32-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03433, current rewards: 68.11850, mean: 0.10321
[32m[0906 15-32-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03434, current rewards: 73.61279, mean: 0.10368
[32m[0906 15-33-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03436, current rewards: 79.10431, mean: 0.10408
[32m[0906 15-33-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03435, current rewards: 84.60101, mean: 0.10445
[32m[0906 15-33-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03437, current rewards: 90.09523, mean: 0.10476
[32m[0906 15-33-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03436, current rewards: 95.58449, mean: 0.10504
[32m[0906 15-33-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03435, current rewards: 96.85646, mean: 0.10089
[32m[0906 15-33-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03436, current rewards: 102.37755, mean: 0.10136
[32m[0906 15-33-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03431, current rewards: 107.89119, mean: 0.10178
[32m[0906 15-33-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03428, current rewards: 113.40769, mean: 0.10217
[32m[0906 15-33-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03425, current rewards: 118.99704, mean: 0.10258
[32m[0906 15-33-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03421, current rewards: 124.48599, mean: 0.10288
[32m[0906 15-33-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03418, current rewards: 129.97709, mean: 0.10316
[32m[0906 15-33-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03415, current rewards: 135.47034, mean: 0.10341
[32m[0906 15-33-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03412, current rewards: 140.96443, mean: 0.10365
[32m[0906 15-33-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03410, current rewards: 146.45322, mean: 0.10387
[32m[0906 15-33-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03407, current rewards: 151.94409, mean: 0.10407
[32m[0906 15-33-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03405, current rewards: 156.32949, mean: 0.10353
[32m[0906 15-33-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03404, current rewards: 161.71992, mean: 0.10367
[32m[0906 15-33-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03405, current rewards: 167.11316, mean: 0.10380
[32m[0906 15-33-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03405, current rewards: 172.50715, mean: 0.10392
[32m[0906 15-33-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03406, current rewards: 177.89588, mean: 0.10403
[32m[0906 15-33-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03407, current rewards: 183.28506, mean: 0.10414
[32m[0906 15-33-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03407, current rewards: 188.67981, mean: 0.10424
[32m[0906 15-33-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03408, current rewards: 194.07181, mean: 0.10434
[32m[0906 15-33-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03409, current rewards: 198.01347, mean: 0.10367
[32m[0906 15-33-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03411, current rewards: 203.60467, mean: 0.10388
[32m[0906 15-33-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03411, current rewards: 209.21188, mean: 0.10409
[32m[0906 15-33-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03412, current rewards: 214.79682, mean: 0.10427
[32m[0906 15-33-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03413, current rewards: 220.38643, mean: 0.10445
[32m[0906 15-33-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03414, current rewards: 225.97273, mean: 0.10462
[32m[0906 15-33-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03415, current rewards: 230.86867, mean: 0.10447
[32m[0906 15-33-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03415, current rewards: 236.25940, mean: 0.10454
[32m[0906 15-33-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03415, current rewards: 241.64050, mean: 0.10461
[32m[0906 15-33-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03416, current rewards: 247.03264, mean: 0.10467
[32m[0906 15-33-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03417, current rewards: 252.24206, mean: 0.10466
[32m[0906 15-34-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03417, current rewards: 257.56557, mean: 0.10470
[32m[0906 15-34-01 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-34-01 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-34-01 @MBExp.py:227][0m Rewards obtained: [261.81802128618875], Lows: [4], Highs: [4], Total time: 4292.95061
[32m[0906 15-35-43 @MBExp.py:144][0m ####################################################################
[32m[0906 15-35-43 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 15-35-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03302, current rewards: -1.08309, mean: -0.10831
[32m[0906 15-35-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03396, current rewards: 4.52726, mean: 0.07545
[32m[0906 15-35-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03413, current rewards: 10.13696, mean: 0.09215
[32m[0906 15-35-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03424, current rewards: 15.75075, mean: 0.09844
[32m[0906 15-35-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03428, current rewards: 21.30242, mean: 0.10144
[32m[0906 15-35-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03431, current rewards: 26.89746, mean: 0.10345
[32m[0906 15-35-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03431, current rewards: 32.33499, mean: 0.10431
[32m[0906 15-35-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03431, current rewards: 37.94017, mean: 0.10539
[32m[0906 15-35-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03431, current rewards: 43.53676, mean: 0.10619
[32m[0906 15-35-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03431, current rewards: 49.13169, mean: 0.10681
[32m[0906 15-36-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03430, current rewards: 54.72730, mean: 0.10731
[32m[0906 15-36-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03429, current rewards: 60.33107, mean: 0.10773
[32m[0906 15-36-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03429, current rewards: 65.93597, mean: 0.10809
[32m[0906 15-36-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03431, current rewards: 71.53462, mean: 0.10839
[32m[0906 15-36-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03431, current rewards: 77.18147, mean: 0.10871
[32m[0906 15-36-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03432, current rewards: 82.78787, mean: 0.10893
[32m[0906 15-36-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03432, current rewards: 86.25515, mean: 0.10649
[32m[0906 15-36-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03432, current rewards: 91.86632, mean: 0.10682
[32m[0906 15-36-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03431, current rewards: 97.48299, mean: 0.10712
[32m[0906 15-36-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03430, current rewards: 103.09694, mean: 0.10739
[32m[0906 15-36-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03427, current rewards: 108.70923, mean: 0.10763
[32m[0906 15-36-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03423, current rewards: 114.32446, mean: 0.10785
[32m[0906 15-36-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03420, current rewards: 120.01546, mean: 0.10812
[32m[0906 15-36-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03418, current rewards: 126.98019, mean: 0.10947
[32m[0906 15-36-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03415, current rewards: 134.25441, mean: 0.11095
[32m[0906 15-36-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03411, current rewards: 141.52862, mean: 0.11232
[32m[0906 15-36-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03409, current rewards: 148.80283, mean: 0.11359
[32m[0906 15-36-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03406, current rewards: 111.40316, mean: 0.08191
[32m[0906 15-36-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03404, current rewards: 61.40316, mean: 0.04355
[32m[0906 15-36-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03403, current rewards: 11.40316, mean: 0.00781
[32m[0906 15-36-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03401, current rewards: -38.59684, mean: -0.02556
[32m[0906 15-36-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03400, current rewards: -88.59684, mean: -0.05679
[32m[0906 15-36-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03401, current rewards: -138.59684, mean: -0.08608
[32m[0906 15-36-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03401, current rewards: -188.59684, mean: -0.11361
[32m[0906 15-36-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03402, current rewards: -238.59684, mean: -0.13953
[32m[0906 15-36-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03403, current rewards: -288.59684, mean: -0.16398
[32m[0906 15-36-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03404, current rewards: -338.59684, mean: -0.18707
[32m[0906 15-36-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03405, current rewards: -388.59684, mean: -0.20892
[32m[0906 15-36-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03406, current rewards: -438.59684, mean: -0.22963
[32m[0906 15-36-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03407, current rewards: -488.59684, mean: -0.24928
[32m[0906 15-36-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03407, current rewards: -538.59684, mean: -0.26796
[32m[0906 15-36-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03407, current rewards: -588.59684, mean: -0.28573
[32m[0906 15-36-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03408, current rewards: -638.59684, mean: -0.30265
[32m[0906 15-36-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03408, current rewards: -688.59684, mean: -0.31879
[32m[0906 15-36-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03408, current rewards: -738.59684, mean: -0.33421
[32m[0906 15-37-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03409, current rewards: -788.59684, mean: -0.34894
[32m[0906 15-37-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03410, current rewards: -838.59684, mean: -0.36303
[32m[0906 15-37-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03410, current rewards: -888.59684, mean: -0.37652
[32m[0906 15-37-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03411, current rewards: -938.59684, mean: -0.38946
[32m[0906 15-37-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03411, current rewards: -988.59684, mean: -0.40187
[32m[0906 15-37-09 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-37-09 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-37-09 @MBExp.py:227][0m Rewards obtained: [-1028.5968386486797], Lows: [1], Highs: [1181], Total time: 4378.951098
[32m[0906 15-38-54 @MBExp.py:144][0m ####################################################################
[32m[0906 15-38-54 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 15-38-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03355, current rewards: -0.01018, mean: -0.00102
[32m[0906 15-38-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03414, current rewards: 5.76963, mean: 0.09616
[32m[0906 15-38-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03426, current rewards: 11.55741, mean: 0.10507
[32m[0906 15-38-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03431, current rewards: 17.34166, mean: 0.10839
[32m[0906 15-39-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03434, current rewards: 23.12491, mean: 0.11012
[32m[0906 15-39-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03432, current rewards: 28.91107, mean: 0.11120
[32m[0906 15-39-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03432, current rewards: 35.01195, mean: 0.11294
[32m[0906 15-39-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03433, current rewards: 40.80024, mean: 0.11333
[32m[0906 15-39-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03431, current rewards: 46.54806, mean: 0.11353
[32m[0906 15-39-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03431, current rewards: 52.30142, mean: 0.11370
[32m[0906 15-39-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03430, current rewards: 58.04917, mean: 0.11382
[32m[0906 15-39-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03432, current rewards: 62.61812, mean: 0.11182
[32m[0906 15-39-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03432, current rewards: 68.16595, mean: 0.11175
[32m[0906 15-39-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03431, current rewards: 73.71130, mean: 0.11168
[32m[0906 15-39-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03431, current rewards: 79.25580, mean: 0.11163
[32m[0906 15-39-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03432, current rewards: 84.68319, mean: 0.11143
[32m[0906 15-39-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03433, current rewards: 90.25060, mean: 0.11142
[32m[0906 15-39-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03434, current rewards: 95.81416, mean: 0.11141
[32m[0906 15-39-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03434, current rewards: 99.27298, mean: 0.10909
[32m[0906 15-39-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03435, current rewards: 104.91093, mean: 0.10928
[32m[0906 15-39-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03430, current rewards: 110.48029, mean: 0.10939
[32m[0906 15-39-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03426, current rewards: 116.04796, mean: 0.10948
[32m[0906 15-39-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03423, current rewards: 121.61981, mean: 0.10957
[32m[0906 15-39-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03419, current rewards: 127.31539, mean: 0.10975
[32m[0906 15-39-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03418, current rewards: 132.85340, mean: 0.10980
[32m[0906 15-39-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03415, current rewards: 137.61215, mean: 0.10922
[32m[0906 15-39-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03412, current rewards: 143.21595, mean: 0.10933
[32m[0906 15-39-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03410, current rewards: 148.82472, mean: 0.10943
[32m[0906 15-39-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03408, current rewards: 154.42751, mean: 0.10952
[32m[0906 15-39-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03406, current rewards: 160.03542, mean: 0.10961
[32m[0906 15-39-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03405, current rewards: 165.63787, mean: 0.10969
[32m[0906 15-39-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03405, current rewards: 172.06108, mean: 0.11030
[32m[0906 15-39-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03406, current rewards: 177.69053, mean: 0.11037
[32m[0906 15-39-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03407, current rewards: 183.31667, mean: 0.11043
[32m[0906 15-39-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03407, current rewards: 188.94467, mean: 0.11049
[32m[0906 15-39-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03409, current rewards: 194.57485, mean: 0.11055
[32m[0906 15-39-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03410, current rewards: 200.20603, mean: 0.11061
[32m[0906 15-39-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03411, current rewards: 203.74286, mean: 0.10954
[32m[0906 15-40-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03411, current rewards: 209.31147, mean: 0.10959
[32m[0906 15-40-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03412, current rewards: 214.87851, mean: 0.10963
[32m[0906 15-40-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03412, current rewards: 220.44758, mean: 0.10968
[32m[0906 15-40-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03413, current rewards: 226.01725, mean: 0.10972
[32m[0906 15-40-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03414, current rewards: 230.58058, mean: 0.10928
[32m[0906 15-40-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03412, current rewards: 236.32935, mean: 0.10941
[32m[0906 15-40-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03413, current rewards: 242.09201, mean: 0.10954
[32m[0906 15-40-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03413, current rewards: 247.84812, mean: 0.10967
[32m[0906 15-40-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03413, current rewards: 253.61258, mean: 0.10979
[32m[0906 15-40-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03414, current rewards: 259.52939, mean: 0.10997
[32m[0906 15-40-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03415, current rewards: 264.27474, mean: 0.10966
[32m[0906 15-40-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03415, current rewards: 269.92396, mean: 0.10973
[32m[0906 15-40-20 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-40-20 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-40-20 @MBExp.py:227][0m Rewards obtained: [274.4436695912743], Lows: [2], Highs: [5], Total time: 4464.993076999999
[32m[0906 15-42-06 @MBExp.py:144][0m ####################################################################
[32m[0906 15-42-06 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 15-42-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03366, current rewards: -0.05550, mean: -0.00555
[32m[0906 15-42-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03424, current rewards: 5.40943, mean: 0.09016
[32m[0906 15-42-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03423, current rewards: 10.87617, mean: 0.09887
[32m[0906 15-42-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03425, current rewards: 16.33991, mean: 0.10212
[32m[0906 15-42-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03424, current rewards: 21.80195, mean: 0.10382
[32m[0906 15-42-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03425, current rewards: 27.26843, mean: 0.10488
[32m[0906 15-42-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03423, current rewards: 32.68092, mean: 0.10542
[32m[0906 15-42-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03425, current rewards: 38.14303, mean: 0.10595
[32m[0906 15-42-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03427, current rewards: 43.60525, mean: 0.10635
[32m[0906 15-42-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03433, current rewards: 49.06277, mean: 0.10666
[32m[0906 15-42-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03432, current rewards: 54.52938, mean: 0.10692
[32m[0906 15-42-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03432, current rewards: 59.98815, mean: 0.10712
[32m[0906 15-42-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03435, current rewards: 62.55175, mean: 0.10254
[32m[0906 15-42-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03434, current rewards: 68.12485, mean: 0.10322
[32m[0906 15-42-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03435, current rewards: 73.69215, mean: 0.10379
[32m[0906 15-42-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03434, current rewards: 79.26245, mean: 0.10429
[32m[0906 15-42-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03435, current rewards: 84.83771, mean: 0.10474
[32m[0906 15-42-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03435, current rewards: 90.40820, mean: 0.10513
[32m[0906 15-42-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03436, current rewards: 95.98261, mean: 0.10548
[32m[0906 15-42-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03433, current rewards: 101.55348, mean: 0.10578
[32m[0906 15-42-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03428, current rewards: 107.12161, mean: 0.10606
[32m[0906 15-42-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03425, current rewards: 112.69328, mean: 0.10631
[32m[0906 15-42-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03422, current rewards: 118.23285, mean: 0.10652
[32m[0906 15-42-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03418, current rewards: 123.80844, mean: 0.10673
[32m[0906 15-42-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03416, current rewards: 129.39520, mean: 0.10694
[32m[0906 15-42-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03413, current rewards: 132.88990, mean: 0.10547
[32m[0906 15-42-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03410, current rewards: 138.52231, mean: 0.10574
[32m[0906 15-42-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03409, current rewards: 144.15942, mean: 0.10600
[32m[0906 15-42-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03406, current rewards: 149.79878, mean: 0.10624
[32m[0906 15-42-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03404, current rewards: 155.43673, mean: 0.10646
[32m[0906 15-42-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03401, current rewards: 161.07918, mean: 0.10667
[32m[0906 15-43-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03402, current rewards: 166.71888, mean: 0.10687
[32m[0906 15-43-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03402, current rewards: 172.35877, mean: 0.10706
[32m[0906 15-43-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03403, current rewards: 177.99466, mean: 0.10723
[32m[0906 15-43-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03404, current rewards: 183.63229, mean: 0.10739
[32m[0906 15-43-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03404, current rewards: 189.27082, mean: 0.10754
[32m[0906 15-43-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03405, current rewards: 192.19653, mean: 0.10619
[32m[0906 15-43-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03406, current rewards: 197.81211, mean: 0.10635
[32m[0906 15-43-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03407, current rewards: 203.69199, mean: 0.10665
[32m[0906 15-43-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03407, current rewards: 209.31992, mean: 0.10680
[32m[0906 15-43-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03408, current rewards: 214.94563, mean: 0.10694
[32m[0906 15-43-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03408, current rewards: 220.07907, mean: 0.10683
[32m[0906 15-43-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03409, current rewards: 227.73415, mean: 0.10793
[32m[0906 15-43-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03407, current rewards: 235.38923, mean: 0.10898
[32m[0906 15-43-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03406, current rewards: 243.04432, mean: 0.10997
[32m[0906 15-43-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03406, current rewards: 204.57533, mean: 0.09052
[32m[0906 15-43-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03407, current rewards: 154.57533, mean: 0.06692
[32m[0906 15-43-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03407, current rewards: 104.57533, mean: 0.04431
[32m[0906 15-43-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03407, current rewards: 54.57533, mean: 0.02265
[32m[0906 15-43-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03408, current rewards: 4.57533, mean: 0.00186
[32m[0906 15-43-32 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-43-32 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-43-32 @MBExp.py:227][0m Rewards obtained: [-35.42466833995121], Lows: [4], Highs: [283], Total time: 4550.890828
[32m[0906 15-45-21 @MBExp.py:144][0m ####################################################################
[32m[0906 15-45-21 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 15-45-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03389, current rewards: 0.07246, mean: 0.00725
[32m[0906 15-45-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03438, current rewards: 5.72476, mean: 0.09541
[32m[0906 15-45-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03437, current rewards: 11.37341, mean: 0.10339
[32m[0906 15-45-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03438, current rewards: 17.01859, mean: 0.10637
[32m[0906 15-45-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03434, current rewards: 22.66906, mean: 0.10795
[32m[0906 15-45-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03433, current rewards: 26.11820, mean: 0.10045
[32m[0906 15-45-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03436, current rewards: 31.71192, mean: 0.10230
[32m[0906 15-45-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03436, current rewards: 37.30538, mean: 0.10363
[32m[0906 15-45-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03436, current rewards: 42.89969, mean: 0.10463
[32m[0906 15-45-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03434, current rewards: 48.49534, mean: 0.10542
[32m[0906 15-45-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03436, current rewards: 54.09086, mean: 0.10606
[32m[0906 15-45-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03435, current rewards: 59.68113, mean: 0.10657
[32m[0906 15-45-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03434, current rewards: 65.26820, mean: 0.10700
[32m[0906 15-45-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03434, current rewards: 70.88743, mean: 0.10741
[32m[0906 15-45-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03432, current rewards: 76.47974, mean: 0.10772
[32m[0906 15-45-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03431, current rewards: 82.06999, mean: 0.10799
[32m[0906 15-45-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03432, current rewards: 87.65967, mean: 0.10822
[32m[0906 15-45-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03432, current rewards: 93.24750, mean: 0.10843
[32m[0906 15-45-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03432, current rewards: 98.83310, mean: 0.10861
[32m[0906 15-45-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03428, current rewards: 104.42111, mean: 0.10877
[32m[0906 15-45-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03424, current rewards: 110.01059, mean: 0.10892
[32m[0906 15-45-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03422, current rewards: 115.62550, mean: 0.10908
[32m[0906 15-45-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03418, current rewards: 121.36578, mean: 0.10934
[32m[0906 15-46-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03416, current rewards: 122.66501, mean: 0.10575
[32m[0906 15-46-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03413, current rewards: 128.15219, mean: 0.10591
[32m[0906 15-46-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03411, current rewards: 133.63757, mean: 0.10606
[32m[0906 15-46-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03408, current rewards: 139.12475, mean: 0.10620
[32m[0906 15-46-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03406, current rewards: 144.60885, mean: 0.10633
[32m[0906 15-46-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03403, current rewards: 149.06263, mean: 0.10572
[32m[0906 15-46-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03401, current rewards: 154.61234, mean: 0.10590
[32m[0906 15-46-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03400, current rewards: 160.20092, mean: 0.10609
[32m[0906 15-46-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03402, current rewards: 165.74998, mean: 0.10625
[32m[0906 15-46-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03403, current rewards: 171.30087, mean: 0.10640
[32m[0906 15-46-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03404, current rewards: 176.85685, mean: 0.10654
[32m[0906 15-46-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03404, current rewards: 182.41197, mean: 0.10667
[32m[0906 15-46-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03406, current rewards: 187.96273, mean: 0.10680
[32m[0906 15-46-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03407, current rewards: 193.51731, mean: 0.10692
[32m[0906 15-46-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03408, current rewards: 199.07351, mean: 0.10703
[32m[0906 15-46-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03409, current rewards: 202.81311, mean: 0.10618
[32m[0906 15-46-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03410, current rewards: 208.30677, mean: 0.10628
[32m[0906 15-46-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03411, current rewards: 213.80032, mean: 0.10637
[32m[0906 15-46-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03412, current rewards: 219.29406, mean: 0.10645
[32m[0906 15-46-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03412, current rewards: 224.78670, mean: 0.10653
[32m[0906 15-46-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03411, current rewards: 230.27987, mean: 0.10661
[32m[0906 15-46-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03409, current rewards: 235.77368, mean: 0.10668
[32m[0906 15-46-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03409, current rewards: 241.26749, mean: 0.10676
[32m[0906 15-46-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03409, current rewards: 246.54358, mean: 0.10673
[32m[0906 15-46-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03410, current rewards: 251.94781, mean: 0.10676
[32m[0906 15-46-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03411, current rewards: 252.55952, mean: 0.10480
[32m[0906 15-46-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03411, current rewards: 258.33110, mean: 0.10501
[32m[0906 15-46-47 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-46-47 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-46-47 @MBExp.py:227][0m Rewards obtained: [262.96098204348914], Lows: [6], Highs: [3], Total time: 4636.85772
[32m[0906 15-48-37 @MBExp.py:144][0m ####################################################################
[32m[0906 15-48-37 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 15-48-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03340, current rewards: -1.80072, mean: -0.18007
[32m[0906 15-48-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03396, current rewards: 3.64403, mean: 0.06073
[32m[0906 15-48-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03401, current rewards: 9.18099, mean: 0.08346
[32m[0906 15-48-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03405, current rewards: 14.71277, mean: 0.09195
[32m[0906 15-48-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03410, current rewards: 20.24626, mean: 0.09641
[32m[0906 15-48-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03415, current rewards: 25.89243, mean: 0.09959
[32m[0906 15-48-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03418, current rewards: 31.52139, mean: 0.10168
[32m[0906 15-48-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03420, current rewards: 37.15895, mean: 0.10322
[32m[0906 15-48-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03423, current rewards: 42.79005, mean: 0.10437
[32m[0906 15-48-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03428, current rewards: 46.39557, mean: 0.10086
[32m[0906 15-48-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03429, current rewards: 52.01646, mean: 0.10199
[32m[0906 15-48-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03429, current rewards: 57.63599, mean: 0.10292
[32m[0906 15-48-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03430, current rewards: 63.25760, mean: 0.10370
[32m[0906 15-49-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03430, current rewards: 68.80846, mean: 0.10426
[32m[0906 15-49-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03431, current rewards: 74.43446, mean: 0.10484
[32m[0906 15-49-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03432, current rewards: 80.06255, mean: 0.10535
[32m[0906 15-49-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03432, current rewards: 85.69383, mean: 0.10579
[32m[0906 15-49-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03432, current rewards: 91.32333, mean: 0.10619
[32m[0906 15-49-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03431, current rewards: 96.94946, mean: 0.10654
[32m[0906 15-49-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03427, current rewards: 102.57842, mean: 0.10685
[32m[0906 15-49-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03422, current rewards: 108.21034, mean: 0.10714
[32m[0906 15-49-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03418, current rewards: 113.92088, mean: 0.10747
[32m[0906 15-49-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03414, current rewards: 119.74258, mean: 0.10788
[32m[0906 15-49-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03411, current rewards: 125.33527, mean: 0.10805
[32m[0906 15-49-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03408, current rewards: 130.99852, mean: 0.10826
[32m[0906 15-49-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03405, current rewards: 137.24008, mean: 0.10892
[32m[0906 15-49-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03404, current rewards: 143.47630, mean: 0.10952
[32m[0906 15-49-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03401, current rewards: 149.71061, mean: 0.11008
[32m[0906 15-49-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03399, current rewards: 155.94345, mean: 0.11060
[32m[0906 15-49-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03398, current rewards: 162.17792, mean: 0.11108
[32m[0906 15-49-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03398, current rewards: 166.13121, mean: 0.11002
[32m[0906 15-49-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03400, current rewards: 171.79597, mean: 0.11013
[32m[0906 15-49-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03402, current rewards: 177.45761, mean: 0.11022
[32m[0906 15-49-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03403, current rewards: 183.11991, mean: 0.11031
[32m[0906 15-49-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03403, current rewards: 188.78323, mean: 0.11040
[32m[0906 15-49-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03404, current rewards: 194.44686, mean: 0.11048
[32m[0906 15-49-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03405, current rewards: 200.10678, mean: 0.11056
[32m[0906 15-49-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03407, current rewards: 203.78169, mean: 0.10956
[32m[0906 15-49-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03408, current rewards: 209.43438, mean: 0.10965
[32m[0906 15-49-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03408, current rewards: 215.08556, mean: 0.10974
[32m[0906 15-49-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03408, current rewards: 220.73432, mean: 0.10982
[32m[0906 15-49-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03409, current rewards: 226.38767, mean: 0.10990
[32m[0906 15-49-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03409, current rewards: 232.03626, mean: 0.10997
[32m[0906 15-49-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03408, current rewards: 237.68540, mean: 0.11004
[32m[0906 15-49-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03407, current rewards: 243.33161, mean: 0.11010
[32m[0906 15-49-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03406, current rewards: 248.98581, mean: 0.11017
[32m[0906 15-49-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03406, current rewards: 254.58812, mean: 0.11021
[32m[0906 15-49-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03407, current rewards: 260.21676, mean: 0.11026
[32m[0906 15-50-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03407, current rewards: 265.84812, mean: 0.11031
[32m[0906 15-50-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03408, current rewards: 271.47934, mean: 0.11036
[32m[0906 15-50-03 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-50-03 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-50-03 @MBExp.py:227][0m Rewards obtained: [273.9814878929238], Lows: [5], Highs: [2], Total time: 4722.744169
[32m[0906 15-51-55 @MBExp.py:144][0m ####################################################################
[32m[0906 15-51-55 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 15-51-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03412, current rewards: 0.41684, mean: 0.04168
[32m[0906 15-51-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03412, current rewards: 5.97283, mean: 0.09955
[32m[0906 15-51-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03421, current rewards: 11.53175, mean: 0.10483
[32m[0906 15-52-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03428, current rewards: 17.09481, mean: 0.10684
[32m[0906 15-52-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03425, current rewards: 22.65638, mean: 0.10789
[32m[0906 15-52-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03423, current rewards: 28.21911, mean: 0.10854
[32m[0906 15-52-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03421, current rewards: 33.78226, mean: 0.10898
[32m[0906 15-52-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03426, current rewards: 39.34171, mean: 0.10928
[32m[0906 15-52-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03427, current rewards: 44.90642, mean: 0.10953
[32m[0906 15-52-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03428, current rewards: 49.22530, mean: 0.10701
[32m[0906 15-52-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03430, current rewards: 54.59859, mean: 0.10706
[32m[0906 15-52-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03432, current rewards: 59.97453, mean: 0.10710
[32m[0906 15-52-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03433, current rewards: 65.33941, mean: 0.10711
[32m[0906 15-52-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03433, current rewards: 70.50507, mean: 0.10683
[32m[0906 15-52-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03433, current rewards: 75.89138, mean: 0.10689
[32m[0906 15-52-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03432, current rewards: 81.27121, mean: 0.10694
[32m[0906 15-52-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03432, current rewards: 86.64576, mean: 0.10697
[32m[0906 15-52-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03433, current rewards: 92.02242, mean: 0.10700
[32m[0906 15-52-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03429, current rewards: 97.39457, mean: 0.10703
[32m[0906 15-52-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03425, current rewards: 102.77592, mean: 0.10706
[32m[0906 15-52-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03423, current rewards: 108.14857, mean: 0.10708
[32m[0906 15-52-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03420, current rewards: 113.81658, mean: 0.10737
[32m[0906 15-52-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03416, current rewards: 119.36789, mean: 0.10754
[32m[0906 15-52-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03414, current rewards: 124.91200, mean: 0.10768
[32m[0906 15-52-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03412, current rewards: 130.46028, mean: 0.10782
[32m[0906 15-52-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03410, current rewards: 136.00723, mean: 0.10794
[32m[0906 15-52-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03408, current rewards: 137.36134, mean: 0.10486
[32m[0906 15-52-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03407, current rewards: 142.79737, mean: 0.10500
[32m[0906 15-52-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03404, current rewards: 148.23356, mean: 0.10513
[32m[0906 15-52-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03402, current rewards: 153.59065, mean: 0.10520
[32m[0906 15-52-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03402, current rewards: 159.00528, mean: 0.10530
[32m[0906 15-52-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03403, current rewards: 164.53262, mean: 0.10547
[32m[0906 15-52-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03403, current rewards: 170.05337, mean: 0.10562
[32m[0906 15-52-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03404, current rewards: 175.57829, mean: 0.10577
[32m[0906 15-52-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03405, current rewards: 179.99597, mean: 0.10526
[32m[0906 15-52-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03406, current rewards: 185.60936, mean: 0.10546
[32m[0906 15-52-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03406, current rewards: 191.22312, mean: 0.10565
[32m[0906 15-52-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03407, current rewards: 196.82859, mean: 0.10582
[32m[0906 15-53-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03408, current rewards: 202.74314, mean: 0.10615
[32m[0906 15-53-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03408, current rewards: 208.42454, mean: 0.10634
[32m[0906 15-53-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03409, current rewards: 214.10993, mean: 0.10652
[32m[0906 15-53-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03410, current rewards: 219.79037, mean: 0.10669
[32m[0906 15-53-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03411, current rewards: 224.32894, mean: 0.10632
[32m[0906 15-53-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03409, current rewards: 229.88821, mean: 0.10643
[32m[0906 15-53-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03408, current rewards: 235.45040, mean: 0.10654
[32m[0906 15-53-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03406, current rewards: 241.01453, mean: 0.10664
[32m[0906 15-53-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03405, current rewards: 244.53693, mean: 0.10586
[32m[0906 15-53-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03406, current rewards: 250.17593, mean: 0.10601
[32m[0906 15-53-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03407, current rewards: 255.81721, mean: 0.10615
[32m[0906 15-53-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03407, current rewards: 261.46024, mean: 0.10628
[32m[0906 15-53-21 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-53-21 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-53-21 @MBExp.py:227][0m Rewards obtained: [265.96978379679047], Lows: [3], Highs: [4], Total time: 4808.630042
[32m[0906 15-55-16 @MBExp.py:144][0m ####################################################################
[32m[0906 15-55-16 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 15-55-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03347, current rewards: -0.09119, mean: -0.00912
[32m[0906 15-55-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03414, current rewards: 5.45056, mean: 0.09084
[32m[0906 15-55-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03416, current rewards: 10.99134, mean: 0.09992
[32m[0906 15-55-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03427, current rewards: 16.53058, mean: 0.10332
[32m[0906 15-55-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03430, current rewards: 22.07345, mean: 0.10511
[32m[0906 15-55-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03433, current rewards: 27.63950, mean: 0.10631
[32m[0906 15-55-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03429, current rewards: 33.18336, mean: 0.10704
[32m[0906 15-55-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03430, current rewards: 38.72577, mean: 0.10757
[32m[0906 15-55-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03432, current rewards: 44.26969, mean: 0.10797
[32m[0906 15-55-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03432, current rewards: 49.81481, mean: 0.10829
[32m[0906 15-55-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03430, current rewards: 55.35800, mean: 0.10855
[32m[0906 15-55-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03429, current rewards: 59.76140, mean: 0.10672
[32m[0906 15-55-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03429, current rewards: 65.31458, mean: 0.10707
[32m[0906 15-55-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03428, current rewards: 70.66062, mean: 0.10706
[32m[0906 15-55-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03428, current rewards: 76.20806, mean: 0.10734
[32m[0906 15-55-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03429, current rewards: 81.76153, mean: 0.10758
[32m[0906 15-55-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03429, current rewards: 87.31432, mean: 0.10780
[32m[0906 15-55-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03429, current rewards: 92.22246, mean: 0.10724
[32m[0906 15-55-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03424, current rewards: 98.09986, mean: 0.10780
[32m[0906 15-55-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03422, current rewards: 103.98189, mean: 0.10831
[32m[0906 15-55-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03418, current rewards: 109.86364, mean: 0.10878
[32m[0906 15-55-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03415, current rewards: 115.80199, mean: 0.10925
[32m[0906 15-55-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03412, current rewards: 121.68346, mean: 0.10962
[32m[0906 15-55-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03409, current rewards: 127.55068, mean: 0.10996
[32m[0906 15-55-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03407, current rewards: 133.42261, mean: 0.11027
[32m[0906 15-55-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03404, current rewards: 139.29789, mean: 0.11055
[32m[0906 15-56-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03402, current rewards: 145.16168, mean: 0.11081
[32m[0906 15-56-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03400, current rewards: 149.00977, mean: 0.10957
[32m[0906 15-56-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03397, current rewards: 154.55167, mean: 0.10961
[32m[0906 15-56-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03396, current rewards: 160.09441, mean: 0.10965
[32m[0906 15-56-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03398, current rewards: 165.63138, mean: 0.10969
[32m[0906 15-56-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03399, current rewards: 171.17324, mean: 0.10973
[32m[0906 15-56-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03400, current rewards: 176.71426, mean: 0.10976
[32m[0906 15-56-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03401, current rewards: 182.25326, mean: 0.10979
[32m[0906 15-56-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03403, current rewards: 187.79365, mean: 0.10982
[32m[0906 15-56-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03404, current rewards: 193.33507, mean: 0.10985
[32m[0906 15-56-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03405, current rewards: 198.87999, mean: 0.10988
[32m[0906 15-56-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03405, current rewards: 203.43034, mean: 0.10937
[32m[0906 15-56-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03406, current rewards: 208.97683, mean: 0.10941
[32m[0906 15-56-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03407, current rewards: 214.53199, mean: 0.10946
[32m[0906 15-56-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03408, current rewards: 220.07838, mean: 0.10949
[32m[0906 15-56-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03408, current rewards: 225.62616, mean: 0.10953
[32m[0906 15-56-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03409, current rewards: 231.17414, mean: 0.10956
[32m[0906 15-56-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03407, current rewards: 236.71470, mean: 0.10959
[32m[0906 15-56-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03406, current rewards: 242.25582, mean: 0.10962
[32m[0906 15-56-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03405, current rewards: 246.93476, mean: 0.10926
[32m[0906 15-56-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03404, current rewards: 252.64816, mean: 0.10937
[32m[0906 15-56-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03404, current rewards: 258.40789, mean: 0.10949
[32m[0906 15-56-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03404, current rewards: 264.16717, mean: 0.10961
[32m[0906 15-56-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03405, current rewards: 269.93272, mean: 0.10973
[32m[0906 15-56-41 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-56-41 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-56-42 @MBExp.py:227][0m Rewards obtained: [274.54135842383545], Lows: [1], Highs: [5], Total time: 4894.448605
[32m[0906 15-58-38 @MBExp.py:144][0m ####################################################################
[32m[0906 15-58-38 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 15-58-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03318, current rewards: -0.98174, mean: -0.09817
[32m[0906 15-58-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03423, current rewards: 4.55255, mean: 0.07588
[32m[0906 15-58-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03413, current rewards: 10.08926, mean: 0.09172
[32m[0906 15-58-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03425, current rewards: 15.62426, mean: 0.09765
[32m[0906 15-58-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03430, current rewards: 21.09672, mean: 0.10046
[32m[0906 15-58-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03431, current rewards: 26.67038, mean: 0.10258
[32m[0906 15-58-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03429, current rewards: 32.24439, mean: 0.10401
[32m[0906 15-58-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03429, current rewards: 37.81412, mean: 0.10504
[32m[0906 15-58-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03429, current rewards: 43.38419, mean: 0.10582
[32m[0906 15-58-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03431, current rewards: 48.95905, mean: 0.10643
[32m[0906 15-58-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03431, current rewards: 54.53165, mean: 0.10692
[32m[0906 15-58-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03431, current rewards: 60.10792, mean: 0.10734
[32m[0906 15-58-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03431, current rewards: 65.91485, mean: 0.10806
[32m[0906 15-59-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03431, current rewards: 71.44329, mean: 0.10825
[32m[0906 15-59-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03433, current rewards: 76.95809, mean: 0.10839
[32m[0906 15-59-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03433, current rewards: 82.47016, mean: 0.10851
[32m[0906 15-59-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03433, current rewards: 86.90712, mean: 0.10729
[32m[0906 15-59-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03428, current rewards: 92.44820, mean: 0.10750
[32m[0906 15-59-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03424, current rewards: 97.98903, mean: 0.10768
[32m[0906 15-59-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03421, current rewards: 103.51570, mean: 0.10783
[32m[0906 15-59-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03416, current rewards: 108.99769, mean: 0.10792
[32m[0906 15-59-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03413, current rewards: 114.20259, mean: 0.10774
[32m[0906 15-59-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03411, current rewards: 119.63959, mean: 0.10778
[32m[0906 15-59-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03409, current rewards: 125.08756, mean: 0.10783
[32m[0906 15-59-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03406, current rewards: 130.52820, mean: 0.10787
[32m[0906 15-59-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03404, current rewards: 135.96648, mean: 0.10791
[32m[0906 15-59-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03401, current rewards: 141.41972, mean: 0.10795
[32m[0906 15-59-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03399, current rewards: 146.86689, mean: 0.10799
[32m[0906 15-59-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03398, current rewards: 152.31746, mean: 0.10803
[32m[0906 15-59-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03398, current rewards: 157.85127, mean: 0.10812
[32m[0906 15-59-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03399, current rewards: 163.31293, mean: 0.10815
[32m[0906 15-59-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03400, current rewards: 168.77449, mean: 0.10819
[32m[0906 15-59-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03402, current rewards: 174.23277, mean: 0.10822
[32m[0906 15-59-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03403, current rewards: 179.68730, mean: 0.10825
[32m[0906 15-59-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03404, current rewards: 182.07116, mean: 0.10647
[32m[0906 15-59-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03405, current rewards: 187.36004, mean: 0.10645
[32m[0906 15-59-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03406, current rewards: 192.64264, mean: 0.10643
[32m[0906 15-59-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03407, current rewards: 198.04573, mean: 0.10648
[32m[0906 15-59-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03409, current rewards: 199.55680, mean: 0.10448
[32m[0906 15-59-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03410, current rewards: 206.48347, mean: 0.10535
[32m[0906 15-59-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03411, current rewards: 213.41013, mean: 0.10617
[32m[0906 15-59-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03412, current rewards: 220.33678, mean: 0.10696
[32m[0906 15-59-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03413, current rewards: 227.26344, mean: 0.10771
[32m[0906 15-59-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03411, current rewards: 234.19010, mean: 0.10842
[32m[0906 15-59-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03410, current rewards: 241.11676, mean: 0.10910
[32m[0906 15-59-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03409, current rewards: 212.74889, mean: 0.09414
[32m[0906 15-59-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03408, current rewards: 162.74889, mean: 0.07045
[32m[0906 15-59-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03407, current rewards: 112.74889, mean: 0.04777
[32m[0906 16-00-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03407, current rewards: 62.74889, mean: 0.02604
[32m[0906 16-00-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03408, current rewards: 12.74889, mean: 0.00518
[32m[0906 16-00-04 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 16-00-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-00-04 @MBExp.py:227][0m Rewards obtained: [-27.251109951911786], Lows: [3], Highs: [275], Total time: 4980.346242
[32m[0906 16-02-03 @MBExp.py:144][0m ####################################################################
[32m[0906 16-02-03 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 16-02-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03338, current rewards: -2.97808, mean: -0.29781
[32m[0906 16-02-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03399, current rewards: 2.56318, mean: 0.04272
[32m[0906 16-02-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03416, current rewards: 8.17573, mean: 0.07432
[32m[0906 16-02-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03424, current rewards: 13.79130, mean: 0.08620
[32m[0906 16-02-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03425, current rewards: 19.36446, mean: 0.09221
[32m[0906 16-02-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03424, current rewards: 24.88775, mean: 0.09572
[32m[0906 16-02-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03423, current rewards: 30.49100, mean: 0.09836
[32m[0906 16-02-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03428, current rewards: 36.09433, mean: 0.10026
[32m[0906 16-02-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03430, current rewards: 41.69964, mean: 0.10171
[32m[0906 16-02-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03431, current rewards: 47.30524, mean: 0.10284
[32m[0906 16-02-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03431, current rewards: 52.90928, mean: 0.10374
[32m[0906 16-02-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03430, current rewards: 56.37361, mean: 0.10067
[32m[0906 16-02-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03432, current rewards: 62.15763, mean: 0.10190
[32m[0906 16-02-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03433, current rewards: 67.93713, mean: 0.10294
[32m[0906 16-02-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03433, current rewards: 73.72244, mean: 0.10383
[32m[0906 16-02-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03432, current rewards: 79.51328, mean: 0.10462
[32m[0906 16-02-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03430, current rewards: 85.29420, mean: 0.10530
[32m[0906 16-02-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03425, current rewards: 91.07927, mean: 0.10591
[32m[0906 16-02-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03420, current rewards: 96.86057, mean: 0.10644
[32m[0906 16-02-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03416, current rewards: 100.35781, mean: 0.10454
[32m[0906 16-02-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03413, current rewards: 105.92006, mean: 0.10487
[32m[0906 16-02-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03410, current rewards: 111.39239, mean: 0.10509
[32m[0906 16-02-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03407, current rewards: 116.93404, mean: 0.10535
[32m[0906 16-02-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03404, current rewards: 122.47685, mean: 0.10558
[32m[0906 16-02-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03403, current rewards: 128.02085, mean: 0.10580
[32m[0906 16-02-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03400, current rewards: 133.63927, mean: 0.10606
[32m[0906 16-02-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03398, current rewards: 139.40171, mean: 0.10641
[32m[0906 16-02-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03395, current rewards: 145.16606, mean: 0.10674
[32m[0906 16-02-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03394, current rewards: 150.92931, mean: 0.10704
[32m[0906 16-02-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03395, current rewards: 156.96420, mean: 0.10751
[32m[0906 16-02-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03396, current rewards: 162.76032, mean: 0.10779
[32m[0906 16-02-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03396, current rewards: 168.54847, mean: 0.10804
[32m[0906 16-02-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03397, current rewards: 172.18706, mean: 0.10695
[32m[0906 16-03-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03398, current rewards: 177.60569, mean: 0.10699
[32m[0906 16-03-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03399, current rewards: 183.02729, mean: 0.10703
[32m[0906 16-03-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03400, current rewards: 188.44840, mean: 0.10707
[32m[0906 16-03-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03401, current rewards: 193.87069, mean: 0.10711
[32m[0906 16-03-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03402, current rewards: 199.24137, mean: 0.10712
[32m[0906 16-03-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03403, current rewards: 204.57811, mean: 0.10711
[32m[0906 16-03-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03404, current rewards: 209.98285, mean: 0.10713
[32m[0906 16-03-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03406, current rewards: 212.42667, mean: 0.10568
[32m[0906 16-03-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03406, current rewards: 218.08791, mean: 0.10587
[32m[0906 16-03-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03407, current rewards: 223.74406, mean: 0.10604
[32m[0906 16-03-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03406, current rewards: 229.39253, mean: 0.10620
[32m[0906 16-03-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03404, current rewards: 235.04860, mean: 0.10636
[32m[0906 16-03-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03403, current rewards: 240.70456, mean: 0.10651
[32m[0906 16-03-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03403, current rewards: 246.49649, mean: 0.10671
[32m[0906 16-03-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03401, current rewards: 250.89613, mean: 0.10631
[32m[0906 16-03-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03401, current rewards: 256.60107, mean: 0.10647
[32m[0906 16-03-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03401, current rewards: 262.30905, mean: 0.10663
[32m[0906 16-03-29 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 16-03-29 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-03-29 @MBExp.py:227][0m Rewards obtained: [266.8728022914319], Lows: [6], Highs: [3], Total time: 5066.0901969999995
[32m[0906 16-05-29 @MBExp.py:144][0m ####################################################################
[32m[0906 16-05-29 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 16-05-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03297, current rewards: 0.02267, mean: 0.00227
[32m[0906 16-05-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03411, current rewards: 5.72980, mean: 0.09550
[32m[0906 16-05-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03420, current rewards: 11.34735, mean: 0.10316
[32m[0906 16-05-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03425, current rewards: 16.96533, mean: 0.10603
[32m[0906 16-05-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03427, current rewards: 22.58347, mean: 0.10754
[32m[0906 16-05-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03431, current rewards: 28.20157, mean: 0.10847
[32m[0906 16-05-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03428, current rewards: 33.81935, mean: 0.10909
[32m[0906 16-05-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03429, current rewards: 39.43726, mean: 0.10955
[32m[0906 16-05-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03434, current rewards: 37.98523, mean: 0.09265
[32m[0906 16-05-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03435, current rewards: 43.58706, mean: 0.09475
[32m[0906 16-05-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03435, current rewards: 49.20140, mean: 0.09647
[32m[0906 16-05-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03434, current rewards: 54.81153, mean: 0.09788
[32m[0906 16-05-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03435, current rewards: 60.36285, mean: 0.09896
[32m[0906 16-05-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03435, current rewards: 65.94075, mean: 0.09991
[32m[0906 16-05-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03434, current rewards: 71.55306, mean: 0.10078
[32m[0906 16-05-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03435, current rewards: 77.16435, mean: 0.10153
[32m[0906 16-05-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03432, current rewards: 82.77559, mean: 0.10219
[32m[0906 16-05-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03427, current rewards: 88.38469, mean: 0.10277
[32m[0906 16-06-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03424, current rewards: 93.99437, mean: 0.10329
[32m[0906 16-06-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03421, current rewards: 99.60104, mean: 0.10375
[32m[0906 16-06-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03418, current rewards: 105.06097, mean: 0.10402
[32m[0906 16-06-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03417, current rewards: 110.00535, mean: 0.10378
[32m[0906 16-06-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03415, current rewards: 116.55471, mean: 0.10500
[32m[0906 16-06-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03413, current rewards: 119.95770, mean: 0.10341
[32m[0906 16-06-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03410, current rewards: 127.26136, mean: 0.10517
[32m[0906 16-06-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03408, current rewards: 131.39222, mean: 0.10428
[32m[0906 16-06-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03407, current rewards: 135.32581, mean: 0.10330
[32m[0906 16-06-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03405, current rewards: 140.83732, mean: 0.10356
[32m[0906 16-06-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03402, current rewards: 146.34653, mean: 0.10379
[32m[0906 16-06-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03403, current rewards: 151.72541, mean: 0.10392
[32m[0906 16-06-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03404, current rewards: 157.20108, mean: 0.10411
[32m[0906 16-06-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03406, current rewards: 162.67581, mean: 0.10428
[32m[0906 16-06-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03406, current rewards: 168.14683, mean: 0.10444
[32m[0906 16-06-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03408, current rewards: 173.61896, mean: 0.10459
[32m[0906 16-06-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03408, current rewards: 179.09060, mean: 0.10473
[32m[0906 16-06-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03409, current rewards: 184.55845, mean: 0.10486
[32m[0906 16-06-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03410, current rewards: 190.02379, mean: 0.10499
[32m[0906 16-06-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03411, current rewards: 193.68724, mean: 0.10413
[32m[0906 16-06-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03411, current rewards: 199.41579, mean: 0.10441
[32m[0906 16-06-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03412, current rewards: 205.14173, mean: 0.10466
[32m[0906 16-06-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03412, current rewards: 210.87168, mean: 0.10491
[32m[0906 16-06-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03413, current rewards: 216.60726, mean: 0.10515
[32m[0906 16-06-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03413, current rewards: 222.33938, mean: 0.10537
[32m[0906 16-06-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03412, current rewards: 228.06921, mean: 0.10559
[32m[0906 16-06-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03411, current rewards: 233.79893, mean: 0.10579
[32m[0906 16-06-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03409, current rewards: 238.12528, mean: 0.10537
[32m[0906 16-06-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03408, current rewards: 243.52437, mean: 0.10542
[32m[0906 16-06-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03407, current rewards: 248.94799, mean: 0.10549
[32m[0906 16-06-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03405, current rewards: 254.36774, mean: 0.10555
[32m[0906 16-06-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03406, current rewards: 259.78230, mean: 0.10560
[32m[0906 16-06-55 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 16-06-55 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-06-55 @MBExp.py:227][0m Rewards obtained: [264.12452247600527], Lows: [14], Highs: [5], Total time: 5151.939791
[32m[0906 16-08-58 @MBExp.py:144][0m ####################################################################
[32m[0906 16-08-58 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 16-08-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03299, current rewards: 0.31465, mean: 0.03147
[32m[0906 16-09-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03400, current rewards: 5.78828, mean: 0.09647
[32m[0906 16-09-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03414, current rewards: 11.27581, mean: 0.10251
[32m[0906 16-09-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03417, current rewards: 16.76124, mean: 0.10476
[32m[0906 16-09-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03419, current rewards: 22.31315, mean: 0.10625
[32m[0906 16-09-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03428, current rewards: 27.68859, mean: 0.10649
[32m[0906 16-09-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03429, current rewards: 33.06166, mean: 0.10665
[32m[0906 16-09-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03433, current rewards: 38.42838, mean: 0.10675
[32m[0906 16-09-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03432, current rewards: 43.80495, mean: 0.10684
[32m[0906 16-09-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03432, current rewards: 49.88569, mean: 0.10845
[32m[0906 16-09-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03431, current rewards: 55.32085, mean: 0.10847
[32m[0906 16-09-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03431, current rewards: 60.76520, mean: 0.10851
[32m[0906 16-09-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03433, current rewards: 66.14642, mean: 0.10844
[32m[0906 16-09-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03433, current rewards: 71.66691, mean: 0.10859
[32m[0906 16-09-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03433, current rewards: 77.18938, mean: 0.10872
[32m[0906 16-09-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03433, current rewards: 82.71221, mean: 0.10883
[32m[0906 16-09-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03428, current rewards: 88.22444, mean: 0.10892
[32m[0906 16-09-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03424, current rewards: 93.74822, mean: 0.10901
[32m[0906 16-09-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03421, current rewards: 99.27157, mean: 0.10909
[32m[0906 16-09-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03417, current rewards: 104.79113, mean: 0.10916
[32m[0906 16-09-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03414, current rewards: 108.24491, mean: 0.10717
[32m[0906 16-09-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03411, current rewards: 113.74819, mean: 0.10731
[32m[0906 16-09-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03409, current rewards: 119.25235, mean: 0.10743
[32m[0906 16-09-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03405, current rewards: 124.75623, mean: 0.10755
[32m[0906 16-09-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03403, current rewards: 130.25854, mean: 0.10765
[32m[0906 16-09-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03401, current rewards: 135.76077, mean: 0.10775
[32m[0906 16-09-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03399, current rewards: 141.26311, mean: 0.10783
[32m[0906 16-09-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03398, current rewards: 146.77083, mean: 0.10792
[32m[0906 16-09-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03397, current rewards: 152.31266, mean: 0.10802
[32m[0906 16-09-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03397, current rewards: 159.13821, mean: 0.10900
[32m[0906 16-09-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03398, current rewards: 166.23476, mean: 0.11009
[32m[0906 16-09-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03399, current rewards: 157.69366, mean: 0.10109
[32m[0906 16-09-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03400, current rewards: 163.19406, mean: 0.10136
[32m[0906 16-09-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03402, current rewards: 168.69578, mean: 0.10162
[32m[0906 16-09-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03402, current rewards: 170.01244, mean: 0.09942
[32m[0906 16-09-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03403, current rewards: 175.54110, mean: 0.09974
[32m[0906 16-10-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03404, current rewards: 181.06642, mean: 0.10004
[32m[0906 16-10-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03405, current rewards: 186.58783, mean: 0.10032
[32m[0906 16-10-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03406, current rewards: 192.11238, mean: 0.10058
[32m[0906 16-10-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03407, current rewards: 197.64015, mean: 0.10084
[32m[0906 16-10-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03408, current rewards: 203.16339, mean: 0.10108
[32m[0906 16-10-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03409, current rewards: 208.69023, mean: 0.10131
[32m[0906 16-10-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03410, current rewards: 214.21540, mean: 0.10152
[32m[0906 16-10-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03409, current rewards: 215.51765, mean: 0.09978
[32m[0906 16-10-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03408, current rewards: 220.84146, mean: 0.09993
[32m[0906 16-10-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03406, current rewards: 226.17629, mean: 0.10008
[32m[0906 16-10-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03405, current rewards: 231.49600, mean: 0.10021
[32m[0906 16-10-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03404, current rewards: 236.81799, mean: 0.10035
[32m[0906 16-10-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03403, current rewards: 242.13978, mean: 0.10047
[32m[0906 16-10-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03402, current rewards: 246.53600, mean: 0.10022
[32m[0906 16-10-24 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 16-10-24 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-10-24 @MBExp.py:227][0m Rewards obtained: [252.21324603017013], Lows: [6], Highs: [14], Total time: 5237.691037
[32m[0906 16-12-28 @MBExp.py:144][0m ####################################################################
[32m[0906 16-12-28 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 16-12-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03432, current rewards: -0.48881, mean: -0.04888
[32m[0906 16-12-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03405, current rewards: 5.08292, mean: 0.08472
[32m[0906 16-12-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03421, current rewards: 10.66778, mean: 0.09698
[32m[0906 16-12-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03427, current rewards: 16.22451, mean: 0.10140
[32m[0906 16-12-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03423, current rewards: 21.79951, mean: 0.10381
[32m[0906 16-12-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03422, current rewards: 27.37109, mean: 0.10527
[32m[0906 16-12-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03427, current rewards: 32.99181, mean: 0.10643
[32m[0906 16-12-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03431, current rewards: 37.82803, mean: 0.10508
[32m[0906 16-12-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03428, current rewards: 42.66573, mean: 0.10406
[32m[0906 16-12-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03428, current rewards: 48.06440, mean: 0.10449
[32m[0906 16-12-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03428, current rewards: 53.78863, mean: 0.10547
[32m[0906 16-12-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03429, current rewards: 59.36981, mean: 0.10602
[32m[0906 16-12-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03430, current rewards: 64.90317, mean: 0.10640
[32m[0906 16-12-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03429, current rewards: 70.43290, mean: 0.10672
[32m[0906 16-12-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03428, current rewards: 75.96942, mean: 0.10700
[32m[0906 16-12-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03426, current rewards: 81.50681, mean: 0.10725
[32m[0906 16-12-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03420, current rewards: 87.04031, mean: 0.10746
[32m[0906 16-12-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03416, current rewards: 90.46537, mean: 0.10519
[32m[0906 16-12-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03412, current rewards: 94.02716, mean: 0.10333
[32m[0906 16-13-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03409, current rewards: 99.08864, mean: 0.10322
[32m[0906 16-13-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03405, current rewards: 104.64288, mean: 0.10361
[32m[0906 16-13-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03403, current rewards: 110.29900, mean: 0.10406
[32m[0906 16-13-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03399, current rewards: 115.95188, mean: 0.10446
[32m[0906 16-13-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03398, current rewards: 121.61079, mean: 0.10484
[32m[0906 16-13-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03397, current rewards: 126.09556, mean: 0.10421
[32m[0906 16-13-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03395, current rewards: 131.54593, mean: 0.10440
[32m[0906 16-13-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03394, current rewards: 136.99989, mean: 0.10458
[32m[0906 16-13-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03392, current rewards: 142.45387, mean: 0.10475
[32m[0906 16-13-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03391, current rewards: 148.11406, mean: 0.10505
[32m[0906 16-13-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03391, current rewards: 153.64445, mean: 0.10524
[32m[0906 16-13-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03392, current rewards: 159.17350, mean: 0.10541
[32m[0906 16-13-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03394, current rewards: 164.69550, mean: 0.10557
[32m[0906 16-13-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03396, current rewards: 168.25635, mean: 0.10451
[32m[0906 16-13-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03396, current rewards: 173.61626, mean: 0.10459
[32m[0906 16-13-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03398, current rewards: 178.98034, mean: 0.10467
[32m[0906 16-13-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03398, current rewards: 184.33993, mean: 0.10474
[32m[0906 16-13-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03399, current rewards: 189.55260, mean: 0.10473
[32m[0906 16-13-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03401, current rewards: 194.89562, mean: 0.10478
[32m[0906 16-13-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03402, current rewards: 200.23432, mean: 0.10483
[32m[0906 16-13-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03403, current rewards: 205.57841, mean: 0.10489
[32m[0906 16-13-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03404, current rewards: 210.91513, mean: 0.10493
[32m[0906 16-13-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03405, current rewards: 216.26154, mean: 0.10498
[32m[0906 16-13-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03406, current rewards: 221.60013, mean: 0.10502
[32m[0906 16-13-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03405, current rewards: 225.81979, mean: 0.10455
[32m[0906 16-13-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03404, current rewards: 231.46299, mean: 0.10473
[32m[0906 16-13-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03402, current rewards: 237.10304, mean: 0.10491
[32m[0906 16-13-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03402, current rewards: 242.66673, mean: 0.10505
[32m[0906 16-13-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03400, current rewards: 248.22302, mean: 0.10518
[32m[0906 16-13-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03400, current rewards: 253.78655, mean: 0.10531
[32m[0906 16-13-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03399, current rewards: 259.34683, mean: 0.10543
[32m[0906 16-13-54 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 16-13-54 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-13-54 @MBExp.py:227][0m Rewards obtained: [263.7389497652943], Lows: [3], Highs: [4], Total time: 5323.345047
[32m[0906 16-16-00 @MBExp.py:144][0m ####################################################################
[32m[0906 16-16-00 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 16-16-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03352, current rewards: 1.11248, mean: 0.11125
[32m[0906 16-16-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03417, current rewards: 6.61116, mean: 0.11019
[32m[0906 16-16-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03430, current rewards: 12.10982, mean: 0.11009
[32m[0906 16-16-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03438, current rewards: 17.48885, mean: 0.10931
[32m[0906 16-16-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03439, current rewards: 22.94322, mean: 0.10925
[32m[0906 16-16-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03437, current rewards: 28.39782, mean: 0.10922
[32m[0906 16-16-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03436, current rewards: 33.85640, mean: 0.10921
[32m[0906 16-16-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03435, current rewards: 39.30854, mean: 0.10919
[32m[0906 16-16-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03435, current rewards: 44.76394, mean: 0.10918
[32m[0906 16-16-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03435, current rewards: 50.22111, mean: 0.10918
[32m[0906 16-16-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03437, current rewards: 55.67318, mean: 0.10916
[32m[0906 16-16-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03436, current rewards: 54.99523, mean: 0.09821
[32m[0906 16-16-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03437, current rewards: 60.65309, mean: 0.09943
[32m[0906 16-16-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03436, current rewards: 66.31082, mean: 0.10047
[32m[0906 16-16-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03436, current rewards: 71.96491, mean: 0.10136
[32m[0906 16-16-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03429, current rewards: 77.62317, mean: 0.10214
[32m[0906 16-16-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03424, current rewards: 81.09106, mean: 0.10011
[32m[0906 16-16-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03420, current rewards: 86.32681, mean: 0.10038
[32m[0906 16-16-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03416, current rewards: 91.55854, mean: 0.10061
[32m[0906 16-16-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03413, current rewards: 96.64921, mean: 0.10068
[32m[0906 16-16-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03410, current rewards: 102.05153, mean: 0.10104
[32m[0906 16-16-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03406, current rewards: 107.45590, mean: 0.10137
[32m[0906 16-16-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03404, current rewards: 110.77093, mean: 0.09979
[32m[0906 16-16-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03401, current rewards: 116.15334, mean: 0.10013
[32m[0906 16-16-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03398, current rewards: 121.52909, mean: 0.10044
[32m[0906 16-16-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03396, current rewards: 126.91213, mean: 0.10072
[32m[0906 16-16-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03395, current rewards: 132.29967, mean: 0.10099
[32m[0906 16-16-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03393, current rewards: 137.67721, mean: 0.10123
[32m[0906 16-16-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03392, current rewards: 140.96951, mean: 0.09998
[32m[0906 16-16-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03392, current rewards: 146.46771, mean: 0.10032
[32m[0906 16-16-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03395, current rewards: 151.97447, mean: 0.10065
[32m[0906 16-16-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03396, current rewards: 157.47749, mean: 0.10095
[32m[0906 16-16-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03398, current rewards: 162.97664, mean: 0.10123
[32m[0906 16-16-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03399, current rewards: 168.48094, mean: 0.10149
[32m[0906 16-16-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03400, current rewards: 173.97842, mean: 0.10174
[32m[0906 16-17-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03400, current rewards: 179.51491, mean: 0.10200
[32m[0906 16-17-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03401, current rewards: 185.26792, mean: 0.10236
[32m[0906 16-17-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03403, current rewards: 190.62623, mean: 0.10249
[32m[0906 16-17-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03404, current rewards: 197.49697, mean: 0.10340
[32m[0906 16-17-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03405, current rewards: 204.37016, mean: 0.10427
[32m[0906 16-17-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03405, current rewards: 211.22327, mean: 0.10509
[32m[0906 16-17-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03406, current rewards: 218.10234, mean: 0.10587
[32m[0906 16-17-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03407, current rewards: 224.98004, mean: 0.10663
[32m[0906 16-17-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03407, current rewards: 231.85238, mean: 0.10734
[32m[0906 16-17-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03405, current rewards: 238.68770, mean: 0.10800
[32m[0906 16-17-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03404, current rewards: 243.59841, mean: 0.10779
[32m[0906 16-17-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03403, current rewards: 249.00346, mean: 0.10779
[32m[0906 16-17-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03401, current rewards: 254.40063, mean: 0.10780
[32m[0906 16-17-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03400, current rewards: 259.80725, mean: 0.10780
[32m[0906 16-17-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03399, current rewards: 265.20758, mean: 0.10781
[32m[0906 16-17-26 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 16-17-26 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-17-26 @MBExp.py:227][0m Rewards obtained: [269.4686211886481], Lows: [6], Highs: [3], Total time: 5408.978504
[32m[0906 16-19-34 @MBExp.py:144][0m ####################################################################
[32m[0906 16-19-34 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 16-19-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03411, current rewards: 0.01157, mean: 0.00116
[32m[0906 16-19-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03402, current rewards: 5.40723, mean: 0.09012
[32m[0906 16-19-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03417, current rewards: 10.96774, mean: 0.09971
[32m[0906 16-19-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03419, current rewards: 16.46812, mean: 0.10293
[32m[0906 16-19-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03423, current rewards: 22.06153, mean: 0.10505
[32m[0906 16-19-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03421, current rewards: 27.65037, mean: 0.10635
[32m[0906 16-19-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03424, current rewards: 33.24873, mean: 0.10725
[32m[0906 16-19-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03425, current rewards: 38.84017, mean: 0.10789
[32m[0906 16-19-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03425, current rewards: 44.43687, mean: 0.10838
[32m[0906 16-19-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03425, current rewards: 50.03152, mean: 0.10876
[32m[0906 16-19-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03425, current rewards: 55.62811, mean: 0.10907
[32m[0906 16-19-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03427, current rewards: 60.48169, mean: 0.10800
[32m[0906 16-19-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03427, current rewards: 66.09660, mean: 0.10836
[32m[0906 16-19-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03426, current rewards: 71.71337, mean: 0.10866
[32m[0906 16-19-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03425, current rewards: 77.33449, mean: 0.10892
[32m[0906 16-20-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03418, current rewards: 82.94991, mean: 0.10914
[32m[0906 16-20-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03415, current rewards: 88.56750, mean: 0.10934
[32m[0906 16-20-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03411, current rewards: 94.19146, mean: 0.10952
[32m[0906 16-20-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03407, current rewards: 99.76393, mean: 0.10963
[32m[0906 16-20-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03404, current rewards: 105.34843, mean: 0.10974
[32m[0906 16-20-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03401, current rewards: 110.91806, mean: 0.10982
[32m[0906 16-20-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03397, current rewards: 116.49376, mean: 0.10990
[32m[0906 16-20-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03395, current rewards: 122.06626, mean: 0.10997
[32m[0906 16-20-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03393, current rewards: 127.63612, mean: 0.11003
[32m[0906 16-20-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03391, current rewards: 129.11665, mean: 0.10671
[32m[0906 16-20-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03390, current rewards: 134.79211, mean: 0.10698
[32m[0906 16-20-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03388, current rewards: 140.46725, mean: 0.10723
[32m[0906 16-20-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03386, current rewards: 146.10397, mean: 0.10743
[32m[0906 16-20-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03384, current rewards: 151.71806, mean: 0.10760
[32m[0906 16-20-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03386, current rewards: 153.38236, mean: 0.10506
[32m[0906 16-20-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03387, current rewards: 159.18528, mean: 0.10542
[32m[0906 16-20-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03388, current rewards: 164.98461, mean: 0.10576
[32m[0906 16-20-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03389, current rewards: 170.78483, mean: 0.10608
[32m[0906 16-20-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03391, current rewards: 176.58599, mean: 0.10638
[32m[0906 16-20-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03393, current rewards: 182.38575, mean: 0.10666
[32m[0906 16-20-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03394, current rewards: 188.18954, mean: 0.10693
[32m[0906 16-20-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03395, current rewards: 194.03649, mean: 0.10720
[32m[0906 16-20-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03396, current rewards: 199.85315, mean: 0.10745
[32m[0906 16-20-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03398, current rewards: 205.66969, mean: 0.10768
[32m[0906 16-20-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03398, current rewards: 211.48483, mean: 0.10790
[32m[0906 16-20-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03400, current rewards: 216.12607, mean: 0.10753
[32m[0906 16-20-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03401, current rewards: 222.03777, mean: 0.10779
[32m[0906 16-20-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03402, current rewards: 227.95387, mean: 0.10804
[32m[0906 16-20-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03402, current rewards: 233.86180, mean: 0.10827
[32m[0906 16-20-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03401, current rewards: 239.76134, mean: 0.10849
[32m[0906 16-20-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03400, current rewards: 245.68005, mean: 0.10871
[32m[0906 16-20-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03398, current rewards: 251.58734, mean: 0.10891
[32m[0906 16-20-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03398, current rewards: 257.45150, mean: 0.10909
[32m[0906 16-20-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03397, current rewards: 263.26673, mean: 0.10924
[32m[0906 16-20-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03396, current rewards: 269.08206, mean: 0.10938
[32m[0906 16-21-00 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 16-21-00 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-21-00 @MBExp.py:227][0m Rewards obtained: [273.7320083591843], Lows: [4], Highs: [4], Total time: 5494.532010999999
[32m[0906 16-23-10 @MBExp.py:144][0m ####################################################################
[32m[0906 16-23-10 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 16-23-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03377, current rewards: -1.20940, mean: -0.12094
[32m[0906 16-23-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03411, current rewards: 4.39227, mean: 0.07320
[32m[0906 16-23-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03414, current rewards: 10.32555, mean: 0.09387
[32m[0906 16-23-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03417, current rewards: 15.87678, mean: 0.09923
[32m[0906 16-23-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03425, current rewards: 21.42512, mean: 0.10202
[32m[0906 16-23-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03423, current rewards: 25.80512, mean: 0.09925
[32m[0906 16-23-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03422, current rewards: 31.08388, mean: 0.10027
[32m[0906 16-23-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03422, current rewards: 36.35763, mean: 0.10099
[32m[0906 16-23-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03424, current rewards: 41.63345, mean: 0.10155
[32m[0906 16-23-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03423, current rewards: 46.91074, mean: 0.10198
[32m[0906 16-23-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03424, current rewards: 52.18636, mean: 0.10233
[32m[0906 16-23-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03425, current rewards: 57.46274, mean: 0.10261
[32m[0906 16-23-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03425, current rewards: 62.73677, mean: 0.10285
[32m[0906 16-23-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03425, current rewards: 68.31352, mean: 0.10351
[32m[0906 16-23-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03424, current rewards: 73.82892, mean: 0.10398
[32m[0906 16-23-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03417, current rewards: 79.34782, mean: 0.10441
[32m[0906 16-23-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03412, current rewards: 84.85948, mean: 0.10476
[32m[0906 16-23-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03408, current rewards: 90.37765, mean: 0.10509
[32m[0906 16-23-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03406, current rewards: 95.89302, mean: 0.10538
[32m[0906 16-23-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03403, current rewards: 101.40472, mean: 0.10563
[32m[0906 16-23-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03400, current rewards: 103.25581, mean: 0.10223
[32m[0906 16-23-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03397, current rewards: 110.01986, mean: 0.10379
[32m[0906 16-23-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03394, current rewards: 116.78390, mean: 0.10521
[32m[0906 16-23-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03392, current rewards: 123.54794, mean: 0.10651
[32m[0906 16-23-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03391, current rewards: 130.31199, mean: 0.10770
[32m[0906 16-23-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03389, current rewards: 137.07603, mean: 0.10879
[32m[0906 16-23-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03387, current rewards: 143.72363, mean: 0.10971
[32m[0906 16-23-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03387, current rewards: 148.99378, mean: 0.10955
[32m[0906 16-23-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03386, current rewards: 152.61043, mean: 0.10823
[32m[0906 16-24-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03388, current rewards: 158.34479, mean: 0.10846
[32m[0906 16-24-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03389, current rewards: 164.08072, mean: 0.10866
[32m[0906 16-24-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03390, current rewards: 169.81682, mean: 0.10886
[32m[0906 16-24-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03391, current rewards: 175.55671, mean: 0.10904
[32m[0906 16-24-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03393, current rewards: 181.24759, mean: 0.10919
[32m[0906 16-24-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03394, current rewards: 186.73847, mean: 0.10920
[32m[0906 16-24-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03395, current rewards: 192.14266, mean: 0.10917
[32m[0906 16-24-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03395, current rewards: 197.68338, mean: 0.10922
[32m[0906 16-24-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03397, current rewards: 203.22991, mean: 0.10926
[32m[0906 16-24-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03398, current rewards: 208.78266, mean: 0.10931
[32m[0906 16-24-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03398, current rewards: 214.33589, mean: 0.10936
[32m[0906 16-24-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03399, current rewards: 219.88929, mean: 0.10940
[32m[0906 16-24-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03400, current rewards: 225.44320, mean: 0.10944
[32m[0906 16-24-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03401, current rewards: 230.99509, mean: 0.10948
[32m[0906 16-24-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03401, current rewards: 236.79098, mean: 0.10963
[32m[0906 16-24-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03401, current rewards: 242.25990, mean: 0.10962
[32m[0906 16-24-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03399, current rewards: 243.50467, mean: 0.10775
[32m[0906 16-24-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03399, current rewards: 249.13234, mean: 0.10785
[32m[0906 16-24-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03398, current rewards: 254.76079, mean: 0.10795
[32m[0906 16-24-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03397, current rewards: 260.38838, mean: 0.10804
[32m[0906 16-24-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03396, current rewards: 266.01575, mean: 0.10814
[32m[0906 16-24-36 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 16-24-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-24-36 @MBExp.py:227][0m Rewards obtained: [270.517841024474], Lows: [4], Highs: [5], Total time: 5580.134633
[32m[0906 16-26-48 @MBExp.py:144][0m ####################################################################
[32m[0906 16-26-48 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 16-26-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03346, current rewards: 0.40017, mean: 0.04002
[32m[0906 16-26-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03401, current rewards: 5.92833, mean: 0.09881
[32m[0906 16-26-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03414, current rewards: 11.62774, mean: 0.10571
[32m[0906 16-26-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03420, current rewards: 17.17680, mean: 0.10735
[32m[0906 16-26-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03424, current rewards: 22.72886, mean: 0.10823
[32m[0906 16-26-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03421, current rewards: 28.68690, mean: 0.11033
[32m[0906 16-26-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03425, current rewards: 34.20429, mean: 0.11034
[32m[0906 16-27-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03425, current rewards: 39.72807, mean: 0.11036
[32m[0906 16-27-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03429, current rewards: 43.37352, mean: 0.10579
[32m[0906 16-27-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03427, current rewards: 48.79670, mean: 0.10608
[32m[0906 16-27-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03426, current rewards: 54.04542, mean: 0.10597
[32m[0906 16-27-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03426, current rewards: 59.50019, mean: 0.10625
[32m[0906 16-27-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03426, current rewards: 64.94897, mean: 0.10647
[32m[0906 16-27-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03427, current rewards: 70.39912, mean: 0.10667
[32m[0906 16-27-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03420, current rewards: 75.84570, mean: 0.10682
[32m[0906 16-27-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03416, current rewards: 81.29529, mean: 0.10697
[32m[0906 16-27-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03411, current rewards: 86.73533, mean: 0.10708
[32m[0906 16-27-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03407, current rewards: 90.46582, mean: 0.10519
[32m[0906 16-27-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03405, current rewards: 96.20110, mean: 0.10572
[32m[0906 16-27-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03401, current rewards: 101.88341, mean: 0.10613
[32m[0906 16-27-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03398, current rewards: 107.56677, mean: 0.10650
[32m[0906 16-27-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03396, current rewards: 113.24794, mean: 0.10684
[32m[0906 16-27-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03394, current rewards: 118.93131, mean: 0.10715
[32m[0906 16-27-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03392, current rewards: 124.61908, mean: 0.10743
[32m[0906 16-27-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03390, current rewards: 130.30301, mean: 0.10769
[32m[0906 16-27-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03389, current rewards: 134.84324, mean: 0.10702
[32m[0906 16-27-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03388, current rewards: 140.40551, mean: 0.10718
[32m[0906 16-27-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03386, current rewards: 145.93962, mean: 0.10731
[32m[0906 16-27-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03385, current rewards: 151.55629, mean: 0.10749
[32m[0906 16-27-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03387, current rewards: 157.16892, mean: 0.10765
[32m[0906 16-27-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03388, current rewards: 162.78608, mean: 0.10781
[32m[0906 16-27-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03389, current rewards: 168.40339, mean: 0.10795
[32m[0906 16-27-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03390, current rewards: 174.01956, mean: 0.10809
[32m[0906 16-27-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03392, current rewards: 179.63819, mean: 0.10822
[32m[0906 16-27-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03393, current rewards: 185.25301, mean: 0.10834
[32m[0906 16-27-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03394, current rewards: 190.98653, mean: 0.10852
[32m[0906 16-27-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03395, current rewards: 196.60544, mean: 0.10862
[32m[0906 16-27-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03396, current rewards: 202.21833, mean: 0.10872
[32m[0906 16-27-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03397, current rewards: 207.83857, mean: 0.10882
[32m[0906 16-27-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03397, current rewards: 213.45622, mean: 0.10891
[32m[0906 16-27-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03398, current rewards: 219.07206, mean: 0.10899
[32m[0906 16-27-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03399, current rewards: 224.78893, mean: 0.10912
[32m[0906 16-28-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03400, current rewards: 230.52703, mean: 0.10925
[32m[0906 16-28-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03401, current rewards: 236.26099, mean: 0.10938
[32m[0906 16-28-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03401, current rewards: 242.06478, mean: 0.10953
[32m[0906 16-28-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03399, current rewards: 247.86544, mean: 0.10967
[32m[0906 16-28-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03398, current rewards: 253.66435, mean: 0.10981
[32m[0906 16-28-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03397, current rewards: 259.47013, mean: 0.10994
[32m[0906 16-28-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03396, current rewards: 265.27655, mean: 0.11007
[32m[0906 16-28-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03395, current rewards: 271.07810, mean: 0.11019
[32m[0906 16-28-14 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 16-28-14 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-28-14 @MBExp.py:227][0m Rewards obtained: [275.7222878637424], Lows: [2], Highs: [3], Total time: 5665.691865
[32m[0906 16-30-28 @MBExp.py:144][0m ####################################################################
[32m[0906 16-30-28 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 16-30-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03345, current rewards: -4.62906, mean: -0.46291
[32m[0906 16-30-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03420, current rewards: 0.98459, mean: 0.01641
[32m[0906 16-30-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03425, current rewards: 6.62556, mean: 0.06023
[32m[0906 16-30-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03421, current rewards: 12.35845, mean: 0.07724
[32m[0906 16-30-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03427, current rewards: 18.10107, mean: 0.08620
[32m[0906 16-30-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03422, current rewards: 23.84548, mean: 0.09171
[32m[0906 16-30-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03423, current rewards: 29.58494, mean: 0.09544
[32m[0906 16-30-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03424, current rewards: 35.32909, mean: 0.09814
[32m[0906 16-30-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03425, current rewards: 41.06906, mean: 0.10017
[32m[0906 16-30-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03425, current rewards: 46.80774, mean: 0.10176
[32m[0906 16-30-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03424, current rewards: 52.70559, mean: 0.10334
[32m[0906 16-30-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03425, current rewards: 58.32401, mean: 0.10415
[32m[0906 16-30-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03425, current rewards: 59.50138, mean: 0.09754
[32m[0906 16-30-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03425, current rewards: 64.77232, mean: 0.09814
[32m[0906 16-30-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03417, current rewards: 70.03961, mean: 0.09865
[32m[0906 16-30-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03412, current rewards: 75.30902, mean: 0.09909
[32m[0906 16-30-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03408, current rewards: 75.45304, mean: 0.09315
[32m[0906 16-30-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03405, current rewards: 80.97496, mean: 0.09416
[32m[0906 16-30-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03401, current rewards: 86.40884, mean: 0.09495
[32m[0906 16-31-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03398, current rewards: 91.87357, mean: 0.09570
[32m[0906 16-31-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03395, current rewards: 97.41285, mean: 0.09645
[32m[0906 16-31-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03392, current rewards: 98.55859, mean: 0.09298
[32m[0906 16-31-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03389, current rewards: 103.94570, mean: 0.09364
[32m[0906 16-31-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03388, current rewards: 109.33419, mean: 0.09425
[32m[0906 16-31-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03386, current rewards: 114.72094, mean: 0.09481
[32m[0906 16-31-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03383, current rewards: 120.10765, mean: 0.09532
[32m[0906 16-31-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03381, current rewards: 125.49387, mean: 0.09580
[32m[0906 16-31-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03380, current rewards: 130.88574, mean: 0.09624
[32m[0906 16-31-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03379, current rewards: 132.75135, mean: 0.09415
[32m[0906 16-31-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03381, current rewards: 139.69580, mean: 0.09568
[32m[0906 16-31-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03382, current rewards: 146.49901, mean: 0.09702
[32m[0906 16-31-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03383, current rewards: 153.34296, mean: 0.09830
[32m[0906 16-31-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03384, current rewards: 160.25991, mean: 0.09954
[32m[0906 16-31-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03386, current rewards: 167.08629, mean: 0.10065
[32m[0906 16-31-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03387, current rewards: 174.01016, mean: 0.10176
[32m[0906 16-31-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03389, current rewards: 182.17190, mean: 0.10351
[32m[0906 16-31-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03390, current rewards: 191.43784, mean: 0.10577
[32m[0906 16-31-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03391, current rewards: 200.95511, mean: 0.10804
[32m[0906 16-31-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03392, current rewards: 210.38359, mean: 0.11015
[32m[0906 16-31-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03393, current rewards: 220.25116, mean: 0.11237
[32m[0906 16-31-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03394, current rewards: 229.74149, mean: 0.11430
[32m[0906 16-31-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03395, current rewards: 239.45739, mean: 0.11624
[32m[0906 16-31-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03395, current rewards: 248.89833, mean: 0.11796
[32m[0906 16-31-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03396, current rewards: 252.52313, mean: 0.11691
[32m[0906 16-31-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03396, current rewards: 258.13834, mean: 0.11680
[32m[0906 16-31-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03395, current rewards: 263.74807, mean: 0.11670
[32m[0906 16-31-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03394, current rewards: 269.36291, mean: 0.11661
[32m[0906 16-31-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03394, current rewards: 274.97342, mean: 0.11651
[32m[0906 16-31-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03392, current rewards: 280.58079, mean: 0.11642
[32m[0906 16-31-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03391, current rewards: 286.19531, mean: 0.11634
[32m[0906 16-31-53 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 16-31-53 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-31-54 @MBExp.py:227][0m Rewards obtained: [286.20348702692485], Lows: [13], Highs: [5], Total time: 5751.185512999999
[32m[0906 16-34-10 @MBExp.py:144][0m ####################################################################
[32m[0906 16-34-10 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 16-34-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03346, current rewards: 0.06321, mean: 0.00632
[32m[0906 16-34-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03403, current rewards: 5.68485, mean: 0.09475
[32m[0906 16-34-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03414, current rewards: 11.04923, mean: 0.10045
[32m[0906 16-34-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03417, current rewards: 16.48663, mean: 0.10304
[32m[0906 16-34-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03422, current rewards: 21.93131, mean: 0.10443
[32m[0906 16-34-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03420, current rewards: 27.38049, mean: 0.10531
[32m[0906 16-34-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03418, current rewards: 32.81932, mean: 0.10587
[32m[0906 16-34-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03415, current rewards: 38.26123, mean: 0.10628
[32m[0906 16-34-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03416, current rewards: 43.70221, mean: 0.10659
[32m[0906 16-34-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03418, current rewards: 49.13617, mean: 0.10682
[32m[0906 16-34-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03418, current rewards: 54.49939, mean: 0.10686
[32m[0906 16-34-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03417, current rewards: 57.90043, mean: 0.10339
[32m[0906 16-34-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03418, current rewards: 63.44672, mean: 0.10401
[32m[0906 16-34-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03414, current rewards: 69.00169, mean: 0.10455
[32m[0906 16-34-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03410, current rewards: 74.54873, mean: 0.10500
[32m[0906 16-34-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03406, current rewards: 80.10024, mean: 0.10540
[32m[0906 16-34-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03402, current rewards: 85.65219, mean: 0.10574
[32m[0906 16-34-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03397, current rewards: 91.20653, mean: 0.10605
[32m[0906 16-34-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03394, current rewards: 96.75687, mean: 0.10633
[32m[0906 16-34-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03390, current rewards: 102.30601, mean: 0.10657
[32m[0906 16-34-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03388, current rewards: 107.85790, mean: 0.10679
[32m[0906 16-34-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03386, current rewards: 113.59203, mean: 0.10716
[32m[0906 16-34-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03384, current rewards: 119.11912, mean: 0.10731
[32m[0906 16-34-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03382, current rewards: 124.64820, mean: 0.10746
[32m[0906 16-34-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03381, current rewards: 130.18403, mean: 0.10759
[32m[0906 16-34-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03378, current rewards: 135.71333, mean: 0.10771
[32m[0906 16-34-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03377, current rewards: 141.12345, mean: 0.10773
[32m[0906 16-34-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03376, current rewards: 146.64817, mean: 0.10783
[32m[0906 16-34-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03376, current rewards: 152.17547, mean: 0.10793
[32m[0906 16-35-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03379, current rewards: 157.70330, mean: 0.10802
[32m[0906 16-35-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03380, current rewards: 163.23689, mean: 0.10810
[32m[0906 16-35-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03382, current rewards: 166.19012, mean: 0.10653
[32m[0906 16-35-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03383, current rewards: 171.56308, mean: 0.10656
[32m[0906 16-35-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03384, current rewards: 176.92640, mean: 0.10658
[32m[0906 16-35-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03386, current rewards: 182.28987, mean: 0.10660
[32m[0906 16-35-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03388, current rewards: 187.97394, mean: 0.10680
[32m[0906 16-35-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03388, current rewards: 193.37398, mean: 0.10684
[32m[0906 16-35-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03388, current rewards: 198.78571, mean: 0.10687
[32m[0906 16-35-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03390, current rewards: 204.18957, mean: 0.10691
[32m[0906 16-35-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03391, current rewards: 209.58973, mean: 0.10693
[32m[0906 16-35-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03392, current rewards: 211.44946, mean: 0.10520
[32m[0906 16-35-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03393, current rewards: 217.76489, mean: 0.10571
[32m[0906 16-35-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03393, current rewards: 224.08031, mean: 0.10620
[32m[0906 16-35-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03394, current rewards: 220.25896, mean: 0.10197
[32m[0906 16-35-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03394, current rewards: 203.52524, mean: 0.09209
[32m[0906 16-35-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03394, current rewards: 209.06270, mean: 0.09251
[32m[0906 16-35-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03392, current rewards: 214.60009, mean: 0.09290
[32m[0906 16-35-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03391, current rewards: 220.14166, mean: 0.09328
[32m[0906 16-35-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03391, current rewards: 225.67594, mean: 0.09364
[32m[0906 16-35-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03389, current rewards: 230.19364, mean: 0.09357
[32m[0906 16-35-35 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 16-35-35 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-35-36 @MBExp.py:227][0m Rewards obtained: [234.5439697670941], Lows: [4], Highs: [32], Total time: 5836.617181
[32m[0906 16-37-54 @MBExp.py:144][0m ####################################################################
[32m[0906 16-37-54 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 16-37-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03344, current rewards: -2.39026, mean: -0.23903
[32m[0906 16-37-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03403, current rewards: 3.55710, mean: 0.05929
[32m[0906 16-37-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03407, current rewards: 9.49761, mean: 0.08634
[32m[0906 16-37-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03419, current rewards: 15.42350, mean: 0.09640
[32m[0906 16-38-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03418, current rewards: 21.34548, mean: 0.10165
[32m[0906 16-38-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03421, current rewards: 27.26239, mean: 0.10486
[32m[0906 16-38-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03419, current rewards: 28.85289, mean: 0.09307
[32m[0906 16-38-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03421, current rewards: 34.39658, mean: 0.09555
[32m[0906 16-38-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03423, current rewards: 39.94061, mean: 0.09742
[32m[0906 16-38-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03425, current rewards: 45.48179, mean: 0.09887
[32m[0906 16-38-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03427, current rewards: 51.11904, mean: 0.10023
[32m[0906 16-38-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03426, current rewards: 56.67496, mean: 0.10121
[32m[0906 16-38-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03426, current rewards: 62.22437, mean: 0.10201
[32m[0906 16-38-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03418, current rewards: 67.77577, mean: 0.10269
[32m[0906 16-38-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03412, current rewards: 73.32773, mean: 0.10328
[32m[0906 16-38-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03408, current rewards: 78.88230, mean: 0.10379
[32m[0906 16-38-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03403, current rewards: 84.42230, mean: 0.10423
[32m[0906 16-38-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03400, current rewards: 87.86042, mean: 0.10216
[32m[0906 16-38-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03397, current rewards: 91.25653, mean: 0.10028
[32m[0906 16-38-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03394, current rewards: 96.71652, mean: 0.10075
[32m[0906 16-38-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03391, current rewards: 102.17639, mean: 0.10116
[32m[0906 16-38-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03389, current rewards: 107.63636, mean: 0.10154
[32m[0906 16-38-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03387, current rewards: 113.09640, mean: 0.10189
[32m[0906 16-38-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03385, current rewards: 118.55629, mean: 0.10220
[32m[0906 16-38-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03384, current rewards: 120.68871, mean: 0.09974
[32m[0906 16-38-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03382, current rewards: 122.78536, mean: 0.09745
[32m[0906 16-38-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03381, current rewards: 127.95253, mean: 0.09767
[32m[0906 16-38-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03380, current rewards: 133.32744, mean: 0.09803
[32m[0906 16-38-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03380, current rewards: 138.69848, mean: 0.09837
[32m[0906 16-38-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03383, current rewards: 144.07193, mean: 0.09868
[32m[0906 16-38-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03384, current rewards: 149.44080, mean: 0.09897
[32m[0906 16-38-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03386, current rewards: 154.81337, mean: 0.09924
[32m[0906 16-38-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03387, current rewards: 160.19138, mean: 0.09950
[32m[0906 16-38-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03388, current rewards: 165.56660, mean: 0.09974
[32m[0906 16-38-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03390, current rewards: 171.01331, mean: 0.10001
[32m[0906 16-38-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03391, current rewards: 176.50318, mean: 0.10029
[32m[0906 16-38-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03392, current rewards: 181.93364, mean: 0.10052
[32m[0906 16-38-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03393, current rewards: 186.37015, mean: 0.10020
[32m[0906 16-38-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03394, current rewards: 191.93487, mean: 0.10049
[32m[0906 16-39-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03394, current rewards: 197.50160, mean: 0.10077
[32m[0906 16-39-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03395, current rewards: 203.06829, mean: 0.10103
[32m[0906 16-39-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03396, current rewards: 208.64124, mean: 0.10128
[32m[0906 16-39-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03397, current rewards: 214.21332, mean: 0.10152
[32m[0906 16-39-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03398, current rewards: 219.87025, mean: 0.10179
[32m[0906 16-39-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03399, current rewards: 225.78991, mean: 0.10217
[32m[0906 16-39-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03398, current rewards: 233.24298, mean: 0.10320
[32m[0906 16-39-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03397, current rewards: 240.68883, mean: 0.10419
[32m[0906 16-39-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03396, current rewards: 248.13390, mean: 0.10514
[32m[0906 16-39-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03395, current rewards: 255.56788, mean: 0.10604
[32m[0906 16-39-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03394, current rewards: 263.02055, mean: 0.10692
[32m[0906 16-39-19 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 16-39-19 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-39-19 @MBExp.py:227][0m Rewards obtained: [268.9864856979708], Lows: [5], Highs: [10], Total time: 5922.191787999999
[32m[0906 16-41-40 @MBExp.py:144][0m ####################################################################
[32m[0906 16-41-40 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 16-41-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03592, current rewards: -0.80158, mean: -0.08016
[32m[0906 16-41-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03460, current rewards: 4.92131, mean: 0.08202
[32m[0906 16-41-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03442, current rewards: 10.54447, mean: 0.09586
[32m[0906 16-41-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03435, current rewards: 16.17253, mean: 0.10108
[32m[0906 16-41-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03433, current rewards: 21.79417, mean: 0.10378
[32m[0906 16-41-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03433, current rewards: 27.41979, mean: 0.10546
[32m[0906 16-41-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03432, current rewards: 33.03302, mean: 0.10656
[32m[0906 16-41-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03433, current rewards: 38.65586, mean: 0.10738
[32m[0906 16-41-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03436, current rewards: 40.13365, mean: 0.09789
[32m[0906 16-41-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03438, current rewards: 45.67285, mean: 0.09929
[32m[0906 16-41-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03439, current rewards: 51.37724, mean: 0.10074
[32m[0906 16-41-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03438, current rewards: 57.08400, mean: 0.10194
[32m[0906 16-42-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03432, current rewards: 62.78744, mean: 0.10293
[32m[0906 16-42-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03425, current rewards: 68.49298, mean: 0.10378
[32m[0906 16-42-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03419, current rewards: 74.19592, mean: 0.10450
[32m[0906 16-42-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03414, current rewards: 79.89853, mean: 0.10513
[32m[0906 16-42-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03409, current rewards: 85.60272, mean: 0.10568
[32m[0906 16-42-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03405, current rewards: 90.06546, mean: 0.10473
[32m[0906 16-42-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03402, current rewards: 95.39772, mean: 0.10483
[32m[0906 16-42-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03400, current rewards: 100.63014, mean: 0.10482
[32m[0906 16-42-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03398, current rewards: 105.86539, mean: 0.10482
[32m[0906 16-42-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03396, current rewards: 111.09843, mean: 0.10481
[32m[0906 16-42-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03393, current rewards: 116.33282, mean: 0.10480
[32m[0906 16-42-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03392, current rewards: 121.56875, mean: 0.10480
[32m[0906 16-42-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03390, current rewards: 126.80836, mean: 0.10480
[32m[0906 16-42-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03390, current rewards: 132.04000, mean: 0.10479
[32m[0906 16-42-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03387, current rewards: 137.24546, mean: 0.10477
[32m[0906 16-42-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03385, current rewards: 138.48859, mean: 0.10183
[32m[0906 16-42-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03386, current rewards: 144.02980, mean: 0.10215
[32m[0906 16-42-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03387, current rewards: 149.56911, mean: 0.10244
[32m[0906 16-42-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03388, current rewards: 155.10589, mean: 0.10272
[32m[0906 16-42-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03390, current rewards: 160.64598, mean: 0.10298
[32m[0906 16-42-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03391, current rewards: 166.18323, mean: 0.10322
[32m[0906 16-42-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03393, current rewards: 171.72292, mean: 0.10345
[32m[0906 16-42-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03394, current rewards: 177.14181, mean: 0.10359
[32m[0906 16-42-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03396, current rewards: 178.40072, mean: 0.10136
[32m[0906 16-42-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03397, current rewards: 183.93226, mean: 0.10162
[32m[0906 16-42-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03398, current rewards: 189.45890, mean: 0.10186
[32m[0906 16-42-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03399, current rewards: 194.98837, mean: 0.10209
[32m[0906 16-42-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03400, current rewards: 200.51478, mean: 0.10230
[32m[0906 16-42-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03401, current rewards: 206.03867, mean: 0.10251
[32m[0906 16-42-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03402, current rewards: 211.56440, mean: 0.10270
[32m[0906 16-42-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03402, current rewards: 217.01690, mean: 0.10285
[32m[0906 16-42-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03402, current rewards: 222.54026, mean: 0.10303
[32m[0906 16-42-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03403, current rewards: 228.05998, mean: 0.10319
[32m[0906 16-42-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03403, current rewards: 220.97437, mean: 0.09778
[32m[0906 16-42-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03402, current rewards: 225.24983, mean: 0.09751
[32m[0906 16-43-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03400, current rewards: 230.48319, mean: 0.09766
[32m[0906 16-43-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03399, current rewards: 235.70849, mean: 0.09780
[32m[0906 16-43-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03398, current rewards: 240.94013, mean: 0.09794
[32m[0906 16-43-05 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 16-43-05 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-43-05 @MBExp.py:227][0m Rewards obtained: [245.15381584714848], Lows: [11], Highs: [6], Total time: 6007.846723999999
[32m[0906 16-45-27 @MBExp.py:144][0m ####################################################################
[32m[0906 16-45-27 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 16-45-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03767, current rewards: -1.10238, mean: -0.11024
[32m[0906 16-45-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03488, current rewards: 4.55392, mean: 0.07590
[32m[0906 16-45-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03461, current rewards: 10.34336, mean: 0.09403
[32m[0906 16-45-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03451, current rewards: 16.12544, mean: 0.10078
[32m[0906 16-45-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03440, current rewards: 21.90786, mean: 0.10432
[32m[0906 16-45-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03438, current rewards: 27.69164, mean: 0.10651
[32m[0906 16-45-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03437, current rewards: 33.48269, mean: 0.10801
[32m[0906 16-45-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03438, current rewards: 39.26492, mean: 0.10907
[32m[0906 16-45-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03438, current rewards: 45.05117, mean: 0.10988
[32m[0906 16-45-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03438, current rewards: 51.18659, mean: 0.11128
[32m[0906 16-45-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03437, current rewards: 57.16828, mean: 0.11209
[32m[0906 16-45-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03434, current rewards: 63.15027, mean: 0.11277
[32m[0906 16-45-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03429, current rewards: 69.13653, mean: 0.11334
[32m[0906 16-45-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03423, current rewards: 70.63098, mean: 0.10702
[32m[0906 16-45-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03417, current rewards: 76.19029, mean: 0.10731
[32m[0906 16-45-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03413, current rewards: 81.74354, mean: 0.10756
[32m[0906 16-45-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03409, current rewards: 87.30432, mean: 0.10778
[32m[0906 16-45-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03406, current rewards: 88.67316, mean: 0.10311
[32m[0906 16-45-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03403, current rewards: 94.13139, mean: 0.10344
[32m[0906 16-46-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03400, current rewards: 99.81835, mean: 0.10398
[32m[0906 16-46-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03398, current rewards: 105.50443, mean: 0.10446
[32m[0906 16-46-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03396, current rewards: 111.19135, mean: 0.10490
[32m[0906 16-46-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03393, current rewards: 116.87359, mean: 0.10529
[32m[0906 16-46-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03391, current rewards: 122.56022, mean: 0.10566
[32m[0906 16-46-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03389, current rewards: 128.24548, mean: 0.10599
[32m[0906 16-46-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03387, current rewards: 133.92875, mean: 0.10629
[32m[0906 16-46-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03394, current rewards: 125.78214, mean: 0.09602
[32m[0906 16-46-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03392, current rewards: 131.56573, mean: 0.09674
[32m[0906 16-46-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03393, current rewards: 137.34868, mean: 0.09741
[32m[0906 16-46-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03393, current rewards: 143.12891, mean: 0.09803
[32m[0906 16-46-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03395, current rewards: 148.90333, mean: 0.09861
[32m[0906 16-46-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03396, current rewards: 154.68653, mean: 0.09916
[32m[0906 16-46-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03397, current rewards: 154.30805, mean: 0.09584
[32m[0906 16-46-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03398, current rewards: 160.19869, mean: 0.09651
[32m[0906 16-46-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03399, current rewards: 165.95966, mean: 0.09705
[32m[0906 16-46-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03400, current rewards: 171.73782, mean: 0.09758
[32m[0906 16-46-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03402, current rewards: 177.56393, mean: 0.09810
[32m[0906 16-46-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03403, current rewards: 183.39123, mean: 0.09860
[32m[0906 16-46-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03403, current rewards: 180.64405, mean: 0.09458
[32m[0906 16-46-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03404, current rewards: 186.18960, mean: 0.09499
[32m[0906 16-46-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03404, current rewards: 191.73159, mean: 0.09539
[32m[0906 16-46-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03406, current rewards: 197.27926, mean: 0.09577
[32m[0906 16-46-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03406, current rewards: 202.82584, mean: 0.09613
[32m[0906 16-46-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03407, current rewards: 208.42873, mean: 0.09649
[32m[0906 16-46-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03408, current rewards: 213.96632, mean: 0.09682
[32m[0906 16-46-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03408, current rewards: 219.50911, mean: 0.09713
[32m[0906 16-46-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03406, current rewards: 225.05010, mean: 0.09742
[32m[0906 16-46-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03404, current rewards: 230.59262, mean: 0.09771
[32m[0906 16-46-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03403, current rewards: 236.13653, mean: 0.09798
[32m[0906 16-46-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03402, current rewards: 241.67509, mean: 0.09824
[32m[0906 16-46-53 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 16-46-53 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-46-53 @MBExp.py:227][0m Rewards obtained: [246.108590285088], Lows: [19], Highs: [5], Total time: 6093.611105999999
[32m[0906 16-49-18 @MBExp.py:144][0m ####################################################################
[32m[0906 16-49-18 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 16-49-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03722, current rewards: -2.97447, mean: -0.29745
[32m[0906 16-49-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03473, current rewards: 3.02634, mean: 0.05044
[32m[0906 16-49-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03458, current rewards: 8.88263, mean: 0.08075
[32m[0906 16-49-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03449, current rewards: 14.74735, mean: 0.09217
[32m[0906 16-49-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03442, current rewards: 20.60908, mean: 0.09814
[32m[0906 16-49-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03443, current rewards: 26.46771, mean: 0.10180
[32m[0906 16-49-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03442, current rewards: 32.32685, mean: 0.10428
[32m[0906 16-49-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03440, current rewards: 38.18788, mean: 0.10608
[32m[0906 16-49-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03438, current rewards: 39.78078, mean: 0.09703
[32m[0906 16-49-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03442, current rewards: 45.42791, mean: 0.09876
[32m[0906 16-49-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03441, current rewards: 51.11095, mean: 0.10022
[32m[0906 16-49-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03434, current rewards: 56.79279, mean: 0.10142
[32m[0906 16-49-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03429, current rewards: 62.47689, mean: 0.10242
[32m[0906 16-49-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03423, current rewards: 68.16203, mean: 0.10328
[32m[0906 16-49-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03417, current rewards: 73.84177, mean: 0.10400
[32m[0906 16-49-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03411, current rewards: 79.52779, mean: 0.10464
[32m[0906 16-49-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03406, current rewards: 84.15048, mean: 0.10389
[32m[0906 16-49-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03404, current rewards: 89.87401, mean: 0.10450
[32m[0906 16-49-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03400, current rewards: 95.71156, mean: 0.10518
[32m[0906 16-49-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03397, current rewards: 101.54853, mean: 0.10578
[32m[0906 16-49-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03395, current rewards: 107.39540, mean: 0.10633
[32m[0906 16-49-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03392, current rewards: 108.91140, mean: 0.10275
[32m[0906 16-49-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03390, current rewards: 114.47985, mean: 0.10313
[32m[0906 16-49-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03388, current rewards: 120.04853, mean: 0.10349
[32m[0906 16-49-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03386, current rewards: 125.61269, mean: 0.10381
[32m[0906 16-50-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03385, current rewards: 131.17872, mean: 0.10411
[32m[0906 16-50-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03384, current rewards: 134.70431, mean: 0.10283
[32m[0906 16-50-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03382, current rewards: 140.44040, mean: 0.10327
[32m[0906 16-50-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03384, current rewards: 146.17502, mean: 0.10367
[32m[0906 16-50-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03385, current rewards: 151.91371, mean: 0.10405
[32m[0906 16-50-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03387, current rewards: 157.64976, mean: 0.10440
[32m[0906 16-50-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03389, current rewards: 163.38722, mean: 0.10474
[32m[0906 16-50-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03390, current rewards: 169.12305, mean: 0.10505
[32m[0906 16-50-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03392, current rewards: 174.86200, mean: 0.10534
[32m[0906 16-50-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03393, current rewards: 180.62550, mean: 0.10563
[32m[0906 16-50-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03394, current rewards: 186.34228, mean: 0.10588
[32m[0906 16-50-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03395, current rewards: 192.05913, mean: 0.10611
[32m[0906 16-50-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03395, current rewards: 195.86978, mean: 0.10531
[32m[0906 16-50-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03397, current rewards: 201.52785, mean: 0.10551
[32m[0906 16-50-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03398, current rewards: 207.18994, mean: 0.10571
[32m[0906 16-50-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03399, current rewards: 212.85415, mean: 0.10590
[32m[0906 16-50-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03400, current rewards: 218.51189, mean: 0.10607
[32m[0906 16-50-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03401, current rewards: 224.31215, mean: 0.10631
[32m[0906 16-50-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03403, current rewards: 229.93286, mean: 0.10645
[32m[0906 16-50-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03404, current rewards: 235.55136, mean: 0.10658
[32m[0906 16-50-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03404, current rewards: 241.16687, mean: 0.10671
[32m[0906 16-50-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03403, current rewards: 246.78978, mean: 0.10684
[32m[0906 16-50-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03402, current rewards: 249.52718, mean: 0.10573
[32m[0906 16-50-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03400, current rewards: 255.32900, mean: 0.10595
[32m[0906 16-50-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03399, current rewards: 261.14094, mean: 0.10615
[32m[0906 16-50-43 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 16-50-43 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-50-43 @MBExp.py:227][0m Rewards obtained: [265.7101873812911], Lows: [7], Highs: [6], Total time: 6179.297164
[32m[0906 16-53-10 @MBExp.py:144][0m ####################################################################
[32m[0906 16-53-10 @MBExp.py:145][0m Starting training iteration 72.
[32m[0906 16-53-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03321, current rewards: 0.07459, mean: 0.00746
[32m[0906 16-53-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03420, current rewards: 5.12198, mean: 0.08537
[32m[0906 16-53-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03434, current rewards: 10.29228, mean: 0.09357
[32m[0906 16-53-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03434, current rewards: 15.45703, mean: 0.09661
[32m[0906 16-53-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03430, current rewards: 20.61967, mean: 0.09819
[32m[0906 16-53-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03435, current rewards: 25.78679, mean: 0.09918
[32m[0906 16-53-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03434, current rewards: 30.94935, mean: 0.09984
[32m[0906 16-53-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03432, current rewards: 36.66032, mean: 0.10183
[32m[0906 16-53-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03433, current rewards: 41.95609, mean: 0.10233
[32m[0906 16-53-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03433, current rewards: 47.47428, mean: 0.10320
[32m[0906 16-53-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03431, current rewards: 52.71901, mean: 0.10337
[32m[0906 16-53-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03424, current rewards: 57.92314, mean: 0.10343
[32m[0906 16-53-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03417, current rewards: 63.13172, mean: 0.10349
[32m[0906 16-53-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03414, current rewards: 66.36299, mean: 0.10055
[32m[0906 16-53-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03407, current rewards: 71.88009, mean: 0.10124
[32m[0906 16-53-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03403, current rewards: 77.39864, mean: 0.10184
[32m[0906 16-53-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03400, current rewards: 82.91498, mean: 0.10236
[32m[0906 16-53-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03396, current rewards: 88.43091, mean: 0.10283
[32m[0906 16-53-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03392, current rewards: 93.90829, mean: 0.10320
[32m[0906 16-53-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03390, current rewards: 99.43435, mean: 0.10358
[32m[0906 16-53-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03388, current rewards: 104.95030, mean: 0.10391
[32m[0906 16-53-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03386, current rewards: 108.38886, mean: 0.10225
[32m[0906 16-53-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03384, current rewards: 113.92274, mean: 0.10263
[32m[0906 16-53-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03384, current rewards: 119.45908, mean: 0.10298
[32m[0906 16-53-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03382, current rewards: 125.00333, mean: 0.10331
[32m[0906 16-53-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03380, current rewards: 130.54475, mean: 0.10361
[32m[0906 16-53-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03379, current rewards: 135.82662, mean: 0.10368
[32m[0906 16-53-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03378, current rewards: 141.34818, mean: 0.10393
[32m[0906 16-53-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03380, current rewards: 142.51217, mean: 0.10107
[32m[0906 16-53-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03382, current rewards: 147.67785, mean: 0.10115
[32m[0906 16-54-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03383, current rewards: 152.84126, mean: 0.10122
[32m[0906 16-54-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03385, current rewards: 158.00540, mean: 0.10129
[32m[0906 16-54-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03387, current rewards: 163.16851, mean: 0.10135
[32m[0906 16-54-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03389, current rewards: 168.32827, mean: 0.10140
[32m[0906 16-54-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03390, current rewards: 173.49362, mean: 0.10146
[32m[0906 16-54-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03391, current rewards: 178.66360, mean: 0.10151
[32m[0906 16-54-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03392, current rewards: 183.82885, mean: 0.10156
[32m[0906 16-54-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03393, current rewards: 187.99602, mean: 0.10107
[32m[0906 16-54-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03395, current rewards: 193.43204, mean: 0.10127
[32m[0906 16-54-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03395, current rewards: 198.86642, mean: 0.10146
[32m[0906 16-54-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03395, current rewards: 204.29904, mean: 0.10164
[32m[0906 16-54-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03396, current rewards: 209.73120, mean: 0.10181
[32m[0906 16-54-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03397, current rewards: 215.27426, mean: 0.10203
[32m[0906 16-54-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03398, current rewards: 220.78038, mean: 0.10221
[32m[0906 16-54-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03399, current rewards: 226.23595, mean: 0.10237
[32m[0906 16-54-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03400, current rewards: 231.69202, mean: 0.10252
[32m[0906 16-54-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03400, current rewards: 236.19682, mean: 0.10225
[32m[0906 16-54-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03399, current rewards: 241.72063, mean: 0.10242
[32m[0906 16-54-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03398, current rewards: 247.24803, mean: 0.10259
[32m[0906 16-54-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03397, current rewards: 252.77494, mean: 0.10275
[32m[0906 16-54-35 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 16-54-35 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-54-35 @MBExp.py:227][0m Rewards obtained: [257.1971342542159], Lows: [4], Highs: [4], Total time: 6264.954537
[32m[0906 16-57-04 @MBExp.py:144][0m ####################################################################
[32m[0906 16-57-04 @MBExp.py:145][0m Starting training iteration 73.
[32m[0906 16-57-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03453, current rewards: 0.00423, mean: 0.00042
[32m[0906 16-57-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03448, current rewards: 5.49231, mean: 0.09154
[32m[0906 16-57-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03437, current rewards: 11.05923, mean: 0.10054
[32m[0906 16-57-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03436, current rewards: 16.62743, mean: 0.10392
[32m[0906 16-57-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03436, current rewards: 22.19578, mean: 0.10569
[32m[0906 16-57-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03437, current rewards: 27.76478, mean: 0.10679
[32m[0906 16-57-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03433, current rewards: 33.33356, mean: 0.10753
[32m[0906 16-57-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03432, current rewards: 38.90312, mean: 0.10806
[32m[0906 16-57-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03432, current rewards: 42.35774, mean: 0.10331
[32m[0906 16-57-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03432, current rewards: 48.05680, mean: 0.10447
[32m[0906 16-57-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03423, current rewards: 53.41520, mean: 0.10474
[32m[0906 16-57-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03418, current rewards: 58.77303, mean: 0.10495
[32m[0906 16-57-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03413, current rewards: 64.12962, mean: 0.10513
[32m[0906 16-57-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03409, current rewards: 69.49743, mean: 0.10530
[32m[0906 16-57-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03405, current rewards: 74.85493, mean: 0.10543
[32m[0906 16-57-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03401, current rewards: 80.21115, mean: 0.10554
[32m[0906 16-57-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03400, current rewards: 80.59315, mean: 0.09950
[32m[0906 16-57-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03398, current rewards: 86.75850, mean: 0.10088
[32m[0906 16-57-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03396, current rewards: 92.83751, mean: 0.10202
[32m[0906 16-57-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03394, current rewards: 98.91856, mean: 0.10304
[32m[0906 16-57-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03392, current rewards: 105.00218, mean: 0.10396
[32m[0906 16-57-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03390, current rewards: 111.08151, mean: 0.10479
[32m[0906 16-57-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03388, current rewards: 117.16532, mean: 0.10555
[32m[0906 16-57-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03387, current rewards: 123.25462, mean: 0.10625
[32m[0906 16-57-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03385, current rewards: 129.34361, mean: 0.10690
[32m[0906 16-57-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03383, current rewards: 135.42023, mean: 0.10748
[32m[0906 16-57-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03382, current rewards: 141.49463, mean: 0.10801
[32m[0906 16-57-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03383, current rewards: 145.01775, mean: 0.10663
[32m[0906 16-57-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03384, current rewards: 150.50888, mean: 0.10674
[32m[0906 16-57-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03386, current rewards: 156.00150, mean: 0.10685
[32m[0906 16-57-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03387, current rewards: 161.49749, mean: 0.10695
[32m[0906 16-57-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03388, current rewards: 166.99105, mean: 0.10705
[32m[0906 16-57-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03390, current rewards: 172.48381, mean: 0.10713
[32m[0906 16-58-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03391, current rewards: 177.97277, mean: 0.10721
[32m[0906 16-58-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03392, current rewards: 181.40847, mean: 0.10609
[32m[0906 16-58-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03394, current rewards: 186.91730, mean: 0.10620
[32m[0906 16-58-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03395, current rewards: 192.42465, mean: 0.10631
[32m[0906 16-58-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03396, current rewards: 197.93333, mean: 0.10642
[32m[0906 16-58-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03397, current rewards: 203.44126, mean: 0.10651
[32m[0906 16-58-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03398, current rewards: 208.94910, mean: 0.10661
[32m[0906 16-58-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03399, current rewards: 214.45776, mean: 0.10670
[32m[0906 16-58-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03401, current rewards: 214.64613, mean: 0.10420
[32m[0906 16-58-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03401, current rewards: 220.35997, mean: 0.10444
[32m[0906 16-58-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03402, current rewards: 226.07929, mean: 0.10467
[32m[0906 16-58-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03402, current rewards: 231.80240, mean: 0.10489
[32m[0906 16-58-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03403, current rewards: 237.52224, mean: 0.10510
[32m[0906 16-58-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03404, current rewards: 243.24238, mean: 0.10530
[32m[0906 16-58-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03402, current rewards: 248.96600, mean: 0.10549
[32m[0906 16-58-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03401, current rewards: 254.68709, mean: 0.10568
[32m[0906 16-58-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03400, current rewards: 260.40609, mean: 0.10586
[32m[0906 16-58-30 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 16-58-30 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-58-30 @MBExp.py:227][0m Rewards obtained: [265.06478175795075], Lows: [6], Highs: [5], Total time: 6350.667426999999
[32m[0906 17-01-01 @MBExp.py:144][0m ####################################################################
[32m[0906 17-01-01 @MBExp.py:145][0m Starting training iteration 74.
[32m[0906 17-01-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03497, current rewards: -2.49564, mean: -0.24956
[32m[0906 17-01-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03450, current rewards: 3.10974, mean: 0.05183
[32m[0906 17-01-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03446, current rewards: 8.72231, mean: 0.07929
[32m[0906 17-01-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03441, current rewards: 14.34064, mean: 0.08963
[32m[0906 17-01-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03432, current rewards: 19.95130, mean: 0.09501
[32m[0906 17-01-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03432, current rewards: 25.56572, mean: 0.09833
[32m[0906 17-01-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03433, current rewards: 31.18465, mean: 0.10060
[32m[0906 17-01-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03432, current rewards: 36.79124, mean: 0.10220
[32m[0906 17-01-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03429, current rewards: 37.88874, mean: 0.09241
[32m[0906 17-01-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03427, current rewards: 43.15013, mean: 0.09380
[32m[0906 17-01-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03416, current rewards: 48.41292, mean: 0.09493
[32m[0906 17-01-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03409, current rewards: 53.67318, mean: 0.09584
[32m[0906 17-01-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03403, current rewards: 58.93212, mean: 0.09661
[32m[0906 17-01-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03399, current rewards: 64.19125, mean: 0.09726
[32m[0906 17-01-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03396, current rewards: 69.45354, mean: 0.09782
[32m[0906 17-01-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03393, current rewards: 74.71397, mean: 0.09831
[32m[0906 17-01-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03390, current rewards: 80.24237, mean: 0.09906
[32m[0906 17-01-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03388, current rewards: 87.18970, mean: 0.10138
[32m[0906 17-01-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03387, current rewards: 72.32090, mean: 0.07947
[32m[0906 17-01-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03384, current rewards: 77.99635, mean: 0.08125
[32m[0906 17-01-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03382, current rewards: 83.67706, mean: 0.08285
[32m[0906 17-01-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03381, current rewards: 89.35738, mean: 0.08430
[32m[0906 17-01-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03379, current rewards: 95.04047, mean: 0.08562
[32m[0906 17-01-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03376, current rewards: 99.17924, mean: 0.08550
[32m[0906 17-01-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03376, current rewards: 105.42391, mean: 0.08713
[32m[0906 17-01-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03376, current rewards: 111.53780, mean: 0.08852
[32m[0906 17-01-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03375, current rewards: 117.68815, mean: 0.08984
[32m[0906 17-01-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03374, current rewards: 123.86748, mean: 0.09108
[32m[0906 17-01-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03376, current rewards: 130.02254, mean: 0.09221
[32m[0906 17-01-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03378, current rewards: 136.19544, mean: 0.09328
[32m[0906 17-01-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03384, current rewards: 133.19064, mean: 0.08821
[32m[0906 17-01-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03385, current rewards: 138.74203, mean: 0.08894
[32m[0906 17-01-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03386, current rewards: 144.28459, mean: 0.08962
[32m[0906 17-01-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03388, current rewards: 149.88223, mean: 0.09029
[32m[0906 17-01-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03390, current rewards: 151.58393, mean: 0.08865
[32m[0906 17-02-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03392, current rewards: 157.13684, mean: 0.08928
[32m[0906 17-02-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03393, current rewards: 162.69172, mean: 0.08988
[32m[0906 17-02-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03395, current rewards: 168.24201, mean: 0.09045
[32m[0906 17-02-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03396, current rewards: 173.79838, mean: 0.09099
[32m[0906 17-02-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03396, current rewards: 179.35265, mean: 0.09151
[32m[0906 17-02-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03397, current rewards: 184.90683, mean: 0.09199
[32m[0906 17-02-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03398, current rewards: 190.42058, mean: 0.09244
[32m[0906 17-02-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03399, current rewards: 195.96589, mean: 0.09287
[32m[0906 17-02-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03400, current rewards: 201.60080, mean: 0.09333
[32m[0906 17-02-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03401, current rewards: 207.27272, mean: 0.09379
[32m[0906 17-02-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03402, current rewards: 212.95298, mean: 0.09423
[32m[0906 17-02-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03402, current rewards: 218.62745, mean: 0.09464
[32m[0906 17-02-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03401, current rewards: 224.30167, mean: 0.09504
[32m[0906 17-02-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03400, current rewards: 229.97926, mean: 0.09543
[32m[0906 17-02-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03399, current rewards: 235.65488, mean: 0.09579
[32m[0906 17-02-26 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 17-02-26 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-02-26 @MBExp.py:227][0m Rewards obtained: [240.19949225761061], Lows: [11], Highs: [20], Total time: 6436.352405
[32m[0906 17-04-59 @MBExp.py:144][0m ####################################################################
[32m[0906 17-04-59 @MBExp.py:145][0m Starting training iteration 75.
[32m[0906 17-04-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03393, current rewards: -0.13943, mean: -0.01394
[32m[0906 17-05-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03421, current rewards: 5.47130, mean: 0.09119
[32m[0906 17-05-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03430, current rewards: 11.07742, mean: 0.10070
[32m[0906 17-05-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03424, current rewards: 16.68504, mean: 0.10428
[32m[0906 17-05-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03428, current rewards: 22.29413, mean: 0.10616
[32m[0906 17-05-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03428, current rewards: 27.90147, mean: 0.10731
[32m[0906 17-05-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03429, current rewards: 33.50492, mean: 0.10808
[32m[0906 17-05-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03428, current rewards: 39.11518, mean: 0.10865
[32m[0906 17-05-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03430, current rewards: 44.72476, mean: 0.10908
[32m[0906 17-05-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03419, current rewards: 50.33163, mean: 0.10942
[32m[0906 17-05-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03413, current rewards: 55.94016, mean: 0.10969
[32m[0906 17-05-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03406, current rewards: 61.54403, mean: 0.10990
[32m[0906 17-05-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03401, current rewards: 66.62113, mean: 0.10921
[32m[0906 17-05-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03397, current rewards: 72.16541, mean: 0.10934
[32m[0906 17-05-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03393, current rewards: 77.70201, mean: 0.10944
[32m[0906 17-05-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03390, current rewards: 83.33086, mean: 0.10965
[32m[0906 17-05-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03389, current rewards: 89.09944, mean: 0.11000
[32m[0906 17-05-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03387, current rewards: 94.70164, mean: 0.11012
[32m[0906 17-05-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03385, current rewards: 98.19533, mean: 0.10791
[32m[0906 17-05-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03383, current rewards: 103.73352, mean: 0.10806
[32m[0906 17-05-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03381, current rewards: 109.27541, mean: 0.10819
[32m[0906 17-05-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03380, current rewards: 114.81570, mean: 0.10832
[32m[0906 17-05-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03377, current rewards: 120.35817, mean: 0.10843
[32m[0906 17-05-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03375, current rewards: 125.90205, mean: 0.10854
[32m[0906 17-05-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03375, current rewards: 131.32524, mean: 0.10853
[32m[0906 17-05-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03374, current rewards: 136.88342, mean: 0.10864
[32m[0906 17-05-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03374, current rewards: 142.43982, mean: 0.10873
[32m[0906 17-05-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03373, current rewards: 147.99911, mean: 0.10882
[32m[0906 17-05-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03376, current rewards: 153.56155, mean: 0.10891
[32m[0906 17-05-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03378, current rewards: 158.16745, mean: 0.10833
[32m[0906 17-05-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03380, current rewards: 163.00123, mean: 0.10795
[32m[0906 17-05-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03383, current rewards: 167.83561, mean: 0.10759
[32m[0906 17-05-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03384, current rewards: 172.76336, mean: 0.10731
[32m[0906 17-05-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03385, current rewards: 177.65526, mean: 0.10702
[32m[0906 17-05-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03386, current rewards: 182.54921, mean: 0.10675
[32m[0906 17-05-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03388, current rewards: 187.44285, mean: 0.10650
[32m[0906 17-06-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03390, current rewards: 192.33419, mean: 0.10626
[32m[0906 17-06-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03392, current rewards: 197.22458, mean: 0.10603
[32m[0906 17-06-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03393, current rewards: 198.38445, mean: 0.10387
[32m[0906 17-06-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03394, current rewards: 204.14211, mean: 0.10415
[32m[0906 17-06-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03395, current rewards: 209.83933, mean: 0.10440
[32m[0906 17-06-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03396, current rewards: 215.45797, mean: 0.10459
[32m[0906 17-06-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03396, current rewards: 221.13780, mean: 0.10480
[32m[0906 17-06-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03397, current rewards: 226.81858, mean: 0.10501
[32m[0906 17-06-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03398, current rewards: 232.50091, mean: 0.10520
[32m[0906 17-06-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03399, current rewards: 238.18231, mean: 0.10539
[32m[0906 17-06-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03399, current rewards: 243.86840, mean: 0.10557
[32m[0906 17-06-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03399, current rewards: 249.55234, mean: 0.10574
[32m[0906 17-06-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03398, current rewards: 252.65966, mean: 0.10484
[32m[0906 17-06-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03397, current rewards: 258.50861, mean: 0.10508
[32m[0906 17-06-24 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 17-06-24 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-06-25 @MBExp.py:227][0m Rewards obtained: [263.037166095229], Lows: [4], Highs: [4], Total time: 6521.991864
[32m[0906 17-08-59 @MBExp.py:144][0m ####################################################################
[32m[0906 17-08-59 @MBExp.py:145][0m Starting training iteration 76.
[32m[0906 17-09-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03545, current rewards: -3.33848, mean: -0.33385
[32m[0906 17-09-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03446, current rewards: 2.31862, mean: 0.03864
[32m[0906 17-09-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03437, current rewards: 7.91527, mean: 0.07196
[32m[0906 17-09-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03437, current rewards: 13.51266, mean: 0.08445
[32m[0906 17-09-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03438, current rewards: 19.10663, mean: 0.09098
[32m[0906 17-09-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03437, current rewards: 24.69644, mean: 0.09499
[32m[0906 17-09-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03442, current rewards: 28.17831, mean: 0.09090
[32m[0906 17-09-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03441, current rewards: 33.66380, mean: 0.09351
[32m[0906 17-09-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03431, current rewards: 39.12416, mean: 0.09542
[32m[0906 17-09-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03427, current rewards: 44.65910, mean: 0.09708
[32m[0906 17-09-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03418, current rewards: 50.20117, mean: 0.09843
[32m[0906 17-09-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03409, current rewards: 55.74341, mean: 0.09954
[32m[0906 17-09-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03405, current rewards: 61.27528, mean: 0.10045
[32m[0906 17-09-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03401, current rewards: 66.81744, mean: 0.10124
[32m[0906 17-09-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03400, current rewards: 72.35742, mean: 0.10191
[32m[0906 17-09-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03396, current rewards: 77.90267, mean: 0.10250
[32m[0906 17-09-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03392, current rewards: 83.62913, mean: 0.10325
[32m[0906 17-09-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03389, current rewards: 89.14037, mean: 0.10365
[32m[0906 17-09-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03388, current rewards: 92.70639, mean: 0.10188
[32m[0906 17-09-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03386, current rewards: 99.80294, mean: 0.10396
[32m[0906 17-09-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03384, current rewards: 106.89950, mean: 0.10584
[32m[0906 17-09-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03383, current rewards: 113.99605, mean: 0.10754
[32m[0906 17-09-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03381, current rewards: 121.09261, mean: 0.10909
[32m[0906 17-09-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03379, current rewards: 128.18916, mean: 0.11051
[32m[0906 17-09-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03378, current rewards: 134.28168, mean: 0.11098
[32m[0906 17-09-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03377, current rewards: 129.56192, mean: 0.10283
[32m[0906 17-09-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03376, current rewards: 79.56192, mean: 0.06073
[32m[0906 17-09-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03375, current rewards: 29.56192, mean: 0.02174
[32m[0906 17-09-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03378, current rewards: -20.43808, mean: -0.01450
[32m[0906 17-09-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03379, current rewards: -70.43808, mean: -0.04825
[32m[0906 17-09-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03381, current rewards: -120.43808, mean: -0.07976
[32m[0906 17-09-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03383, current rewards: -170.43808, mean: -0.10926
[32m[0906 17-09-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03384, current rewards: -220.43808, mean: -0.13692
[32m[0906 17-09-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03386, current rewards: -270.43808, mean: -0.16291
[32m[0906 17-09-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03387, current rewards: -320.43808, mean: -0.18739
[32m[0906 17-09-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03389, current rewards: -370.43808, mean: -0.21048
[32m[0906 17-10-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03390, current rewards: -420.43808, mean: -0.23229
[32m[0906 17-10-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03391, current rewards: -470.43808, mean: -0.25292
[32m[0906 17-10-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03393, current rewards: -520.43808, mean: -0.27248
[32m[0906 17-10-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03394, current rewards: -570.43808, mean: -0.29104
[32m[0906 17-10-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03394, current rewards: -620.43808, mean: -0.30868
[32m[0906 17-10-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03396, current rewards: -670.43808, mean: -0.32546
[32m[0906 17-10-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03396, current rewards: -720.43808, mean: -0.34144
[32m[0906 17-10-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03397, current rewards: -770.43808, mean: -0.35668
[32m[0906 17-10-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03398, current rewards: -820.43808, mean: -0.37124
[32m[0906 17-10-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03399, current rewards: -870.43808, mean: -0.38515
[32m[0906 17-10-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03400, current rewards: -920.43808, mean: -0.39846
[32m[0906 17-10-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03400, current rewards: -970.43808, mean: -0.41120
[32m[0906 17-10-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03398, current rewards: -1020.43808, mean: -0.42342
[32m[0906 17-10-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03397, current rewards: -1070.43808, mean: -0.43514
[32m[0906 17-10-25 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 17-10-25 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-10-25 @MBExp.py:227][0m Rewards obtained: [-1110.4380823666893], Lows: [2], Highs: [1251], Total time: 6607.637570999999
[32m[0906 17-13-02 @MBExp.py:144][0m ####################################################################
[32m[0906 17-13-02 @MBExp.py:145][0m Starting training iteration 77.
[32m[0906 17-13-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03337, current rewards: 0.95385, mean: 0.09539
[32m[0906 17-13-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03423, current rewards: 6.48897, mean: 0.10815
[32m[0906 17-13-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03430, current rewards: 12.01918, mean: 0.10927
[32m[0906 17-13-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03423, current rewards: 17.54972, mean: 0.10969
[32m[0906 17-13-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03430, current rewards: 23.08390, mean: 0.10992
[32m[0906 17-13-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03432, current rewards: 28.61199, mean: 0.11005
[32m[0906 17-13-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03436, current rewards: 34.14763, mean: 0.11015
[32m[0906 17-13-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03434, current rewards: 39.47649, mean: 0.10966
[32m[0906 17-13-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03418, current rewards: 45.19353, mean: 0.11023
[32m[0906 17-13-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03409, current rewards: 50.75225, mean: 0.11033
[32m[0906 17-13-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03404, current rewards: 56.30932, mean: 0.11041
[32m[0906 17-13-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03399, current rewards: 61.87095, mean: 0.11048
[32m[0906 17-13-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03395, current rewards: 67.42808, mean: 0.11054
[32m[0906 17-13-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03391, current rewards: 72.99011, mean: 0.11059
[32m[0906 17-13-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03390, current rewards: 78.54028, mean: 0.11062
[32m[0906 17-13-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03386, current rewards: 84.09417, mean: 0.11065
[32m[0906 17-13-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03415, current rewards: 64.21247, mean: 0.07927
[32m[0906 17-13-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03494, current rewards: 53.98159, mean: 0.06277
[32m[0906 17-13-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03540, current rewards: 29.79159, mean: 0.03274
[32m[0906 17-13-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03590, current rewards: 13.84009, mean: 0.01442
[32m[0906 17-13-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03646, current rewards: 3.48076, mean: 0.00345
[32m[0906 17-13-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03642, current rewards: 1.25718, mean: 0.00119
[32m[0906 17-13-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03629, current rewards: 6.75895, mean: 0.00609
[32m[0906 17-13-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03617, current rewards: 12.26070, mean: 0.01057
[32m[0906 17-13-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03606, current rewards: 17.56823, mean: 0.01452
[32m[0906 17-13-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03597, current rewards: 23.02497, mean: 0.01827
[32m[0906 17-13-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03591, current rewards: 28.50998, mean: 0.02176
[32m[0906 17-13-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03585, current rewards: 33.98883, mean: 0.02499
[32m[0906 17-13-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03580, current rewards: 39.47323, mean: 0.02800
[32m[0906 17-13-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03575, current rewards: 44.95504, mean: 0.03079
[32m[0906 17-13-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03570, current rewards: 50.43475, mean: 0.03340
[32m[0906 17-13-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03565, current rewards: 55.91514, mean: 0.03584
[32m[0906 17-13-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03561, current rewards: 61.39483, mean: 0.03813
[32m[0906 17-14-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03557, current rewards: 66.87833, mean: 0.04029
[32m[0906 17-14-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03554, current rewards: 72.36222, mean: 0.04232
[32m[0906 17-14-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03551, current rewards: 68.29672, mean: 0.03880
[32m[0906 17-14-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03548, current rewards: 74.01037, mean: 0.04089
[32m[0906 17-14-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03545, current rewards: 79.69197, mean: 0.04285
[32m[0906 17-14-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03542, current rewards: 85.38238, mean: 0.04470
[32m[0906 17-14-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03539, current rewards: 91.07088, mean: 0.04646
[32m[0906 17-14-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03536, current rewards: 96.74882, mean: 0.04813
[32m[0906 17-14-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03534, current rewards: 102.57423, mean: 0.04979
[32m[0906 17-14-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03531, current rewards: 108.27605, mean: 0.05132
[32m[0906 17-14-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03529, current rewards: 113.98249, mean: 0.05277
[32m[0906 17-14-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03526, current rewards: 119.67605, mean: 0.05415
[32m[0906 17-14-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03524, current rewards: 121.13162, mean: 0.05360
[32m[0906 17-14-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03521, current rewards: 126.60950, mean: 0.05481
[32m[0906 17-14-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03517, current rewards: 132.08521, mean: 0.05597
[32m[0906 17-14-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03514, current rewards: 137.56340, mean: 0.05708
[32m[0906 17-14-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03511, current rewards: 143.03826, mean: 0.05815
[32m[0906 17-14-30 @Agent.py:117][0m Average action selection time: 0.0351
[32m[0906 17-14-30 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-14-30 @MBExp.py:227][0m Rewards obtained: [147.40682666386928], Lows: [69], Highs: [2], Total time: 6696.094138999999
[32m[0906 17-17-08 @MBExp.py:144][0m ####################################################################
[32m[0906 17-17-08 @MBExp.py:145][0m Starting training iteration 78.
[32m[0906 17-17-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03316, current rewards: -1.11749, mean: -0.11175
[32m[0906 17-17-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03394, current rewards: 4.61899, mean: 0.07698
[32m[0906 17-17-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03418, current rewards: 10.35482, mean: 0.09413
[32m[0906 17-17-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03422, current rewards: 16.09001, mean: 0.10056
[32m[0906 17-17-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03425, current rewards: 21.82844, mean: 0.10394
[32m[0906 17-17-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03422, current rewards: 27.56878, mean: 0.10603
[32m[0906 17-17-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03402, current rewards: 33.30852, mean: 0.10745
[32m[0906 17-17-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03396, current rewards: 37.89133, mean: 0.10525
[32m[0906 17-17-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03390, current rewards: 43.46082, mean: 0.10600
[32m[0906 17-17-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03384, current rewards: 49.02296, mean: 0.10657
[32m[0906 17-17-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03381, current rewards: 54.58961, mean: 0.10704
[32m[0906 17-17-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03378, current rewards: 60.15611, mean: 0.10742
[32m[0906 17-17-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03372, current rewards: 64.84222, mean: 0.10630
[32m[0906 17-17-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03372, current rewards: 70.37166, mean: 0.10662
[32m[0906 17-17-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03369, current rewards: 75.90063, mean: 0.10690
[32m[0906 17-17-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03368, current rewards: 81.42748, mean: 0.10714
[32m[0906 17-17-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03366, current rewards: 86.95418, mean: 0.10735
[32m[0906 17-17-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03365, current rewards: 92.48466, mean: 0.10754
[32m[0906 17-17-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03364, current rewards: 98.01995, mean: 0.10771
[32m[0906 17-17-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03363, current rewards: 103.54506, mean: 0.10786
[32m[0906 17-17-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03382, current rewards: 107.53955, mean: 0.10647
[32m[0906 17-17-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03406, current rewards: 113.57234, mean: 0.10714
[32m[0906 17-17-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03433, current rewards: 119.60010, mean: 0.10775
[32m[0906 17-17-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03456, current rewards: 125.51566, mean: 0.10820
[32m[0906 17-17-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03484, current rewards: 131.54388, mean: 0.10871
[32m[0906 17-17-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03502, current rewards: 136.98851, mean: 0.10872
[32m[0906 17-17-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03500, current rewards: 142.70892, mean: 0.10894
[32m[0906 17-17-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03498, current rewards: 148.43603, mean: 0.10914
[32m[0906 17-17-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03496, current rewards: 154.15901, mean: 0.10933
[32m[0906 17-18-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03494, current rewards: 159.89064, mean: 0.10951
[32m[0906 17-18-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03493, current rewards: 165.61849, mean: 0.10968
[32m[0906 17-18-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03491, current rewards: 171.57211, mean: 0.10998
[32m[0906 17-18-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03490, current rewards: 177.32857, mean: 0.11014
[32m[0906 17-18-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03487, current rewards: 183.07708, mean: 0.11029
[32m[0906 17-18-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03486, current rewards: 188.82973, mean: 0.11043
[32m[0906 17-18-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03484, current rewards: 194.58458, mean: 0.11056
[32m[0906 17-18-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03482, current rewards: 197.96189, mean: 0.10937
[32m[0906 17-18-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03481, current rewards: 206.75055, mean: 0.11116
[32m[0906 17-18-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03479, current rewards: 215.53922, mean: 0.11285
[32m[0906 17-18-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03478, current rewards: 224.01725, mean: 0.11429
[32m[0906 17-18-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03477, current rewards: 193.27688, mean: 0.09616
[32m[0906 17-18-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03475, current rewards: 143.27688, mean: 0.06955
[32m[0906 17-18-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03474, current rewards: 93.27688, mean: 0.04421
[32m[0906 17-18-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03473, current rewards: 43.27688, mean: 0.02004
[32m[0906 17-18-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03472, current rewards: -6.72312, mean: -0.00304
[32m[0906 17-18-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03470, current rewards: -56.72312, mean: -0.02510
[32m[0906 17-18-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03468, current rewards: -106.72312, mean: -0.04620
[32m[0906 17-18-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03465, current rewards: -156.72312, mean: -0.06641
[32m[0906 17-18-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03463, current rewards: -190.75081, mean: -0.07915
[32m[0906 17-18-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03461, current rewards: -223.88466, mean: -0.09101
[32m[0906 17-18-36 @Agent.py:117][0m Average action selection time: 0.0346
[32m[0906 17-18-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-18-36 @MBExp.py:227][0m Rewards obtained: [-263.88465818167913], Lows: [3], Highs: [497], Total time: 6783.313797999999
[32m[0906 17-21-17 @MBExp.py:144][0m ####################################################################
[32m[0906 17-21-17 @MBExp.py:145][0m Starting training iteration 79.
[32m[0906 17-21-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03382, current rewards: -2.23083, mean: -0.22308
[32m[0906 17-21-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03417, current rewards: 3.33640, mean: 0.05561
[32m[0906 17-21-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03430, current rewards: 8.90370, mean: 0.08094
[32m[0906 17-21-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03416, current rewards: 14.46858, mean: 0.09043
[32m[0906 17-21-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03400, current rewards: 20.02440, mean: 0.09535
[32m[0906 17-21-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03381, current rewards: 25.58876, mean: 0.09842
[32m[0906 17-21-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03371, current rewards: 31.15494, mean: 0.10050
[32m[0906 17-21-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03367, current rewards: 32.30430, mean: 0.08973
[32m[0906 17-21-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03364, current rewards: 37.91584, mean: 0.09248
[32m[0906 17-21-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03361, current rewards: 43.52964, mean: 0.09463
[32m[0906 17-21-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03361, current rewards: 49.14629, mean: 0.09637
[32m[0906 17-21-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03359, current rewards: 54.76314, mean: 0.09779
[32m[0906 17-21-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03358, current rewards: 60.37622, mean: 0.09898
[32m[0906 17-21-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03359, current rewards: 65.99141, mean: 0.09999
[32m[0906 17-21-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03358, current rewards: 71.60718, mean: 0.10086
[32m[0906 17-21-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03358, current rewards: 77.33085, mean: 0.10175
[32m[0906 17-21-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03358, current rewards: 82.96774, mean: 0.10243
[32m[0906 17-21-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03358, current rewards: 88.60971, mean: 0.10303
[32m[0906 17-21-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03359, current rewards: 94.24715, mean: 0.10357
[32m[0906 17-21-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03357, current rewards: 98.69967, mean: 0.10281
[32m[0906 17-21-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03358, current rewards: 104.27410, mean: 0.10324
[32m[0906 17-21-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03357, current rewards: 109.84072, mean: 0.10362
[32m[0906 17-21-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03358, current rewards: 115.41422, mean: 0.10398
[32m[0906 17-21-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03356, current rewards: 121.00982, mean: 0.10432
[32m[0906 17-21-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03357, current rewards: 126.58351, mean: 0.10461
[32m[0906 17-21-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03360, current rewards: 131.09254, mean: 0.10404
[32m[0906 17-22-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03363, current rewards: 136.70207, mean: 0.10435
[32m[0906 17-22-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03365, current rewards: 142.30476, mean: 0.10464
[32m[0906 17-22-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03367, current rewards: 147.91607, mean: 0.10491
[32m[0906 17-22-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03370, current rewards: 153.52290, mean: 0.10515
[32m[0906 17-22-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03372, current rewards: 159.13157, mean: 0.10539
[32m[0906 17-22-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03374, current rewards: 164.84172, mean: 0.10567
[32m[0906 17-22-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03376, current rewards: 170.50078, mean: 0.10590
[32m[0906 17-22-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03378, current rewards: 177.16016, mean: 0.10672
[32m[0906 17-22-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03380, current rewards: 182.99646, mean: 0.10702
[32m[0906 17-22-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03381, current rewards: 188.83291, mean: 0.10729
[32m[0906 17-22-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03384, current rewards: 192.54682, mean: 0.10638
[32m[0906 17-22-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03385, current rewards: 195.77054, mean: 0.10525
[32m[0906 17-22-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03386, current rewards: 201.03443, mean: 0.10525
[32m[0906 17-22-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03387, current rewards: 206.29806, mean: 0.10525
[32m[0906 17-22-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03388, current rewards: 211.52418, mean: 0.10524
[32m[0906 17-22-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03389, current rewards: 216.80392, mean: 0.10524
[32m[0906 17-22-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03390, current rewards: 222.08331, mean: 0.10525
[32m[0906 17-22-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03391, current rewards: 226.24983, mean: 0.10475
[32m[0906 17-22-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03392, current rewards: 231.93296, mean: 0.10495
[32m[0906 17-22-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03393, current rewards: 237.61272, mean: 0.10514
[32m[0906 17-22-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03391, current rewards: 243.29243, mean: 0.10532
[32m[0906 17-22-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03390, current rewards: 248.97794, mean: 0.10550
[32m[0906 17-22-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03389, current rewards: 251.61003, mean: 0.10440
[32m[0906 17-22-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03388, current rewards: 257.21942, mean: 0.10456
[32m[0906 17-22-42 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 17-22-42 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-22-42 @MBExp.py:227][0m Rewards obtained: [261.70821088409497], Lows: [6], Highs: [5], Total time: 6868.734570999999
[32m[0906 17-25-24 @MBExp.py:144][0m ####################################################################
[32m[0906 17-25-24 @MBExp.py:145][0m Starting training iteration 80.
[32m[0906 17-25-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03365, current rewards: 1.15794, mean: 0.11579
[32m[0906 17-25-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03401, current rewards: 8.90198, mean: 0.14837
[32m[0906 17-25-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03410, current rewards: 16.97626, mean: 0.15433
[32m[0906 17-25-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03389, current rewards: 25.05055, mean: 0.15657
[32m[0906 17-25-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03377, current rewards: 6.41066, mean: 0.03053
[32m[0906 17-25-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03367, current rewards: -43.58934, mean: -0.16765
[32m[0906 17-25-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03363, current rewards: -93.58934, mean: -0.30190
[32m[0906 17-25-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03360, current rewards: -143.58934, mean: -0.39886
[32m[0906 17-25-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03359, current rewards: -193.58934, mean: -0.47217
[32m[0906 17-25-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03355, current rewards: -243.58934, mean: -0.52954
[32m[0906 17-25-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03352, current rewards: -293.58934, mean: -0.57567
[32m[0906 17-25-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03352, current rewards: -343.58934, mean: -0.61355
[32m[0906 17-25-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03350, current rewards: -393.58934, mean: -0.64523
[32m[0906 17-25-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03349, current rewards: -443.58934, mean: -0.67211
[32m[0906 17-25-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03348, current rewards: -493.58934, mean: -0.69520
[32m[0906 17-25-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03349, current rewards: -501.60428, mean: -0.66001
[32m[0906 17-25-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03350, current rewards: -495.93051, mean: -0.61226
[32m[0906 17-25-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03350, current rewards: -490.26248, mean: -0.57007
[32m[0906 17-25-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03350, current rewards: -484.58994, mean: -0.53252
[32m[0906 17-25-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03349, current rewards: -478.73777, mean: -0.49869
[32m[0906 17-25-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03350, current rewards: -472.67161, mean: -0.46799
[32m[0906 17-26-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03351, current rewards: -466.61030, mean: -0.44020
[32m[0906 17-26-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03350, current rewards: -460.54522, mean: -0.41491
[32m[0906 17-26-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03349, current rewards: -454.47642, mean: -0.39179
[32m[0906 17-26-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03349, current rewards: -448.41016, mean: -0.37059
[32m[0906 17-26-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03353, current rewards: -446.92470, mean: -0.35470
[32m[0906 17-26-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03356, current rewards: -441.46513, mean: -0.33700
[32m[0906 17-26-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03359, current rewards: -436.01182, mean: -0.32060
[32m[0906 17-26-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03361, current rewards: -430.55762, mean: -0.30536
[32m[0906 17-26-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03364, current rewards: -425.10440, mean: -0.29117
[32m[0906 17-26-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03366, current rewards: -419.65806, mean: -0.27792
[32m[0906 17-26-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03368, current rewards: -414.19979, mean: -0.26551
[32m[0906 17-26-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03370, current rewards: -415.00077, mean: -0.25776
[32m[0906 17-26-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03372, current rewards: -409.44909, mean: -0.24666
[32m[0906 17-26-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03373, current rewards: -403.89274, mean: -0.23619
[32m[0906 17-26-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03375, current rewards: -398.34068, mean: -0.22633
[32m[0906 17-26-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03377, current rewards: -392.78275, mean: -0.21701
[32m[0906 17-26-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03378, current rewards: -387.22312, mean: -0.20818
[32m[0906 17-26-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03379, current rewards: -381.67270, mean: -0.19983
[32m[0906 17-26-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03380, current rewards: -378.98115, mean: -0.19336
[32m[0906 17-26-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03381, current rewards: -371.52316, mean: -0.18484
[32m[0906 17-26-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03382, current rewards: -364.05176, mean: -0.17672
[32m[0906 17-26-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03383, current rewards: -356.58482, mean: -0.16900
[32m[0906 17-26-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03385, current rewards: -349.11849, mean: -0.16163
[32m[0906 17-26-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03386, current rewards: -341.65681, mean: -0.15460
[32m[0906 17-26-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03387, current rewards: -334.18639, mean: -0.14787
[32m[0906 17-26-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03386, current rewards: -326.72354, mean: -0.14144
[32m[0906 17-26-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03385, current rewards: -318.67845, mean: -0.13503
[32m[0906 17-26-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03385, current rewards: -311.29831, mean: -0.12917
[32m[0906 17-26-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03384, current rewards: -303.91849, mean: -0.12354
[32m[0906 17-26-50 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-26-50 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-26-50 @MBExp.py:227][0m Rewards obtained: [-298.00713478213765], Lows: [7], Highs: [535], Total time: 6954.065540999999
[32m[0906 17-29-35 @MBExp.py:144][0m ####################################################################
[32m[0906 17-29-35 @MBExp.py:145][0m Starting training iteration 81.
[32m[0906 17-29-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03324, current rewards: -6.22784, mean: -0.62278
[32m[0906 17-29-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03409, current rewards: -0.64941, mean: -0.01082
[32m[0906 17-29-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03381, current rewards: 4.91436, mean: 0.04468
[32m[0906 17-29-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03376, current rewards: 10.47950, mean: 0.06550
[32m[0906 17-29-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03368, current rewards: 16.04671, mean: 0.07641
[32m[0906 17-29-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03362, current rewards: 21.61328, mean: 0.08313
[32m[0906 17-29-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03366, current rewards: 25.72161, mean: 0.08297
[32m[0906 17-29-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03363, current rewards: 31.13087, mean: 0.08647
[32m[0906 17-29-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03362, current rewards: 36.54888, mean: 0.08914
[32m[0906 17-29-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03359, current rewards: 41.96583, mean: 0.09123
[32m[0906 17-29-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03358, current rewards: 47.38340, mean: 0.09291
[32m[0906 17-29-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03357, current rewards: 52.80047, mean: 0.09429
[32m[0906 17-29-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03356, current rewards: 58.21468, mean: 0.09543
[32m[0906 17-29-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03360, current rewards: 58.96107, mean: 0.08933
[32m[0906 17-29-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03358, current rewards: 64.51257, mean: 0.09086
[32m[0906 17-30-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03358, current rewards: 70.19179, mean: 0.09236
[32m[0906 17-30-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03360, current rewards: 75.88059, mean: 0.09368
[32m[0906 17-30-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03359, current rewards: 81.56909, mean: 0.09485
[32m[0906 17-30-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03358, current rewards: 87.25338, mean: 0.09588
[32m[0906 17-30-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03357, current rewards: 92.93682, mean: 0.09681
[32m[0906 17-30-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03356, current rewards: 98.62606, mean: 0.09765
[32m[0906 17-30-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03357, current rewards: 104.30590, mean: 0.09840
[32m[0906 17-30-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03355, current rewards: 109.86226, mean: 0.09898
[32m[0906 17-30-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03354, current rewards: 115.56683, mean: 0.09963
[32m[0906 17-30-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03354, current rewards: 116.88132, mean: 0.09660
[32m[0906 17-30-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03358, current rewards: 122.41596, mean: 0.09716
[32m[0906 17-30-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03360, current rewards: 127.94546, mean: 0.09767
[32m[0906 17-30-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03362, current rewards: 133.47984, mean: 0.09815
[32m[0906 17-30-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03365, current rewards: 139.01142, mean: 0.09859
[32m[0906 17-30-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03367, current rewards: 144.54319, mean: 0.09900
[32m[0906 17-30-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03369, current rewards: 150.27545, mean: 0.09952
[32m[0906 17-30-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03372, current rewards: 155.80821, mean: 0.09988
[32m[0906 17-30-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03373, current rewards: 161.34021, mean: 0.10021
[32m[0906 17-30-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03375, current rewards: 166.87634, mean: 0.10053
[32m[0906 17-30-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03376, current rewards: 172.41704, mean: 0.10083
[32m[0906 17-30-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03380, current rewards: 173.96082, mean: 0.09884
[32m[0906 17-30-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03381, current rewards: 179.63983, mean: 0.09925
[32m[0906 17-30-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03382, current rewards: 185.31771, mean: 0.09963
[32m[0906 17-30-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03384, current rewards: 191.04453, mean: 0.10002
[32m[0906 17-30-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03385, current rewards: 196.74131, mean: 0.10038
[32m[0906 17-30-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03387, current rewards: 202.40957, mean: 0.10070
[32m[0906 17-30-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03410, current rewards: 203.86504, mean: 0.09896
[32m[0906 17-30-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03439, current rewards: 209.15498, mean: 0.09913
[32m[0906 17-30-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03469, current rewards: 214.48860, mean: 0.09930
[32m[0906 17-30-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03502, current rewards: 219.82921, mean: 0.09947
[32m[0906 17-30-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03523, current rewards: 225.12453, mean: 0.09961
[32m[0906 17-30-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03549, current rewards: 230.46383, mean: 0.09977
[32m[0906 17-30-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03550, current rewards: 236.29041, mean: 0.10012
[32m[0906 17-31-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03545, current rewards: 241.97621, mean: 0.10041
[32m[0906 17-31-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03541, current rewards: 247.65782, mean: 0.10067
[32m[0906 17-31-04 @Agent.py:117][0m Average action selection time: 0.0354
[32m[0906 17-31-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-31-04 @MBExp.py:227][0m Rewards obtained: [252.2077894036244], Lows: [11], Highs: [4], Total time: 7043.262918999999
[32m[0906 17-33-50 @MBExp.py:144][0m ####################################################################
[32m[0906 17-33-50 @MBExp.py:145][0m Starting training iteration 82.
[32m[0906 17-33-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03322, current rewards: -2.37827, mean: -0.23783
[32m[0906 17-33-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03432, current rewards: 2.08247, mean: 0.03471
[32m[0906 17-33-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03405, current rewards: 6.46847, mean: 0.05880
[32m[0906 17-33-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03414, current rewards: 11.05631, mean: 0.06910
[32m[0906 17-33-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03394, current rewards: 15.41433, mean: 0.07340
[32m[0906 17-33-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03390, current rewards: 20.05703, mean: 0.07714
[32m[0906 17-34-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03381, current rewards: 25.42384, mean: 0.08201
[32m[0906 17-34-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03376, current rewards: 30.79216, mean: 0.08553
[32m[0906 17-34-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03371, current rewards: 36.15525, mean: 0.08818
[32m[0906 17-34-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03368, current rewards: 41.52138, mean: 0.09026
[32m[0906 17-34-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03366, current rewards: 46.89255, mean: 0.09195
[32m[0906 17-34-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03363, current rewards: 43.45450, mean: 0.07760
[32m[0906 17-34-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03362, current rewards: 47.18767, mean: 0.07736
[32m[0906 17-34-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03360, current rewards: 51.11189, mean: 0.07744
[32m[0906 17-34-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03359, current rewards: 55.72667, mean: 0.07849
[32m[0906 17-34-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03357, current rewards: 60.34144, mean: 0.07940
[32m[0906 17-34-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03356, current rewards: 64.95622, mean: 0.08019
[32m[0906 17-34-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03354, current rewards: 69.57099, mean: 0.08090
[32m[0906 17-34-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03354, current rewards: 74.18577, mean: 0.08152
[32m[0906 17-34-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03354, current rewards: 78.80054, mean: 0.08208
[32m[0906 17-34-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03351, current rewards: 59.38481, mean: 0.05880
[32m[0906 17-34-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03351, current rewards: 9.38481, mean: 0.00885
[32m[0906 17-34-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03351, current rewards: -40.61519, mean: -0.03659
[32m[0906 17-34-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03354, current rewards: -90.61519, mean: -0.07812
[32m[0906 17-34-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03357, current rewards: -140.61519, mean: -0.11621
[32m[0906 17-34-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03360, current rewards: -190.61519, mean: -0.15128
[32m[0906 17-34-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03362, current rewards: -240.61519, mean: -0.18368
[32m[0906 17-34-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03365, current rewards: -290.61519, mean: -0.21369
[32m[0906 17-34-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03367, current rewards: -340.61519, mean: -0.24157
[32m[0906 17-34-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03369, current rewards: -390.61519, mean: -0.26754
[32m[0906 17-34-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03371, current rewards: -440.61519, mean: -0.29180
[32m[0906 17-34-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03373, current rewards: -490.61519, mean: -0.31450
[32m[0906 17-34-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03375, current rewards: -540.61519, mean: -0.33579
[32m[0906 17-34-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03377, current rewards: -590.61519, mean: -0.35579
[32m[0906 17-34-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03379, current rewards: -640.61519, mean: -0.37463
[32m[0906 17-34-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03380, current rewards: -690.61519, mean: -0.39239
[32m[0906 17-34-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03381, current rewards: -740.61519, mean: -0.40918
[32m[0906 17-34-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03382, current rewards: -790.61519, mean: -0.42506
[32m[0906 17-34-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03383, current rewards: -840.61519, mean: -0.44011
[32m[0906 17-34-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03384, current rewards: -890.61519, mean: -0.45440
[32m[0906 17-34-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03386, current rewards: -940.61519, mean: -0.46797
[32m[0906 17-35-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03387, current rewards: -990.61519, mean: -0.48088
[32m[0906 17-35-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03389, current rewards: -1040.61519, mean: -0.49318
[32m[0906 17-35-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03389, current rewards: -1090.61519, mean: -0.50491
[32m[0906 17-35-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03388, current rewards: -1140.61519, mean: -0.51612
[32m[0906 17-35-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03387, current rewards: -1190.61519, mean: -0.52682
[32m[0906 17-35-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03387, current rewards: -1240.61519, mean: -0.53706
[32m[0906 17-35-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03386, current rewards: -1290.61519, mean: -0.54687
[32m[0906 17-35-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03385, current rewards: -1340.61519, mean: -0.55627
[32m[0906 17-35-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03385, current rewards: -1390.61519, mean: -0.56529
[32m[0906 17-35-15 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-35-15 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-35-15 @MBExp.py:227][0m Rewards obtained: [-1430.6151858548546], Lows: [4], Highs: [1515], Total time: 7128.634002999999
[32m[0906 17-38-04 @MBExp.py:144][0m ####################################################################
[32m[0906 17-38-04 @MBExp.py:145][0m Starting training iteration 83.
[32m[0906 17-38-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03622, current rewards: -0.22555, mean: -0.02255
[32m[0906 17-38-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.04097, current rewards: -0.20700, mean: -0.00345
[32m[0906 17-38-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.04022, current rewards: -4.32158, mean: -0.03929
[32m[0906 17-38-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.04021, current rewards: -7.38558, mean: -0.04616
[32m[0906 17-38-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.04051, current rewards: -7.43126, mean: -0.03539
[32m[0906 17-38-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.04044, current rewards: -2.69194, mean: -0.01035
[32m[0906 17-38-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03997, current rewards: 2.41122, mean: 0.00778
[32m[0906 17-38-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03983, current rewards: 7.52914, mean: 0.02091
[32m[0906 17-38-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03947, current rewards: 12.59755, mean: 0.03073
[32m[0906 17-38-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03928, current rewards: 17.69827, mean: 0.03847
[32m[0906 17-38-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03921, current rewards: 15.70723, mean: 0.03080
[32m[0906 17-38-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03871, current rewards: 21.67406, mean: 0.03870
[32m[0906 17-38-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03827, current rewards: 27.42964, mean: 0.04497
[32m[0906 17-38-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03791, current rewards: 33.01263, mean: 0.05002
[32m[0906 17-38-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03760, current rewards: 38.60864, mean: 0.05438
[32m[0906 17-38-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03732, current rewards: 44.20858, mean: 0.05817
[32m[0906 17-38-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03708, current rewards: 49.81253, mean: 0.06150
[32m[0906 17-38-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03686, current rewards: 55.41224, mean: 0.06443
[32m[0906 17-38-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03669, current rewards: 61.01099, mean: 0.06705
[32m[0906 17-38-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03651, current rewards: 66.60873, mean: 0.06938
[32m[0906 17-38-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03635, current rewards: 72.20601, mean: 0.07149
[32m[0906 17-38-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03626, current rewards: 77.80732, mean: 0.07340
[32m[0906 17-38-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03618, current rewards: 78.68961, mean: 0.07089
[32m[0906 17-38-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03610, current rewards: 83.30438, mean: 0.07181
[32m[0906 17-38-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03603, current rewards: 87.91916, mean: 0.07266
[32m[0906 17-38-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03596, current rewards: 92.53393, mean: 0.07344
[32m[0906 17-38-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03589, current rewards: 97.14871, mean: 0.07416
[32m[0906 17-38-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03583, current rewards: 101.76349, mean: 0.07483
[32m[0906 17-38-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03578, current rewards: 106.37826, mean: 0.07545
[32m[0906 17-38-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03573, current rewards: 110.99304, mean: 0.07602
[32m[0906 17-38-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03568, current rewards: 86.39738, mean: 0.05722
[32m[0906 17-39-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03564, current rewards: 91.97404, mean: 0.05896
[32m[0906 17-39-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03560, current rewards: 97.54884, mean: 0.06059
[32m[0906 17-39-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03556, current rewards: 103.12406, mean: 0.06212
[32m[0906 17-39-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03553, current rewards: 108.70728, mean: 0.06357
[32m[0906 17-39-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03549, current rewards: 114.27628, mean: 0.06493
[32m[0906 17-39-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03546, current rewards: 119.85015, mean: 0.06622
[32m[0906 17-39-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03543, current rewards: 125.47668, mean: 0.06746
[32m[0906 17-39-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03540, current rewards: 131.12508, mean: 0.06865
[32m[0906 17-39-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03537, current rewards: 136.89542, mean: 0.06984
[32m[0906 17-39-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03535, current rewards: 142.66775, mean: 0.07098
[32m[0906 17-39-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03533, current rewards: 148.44083, mean: 0.07206
[32m[0906 17-39-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03529, current rewards: 154.21691, mean: 0.07309
[32m[0906 17-39-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03525, current rewards: 159.99447, mean: 0.07407
[32m[0906 17-39-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03521, current rewards: 165.76600, mean: 0.07501
[32m[0906 17-39-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03517, current rewards: 171.54780, mean: 0.07591
[32m[0906 17-39-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03514, current rewards: 177.26774, mean: 0.07674
[32m[0906 17-39-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03510, current rewards: 183.06006, mean: 0.07757
[32m[0906 17-39-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03506, current rewards: 186.57075, mean: 0.07742
[32m[0906 17-39-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03503, current rewards: 192.06317, mean: 0.07807
[32m[0906 17-39-32 @Agent.py:117][0m Average action selection time: 0.0350
[32m[0906 17-39-32 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-39-32 @MBExp.py:227][0m Rewards obtained: [196.46302009401404], Lows: [6], Highs: [52], Total time: 7216.884998999999
[32m[0906 17-42-22 @MBExp.py:144][0m ####################################################################
[32m[0906 17-42-22 @MBExp.py:145][0m Starting training iteration 84.
[32m[0906 17-42-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03292, current rewards: -0.04036, mean: -0.00404
[32m[0906 17-42-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03340, current rewards: 5.39135, mean: 0.08986
[32m[0906 17-42-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03338, current rewards: 10.83023, mean: 0.09846
[32m[0906 17-42-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03339, current rewards: 16.26399, mean: 0.10165
[32m[0906 17-42-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03338, current rewards: 21.79101, mean: 0.10377
[32m[0906 17-42-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03339, current rewards: 27.26585, mean: 0.10487
[32m[0906 17-42-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03340, current rewards: 32.69313, mean: 0.10546
[32m[0906 17-42-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03343, current rewards: 38.12100, mean: 0.10589
[32m[0906 17-42-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03344, current rewards: 34.06281, mean: 0.08308
[32m[0906 17-42-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03343, current rewards: 39.56818, mean: 0.08602
[32m[0906 17-42-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03344, current rewards: 45.07328, mean: 0.08838
[32m[0906 17-42-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03344, current rewards: 50.52553, mean: 0.09022
[32m[0906 17-42-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03344, current rewards: 56.03630, mean: 0.09186
[32m[0906 17-42-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03344, current rewards: 61.65332, mean: 0.09341
[32m[0906 17-42-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03344, current rewards: 67.48655, mean: 0.09505
[32m[0906 17-42-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03343, current rewards: 73.37149, mean: 0.09654
[32m[0906 17-42-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03343, current rewards: 79.24971, mean: 0.09784
[32m[0906 17-42-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03341, current rewards: 85.12658, mean: 0.09898
[32m[0906 17-42-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03341, current rewards: 90.98462, mean: 0.09998
[32m[0906 17-42-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03344, current rewards: 90.96251, mean: 0.09475
[32m[0906 17-42-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03343, current rewards: 96.31707, mean: 0.09536
[32m[0906 17-42-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03346, current rewards: 101.75696, mean: 0.09600
[32m[0906 17-43-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03350, current rewards: 107.13897, mean: 0.09652
[32m[0906 17-43-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03354, current rewards: 112.51972, mean: 0.09700
[32m[0906 17-43-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03358, current rewards: 117.90132, mean: 0.09744
[32m[0906 17-43-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03362, current rewards: 123.28401, mean: 0.09784
[32m[0906 17-43-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03365, current rewards: 128.66422, mean: 0.09822
[32m[0906 17-43-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03368, current rewards: 134.04773, mean: 0.09856
[32m[0906 17-43-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03371, current rewards: 139.43506, mean: 0.09889
[32m[0906 17-43-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03373, current rewards: 144.74322, mean: 0.09914
[32m[0906 17-43-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03375, current rewards: 150.09632, mean: 0.09940
[32m[0906 17-43-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03376, current rewards: 153.34896, mean: 0.09830
[32m[0906 17-43-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03378, current rewards: 158.88451, mean: 0.09869
[32m[0906 17-43-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03379, current rewards: 164.26856, mean: 0.09896
[32m[0906 17-43-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03381, current rewards: 169.65369, mean: 0.09921
[32m[0906 17-43-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03382, current rewards: 175.03736, mean: 0.09945
[32m[0906 17-43-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03383, current rewards: 180.42276, mean: 0.09968
[32m[0906 17-43-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03384, current rewards: 185.73981, mean: 0.09986
[32m[0906 17-43-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03385, current rewards: 191.13870, mean: 0.10007
[32m[0906 17-43-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03387, current rewards: 196.53261, mean: 0.10027
[32m[0906 17-43-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03388, current rewards: 201.92314, mean: 0.10046
[32m[0906 17-43-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03388, current rewards: 207.31592, mean: 0.10064
[32m[0906 17-43-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03389, current rewards: 209.78766, mean: 0.09943
[32m[0906 17-43-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03387, current rewards: 215.56872, mean: 0.09980
[32m[0906 17-43-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03386, current rewards: 221.32508, mean: 0.10015
[32m[0906 17-43-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03385, current rewards: 227.12957, mean: 0.10050
[32m[0906 17-43-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03385, current rewards: 232.62500, mean: 0.10070
[32m[0906 17-43-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03384, current rewards: 238.14453, mean: 0.10091
[32m[0906 17-43-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03383, current rewards: 243.68514, mean: 0.10111
[32m[0906 17-43-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03382, current rewards: 245.31960, mean: 0.09972
[32m[0906 17-43-47 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-43-47 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-43-48 @MBExp.py:227][0m Rewards obtained: [249.88837200048823], Lows: [11], Highs: [3], Total time: 7302.172877999999
[32m[0906 17-46-40 @MBExp.py:144][0m ####################################################################
[32m[0906 17-46-40 @MBExp.py:145][0m Starting training iteration 85.
[32m[0906 17-46-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03456, current rewards: -4.61265, mean: -0.46127
[32m[0906 17-46-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03357, current rewards: 0.92456, mean: 0.01541
[32m[0906 17-46-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03353, current rewards: 6.45774, mean: 0.05871
[32m[0906 17-46-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03349, current rewards: 11.99212, mean: 0.07495
[32m[0906 17-46-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03347, current rewards: 17.46507, mean: 0.08317
[32m[0906 17-46-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03343, current rewards: 23.00196, mean: 0.08847
[32m[0906 17-46-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03343, current rewards: 28.53561, mean: 0.09205
[32m[0906 17-46-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03341, current rewards: 34.07068, mean: 0.09464
[32m[0906 17-46-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03338, current rewards: 39.60654, mean: 0.09660
[32m[0906 17-46-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03338, current rewards: 45.12145, mean: 0.09809
[32m[0906 17-46-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03338, current rewards: 50.66781, mean: 0.09935
[32m[0906 17-46-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03338, current rewards: 56.21512, mean: 0.10038
[32m[0906 17-47-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03338, current rewards: 61.76296, mean: 0.10125
[32m[0906 17-47-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03339, current rewards: 67.31138, mean: 0.10199
[32m[0906 17-47-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03339, current rewards: 72.85816, mean: 0.10262
[32m[0906 17-47-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03338, current rewards: 78.40897, mean: 0.10317
[32m[0906 17-47-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03338, current rewards: 83.95945, mean: 0.10365
[32m[0906 17-47-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03338, current rewards: 89.49802, mean: 0.10407
[32m[0906 17-47-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03338, current rewards: 95.05124, mean: 0.10445
[32m[0906 17-47-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03339, current rewards: 100.59462, mean: 0.10479
[32m[0906 17-47-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03339, current rewards: 106.35674, mean: 0.10530
[32m[0906 17-47-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03341, current rewards: 111.97050, mean: 0.10563
[32m[0906 17-47-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03344, current rewards: 117.58005, mean: 0.10593
[32m[0906 17-47-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03348, current rewards: 123.19711, mean: 0.10620
[32m[0906 17-47-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03351, current rewards: 128.80894, mean: 0.10645
[32m[0906 17-47-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03355, current rewards: 133.30856, mean: 0.10580
[32m[0906 17-47-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03357, current rewards: 138.90713, mean: 0.10604
[32m[0906 17-47-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03360, current rewards: 144.53354, mean: 0.10627
[32m[0906 17-47-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03362, current rewards: 150.06408, mean: 0.10643
[32m[0906 17-47-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03365, current rewards: 155.73284, mean: 0.10667
[32m[0906 17-47-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03368, current rewards: 161.39946, mean: 0.10689
[32m[0906 17-47-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03370, current rewards: 167.06793, mean: 0.10709
[32m[0906 17-47-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03372, current rewards: 172.74375, mean: 0.10729
[32m[0906 17-47-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03374, current rewards: 178.41127, mean: 0.10748
[32m[0906 17-47-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03376, current rewards: 184.07927, mean: 0.10765
[32m[0906 17-47-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03378, current rewards: 189.75281, mean: 0.10781
[32m[0906 17-47-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03379, current rewards: 195.43400, mean: 0.10797
[32m[0906 17-47-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03380, current rewards: 201.09938, mean: 0.10812
[32m[0906 17-47-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03381, current rewards: 206.76246, mean: 0.10825
[32m[0906 17-47-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03383, current rewards: 212.42515, mean: 0.10838
[32m[0906 17-47-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03384, current rewards: 212.02744, mean: 0.10549
[32m[0906 17-47-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03385, current rewards: 217.39905, mean: 0.10553
[32m[0906 17-47-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03385, current rewards: 222.76621, mean: 0.10558
[32m[0906 17-47-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03384, current rewards: 228.13216, mean: 0.10562
[32m[0906 17-47-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03384, current rewards: 233.47250, mean: 0.10564
[32m[0906 17-47-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03383, current rewards: 238.91043, mean: 0.10571
[32m[0906 17-47-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03382, current rewards: 244.33839, mean: 0.10577
[32m[0906 17-48-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03382, current rewards: 249.76615, mean: 0.10583
[32m[0906 17-48-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03381, current rewards: 203.61987, mean: 0.08449
[32m[0906 17-48-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03381, current rewards: 145.32882, mean: 0.05908
[32m[0906 17-48-05 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-48-05 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-48-05 @MBExp.py:227][0m Rewards obtained: [97.41048966540637], Lows: [91], Highs: [4], Total time: 7387.444869999999
[32m[0906 17-51-00 @MBExp.py:144][0m ####################################################################
[32m[0906 17-51-00 @MBExp.py:145][0m Starting training iteration 86.
[32m[0906 17-51-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03478, current rewards: -0.06409, mean: -0.00641
[32m[0906 17-51-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03505, current rewards: 5.59535, mean: 0.09326
[32m[0906 17-51-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03487, current rewards: 11.25022, mean: 0.10227
[32m[0906 17-51-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03675, current rewards: 17.00362, mean: 0.10627
[32m[0906 17-51-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03784, current rewards: 22.69751, mean: 0.10808
[32m[0906 17-51-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03847, current rewards: 28.40911, mean: 0.10927
[32m[0906 17-51-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03889, current rewards: 34.11286, mean: 0.11004
[32m[0906 17-51-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03930, current rewards: 39.77911, mean: 0.11050
[32m[0906 17-51-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03915, current rewards: 41.17184, mean: 0.10042
[32m[0906 17-51-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03856, current rewards: 46.79584, mean: 0.10173
[32m[0906 17-51-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03806, current rewards: 52.41828, mean: 0.10278
[32m[0906 17-51-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03766, current rewards: 58.04306, mean: 0.10365
[32m[0906 17-51-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03731, current rewards: 63.66710, mean: 0.10437
[32m[0906 17-51-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03701, current rewards: 69.29232, mean: 0.10499
[32m[0906 17-51-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03672, current rewards: 74.91579, mean: 0.10552
[32m[0906 17-51-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03651, current rewards: 75.02914, mean: 0.09872
[32m[0906 17-51-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03634, current rewards: 80.52249, mean: 0.09941
[32m[0906 17-51-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03616, current rewards: 86.01818, mean: 0.10002
[32m[0906 17-51-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03601, current rewards: 91.52104, mean: 0.10057
[32m[0906 17-51-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03588, current rewards: 96.90897, mean: 0.10095
[32m[0906 17-51-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03577, current rewards: 102.42586, mean: 0.10141
[32m[0906 17-51-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03571, current rewards: 107.94746, mean: 0.10184
[32m[0906 17-51-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03564, current rewards: 113.47625, mean: 0.10223
[32m[0906 17-51-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03559, current rewards: 114.69978, mean: 0.09888
[32m[0906 17-51-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03554, current rewards: 120.32351, mean: 0.09944
[32m[0906 17-51-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03550, current rewards: 125.94842, mean: 0.09996
[32m[0906 17-51-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03546, current rewards: 131.57284, mean: 0.10044
[32m[0906 17-51-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03542, current rewards: 137.22175, mean: 0.10090
[32m[0906 17-51-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03539, current rewards: 142.85055, mean: 0.10131
[32m[0906 17-51-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03536, current rewards: 148.47896, mean: 0.10170
[32m[0906 17-51-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03532, current rewards: 154.10971, mean: 0.10206
[32m[0906 17-51-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03530, current rewards: 155.89524, mean: 0.09993
[32m[0906 17-51-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03527, current rewards: 162.03648, mean: 0.10064
[32m[0906 17-51-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03524, current rewards: 168.17798, mean: 0.10131
[32m[0906 17-52-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03522, current rewards: 174.31570, mean: 0.10194
[32m[0906 17-52-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03518, current rewards: 180.34124, mean: 0.10247
[32m[0906 17-52-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03516, current rewards: 186.48180, mean: 0.10303
[32m[0906 17-52-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03514, current rewards: 192.62191, mean: 0.10356
[32m[0906 17-52-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03511, current rewards: 198.75988, mean: 0.10406
[32m[0906 17-52-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03510, current rewards: 204.89791, mean: 0.10454
[32m[0906 17-52-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03510, current rewards: 208.94813, mean: 0.10395
[32m[0906 17-52-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03506, current rewards: 214.56473, mean: 0.10416
[32m[0906 17-52-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03503, current rewards: 220.17216, mean: 0.10435
[32m[0906 17-52-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03499, current rewards: 225.78360, mean: 0.10453
[32m[0906 17-52-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03496, current rewards: 231.39447, mean: 0.10470
[32m[0906 17-52-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03493, current rewards: 237.00141, mean: 0.10487
[32m[0906 17-52-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03490, current rewards: 242.61193, mean: 0.10503
[32m[0906 17-52-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03487, current rewards: 246.11123, mean: 0.10428
[32m[0906 17-52-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03485, current rewards: 250.86114, mean: 0.10409
[32m[0906 17-52-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03482, current rewards: 256.38557, mean: 0.10422
[32m[0906 17-52-27 @Agent.py:117][0m Average action selection time: 0.0348
[32m[0906 17-52-27 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-52-27 @MBExp.py:227][0m Rewards obtained: [260.8086133264022], Lows: [9], Highs: [5], Total time: 7475.206232999999
[32m[0906 17-55-24 @MBExp.py:144][0m ####################################################################
[32m[0906 17-55-24 @MBExp.py:145][0m Starting training iteration 87.
[32m[0906 17-55-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03435, current rewards: -0.61720, mean: -0.06172
[32m[0906 17-55-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03354, current rewards: 5.11860, mean: 0.08531
[32m[0906 17-55-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03341, current rewards: 10.51898, mean: 0.09563
[32m[0906 17-55-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03344, current rewards: 16.04053, mean: 0.10025
[32m[0906 17-55-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03347, current rewards: 21.56332, mean: 0.10268
[32m[0906 17-55-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03345, current rewards: 27.09292, mean: 0.10420
[32m[0906 17-55-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03344, current rewards: 32.61368, mean: 0.10521
[32m[0906 17-55-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03347, current rewards: 38.13462, mean: 0.10593
[32m[0906 17-55-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03349, current rewards: 43.65776, mean: 0.10648
[32m[0906 17-55-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03350, current rewards: 49.17928, mean: 0.10691
[32m[0906 17-55-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03348, current rewards: 54.61587, mean: 0.10709
[32m[0906 17-55-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03349, current rewards: 60.21415, mean: 0.10753
[32m[0906 17-55-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03348, current rewards: 65.81639, mean: 0.10790
[32m[0906 17-55-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03349, current rewards: 71.41712, mean: 0.10821
[32m[0906 17-55-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03346, current rewards: 74.85120, mean: 0.10542
[32m[0906 17-55-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03346, current rewards: 80.01516, mean: 0.10528
[32m[0906 17-55-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03347, current rewards: 85.17889, mean: 0.10516
[32m[0906 17-55-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03347, current rewards: 90.34010, mean: 0.10505
[32m[0906 17-55-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03347, current rewards: 95.55464, mean: 0.10501
[32m[0906 17-55-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03348, current rewards: 100.83702, mean: 0.10504
[32m[0906 17-55-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03348, current rewards: 106.06326, mean: 0.10501
[32m[0906 17-56-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03348, current rewards: 111.29040, mean: 0.10499
[32m[0906 17-56-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03348, current rewards: 110.77416, mean: 0.09980
[32m[0906 17-56-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03347, current rewards: 117.10650, mean: 0.10095
[32m[0906 17-56-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03352, current rewards: 123.46102, mean: 0.10203
[32m[0906 17-56-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03355, current rewards: 129.78779, mean: 0.10301
[32m[0906 17-56-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03358, current rewards: 136.11589, mean: 0.10391
[32m[0906 17-56-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03361, current rewards: 142.58262, mean: 0.10484
[32m[0906 17-56-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03364, current rewards: 149.48721, mean: 0.10602
[32m[0906 17-56-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03367, current rewards: 156.47458, mean: 0.10717
[32m[0906 17-56-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03369, current rewards: 163.40606, mean: 0.10822
[32m[0906 17-56-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03371, current rewards: 170.34165, mean: 0.10919
[32m[0906 17-56-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03374, current rewards: 176.03221, mean: 0.10934
[32m[0906 17-56-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03375, current rewards: 181.08682, mean: 0.10909
[32m[0906 17-56-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03377, current rewards: 186.00014, mean: 0.10877
[32m[0906 17-56-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03377, current rewards: 190.98968, mean: 0.10852
[32m[0906 17-56-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03379, current rewards: 195.89880, mean: 0.10823
[32m[0906 17-56-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03381, current rewards: 200.81026, mean: 0.10796
[32m[0906 17-56-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03382, current rewards: 205.68605, mean: 0.10769
[32m[0906 17-56-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03384, current rewards: 210.89501, mean: 0.10760
[32m[0906 17-56-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03385, current rewards: 216.39288, mean: 0.10766
[32m[0906 17-56-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03385, current rewards: 221.88758, mean: 0.10771
[32m[0906 17-56-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03384, current rewards: 227.36363, mean: 0.10776
[32m[0906 17-56-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03384, current rewards: 232.60740, mean: 0.10769
[32m[0906 17-56-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03383, current rewards: 238.10381, mean: 0.10774
[32m[0906 17-56-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03383, current rewards: 243.61293, mean: 0.10779
[32m[0906 17-56-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03382, current rewards: 249.11795, mean: 0.10784
[32m[0906 17-56-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03381, current rewards: 254.61533, mean: 0.10789
[32m[0906 17-56-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03381, current rewards: 258.47011, mean: 0.10725
[32m[0906 17-56-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03381, current rewards: 264.10945, mean: 0.10736
[32m[0906 17-56-50 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-56-50 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-56-50 @MBExp.py:227][0m Rewards obtained: [268.60393171844487], Lows: [4], Highs: [5], Total time: 7560.462546999999
[32m[0906 17-59-48 @MBExp.py:144][0m ####################################################################
[32m[0906 17-59-48 @MBExp.py:145][0m Starting training iteration 88.
[32m[0906 17-59-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03524, current rewards: -5.46548, mean: -0.54655
[32m[0906 17-59-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03589, current rewards: 0.56098, mean: 0.00935
[32m[0906 17-59-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03611, current rewards: 6.16683, mean: 0.05606
[32m[0906 17-59-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03696, current rewards: 11.96392, mean: 0.07477
[32m[0906 17-59-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03806, current rewards: 17.80024, mean: 0.08476
[32m[0906 17-59-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03877, current rewards: 23.65101, mean: 0.09097
[32m[0906 18-00-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03914, current rewards: 29.24262, mean: 0.09433
[32m[0906 18-00-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03937, current rewards: 34.98860, mean: 0.09719
[32m[0906 18-00-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03955, current rewards: 40.82081, mean: 0.09956
[32m[0906 18-00-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03981, current rewards: 46.59839, mean: 0.10130
[32m[0906 18-00-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03987, current rewards: 52.11025, mean: 0.10218
[32m[0906 18-00-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03945, current rewards: 57.95552, mean: 0.10349
[32m[0906 18-00-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03904, current rewards: 63.82270, mean: 0.10463
[32m[0906 18-00-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03894, current rewards: 59.64973, mean: 0.09038
[32m[0906 18-00-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03889, current rewards: 47.79042, mean: 0.06731
[32m[0906 18-00-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03881, current rewards: 35.93300, mean: 0.04728
[32m[0906 18-00-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03872, current rewards: 23.02859, mean: 0.02843
[32m[0906 18-00-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03861, current rewards: 9.08155, mean: 0.01056
[32m[0906 18-00-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03851, current rewards: -2.77136, mean: -0.00305
[32m[0906 18-00-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03826, current rewards: -25.16237, mean: -0.02621
[32m[0906 18-00-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03808, current rewards: -45.17557, mean: -0.04473
[32m[0906 18-00-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03785, current rewards: -39.24349, mean: -0.03702
[32m[0906 18-00-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03769, current rewards: -33.31023, mean: -0.03001
[32m[0906 18-00-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03755, current rewards: -27.37739, mean: -0.02360
[32m[0906 18-00-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03741, current rewards: -21.44086, mean: -0.01772
[32m[0906 18-00-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03729, current rewards: -15.50398, mean: -0.01230
[32m[0906 18-00-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03717, current rewards: -9.57314, mean: -0.00731
[32m[0906 18-00-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03707, current rewards: -3.47032, mean: -0.00255
[32m[0906 18-00-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03697, current rewards: 2.36392, mean: 0.00168
[32m[0906 18-00-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03689, current rewards: 8.19736, mean: 0.00561
[32m[0906 18-00-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03681, current rewards: 11.51745, mean: 0.00763
[32m[0906 18-00-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03673, current rewards: 17.68268, mean: 0.01134
[32m[0906 18-00-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03665, current rewards: 23.85059, mean: 0.01481
[32m[0906 18-00-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03657, current rewards: 30.00983, mean: 0.01808
[32m[0906 18-00-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03651, current rewards: 36.18342, mean: 0.02116
[32m[0906 18-00-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03645, current rewards: 42.17335, mean: 0.02396
[32m[0906 18-00-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03641, current rewards: 43.64490, mean: 0.02411
[32m[0906 18-00-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03635, current rewards: 49.33394, mean: 0.02652
[32m[0906 18-00-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03630, current rewards: 55.01875, mean: 0.02881
[32m[0906 18-00-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03622, current rewards: 60.70619, mean: 0.03097
[32m[0906 18-01-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03615, current rewards: 66.39829, mean: 0.03303
[32m[0906 18-01-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03608, current rewards: 72.08476, mean: 0.03499
[32m[0906 18-01-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03602, current rewards: 77.76808, mean: 0.03686
[32m[0906 18-01-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03596, current rewards: 83.44261, mean: 0.03863
[32m[0906 18-01-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03591, current rewards: 89.13865, mean: 0.04033
[32m[0906 18-01-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03586, current rewards: 94.82842, mean: 0.04196
[32m[0906 18-01-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03581, current rewards: 100.51470, mean: 0.04351
[32m[0906 18-01-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03576, current rewards: 106.21031, mean: 0.04500
[32m[0906 18-01-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03571, current rewards: 111.90423, mean: 0.04643
[32m[0906 18-01-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03567, current rewards: 117.59550, mean: 0.04780
[32m[0906 18-01-18 @Agent.py:117][0m Average action selection time: 0.0356
[32m[0906 18-01-18 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-01-18 @MBExp.py:227][0m Rewards obtained: [122.15294747164161], Lows: [4], Highs: [131], Total time: 7650.298264999999
[32m[0906 18-04-18 @MBExp.py:144][0m ####################################################################
[32m[0906 18-04-18 @MBExp.py:145][0m Starting training iteration 89.
[32m[0906 18-04-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03419, current rewards: -5.10912, mean: -0.51091
[32m[0906 18-04-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03584, current rewards: -12.04001, mean: -0.20067
[32m[0906 18-04-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03579, current rewards: -22.68753, mean: -0.20625
[32m[0906 18-04-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03572, current rewards: -43.15088, mean: -0.26969
[32m[0906 18-04-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03588, current rewards: -65.84723, mean: -0.31356
[32m[0906 18-04-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03581, current rewards: -84.22521, mean: -0.32394
[32m[0906 18-04-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03585, current rewards: -94.99804, mean: -0.30645
[32m[0906 18-04-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03598, current rewards: -114.06628, mean: -0.31685
[32m[0906 18-04-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03618, current rewards: -136.72449, mean: -0.33347
[32m[0906 18-04-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03619, current rewards: -155.55942, mean: -0.33817
[32m[0906 18-04-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03597, current rewards: -172.34976, mean: -0.33794
[32m[0906 18-04-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03593, current rewards: -188.85236, mean: -0.33724
[32m[0906 18-04-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03586, current rewards: -193.82053, mean: -0.31774
[32m[0906 18-04-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03567, current rewards: -188.23043, mean: -0.28520
[32m[0906 18-04-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03551, current rewards: -182.64950, mean: -0.25725
[32m[0906 18-04-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03536, current rewards: -177.06557, mean: -0.23298
[32m[0906 18-04-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03528, current rewards: -174.00976, mean: -0.21483
[32m[0906 18-04-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03517, current rewards: -165.22110, mean: -0.19212
[32m[0906 18-04-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03507, current rewards: -156.43243, mean: -0.17190
[32m[0906 18-04-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03499, current rewards: -148.02917, mean: -0.15420
[32m[0906 18-04-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03491, current rewards: -179.87054, mean: -0.17809
[32m[0906 18-04-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03487, current rewards: -229.87054, mean: -0.21686
[32m[0906 18-04-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03484, current rewards: -279.87054, mean: -0.25214
[32m[0906 18-04-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03482, current rewards: -329.87054, mean: -0.28437
[32m[0906 18-05-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03481, current rewards: -379.87054, mean: -0.31394
[32m[0906 18-05-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03480, current rewards: -429.87054, mean: -0.34117
[32m[0906 18-05-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03479, current rewards: -479.87054, mean: -0.36631
[32m[0906 18-05-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03478, current rewards: -529.87054, mean: -0.38961
[32m[0906 18-05-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03476, current rewards: -579.87054, mean: -0.41126
[32m[0906 18-05-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03474, current rewards: -629.87054, mean: -0.43142
[32m[0906 18-05-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03474, current rewards: -679.87054, mean: -0.45025
[32m[0906 18-05-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03472, current rewards: -729.87054, mean: -0.46787
[32m[0906 18-05-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03470, current rewards: -779.87054, mean: -0.48439
[32m[0906 18-05-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03469, current rewards: -829.87054, mean: -0.49992
[32m[0906 18-05-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03469, current rewards: -879.87054, mean: -0.51454
[32m[0906 18-05-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03469, current rewards: -929.87054, mean: -0.52834
[32m[0906 18-05-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03468, current rewards: -979.87054, mean: -0.54136
[32m[0906 18-05-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03467, current rewards: -1029.87054, mean: -0.55369
[32m[0906 18-05-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03463, current rewards: -1079.87054, mean: -0.56538
[32m[0906 18-05-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03460, current rewards: -1129.87054, mean: -0.57646
[32m[0906 18-05-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03457, current rewards: -1179.87054, mean: -0.58700
[32m[0906 18-05-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03455, current rewards: -1229.87054, mean: -0.59702
[32m[0906 18-05-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03453, current rewards: -1279.87054, mean: -0.60657
[32m[0906 18-05-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03451, current rewards: -1329.87054, mean: -0.61568
[32m[0906 18-05-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03449, current rewards: -1379.87054, mean: -0.62438
[32m[0906 18-05-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03448, current rewards: -1429.87054, mean: -0.63269
[32m[0906 18-05-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03446, current rewards: -1479.87054, mean: -0.64064
[32m[0906 18-05-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03443, current rewards: -1499.94950, mean: -0.63557
[32m[0906 18-05-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03441, current rewards: -1496.51907, mean: -0.62096
[32m[0906 18-05-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03440, current rewards: -1493.08863, mean: -0.60695
[32m[0906 18-05-45 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 18-05-45 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-05-45 @MBExp.py:227][0m Rewards obtained: [-1490.3442891081022], Lows: [132], Highs: [1375], Total time: 7737.026365999999
[32m[0906 18-08-47 @MBExp.py:144][0m ####################################################################
[32m[0906 18-08-47 @MBExp.py:145][0m Starting training iteration 90.
[32m[0906 18-08-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03585, current rewards: -4.46115, mean: -0.44612
[32m[0906 18-08-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.04123, current rewards: -8.74737, mean: -0.14579
[32m[0906 18-08-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.04183, current rewards: -10.89759, mean: -0.09907
[32m[0906 18-08-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.04227, current rewards: -14.18952, mean: -0.08868
[32m[0906 18-08-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.04281, current rewards: -16.14952, mean: -0.07690
[32m[0906 18-08-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.04338, current rewards: -15.91012, mean: -0.06119
[32m[0906 18-09-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.04327, current rewards: -19.06879, mean: -0.06151
[32m[0906 18-09-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.04325, current rewards: -21.06629, mean: -0.05852
[32m[0906 18-09-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.04331, current rewards: -23.10760, mean: -0.05636
[32m[0906 18-09-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.04222, current rewards: -17.60616, mean: -0.03827
[32m[0906 18-09-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.04140, current rewards: -11.97660, mean: -0.02348
[32m[0906 18-09-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.04068, current rewards: -6.44539, mean: -0.01151
[32m[0906 18-09-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.04010, current rewards: -0.79021, mean: -0.00130
[32m[0906 18-09-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03960, current rewards: 4.92172, mean: 0.00746
[32m[0906 18-09-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03916, current rewards: 10.63656, mean: 0.01498
[32m[0906 18-09-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03880, current rewards: 16.22508, mean: 0.02135
[32m[0906 18-09-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03849, current rewards: 21.67078, mean: 0.02675
[32m[0906 18-09-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03820, current rewards: 27.12316, mean: 0.03154
[32m[0906 18-09-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03793, current rewards: 32.56874, mean: 0.03579
[32m[0906 18-09-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03775, current rewards: 38.01385, mean: 0.03960
[32m[0906 18-09-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03758, current rewards: 43.72520, mean: 0.04329
[32m[0906 18-09-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03743, current rewards: 49.17355, mean: 0.04639
[32m[0906 18-09-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03730, current rewards: 54.62247, mean: 0.04921
[32m[0906 18-09-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03717, current rewards: 60.07834, mean: 0.05179
[32m[0906 18-09-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03705, current rewards: 65.52958, mean: 0.05416
[32m[0906 18-09-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03694, current rewards: 70.97522, mean: 0.05633
[32m[0906 18-09-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03686, current rewards: 74.25997, mean: 0.05669
[32m[0906 18-09-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03676, current rewards: 79.76088, mean: 0.05865
[32m[0906 18-09-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03669, current rewards: 85.16693, mean: 0.06040
[32m[0906 18-09-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03659, current rewards: 90.66329, mean: 0.06210
[32m[0906 18-09-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03652, current rewards: 96.16477, mean: 0.06369
[32m[0906 18-09-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03645, current rewards: 101.66302, mean: 0.06517
[32m[0906 18-09-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03638, current rewards: 107.16613, mean: 0.06656
[32m[0906 18-09-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03632, current rewards: 112.66797, mean: 0.06787
[32m[0906 18-09-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03626, current rewards: 118.16992, mean: 0.06911
[32m[0906 18-09-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03621, current rewards: 123.66940, mean: 0.07027
[32m[0906 18-09-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03613, current rewards: 127.06417, mean: 0.07020
[32m[0906 18-09-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03607, current rewards: 132.57512, mean: 0.07128
[32m[0906 18-09-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03600, current rewards: 138.08932, mean: 0.07230
[32m[0906 18-09-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03594, current rewards: 143.60042, mean: 0.07327
[32m[0906 18-10-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03589, current rewards: 147.32119, mean: 0.07329
[32m[0906 18-10-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03584, current rewards: 152.87343, mean: 0.07421
[32m[0906 18-10-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03578, current rewards: 158.42640, mean: 0.07508
[32m[0906 18-10-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03572, current rewards: 163.97878, mean: 0.07592
[32m[0906 18-10-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03568, current rewards: 169.59594, mean: 0.07674
[32m[0906 18-10-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03563, current rewards: 175.91137, mean: 0.07784
[32m[0906 18-10-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03558, current rewards: 182.22680, mean: 0.07889
[32m[0906 18-10-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03554, current rewards: 188.54223, mean: 0.07989
[32m[0906 18-10-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03550, current rewards: 194.85766, mean: 0.08085
[32m[0906 18-10-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03546, current rewards: 201.17308, mean: 0.08178
[32m[0906 18-10-17 @Agent.py:117][0m Average action selection time: 0.0354
[32m[0906 18-10-17 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-10-17 @MBExp.py:227][0m Rewards obtained: [165.67831626616453], Lows: [4], Highs: [89], Total time: 7826.365566999999
[32m[0906 18-13-22 @MBExp.py:144][0m ####################################################################
[32m[0906 18-13-22 @MBExp.py:145][0m Starting training iteration 91.
[32m[0906 18-13-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03310, current rewards: -4.09767, mean: -0.40977
[32m[0906 18-13-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03331, current rewards: 1.45603, mean: 0.02427
[32m[0906 18-13-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03333, current rewards: 7.00578, mean: 0.06369
[32m[0906 18-13-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03334, current rewards: 12.29500, mean: 0.07684
[32m[0906 18-13-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03341, current rewards: 17.66280, mean: 0.08411
[32m[0906 18-13-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03338, current rewards: 23.02470, mean: 0.08856
[32m[0906 18-13-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03341, current rewards: 28.38855, mean: 0.09158
[32m[0906 18-13-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03343, current rewards: 33.75212, mean: 0.09376
[32m[0906 18-13-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03341, current rewards: 39.11415, mean: 0.09540
[32m[0906 18-13-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03340, current rewards: 44.47385, mean: 0.09668
[32m[0906 18-13-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03341, current rewards: 49.83182, mean: 0.09771
[32m[0906 18-13-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03341, current rewards: 55.18674, mean: 0.09855
[32m[0906 18-13-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03340, current rewards: 58.89435, mean: 0.09655
[32m[0906 18-13-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03338, current rewards: 64.39379, mean: 0.09757
[32m[0906 18-13-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03339, current rewards: 69.88957, mean: 0.09844
[32m[0906 18-13-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03339, current rewards: 75.38524, mean: 0.09919
[32m[0906 18-13-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03341, current rewards: 80.88513, mean: 0.09986
[32m[0906 18-13-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03341, current rewards: 86.38233, mean: 0.10044
[32m[0906 18-13-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03340, current rewards: 91.88685, mean: 0.10097
[32m[0906 18-13-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03346, current rewards: 97.66060, mean: 0.10173
[32m[0906 18-13-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03350, current rewards: 103.17394, mean: 0.10215
[32m[0906 18-13-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03354, current rewards: 108.68973, mean: 0.10254
[32m[0906 18-13-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03357, current rewards: 114.20401, mean: 0.10289
[32m[0906 18-14-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03362, current rewards: 115.52309, mean: 0.09959
[32m[0906 18-14-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03366, current rewards: 121.05792, mean: 0.10005
[32m[0906 18-14-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03368, current rewards: 126.59921, mean: 0.10048
[32m[0906 18-14-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03370, current rewards: 132.13668, mean: 0.10087
[32m[0906 18-14-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03372, current rewards: 137.68539, mean: 0.10124
[32m[0906 18-14-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03373, current rewards: 143.22128, mean: 0.10158
[32m[0906 18-14-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03375, current rewards: 148.75688, mean: 0.10189
[32m[0906 18-14-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03376, current rewards: 154.29278, mean: 0.10218
[32m[0906 18-14-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03377, current rewards: 159.82741, mean: 0.10245
[32m[0906 18-14-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03379, current rewards: 163.70709, mean: 0.10168
[32m[0906 18-14-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03380, current rewards: 169.38806, mean: 0.10204
[32m[0906 18-14-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03381, current rewards: 175.06912, mean: 0.10238
[32m[0906 18-14-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03382, current rewards: 180.70299, mean: 0.10267
[32m[0906 18-14-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03380, current rewards: 186.32999, mean: 0.10294
[32m[0906 18-14-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03379, current rewards: 192.01321, mean: 0.10323
[32m[0906 18-14-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03379, current rewards: 193.43721, mean: 0.10128
[32m[0906 18-14-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03378, current rewards: 199.00848, mean: 0.10153
[32m[0906 18-14-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03377, current rewards: 204.58644, mean: 0.10178
[32m[0906 18-14-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03376, current rewards: 210.16020, mean: 0.10202
[32m[0906 18-14-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03375, current rewards: 215.72824, mean: 0.10224
[32m[0906 18-14-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03375, current rewards: 221.29886, mean: 0.10245
[32m[0906 18-14-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03374, current rewards: 226.99697, mean: 0.10271
[32m[0906 18-14-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03375, current rewards: 228.35455, mean: 0.10104
[32m[0906 18-14-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03374, current rewards: 231.92037, mean: 0.10040
[32m[0906 18-14-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03374, current rewards: 237.61403, mean: 0.10068
[32m[0906 18-14-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03373, current rewards: 243.30937, mean: 0.10096
[32m[0906 18-14-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03373, current rewards: 248.99968, mean: 0.10122
[32m[0906 18-14-47 @Agent.py:117][0m Average action selection time: 0.0337
[32m[0906 18-14-47 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-14-47 @MBExp.py:227][0m Rewards obtained: [253.55444510416163], Lows: [10], Highs: [3], Total time: 7911.433810999999
[32m[0906 18-17-53 @MBExp.py:144][0m ####################################################################
[32m[0906 18-17-53 @MBExp.py:145][0m Starting training iteration 92.
[32m[0906 18-17-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03268, current rewards: 0.95787, mean: 0.09579
[32m[0906 18-17-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03315, current rewards: 6.48818, mean: 0.10814
[32m[0906 18-17-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03329, current rewards: 12.38649, mean: 0.11260
[32m[0906 18-17-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03328, current rewards: 18.70192, mean: 0.11689
[32m[0906 18-18-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03330, current rewards: 25.01734, mean: 0.11913
[32m[0906 18-18-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03335, current rewards: 31.33277, mean: 0.12051
[32m[0906 18-18-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03335, current rewards: 37.64819, mean: 0.12145
[32m[0906 18-18-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03333, current rewards: 43.96362, mean: 0.12212
[32m[0906 18-18-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03334, current rewards: 50.27904, mean: 0.12263
[32m[0906 18-18-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03335, current rewards: 56.59447, mean: 0.12303
[32m[0906 18-18-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03335, current rewards: 62.72732, mean: 0.12299
[32m[0906 18-18-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03335, current rewards: 32.25418, mean: 0.05760
[32m[0906 18-18-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03333, current rewards: -17.74582, mean: -0.02909
[32m[0906 18-18-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03335, current rewards: -67.74582, mean: -0.10265
[32m[0906 18-18-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03337, current rewards: -117.74582, mean: -0.16584
[32m[0906 18-18-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03339, current rewards: -167.74582, mean: -0.22072
[32m[0906 18-18-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03338, current rewards: -217.74582, mean: -0.26882
[32m[0906 18-18-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03337, current rewards: -267.74582, mean: -0.31133
[32m[0906 18-18-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03338, current rewards: -317.74582, mean: -0.34917
[32m[0906 18-18-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03340, current rewards: -367.74582, mean: -0.38307
[32m[0906 18-18-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03345, current rewards: -417.74582, mean: -0.41361
[32m[0906 18-18-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03349, current rewards: -467.74582, mean: -0.44127
[32m[0906 18-18-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03353, current rewards: -517.74582, mean: -0.46644
[32m[0906 18-18-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03357, current rewards: -567.74582, mean: -0.48944
[32m[0906 18-18-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03360, current rewards: -617.74582, mean: -0.51053
[32m[0906 18-18-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03362, current rewards: -667.74582, mean: -0.52996
[32m[0906 18-18-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03364, current rewards: -717.74582, mean: -0.54790
[32m[0906 18-18-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03366, current rewards: -767.74582, mean: -0.56452
[32m[0906 18-18-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03369, current rewards: -817.74582, mean: -0.57996
[32m[0906 18-18-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03371, current rewards: -867.74582, mean: -0.59435
[32m[0906 18-18-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03372, current rewards: -917.74582, mean: -0.60778
[32m[0906 18-18-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03374, current rewards: -967.74582, mean: -0.62035
[32m[0906 18-18-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03375, current rewards: -1017.74582, mean: -0.63214
[32m[0906 18-18-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03377, current rewards: -1067.74582, mean: -0.64322
[32m[0906 18-18-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03378, current rewards: -1117.74582, mean: -0.65365
[32m[0906 18-18-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03380, current rewards: -1167.74582, mean: -0.66349
[32m[0906 18-18-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03377, current rewards: -1217.74582, mean: -0.67279
[32m[0906 18-18-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03377, current rewards: -1267.74582, mean: -0.68158
[32m[0906 18-18-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03376, current rewards: -1317.74582, mean: -0.68992
[32m[0906 18-19-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03376, current rewards: -1367.74582, mean: -0.69783
[32m[0906 18-19-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03375, current rewards: -1417.74582, mean: -0.70535
[32m[0906 18-19-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03375, current rewards: -1467.74582, mean: -0.71250
[32m[0906 18-19-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03373, current rewards: -1517.74582, mean: -0.71931
[32m[0906 18-19-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03373, current rewards: -1567.74582, mean: -0.72581
[32m[0906 18-19-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03372, current rewards: -1617.74582, mean: -0.73201
[32m[0906 18-19-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03371, current rewards: -1667.74582, mean: -0.73794
[32m[0906 18-19-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03370, current rewards: -1717.74582, mean: -0.74361
[32m[0906 18-19-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03370, current rewards: -1767.74582, mean: -0.74904
[32m[0906 18-19-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03369, current rewards: -1817.74582, mean: -0.75425
[32m[0906 18-19-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03369, current rewards: -1867.74582, mean: -0.75925
[32m[0906 18-19-18 @Agent.py:117][0m Average action selection time: 0.0337
[32m[0906 18-19-18 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-19-18 @MBExp.py:227][0m Rewards obtained: [-1907.7458217815224], Lows: [0], Highs: [1972], Total time: 7996.395922999999
[32m[0906 18-22-26 @MBExp.py:144][0m ####################################################################
[32m[0906 18-22-26 @MBExp.py:145][0m Starting training iteration 93.
[32m[0906 18-22-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03227, current rewards: -5.32514, mean: -0.53251
[32m[0906 18-22-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03323, current rewards: 0.39963, mean: 0.00666
[32m[0906 18-22-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03336, current rewards: 5.91366, mean: 0.05376
[32m[0906 18-22-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03341, current rewards: 11.42651, mean: 0.07142
[32m[0906 18-22-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03338, current rewards: 16.93684, mean: 0.08065
[32m[0906 18-22-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03338, current rewards: 22.45381, mean: 0.08636
[32m[0906 18-22-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03336, current rewards: 27.96499, mean: 0.09021
[32m[0906 18-22-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03330, current rewards: 33.47657, mean: 0.09299
[32m[0906 18-22-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03338, current rewards: 36.94335, mean: 0.09011
[32m[0906 18-22-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03337, current rewards: 42.47885, mean: 0.09235
[32m[0906 18-22-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03334, current rewards: 47.92484, mean: 0.09397
[32m[0906 18-22-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03336, current rewards: 53.44581, mean: 0.09544
[32m[0906 18-22-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03338, current rewards: 58.96379, mean: 0.09666
[32m[0906 18-22-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03339, current rewards: 64.48321, mean: 0.09770
[32m[0906 18-22-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03340, current rewards: 70.00320, mean: 0.09860
[32m[0906 18-22-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03339, current rewards: 75.52736, mean: 0.09938
[32m[0906 18-22-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03342, current rewards: 77.82381, mean: 0.09608
[32m[0906 18-22-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03341, current rewards: 82.92471, mean: 0.09642
[32m[0906 18-22-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03341, current rewards: 87.93620, mean: 0.09663
[32m[0906 18-22-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03344, current rewards: 93.04843, mean: 0.09693
[32m[0906 18-23-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03348, current rewards: 98.16566, mean: 0.09719
[32m[0906 18-23-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03352, current rewards: 103.28484, mean: 0.09744
[32m[0906 18-23-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03356, current rewards: 109.05261, mean: 0.09825
[32m[0906 18-23-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03360, current rewards: 114.40750, mean: 0.09863
[32m[0906 18-23-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03364, current rewards: 119.76440, mean: 0.09898
[32m[0906 18-23-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03366, current rewards: 125.11518, mean: 0.09930
[32m[0906 18-23-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03368, current rewards: 130.46941, mean: 0.09959
[32m[0906 18-23-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03371, current rewards: 135.81847, mean: 0.09987
[32m[0906 18-23-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03374, current rewards: 141.16222, mean: 0.10012
[32m[0906 18-23-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03375, current rewards: 146.51543, mean: 0.10035
[32m[0906 18-23-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03378, current rewards: 151.86641, mean: 0.10057
[32m[0906 18-23-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03379, current rewards: 157.22052, mean: 0.10078
[32m[0906 18-23-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03381, current rewards: 162.57152, mean: 0.10098
[32m[0906 18-23-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03383, current rewards: 167.92098, mean: 0.10116
[32m[0906 18-23-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03384, current rewards: 173.35144, mean: 0.10138
[32m[0906 18-23-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03384, current rewards: 174.48635, mean: 0.09914
[32m[0906 18-23-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03383, current rewards: 179.94648, mean: 0.09942
[32m[0906 18-23-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03382, current rewards: 185.42800, mean: 0.09969
[32m[0906 18-23-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03381, current rewards: 190.90555, mean: 0.09995
[32m[0906 18-23-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03381, current rewards: 196.38130, mean: 0.10019
[32m[0906 18-23-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03380, current rewards: 201.85493, mean: 0.10043
[32m[0906 18-23-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03380, current rewards: 205.26537, mean: 0.09964
[32m[0906 18-23-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03380, current rewards: 211.06507, mean: 0.10003
[32m[0906 18-23-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03379, current rewards: 217.82912, mean: 0.10085
[32m[0906 18-23-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03378, current rewards: 224.59315, mean: 0.10163
[32m[0906 18-23-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03378, current rewards: 231.35719, mean: 0.10237
[32m[0906 18-23-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03377, current rewards: 238.12123, mean: 0.10308
[32m[0906 18-23-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03377, current rewards: 244.88527, mean: 0.10376
[32m[0906 18-23-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03376, current rewards: 233.48481, mean: 0.09688
[32m[0906 18-23-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03376, current rewards: 183.48481, mean: 0.07459
[32m[0906 18-23-51 @Agent.py:117][0m Average action selection time: 0.0337
[32m[0906 18-23-51 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-23-52 @MBExp.py:227][0m Rewards obtained: [143.4848140515711], Lows: [7], Highs: [109], Total time: 8081.536298999999
[32m[0906 18-27-02 @MBExp.py:144][0m ####################################################################
[32m[0906 18-27-02 @MBExp.py:145][0m Starting training iteration 94.
[32m[0906 18-27-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03186, current rewards: -4.10624, mean: -0.41062
[32m[0906 18-27-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03305, current rewards: 1.50815, mean: 0.02514
[32m[0906 18-27-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03309, current rewards: 7.03080, mean: 0.06392
[32m[0906 18-27-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03316, current rewards: 12.55348, mean: 0.07846
[32m[0906 18-27-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03322, current rewards: 18.07843, mean: 0.08609
[32m[0906 18-27-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03325, current rewards: 25.03803, mean: 0.09630
[32m[0906 18-27-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03329, current rewards: 35.43293, mean: 0.11430
[32m[0906 18-27-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03331, current rewards: 45.88601, mean: 0.12746
[32m[0906 18-27-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03332, current rewards: 56.36522, mean: 0.13748
[32m[0906 18-27-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03328, current rewards: 66.97149, mean: 0.14559
[32m[0906 18-27-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03327, current rewards: 78.25648, mean: 0.15344
[32m[0906 18-27-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03327, current rewards: 89.58649, mean: 0.15998
[32m[0906 18-27-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03327, current rewards: 100.81809, mean: 0.16528
[32m[0906 18-27-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03328, current rewards: 112.10905, mean: 0.16986
[32m[0906 18-27-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03330, current rewards: 123.39535, mean: 0.17380
[32m[0906 18-27-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03331, current rewards: 134.68733, mean: 0.17722
[32m[0906 18-27-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03330, current rewards: 144.29442, mean: 0.17814
[32m[0906 18-27-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03331, current rewards: 153.63917, mean: 0.17865
[32m[0906 18-27-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03331, current rewards: 163.14195, mean: 0.17928
[32m[0906 18-27-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03332, current rewards: 172.61032, mean: 0.17980
[32m[0906 18-27-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03337, current rewards: 182.05664, mean: 0.18025
[32m[0906 18-27-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03340, current rewards: 191.48314, mean: 0.18064
[32m[0906 18-27-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03343, current rewards: 200.94470, mean: 0.18103
[32m[0906 18-27-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03346, current rewards: 210.39270, mean: 0.18137
[32m[0906 18-27-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03349, current rewards: 219.85239, mean: 0.18170
[32m[0906 18-27-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03351, current rewards: 229.30762, mean: 0.18199
[32m[0906 18-27-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03354, current rewards: 239.28534, mean: 0.18266
[32m[0906 18-27-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03356, current rewards: 249.27735, mean: 0.18329
[32m[0906 18-27-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03359, current rewards: 259.31661, mean: 0.18391
[32m[0906 18-27-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03361, current rewards: 260.99072, mean: 0.17876
[32m[0906 18-27-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03363, current rewards: 266.56174, mean: 0.17653
[32m[0906 18-27-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03364, current rewards: 272.12749, mean: 0.17444
[32m[0906 18-27-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03365, current rewards: 277.69459, mean: 0.17248
[32m[0906 18-27-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03367, current rewards: 283.46646, mean: 0.17076
[32m[0906 18-28-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03369, current rewards: 289.04503, mean: 0.16903
[32m[0906 18-28-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03368, current rewards: 294.62778, mean: 0.16740
[32m[0906 18-28-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03367, current rewards: 300.20416, mean: 0.16586
[32m[0906 18-28-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03365, current rewards: 305.78701, mean: 0.16440
[32m[0906 18-28-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03365, current rewards: 311.36769, mean: 0.16302
[32m[0906 18-28-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03364, current rewards: 316.94755, mean: 0.16171
[32m[0906 18-28-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03366, current rewards: 317.15199, mean: 0.15779
[32m[0906 18-28-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03365, current rewards: 324.34578, mean: 0.15745
[32m[0906 18-28-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03365, current rewards: 331.06841, mean: 0.15690
[32m[0906 18-28-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03364, current rewards: 337.58293, mean: 0.15629
[32m[0906 18-28-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03364, current rewards: 342.53604, mean: 0.15499
[32m[0906 18-28-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03363, current rewards: 349.63259, mean: 0.15470
[32m[0906 18-28-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03362, current rewards: 356.72914, mean: 0.15443
[32m[0906 18-28-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03361, current rewards: 363.82569, mean: 0.15416
[32m[0906 18-28-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03361, current rewards: 370.92224, mean: 0.15391
[32m[0906 18-28-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03360, current rewards: 360.88983, mean: 0.14670
[32m[0906 18-28-27 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 18-28-27 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-28-27 @MBExp.py:227][0m Rewards obtained: [320.8898300729871], Lows: [7], Highs: [59], Total time: 8166.296248999999
[32m[0906 18-31-40 @MBExp.py:144][0m ####################################################################
[32m[0906 18-31-40 @MBExp.py:145][0m Starting training iteration 95.
[32m[0906 18-31-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03257, current rewards: 0.29231, mean: 0.02923
[32m[0906 18-31-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03315, current rewards: 5.89564, mean: 0.09826
[32m[0906 18-31-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03335, current rewards: 11.45551, mean: 0.10414
[32m[0906 18-31-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03331, current rewards: 17.01858, mean: 0.10637
[32m[0906 18-31-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03335, current rewards: 22.58321, mean: 0.10754
[32m[0906 18-31-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03334, current rewards: 28.14818, mean: 0.10826
[32m[0906 18-31-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03336, current rewards: 33.71013, mean: 0.10874
[32m[0906 18-31-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03336, current rewards: 39.27574, mean: 0.10910
[32m[0906 18-31-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03333, current rewards: 44.80059, mean: 0.10927
[32m[0906 18-31-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03332, current rewards: 50.36071, mean: 0.10948
[32m[0906 18-31-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03331, current rewards: 55.92137, mean: 0.10965
[32m[0906 18-31-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03331, current rewards: 60.41820, mean: 0.10789
[32m[0906 18-32-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03331, current rewards: 65.98628, mean: 0.10817
[32m[0906 18-32-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03331, current rewards: 71.55623, mean: 0.10842
[32m[0906 18-32-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03329, current rewards: 77.12709, mean: 0.10863
[32m[0906 18-32-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03332, current rewards: 82.69477, mean: 0.10881
[32m[0906 18-32-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03332, current rewards: 88.37688, mean: 0.10911
[32m[0906 18-32-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03333, current rewards: 93.62466, mean: 0.10887
[32m[0906 18-32-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03332, current rewards: 98.86970, mean: 0.10865
[32m[0906 18-32-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03333, current rewards: 104.11756, mean: 0.10846
[32m[0906 18-32-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03334, current rewards: 109.36395, mean: 0.10828
[32m[0906 18-32-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03335, current rewards: 114.60942, mean: 0.10812
[32m[0906 18-32-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03339, current rewards: 119.85396, mean: 0.10798
[32m[0906 18-32-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03342, current rewards: 125.09706, mean: 0.10784
[32m[0906 18-32-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03346, current rewards: 130.30815, mean: 0.10769
[32m[0906 18-32-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03349, current rewards: 135.44656, mean: 0.10750
[32m[0906 18-32-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03352, current rewards: 140.42902, mean: 0.10720
[32m[0906 18-32-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03354, current rewards: 145.41554, mean: 0.10692
[32m[0906 18-32-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03357, current rewards: 150.39942, mean: 0.10667
[32m[0906 18-32-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03360, current rewards: 155.38400, mean: 0.10643
[32m[0906 18-32-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03361, current rewards: 160.36931, mean: 0.10620
[32m[0906 18-32-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03363, current rewards: 165.67767, mean: 0.10620
[32m[0906 18-32-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03365, current rewards: 171.41053, mean: 0.10647
[32m[0906 18-32-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03366, current rewards: 177.12012, mean: 0.10670
[32m[0906 18-32-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03367, current rewards: 182.82438, mean: 0.10691
[32m[0906 18-32-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03366, current rewards: 188.52607, mean: 0.10712
[32m[0906 18-32-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03366, current rewards: 194.23456, mean: 0.10731
[32m[0906 18-32-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03365, current rewards: 199.93813, mean: 0.10749
[32m[0906 18-32-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03364, current rewards: 205.64533, mean: 0.10767
[32m[0906 18-32-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03364, current rewards: 211.35196, mean: 0.10783
[32m[0906 18-32-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03363, current rewards: 210.72642, mean: 0.10484
[32m[0906 18-32-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03363, current rewards: 216.36770, mean: 0.10503
[32m[0906 18-32-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03363, current rewards: 222.00932, mean: 0.10522
[32m[0906 18-32-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03363, current rewards: 227.65045, mean: 0.10539
[32m[0906 18-32-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03362, current rewards: 233.29128, mean: 0.10556
[32m[0906 18-32-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03362, current rewards: 238.93319, mean: 0.10572
[32m[0906 18-32-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03362, current rewards: 244.57522, mean: 0.10588
[32m[0906 18-32-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03361, current rewards: 250.21628, mean: 0.10602
[32m[0906 18-33-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03360, current rewards: 255.89102, mean: 0.10618
[32m[0906 18-33-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03360, current rewards: 261.56944, mean: 0.10633
[32m[0906 18-33-04 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 18-33-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-33-04 @MBExp.py:227][0m Rewards obtained: [266.08835266778755], Lows: [3], Highs: [2], Total time: 8251.044480999999
[32m[0906 18-36-19 @MBExp.py:144][0m ####################################################################
[32m[0906 18-36-19 @MBExp.py:145][0m Starting training iteration 96.
[32m[0906 18-36-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03527, current rewards: 0.68670, mean: 0.06867
[32m[0906 18-36-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03353, current rewards: 6.21550, mean: 0.10359
[32m[0906 18-36-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03347, current rewards: 11.74704, mean: 0.10679
[32m[0906 18-36-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03350, current rewards: 17.27901, mean: 0.10799
[32m[0906 18-36-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03351, current rewards: 22.80928, mean: 0.10862
[32m[0906 18-36-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03350, current rewards: 28.34284, mean: 0.10901
[32m[0906 18-36-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03347, current rewards: 33.87437, mean: 0.10927
[32m[0906 18-36-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03347, current rewards: 39.63981, mean: 0.11011
[32m[0906 18-36-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03343, current rewards: 45.17240, mean: 0.11018
[32m[0906 18-36-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03342, current rewards: 50.70401, mean: 0.11023
[32m[0906 18-36-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03342, current rewards: 55.07452, mean: 0.10799
[32m[0906 18-36-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03342, current rewards: 60.64291, mean: 0.10829
[32m[0906 18-36-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03341, current rewards: 66.21089, mean: 0.10854
[32m[0906 18-36-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03341, current rewards: 71.78119, mean: 0.10876
[32m[0906 18-36-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03342, current rewards: 77.34776, mean: 0.10894
[32m[0906 18-36-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03341, current rewards: 82.91036, mean: 0.10909
[32m[0906 18-36-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03341, current rewards: 88.47512, mean: 0.10923
[32m[0906 18-36-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03341, current rewards: 94.03945, mean: 0.10935
[32m[0906 18-36-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03341, current rewards: 99.60011, mean: 0.10945
[32m[0906 18-36-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03339, current rewards: 99.92858, mean: 0.10409
[32m[0906 18-36-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03340, current rewards: 105.48481, mean: 0.10444
[32m[0906 18-36-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03339, current rewards: 111.04215, mean: 0.10476
[32m[0906 18-36-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03344, current rewards: 116.59601, mean: 0.10504
[32m[0906 18-36-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03347, current rewards: 122.18657, mean: 0.10533
[32m[0906 18-36-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03350, current rewards: 127.74506, mean: 0.10557
[32m[0906 18-37-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03352, current rewards: 133.29979, mean: 0.10579
[32m[0906 18-37-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03356, current rewards: 136.96539, mean: 0.10455
[32m[0906 18-37-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03358, current rewards: 142.57025, mean: 0.10483
[32m[0906 18-37-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03360, current rewards: 148.17363, mean: 0.10509
[32m[0906 18-37-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03363, current rewards: 153.77506, mean: 0.10533
[32m[0906 18-37-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03364, current rewards: 159.37520, mean: 0.10555
[32m[0906 18-37-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03366, current rewards: 164.98010, mean: 0.10576
[32m[0906 18-37-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03367, current rewards: 170.57844, mean: 0.10595
[32m[0906 18-37-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03368, current rewards: 176.18222, mean: 0.10613
[32m[0906 18-37-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03370, current rewards: 181.78118, mean: 0.10630
[32m[0906 18-37-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03369, current rewards: 187.38998, mean: 0.10647
[32m[0906 18-37-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03367, current rewards: 191.95264, mean: 0.10605
[32m[0906 18-37-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03366, current rewards: 197.15205, mean: 0.10600
[32m[0906 18-37-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03366, current rewards: 202.35040, mean: 0.10594
[32m[0906 18-37-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03366, current rewards: 207.48006, mean: 0.10586
[32m[0906 18-37-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03365, current rewards: 212.69538, mean: 0.10582
[32m[0906 18-37-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03365, current rewards: 217.92067, mean: 0.10579
[32m[0906 18-37-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03364, current rewards: 223.13902, mean: 0.10575
[32m[0906 18-37-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03363, current rewards: 228.35381, mean: 0.10572
[32m[0906 18-37-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03363, current rewards: 233.57596, mean: 0.10569
[32m[0906 18-37-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03362, current rewards: 238.79072, mean: 0.10566
[32m[0906 18-37-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03362, current rewards: 244.00808, mean: 0.10563
[32m[0906 18-37-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03362, current rewards: 247.50219, mean: 0.10487
[32m[0906 18-37-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03361, current rewards: 252.99115, mean: 0.10498
[32m[0906 18-37-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03361, current rewards: 258.51181, mean: 0.10509
[32m[0906 18-37-43 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 18-37-43 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-37-43 @MBExp.py:227][0m Rewards obtained: [262.922003170955], Lows: [4], Highs: [4], Total time: 8335.830772
[32m[0906 18-41-00 @MBExp.py:144][0m ####################################################################
[32m[0906 18-41-00 @MBExp.py:145][0m Starting training iteration 97.
[32m[0906 18-41-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03200, current rewards: -2.55328, mean: -0.25533
[32m[0906 18-41-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03314, current rewards: 2.52101, mean: 0.04202
[32m[0906 18-41-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03319, current rewards: 7.59476, mean: 0.06904
[32m[0906 18-41-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03321, current rewards: 12.66898, mean: 0.07918
[32m[0906 18-41-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03329, current rewards: 17.73962, mean: 0.08447
[32m[0906 18-41-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03332, current rewards: 22.80953, mean: 0.08773
[32m[0906 18-41-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03333, current rewards: 28.02514, mean: 0.09040
[32m[0906 18-41-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03330, current rewards: 33.05148, mean: 0.09181
[32m[0906 18-41-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03330, current rewards: 38.07491, mean: 0.09287
[32m[0906 18-41-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03333, current rewards: 43.09895, mean: 0.09369
[32m[0906 18-41-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03330, current rewards: 48.11733, mean: 0.09435
[32m[0906 18-41-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03331, current rewards: 53.84932, mean: 0.09616
[32m[0906 18-41-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03332, current rewards: 58.86793, mean: 0.09650
[32m[0906 18-41-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03332, current rewards: 63.89473, mean: 0.09681
[32m[0906 18-41-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03331, current rewards: 68.91431, mean: 0.09706
[32m[0906 18-41-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03332, current rewards: 74.12427, mean: 0.09753
[32m[0906 18-41-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03334, current rewards: 79.32486, mean: 0.09793
[32m[0906 18-41-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03334, current rewards: 84.54286, mean: 0.09831
[32m[0906 18-41-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03336, current rewards: 89.73781, mean: 0.09861
[32m[0906 18-41-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03336, current rewards: 94.94485, mean: 0.09890
[32m[0906 18-41-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03335, current rewards: 100.16454, mean: 0.09917
[32m[0906 18-41-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03335, current rewards: 105.36895, mean: 0.09940
[32m[0906 18-41-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03339, current rewards: 104.61710, mean: 0.09425
[32m[0906 18-41-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03343, current rewards: 110.21955, mean: 0.09502
[32m[0906 18-41-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03347, current rewards: 115.78310, mean: 0.09569
[32m[0906 18-41-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03350, current rewards: 121.33877, mean: 0.09630
[32m[0906 18-41-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03353, current rewards: 126.89685, mean: 0.09687
[32m[0906 18-41-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03357, current rewards: 132.45858, mean: 0.09740
[32m[0906 18-41-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03360, current rewards: 133.87191, mean: 0.09494
[32m[0906 18-41-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03363, current rewards: 139.49881, mean: 0.09555
[32m[0906 18-41-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03365, current rewards: 145.12529, mean: 0.09611
[32m[0906 18-41-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03367, current rewards: 150.56439, mean: 0.09652
[32m[0906 18-41-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03369, current rewards: 156.22486, mean: 0.09703
[32m[0906 18-41-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03370, current rewards: 161.88467, mean: 0.09752
[32m[0906 18-41-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03371, current rewards: 167.54388, mean: 0.09798
[32m[0906 18-41-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03369, current rewards: 173.20308, mean: 0.09841
[32m[0906 18-42-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03369, current rewards: 178.86271, mean: 0.09882
[32m[0906 18-42-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03368, current rewards: 179.09544, mean: 0.09629
[32m[0906 18-42-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03367, current rewards: 184.60496, mean: 0.09665
[32m[0906 18-42-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03366, current rewards: 190.27564, mean: 0.09708
[32m[0906 18-42-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03365, current rewards: 195.78080, mean: 0.09740
[32m[0906 18-42-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03365, current rewards: 201.28589, mean: 0.09771
[32m[0906 18-42-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03365, current rewards: 206.78741, mean: 0.09800
[32m[0906 18-42-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03364, current rewards: 212.28835, mean: 0.09828
[32m[0906 18-42-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03364, current rewards: 217.78936, mean: 0.09855
[32m[0906 18-42-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03363, current rewards: 223.29139, mean: 0.09880
[32m[0906 18-42-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03363, current rewards: 228.79580, mean: 0.09905
[32m[0906 18-42-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03362, current rewards: 234.34891, mean: 0.09930
[32m[0906 18-42-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03363, current rewards: 231.85549, mean: 0.09621
[32m[0906 18-42-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03363, current rewards: 237.30467, mean: 0.09647
[32m[0906 18-42-24 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 18-42-24 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-42-25 @MBExp.py:227][0m Rewards obtained: [241.662845571588], Lows: [12], Highs: [3], Total time: 8420.666468
[32m[0906 18-45-42 @MBExp.py:144][0m ####################################################################
[32m[0906 18-45-42 @MBExp.py:145][0m Starting training iteration 98.
[32m[0906 18-45-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03426, current rewards: -0.06065, mean: -0.00607
[32m[0906 18-45-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03374, current rewards: 5.36730, mean: 0.08946
[32m[0906 18-45-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03362, current rewards: 10.79460, mean: 0.09813
[32m[0906 18-45-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03354, current rewards: 16.22215, mean: 0.10139
[32m[0906 18-45-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03349, current rewards: 21.65246, mean: 0.10311
[32m[0906 18-45-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03348, current rewards: 27.08066, mean: 0.10416
[32m[0906 18-45-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03345, current rewards: 32.44197, mean: 0.10465
[32m[0906 18-45-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03342, current rewards: 37.87603, mean: 0.10521
[32m[0906 18-45-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03342, current rewards: 43.30997, mean: 0.10563
[32m[0906 18-45-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03345, current rewards: 48.74222, mean: 0.10596
[32m[0906 18-46-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03342, current rewards: 54.17733, mean: 0.10623
[32m[0906 18-46-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03342, current rewards: 45.83385, mean: 0.08185
[32m[0906 18-46-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03343, current rewards: 51.13836, mean: 0.08383
[32m[0906 18-46-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03344, current rewards: 56.44166, mean: 0.08552
[32m[0906 18-46-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03344, current rewards: 61.75550, mean: 0.08698
[32m[0906 18-46-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03345, current rewards: 67.02240, mean: 0.08819
[32m[0906 18-46-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03345, current rewards: 72.28949, mean: 0.08925
[32m[0906 18-46-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03344, current rewards: 77.55734, mean: 0.09018
[32m[0906 18-46-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03344, current rewards: 82.82595, mean: 0.09102
[32m[0906 18-46-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03350, current rewards: 42.30046, mean: 0.04406
[32m[0906 18-46-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03349, current rewards: -6.05284, mean: -0.00599
[32m[0906 18-46-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03348, current rewards: -54.41023, mean: -0.05133
[32m[0906 18-46-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03349, current rewards: -102.77013, mean: -0.09259
[32m[0906 18-46-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03352, current rewards: -151.15430, mean: -0.13031
[32m[0906 18-46-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03355, current rewards: -199.54853, mean: -0.16492
[32m[0906 18-46-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03358, current rewards: -247.93971, mean: -0.19678
[32m[0906 18-46-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03361, current rewards: -296.33325, mean: -0.22621
[32m[0906 18-46-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03372, current rewards: -333.86014, mean: -0.24549
[32m[0906 18-46-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03375, current rewards: -328.77843, mean: -0.23318
[32m[0906 18-46-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03378, current rewards: -323.68946, mean: -0.22171
[32m[0906 18-46-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03379, current rewards: -318.72684, mean: -0.21108
[32m[0906 18-46-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03381, current rewards: -317.81628, mean: -0.20373
[32m[0906 18-46-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03384, current rewards: -312.66942, mean: -0.19420
[32m[0906 18-46-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03385, current rewards: -307.52456, mean: -0.18526
[32m[0906 18-46-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03386, current rewards: -302.37669, mean: -0.17683
[32m[0906 18-46-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03384, current rewards: -303.64065, mean: -0.17252
[32m[0906 18-46-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03384, current rewards: -302.82409, mean: -0.16731
[32m[0906 18-46-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03383, current rewards: -298.09214, mean: -0.16026
[32m[0906 18-46-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03382, current rewards: -293.41195, mean: -0.15362
[32m[0906 18-46-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03381, current rewards: -288.75248, mean: -0.14732
[32m[0906 18-46-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03380, current rewards: -284.09114, mean: -0.14134
[32m[0906 18-46-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03380, current rewards: -279.42808, mean: -0.13564
[32m[0906 18-46-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03378, current rewards: -274.76618, mean: -0.13022
[32m[0906 18-46-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03377, current rewards: -271.19706, mean: -0.12555
[32m[0906 18-46-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03384, current rewards: -323.32232, mean: -0.14630
[32m[0906 18-47-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03395, current rewards: -364.36393, mean: -0.16122
[32m[0906 18-47-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03397, current rewards: -417.51937, mean: -0.18074
[32m[0906 18-47-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03402, current rewards: -469.23570, mean: -0.19883
[32m[0906 18-47-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03415, current rewards: -500.74912, mean: -0.20778
[32m[0906 18-47-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03416, current rewards: -564.87408, mean: -0.22962
[32m[0906 18-47-08 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 18-47-08 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-47-09 @MBExp.py:227][0m Rewards obtained: [-603.1087359665443], Lows: [388], Highs: [44], Total time: 8507.006288999999
[32m[0906 18-50-29 @MBExp.py:144][0m ####################################################################
[32m[0906 18-50-29 @MBExp.py:145][0m Starting training iteration 99.
[32m[0906 18-50-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03319, current rewards: -4.20801, mean: -0.42080
[32m[0906 18-50-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03330, current rewards: 0.77407, mean: 0.01290
[32m[0906 18-50-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03335, current rewards: 5.75396, mean: 0.05231
[32m[0906 18-50-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03335, current rewards: 10.73526, mean: 0.06710
[32m[0906 18-50-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03337, current rewards: 15.70882, mean: 0.07480
[32m[0906 18-50-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03332, current rewards: 20.75553, mean: 0.07983
[32m[0906 18-50-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03332, current rewards: 25.75930, mean: 0.08309
[32m[0906 18-50-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03331, current rewards: 30.75947, mean: 0.08544
[32m[0906 18-50-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03331, current rewards: 35.76037, mean: 0.08722
[32m[0906 18-50-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03333, current rewards: 40.76203, mean: 0.08861
[32m[0906 18-50-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03330, current rewards: 45.76535, mean: 0.08974
[32m[0906 18-50-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03333, current rewards: 47.65913, mean: 0.08511
[32m[0906 18-50-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03335, current rewards: 52.77474, mean: 0.08652
[32m[0906 18-50-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03335, current rewards: 57.69960, mean: 0.08742
[32m[0906 18-50-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03335, current rewards: 62.63065, mean: 0.08821
[32m[0906 18-50-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03335, current rewards: 67.56272, mean: 0.08890
[32m[0906 18-50-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03336, current rewards: 66.25432, mean: 0.08180
[32m[0906 18-50-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03336, current rewards: 71.49774, mean: 0.08314
[32m[0906 18-51-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03336, current rewards: 76.74363, mean: 0.08433
[32m[0906 18-51-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03336, current rewards: 81.98842, mean: 0.08540
[32m[0906 18-51-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03336, current rewards: 87.22956, mean: 0.08637
[32m[0906 18-51-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03338, current rewards: 92.47429, mean: 0.08724
[32m[0906 18-51-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03342, current rewards: 97.73137, mean: 0.08805
[32m[0906 18-51-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03347, current rewards: 102.97798, mean: 0.08877
[32m[0906 18-51-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03350, current rewards: 108.22641, mean: 0.08944
[32m[0906 18-51-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03353, current rewards: 113.47248, mean: 0.09006
[32m[0906 18-51-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03356, current rewards: 118.71799, mean: 0.09062
[32m[0906 18-51-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03358, current rewards: 123.96459, mean: 0.09115
[32m[0906 18-51-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03360, current rewards: 129.21212, mean: 0.09164
[32m[0906 18-51-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03362, current rewards: 134.46225, mean: 0.09210
[32m[0906 18-51-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03365, current rewards: 140.04982, mean: 0.09275
[32m[0906 18-51-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03367, current rewards: 144.81748, mean: 0.09283
[32m[0906 18-51-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03369, current rewards: 151.27630, mean: 0.09396
[32m[0906 18-51-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03371, current rewards: 157.73512, mean: 0.09502
[32m[0906 18-51-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03368, current rewards: 164.19395, mean: 0.09602
[32m[0906 18-51-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03367, current rewards: 170.65277, mean: 0.09696
[32m[0906 18-51-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03367, current rewards: 177.11159, mean: 0.09785
[32m[0906 18-51-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03366, current rewards: 183.57042, mean: 0.09869
[32m[0906 18-51-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03366, current rewards: 190.02924, mean: 0.09949
[32m[0906 18-51-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03366, current rewards: 196.48806, mean: 0.10025
[32m[0906 18-51-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03365, current rewards: 172.45912, mean: 0.08580
[32m[0906 18-51-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03364, current rewards: 122.45912, mean: 0.05945
[32m[0906 18-51-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03364, current rewards: 72.45912, mean: 0.03434
[32m[0906 18-51-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03363, current rewards: 22.45912, mean: 0.01040
[32m[0906 18-51-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03363, current rewards: -27.54088, mean: -0.01246
[32m[0906 18-51-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03362, current rewards: -77.54088, mean: -0.03431
[32m[0906 18-51-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03361, current rewards: -127.54088, mean: -0.05521
[32m[0906 18-51-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03361, current rewards: -177.54088, mean: -0.07523
[32m[0906 18-51-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03361, current rewards: -227.54088, mean: -0.09442
[32m[0906 18-51-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03360, current rewards: -277.54088, mean: -0.11282
[32m[0906 18-51-54 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 18-51-54 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-51-54 @MBExp.py:227][0m Rewards obtained: [-317.5408771462603], Lows: [7], Highs: [519], Total time: 8591.781240999999
[32m[0906 18-55-16 @MBExp.py:144][0m ####################################################################
[32m[0906 18-55-16 @MBExp.py:145][0m Starting training iteration 100.
[32m[0906 18-55-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03266, current rewards: -8.29855, mean: -0.82985
[32m[0906 18-55-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03314, current rewards: -2.07561, mean: -0.03459
[32m[0906 18-55-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03324, current rewards: 4.16276, mean: 0.03784
[32m[0906 18-55-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03323, current rewards: 10.42118, mean: 0.06513
[32m[0906 18-55-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03327, current rewards: 16.67876, mean: 0.07942
[32m[0906 18-55-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03318, current rewards: 23.23781, mean: 0.08938
[32m[0906 18-55-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03320, current rewards: 29.45082, mean: 0.09500
[32m[0906 18-55-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03321, current rewards: 31.25505, mean: 0.08682
[32m[0906 18-55-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03326, current rewards: 35.95146, mean: 0.08769
[32m[0906 18-55-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03326, current rewards: 40.64787, mean: 0.08836
[32m[0906 18-55-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03325, current rewards: 45.34428, mean: 0.08891
[32m[0906 18-55-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03325, current rewards: 50.04069, mean: 0.08936
[32m[0906 18-55-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03326, current rewards: 54.73709, mean: 0.08973
[32m[0906 18-55-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03327, current rewards: 58.84482, mean: 0.08916
[32m[0906 18-55-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03328, current rewards: 62.53207, mean: 0.08807
[32m[0906 18-55-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03329, current rewards: 66.21931, mean: 0.08713
[32m[0906 18-55-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03329, current rewards: 69.90656, mean: 0.08630
[32m[0906 18-55-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03331, current rewards: 43.52895, mean: 0.05062
[32m[0906 18-55-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03331, current rewards: -6.47105, mean: -0.00711
[32m[0906 18-55-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03331, current rewards: -56.47105, mean: -0.05882
[32m[0906 18-55-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03333, current rewards: -106.47105, mean: -0.10542
[32m[0906 18-55-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03333, current rewards: -156.47105, mean: -0.14761
[32m[0906 18-55-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03338, current rewards: -206.47105, mean: -0.18601
[32m[0906 18-55-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03341, current rewards: -256.47105, mean: -0.22110
[32m[0906 18-55-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03345, current rewards: -306.47105, mean: -0.25328
[32m[0906 18-55-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03348, current rewards: -356.47105, mean: -0.28291
[32m[0906 18-56-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03351, current rewards: -406.47105, mean: -0.31028
[32m[0906 18-56-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03353, current rewards: -456.47105, mean: -0.33564
[32m[0906 18-56-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03356, current rewards: -506.47105, mean: -0.35920
[32m[0906 18-56-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03356, current rewards: -556.47105, mean: -0.38114
[32m[0906 18-56-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03358, current rewards: -606.47105, mean: -0.40164
[32m[0906 18-56-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03360, current rewards: -656.47105, mean: -0.42081
[32m[0906 18-56-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03362, current rewards: -706.47105, mean: -0.43880
[32m[0906 18-56-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03364, current rewards: -756.47105, mean: -0.45571
[32m[0906 18-56-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03362, current rewards: -806.47105, mean: -0.47162
[32m[0906 18-56-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03360, current rewards: -856.47105, mean: -0.48663
[32m[0906 18-56-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03359, current rewards: -906.47105, mean: -0.50081
[32m[0906 18-56-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03359, current rewards: -956.47105, mean: -0.51423
[32m[0906 18-56-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03359, current rewards: -1006.47105, mean: -0.52695
[32m[0906 18-56-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03358, current rewards: -1056.47105, mean: -0.53902
[32m[0906 18-56-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03357, current rewards: -1106.47105, mean: -0.55048
[32m[0906 18-56-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03356, current rewards: -1156.47105, mean: -0.56139
[32m[0906 18-56-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03356, current rewards: -1206.47105, mean: -0.57179
[32m[0906 18-56-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03355, current rewards: -1256.47105, mean: -0.58170
[32m[0906 18-56-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03355, current rewards: -1306.47105, mean: -0.59116
[32m[0906 18-56-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03355, current rewards: -1356.47105, mean: -0.60021
[32m[0906 18-56-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03355, current rewards: -1406.47105, mean: -0.60886
[32m[0906 18-56-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03355, current rewards: -1456.47105, mean: -0.61715
[32m[0906 18-56-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03354, current rewards: -1506.47105, mean: -0.62509
[32m[0906 18-56-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03354, current rewards: -1556.47105, mean: -0.63271
[32m[0906 18-56-40 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 18-56-40 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-56-40 @MBExp.py:227][0m Rewards obtained: [-1596.471052055967], Lows: [6], Highs: [1669], Total time: 8676.412048999999
[32m[0906 19-00-04 @MBExp.py:144][0m ####################################################################
[32m[0906 19-00-04 @MBExp.py:145][0m Starting training iteration 101.
[32m[0906 19-00-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03521, current rewards: -3.34234, mean: -0.33423
[32m[0906 19-00-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03369, current rewards: 2.04080, mean: 0.03401
[32m[0906 19-00-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03362, current rewards: 7.39683, mean: 0.06724
[32m[0906 19-00-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03353, current rewards: 12.75568, mean: 0.07972
[32m[0906 19-00-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03341, current rewards: 18.03703, mean: 0.08589
[32m[0906 19-00-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03340, current rewards: 23.43853, mean: 0.09015
[32m[0906 19-00-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03341, current rewards: 28.83619, mean: 0.09302
[32m[0906 19-00-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03341, current rewards: 34.23706, mean: 0.09510
[32m[0906 19-00-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03344, current rewards: 37.59179, mean: 0.09169
[32m[0906 19-00-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03343, current rewards: 42.86208, mean: 0.09318
[32m[0906 19-00-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03343, current rewards: 48.12455, mean: 0.09436
[32m[0906 19-00-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03340, current rewards: 53.38519, mean: 0.09533
[32m[0906 19-00-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03339, current rewards: 58.64775, mean: 0.09614
[32m[0906 19-00-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03341, current rewards: 63.90987, mean: 0.09683
[32m[0906 19-00-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03341, current rewards: 69.17363, mean: 0.09743
[32m[0906 19-00-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03341, current rewards: 74.42886, mean: 0.09793
[32m[0906 19-00-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03340, current rewards: 79.68870, mean: 0.09838
[32m[0906 19-00-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03339, current rewards: 80.83759, mean: 0.09400
[32m[0906 19-00-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03340, current rewards: 86.28200, mean: 0.09482
[32m[0906 19-00-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03341, current rewards: 91.72765, mean: 0.09555
[32m[0906 19-00-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03340, current rewards: 97.15416, mean: 0.09619
[32m[0906 19-00-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03341, current rewards: 102.18801, mean: 0.09640
[32m[0906 19-00-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03344, current rewards: 107.43539, mean: 0.09679
[32m[0906 19-00-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03347, current rewards: 112.67919, mean: 0.09714
[32m[0906 19-00-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03349, current rewards: 117.92353, mean: 0.09746
[32m[0906 19-00-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03352, current rewards: 123.16978, mean: 0.09775
[32m[0906 19-00-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03358, current rewards: 123.12414, mean: 0.09399
[32m[0906 19-00-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03360, current rewards: 128.17876, mean: 0.09425
[32m[0906 19-00-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03363, current rewards: 133.23688, mean: 0.09449
[32m[0906 19-00-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03364, current rewards: 138.54332, mean: 0.09489
[32m[0906 19-00-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03368, current rewards: 143.62086, mean: 0.09511
[32m[0906 19-00-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03370, current rewards: 148.69995, mean: 0.09532
[32m[0906 19-00-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03372, current rewards: 153.78186, mean: 0.09552
[32m[0906 19-01-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03372, current rewards: 155.07220, mean: 0.09342
[32m[0906 19-01-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03370, current rewards: 161.02158, mean: 0.09416
[32m[0906 19-01-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03368, current rewards: 166.97088, mean: 0.09487
[32m[0906 19-01-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03368, current rewards: 172.92019, mean: 0.09554
[32m[0906 19-01-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03367, current rewards: 178.86929, mean: 0.09617
[32m[0906 19-01-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03366, current rewards: 184.61042, mean: 0.09665
[32m[0906 19-01-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03366, current rewards: 190.55494, mean: 0.09722
[32m[0906 19-01-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03365, current rewards: 196.50478, mean: 0.09776
[32m[0906 19-01-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03365, current rewards: 194.57706, mean: 0.09445
[32m[0906 19-01-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03364, current rewards: 200.13264, mean: 0.09485
[32m[0906 19-01-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03364, current rewards: 205.69119, mean: 0.09523
[32m[0906 19-01-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03363, current rewards: 211.24560, mean: 0.09559
[32m[0906 19-01-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03363, current rewards: 216.79832, mean: 0.09593
[32m[0906 19-01-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03362, current rewards: 222.45985, mean: 0.09630
[32m[0906 19-01-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03362, current rewards: 227.99899, mean: 0.09661
[32m[0906 19-01-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03361, current rewards: 233.53566, mean: 0.09690
[32m[0906 19-01-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03361, current rewards: 239.07907, mean: 0.09719
[32m[0906 19-01-29 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 19-01-29 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-01-29 @MBExp.py:227][0m Rewards obtained: [243.5285525142124], Lows: [11], Highs: [5], Total time: 8761.195242999998
[32m[0906 19-04-54 @MBExp.py:144][0m ####################################################################
[32m[0906 19-04-54 @MBExp.py:145][0m Starting training iteration 102.
[32m[0906 19-04-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03266, current rewards: -1.04875, mean: -0.10488
[32m[0906 19-04-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03322, current rewards: 5.03287, mean: 0.08388
[32m[0906 19-04-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03334, current rewards: 11.07814, mean: 0.10071
[32m[0906 19-04-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03340, current rewards: 17.12340, mean: 0.10702
[32m[0906 19-05-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03331, current rewards: 23.16867, mean: 0.11033
[32m[0906 19-05-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03328, current rewards: 28.45602, mean: 0.10945
[32m[0906 19-05-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03328, current rewards: 33.50589, mean: 0.10808
[32m[0906 19-05-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03328, current rewards: 38.55577, mean: 0.10710
[32m[0906 19-05-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03330, current rewards: 43.60565, mean: 0.10636
[32m[0906 19-05-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03330, current rewards: 14.52460, mean: 0.03158
[32m[0906 19-05-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03331, current rewards: -35.47540, mean: -0.06956
[32m[0906 19-05-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03328, current rewards: -85.47540, mean: -0.15263
[32m[0906 19-05-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03329, current rewards: -135.47540, mean: -0.22209
[32m[0906 19-05-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03330, current rewards: -185.47540, mean: -0.28102
[32m[0906 19-05-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03331, current rewards: -235.47540, mean: -0.33166
[32m[0906 19-05-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03332, current rewards: -285.47540, mean: -0.37563
[32m[0906 19-05-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03332, current rewards: -335.47540, mean: -0.41417
[32m[0906 19-05-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03334, current rewards: -385.47540, mean: -0.44823
[32m[0906 19-05-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03334, current rewards: -435.47540, mean: -0.47854
[32m[0906 19-05-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03333, current rewards: -485.47540, mean: -0.50570
[32m[0906 19-05-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03333, current rewards: -535.47540, mean: -0.53017
[32m[0906 19-05-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03335, current rewards: -585.47540, mean: -0.55234
[32m[0906 19-05-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03338, current rewards: -635.47540, mean: -0.57250
[32m[0906 19-05-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03342, current rewards: -685.47540, mean: -0.59093
[32m[0906 19-05-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03345, current rewards: -735.47540, mean: -0.60783
[32m[0906 19-05-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03348, current rewards: -785.47540, mean: -0.62339
[32m[0906 19-05-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03351, current rewards: -835.47540, mean: -0.63777
[32m[0906 19-05-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03353, current rewards: -885.47540, mean: -0.65108
[32m[0906 19-05-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03355, current rewards: -935.47540, mean: -0.66346
[32m[0906 19-05-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03357, current rewards: -985.47540, mean: -0.67498
[32m[0906 19-05-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03359, current rewards: -1035.47540, mean: -0.68575
[32m[0906 19-05-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03361, current rewards: -1085.47540, mean: -0.69582
[32m[0906 19-05-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03364, current rewards: -1135.47540, mean: -0.70526
[32m[0906 19-05-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03366, current rewards: -1185.47540, mean: -0.71414
[32m[0906 19-05-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03364, current rewards: -1235.47540, mean: -0.72250
[32m[0906 19-05-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03363, current rewards: -1285.47540, mean: -0.73038
[32m[0906 19-05-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03362, current rewards: -1335.47540, mean: -0.73783
[32m[0906 19-05-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03361, current rewards: -1385.47540, mean: -0.74488
[32m[0906 19-05-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03361, current rewards: -1435.47540, mean: -0.75156
[32m[0906 19-06-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03361, current rewards: -1485.47540, mean: -0.75790
[32m[0906 19-06-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03360, current rewards: -1535.47540, mean: -0.76392
[32m[0906 19-06-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03359, current rewards: -1585.47540, mean: -0.76965
[32m[0906 19-06-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03359, current rewards: -1635.47540, mean: -0.77511
[32m[0906 19-06-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03358, current rewards: -1685.47540, mean: -0.78031
[32m[0906 19-06-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03358, current rewards: -1735.47540, mean: -0.78528
[32m[0906 19-06-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03357, current rewards: -1785.47540, mean: -0.79003
[32m[0906 19-06-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03357, current rewards: -1835.47540, mean: -0.79458
[32m[0906 19-06-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03357, current rewards: -1885.47540, mean: -0.79893
[32m[0906 19-06-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03357, current rewards: -1935.47540, mean: -0.80310
[32m[0906 19-06-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03356, current rewards: -1985.47540, mean: -0.80710
[32m[0906 19-06-18 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 19-06-18 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-06-18 @MBExp.py:227][0m Rewards obtained: [-2025.475401078822], Lows: [0], Highs: [2073], Total time: 8845.881580999998
[32m[0906 19-09-46 @MBExp.py:144][0m ####################################################################
[32m[0906 19-09-46 @MBExp.py:145][0m Starting training iteration 103.
[32m[0906 19-09-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03299, current rewards: -1.15154, mean: -0.11515
[32m[0906 19-09-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03315, current rewards: 4.31506, mean: 0.07192
[32m[0906 19-09-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03325, current rewards: 9.78589, mean: 0.08896
[32m[0906 19-09-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03321, current rewards: 15.25640, mean: 0.09535
[32m[0906 19-09-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03326, current rewards: 20.73234, mean: 0.09873
[32m[0906 19-09-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03331, current rewards: 26.20728, mean: 0.10080
[32m[0906 19-09-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03331, current rewards: 31.67811, mean: 0.10219
[32m[0906 19-09-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03332, current rewards: 37.15180, mean: 0.10320
[32m[0906 19-10-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03332, current rewards: 42.62040, mean: 0.10395
[32m[0906 19-10-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03332, current rewards: 48.09324, mean: 0.10455
[32m[0906 19-10-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03332, current rewards: 53.56383, mean: 0.10503
[32m[0906 19-10-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03332, current rewards: 59.03403, mean: 0.10542
[32m[0906 19-10-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03332, current rewards: 64.67531, mean: 0.10603
[32m[0906 19-10-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03334, current rewards: 66.08370, mean: 0.10013
[32m[0906 19-10-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03337, current rewards: 71.61968, mean: 0.10087
[32m[0906 19-10-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03337, current rewards: 77.15342, mean: 0.10152
[32m[0906 19-10-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03336, current rewards: 82.69336, mean: 0.10209
[32m[0906 19-10-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03337, current rewards: 88.22993, mean: 0.10259
[32m[0906 19-10-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03337, current rewards: 93.76545, mean: 0.10304
[32m[0906 19-10-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03337, current rewards: 99.29918, mean: 0.10344
[32m[0906 19-10-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03337, current rewards: 104.83157, mean: 0.10379
[32m[0906 19-10-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03336, current rewards: 110.12818, mean: 0.10389
[32m[0906 19-10-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03339, current rewards: 115.13316, mean: 0.10372
[32m[0906 19-10-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03344, current rewards: 120.23136, mean: 0.10365
[32m[0906 19-10-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03347, current rewards: 125.32991, mean: 0.10358
[32m[0906 19-10-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03350, current rewards: 130.43388, mean: 0.10352
[32m[0906 19-10-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03353, current rewards: 135.53590, mean: 0.10346
[32m[0906 19-10-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03356, current rewards: 140.63487, mean: 0.10341
[32m[0906 19-10-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03358, current rewards: 145.73722, mean: 0.10336
[32m[0906 19-10-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03360, current rewards: 150.99805, mean: 0.10342
[32m[0906 19-10-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03363, current rewards: 156.13143, mean: 0.10340
[32m[0906 19-10-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03365, current rewards: 161.23959, mean: 0.10336
[32m[0906 19-10-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03367, current rewards: 166.34783, mean: 0.10332
[32m[0906 19-10-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03366, current rewards: 171.45687, mean: 0.10329
[32m[0906 19-10-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03365, current rewards: 175.61211, mean: 0.10270
[32m[0906 19-10-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03365, current rewards: 181.26763, mean: 0.10299
[32m[0906 19-10-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03363, current rewards: 186.92189, mean: 0.10327
[32m[0906 19-10-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03362, current rewards: 192.57607, mean: 0.10354
[32m[0906 19-10-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03362, current rewards: 198.02547, mean: 0.10368
[32m[0906 19-10-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03361, current rewards: 203.67005, mean: 0.10391
[32m[0906 19-10-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03361, current rewards: 209.31534, mean: 0.10414
[32m[0906 19-10-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03361, current rewards: 214.95668, mean: 0.10435
[32m[0906 19-10-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03361, current rewards: 220.59995, mean: 0.10455
[32m[0906 19-10-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03361, current rewards: 226.24267, mean: 0.10474
[32m[0906 19-11-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03360, current rewards: 230.73475, mean: 0.10440
[32m[0906 19-11-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03360, current rewards: 236.13188, mean: 0.10448
[32m[0906 19-11-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03360, current rewards: 241.61817, mean: 0.10460
[32m[0906 19-11-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03360, current rewards: 246.97296, mean: 0.10465
[32m[0906 19-11-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03359, current rewards: 252.32849, mean: 0.10470
[32m[0906 19-11-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03358, current rewards: 257.67724, mean: 0.10475
[32m[0906 19-11-11 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 19-11-11 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-11-11 @MBExp.py:227][0m Rewards obtained: [261.96516142112205], Lows: [3], Highs: [4], Total time: 8930.619332999999
[32m[0906 19-14-40 @MBExp.py:144][0m ####################################################################
[32m[0906 19-14-40 @MBExp.py:145][0m Starting training iteration 104.
[32m[0906 19-14-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03315, current rewards: -5.16056, mean: -0.51606
[32m[0906 19-14-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03312, current rewards: 2.01005, mean: 0.03350
[32m[0906 19-14-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03325, current rewards: 9.48603, mean: 0.08624
[32m[0906 19-14-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03326, current rewards: 16.96061, mean: 0.10600
[32m[0906 19-14-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03333, current rewards: 24.39164, mean: 0.11615
[32m[0906 19-14-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03333, current rewards: 26.70281, mean: 0.10270
[32m[0906 19-14-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03334, current rewards: 32.19641, mean: 0.10386
[32m[0906 19-14-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03337, current rewards: 37.69183, mean: 0.10470
[32m[0906 19-14-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03338, current rewards: 43.18616, mean: 0.10533
[32m[0906 19-14-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03338, current rewards: 48.68103, mean: 0.10583
[32m[0906 19-14-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03341, current rewards: 50.86065, mean: 0.09973
[32m[0906 19-14-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03338, current rewards: 55.05337, mean: 0.09831
[32m[0906 19-15-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03340, current rewards: 59.25508, mean: 0.09714
[32m[0906 19-15-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03342, current rewards: 63.32340, mean: 0.09594
[32m[0906 19-15-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03342, current rewards: 67.48631, mean: 0.09505
[32m[0906 19-15-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03343, current rewards: 71.64270, mean: 0.09427
[32m[0906 19-15-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03343, current rewards: 75.78622, mean: 0.09356
[32m[0906 19-15-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03343, current rewards: 79.95692, mean: 0.09297
[32m[0906 19-15-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03344, current rewards: 84.11642, mean: 0.09244
[32m[0906 19-15-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03344, current rewards: 88.27473, mean: 0.09195
[32m[0906 19-15-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03345, current rewards: 92.39666, mean: 0.09148
[32m[0906 19-15-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03347, current rewards: 96.60539, mean: 0.09114
[32m[0906 19-15-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03348, current rewards: 100.77766, mean: 0.09079
[32m[0906 19-15-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03351, current rewards: 104.95257, mean: 0.09048
[32m[0906 19-15-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03355, current rewards: 109.14874, mean: 0.09021
[32m[0906 19-15-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03358, current rewards: 113.32592, mean: 0.08994
[32m[0906 19-15-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03361, current rewards: 117.53288, mean: 0.08972
[32m[0906 19-15-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03364, current rewards: 118.05523, mean: 0.08681
[32m[0906 19-15-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03365, current rewards: 123.57275, mean: 0.08764
[32m[0906 19-15-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03367, current rewards: 129.07697, mean: 0.08841
[32m[0906 19-15-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03370, current rewards: 134.60267, mean: 0.08914
[32m[0906 19-15-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03372, current rewards: 140.12030, mean: 0.08982
[32m[0906 19-15-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03374, current rewards: 145.63527, mean: 0.09046
[32m[0906 19-15-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03373, current rewards: 151.15182, mean: 0.09106
[32m[0906 19-15-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03372, current rewards: 156.67039, mean: 0.09162
[32m[0906 19-15-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03371, current rewards: 162.19451, mean: 0.09216
[32m[0906 19-15-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03370, current rewards: 167.71416, mean: 0.09266
[32m[0906 19-15-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03370, current rewards: 173.36430, mean: 0.09321
[32m[0906 19-15-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03373, current rewards: 176.85407, mean: 0.09259
[32m[0906 19-15-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03379, current rewards: 180.98343, mean: 0.09234
[32m[0906 19-15-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03382, current rewards: 185.14274, mean: 0.09211
[32m[0906 19-15-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03387, current rewards: 189.16324, mean: 0.09183
[32m[0906 19-15-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03390, current rewards: 193.30583, mean: 0.09161
[32m[0906 19-15-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03392, current rewards: 197.46445, mean: 0.09142
[32m[0906 19-15-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03397, current rewards: 201.53728, mean: 0.09119
[32m[0906 19-15-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03399, current rewards: 205.71194, mean: 0.09102
[32m[0906 19-15-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03401, current rewards: 209.81129, mean: 0.09083
[32m[0906 19-16-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03404, current rewards: 213.92365, mean: 0.09065
[32m[0906 19-16-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03408, current rewards: 218.02201, mean: 0.09047
[32m[0906 19-16-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03409, current rewards: 217.51118, mean: 0.08842
[32m[0906 19-16-06 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 19-16-06 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-16-06 @MBExp.py:227][0m Rewards obtained: [222.0468229757653], Lows: [9], Highs: [5], Total time: 9016.610255
[32m[0906 19-19-37 @MBExp.py:144][0m ####################################################################
[32m[0906 19-19-37 @MBExp.py:145][0m Starting training iteration 105.
[32m[0906 19-19-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03262, current rewards: 1.59495, mean: 0.15949
[32m[0906 19-19-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03298, current rewards: 9.05515, mean: 0.15092
[32m[0906 19-19-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03291, current rewards: 16.51534, mean: 0.15014
[32m[0906 19-19-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03307, current rewards: 23.88087, mean: 0.14926
[32m[0906 19-19-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03314, current rewards: -19.55651, mean: -0.09313
[32m[0906 19-19-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03313, current rewards: -69.55651, mean: -0.26753
[32m[0906 19-19-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03318, current rewards: -119.55651, mean: -0.38567
[32m[0906 19-19-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03318, current rewards: -169.55651, mean: -0.47099
[32m[0906 19-19-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03323, current rewards: -219.55651, mean: -0.53550
[32m[0906 19-19-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03326, current rewards: -269.55651, mean: -0.58599
[32m[0906 19-19-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03326, current rewards: -319.55651, mean: -0.62658
[32m[0906 19-19-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03326, current rewards: -369.55651, mean: -0.65992
[32m[0906 19-19-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03326, current rewards: -419.55651, mean: -0.68780
[32m[0906 19-20-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03330, current rewards: -469.55651, mean: -0.71145
[32m[0906 19-20-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03330, current rewards: -519.55651, mean: -0.73177
[32m[0906 19-20-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03331, current rewards: -569.55651, mean: -0.74942
[32m[0906 19-20-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03329, current rewards: -619.55651, mean: -0.76488
[32m[0906 19-20-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03330, current rewards: -669.55651, mean: -0.77855
[32m[0906 19-20-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03331, current rewards: -719.55651, mean: -0.79072
[32m[0906 19-20-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03332, current rewards: -769.55651, mean: -0.80162
[32m[0906 19-20-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03332, current rewards: -819.55651, mean: -0.81144
[32m[0906 19-20-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03333, current rewards: -869.55651, mean: -0.82034
[32m[0906 19-20-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03337, current rewards: -919.55651, mean: -0.82843
[32m[0906 19-20-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03341, current rewards: -969.55651, mean: -0.83582
[32m[0906 19-20-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03344, current rewards: -1019.55651, mean: -0.84261
[32m[0906 19-20-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03348, current rewards: -1069.55651, mean: -0.84885
[32m[0906 19-20-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03351, current rewards: -1119.55651, mean: -0.85462
[32m[0906 19-20-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03353, current rewards: -1169.55651, mean: -0.85997
[32m[0906 19-20-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03356, current rewards: -1219.55651, mean: -0.86493
[32m[0906 19-20-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03359, current rewards: -1269.55651, mean: -0.86956
[32m[0906 19-20-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03361, current rewards: -1319.55651, mean: -0.87388
[32m[0906 19-20-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03363, current rewards: -1369.55651, mean: -0.87792
[32m[0906 19-20-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03362, current rewards: -1419.55651, mean: -0.88171
[32m[0906 19-20-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03361, current rewards: -1469.55651, mean: -0.88528
[32m[0906 19-20-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03360, current rewards: -1519.55651, mean: -0.88863
[32m[0906 19-20-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03360, current rewards: -1569.55651, mean: -0.89179
[32m[0906 19-20-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03358, current rewards: -1619.55651, mean: -0.89478
[32m[0906 19-20-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03358, current rewards: -1669.55651, mean: -0.89761
[32m[0906 19-20-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03358, current rewards: -1719.55651, mean: -0.90029
[32m[0906 19-20-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03358, current rewards: -1769.55651, mean: -0.90283
[32m[0906 19-20-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03358, current rewards: -1819.55651, mean: -0.90525
[32m[0906 19-20-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03358, current rewards: -1869.55651, mean: -0.90755
[32m[0906 19-20-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03358, current rewards: -1919.55651, mean: -0.90974
[32m[0906 19-20-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03357, current rewards: -1969.55651, mean: -0.91183
[32m[0906 19-20-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03357, current rewards: -2019.55651, mean: -0.91383
[32m[0906 19-20-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03357, current rewards: -2069.55651, mean: -0.91573
[32m[0906 19-20-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03357, current rewards: -2119.55651, mean: -0.91756
[32m[0906 19-20-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03356, current rewards: -2169.55651, mean: -0.91930
[32m[0906 19-20-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03356, current rewards: -2219.55651, mean: -0.92098
[32m[0906 19-21-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03356, current rewards: -2237.09274, mean: -0.90939
[32m[0906 19-21-02 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 19-21-02 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-21-02 @MBExp.py:227][0m Rewards obtained: [-2233.8077141108583], Lows: [0], Highs: [2264], Total time: 9101.285915
[32m[0906 19-24-35 @MBExp.py:144][0m ####################################################################
[32m[0906 19-24-35 @MBExp.py:145][0m Starting training iteration 106.
[32m[0906 19-24-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03309, current rewards: 1.34022, mean: 0.13402
[32m[0906 19-24-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03350, current rewards: 8.10426, mean: 0.13507
[32m[0906 19-24-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03347, current rewards: 14.86830, mean: 0.13517
[32m[0906 19-24-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03341, current rewards: 19.57959, mean: 0.12237
[32m[0906 19-24-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03342, current rewards: 23.43703, mean: 0.11160
[32m[0906 19-24-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03343, current rewards: 27.29448, mean: 0.10498
[32m[0906 19-24-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03346, current rewards: 31.15193, mean: 0.10049
[32m[0906 19-24-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03345, current rewards: 23.16074, mean: 0.06434
[32m[0906 19-24-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03345, current rewards: -26.83926, mean: -0.06546
[32m[0906 19-24-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03344, current rewards: -76.83926, mean: -0.16704
[32m[0906 19-24-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03345, current rewards: -126.83926, mean: -0.24870
[32m[0906 19-24-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03344, current rewards: -176.83926, mean: -0.31578
[32m[0906 19-24-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03341, current rewards: -226.83926, mean: -0.37187
[32m[0906 19-24-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03341, current rewards: -276.83926, mean: -0.41945
[32m[0906 19-24-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03340, current rewards: -326.83926, mean: -0.46034
[32m[0906 19-25-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03340, current rewards: -376.83926, mean: -0.49584
[32m[0906 19-25-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03340, current rewards: -426.83926, mean: -0.52696
[32m[0906 19-25-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03340, current rewards: -476.83926, mean: -0.55446
[32m[0906 19-25-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03340, current rewards: -526.83926, mean: -0.57894
[32m[0906 19-25-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03339, current rewards: -576.83926, mean: -0.60087
[32m[0906 19-25-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03340, current rewards: -626.83926, mean: -0.62063
[32m[0906 19-25-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03338, current rewards: -676.83926, mean: -0.63853
[32m[0906 19-25-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03343, current rewards: -726.83926, mean: -0.65481
[32m[0906 19-25-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03346, current rewards: -776.83926, mean: -0.66969
[32m[0906 19-25-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03350, current rewards: -826.83926, mean: -0.68334
[32m[0906 19-25-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03353, current rewards: -876.83926, mean: -0.69590
[32m[0906 19-25-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03355, current rewards: -926.83926, mean: -0.70751
[32m[0906 19-25-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03358, current rewards: -976.83926, mean: -0.71826
[32m[0906 19-25-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03360, current rewards: -1026.83926, mean: -0.72825
[32m[0906 19-25-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03362, current rewards: -1076.83926, mean: -0.73756
[32m[0906 19-25-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03364, current rewards: -1126.83926, mean: -0.74625
[32m[0906 19-25-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03365, current rewards: -1176.83926, mean: -0.75438
[32m[0906 19-25-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03364, current rewards: -1226.83926, mean: -0.76201
[32m[0906 19-25-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03363, current rewards: -1276.83926, mean: -0.76918
[32m[0906 19-25-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03362, current rewards: -1326.83926, mean: -0.77593
[32m[0906 19-25-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03361, current rewards: -1376.83926, mean: -0.78230
[32m[0906 19-25-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03361, current rewards: -1426.83926, mean: -0.78831
[32m[0906 19-25-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03360, current rewards: -1476.83926, mean: -0.79400
[32m[0906 19-25-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03359, current rewards: -1526.83926, mean: -0.79939
[32m[0906 19-25-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03359, current rewards: -1576.83926, mean: -0.80451
[32m[0906 19-25-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03358, current rewards: -1626.83926, mean: -0.80937
[32m[0906 19-25-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03358, current rewards: -1676.83926, mean: -0.81400
[32m[0906 19-25-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03358, current rewards: -1726.83926, mean: -0.81841
[32m[0906 19-25-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03357, current rewards: -1776.83926, mean: -0.82261
[32m[0906 19-25-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03357, current rewards: -1826.83926, mean: -0.82662
[32m[0906 19-25-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03357, current rewards: -1876.83926, mean: -0.83046
[32m[0906 19-25-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03356, current rewards: -1926.83926, mean: -0.83413
[32m[0906 19-25-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03356, current rewards: -1976.83926, mean: -0.83764
[32m[0906 19-25-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03356, current rewards: -2026.83926, mean: -0.84101
[32m[0906 19-25-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03355, current rewards: -2076.83926, mean: -0.84424
[32m[0906 19-25-59 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 19-25-59 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-26-00 @MBExp.py:227][0m Rewards obtained: [-2116.839261313143], Lows: [0], Highs: [2151], Total time: 9185.960456
[32m[0906 19-29-35 @MBExp.py:144][0m ####################################################################
[32m[0906 19-29-35 @MBExp.py:145][0m Starting training iteration 107.
[32m[0906 19-29-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03313, current rewards: -7.79029, mean: -0.77903
[32m[0906 19-29-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03341, current rewards: -2.33289, mean: -0.03888
[32m[0906 19-29-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03342, current rewards: 3.12215, mean: 0.02838
[32m[0906 19-29-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03342, current rewards: 8.57116, mean: 0.05357
[32m[0906 19-29-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03336, current rewards: 14.02180, mean: 0.06677
[32m[0906 19-29-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03337, current rewards: 19.47699, mean: 0.07491
[32m[0906 19-29-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03340, current rewards: 24.93355, mean: 0.08043
[32m[0906 19-29-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03339, current rewards: 30.38406, mean: 0.08440
[32m[0906 19-29-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03337, current rewards: 35.83638, mean: 0.08741
[32m[0906 19-29-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03337, current rewards: 41.28960, mean: 0.08976
[32m[0906 19-29-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03338, current rewards: 42.48382, mean: 0.08330
[32m[0906 19-29-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03337, current rewards: 48.05185, mean: 0.08581
[32m[0906 19-29-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03336, current rewards: 53.62410, mean: 0.08791
[32m[0906 19-29-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03336, current rewards: 59.19816, mean: 0.08969
[32m[0906 19-29-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03337, current rewards: 64.77759, mean: 0.09124
[32m[0906 19-30-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03336, current rewards: 70.36182, mean: 0.09258
[32m[0906 19-30-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03338, current rewards: 70.48651, mean: 0.08702
[32m[0906 19-30-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03337, current rewards: 74.85213, mean: 0.08704
[32m[0906 19-30-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03339, current rewards: 79.21565, mean: 0.08705
[32m[0906 19-30-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03339, current rewards: 83.55361, mean: 0.08704
[32m[0906 19-30-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03341, current rewards: 87.68428, mean: 0.08682
[32m[0906 19-30-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03342, current rewards: 91.81894, mean: 0.08662
[32m[0906 19-30-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03342, current rewards: 95.95696, mean: 0.08645
[32m[0906 19-30-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03342, current rewards: 100.09358, mean: 0.08629
[32m[0906 19-30-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03343, current rewards: 104.22911, mean: 0.08614
[32m[0906 19-30-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03347, current rewards: 108.36045, mean: 0.08600
[32m[0906 19-30-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03351, current rewards: 111.91244, mean: 0.08543
[32m[0906 19-30-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03353, current rewards: 117.34286, mean: 0.08628
[32m[0906 19-30-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03356, current rewards: 122.96503, mean: 0.08721
[32m[0906 19-30-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03358, current rewards: 128.58256, mean: 0.08807
[32m[0906 19-30-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03360, current rewards: 134.19968, mean: 0.08887
[32m[0906 19-30-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03362, current rewards: 139.81731, mean: 0.08963
[32m[0906 19-30-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03359, current rewards: 145.44199, mean: 0.09034
[32m[0906 19-30-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03358, current rewards: 151.06360, mean: 0.09100
[32m[0906 19-30-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03357, current rewards: 156.67663, mean: 0.09162
[32m[0906 19-30-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03357, current rewards: 162.29805, mean: 0.09221
[32m[0906 19-30-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03356, current rewards: 166.80651, mean: 0.09216
[32m[0906 19-30-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03355, current rewards: 169.60095, mean: 0.09118
[32m[0906 19-30-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03355, current rewards: 174.36413, mean: 0.09129
[32m[0906 19-30-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03354, current rewards: 179.20273, mean: 0.09143
[32m[0906 19-30-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03353, current rewards: 184.21938, mean: 0.09165
[32m[0906 19-30-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03353, current rewards: 189.09063, mean: 0.09179
[32m[0906 19-30-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03352, current rewards: 193.91446, mean: 0.09190
[32m[0906 19-30-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03352, current rewards: 198.68779, mean: 0.09199
[32m[0906 19-30-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03352, current rewards: 203.67958, mean: 0.09216
[32m[0906 19-30-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03351, current rewards: 208.58153, mean: 0.09229
[32m[0906 19-30-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03351, current rewards: 213.57411, mean: 0.09246
[32m[0906 19-30-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03351, current rewards: 218.54380, mean: 0.09260
[32m[0906 19-30-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03351, current rewards: 223.56875, mean: 0.09277
[32m[0906 19-30-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03351, current rewards: 224.37478, mean: 0.09121
[32m[0906 19-30-59 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 19-30-59 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-31-00 @MBExp.py:227][0m Rewards obtained: [228.90342464411412], Lows: [12], Highs: [3], Total time: 9270.516868
[32m[0906 19-34-36 @MBExp.py:144][0m ####################################################################
[32m[0906 19-34-36 @MBExp.py:145][0m Starting training iteration 108.
[32m[0906 19-34-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03227, current rewards: -0.04955, mean: -0.00495
[32m[0906 19-34-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03284, current rewards: 14.63629, mean: 0.24394
[32m[0906 19-34-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03358, current rewards: 21.70297, mean: 0.19730
[32m[0906 19-34-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03371, current rewards: 4.62554, mean: 0.02891
[32m[0906 19-34-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03387, current rewards: -11.58575, mean: -0.05517
[32m[0906 19-34-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03390, current rewards: -28.72976, mean: -0.11050
[32m[0906 19-34-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03396, current rewards: -45.56407, mean: -0.14698
[32m[0906 19-34-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03397, current rewards: -62.01060, mean: -0.17225
[32m[0906 19-34-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03406, current rewards: -75.55969, mean: -0.18429
[32m[0906 19-34-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03402, current rewards: -93.33928, mean: -0.20291
[32m[0906 19-34-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03408, current rewards: -114.47402, mean: -0.22446
[32m[0906 19-34-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03436, current rewards: -147.01491, mean: -0.26253
[32m[0906 19-34-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03452, current rewards: -173.26819, mean: -0.28405
[32m[0906 19-34-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03475, current rewards: -191.13973, mean: -0.28961
[32m[0906 19-35-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03499, current rewards: -205.75761, mean: -0.28980
[32m[0906 19-35-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03525, current rewards: -229.68933, mean: -0.30222
[32m[0906 19-35-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03537, current rewards: -243.73591, mean: -0.30091
[32m[0906 19-35-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03552, current rewards: -253.61983, mean: -0.29491
[32m[0906 19-35-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03553, current rewards: -272.77711, mean: -0.29976
[32m[0906 19-35-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03541, current rewards: -317.68062, mean: -0.33092
[32m[0906 19-35-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03530, current rewards: -362.62798, mean: -0.35904
[32m[0906 19-35-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03521, current rewards: -407.56236, mean: -0.38449
[32m[0906 19-35-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03513, current rewards: -421.57071, mean: -0.37979
[32m[0906 19-35-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03505, current rewards: -415.48546, mean: -0.35818
[32m[0906 19-35-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03501, current rewards: -409.39756, mean: -0.33835
[32m[0906 19-35-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03498, current rewards: -403.30280, mean: -0.32008
[32m[0906 19-35-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03495, current rewards: -397.21827, mean: -0.30322
[32m[0906 19-35-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03492, current rewards: -391.13742, mean: -0.28760
[32m[0906 19-35-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03489, current rewards: -385.04876, mean: -0.27308
[32m[0906 19-35-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03486, current rewards: -378.95984, mean: -0.25956
[32m[0906 19-35-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03484, current rewards: -398.22241, mean: -0.26372
[32m[0906 19-35-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03479, current rewards: -392.18406, mean: -0.25140
[32m[0906 19-35-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03475, current rewards: -386.14109, mean: -0.23984
[32m[0906 19-35-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03470, current rewards: -380.09602, mean: -0.22897
[32m[0906 19-35-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03466, current rewards: -374.16529, mean: -0.21881
[32m[0906 19-35-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03463, current rewards: -368.82694, mean: -0.20956
[32m[0906 19-35-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03460, current rewards: -363.29500, mean: -0.20072
[32m[0906 19-35-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03456, current rewards: -357.73651, mean: -0.19233
[32m[0906 19-35-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03454, current rewards: -354.51964, mean: -0.18561
[32m[0906 19-35-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03451, current rewards: -347.85103, mean: -0.17748
[32m[0906 19-35-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03449, current rewards: -341.18828, mean: -0.16975
[32m[0906 19-35-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03446, current rewards: -334.53556, mean: -0.16240
[32m[0906 19-35-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03444, current rewards: -327.86198, mean: -0.15538
[32m[0906 19-35-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03441, current rewards: -321.18270, mean: -0.14870
[32m[0906 19-35-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03439, current rewards: -314.50871, mean: -0.14231
[32m[0906 19-35-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03437, current rewards: -307.86076, mean: -0.13622
[32m[0906 19-35-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03435, current rewards: -301.21509, mean: -0.13040
[32m[0906 19-35-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03432, current rewards: -294.54778, mean: -0.12481
[32m[0906 19-36-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03431, current rewards: -287.90117, mean: -0.11946
[32m[0906 19-36-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03429, current rewards: -281.25073, mean: -0.11433
[32m[0906 19-36-03 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 19-36-03 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-36-03 @MBExp.py:227][0m Rewards obtained: [-275.9278988236139], Lows: [308], Highs: [20], Total time: 9356.992258
[32m[0906 19-39-43 @MBExp.py:144][0m ####################################################################
[32m[0906 19-39-43 @MBExp.py:145][0m Starting training iteration 109.
[32m[0906 19-39-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03254, current rewards: -12.31831, mean: -1.23183
[32m[0906 19-39-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03336, current rewards: -7.16611, mean: -0.11944
[32m[0906 19-39-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03329, current rewards: -2.09724, mean: -0.01907
[32m[0906 19-39-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03337, current rewards: 3.00696, mean: 0.01879
[32m[0906 19-39-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03338, current rewards: 8.09300, mean: 0.03854
[32m[0906 19-39-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03335, current rewards: 13.18374, mean: 0.05071
[32m[0906 19-39-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03335, current rewards: 18.26182, mean: 0.05891
[32m[0906 19-39-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03335, current rewards: 23.36299, mean: 0.06490
[32m[0906 19-39-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03337, current rewards: 28.43197, mean: 0.06935
[32m[0906 19-39-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03337, current rewards: 33.53155, mean: 0.07289
[32m[0906 19-40-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03337, current rewards: 38.62346, mean: 0.07573
[32m[0906 19-40-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03336, current rewards: 43.66840, mean: 0.07798
[32m[0906 19-40-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03336, current rewards: 48.75697, mean: 0.07993
[32m[0906 19-40-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03337, current rewards: 53.80577, mean: 0.08152
[32m[0906 19-40-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03338, current rewards: 56.93443, mean: 0.08019
[32m[0906 19-40-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03337, current rewards: 61.83827, mean: 0.08137
[32m[0906 19-40-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03338, current rewards: 66.74042, mean: 0.08240
[32m[0906 19-40-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03337, current rewards: 71.64022, mean: 0.08330
[32m[0906 19-40-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03338, current rewards: 76.52950, mean: 0.08410
[32m[0906 19-40-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03338, current rewards: 81.42679, mean: 0.08482
[32m[0906 19-40-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03338, current rewards: 86.32488, mean: 0.08547
[32m[0906 19-40-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03338, current rewards: 91.22366, mean: 0.08606
[32m[0906 19-40-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03338, current rewards: 96.12313, mean: 0.08660
[32m[0906 19-40-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03338, current rewards: 101.02080, mean: 0.08709
[32m[0906 19-40-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03342, current rewards: 105.91647, mean: 0.08753
[32m[0906 19-40-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03346, current rewards: 110.81754, mean: 0.08795
[32m[0906 19-40-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03348, current rewards: 115.86075, mean: 0.08844
[32m[0906 19-40-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03351, current rewards: 120.81025, mean: 0.08883
[32m[0906 19-40-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03354, current rewards: 125.75695, mean: 0.08919
[32m[0906 19-40-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03353, current rewards: 130.70540, mean: 0.08952
[32m[0906 19-40-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03353, current rewards: 129.52178, mean: 0.08578
[32m[0906 19-40-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03353, current rewards: 134.92938, mean: 0.08649
[32m[0906 19-40-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03353, current rewards: 140.39836, mean: 0.08720
[32m[0906 19-40-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03353, current rewards: 145.79689, mean: 0.08783
[32m[0906 19-40-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03352, current rewards: 151.15175, mean: 0.08839
[32m[0906 19-40-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03352, current rewards: 156.61080, mean: 0.08898
[32m[0906 19-40-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03352, current rewards: 162.09114, mean: 0.08955
[32m[0906 19-40-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03349, current rewards: 167.54290, mean: 0.09008
[32m[0906 19-40-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03349, current rewards: 172.99408, mean: 0.09057
[32m[0906 19-40-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03348, current rewards: 178.44223, mean: 0.09104
[32m[0906 19-40-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03348, current rewards: 183.90042, mean: 0.09149
[32m[0906 19-40-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03348, current rewards: 189.38803, mean: 0.09194
[32m[0906 19-40-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03348, current rewards: 194.94030, mean: 0.09239
[32m[0906 19-40-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03348, current rewards: 200.21798, mean: 0.09269
[32m[0906 19-40-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03351, current rewards: 203.71007, mean: 0.09218
[32m[0906 19-40-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03351, current rewards: 208.41624, mean: 0.09222
[32m[0906 19-41-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03351, current rewards: 213.12125, mean: 0.09226
[32m[0906 19-41-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03350, current rewards: 217.82871, mean: 0.09230
[32m[0906 19-41-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03350, current rewards: 222.53662, mean: 0.09234
[32m[0906 19-41-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03350, current rewards: 227.07947, mean: 0.09231
[32m[0906 19-41-07 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 19-41-07 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-41-07 @MBExp.py:227][0m Rewards obtained: [231.43367401066223], Lows: [10], Highs: [4], Total time: 9441.530865
[32m[0906 19-44-49 @MBExp.py:144][0m ####################################################################
[32m[0906 19-44-49 @MBExp.py:145][0m Starting training iteration 110.
[32m[0906 19-44-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03309, current rewards: -6.38628, mean: -0.63863
[32m[0906 19-44-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03321, current rewards: -0.56714, mean: -0.00945
[32m[0906 19-44-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03322, current rewards: 5.16226, mean: 0.04693
[32m[0906 19-44-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03326, current rewards: 10.89518, mean: 0.06809
[32m[0906 19-44-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03329, current rewards: 16.63248, mean: 0.07920
[32m[0906 19-44-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03329, current rewards: 22.36440, mean: 0.08602
[32m[0906 19-44-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03331, current rewards: 26.34509, mean: 0.08498
[32m[0906 19-45-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03334, current rewards: 32.09951, mean: 0.08917
[32m[0906 19-45-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03334, current rewards: 37.85905, mean: 0.09234
[32m[0906 19-45-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03334, current rewards: 43.60689, mean: 0.09480
[32m[0906 19-45-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03338, current rewards: 49.36225, mean: 0.09679
[32m[0906 19-45-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03336, current rewards: 55.11510, mean: 0.09842
[32m[0906 19-45-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03337, current rewards: 60.85722, mean: 0.09977
[32m[0906 19-45-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03338, current rewards: 66.61669, mean: 0.10093
[32m[0906 19-45-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03340, current rewards: 68.07255, mean: 0.09588
[32m[0906 19-45-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03345, current rewards: 65.30034, mean: 0.08592
[32m[0906 19-45-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03345, current rewards: 71.25848, mean: 0.08797
[32m[0906 19-45-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03346, current rewards: 74.88221, mean: 0.08707
[32m[0906 19-45-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03347, current rewards: 78.94317, mean: 0.08675
[32m[0906 19-45-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03350, current rewards: 83.94940, mean: 0.08745
[32m[0906 19-45-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03353, current rewards: 85.53181, mean: 0.08468
[32m[0906 19-45-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03355, current rewards: 90.97186, mean: 0.08582
[32m[0906 19-45-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03356, current rewards: 90.22941, mean: 0.08129
[32m[0906 19-45-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03357, current rewards: 96.45988, mean: 0.08316
[32m[0906 19-45-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03357, current rewards: 97.10369, mean: 0.08025
[32m[0906 19-45-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03357, current rewards: 91.58384, mean: 0.07269
[32m[0906 19-45-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03356, current rewards: 97.19970, mean: 0.07420
[32m[0906 19-45-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03354, current rewards: 102.81308, mean: 0.07560
[32m[0906 19-45-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03354, current rewards: 108.42965, mean: 0.07690
[32m[0906 19-45-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03352, current rewards: 114.04796, mean: 0.07812
[32m[0906 19-45-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03353, current rewards: 119.66378, mean: 0.07925
[32m[0906 19-45-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03352, current rewards: 125.27957, mean: 0.08031
[32m[0906 19-45-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03352, current rewards: 130.89508, mean: 0.08130
[32m[0906 19-45-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03352, current rewards: 135.06470, mean: 0.08136
[32m[0906 19-45-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03352, current rewards: 140.16223, mean: 0.08197
[32m[0906 19-45-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03352, current rewards: 145.72883, mean: 0.08280
[32m[0906 19-45-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03352, current rewards: 151.29656, mean: 0.08359
[32m[0906 19-45-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03352, current rewards: 156.86686, mean: 0.08434
[32m[0906 19-45-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03351, current rewards: 162.43385, mean: 0.08504
[32m[0906 19-45-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03351, current rewards: 168.00793, mean: 0.08572
[32m[0906 19-45-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03351, current rewards: 173.57711, mean: 0.08636
[32m[0906 19-45-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03351, current rewards: 179.14296, mean: 0.08696
[32m[0906 19-46-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03351, current rewards: 184.21031, mean: 0.08730
[32m[0906 19-46-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03351, current rewards: 190.16613, mean: 0.08804
[32m[0906 19-46-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03351, current rewards: 196.12137, mean: 0.08874
[32m[0906 19-46-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03350, current rewards: 202.08571, mean: 0.08942
[32m[0906 19-46-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03350, current rewards: 208.04010, mean: 0.09006
[32m[0906 19-46-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03350, current rewards: 213.98903, mean: 0.09067
[32m[0906 19-46-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03350, current rewards: 219.94308, mean: 0.09126
[32m[0906 19-46-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03350, current rewards: 225.90270, mean: 0.09183
[32m[0906 19-46-13 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 19-46-13 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-46-13 @MBExp.py:227][0m Rewards obtained: [230.6700253952354], Lows: [70], Highs: [4], Total time: 9526.078026000001
[32m[0906 19-49-59 @MBExp.py:144][0m ####################################################################
[32m[0906 19-49-59 @MBExp.py:145][0m Starting training iteration 111.
[32m[0906 19-49-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03290, current rewards: 0.87747, mean: 0.08775
[32m[0906 19-50-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03329, current rewards: 6.36438, mean: 0.10607
[32m[0906 19-50-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03324, current rewards: 11.87840, mean: 0.10799
[32m[0906 19-50-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03330, current rewards: 17.39058, mean: 0.10869
[32m[0906 19-50-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03331, current rewards: 22.89806, mean: 0.10904
[32m[0906 19-50-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03333, current rewards: 28.40759, mean: 0.10926
[32m[0906 19-50-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03332, current rewards: 33.92128, mean: 0.10942
[32m[0906 19-50-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03331, current rewards: 39.43362, mean: 0.10954
[32m[0906 19-50-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03334, current rewards: 44.94524, mean: 0.10962
[32m[0906 19-50-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03335, current rewards: 50.71373, mean: 0.11025
[32m[0906 19-50-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03337, current rewards: 56.22206, mean: 0.11024
[32m[0906 19-50-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03335, current rewards: 61.73259, mean: 0.11024
[32m[0906 19-50-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03337, current rewards: 66.12983, mean: 0.10841
[32m[0906 19-50-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03339, current rewards: 70.24838, mean: 0.10644
[32m[0906 19-50-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03340, current rewards: 75.54150, mean: 0.10640
[32m[0906 19-50-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03341, current rewards: 80.83152, mean: 0.10636
[32m[0906 19-50-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03341, current rewards: 86.12799, mean: 0.10633
[32m[0906 19-50-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03341, current rewards: 91.28963, mean: 0.10615
[32m[0906 19-50-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03341, current rewards: 96.59096, mean: 0.10614
[32m[0906 19-50-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03342, current rewards: 101.89299, mean: 0.10614
[32m[0906 19-50-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03342, current rewards: 107.19361, mean: 0.10613
[32m[0906 19-50-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03342, current rewards: 112.48940, mean: 0.10612
[32m[0906 19-50-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03342, current rewards: 117.79141, mean: 0.10612
[32m[0906 19-50-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03341, current rewards: 121.32914, mean: 0.10459
[32m[0906 19-50-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03341, current rewards: 126.75717, mean: 0.10476
[32m[0906 19-50-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03342, current rewards: 132.25983, mean: 0.10497
[32m[0906 19-50-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03343, current rewards: 137.68616, mean: 0.10510
[32m[0906 19-50-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03343, current rewards: 143.11725, mean: 0.10523
[32m[0906 19-50-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03339, current rewards: 148.54709, mean: 0.10535
[32m[0906 19-50-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03338, current rewards: 153.97602, mean: 0.10546
[32m[0906 19-50-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03339, current rewards: 159.40823, mean: 0.10557
[32m[0906 19-50-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03338, current rewards: 163.90278, mean: 0.10507
[32m[0906 19-50-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03339, current rewards: 169.38868, mean: 0.10521
[32m[0906 19-50-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03339, current rewards: 174.87334, mean: 0.10535
[32m[0906 19-50-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03338, current rewards: 180.36105, mean: 0.10547
[32m[0906 19-50-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03338, current rewards: 185.85081, mean: 0.10560
[32m[0906 19-51-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03339, current rewards: 191.33719, mean: 0.10571
[32m[0906 19-51-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03338, current rewards: 196.82234, mean: 0.10582
[32m[0906 19-51-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03338, current rewards: 202.31302, mean: 0.10592
[32m[0906 19-51-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03338, current rewards: 207.80082, mean: 0.10602
[32m[0906 19-51-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03338, current rewards: 213.28541, mean: 0.10611
[32m[0906 19-51-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03339, current rewards: 218.84896, mean: 0.10624
[32m[0906 19-51-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03339, current rewards: 223.50943, mean: 0.10593
[32m[0906 19-51-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03339, current rewards: 229.72364, mean: 0.10635
[32m[0906 19-51-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03340, current rewards: 235.93468, mean: 0.10676
[32m[0906 19-51-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03340, current rewards: 242.13971, mean: 0.10714
[32m[0906 19-51-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03340, current rewards: 248.35156, mean: 0.10751
[32m[0906 19-51-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03340, current rewards: 254.55520, mean: 0.10786
[32m[0906 19-51-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03340, current rewards: 258.55950, mean: 0.10729
[32m[0906 19-51-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03340, current rewards: 263.70349, mean: 0.10720
[32m[0906 19-51-23 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 19-51-23 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-51-23 @MBExp.py:227][0m Rewards obtained: [267.8240981483974], Lows: [2], Highs: [4], Total time: 9610.351478
[32m[0906 19-55-10 @MBExp.py:144][0m ####################################################################
[32m[0906 19-55-10 @MBExp.py:145][0m Starting training iteration 112.
[32m[0906 19-55-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03301, current rewards: -1.21307, mean: -0.12131
[32m[0906 19-55-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03329, current rewards: 4.61714, mean: 0.07695
[32m[0906 19-55-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03318, current rewards: 10.44558, mean: 0.09496
[32m[0906 19-55-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03329, current rewards: 16.27322, mean: 0.10171
[32m[0906 19-55-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03331, current rewards: 22.09893, mean: 0.10523
[32m[0906 19-55-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03334, current rewards: 27.92871, mean: 0.10742
[32m[0906 19-55-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03334, current rewards: 33.75140, mean: 0.10888
[32m[0906 19-55-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03333, current rewards: 39.57488, mean: 0.10993
[32m[0906 19-55-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03335, current rewards: 45.53079, mean: 0.11105
[32m[0906 19-55-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03333, current rewards: 51.33080, mean: 0.11159
[32m[0906 19-55-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03334, current rewards: 57.12871, mean: 0.11202
[32m[0906 19-55-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03333, current rewards: 62.93340, mean: 0.11238
[32m[0906 19-55-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03332, current rewards: 68.73541, mean: 0.11268
[32m[0906 19-55-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03332, current rewards: 72.37379, mean: 0.10966
[32m[0906 19-55-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03333, current rewards: 77.88390, mean: 0.10970
[32m[0906 19-55-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03333, current rewards: 83.39454, mean: 0.10973
[32m[0906 19-55-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03332, current rewards: 88.87581, mean: 0.10972
[32m[0906 19-55-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03333, current rewards: 94.45100, mean: 0.10983
[32m[0906 19-55-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03334, current rewards: 100.02402, mean: 0.10992
[32m[0906 19-55-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03335, current rewards: 105.59779, mean: 0.11000
[32m[0906 19-55-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03335, current rewards: 111.17252, mean: 0.11007
[32m[0906 19-55-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03335, current rewards: 116.74688, mean: 0.11014
[32m[0906 19-55-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03334, current rewards: 122.32002, mean: 0.11020
[32m[0906 19-55-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03334, current rewards: 125.88407, mean: 0.10852
[32m[0906 19-55-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03335, current rewards: 131.60510, mean: 0.10876
[32m[0906 19-55-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03335, current rewards: 137.25110, mean: 0.10893
[32m[0906 19-55-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03334, current rewards: 142.82274, mean: 0.10902
[32m[0906 19-55-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03335, current rewards: 148.39458, mean: 0.10911
[32m[0906 19-55-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03330, current rewards: 153.96525, mean: 0.10920
[32m[0906 19-55-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03328, current rewards: 159.53583, mean: 0.10927
[32m[0906 19-56-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03329, current rewards: 165.10939, mean: 0.10934
[32m[0906 19-56-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03330, current rewards: 170.68106, mean: 0.10941
[32m[0906 19-56-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03330, current rewards: 175.87777, mean: 0.10924
[32m[0906 19-56-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03331, current rewards: 182.38256, mean: 0.10987
[32m[0906 19-56-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03332, current rewards: 188.94676, mean: 0.11050
[32m[0906 19-56-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03331, current rewards: 195.51207, mean: 0.11109
[32m[0906 19-56-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03331, current rewards: 200.10259, mean: 0.11055
[32m[0906 19-56-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03333, current rewards: 206.12831, mean: 0.11082
[32m[0906 19-56-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03333, current rewards: 212.15537, mean: 0.11108
[32m[0906 19-56-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03333, current rewards: 218.18307, mean: 0.11132
[32m[0906 19-56-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03334, current rewards: 224.20758, mean: 0.11155
[32m[0906 19-56-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03334, current rewards: 230.39255, mean: 0.11184
[32m[0906 19-56-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03334, current rewards: 235.38031, mean: 0.11155
[32m[0906 19-56-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03335, current rewards: 239.70029, mean: 0.11097
[32m[0906 19-56-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03335, current rewards: 245.13665, mean: 0.11092
[32m[0906 19-56-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03335, current rewards: 250.56009, mean: 0.11087
[32m[0906 19-56-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03335, current rewards: 255.99992, mean: 0.11082
[32m[0906 19-56-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03335, current rewards: 262.04079, mean: 0.11103
[32m[0906 19-56-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03335, current rewards: 268.59082, mean: 0.11145
[32m[0906 19-56-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03335, current rewards: 274.90302, mean: 0.11175
[32m[0906 19-56-34 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 19-56-34 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-56-34 @MBExp.py:227][0m Rewards obtained: [280.04090321690984], Lows: [2], Highs: [7], Total time: 9694.540229
[32m[0906 20-00-23 @MBExp.py:144][0m ####################################################################
[32m[0906 20-00-23 @MBExp.py:145][0m Starting training iteration 113.
[32m[0906 20-00-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03323, current rewards: -2.36025, mean: -0.23602
[32m[0906 20-00-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03291, current rewards: 3.12230, mean: 0.05204
[32m[0906 20-00-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03322, current rewards: 8.64617, mean: 0.07860
[32m[0906 20-00-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03328, current rewards: 14.16580, mean: 0.08854
[32m[0906 20-00-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03333, current rewards: 19.68975, mean: 0.09376
[32m[0906 20-00-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03338, current rewards: 25.21064, mean: 0.09696
[32m[0906 20-00-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03338, current rewards: 30.73214, mean: 0.09914
[32m[0906 20-00-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03337, current rewards: 36.25470, mean: 0.10071
[32m[0906 20-00-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03336, current rewards: 40.76804, mean: 0.09943
[32m[0906 20-00-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03336, current rewards: 46.28490, mean: 0.10062
[32m[0906 20-00-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03337, current rewards: 51.79965, mean: 0.10157
[32m[0906 20-00-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03336, current rewards: 57.31969, mean: 0.10236
[32m[0906 20-00-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03337, current rewards: 62.83005, mean: 0.10300
[32m[0906 20-00-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03336, current rewards: 68.34710, mean: 0.10356
[32m[0906 20-00-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03336, current rewards: 73.86515, mean: 0.10404
[32m[0906 20-00-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03337, current rewards: 79.38050, mean: 0.10445
[32m[0906 20-00-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03337, current rewards: 84.95855, mean: 0.10489
[32m[0906 20-00-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03338, current rewards: 90.47484, mean: 0.10520
[32m[0906 20-00-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03340, current rewards: 94.87483, mean: 0.10426
[32m[0906 20-00-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03339, current rewards: 100.50976, mean: 0.10470
[32m[0906 20-00-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03340, current rewards: 106.23938, mean: 0.10519
[32m[0906 20-00-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03341, current rewards: 111.96095, mean: 0.10562
[32m[0906 20-01-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03341, current rewards: 117.68789, mean: 0.10603
[32m[0906 20-01-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03341, current rewards: 121.72707, mean: 0.10494
[32m[0906 20-01-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03341, current rewards: 126.64692, mean: 0.10467
[32m[0906 20-01-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03341, current rewards: 132.04078, mean: 0.10479
[32m[0906 20-01-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03342, current rewards: 137.43697, mean: 0.10491
[32m[0906 20-01-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03341, current rewards: 142.82848, mean: 0.10502
[32m[0906 20-01-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03337, current rewards: 148.22146, mean: 0.10512
[32m[0906 20-01-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03335, current rewards: 152.54031, mean: 0.10448
[32m[0906 20-01-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03335, current rewards: 158.11114, mean: 0.10471
[32m[0906 20-01-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03335, current rewards: 163.69010, mean: 0.10493
[32m[0906 20-01-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03335, current rewards: 169.27771, mean: 0.10514
[32m[0906 20-01-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03335, current rewards: 174.85522, mean: 0.10533
[32m[0906 20-01-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03336, current rewards: 180.42689, mean: 0.10551
[32m[0906 20-01-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03336, current rewards: 185.99829, mean: 0.10568
[32m[0906 20-01-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03336, current rewards: 190.44423, mean: 0.10522
[32m[0906 20-01-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03336, current rewards: 196.52229, mean: 0.10566
[32m[0906 20-01-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03336, current rewards: 202.60376, mean: 0.10608
[32m[0906 20-01-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03336, current rewards: 208.68796, mean: 0.10647
[32m[0906 20-01-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03336, current rewards: 214.76737, mean: 0.10685
[32m[0906 20-01-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03337, current rewards: 220.84329, mean: 0.10721
[32m[0906 20-01-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03337, current rewards: 226.92090, mean: 0.10755
[32m[0906 20-01-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03338, current rewards: 233.01066, mean: 0.10788
[32m[0906 20-01-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03338, current rewards: 239.08135, mean: 0.10818
[32m[0906 20-01-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03338, current rewards: 245.15928, mean: 0.10848
[32m[0906 20-01-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03338, current rewards: 251.25087, mean: 0.10877
[32m[0906 20-01-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03338, current rewards: 257.33654, mean: 0.10904
[32m[0906 20-01-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03338, current rewards: 263.39174, mean: 0.10929
[32m[0906 20-01-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03339, current rewards: 269.50325, mean: 0.10955
[32m[0906 20-01-47 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 20-01-47 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-01-47 @MBExp.py:227][0m Rewards obtained: [274.3843435173823], Lows: [1], Highs: [7], Total time: 9778.829941
[32m[0906 20-05-38 @MBExp.py:144][0m ####################################################################
[32m[0906 20-05-38 @MBExp.py:145][0m Starting training iteration 114.
[32m[0906 20-05-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03281, current rewards: -0.05437, mean: -0.00544
[32m[0906 20-05-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03334, current rewards: 5.55146, mean: 0.09252
[32m[0906 20-05-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03324, current rewards: 11.15630, mean: 0.10142
[32m[0906 20-05-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03331, current rewards: 16.76267, mean: 0.10477
[32m[0906 20-05-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03326, current rewards: 22.36718, mean: 0.10651
[32m[0906 20-05-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03327, current rewards: 27.96979, mean: 0.10758
[32m[0906 20-05-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03328, current rewards: 33.59654, mean: 0.10838
[32m[0906 20-05-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03332, current rewards: 38.18791, mean: 0.10608
[32m[0906 20-05-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03329, current rewards: 43.84426, mean: 0.10694
[32m[0906 20-05-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03329, current rewards: 49.50122, mean: 0.10761
[32m[0906 20-05-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03330, current rewards: 55.15678, mean: 0.10815
[32m[0906 20-05-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03331, current rewards: 60.81181, mean: 0.10859
[32m[0906 20-05-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03331, current rewards: 66.10804, mean: 0.10837
[32m[0906 20-06-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03332, current rewards: 72.04212, mean: 0.10915
[32m[0906 20-06-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03332, current rewards: 77.97465, mean: 0.10982
[32m[0906 20-06-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03332, current rewards: 83.66097, mean: 0.11008
[32m[0906 20-06-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03333, current rewards: 89.21758, mean: 0.11015
[32m[0906 20-06-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03333, current rewards: 94.78535, mean: 0.11022
[32m[0906 20-06-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03334, current rewards: 96.20586, mean: 0.10572
[32m[0906 20-06-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03334, current rewards: 103.48020, mean: 0.10779
[32m[0906 20-06-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03334, current rewards: 110.75441, mean: 0.10966
[32m[0906 20-06-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03335, current rewards: 118.02863, mean: 0.11135
[32m[0906 20-06-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03336, current rewards: 125.30284, mean: 0.11289
[32m[0906 20-06-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03335, current rewards: 130.59238, mean: 0.11258
[32m[0906 20-06-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03335, current rewards: 136.33566, mean: 0.11267
[32m[0906 20-06-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03336, current rewards: 142.07931, mean: 0.11276
[32m[0906 20-06-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03336, current rewards: 147.82403, mean: 0.11284
[32m[0906 20-06-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03336, current rewards: 153.56815, mean: 0.11292
[32m[0906 20-06-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03331, current rewards: 155.09486, mean: 0.11000
[32m[0906 20-06-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03329, current rewards: 160.33205, mean: 0.10982
[32m[0906 20-06-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03328, current rewards: 165.56374, mean: 0.10964
[32m[0906 20-06-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03329, current rewards: 170.92115, mean: 0.10956
[32m[0906 20-06-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03330, current rewards: 176.21451, mean: 0.10945
[32m[0906 20-06-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03330, current rewards: 181.49153, mean: 0.10933
[32m[0906 20-06-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03330, current rewards: 186.76930, mean: 0.10922
[32m[0906 20-06-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03331, current rewards: 189.98239, mean: 0.10794
[32m[0906 20-06-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03331, current rewards: 195.66375, mean: 0.10810
[32m[0906 20-06-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03331, current rewards: 201.34052, mean: 0.10825
[32m[0906 20-06-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03332, current rewards: 207.02184, mean: 0.10839
[32m[0906 20-06-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03332, current rewards: 212.52987, mean: 0.10843
[32m[0906 20-06-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03332, current rewards: 218.28633, mean: 0.10860
[32m[0906 20-06-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03333, current rewards: 224.04497, mean: 0.10876
[32m[0906 20-06-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03333, current rewards: 229.79641, mean: 0.10891
[32m[0906 20-06-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03334, current rewards: 233.27369, mean: 0.10800
[32m[0906 20-06-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03334, current rewards: 238.89554, mean: 0.10810
[32m[0906 20-06-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03334, current rewards: 244.52412, mean: 0.10820
[32m[0906 20-06-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03335, current rewards: 250.14490, mean: 0.10829
[32m[0906 20-06-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03335, current rewards: 255.72744, mean: 0.10836
[32m[0906 20-06-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03335, current rewards: 261.08902, mean: 0.10834
[32m[0906 20-07-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03335, current rewards: 266.53150, mean: 0.10835
[32m[0906 20-07-02 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 20-07-02 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-07-02 @MBExp.py:227][0m Rewards obtained: [270.882728156433], Lows: [5], Highs: [5], Total time: 9863.016957
[32m[0906 20-10-54 @MBExp.py:144][0m ####################################################################
[32m[0906 20-10-54 @MBExp.py:145][0m Starting training iteration 115.
[32m[0906 20-10-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03314, current rewards: -3.19400, mean: -0.31940
[32m[0906 20-10-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03320, current rewards: 2.17781, mean: 0.03630
[32m[0906 20-10-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03319, current rewards: 7.54775, mean: 0.06862
[32m[0906 20-11-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03326, current rewards: 12.91030, mean: 0.08069
[32m[0906 20-11-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03326, current rewards: 18.27471, mean: 0.08702
[32m[0906 20-11-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03335, current rewards: 23.63824, mean: 0.09092
[32m[0906 20-11-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03332, current rewards: 29.07734, mean: 0.09380
[32m[0906 20-11-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03332, current rewards: 32.53465, mean: 0.09037
[32m[0906 20-11-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03331, current rewards: 38.11725, mean: 0.09297
[32m[0906 20-11-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03329, current rewards: 43.69900, mean: 0.09500
[32m[0906 20-11-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03330, current rewards: 49.28055, mean: 0.09663
[32m[0906 20-11-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03330, current rewards: 54.86108, mean: 0.09797
[32m[0906 20-11-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03328, current rewards: 58.33454, mean: 0.09563
[32m[0906 20-11-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03330, current rewards: 63.95183, mean: 0.09690
[32m[0906 20-11-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03331, current rewards: 69.52590, mean: 0.09792
[32m[0906 20-11-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03331, current rewards: 75.11012, mean: 0.09883
[32m[0906 20-11-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03331, current rewards: 80.69248, mean: 0.09962
[32m[0906 20-11-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03331, current rewards: 84.00063, mean: 0.09768
[32m[0906 20-11-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03333, current rewards: 89.60395, mean: 0.09847
[32m[0906 20-11-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03333, current rewards: 95.20366, mean: 0.09917
[32m[0906 20-11-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03333, current rewards: 100.80559, mean: 0.09981
[32m[0906 20-11-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03334, current rewards: 106.40699, mean: 0.10038
[32m[0906 20-11-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03334, current rewards: 111.87250, mean: 0.10079
[32m[0906 20-11-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03335, current rewards: 117.46792, mean: 0.10127
[32m[0906 20-11-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03335, current rewards: 120.97595, mean: 0.09998
[32m[0906 20-11-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03335, current rewards: 126.63609, mean: 0.10050
[32m[0906 20-11-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03335, current rewards: 132.29031, mean: 0.10098
[32m[0906 20-11-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03332, current rewards: 137.94397, mean: 0.10143
[32m[0906 20-11-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03329, current rewards: 143.60431, mean: 0.10185
[32m[0906 20-11-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03326, current rewards: 149.25833, mean: 0.10223
[32m[0906 20-11-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03326, current rewards: 154.89454, mean: 0.10258
[32m[0906 20-11-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03326, current rewards: 160.56091, mean: 0.10292
[32m[0906 20-11-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03326, current rewards: 166.22386, mean: 0.10324
[32m[0906 20-11-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03327, current rewards: 171.89043, mean: 0.10355
[32m[0906 20-11-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03327, current rewards: 172.31259, mean: 0.10077
[32m[0906 20-11-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03328, current rewards: 178.04065, mean: 0.10116
[32m[0906 20-11-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03327, current rewards: 183.76711, mean: 0.10153
[32m[0906 20-11-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03328, current rewards: 189.49444, mean: 0.10188
[32m[0906 20-11-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03328, current rewards: 195.19715, mean: 0.10220
[32m[0906 20-12-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03328, current rewards: 200.90197, mean: 0.10250
[32m[0906 20-12-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03329, current rewards: 206.60926, mean: 0.10279
[32m[0906 20-12-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03329, current rewards: 212.32088, mean: 0.10307
[32m[0906 20-12-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03330, current rewards: 218.03160, mean: 0.10333
[32m[0906 20-12-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03330, current rewards: 223.74316, mean: 0.10358
[32m[0906 20-12-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03331, current rewards: 225.12951, mean: 0.10187
[32m[0906 20-12-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03331, current rewards: 230.72851, mean: 0.10209
[32m[0906 20-12-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03330, current rewards: 236.40777, mean: 0.10234
[32m[0906 20-12-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03331, current rewards: 242.11283, mean: 0.10259
[32m[0906 20-12-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03331, current rewards: 247.69790, mean: 0.10278
[32m[0906 20-12-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03332, current rewards: 253.28623, mean: 0.10296
[32m[0906 20-12-18 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 20-12-18 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-12-18 @MBExp.py:227][0m Rewards obtained: [257.7526997050442], Lows: [8], Highs: [5], Total time: 9947.104716
[32m[0906 20-16-13 @MBExp.py:144][0m ####################################################################
[32m[0906 20-16-13 @MBExp.py:145][0m Starting training iteration 116.
[32m[0906 20-16-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03271, current rewards: -4.01324, mean: -0.40132
[32m[0906 20-16-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03311, current rewards: 1.91389, mean: 0.03190
[32m[0906 20-16-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03317, current rewards: 7.74077, mean: 0.07037
[32m[0906 20-16-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03321, current rewards: 13.56161, mean: 0.08476
[32m[0906 20-16-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03327, current rewards: 19.38959, mean: 0.09233
[32m[0906 20-16-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03331, current rewards: 24.98533, mean: 0.09610
[32m[0906 20-16-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03333, current rewards: 30.00167, mean: 0.09678
[32m[0906 20-16-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03334, current rewards: 35.06916, mean: 0.09741
[32m[0906 20-16-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03331, current rewards: 40.13990, mean: 0.09790
[32m[0906 20-16-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03332, current rewards: 45.20945, mean: 0.09828
[32m[0906 20-16-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03333, current rewards: 50.27736, mean: 0.09858
[32m[0906 20-16-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03333, current rewards: 53.59600, mean: 0.09571
[32m[0906 20-16-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03332, current rewards: 59.10255, mean: 0.09689
[32m[0906 20-16-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03334, current rewards: 64.60738, mean: 0.09789
[32m[0906 20-16-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03334, current rewards: 70.19033, mean: 0.09886
[32m[0906 20-16-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03336, current rewards: 75.70612, mean: 0.09961
[32m[0906 20-16-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03337, current rewards: 81.21858, mean: 0.10027
[32m[0906 20-16-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03338, current rewards: 86.73323, mean: 0.10085
[32m[0906 20-16-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03338, current rewards: 92.24722, mean: 0.10137
[32m[0906 20-16-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03339, current rewards: 97.76018, mean: 0.10183
[32m[0906 20-16-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03340, current rewards: 103.27100, mean: 0.10225
[32m[0906 20-16-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03341, current rewards: 108.78279, mean: 0.10263
[32m[0906 20-16-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03340, current rewards: 114.37010, mean: 0.10304
[32m[0906 20-16-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03341, current rewards: 119.88713, mean: 0.10335
[32m[0906 20-16-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03342, current rewards: 125.40589, mean: 0.10364
[32m[0906 20-16-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03342, current rewards: 130.92164, mean: 0.10391
[32m[0906 20-16-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03342, current rewards: 134.35862, mean: 0.10256
[32m[0906 20-16-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03337, current rewards: 139.86335, mean: 0.10284
[32m[0906 20-17-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03333, current rewards: 145.36833, mean: 0.10310
[32m[0906 20-17-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03331, current rewards: 150.87160, mean: 0.10334
[32m[0906 20-17-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03329, current rewards: 156.53629, mean: 0.10367
[32m[0906 20-17-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03329, current rewards: 162.06684, mean: 0.10389
[32m[0906 20-17-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03329, current rewards: 165.29257, mean: 0.10267
[32m[0906 20-17-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03330, current rewards: 170.82765, mean: 0.10291
[32m[0906 20-17-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03331, current rewards: 176.35627, mean: 0.10313
[32m[0906 20-17-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03331, current rewards: 181.89172, mean: 0.10335
[32m[0906 20-17-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03330, current rewards: 187.42609, mean: 0.10355
[32m[0906 20-17-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03330, current rewards: 192.95819, mean: 0.10374
[32m[0906 20-17-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03330, current rewards: 198.33497, mean: 0.10384
[32m[0906 20-17-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03330, current rewards: 203.78390, mean: 0.10397
[32m[0906 20-17-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03330, current rewards: 209.31621, mean: 0.10414
[32m[0906 20-17-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03331, current rewards: 214.84222, mean: 0.10429
[32m[0906 20-17-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03330, current rewards: 220.36981, mean: 0.10444
[32m[0906 20-17-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03331, current rewards: 225.89882, mean: 0.10458
[32m[0906 20-17-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03332, current rewards: 231.42536, mean: 0.10472
[32m[0906 20-17-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03331, current rewards: 236.95242, mean: 0.10485
[32m[0906 20-17-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03332, current rewards: 242.48013, mean: 0.10497
[32m[0906 20-17-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03332, current rewards: 245.67772, mean: 0.10410
[32m[0906 20-17-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03332, current rewards: 251.26193, mean: 0.10426
[32m[0906 20-17-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03332, current rewards: 256.84881, mean: 0.10441
[32m[0906 20-17-37 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 20-17-37 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-17-37 @MBExp.py:227][0m Rewards obtained: [261.3165242391228], Lows: [5], Highs: [4], Total time: 10031.201273
[32m[0906 20-21-34 @MBExp.py:144][0m ####################################################################
[32m[0906 20-21-34 @MBExp.py:145][0m Starting training iteration 117.
[32m[0906 20-21-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03273, current rewards: -8.59429, mean: -0.85943
[32m[0906 20-21-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03325, current rewards: -3.11574, mean: -0.05193
[32m[0906 20-21-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03313, current rewards: 2.36620, mean: 0.02151
[32m[0906 20-21-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03324, current rewards: 7.84898, mean: 0.04906
[32m[0906 20-21-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03326, current rewards: 13.32596, mean: 0.06346
[32m[0906 20-21-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03324, current rewards: 18.98330, mean: 0.07301
[32m[0906 20-21-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03327, current rewards: 24.49140, mean: 0.07900
[32m[0906 20-21-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03322, current rewards: 25.88068, mean: 0.07189
[32m[0906 20-21-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03322, current rewards: 31.48161, mean: 0.07678
[32m[0906 20-21-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03323, current rewards: 37.08505, mean: 0.08062
[32m[0906 20-21-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03323, current rewards: 42.68855, mean: 0.08370
[32m[0906 20-21-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03324, current rewards: 48.29572, mean: 0.08624
[32m[0906 20-21-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03323, current rewards: 52.78427, mean: 0.08653
[32m[0906 20-21-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03322, current rewards: 58.33848, mean: 0.08839
[32m[0906 20-21-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03325, current rewards: 63.94586, mean: 0.09006
[32m[0906 20-21-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03326, current rewards: 69.54854, mean: 0.09151
[32m[0906 20-22-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03327, current rewards: 75.15229, mean: 0.09278
[32m[0906 20-22-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03328, current rewards: 80.75605, mean: 0.09390
[32m[0906 20-22-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03328, current rewards: 86.35944, mean: 0.09490
[32m[0906 20-22-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03329, current rewards: 91.96938, mean: 0.09580
[32m[0906 20-22-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03329, current rewards: 97.57689, mean: 0.09661
[32m[0906 20-22-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03330, current rewards: 103.24191, mean: 0.09740
[32m[0906 20-22-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03330, current rewards: 108.89637, mean: 0.09810
[32m[0906 20-22-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03329, current rewards: 113.38343, mean: 0.09774
[32m[0906 20-22-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03330, current rewards: 118.96697, mean: 0.09832
[32m[0906 20-22-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03330, current rewards: 124.55045, mean: 0.09885
[32m[0906 20-22-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03328, current rewards: 130.13333, mean: 0.09934
[32m[0906 20-22-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03325, current rewards: 135.71797, mean: 0.09979
[32m[0906 20-22-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03323, current rewards: 141.29527, mean: 0.10021
[32m[0906 20-22-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03320, current rewards: 146.88025, mean: 0.10060
[32m[0906 20-22-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03317, current rewards: 152.46991, mean: 0.10097
[32m[0906 20-22-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03315, current rewards: 157.89547, mean: 0.10122
[32m[0906 20-22-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03316, current rewards: 163.38354, mean: 0.10148
[32m[0906 20-22-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03317, current rewards: 168.87599, mean: 0.10173
[32m[0906 20-22-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03318, current rewards: 174.35967, mean: 0.10196
[32m[0906 20-22-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03318, current rewards: 178.74040, mean: 0.10156
[32m[0906 20-22-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03318, current rewards: 184.64058, mean: 0.10201
[32m[0906 20-22-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03320, current rewards: 190.54488, mean: 0.10244
[32m[0906 20-22-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03320, current rewards: 196.48772, mean: 0.10287
[32m[0906 20-22-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03321, current rewards: 202.38818, mean: 0.10326
[32m[0906 20-22-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03322, current rewards: 208.28422, mean: 0.10362
[32m[0906 20-22-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03321, current rewards: 210.09168, mean: 0.10199
[32m[0906 20-22-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03321, current rewards: 216.69992, mean: 0.10270
[32m[0906 20-22-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03321, current rewards: 223.30816, mean: 0.10338
[32m[0906 20-22-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03322, current rewards: 229.91639, mean: 0.10403
[32m[0906 20-22-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03323, current rewards: 236.52463, mean: 0.10466
[32m[0906 20-22-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03324, current rewards: 219.25671, mean: 0.09492
[32m[0906 20-22-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03324, current rewards: 169.25671, mean: 0.07172
[32m[0906 20-22-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03324, current rewards: 119.25671, mean: 0.04948
[32m[0906 20-22-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03325, current rewards: 69.25671, mean: 0.02815
[32m[0906 20-22-57 @Agent.py:117][0m Average action selection time: 0.0332
[32m[0906 20-22-57 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-22-57 @MBExp.py:227][0m Rewards obtained: [29.256709505656232], Lows: [7], Highs: [216], Total time: 10115.125751000001
[32m[0906 20-26-56 @MBExp.py:144][0m ####################################################################
[32m[0906 20-26-56 @MBExp.py:145][0m Starting training iteration 118.
[32m[0906 20-26-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03239, current rewards: -0.90174, mean: -0.09017
[32m[0906 20-26-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03329, current rewards: 4.70400, mean: 0.07840
[32m[0906 20-27-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03334, current rewards: 10.25354, mean: 0.09321
[32m[0906 20-27-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03329, current rewards: 15.80625, mean: 0.09879
[32m[0906 20-27-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03336, current rewards: 21.35978, mean: 0.10171
[32m[0906 20-27-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03342, current rewards: 26.96683, mean: 0.10372
[32m[0906 20-27-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03343, current rewards: 32.52373, mean: 0.10492
[32m[0906 20-27-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03341, current rewards: 36.24797, mean: 0.10069
[32m[0906 20-27-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03343, current rewards: 41.81100, mean: 0.10198
[32m[0906 20-27-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03343, current rewards: 47.37410, mean: 0.10299
[32m[0906 20-27-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03344, current rewards: 52.93719, mean: 0.10380
[32m[0906 20-27-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03343, current rewards: 58.50004, mean: 0.10446
[32m[0906 20-27-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03344, current rewards: 64.06325, mean: 0.10502
[32m[0906 20-27-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03345, current rewards: 69.62634, mean: 0.10549
[32m[0906 20-27-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03345, current rewards: 75.18932, mean: 0.10590
[32m[0906 20-27-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03343, current rewards: 80.75216, mean: 0.10625
[32m[0906 20-27-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03343, current rewards: 82.09129, mean: 0.10135
[32m[0906 20-27-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03343, current rewards: 86.56787, mean: 0.10066
[32m[0906 20-27-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03344, current rewards: 91.04159, mean: 0.10005
[32m[0906 20-27-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03344, current rewards: 95.51742, mean: 0.09950
[32m[0906 20-27-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03345, current rewards: 99.98782, mean: 0.09900
[32m[0906 20-27-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03345, current rewards: 104.41731, mean: 0.09851
[32m[0906 20-27-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03346, current rewards: 108.85680, mean: 0.09807
[32m[0906 20-27-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03346, current rewards: 113.30176, mean: 0.09767
[32m[0906 20-27-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03348, current rewards: 116.33091, mean: 0.09614
[32m[0906 20-27-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03348, current rewards: 121.35095, mean: 0.09631
[32m[0906 20-27-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03343, current rewards: 126.36471, mean: 0.09646
[32m[0906 20-27-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03340, current rewards: 131.38181, mean: 0.09660
[32m[0906 20-27-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03336, current rewards: 136.40008, mean: 0.09674
[32m[0906 20-27-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03333, current rewards: 141.23938, mean: 0.09674
[32m[0906 20-27-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03330, current rewards: 144.25491, mean: 0.09553
[32m[0906 20-27-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03327, current rewards: 149.58491, mean: 0.09589
[32m[0906 20-27-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03325, current rewards: 154.91314, mean: 0.09622
[32m[0906 20-27-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03326, current rewards: 160.23739, mean: 0.09653
[32m[0906 20-27-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03327, current rewards: 165.56773, mean: 0.09682
[32m[0906 20-27-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03327, current rewards: 170.89566, mean: 0.09710
[32m[0906 20-27-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03327, current rewards: 176.22681, mean: 0.09736
[32m[0906 20-27-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03328, current rewards: 181.53338, mean: 0.09760
[32m[0906 20-28-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03328, current rewards: 186.84769, mean: 0.09783
[32m[0906 20-28-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03329, current rewards: 192.16773, mean: 0.09804
[32m[0906 20-28-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03329, current rewards: 197.48000, mean: 0.09825
[32m[0906 20-28-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03329, current rewards: 202.79430, mean: 0.09844
[32m[0906 20-28-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03329, current rewards: 208.11203, mean: 0.09863
[32m[0906 20-28-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03329, current rewards: 213.42473, mean: 0.09881
[32m[0906 20-28-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03329, current rewards: 218.73515, mean: 0.09898
[32m[0906 20-28-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03330, current rewards: 224.19189, mean: 0.09920
[32m[0906 20-28-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03330, current rewards: 229.80115, mean: 0.09948
[32m[0906 20-28-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03330, current rewards: 235.18124, mean: 0.09965
[32m[0906 20-28-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03330, current rewards: 240.67966, mean: 0.09987
[32m[0906 20-28-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03331, current rewards: 246.18415, mean: 0.10007
[32m[0906 20-28-20 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 20-28-20 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-28-20 @MBExp.py:227][0m Rewards obtained: [250.58409941038866], Lows: [3], Highs: [5], Total time: 10199.195244000002
[32m[0906 20-32-21 @MBExp.py:144][0m ####################################################################
[32m[0906 20-32-21 @MBExp.py:145][0m Starting training iteration 119.
[32m[0906 20-32-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03204, current rewards: 1.03806, mean: 0.10381
[32m[0906 20-32-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03297, current rewards: 6.69496, mean: 0.11158
[32m[0906 20-32-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03304, current rewards: 12.27715, mean: 0.11161
[32m[0906 20-32-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03309, current rewards: 17.86000, mean: 0.11162
[32m[0906 20-32-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03316, current rewards: 23.41828, mean: 0.11152
[32m[0906 20-32-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03323, current rewards: 29.00107, mean: 0.11154
[32m[0906 20-32-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03324, current rewards: 34.58463, mean: 0.11156
[32m[0906 20-32-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03324, current rewards: 40.16875, mean: 0.11158
[32m[0906 20-32-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03327, current rewards: 45.75360, mean: 0.11159
[32m[0906 20-32-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03328, current rewards: 51.33686, mean: 0.11160
[32m[0906 20-32-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03329, current rewards: 56.92180, mean: 0.11161
[32m[0906 20-32-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03330, current rewards: 57.02860, mean: 0.10184
[32m[0906 20-32-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03329, current rewards: 61.30516, mean: 0.10050
[32m[0906 20-32-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03328, current rewards: 65.91637, mean: 0.09987
[32m[0906 20-32-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03328, current rewards: 70.58440, mean: 0.09941
[32m[0906 20-32-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03327, current rewards: 75.24117, mean: 0.09900
[32m[0906 20-32-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03327, current rewards: 79.92754, mean: 0.09868
[32m[0906 20-32-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03327, current rewards: 84.59996, mean: 0.09837
[32m[0906 20-32-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03328, current rewards: 87.54686, mean: 0.09621
[32m[0906 20-32-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03328, current rewards: 93.05365, mean: 0.09693
[32m[0906 20-32-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03329, current rewards: 98.54960, mean: 0.09757
[32m[0906 20-32-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03329, current rewards: 104.22452, mean: 0.09833
[32m[0906 20-32-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03329, current rewards: 109.39866, mean: 0.09856
[32m[0906 20-33-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03330, current rewards: 114.57309, mean: 0.09877
[32m[0906 20-33-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03330, current rewards: 119.74620, mean: 0.09896
[32m[0906 20-33-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03330, current rewards: 124.92141, mean: 0.09914
[32m[0906 20-33-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03326, current rewards: 130.09316, mean: 0.09931
[32m[0906 20-33-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03323, current rewards: 135.26800, mean: 0.09946
[32m[0906 20-33-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03321, current rewards: 140.44247, mean: 0.09960
[32m[0906 20-33-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03320, current rewards: 143.75138, mean: 0.09846
[32m[0906 20-33-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03318, current rewards: 148.99495, mean: 0.09867
[32m[0906 20-33-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03319, current rewards: 154.23185, mean: 0.09887
[32m[0906 20-33-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03324, current rewards: 159.22225, mean: 0.09890
[32m[0906 20-33-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03328, current rewards: 164.30409, mean: 0.09898
[32m[0906 20-33-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03330, current rewards: 169.68637, mean: 0.09923
[32m[0906 20-33-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03333, current rewards: 174.79533, mean: 0.09932
[32m[0906 20-33-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03338, current rewards: 179.72814, mean: 0.09930
[32m[0906 20-33-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03341, current rewards: 185.49418, mean: 0.09973
[32m[0906 20-33-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03340, current rewards: 190.88464, mean: 0.09994
[32m[0906 20-33-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03341, current rewards: 196.45086, mean: 0.10023
[32m[0906 20-33-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03340, current rewards: 202.01762, mean: 0.10051
[32m[0906 20-33-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03340, current rewards: 207.58542, mean: 0.10077
[32m[0906 20-33-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03340, current rewards: 213.14842, mean: 0.10102
[32m[0906 20-33-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03339, current rewards: 218.71771, mean: 0.10126
[32m[0906 20-33-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03339, current rewards: 224.28298, mean: 0.10149
[32m[0906 20-33-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03338, current rewards: 229.84965, mean: 0.10170
[32m[0906 20-33-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03338, current rewards: 235.41952, mean: 0.10191
[32m[0906 20-33-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03338, current rewards: 240.97741, mean: 0.10211
[32m[0906 20-33-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03339, current rewards: 246.53997, mean: 0.10230
[32m[0906 20-33-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03339, current rewards: 252.10392, mean: 0.10248
[32m[0906 20-33-45 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 20-33-45 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-33-46 @MBExp.py:227][0m Rewards obtained: [256.5582878651859], Lows: [2], Highs: [4], Total time: 10283.457597000002
[32m[0906 20-37-33 @MBExp.py:144][0m ####################################################################
[32m[0906 20-37-33 @MBExp.py:145][0m Starting training iteration 120.
[32m[0906 20-37-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02631, current rewards: -2.17272, mean: -0.21727
[32m[0906 20-37-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02673, current rewards: 3.72247, mean: 0.06204
[32m[0906 20-37-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02682, current rewards: 9.61715, mean: 0.08743
[32m[0906 20-37-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02673, current rewards: 15.51487, mean: 0.09697
[32m[0906 20-37-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02678, current rewards: 21.39631, mean: 0.10189
[32m[0906 20-37-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02681, current rewards: 27.56611, mean: 0.10602
[32m[0906 20-37-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02684, current rewards: 33.73721, mean: 0.10883
[32m[0906 20-37-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02688, current rewards: 39.90202, mean: 0.11084
[32m[0906 20-37-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02689, current rewards: 46.06968, mean: 0.11237
[32m[0906 20-37-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02691, current rewards: 52.23770, mean: 0.11356
[32m[0906 20-37-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02692, current rewards: 58.41185, mean: 0.11453
[32m[0906 20-37-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02693, current rewards: 64.57860, mean: 0.11532
[32m[0906 20-37-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02693, current rewards: 70.88934, mean: 0.11621
[32m[0906 20-37-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02694, current rewards: 76.94522, mean: 0.11658
[32m[0906 20-37-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02697, current rewards: 81.81481, mean: 0.11523
[32m[0906 20-37-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02697, current rewards: 88.08254, mean: 0.11590
[32m[0906 20-37-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02698, current rewards: 94.47593, mean: 0.11664
[32m[0906 20-37-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02699, current rewards: 100.87462, mean: 0.11730
[32m[0906 20-37-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02700, current rewards: 107.27347, mean: 0.11788
[32m[0906 20-37-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02701, current rewards: 113.70397, mean: 0.11844
[32m[0906 20-38-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02701, current rewards: 120.09163, mean: 0.11890
[32m[0906 20-38-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02701, current rewards: 126.38105, mean: 0.11923
[32m[0906 20-38-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02701, current rewards: 132.78718, mean: 0.11963
[32m[0906 20-38-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02701, current rewards: 139.20091, mean: 0.12000
[32m[0906 20-38-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02701, current rewards: 145.60269, mean: 0.12033
[32m[0906 20-38-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02699, current rewards: 151.44800, mean: 0.12020
[32m[0906 20-38-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02685, current rewards: 157.31683, mean: 0.12009
[32m[0906 20-38-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02671, current rewards: 163.18759, mean: 0.11999
[32m[0906 20-38-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02658, current rewards: 169.05349, mean: 0.11990
[32m[0906 20-38-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02646, current rewards: 174.91542, mean: 0.11981
[32m[0906 20-38-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02634, current rewards: 180.86123, mean: 0.11978
[32m[0906 20-38-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02623, current rewards: 186.81193, mean: 0.11975
[32m[0906 20-38-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02613, current rewards: 192.75788, mean: 0.11973
[32m[0906 20-38-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02608, current rewards: 198.71128, mean: 0.11971
[32m[0906 20-38-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02603, current rewards: 204.65919, mean: 0.11968
[32m[0906 20-38-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02599, current rewards: 210.60632, mean: 0.11966
[32m[0906 20-38-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02594, current rewards: 216.55111, mean: 0.11964
[32m[0906 20-38-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02590, current rewards: 220.69195, mean: 0.11865
[32m[0906 20-38-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02586, current rewards: 226.58204, mean: 0.11863
[32m[0906 20-38-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02582, current rewards: 232.47100, mean: 0.11861
[32m[0906 20-38-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02578, current rewards: 238.35922, mean: 0.11859
[32m[0906 20-38-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02575, current rewards: 244.24586, mean: 0.11857
[32m[0906 20-38-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02572, current rewards: 250.13465, mean: 0.11855
[32m[0906 20-38-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02569, current rewards: 256.02423, mean: 0.11853
[32m[0906 20-38-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02566, current rewards: 261.91857, mean: 0.11852
[32m[0906 20-38-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02563, current rewards: 265.82734, mean: 0.11762
[32m[0906 20-38-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02560, current rewards: 273.04463, mean: 0.11820
[32m[0906 20-38-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02557, current rewards: 279.80867, mean: 0.11856
[32m[0906 20-38-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02555, current rewards: 286.57271, mean: 0.11891
[32m[0906 20-38-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02553, current rewards: 293.33675, mean: 0.11924
[32m[0906 20-38-37 @Agent.py:117][0m Average action selection time: 0.0255
[32m[0906 20-38-37 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-38-37 @MBExp.py:227][0m Rewards obtained: [298.7479755724488], Lows: [2], Highs: [4], Total time: 10347.921194000002
