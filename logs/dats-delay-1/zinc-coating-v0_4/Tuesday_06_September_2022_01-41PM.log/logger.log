[32m[0906 13-41-22 @logger.py:99][0m Log file set to /app/logs/dats-delay-1/zinc-coating-v0_4/Tuesday_06_September_2022_01-41PM.log
[32m[0906 13-41-22 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00003, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -64.27791, mean: -1.07130
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -116.53652, mean: -1.05942
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -165.58134, mean: -1.03488
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -216.62153, mean: -1.03153
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -269.32676, mean: -1.03587
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -313.80092, mean: -1.01226
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -358.48933, mean: -0.99580
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -411.08741, mean: -1.00265
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -460.74655, mean: -1.00162
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -505.94468, mean: -0.99205
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -557.15837, mean: -0.99493
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -608.60728, mean: -0.99772
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -661.13531, mean: -1.00172
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -716.35112, mean: -1.00895
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -780.19334, mean: -1.02657
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -839.91373, mean: -1.03693
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -902.24842, mean: -1.04913
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -949.13267, mean: -1.04300
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -1004.40101, mean: -1.04625
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1056.29527, mean: -1.04584
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1108.61716, mean: -1.04587
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1158.62748, mean: -1.04381
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1225.50716, mean: -1.05647
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1299.04388, mean: -1.07359
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1377.23831, mean: -1.09305
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1453.41441, mean: -1.10948
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1538.02675, mean: -1.13090
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1600.76938, mean: -1.13530
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1669.21221, mean: -1.14330
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1744.10711, mean: -1.15504
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -1808.72730, mean: -1.15944
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -1882.83022, mean: -1.16946
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -1954.97055, mean: -1.17769
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -2011.08227, mean: -1.17607
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -2071.40398, mean: -1.17693
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -2133.29149, mean: -1.17861
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2197.89472, mean: -1.18166
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2270.97180, mean: -1.18899
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2338.77415, mean: -1.19325
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2395.04948, mean: -1.19157
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2463.76667, mean: -1.19600
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2523.73251, mean: -1.19608
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2582.09460, mean: -1.19541
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2639.27142, mean: -1.19424
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2694.76625, mean: -1.19237
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2759.13074, mean: -1.19443
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2822.34095, mean: -1.19591
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2882.20025, mean: -1.19593
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2940.93426, mean: -1.19550
[32m[0906 13-41-22 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-41-22 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-41-25 @MBExp.py:144][0m ####################################################################
[32m[0906 13-41-25 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-41-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.05292, current rewards: 0.66605, mean: 0.06660
[32m[0906 13-41-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03877, current rewards: 16.44244, mean: 0.27404
[32m[0906 13-41-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03751, current rewards: 32.25602, mean: 0.29324
[32m[0906 13-41-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03703, current rewards: 47.98397, mean: 0.29990
[32m[0906 13-41-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03691, current rewards: 61.33223, mean: 0.29206
[32m[0906 13-41-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03683, current rewards: 80.08602, mean: 0.30802
[32m[0906 13-41-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03675, current rewards: 98.83647, mean: 0.31883
[32m[0906 13-41-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03665, current rewards: 117.64852, mean: 0.32680
[32m[0906 13-41-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03668, current rewards: 136.42894, mean: 0.33275
[32m[0906 13-41-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03670, current rewards: 151.13878, mean: 0.32856
[32m[0906 13-41-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03671, current rewards: 158.93671, mean: 0.31164
[32m[0906 13-41-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03674, current rewards: 166.75438, mean: 0.29778
[32m[0906 13-41-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03677, current rewards: 174.55671, mean: 0.28616
[32m[0906 13-41-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03679, current rewards: 182.35537, mean: 0.27630
[32m[0906 13-41-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03678, current rewards: 190.16121, mean: 0.26783
[32m[0906 13-41-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03679, current rewards: 197.96701, mean: 0.26048
[32m[0906 13-41-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03681, current rewards: 204.00544, mean: 0.25186
[32m[0906 13-41-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03681, current rewards: 210.71155, mean: 0.24501
[32m[0906 13-41-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03686, current rewards: 223.63029, mean: 0.24575
[32m[0906 13-42-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03685, current rewards: 236.55707, mean: 0.24641
[32m[0906 13-42-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03680, current rewards: 249.46888, mean: 0.24700
[32m[0906 13-42-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03677, current rewards: 262.37033, mean: 0.24752
[32m[0906 13-42-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03678, current rewards: 275.27583, mean: 0.24800
[32m[0906 13-42-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03679, current rewards: 288.17043, mean: 0.24842
[32m[0906 13-42-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03678, current rewards: 297.98958, mean: 0.24627
[32m[0906 13-42-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03679, current rewards: 305.28609, mean: 0.24229
[32m[0906 13-42-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03679, current rewards: 312.57753, mean: 0.23861
[32m[0906 13-42-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03680, current rewards: 319.86987, mean: 0.23520
[32m[0906 13-42-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03680, current rewards: 327.16077, mean: 0.23203
[32m[0906 13-42-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03681, current rewards: 334.45030, mean: 0.22908
[32m[0906 13-42-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03681, current rewards: 339.75287, mean: 0.22500
[32m[0906 13-42-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03680, current rewards: 347.17340, mean: 0.22255
[32m[0906 13-42-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03681, current rewards: 355.81129, mean: 0.22100
[32m[0906 13-42-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03681, current rewards: 283.47476, mean: 0.17077
[32m[0906 13-42-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03681, current rewards: 183.47476, mean: 0.10730
[32m[0906 13-42-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03682, current rewards: 83.47476, mean: 0.04743
[32m[0906 13-42-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03681, current rewards: -16.52524, mean: -0.00913
[32m[0906 13-42-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03681, current rewards: -116.52524, mean: -0.06265
[32m[0906 13-42-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03681, current rewards: -179.08713, mean: -0.09376
[32m[0906 13-42-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03681, current rewards: -222.92902, mean: -0.11374
[32m[0906 13-42-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03680, current rewards: -262.10255, mean: -0.13040
[32m[0906 13-42-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03679, current rewards: -265.03883, mean: -0.12866
[32m[0906 13-42-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03678, current rewards: -253.35868, mean: -0.12008
[32m[0906 13-42-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03675, current rewards: -241.65360, mean: -0.11188
[32m[0906 13-42-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03673, current rewards: -229.96319, mean: -0.10406
[32m[0906 13-42-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03670, current rewards: -218.26630, mean: -0.09658
[32m[0906 13-42-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03670, current rewards: -206.56114, mean: -0.08942
[32m[0906 13-42-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03670, current rewards: -202.93264, mean: -0.08599
[32m[0906 13-42-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03670, current rewards: -198.20089, mean: -0.08224
[32m[0906 13-42-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03670, current rewards: -193.17918, mean: -0.07853
[32m[0906 13-42-57 @Agent.py:117][0m Average action selection time: 0.0367
[32m[0906 13-42-57 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-42-57 @MBExp.py:227][0m Rewards obtained: [-188.50344682161722], Lows: [335], Highs: [6], Total time: 92.410841
[32m[0906 13-43-01 @MBExp.py:144][0m ####################################################################
[32m[0906 13-43-01 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-43-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03565, current rewards: -3.15790, mean: -0.31579
[32m[0906 13-43-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03566, current rewards: 4.02370, mean: 0.06706
[32m[0906 13-43-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03563, current rewards: 11.19196, mean: 0.10175
[32m[0906 13-43-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03556, current rewards: 18.37724, mean: 0.11486
[32m[0906 13-43-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03548, current rewards: 25.55896, mean: 0.12171
[32m[0906 13-43-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03535, current rewards: 32.73236, mean: 0.12589
[32m[0906 13-43-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03541, current rewards: 39.91037, mean: 0.12874
[32m[0906 13-43-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03541, current rewards: 47.04946, mean: 0.13069
[32m[0906 13-43-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03551, current rewards: 52.69382, mean: 0.12852
[32m[0906 13-43-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03560, current rewards: 58.33043, mean: 0.12681
[32m[0906 13-43-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03565, current rewards: 60.06995, mean: 0.11778
[32m[0906 13-43-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03571, current rewards: 66.52881, mean: 0.11880
[32m[0906 13-43-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03575, current rewards: 72.99943, mean: 0.11967
[32m[0906 13-43-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03582, current rewards: 79.45317, mean: 0.12038
[32m[0906 13-43-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03586, current rewards: 83.43068, mean: 0.11751
[32m[0906 13-43-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03587, current rewards: 89.44614, mean: 0.11769
[32m[0906 13-43-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03589, current rewards: 95.19791, mean: 0.11753
[32m[0906 13-43-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03591, current rewards: 100.89014, mean: 0.11731
[32m[0906 13-43-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03593, current rewards: 106.58280, mean: 0.11712
[32m[0906 13-43-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03592, current rewards: 112.27036, mean: 0.11695
[32m[0906 13-43-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03589, current rewards: 117.95888, mean: 0.11679
[32m[0906 13-43-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03587, current rewards: 123.65576, mean: 0.11666
[32m[0906 13-43-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03586, current rewards: 129.33976, mean: 0.11652
[32m[0906 13-43-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03588, current rewards: 135.03243, mean: 0.11641
[32m[0906 13-43-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03590, current rewards: 140.88725, mean: 0.11644
[32m[0906 13-43-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03592, current rewards: 142.51959, mean: 0.11311
[32m[0906 13-43-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03593, current rewards: 148.40002, mean: 0.11328
[32m[0906 13-43-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03595, current rewards: 154.28306, mean: 0.11344
[32m[0906 13-43-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03595, current rewards: 160.16633, mean: 0.11359
[32m[0906 13-43-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03596, current rewards: 166.04917, mean: 0.11373
[32m[0906 13-43-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03598, current rewards: 171.92726, mean: 0.11386
[32m[0906 13-43-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03599, current rewards: 177.80711, mean: 0.11398
[32m[0906 13-44-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03600, current rewards: 183.75366, mean: 0.11413
[32m[0906 13-44-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03601, current rewards: 189.67793, mean: 0.11426
[32m[0906 13-44-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03601, current rewards: 195.61009, mean: 0.11439
[32m[0906 13-44-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03601, current rewards: 198.75979, mean: 0.11293
[32m[0906 13-44-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03602, current rewards: 203.75254, mean: 0.11257
[32m[0906 13-44-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03604, current rewards: 208.74260, mean: 0.11223
[32m[0906 13-44-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03604, current rewards: 213.73686, mean: 0.11190
[32m[0906 13-44-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03606, current rewards: 218.72933, mean: 0.11160
[32m[0906 13-44-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03606, current rewards: 223.06499, mean: 0.11098
[32m[0906 13-44-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03607, current rewards: 222.76933, mean: 0.10814
[32m[0906 13-44-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03608, current rewards: 226.67901, mean: 0.10743
[32m[0906 13-44-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03607, current rewards: 230.58608, mean: 0.10675
[32m[0906 13-44-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03606, current rewards: 234.49509, mean: 0.10611
[32m[0906 13-44-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03605, current rewards: 238.40206, mean: 0.10549
[32m[0906 13-44-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03604, current rewards: 242.31004, mean: 0.10490
[32m[0906 13-44-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03603, current rewards: 246.21386, mean: 0.10433
[32m[0906 13-44-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03603, current rewards: 250.21592, mean: 0.10382
[32m[0906 13-44-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03604, current rewards: 254.48566, mean: 0.10345
[32m[0906 13-44-32 @Agent.py:117][0m Average action selection time: 0.0360
[32m[0906 13-44-32 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-44-32 @MBExp.py:227][0m Rewards obtained: [257.89826152571476], Lows: [6], Highs: [8], Total time: 183.169587
[32m[0906 13-44-39 @MBExp.py:144][0m ####################################################################
[32m[0906 13-44-39 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-44-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03670, current rewards: -2.27574, mean: -0.22757
[32m[0906 13-44-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03641, current rewards: 2.66035, mean: 0.04434
[32m[0906 13-44-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03615, current rewards: 7.60603, mean: 0.06915
[32m[0906 13-44-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03595, current rewards: 12.55821, mean: 0.07849
[32m[0906 13-44-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03578, current rewards: 17.50287, mean: 0.08335
[32m[0906 13-44-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03558, current rewards: 22.45077, mean: 0.08635
[32m[0906 13-44-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03539, current rewards: 27.39548, mean: 0.08837
[32m[0906 13-44-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03529, current rewards: 32.34788, mean: 0.08986
[32m[0906 13-44-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03530, current rewards: 37.29576, mean: 0.09097
[32m[0906 13-44-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03536, current rewards: 42.24376, mean: 0.09183
[32m[0906 13-44-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03545, current rewards: 47.19412, mean: 0.09254
[32m[0906 13-44-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03553, current rewards: 52.13945, mean: 0.09311
[32m[0906 13-45-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03558, current rewards: 57.09122, mean: 0.09359
[32m[0906 13-45-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03564, current rewards: 62.03855, mean: 0.09400
[32m[0906 13-45-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03570, current rewards: 66.98561, mean: 0.09435
[32m[0906 13-45-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03573, current rewards: 72.78756, mean: 0.09577
[32m[0906 13-45-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03576, current rewards: 74.97790, mean: 0.09257
[32m[0906 13-45-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03578, current rewards: 81.39980, mean: 0.09465
[32m[0906 13-45-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03580, current rewards: 87.81997, mean: 0.09651
[32m[0906 13-45-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03579, current rewards: 94.24130, mean: 0.09817
[32m[0906 13-45-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03578, current rewards: 98.09289, mean: 0.09712
[32m[0906 13-45-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03577, current rewards: 103.81127, mean: 0.09794
[32m[0906 13-45-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03575, current rewards: 109.53716, mean: 0.09868
[32m[0906 13-45-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03575, current rewards: 115.11102, mean: 0.09923
[32m[0906 13-45-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03579, current rewards: 120.43470, mean: 0.09953
[32m[0906 13-45-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03581, current rewards: 125.76365, mean: 0.09981
[32m[0906 13-45-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03583, current rewards: 131.09695, mean: 0.10007
[32m[0906 13-45-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03585, current rewards: 134.79735, mean: 0.09912
[32m[0906 13-45-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03586, current rewards: 141.12615, mean: 0.10009
[32m[0906 13-45-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03588, current rewards: 147.46751, mean: 0.10101
[32m[0906 13-45-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03589, current rewards: 153.79827, mean: 0.10185
[32m[0906 13-45-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03591, current rewards: 160.28004, mean: 0.10274
[32m[0906 13-45-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03592, current rewards: 163.83697, mean: 0.10176
[32m[0906 13-45-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03593, current rewards: 171.47013, mean: 0.10330
[32m[0906 13-45-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03595, current rewards: 179.10187, mean: 0.10474
[32m[0906 13-45-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03596, current rewards: 186.74661, mean: 0.10611
[32m[0906 13-45-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03597, current rewards: 194.37567, mean: 0.10739
[32m[0906 13-45-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03598, current rewards: 202.01761, mean: 0.10861
[32m[0906 13-45-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03599, current rewards: 209.65182, mean: 0.10977
[32m[0906 13-45-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03600, current rewards: 217.28679, mean: 0.11086
[32m[0906 13-45-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03601, current rewards: 224.33342, mean: 0.11161
[32m[0906 13-45-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03601, current rewards: 228.99757, mean: 0.11116
[32m[0906 13-45-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03602, current rewards: 235.32148, mean: 0.11153
[32m[0906 13-45-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03603, current rewards: 241.65701, mean: 0.11188
[32m[0906 13-45-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03603, current rewards: 247.98168, mean: 0.11221
[32m[0906 13-46-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03602, current rewards: 254.30864, mean: 0.11253
[32m[0906 13-46-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03601, current rewards: 256.57778, mean: 0.11107
[32m[0906 13-46-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03600, current rewards: 263.59703, mean: 0.11169
[32m[0906 13-46-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03599, current rewards: 271.21966, mean: 0.11254
[32m[0906 13-46-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03598, current rewards: 278.94053, mean: 0.11339
[32m[0906 13-46-09 @Agent.py:117][0m Average action selection time: 0.0360
[32m[0906 13-46-09 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-46-09 @MBExp.py:227][0m Rewards obtained: [285.13191321139215], Lows: [7], Highs: [7], Total time: 273.76421
[32m[0906 13-46-18 @MBExp.py:144][0m ####################################################################
[32m[0906 13-46-18 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 13-46-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03625, current rewards: 0.95023, mean: 0.09502
[32m[0906 13-46-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03615, current rewards: 6.27415, mean: 0.10457
[32m[0906 13-46-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03629, current rewards: 11.59851, mean: 0.10544
[32m[0906 13-46-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03610, current rewards: 16.92325, mean: 0.10577
[32m[0906 13-46-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03584, current rewards: 22.24565, mean: 0.10593
[32m[0906 13-46-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03558, current rewards: 27.57422, mean: 0.10605
[32m[0906 13-46-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03543, current rewards: 32.83649, mean: 0.10592
[32m[0906 13-46-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03529, current rewards: 38.16423, mean: 0.10601
[32m[0906 13-46-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03518, current rewards: 43.49569, mean: 0.10609
[32m[0906 13-46-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03512, current rewards: 48.82618, mean: 0.10614
[32m[0906 13-46-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03515, current rewards: 54.15793, mean: 0.10619
[32m[0906 13-46-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03526, current rewards: 59.49524, mean: 0.10624
[32m[0906 13-46-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03536, current rewards: 62.47668, mean: 0.10242
[32m[0906 13-46-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03543, current rewards: 67.57783, mean: 0.10239
[32m[0906 13-46-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03549, current rewards: 72.57255, mean: 0.10221
[32m[0906 13-46-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03554, current rewards: 77.48324, mean: 0.10195
[32m[0906 13-46-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03560, current rewards: 82.39842, mean: 0.10173
[32m[0906 13-46-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03564, current rewards: 87.30830, mean: 0.10152
[32m[0906 13-46-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03565, current rewards: 92.21710, mean: 0.10134
[32m[0906 13-46-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03564, current rewards: 97.12966, mean: 0.10118
[32m[0906 13-46-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03563, current rewards: 102.03936, mean: 0.10103
[32m[0906 13-46-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03562, current rewards: 106.95119, mean: 0.10090
[32m[0906 13-46-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03562, current rewards: 111.91931, mean: 0.10083
[32m[0906 13-46-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03561, current rewards: 115.72603, mean: 0.09976
[32m[0906 13-47-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03563, current rewards: 121.34813, mean: 0.10029
[32m[0906 13-47-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03564, current rewards: 126.96826, mean: 0.10077
[32m[0906 13-47-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03566, current rewards: 132.58913, mean: 0.10121
[32m[0906 13-47-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03569, current rewards: 138.21405, mean: 0.10163
[32m[0906 13-47-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03571, current rewards: 143.83609, mean: 0.10201
[32m[0906 13-47-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03572, current rewards: 149.45751, mean: 0.10237
[32m[0906 13-47-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03575, current rewards: 155.08219, mean: 0.10270
[32m[0906 13-47-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03576, current rewards: 158.61721, mean: 0.10168
[32m[0906 13-47-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03578, current rewards: 164.45626, mean: 0.10215
[32m[0906 13-47-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03579, current rewards: 170.30866, mean: 0.10260
[32m[0906 13-47-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03580, current rewards: 176.16154, mean: 0.10302
[32m[0906 13-47-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03581, current rewards: 182.00698, mean: 0.10341
[32m[0906 13-47-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03583, current rewards: 187.84776, mean: 0.10378
[32m[0906 13-47-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03584, current rewards: 193.68516, mean: 0.10413
[32m[0906 13-47-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03586, current rewards: 199.53018, mean: 0.10447
[32m[0906 13-47-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03587, current rewards: 204.87411, mean: 0.10453
[32m[0906 13-47-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03588, current rewards: 209.96815, mean: 0.10446
[32m[0906 13-47-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03589, current rewards: 215.05799, mean: 0.10440
[32m[0906 13-47-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03591, current rewards: 219.78358, mean: 0.10416
[32m[0906 13-47-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03591, current rewards: 224.18011, mean: 0.10379
[32m[0906 13-47-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03592, current rewards: 228.57331, mean: 0.10343
[32m[0906 13-47-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03591, current rewards: 232.96709, mean: 0.10308
[32m[0906 13-47-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03590, current rewards: 237.36040, mean: 0.10275
[32m[0906 13-47-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03590, current rewards: 241.77947, mean: 0.10245
[32m[0906 13-47-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03589, current rewards: 247.69620, mean: 0.10278
[32m[0906 13-47-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03588, current rewards: 253.86403, mean: 0.10320
[32m[0906 13-47-48 @Agent.py:117][0m Average action selection time: 0.0359
[32m[0906 13-47-48 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-47-48 @MBExp.py:227][0m Rewards obtained: [258.7980141334973], Lows: [1], Highs: [4], Total time: 364.06935599999997
[32m[0906 13-47-58 @MBExp.py:144][0m ####################################################################
[32m[0906 13-47-58 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 13-47-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03562, current rewards: -1.12225, mean: -0.11222
[32m[0906 13-48-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03619, current rewards: 3.88386, mean: 0.06473
[32m[0906 13-48-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03625, current rewards: 8.88910, mean: 0.08081
[32m[0906 13-48-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03623, current rewards: 13.89576, mean: 0.08685
[32m[0906 13-48-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03595, current rewards: 18.90252, mean: 0.09001
[32m[0906 13-48-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03567, current rewards: 23.90166, mean: 0.09193
[32m[0906 13-48-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03550, current rewards: 28.90083, mean: 0.09323
[32m[0906 13-48-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03539, current rewards: 33.90540, mean: 0.09418
[32m[0906 13-48-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03528, current rewards: 38.90906, mean: 0.09490
[32m[0906 13-48-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03518, current rewards: 43.91087, mean: 0.09546
[32m[0906 13-48-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03511, current rewards: 48.91481, mean: 0.09591
[32m[0906 13-48-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03511, current rewards: 53.92432, mean: 0.09629
[32m[0906 13-48-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03514, current rewards: 58.92984, mean: 0.09661
[32m[0906 13-48-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03522, current rewards: 63.93256, mean: 0.09687
[32m[0906 13-48-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03530, current rewards: 69.09326, mean: 0.09731
[32m[0906 13-48-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03536, current rewards: 74.99714, mean: 0.09868
[32m[0906 13-48-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03541, current rewards: 80.06688, mean: 0.09885
[32m[0906 13-48-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03546, current rewards: 85.17903, mean: 0.09905
[32m[0906 13-48-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03547, current rewards: 90.28832, mean: 0.09922
[32m[0906 13-48-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03547, current rewards: 95.40322, mean: 0.09938
[32m[0906 13-48-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03546, current rewards: 100.51310, mean: 0.09952
[32m[0906 13-48-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03546, current rewards: 105.62005, mean: 0.09964
[32m[0906 13-48-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03545, current rewards: 110.76467, mean: 0.09979
[32m[0906 13-48-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03545, current rewards: 114.10327, mean: 0.09836
[32m[0906 13-48-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03545, current rewards: 119.57824, mean: 0.09882
[32m[0906 13-48-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03548, current rewards: 125.04648, mean: 0.09924
[32m[0906 13-48-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03551, current rewards: 130.51367, mean: 0.09963
[32m[0906 13-48-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03554, current rewards: 135.98551, mean: 0.09999
[32m[0906 13-48-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03556, current rewards: 141.45705, mean: 0.10032
[32m[0906 13-48-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03561, current rewards: 146.92754, mean: 0.10064
[32m[0906 13-48-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03563, current rewards: 152.40007, mean: 0.10093
[32m[0906 13-48-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03565, current rewards: 157.64797, mean: 0.10106
[32m[0906 13-48-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03567, current rewards: 163.30262, mean: 0.10143
[32m[0906 13-48-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03569, current rewards: 168.96037, mean: 0.10178
[32m[0906 13-49-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03571, current rewards: 174.61752, mean: 0.10212
[32m[0906 13-49-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03572, current rewards: 180.27802, mean: 0.10243
[32m[0906 13-49-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03574, current rewards: 184.55281, mean: 0.10196
[32m[0906 13-49-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03575, current rewards: 189.87166, mean: 0.10208
[32m[0906 13-49-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03576, current rewards: 195.18634, mean: 0.10219
[32m[0906 13-49-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03577, current rewards: 200.49689, mean: 0.10229
[32m[0906 13-49-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03579, current rewards: 205.81447, mean: 0.10240
[32m[0906 13-49-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03581, current rewards: 211.12737, mean: 0.10249
[32m[0906 13-49-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03581, current rewards: 216.43905, mean: 0.10258
[32m[0906 13-49-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03582, current rewards: 221.75721, mean: 0.10267
[32m[0906 13-49-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03583, current rewards: 227.07658, mean: 0.10275
[32m[0906 13-49-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03585, current rewards: 232.39283, mean: 0.10283
[32m[0906 13-49-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03585, current rewards: 235.57140, mean: 0.10198
[32m[0906 13-49-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03584, current rewards: 240.96310, mean: 0.10210
[32m[0906 13-49-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03583, current rewards: 246.16895, mean: 0.10214
[32m[0906 13-49-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03582, current rewards: 251.32996, mean: 0.10217
[32m[0906 13-49-29 @Agent.py:117][0m Average action selection time: 0.0358
[32m[0906 13-49-29 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-49-29 @MBExp.py:227][0m Rewards obtained: [255.4568625880343], Lows: [2], Highs: [3], Total time: 454.258587
[32m[0906 13-49-41 @MBExp.py:144][0m ####################################################################
[32m[0906 13-49-41 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 13-49-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03573, current rewards: -1.22547, mean: -0.12255
[32m[0906 13-49-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03627, current rewards: 4.24871, mean: 0.07081
[32m[0906 13-49-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03628, current rewards: 9.71759, mean: 0.08834
[32m[0906 13-49-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03624, current rewards: 15.19408, mean: 0.09496
[32m[0906 13-49-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03603, current rewards: 20.66606, mean: 0.09841
[32m[0906 13-49-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03583, current rewards: 26.14546, mean: 0.10056
[32m[0906 13-49-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03563, current rewards: 31.31273, mean: 0.10101
[32m[0906 13-49-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03549, current rewards: 36.51950, mean: 0.10144
[32m[0906 13-49-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03538, current rewards: 41.73478, mean: 0.10179
[32m[0906 13-49-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03531, current rewards: 44.96544, mean: 0.09775
[32m[0906 13-49-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03523, current rewards: 50.40717, mean: 0.09884
[32m[0906 13-50-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03517, current rewards: 55.84971, mean: 0.09973
[32m[0906 13-50-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03517, current rewards: 61.29328, mean: 0.10048
[32m[0906 13-50-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03520, current rewards: 66.73256, mean: 0.10111
[32m[0906 13-50-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03520, current rewards: 72.23147, mean: 0.10173
[32m[0906 13-50-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03528, current rewards: 77.67383, mean: 0.10220
[32m[0906 13-50-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03535, current rewards: 83.11553, mean: 0.10261
[32m[0906 13-50-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03539, current rewards: 88.55594, mean: 0.10297
[32m[0906 13-50-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03540, current rewards: 91.86072, mean: 0.10095
[32m[0906 13-50-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03540, current rewards: 96.89111, mean: 0.10093
[32m[0906 13-50-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03541, current rewards: 101.92244, mean: 0.10091
[32m[0906 13-50-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03541, current rewards: 106.95180, mean: 0.10090
[32m[0906 13-50-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03540, current rewards: 111.92748, mean: 0.10084
[32m[0906 13-50-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03540, current rewards: 117.33359, mean: 0.10115
[32m[0906 13-50-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03539, current rewards: 120.74906, mean: 0.09979
[32m[0906 13-50-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03540, current rewards: 126.29654, mean: 0.10024
[32m[0906 13-50-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03543, current rewards: 131.84074, mean: 0.10064
[32m[0906 13-50-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03545, current rewards: 137.38496, mean: 0.10102
[32m[0906 13-50-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03548, current rewards: 142.93183, mean: 0.10137
[32m[0906 13-50-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03553, current rewards: 148.47921, mean: 0.10170
[32m[0906 13-50-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03554, current rewards: 154.01232, mean: 0.10199
[32m[0906 13-50-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03556, current rewards: 159.55322, mean: 0.10228
[32m[0906 13-50-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03558, current rewards: 165.09231, mean: 0.10254
[32m[0906 13-50-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03560, current rewards: 170.63047, mean: 0.10279
[32m[0906 13-50-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03562, current rewards: 176.17290, mean: 0.10303
[32m[0906 13-50-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03564, current rewards: 181.71147, mean: 0.10325
[32m[0906 13-50-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03566, current rewards: 186.05505, mean: 0.10279
[32m[0906 13-50-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03567, current rewards: 191.53929, mean: 0.10298
[32m[0906 13-50-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03568, current rewards: 197.07272, mean: 0.10318
[32m[0906 13-50-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03569, current rewards: 202.71251, mean: 0.10342
[32m[0906 13-50-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03571, current rewards: 208.06824, mean: 0.10352
[32m[0906 13-50-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03572, current rewards: 213.42658, mean: 0.10361
[32m[0906 13-50-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03573, current rewards: 218.78554, mean: 0.10369
[32m[0906 13-50-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03574, current rewards: 224.14573, mean: 0.10377
[32m[0906 13-51-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03576, current rewards: 229.50160, mean: 0.10385
[32m[0906 13-51-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03577, current rewards: 233.93068, mean: 0.10351
[32m[0906 13-51-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03577, current rewards: 239.74689, mean: 0.10379
[32m[0906 13-51-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03578, current rewards: 245.56303, mean: 0.10405
[32m[0906 13-51-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03577, current rewards: 251.37260, mean: 0.10430
[32m[0906 13-51-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03577, current rewards: 257.18309, mean: 0.10455
[32m[0906 13-51-11 @Agent.py:117][0m Average action selection time: 0.0358
[32m[0906 13-51-11 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-51-11 @MBExp.py:227][0m Rewards obtained: [259.1775650084818], Lows: [4], Highs: [4], Total time: 544.28919
[32m[0906 13-51-26 @MBExp.py:144][0m ####################################################################
[32m[0906 13-51-26 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 13-51-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03569, current rewards: -2.20864, mean: -0.22086
[32m[0906 13-51-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03635, current rewards: 3.43780, mean: 0.05730
[32m[0906 13-51-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03639, current rewards: 9.09070, mean: 0.08264
[32m[0906 13-51-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03632, current rewards: 14.74023, mean: 0.09213
[32m[0906 13-51-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03612, current rewards: 20.39265, mean: 0.09711
[32m[0906 13-51-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03600, current rewards: 26.10848, mean: 0.10042
[32m[0906 13-51-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03585, current rewards: 31.73474, mean: 0.10237
[32m[0906 13-51-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03565, current rewards: 37.36993, mean: 0.10381
[32m[0906 13-51-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03551, current rewards: 43.00479, mean: 0.10489
[32m[0906 13-51-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03540, current rewards: 48.63875, mean: 0.10574
[32m[0906 13-51-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03531, current rewards: 53.01231, mean: 0.10395
[32m[0906 13-51-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03525, current rewards: 58.45961, mean: 0.10439
[32m[0906 13-51-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03520, current rewards: 63.91371, mean: 0.10478
[32m[0906 13-51-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03519, current rewards: 69.18154, mean: 0.10482
[32m[0906 13-51-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03521, current rewards: 74.48181, mean: 0.10490
[32m[0906 13-51-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03524, current rewards: 79.77990, mean: 0.10497
[32m[0906 13-51-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03526, current rewards: 85.07710, mean: 0.10503
[32m[0906 13-51-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03528, current rewards: 90.37623, mean: 0.10509
[32m[0906 13-51-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03531, current rewards: 95.67117, mean: 0.10513
[32m[0906 13-52-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03532, current rewards: 100.96651, mean: 0.10517
[32m[0906 13-52-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03532, current rewards: 106.26567, mean: 0.10521
[32m[0906 13-52-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03533, current rewards: 111.70471, mean: 0.10538
[32m[0906 13-52-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03534, current rewards: 115.21944, mean: 0.10380
[32m[0906 13-52-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03534, current rewards: 120.80782, mean: 0.10414
[32m[0906 13-52-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03535, current rewards: 126.39460, mean: 0.10446
[32m[0906 13-52-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03536, current rewards: 131.97814, mean: 0.10474
[32m[0906 13-52-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03537, current rewards: 137.56278, mean: 0.10501
[32m[0906 13-52-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03540, current rewards: 143.14295, mean: 0.10525
[32m[0906 13-52-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03544, current rewards: 147.22037, mean: 0.10441
[32m[0906 13-52-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03547, current rewards: 152.66915, mean: 0.10457
[32m[0906 13-52-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03550, current rewards: 157.95303, mean: 0.10460
[32m[0906 13-52-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03552, current rewards: 163.55736, mean: 0.10484
[32m[0906 13-52-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03555, current rewards: 169.16358, mean: 0.10507
[32m[0906 13-52-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03556, current rewards: 174.76689, mean: 0.10528
[32m[0906 13-52-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03559, current rewards: 180.37052, mean: 0.10548
[32m[0906 13-52-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03561, current rewards: 185.97385, mean: 0.10567
[32m[0906 13-52-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03562, current rewards: 191.57492, mean: 0.10584
[32m[0906 13-52-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03564, current rewards: 197.17736, mean: 0.10601
[32m[0906 13-52-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03565, current rewards: 202.89132, mean: 0.10623
[32m[0906 13-52-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03567, current rewards: 208.46683, mean: 0.10636
[32m[0906 13-52-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03568, current rewards: 214.04015, mean: 0.10649
[32m[0906 13-52-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03569, current rewards: 219.61241, mean: 0.10661
[32m[0906 13-52-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03570, current rewards: 225.18541, mean: 0.10672
[32m[0906 13-52-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03572, current rewards: 230.75984, mean: 0.10683
[32m[0906 13-52-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03574, current rewards: 234.25889, mean: 0.10600
[32m[0906 13-52-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03575, current rewards: 239.68890, mean: 0.10606
[32m[0906 13-52-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03576, current rewards: 245.11696, mean: 0.10611
[32m[0906 13-52-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03578, current rewards: 250.54689, mean: 0.10616
[32m[0906 13-52-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03578, current rewards: 255.97558, mean: 0.10621
[32m[0906 13-52-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03578, current rewards: 261.40317, mean: 0.10626
[32m[0906 13-52-56 @Agent.py:117][0m Average action selection time: 0.0358
[32m[0906 13-52-56 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-52-56 @MBExp.py:227][0m Rewards obtained: [265.7434078149285], Lows: [2], Highs: [6], Total time: 634.352181
[32m[0906 13-53-12 @MBExp.py:144][0m ####################################################################
[32m[0906 13-53-12 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 13-53-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03619, current rewards: -2.18666, mean: -0.21867
[32m[0906 13-53-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03636, current rewards: 2.99896, mean: 0.04998
[32m[0906 13-53-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03632, current rewards: 8.16613, mean: 0.07424
[32m[0906 13-53-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03629, current rewards: 13.33403, mean: 0.08334
[32m[0906 13-53-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03603, current rewards: 18.48973, mean: 0.08805
[32m[0906 13-53-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03592, current rewards: 23.65031, mean: 0.09096
[32m[0906 13-53-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03587, current rewards: 28.81792, mean: 0.09296
[32m[0906 13-53-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03577, current rewards: 33.98258, mean: 0.09440
[32m[0906 13-53-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03564, current rewards: 39.20238, mean: 0.09562
[32m[0906 13-53-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03553, current rewards: 44.56528, mean: 0.09688
[32m[0906 13-53-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03543, current rewards: 49.93336, mean: 0.09791
[32m[0906 13-53-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03534, current rewards: 55.29976, mean: 0.09875
[32m[0906 13-53-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03529, current rewards: 60.66324, mean: 0.09945
[32m[0906 13-53-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03523, current rewards: 65.80237, mean: 0.09970
[32m[0906 13-53-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03520, current rewards: 68.92446, mean: 0.09708
[32m[0906 13-53-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03522, current rewards: 74.12216, mean: 0.09753
[32m[0906 13-53-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03522, current rewards: 79.31855, mean: 0.09792
[32m[0906 13-53-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03519, current rewards: 84.51256, mean: 0.09827
[32m[0906 13-53-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03515, current rewards: 89.71009, mean: 0.09858
[32m[0906 13-53-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03514, current rewards: 94.90367, mean: 0.09886
[32m[0906 13-53-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03515, current rewards: 100.10239, mean: 0.09911
[32m[0906 13-53-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03517, current rewards: 105.30239, mean: 0.09934
[32m[0906 13-53-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03519, current rewards: 109.32226, mean: 0.09849
[32m[0906 13-53-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03520, current rewards: 114.45750, mean: 0.09867
[32m[0906 13-53-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03522, current rewards: 119.59116, mean: 0.09884
[32m[0906 13-53-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03523, current rewards: 124.73066, mean: 0.09899
[32m[0906 13-53-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03524, current rewards: 129.87124, mean: 0.09914
[32m[0906 13-54-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03525, current rewards: 135.00981, mean: 0.09927
[32m[0906 13-54-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03529, current rewards: 140.15033, mean: 0.09940
[32m[0906 13-54-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03533, current rewards: 145.31152, mean: 0.09953
[32m[0906 13-54-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03536, current rewards: 150.44419, mean: 0.09963
[32m[0906 13-54-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03539, current rewards: 155.58328, mean: 0.09973
[32m[0906 13-54-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03542, current rewards: 160.71737, mean: 0.09982
[32m[0906 13-54-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03545, current rewards: 164.02901, mean: 0.09881
[32m[0906 13-54-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03547, current rewards: 168.41834, mean: 0.09849
[32m[0906 13-54-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03550, current rewards: 172.80918, mean: 0.09819
[32m[0906 13-54-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03553, current rewards: 177.19958, mean: 0.09790
[32m[0906 13-54-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03555, current rewards: 181.58715, mean: 0.09763
[32m[0906 13-54-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03556, current rewards: 185.97224, mean: 0.09737
[32m[0906 13-54-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03558, current rewards: 190.36034, mean: 0.09712
[32m[0906 13-54-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03560, current rewards: 194.75463, mean: 0.09689
[32m[0906 13-54-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03562, current rewards: 199.14437, mean: 0.09667
[32m[0906 13-54-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03564, current rewards: 203.53190, mean: 0.09646
[32m[0906 13-54-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03565, current rewards: 207.91935, mean: 0.09626
[32m[0906 13-54-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03566, current rewards: 212.30829, mean: 0.09607
[32m[0906 13-54-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03567, current rewards: 216.08530, mean: 0.09561
[32m[0906 13-54-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03569, current rewards: 221.18765, mean: 0.09575
[32m[0906 13-54-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03570, current rewards: 226.28010, mean: 0.09588
[32m[0906 13-54-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03572, current rewards: 231.37936, mean: 0.09601
[32m[0906 13-54-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03573, current rewards: 236.47308, mean: 0.09613
[32m[0906 13-54-42 @Agent.py:117][0m Average action selection time: 0.0357
[32m[0906 13-54-42 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-54-42 @MBExp.py:227][0m Rewards obtained: [240.54915820598288], Lows: [1], Highs: [6], Total time: 724.2869089999999
[32m[0906 13-55-01 @MBExp.py:144][0m ####################################################################
[32m[0906 13-55-01 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 13-55-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03552, current rewards: -1.06459, mean: -0.10646
[32m[0906 13-55-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03604, current rewards: 4.78652, mean: 0.07978
[32m[0906 13-55-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03609, current rewards: 10.63338, mean: 0.09667
[32m[0906 13-55-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03604, current rewards: 16.48325, mean: 0.10302
[32m[0906 13-55-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03591, current rewards: 22.32701, mean: 0.10632
[32m[0906 13-55-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03581, current rewards: 28.16996, mean: 0.10835
[32m[0906 13-55-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03573, current rewards: 34.01793, mean: 0.10974
[32m[0906 13-55-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03570, current rewards: 39.86686, mean: 0.11074
[32m[0906 13-55-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03565, current rewards: 45.71434, mean: 0.11150
[32m[0906 13-55-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03552, current rewards: 51.55560, mean: 0.11208
[32m[0906 13-55-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03541, current rewards: 55.71456, mean: 0.10924
[32m[0906 13-55-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03534, current rewards: 61.58713, mean: 0.10998
[32m[0906 13-55-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03527, current rewards: 67.48403, mean: 0.11063
[32m[0906 13-55-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03522, current rewards: 73.38320, mean: 0.11119
[32m[0906 13-55-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03518, current rewards: 79.28184, mean: 0.11166
[32m[0906 13-55-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03515, current rewards: 85.17884, mean: 0.11208
[32m[0906 13-55-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03515, current rewards: 88.70644, mean: 0.10951
[32m[0906 13-55-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03510, current rewards: 94.46099, mean: 0.10984
[32m[0906 13-55-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03507, current rewards: 100.20790, mean: 0.11012
[32m[0906 13-55-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03505, current rewards: 106.03002, mean: 0.11045
[32m[0906 13-55-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03502, current rewards: 109.85388, mean: 0.10877
[32m[0906 13-55-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03500, current rewards: 115.71368, mean: 0.10916
[32m[0906 13-55-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03503, current rewards: 121.57240, mean: 0.10952
[32m[0906 13-55-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03505, current rewards: 127.43210, mean: 0.10986
[32m[0906 13-55-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03506, current rewards: 133.29193, mean: 0.11016
[32m[0906 13-55-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03507, current rewards: 139.15371, mean: 0.11044
[32m[0906 13-55-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03509, current rewards: 145.01418, mean: 0.11070
[32m[0906 13-55-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03510, current rewards: 148.95282, mean: 0.10952
[32m[0906 13-55-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03513, current rewards: 154.47862, mean: 0.10956
[32m[0906 13-55-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03516, current rewards: 160.17134, mean: 0.10971
[32m[0906 13-55-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03520, current rewards: 165.86462, mean: 0.10984
[32m[0906 13-55-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03523, current rewards: 171.55335, mean: 0.10997
[32m[0906 13-55-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03527, current rewards: 177.21392, mean: 0.11007
[32m[0906 13-56-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03529, current rewards: 183.05436, mean: 0.11027
[32m[0906 13-56-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03532, current rewards: 188.88629, mean: 0.11046
[32m[0906 13-56-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03534, current rewards: 194.72402, mean: 0.11064
[32m[0906 13-56-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03537, current rewards: 200.70075, mean: 0.11088
[32m[0906 13-56-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03539, current rewards: 206.76094, mean: 0.11116
[32m[0906 13-56-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03542, current rewards: 212.69008, mean: 0.11136
[32m[0906 13-56-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03544, current rewards: 218.61278, mean: 0.11154
[32m[0906 13-56-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03546, current rewards: 224.54601, mean: 0.11171
[32m[0906 13-56-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03548, current rewards: 230.47039, mean: 0.11188
[32m[0906 13-56-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03550, current rewards: 234.31999, mean: 0.11105
[32m[0906 13-56-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03552, current rewards: 240.22779, mean: 0.11122
[32m[0906 13-56-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03553, current rewards: 246.14480, mean: 0.11138
[32m[0906 13-56-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03555, current rewards: 251.92889, mean: 0.11147
[32m[0906 13-56-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03557, current rewards: 257.72977, mean: 0.11157
[32m[0906 13-56-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03558, current rewards: 263.53336, mean: 0.11167
[32m[0906 13-56-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03560, current rewards: 268.29376, mean: 0.11133
[32m[0906 13-56-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03561, current rewards: 274.14559, mean: 0.11144
[32m[0906 13-56-31 @Agent.py:117][0m Average action selection time: 0.0356
[32m[0906 13-56-31 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-56-31 @MBExp.py:227][0m Rewards obtained: [278.8226652785766], Lows: [4], Highs: [5], Total time: 813.95328
[32m[0906 13-56-51 @MBExp.py:144][0m ####################################################################
[32m[0906 13-56-51 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 13-56-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03495, current rewards: -1.12234, mean: -0.11223
[32m[0906 13-56-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03521, current rewards: 4.50079, mean: 0.07501
[32m[0906 13-56-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03560, current rewards: 10.12314, mean: 0.09203
[32m[0906 13-56-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03578, current rewards: 15.64127, mean: 0.09776
[32m[0906 13-56-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03569, current rewards: 21.25366, mean: 0.10121
[32m[0906 13-57-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03565, current rewards: 26.87310, mean: 0.10336
[32m[0906 13-57-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03562, current rewards: 32.48752, mean: 0.10480
[32m[0906 13-57-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03566, current rewards: 38.10652, mean: 0.10585
[32m[0906 13-57-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03563, current rewards: 43.72038, mean: 0.10664
[32m[0906 13-57-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03558, current rewards: 49.33579, mean: 0.10725
[32m[0906 13-57-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03548, current rewards: 54.94737, mean: 0.10774
[32m[0906 13-57-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03540, current rewards: 60.55364, mean: 0.10813
[32m[0906 13-57-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03533, current rewards: 66.17145, mean: 0.10848
[32m[0906 13-57-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03528, current rewards: 71.78530, mean: 0.10877
[32m[0906 13-57-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03522, current rewards: 77.39860, mean: 0.10901
[32m[0906 13-57-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03519, current rewards: 83.01097, mean: 0.10922
[32m[0906 13-57-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03512, current rewards: 88.57140, mean: 0.10935
[32m[0906 13-57-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03509, current rewards: 94.07770, mean: 0.10939
[32m[0906 13-57-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03507, current rewards: 99.58912, mean: 0.10944
[32m[0906 13-57-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03505, current rewards: 105.21034, mean: 0.10959
[32m[0906 13-57-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03503, current rewards: 110.87198, mean: 0.10977
[32m[0906 13-57-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03501, current rewards: 116.53939, mean: 0.10994
[32m[0906 13-57-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03498, current rewards: 122.20247, mean: 0.11009
[32m[0906 13-57-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03496, current rewards: 127.86306, mean: 0.11023
[32m[0906 13-57-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03498, current rewards: 133.52645, mean: 0.11035
[32m[0906 13-57-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03500, current rewards: 137.06643, mean: 0.10878
[32m[0906 13-57-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03502, current rewards: 142.67496, mean: 0.10891
[32m[0906 13-57-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03503, current rewards: 148.27054, mean: 0.10902
[32m[0906 13-57-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03504, current rewards: 153.79720, mean: 0.10908
[32m[0906 13-57-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03507, current rewards: 159.44807, mean: 0.10921
[32m[0906 13-57-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03511, current rewards: 165.09275, mean: 0.10933
[32m[0906 13-57-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03516, current rewards: 170.73950, mean: 0.10945
[32m[0906 13-57-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03519, current rewards: 176.38497, mean: 0.10956
[32m[0906 13-57-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03523, current rewards: 182.03373, mean: 0.10966
[32m[0906 13-57-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03526, current rewards: 187.68083, mean: 0.10975
[32m[0906 13-57-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03529, current rewards: 193.32559, mean: 0.10984
[32m[0906 13-57-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03532, current rewards: 199.03478, mean: 0.10996
[32m[0906 13-57-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03535, current rewards: 204.67290, mean: 0.11004
[32m[0906 13-57-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03537, current rewards: 210.30118, mean: 0.11011
[32m[0906 13-58-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03539, current rewards: 215.93777, mean: 0.11017
[32m[0906 13-58-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03541, current rewards: 221.57276, mean: 0.11024
[32m[0906 13-58-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03543, current rewards: 226.28670, mean: 0.10985
[32m[0906 13-58-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03544, current rewards: 232.00261, mean: 0.10995
[32m[0906 13-58-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03546, current rewards: 237.71896, mean: 0.11006
[32m[0906 13-58-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03547, current rewards: 243.63901, mean: 0.11024
[32m[0906 13-58-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03549, current rewards: 249.34207, mean: 0.11033
[32m[0906 13-58-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03551, current rewards: 255.04193, mean: 0.11041
[32m[0906 13-58-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03552, current rewards: 260.74552, mean: 0.11049
[32m[0906 13-58-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03553, current rewards: 266.45240, mean: 0.11056
[32m[0906 13-58-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03555, current rewards: 272.15773, mean: 0.11063
[32m[0906 13-58-21 @Agent.py:117][0m Average action selection time: 0.0356
[32m[0906 13-58-21 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-58-21 @MBExp.py:227][0m Rewards obtained: [272.5516302259585], Lows: [3], Highs: [3], Total time: 903.4934629999999
[32m[0906 13-58-44 @MBExp.py:144][0m ####################################################################
[32m[0906 13-58-44 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 13-58-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03497, current rewards: 0.04129, mean: 0.00413
[32m[0906 13-58-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03529, current rewards: 5.85334, mean: 0.09756
[32m[0906 13-58-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03547, current rewards: 11.62806, mean: 0.10571
[32m[0906 13-58-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03549, current rewards: 17.43276, mean: 0.10895
[32m[0906 13-58-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03548, current rewards: 23.25151, mean: 0.11072
[32m[0906 13-58-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03546, current rewards: 29.06121, mean: 0.11177
[32m[0906 13-58-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03545, current rewards: 32.66924, mean: 0.10538
[32m[0906 13-58-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03547, current rewards: 38.39367, mean: 0.10665
[32m[0906 13-58-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03545, current rewards: 44.12123, mean: 0.10761
[32m[0906 13-59-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03545, current rewards: 49.84725, mean: 0.10836
[32m[0906 13-59-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03544, current rewards: 55.57922, mean: 0.10898
[32m[0906 13-59-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03536, current rewards: 61.16640, mean: 0.10923
[32m[0906 13-59-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03530, current rewards: 66.87562, mean: 0.10963
[32m[0906 13-59-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03524, current rewards: 72.57868, mean: 0.10997
[32m[0906 13-59-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03520, current rewards: 78.29184, mean: 0.11027
[32m[0906 13-59-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03515, current rewards: 81.86666, mean: 0.10772
[32m[0906 13-59-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03506, current rewards: 87.50878, mean: 0.10804
[32m[0906 13-59-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03499, current rewards: 93.14561, mean: 0.10831
[32m[0906 13-59-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03497, current rewards: 98.78712, mean: 0.10856
[32m[0906 13-59-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03494, current rewards: 104.52399, mean: 0.10888
[32m[0906 13-59-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03492, current rewards: 110.11158, mean: 0.10902
[32m[0906 13-59-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03490, current rewards: 115.69794, mean: 0.10915
[32m[0906 13-59-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03488, current rewards: 121.28353, mean: 0.10926
[32m[0906 13-59-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03486, current rewards: 126.86653, mean: 0.10937
[32m[0906 13-59-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03485, current rewards: 132.45499, mean: 0.10947
[32m[0906 13-59-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03483, current rewards: 138.04058, mean: 0.10956
[32m[0906 13-59-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03484, current rewards: 143.62697, mean: 0.10964
[32m[0906 13-59-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03486, current rewards: 148.09277, mean: 0.10889
[32m[0906 13-59-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03488, current rewards: 153.77240, mean: 0.10906
[32m[0906 13-59-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03489, current rewards: 159.45333, mean: 0.10921
[32m[0906 13-59-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03493, current rewards: 165.13671, mean: 0.10936
[32m[0906 13-59-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03498, current rewards: 170.81678, mean: 0.10950
[32m[0906 13-59-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03502, current rewards: 176.49756, mean: 0.10963
[32m[0906 13-59-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03506, current rewards: 182.17414, mean: 0.10974
[32m[0906 13-59-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03510, current rewards: 187.85727, mean: 0.10986
[32m[0906 13-59-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03513, current rewards: 193.65540, mean: 0.11003
[32m[0906 13-59-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03516, current rewards: 199.37425, mean: 0.11015
[32m[0906 13-59-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03518, current rewards: 205.06472, mean: 0.11025
[32m[0906 13-59-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03521, current rewards: 210.74678, mean: 0.11034
[32m[0906 13-59-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03524, current rewards: 216.43488, mean: 0.11043
[32m[0906 13-59-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03526, current rewards: 220.31932, mean: 0.10961
[32m[0906 13-59-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03529, current rewards: 226.55792, mean: 0.10998
[32m[0906 13-59-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03530, current rewards: 232.80455, mean: 0.11033
[32m[0906 14-00-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03533, current rewards: 239.04560, mean: 0.11067
[32m[0906 14-00-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03535, current rewards: 241.10464, mean: 0.10910
[32m[0906 14-00-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03537, current rewards: 247.02451, mean: 0.10930
[32m[0906 14-00-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03539, current rewards: 252.94529, mean: 0.10950
[32m[0906 14-00-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03541, current rewards: 258.86591, mean: 0.10969
[32m[0906 14-00-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03543, current rewards: 264.78623, mean: 0.10987
[32m[0906 14-00-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03545, current rewards: 270.70627, mean: 0.11004
[32m[0906 14-00-13 @Agent.py:117][0m Average action selection time: 0.0355
[32m[0906 14-00-13 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-00-13 @MBExp.py:227][0m Rewards obtained: [275.4420299007161], Lows: [5], Highs: [2], Total time: 992.7700379999999
[32m[0906 14-00-38 @MBExp.py:144][0m ####################################################################
[32m[0906 14-00-38 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 14-00-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03555, current rewards: -0.09654, mean: -0.00965
[32m[0906 14-00-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03543, current rewards: 5.46087, mean: 0.09101
[32m[0906 14-00-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03548, current rewards: 11.26351, mean: 0.10240
[32m[0906 14-00-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03532, current rewards: 16.94822, mean: 0.10593
[32m[0906 14-00-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03520, current rewards: 22.63593, mean: 0.10779
[32m[0906 14-00-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03527, current rewards: 28.32204, mean: 0.10893
[32m[0906 14-00-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03533, current rewards: 33.84794, mean: 0.10919
[32m[0906 14-00-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03532, current rewards: 39.41384, mean: 0.10948
[32m[0906 14-00-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03535, current rewards: 44.98328, mean: 0.10972
[32m[0906 14-00-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03535, current rewards: 50.54900, mean: 0.10989
[32m[0906 14-00-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03534, current rewards: 56.09159, mean: 0.10998
[32m[0906 14-00-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03534, current rewards: 57.50903, mean: 0.10269
[32m[0906 14-00-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03530, current rewards: 63.18250, mean: 0.10358
[32m[0906 14-01-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03522, current rewards: 68.85813, mean: 0.10433
[32m[0906 14-01-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03517, current rewards: 74.53011, mean: 0.10497
[32m[0906 14-01-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03511, current rewards: 80.20902, mean: 0.10554
[32m[0906 14-01-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03502, current rewards: 85.88304, mean: 0.10603
[32m[0906 14-01-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03494, current rewards: 91.56132, mean: 0.10647
[32m[0906 14-01-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03487, current rewards: 97.23463, mean: 0.10685
[32m[0906 14-01-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03486, current rewards: 102.77323, mean: 0.10706
[32m[0906 14-01-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03483, current rewards: 108.42191, mean: 0.10735
[32m[0906 14-01-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03481, current rewards: 114.07419, mean: 0.10762
[32m[0906 14-01-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03480, current rewards: 119.72207, mean: 0.10786
[32m[0906 14-01-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03479, current rewards: 125.37140, mean: 0.10808
[32m[0906 14-01-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03477, current rewards: 131.01776, mean: 0.10828
[32m[0906 14-01-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03476, current rewards: 135.19346, mean: 0.10730
[32m[0906 14-01-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03476, current rewards: 141.27530, mean: 0.10784
[32m[0906 14-01-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03474, current rewards: 147.37982, mean: 0.10837
[32m[0906 14-01-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03474, current rewards: 153.39847, mean: 0.10879
[32m[0906 14-01-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03477, current rewards: 159.42061, mean: 0.10919
[32m[0906 14-01-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03479, current rewards: 165.45064, mean: 0.10957
[32m[0906 14-01-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03483, current rewards: 171.47588, mean: 0.10992
[32m[0906 14-01-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03488, current rewards: 177.49938, mean: 0.11025
[32m[0906 14-01-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03492, current rewards: 183.52307, mean: 0.11056
[32m[0906 14-01-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03496, current rewards: 189.54704, mean: 0.11085
[32m[0906 14-01-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03500, current rewards: 195.63119, mean: 0.11115
[32m[0906 14-01-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03504, current rewards: 201.58586, mean: 0.11137
[32m[0906 14-01-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03507, current rewards: 205.83771, mean: 0.11067
[32m[0906 14-01-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03510, current rewards: 211.47688, mean: 0.11072
[32m[0906 14-01-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03513, current rewards: 217.12185, mean: 0.11078
[32m[0906 14-01-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03515, current rewards: 222.76790, mean: 0.11083
[32m[0906 14-01-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03518, current rewards: 228.40985, mean: 0.11088
[32m[0906 14-01-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03520, current rewards: 234.05160, mean: 0.11092
[32m[0906 14-01-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03523, current rewards: 238.40160, mean: 0.11037
[32m[0906 14-01-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03525, current rewards: 243.79681, mean: 0.11032
[32m[0906 14-01-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03527, current rewards: 249.25429, mean: 0.11029
[32m[0906 14-02-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03530, current rewards: 254.71129, mean: 0.11026
[32m[0906 14-02-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03532, current rewards: 260.16597, mean: 0.11024
[32m[0906 14-02-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03533, current rewards: 265.61773, mean: 0.11021
[32m[0906 14-02-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03535, current rewards: 271.07137, mean: 0.11019
[32m[0906 14-02-07 @Agent.py:117][0m Average action selection time: 0.0354
[32m[0906 14-02-07 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-02-07 @MBExp.py:227][0m Rewards obtained: [275.43678894815895], Lows: [3], Highs: [4], Total time: 1081.8127749999999
[32m[0906 14-02-33 @MBExp.py:144][0m ####################################################################
[32m[0906 14-02-33 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 14-02-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03463, current rewards: -0.93826, mean: -0.09383
[32m[0906 14-02-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03521, current rewards: 5.07398, mean: 0.08457
[32m[0906 14-02-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03525, current rewards: 10.83812, mean: 0.09853
[32m[0906 14-02-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03520, current rewards: 16.64586, mean: 0.10404
[32m[0906 14-02-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03502, current rewards: 22.45869, mean: 0.10695
[32m[0906 14-02-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03499, current rewards: 28.26660, mean: 0.10872
[32m[0906 14-02-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03510, current rewards: 34.07384, mean: 0.10992
[32m[0906 14-02-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03513, current rewards: 39.88127, mean: 0.11078
[32m[0906 14-02-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03516, current rewards: 45.68656, mean: 0.11143
[32m[0906 14-02-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03519, current rewards: 47.21590, mean: 0.10264
[32m[0906 14-02-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03522, current rewards: 52.97816, mean: 0.10388
[32m[0906 14-02-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03526, current rewards: 58.71800, mean: 0.10485
[32m[0906 14-02-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03526, current rewards: 64.45506, mean: 0.10566
[32m[0906 14-02-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03523, current rewards: 70.19415, mean: 0.10635
[32m[0906 14-02-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03518, current rewards: 73.74587, mean: 0.10387
[32m[0906 14-03-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03511, current rewards: 79.55139, mean: 0.10467
[32m[0906 14-03-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03502, current rewards: 85.35211, mean: 0.10537
[32m[0906 14-03-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03494, current rewards: 91.15699, mean: 0.10600
[32m[0906 14-03-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03486, current rewards: 96.93540, mean: 0.10652
[32m[0906 14-03-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03481, current rewards: 102.56520, mean: 0.10684
[32m[0906 14-03-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03479, current rewards: 108.26848, mean: 0.10720
[32m[0906 14-03-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03477, current rewards: 113.97694, mean: 0.10753
[32m[0906 14-03-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03476, current rewards: 119.68257, mean: 0.10782
[32m[0906 14-03-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03475, current rewards: 123.31270, mean: 0.10630
[32m[0906 14-03-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03474, current rewards: 128.84618, mean: 0.10648
[32m[0906 14-03-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03474, current rewards: 134.38371, mean: 0.10665
[32m[0906 14-03-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03473, current rewards: 139.91910, mean: 0.10681
[32m[0906 14-03-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03472, current rewards: 145.36675, mean: 0.10689
[32m[0906 14-03-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03471, current rewards: 150.91794, mean: 0.10703
[32m[0906 14-03-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03470, current rewards: 156.46691, mean: 0.10717
[32m[0906 14-03-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03469, current rewards: 162.02052, mean: 0.10730
[32m[0906 14-03-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03470, current rewards: 167.57334, mean: 0.10742
[32m[0906 14-03-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03474, current rewards: 173.12902, mean: 0.10753
[32m[0906 14-03-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03479, current rewards: 178.68459, mean: 0.10764
[32m[0906 14-03-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03483, current rewards: 183.36985, mean: 0.10723
[32m[0906 14-03-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03487, current rewards: 189.25129, mean: 0.10753
[32m[0906 14-03-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03491, current rewards: 194.98297, mean: 0.10773
[32m[0906 14-03-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03494, current rewards: 200.72436, mean: 0.10792
[32m[0906 14-03-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03498, current rewards: 206.45382, mean: 0.10809
[32m[0906 14-03-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03501, current rewards: 212.19233, mean: 0.10826
[32m[0906 14-03-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03504, current rewards: 217.92469, mean: 0.10842
[32m[0906 14-03-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03507, current rewards: 223.65981, mean: 0.10857
[32m[0906 14-03-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03509, current rewards: 229.39537, mean: 0.10872
[32m[0906 14-03-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03512, current rewards: 235.07363, mean: 0.10883
[32m[0906 14-03-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03514, current rewards: 240.73236, mean: 0.10893
[32m[0906 14-03-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03517, current rewards: 245.46369, mean: 0.10861
[32m[0906 14-03-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03520, current rewards: 251.25934, mean: 0.10877
[32m[0906 14-03-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03522, current rewards: 257.06758, mean: 0.10893
[32m[0906 14-03-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03525, current rewards: 262.85850, mean: 0.10907
[32m[0906 14-04-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03527, current rewards: 268.66067, mean: 0.10921
[32m[0906 14-04-02 @Agent.py:117][0m Average action selection time: 0.0353
[32m[0906 14-04-02 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-04-02 @MBExp.py:227][0m Rewards obtained: [273.2968839846625], Lows: [3], Highs: [6], Total time: 1170.6741909999998
[32m[0906 14-04-31 @MBExp.py:144][0m ####################################################################
[32m[0906 14-04-31 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 14-04-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03537, current rewards: -0.03516, mean: -0.00352
[32m[0906 14-04-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03556, current rewards: 5.62006, mean: 0.09367
[32m[0906 14-04-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03548, current rewards: 11.22336, mean: 0.10203
[32m[0906 14-04-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03530, current rewards: 16.92305, mean: 0.10577
[32m[0906 14-04-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03510, current rewards: 22.62126, mean: 0.10772
[32m[0906 14-04-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03497, current rewards: 28.32864, mean: 0.10896
[32m[0906 14-04-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03489, current rewards: 34.02880, mean: 0.10977
[32m[0906 14-04-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03498, current rewards: 39.73135, mean: 0.11036
[32m[0906 14-04-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03503, current rewards: 45.43045, mean: 0.11081
[32m[0906 14-04-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03505, current rewards: 51.13273, mean: 0.11116
[32m[0906 14-04-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03509, current rewards: 57.01838, mean: 0.11180
[32m[0906 14-04-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03510, current rewards: 62.80389, mean: 0.11215
[32m[0906 14-04-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03510, current rewards: 67.39525, mean: 0.11048
[32m[0906 14-04-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03511, current rewards: 73.06995, mean: 0.11071
[32m[0906 14-04-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03512, current rewards: 78.74383, mean: 0.11091
[32m[0906 14-04-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03505, current rewards: 84.41762, mean: 0.11108
[32m[0906 14-05-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03497, current rewards: 90.09043, mean: 0.11122
[32m[0906 14-05-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03490, current rewards: 95.76546, mean: 0.11136
[32m[0906 14-05-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03482, current rewards: 101.43979, mean: 0.11147
[32m[0906 14-05-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03475, current rewards: 107.11504, mean: 0.11158
[32m[0906 14-05-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03469, current rewards: 112.78820, mean: 0.11167
[32m[0906 14-05-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03466, current rewards: 116.25313, mean: 0.10967
[32m[0906 14-05-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03466, current rewards: 121.69606, mean: 0.10964
[32m[0906 14-05-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03465, current rewards: 127.13794, mean: 0.10960
[32m[0906 14-05-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03463, current rewards: 129.11749, mean: 0.10671
[32m[0906 14-05-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03463, current rewards: 136.57769, mean: 0.10839
[32m[0906 14-05-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03463, current rewards: 144.03788, mean: 0.10995
[32m[0906 14-05-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03462, current rewards: 151.04990, mean: 0.11107
[32m[0906 14-05-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03461, current rewards: 157.97656, mean: 0.11204
[32m[0906 14-05-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03462, current rewards: 164.90322, mean: 0.11295
[32m[0906 14-05-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03461, current rewards: 171.82988, mean: 0.11379
[32m[0906 14-05-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03461, current rewards: 178.75653, mean: 0.11459
[32m[0906 14-05-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03460, current rewards: 185.68319, mean: 0.11533
[32m[0906 14-05-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03462, current rewards: 192.60985, mean: 0.11603
[32m[0906 14-05-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03466, current rewards: 156.27225, mean: 0.09139
[32m[0906 14-05-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03471, current rewards: 106.27225, mean: 0.06038
[32m[0906 14-05-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03475, current rewards: 56.27225, mean: 0.03109
[32m[0906 14-05-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03479, current rewards: 6.27225, mean: 0.00337
[32m[0906 14-05-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03483, current rewards: -43.72775, mean: -0.02289
[32m[0906 14-05-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03487, current rewards: -93.72775, mean: -0.04782
[32m[0906 14-05-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03491, current rewards: -143.72775, mean: -0.07151
[32m[0906 14-05-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03494, current rewards: -193.72775, mean: -0.09404
[32m[0906 14-05-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03497, current rewards: -243.72775, mean: -0.11551
[32m[0906 14-05-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03500, current rewards: -293.72775, mean: -0.13599
[32m[0906 14-05-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03503, current rewards: -343.72775, mean: -0.15553
[32m[0906 14-05-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03506, current rewards: -393.72775, mean: -0.17422
[32m[0906 14-05-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03508, current rewards: -443.72775, mean: -0.19209
[32m[0906 14-05-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03511, current rewards: -493.72775, mean: -0.20921
[32m[0906 14-05-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03513, current rewards: -543.72775, mean: -0.22561
[32m[0906 14-05-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03515, current rewards: -593.72775, mean: -0.24135
[32m[0906 14-06-00 @Agent.py:117][0m Average action selection time: 0.0352
[32m[0906 14-06-00 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-06-00 @MBExp.py:227][0m Rewards obtained: [-633.7277507033673], Lows: [3], Highs: [830], Total time: 1259.2412499999998
[32m[0906 14-06-31 @MBExp.py:144][0m ####################################################################
[32m[0906 14-06-31 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 14-06-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03560, current rewards: 0.11372, mean: 0.01137
[32m[0906 14-06-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03532, current rewards: 5.40077, mean: 0.09001
[32m[0906 14-06-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03530, current rewards: 10.46015, mean: 0.09509
[32m[0906 14-06-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03514, current rewards: 15.56691, mean: 0.09729
[32m[0906 14-06-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03502, current rewards: 20.67494, mean: 0.09845
[32m[0906 14-06-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03489, current rewards: 25.77876, mean: 0.09915
[32m[0906 14-06-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03483, current rewards: 30.88541, mean: 0.09963
[32m[0906 14-06-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03479, current rewards: 35.98944, mean: 0.09997
[32m[0906 14-06-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03486, current rewards: 41.09453, mean: 0.10023
[32m[0906 14-06-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03491, current rewards: 43.66400, mean: 0.09492
[32m[0906 14-06-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03497, current rewards: 48.28972, mean: 0.09469
[32m[0906 14-06-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03502, current rewards: 52.91068, mean: 0.09448
[32m[0906 14-06-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03506, current rewards: 57.52739, mean: 0.09431
[32m[0906 14-06-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03508, current rewards: 62.14717, mean: 0.09416
[32m[0906 14-06-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03510, current rewards: 66.76779, mean: 0.09404
[32m[0906 14-06-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03509, current rewards: 71.38788, mean: 0.09393
[32m[0906 14-06-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03502, current rewards: 76.01044, mean: 0.09384
[32m[0906 14-07-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03494, current rewards: 80.62721, mean: 0.09375
[32m[0906 14-07-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03486, current rewards: 85.24803, mean: 0.09368
[32m[0906 14-07-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03480, current rewards: 89.86564, mean: 0.09361
[32m[0906 14-07-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03474, current rewards: 94.48301, mean: 0.09355
[32m[0906 14-07-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03468, current rewards: 99.10405, mean: 0.09349
[32m[0906 14-07-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03467, current rewards: 103.72215, mean: 0.09344
[32m[0906 14-07-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03466, current rewards: 108.34092, mean: 0.09340
[32m[0906 14-07-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03466, current rewards: 112.96119, mean: 0.09336
[32m[0906 14-07-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03466, current rewards: 117.57788, mean: 0.09332
[32m[0906 14-07-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03465, current rewards: 122.28058, mean: 0.09334
[32m[0906 14-07-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03464, current rewards: 125.95451, mean: 0.09261
[32m[0906 14-07-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03465, current rewards: 130.60078, mean: 0.09262
[32m[0906 14-07-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03465, current rewards: 135.25108, mean: 0.09264
[32m[0906 14-07-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03464, current rewards: 139.89434, mean: 0.09265
[32m[0906 14-07-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03464, current rewards: 144.53711, mean: 0.09265
[32m[0906 14-07-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03463, current rewards: 149.18411, mean: 0.09266
[32m[0906 14-07-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03462, current rewards: 153.83173, mean: 0.09267
[32m[0906 14-07-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03464, current rewards: 158.45859, mean: 0.09267
[32m[0906 14-07-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03466, current rewards: 163.07615, mean: 0.09266
[32m[0906 14-07-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03469, current rewards: 167.69337, mean: 0.09265
[32m[0906 14-07-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03473, current rewards: 172.30844, mean: 0.09264
[32m[0906 14-07-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03477, current rewards: 176.92476, mean: 0.09263
[32m[0906 14-07-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03481, current rewards: 181.53741, mean: 0.09262
[32m[0906 14-07-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03485, current rewards: 186.42562, mean: 0.09275
[32m[0906 14-07-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03488, current rewards: 191.08007, mean: 0.09276
[32m[0906 14-07-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03492, current rewards: 195.79176, mean: 0.09279
[32m[0906 14-07-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03496, current rewards: 200.56304, mean: 0.09285
[32m[0906 14-07-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03498, current rewards: 205.33471, mean: 0.09291
[32m[0906 14-07-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03501, current rewards: 210.10347, mean: 0.09297
[32m[0906 14-07-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03503, current rewards: 214.87138, mean: 0.09302
[32m[0906 14-07-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03505, current rewards: 219.63824, mean: 0.09307
[32m[0906 14-07-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03508, current rewards: 224.40510, mean: 0.09311
[32m[0906 14-07-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03510, current rewards: 229.17302, mean: 0.09316
[32m[0906 14-07-59 @Agent.py:117][0m Average action selection time: 0.0351
[32m[0906 14-07-59 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-07-59 @MBExp.py:227][0m Rewards obtained: [232.98998723798357], Lows: [1], Highs: [2], Total time: 1347.6840019999997
[32m[0906 14-08-32 @MBExp.py:144][0m ####################################################################
[32m[0906 14-08-32 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 14-08-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03583, current rewards: -0.52328, mean: -0.05233
[32m[0906 14-08-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03563, current rewards: 5.25377, mean: 0.08756
[32m[0906 14-08-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03554, current rewards: 10.99893, mean: 0.09999
[32m[0906 14-08-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03532, current rewards: 16.75258, mean: 0.10470
[32m[0906 14-08-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03515, current rewards: 22.50680, mean: 0.10718
[32m[0906 14-08-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03505, current rewards: 28.26525, mean: 0.10871
[32m[0906 14-08-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03497, current rewards: 34.01162, mean: 0.10971
[32m[0906 14-08-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03491, current rewards: 39.76391, mean: 0.11046
[32m[0906 14-08-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03489, current rewards: 43.23529, mean: 0.10545
[32m[0906 14-08-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03490, current rewards: 48.72128, mean: 0.10592
[32m[0906 14-08-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03494, current rewards: 54.24775, mean: 0.10637
[32m[0906 14-08-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03501, current rewards: 59.77418, mean: 0.10674
[32m[0906 14-08-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03506, current rewards: 65.29762, mean: 0.10705
[32m[0906 14-08-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03509, current rewards: 70.81516, mean: 0.10730
[32m[0906 14-08-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03514, current rewards: 76.33555, mean: 0.10751
[32m[0906 14-08-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03513, current rewards: 81.85371, mean: 0.10770
[32m[0906 14-09-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03509, current rewards: 87.37646, mean: 0.10787
[32m[0906 14-09-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03502, current rewards: 92.88827, mean: 0.10801
[32m[0906 14-09-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03495, current rewards: 98.41700, mean: 0.10815
[32m[0906 14-09-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03488, current rewards: 103.95293, mean: 0.10828
[32m[0906 14-09-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03483, current rewards: 109.48333, mean: 0.10840
[32m[0906 14-09-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03479, current rewards: 115.01649, mean: 0.10851
[32m[0906 14-09-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03474, current rewards: 120.54790, mean: 0.10860
[32m[0906 14-09-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03470, current rewards: 124.14882, mean: 0.10702
[32m[0906 14-09-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03470, current rewards: 129.67473, mean: 0.10717
[32m[0906 14-09-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03469, current rewards: 135.25410, mean: 0.10734
[32m[0906 14-09-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03468, current rewards: 140.77232, mean: 0.10746
[32m[0906 14-09-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03467, current rewards: 146.29194, mean: 0.10757
[32m[0906 14-09-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03465, current rewards: 151.80923, mean: 0.10767
[32m[0906 14-09-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03465, current rewards: 157.32609, mean: 0.10776
[32m[0906 14-09-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03464, current rewards: 162.84268, mean: 0.10784
[32m[0906 14-09-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03464, current rewards: 168.36096, mean: 0.10792
[32m[0906 14-09-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03464, current rewards: 173.87779, mean: 0.10800
[32m[0906 14-09-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03463, current rewards: 179.32818, mean: 0.10803
[32m[0906 14-09-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03463, current rewards: 184.85793, mean: 0.10810
[32m[0906 14-09-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03463, current rewards: 190.38499, mean: 0.10817
[32m[0906 14-09-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03465, current rewards: 195.91027, mean: 0.10824
[32m[0906 14-09-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03468, current rewards: 201.43995, mean: 0.10830
[32m[0906 14-09-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03470, current rewards: 206.11356, mean: 0.10791
[32m[0906 14-09-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03474, current rewards: 211.66802, mean: 0.10799
[32m[0906 14-09-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03478, current rewards: 217.21188, mean: 0.10807
[32m[0906 14-09-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03482, current rewards: 222.77586, mean: 0.10814
[32m[0906 14-09-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03486, current rewards: 228.32418, mean: 0.10821
[32m[0906 14-09-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03490, current rewards: 233.87574, mean: 0.10828
[32m[0906 14-09-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03493, current rewards: 239.43768, mean: 0.10834
[32m[0906 14-09-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03496, current rewards: 244.99994, mean: 0.10841
[32m[0906 14-09-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03499, current rewards: 250.55827, mean: 0.10847
[32m[0906 14-09-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03501, current rewards: 253.55427, mean: 0.10744
[32m[0906 14-09-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03504, current rewards: 258.48890, mean: 0.10726
[32m[0906 14-09-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03507, current rewards: 263.42542, mean: 0.10708
[32m[0906 14-10-01 @Agent.py:117][0m Average action selection time: 0.0351
[32m[0906 14-10-01 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-10-01 @MBExp.py:227][0m Rewards obtained: [267.3688369807475], Lows: [3], Highs: [3], Total time: 1436.0431469999996
[32m[0906 14-10-36 @MBExp.py:144][0m ####################################################################
[32m[0906 14-10-36 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 14-10-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03566, current rewards: -1.02711, mean: -0.10271
[32m[0906 14-10-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03548, current rewards: 4.40464, mean: 0.07341
[32m[0906 14-10-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03546, current rewards: 9.83675, mean: 0.08943
[32m[0906 14-10-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03532, current rewards: 15.27256, mean: 0.09545
[32m[0906 14-10-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03510, current rewards: 20.70854, mean: 0.09861
[32m[0906 14-10-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03499, current rewards: 26.13980, mean: 0.10054
[32m[0906 14-10-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03490, current rewards: 31.57056, mean: 0.10184
[32m[0906 14-10-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03488, current rewards: 36.94184, mean: 0.10262
[32m[0906 14-10-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03485, current rewards: 42.29286, mean: 0.10315
[32m[0906 14-10-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03480, current rewards: 47.69621, mean: 0.10369
[32m[0906 14-10-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03480, current rewards: 53.10178, mean: 0.10412
[32m[0906 14-10-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03486, current rewards: 58.50460, mean: 0.10447
[32m[0906 14-10-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03490, current rewards: 63.90885, mean: 0.10477
[32m[0906 14-10-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03493, current rewards: 69.31511, mean: 0.10502
[32m[0906 14-11-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03498, current rewards: 72.61895, mean: 0.10228
[32m[0906 14-11-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03496, current rewards: 78.32306, mean: 0.10306
[32m[0906 14-11-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03493, current rewards: 84.46033, mean: 0.10427
[32m[0906 14-11-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03491, current rewards: 90.33046, mean: 0.10504
[32m[0906 14-11-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03488, current rewards: 96.20169, mean: 0.10572
[32m[0906 14-11-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03482, current rewards: 102.07457, mean: 0.10633
[32m[0906 14-11-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03476, current rewards: 107.94475, mean: 0.10688
[32m[0906 14-11-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03471, current rewards: 113.81158, mean: 0.10737
[32m[0906 14-11-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03466, current rewards: 119.68069, mean: 0.10782
[32m[0906 14-11-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03462, current rewards: 125.54628, mean: 0.10823
[32m[0906 14-11-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03459, current rewards: 131.40421, mean: 0.10860
[32m[0906 14-11-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03459, current rewards: 135.98704, mean: 0.10793
[32m[0906 14-11-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03459, current rewards: 141.39782, mean: 0.10794
[32m[0906 14-11-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03459, current rewards: 146.80342, mean: 0.10794
[32m[0906 14-11-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03459, current rewards: 152.20544, mean: 0.10795
[32m[0906 14-11-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03459, current rewards: 153.54334, mean: 0.10517
[32m[0906 14-11-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03459, current rewards: 159.34578, mean: 0.10553
[32m[0906 14-11-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03459, current rewards: 165.14101, mean: 0.10586
[32m[0906 14-11-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03459, current rewards: 170.59858, mean: 0.10596
[32m[0906 14-11-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03459, current rewards: 175.71030, mean: 0.10585
[32m[0906 14-11-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03459, current rewards: 181.16954, mean: 0.10595
[32m[0906 14-11-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03459, current rewards: 186.62993, mean: 0.10604
[32m[0906 14-11-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03459, current rewards: 192.08912, mean: 0.10613
[32m[0906 14-11-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03462, current rewards: 197.54858, mean: 0.10621
[32m[0906 14-11-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03464, current rewards: 200.81963, mean: 0.10514
[32m[0906 14-11-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03466, current rewards: 206.35690, mean: 0.10528
[32m[0906 14-11-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03468, current rewards: 211.89789, mean: 0.10542
[32m[0906 14-11-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03471, current rewards: 217.56636, mean: 0.10561
[32m[0906 14-11-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03476, current rewards: 223.11115, mean: 0.10574
[32m[0906 14-11-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03479, current rewards: 228.65966, mean: 0.10586
[32m[0906 14-11-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03482, current rewards: 234.20819, mean: 0.10598
[32m[0906 14-11-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03485, current rewards: 239.75734, mean: 0.10609
[32m[0906 14-11-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03488, current rewards: 243.32175, mean: 0.10533
[32m[0906 14-11-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03491, current rewards: 248.80665, mean: 0.10543
[32m[0906 14-12-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03494, current rewards: 254.29123, mean: 0.10552
[32m[0906 14-12-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03497, current rewards: 259.76611, mean: 0.10560
[32m[0906 14-12-04 @Agent.py:117][0m Average action selection time: 0.0350
[32m[0906 14-12-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-12-04 @MBExp.py:227][0m Rewards obtained: [264.15034834573953], Lows: [4], Highs: [5], Total time: 1524.1766899999996
[32m[0906 14-12-41 @MBExp.py:144][0m ####################################################################
[32m[0906 14-12-41 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 14-12-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03465, current rewards: -0.51962, mean: -0.05196
[32m[0906 14-12-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03533, current rewards: 5.16475, mean: 0.08608
[32m[0906 14-12-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03536, current rewards: 10.63783, mean: 0.09671
[32m[0906 14-12-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03530, current rewards: 16.11364, mean: 0.10071
[32m[0906 14-12-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03511, current rewards: 21.58450, mean: 0.10278
[32m[0906 14-12-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03503, current rewards: 27.05529, mean: 0.10406
[32m[0906 14-12-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03490, current rewards: 31.43601, mean: 0.10141
[32m[0906 14-12-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03486, current rewards: 36.87106, mean: 0.10242
[32m[0906 14-12-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03479, current rewards: 42.09906, mean: 0.10268
[32m[0906 14-12-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03476, current rewards: 47.53219, mean: 0.10333
[32m[0906 14-12-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03473, current rewards: 52.95580, mean: 0.10383
[32m[0906 14-13-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03473, current rewards: 58.38670, mean: 0.10426
[32m[0906 14-13-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03479, current rewards: 63.81644, mean: 0.10462
[32m[0906 14-13-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03483, current rewards: 69.24013, mean: 0.10491
[32m[0906 14-13-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03487, current rewards: 74.67005, mean: 0.10517
[32m[0906 14-13-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03487, current rewards: 80.09914, mean: 0.10539
[32m[0906 14-13-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03486, current rewards: 83.68077, mean: 0.10331
[32m[0906 14-13-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03484, current rewards: 89.24678, mean: 0.10378
[32m[0906 14-13-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03483, current rewards: 94.80045, mean: 0.10418
[32m[0906 14-13-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03480, current rewards: 100.35493, mean: 0.10454
[32m[0906 14-13-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03476, current rewards: 105.91654, mean: 0.10487
[32m[0906 14-13-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03471, current rewards: 111.47186, mean: 0.10516
[32m[0906 14-13-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03467, current rewards: 117.03090, mean: 0.10543
[32m[0906 14-13-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03462, current rewards: 122.58871, mean: 0.10568
[32m[0906 14-13-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03458, current rewards: 128.14552, mean: 0.10591
[32m[0906 14-13-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03455, current rewards: 133.64297, mean: 0.10607
[32m[0906 14-13-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03453, current rewards: 139.25648, mean: 0.10630
[32m[0906 14-13-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03454, current rewards: 143.65204, mean: 0.10563
[32m[0906 14-13-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03454, current rewards: 149.10240, mean: 0.10575
[32m[0906 14-13-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03454, current rewards: 154.54831, mean: 0.10586
[32m[0906 14-13-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03454, current rewards: 159.99784, mean: 0.10596
[32m[0906 14-13-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03453, current rewards: 165.44785, mean: 0.10606
[32m[0906 14-13-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03453, current rewards: 170.89506, mean: 0.10615
[32m[0906 14-13-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03453, current rewards: 176.51166, mean: 0.10633
[32m[0906 14-13-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03453, current rewards: 182.00457, mean: 0.10644
[32m[0906 14-13-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03453, current rewards: 187.49693, mean: 0.10653
[32m[0906 14-13-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03453, current rewards: 192.99054, mean: 0.10662
[32m[0906 14-13-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03453, current rewards: 194.40957, mean: 0.10452
[32m[0906 14-13-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03455, current rewards: 199.92357, mean: 0.10467
[32m[0906 14-13-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03457, current rewards: 205.43229, mean: 0.10481
[32m[0906 14-13-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03460, current rewards: 210.94272, mean: 0.10495
[32m[0906 14-13-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03462, current rewards: 216.34158, mean: 0.10502
[32m[0906 14-13-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03464, current rewards: 220.12699, mean: 0.10433
[32m[0906 14-13-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03466, current rewards: 225.63139, mean: 0.10446
[32m[0906 14-13-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03469, current rewards: 231.13137, mean: 0.10458
[32m[0906 14-14-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03472, current rewards: 236.63502, mean: 0.10471
[32m[0906 14-14-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03476, current rewards: 242.13851, mean: 0.10482
[32m[0906 14-14-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03479, current rewards: 247.64375, mean: 0.10493
[32m[0906 14-14-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03483, current rewards: 253.14876, mean: 0.10504
[32m[0906 14-14-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03486, current rewards: 258.63679, mean: 0.10514
[32m[0906 14-14-09 @Agent.py:117][0m Average action selection time: 0.0349
[32m[0906 14-14-09 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-14-09 @MBExp.py:227][0m Rewards obtained: [263.0077852683173], Lows: [4], Highs: [4], Total time: 1612.0214319999995
[32m[0906 14-14-48 @MBExp.py:144][0m ####################################################################
[32m[0906 14-14-48 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 14-14-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03458, current rewards: 1.00637, mean: 0.10064
[32m[0906 14-14-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03529, current rewards: 6.50281, mean: 0.10838
[32m[0906 14-14-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03531, current rewards: 11.99724, mean: 0.10907
[32m[0906 14-14-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03530, current rewards: 17.49212, mean: 0.10933
[32m[0906 14-14-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03515, current rewards: 22.98735, mean: 0.10946
[32m[0906 14-14-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03504, current rewards: 28.48084, mean: 0.10954
[32m[0906 14-14-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03496, current rewards: 33.97490, mean: 0.10960
[32m[0906 14-15-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03489, current rewards: 39.46642, mean: 0.10963
[32m[0906 14-15-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03485, current rewards: 45.00359, mean: 0.10976
[32m[0906 14-15-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03484, current rewards: 50.50108, mean: 0.10978
[32m[0906 14-15-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03481, current rewards: 55.99998, mean: 0.10980
[32m[0906 14-15-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03478, current rewards: 59.28455, mean: 0.10587
[32m[0906 14-15-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03476, current rewards: 64.51918, mean: 0.10577
[32m[0906 14-15-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03480, current rewards: 69.76212, mean: 0.10570
[32m[0906 14-15-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03485, current rewards: 75.00428, mean: 0.10564
[32m[0906 14-15-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03485, current rewards: 80.24317, mean: 0.10558
[32m[0906 14-15-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03483, current rewards: 85.57624, mean: 0.10565
[32m[0906 14-15-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03482, current rewards: 90.86935, mean: 0.10566
[32m[0906 14-15-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03482, current rewards: 95.11749, mean: 0.10452
[32m[0906 14-15-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03479, current rewards: 100.47431, mean: 0.10466
[32m[0906 14-15-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03478, current rewards: 105.83013, mean: 0.10478
[32m[0906 14-15-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03475, current rewards: 109.50469, mean: 0.10331
[32m[0906 14-15-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03471, current rewards: 114.83613, mean: 0.10346
[32m[0906 14-15-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03466, current rewards: 120.16870, mean: 0.10359
[32m[0906 14-15-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03463, current rewards: 125.28271, mean: 0.10354
[32m[0906 14-15-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03459, current rewards: 130.51446, mean: 0.10358
[32m[0906 14-15-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03456, current rewards: 135.74381, mean: 0.10362
[32m[0906 14-15-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03455, current rewards: 140.97381, mean: 0.10366
[32m[0906 14-15-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03455, current rewards: 146.20520, mean: 0.10369
[32m[0906 14-15-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03455, current rewards: 151.43564, mean: 0.10372
[32m[0906 14-15-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03455, current rewards: 156.66387, mean: 0.10375
[32m[0906 14-15-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03454, current rewards: 160.82512, mean: 0.10309
[32m[0906 14-15-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03455, current rewards: 166.26844, mean: 0.10327
[32m[0906 14-15-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03454, current rewards: 171.81918, mean: 0.10351
[32m[0906 14-15-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03455, current rewards: 177.22942, mean: 0.10364
[32m[0906 14-15-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03455, current rewards: 182.64043, mean: 0.10377
[32m[0906 14-15-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03455, current rewards: 188.05308, mean: 0.10390
[32m[0906 14-15-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03456, current rewards: 193.46354, mean: 0.10401
[32m[0906 14-15-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03456, current rewards: 198.82154, mean: 0.10410
[32m[0906 14-15-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03457, current rewards: 204.68831, mean: 0.10443
[32m[0906 14-15-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03460, current rewards: 210.58213, mean: 0.10477
[32m[0906 14-16-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03462, current rewards: 216.32491, mean: 0.10501
[32m[0906 14-16-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03465, current rewards: 222.15330, mean: 0.10529
[32m[0906 14-16-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03466, current rewards: 227.99501, mean: 0.10555
[32m[0906 14-16-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03468, current rewards: 233.82233, mean: 0.10580
[32m[0906 14-16-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03469, current rewards: 239.65836, mean: 0.10604
[32m[0906 14-16-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03472, current rewards: 245.49624, mean: 0.10628
[32m[0906 14-16-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03476, current rewards: 251.32428, mean: 0.10649
[32m[0906 14-16-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03479, current rewards: 257.15286, mean: 0.10670
[32m[0906 14-16-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03482, current rewards: 262.89992, mean: 0.10687
[32m[0906 14-16-16 @Agent.py:117][0m Average action selection time: 0.0348
[32m[0906 14-16-16 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-16-16 @MBExp.py:227][0m Rewards obtained: [267.5155519753247], Lows: [1], Highs: [4], Total time: 1699.7606379999995
[32m[0906 14-16-58 @MBExp.py:144][0m ####################################################################
[32m[0906 14-16-58 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 14-16-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03456, current rewards: 1.06174, mean: 0.10617
[32m[0906 14-17-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03517, current rewards: 6.55689, mean: 0.10928
[32m[0906 14-17-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03523, current rewards: 12.05434, mean: 0.10958
[32m[0906 14-17-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03532, current rewards: 17.55144, mean: 0.10970
[32m[0906 14-17-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03512, current rewards: 23.04835, mean: 0.10975
[32m[0906 14-17-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03498, current rewards: 28.54459, mean: 0.10979
[32m[0906 14-17-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03495, current rewards: 34.04286, mean: 0.10982
[32m[0906 14-17-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03489, current rewards: 39.41208, mean: 0.10948
[32m[0906 14-17-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03482, current rewards: 42.76818, mean: 0.10431
[32m[0906 14-17-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03478, current rewards: 48.25384, mean: 0.10490
[32m[0906 14-17-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03475, current rewards: 53.73499, mean: 0.10536
[32m[0906 14-17-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03473, current rewards: 59.21275, mean: 0.10574
[32m[0906 14-17-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03470, current rewards: 64.69264, mean: 0.10605
[32m[0906 14-17-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03469, current rewards: 70.17358, mean: 0.10632
[32m[0906 14-17-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03472, current rewards: 75.65495, mean: 0.10656
[32m[0906 14-17-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03473, current rewards: 81.15310, mean: 0.10678
[32m[0906 14-17-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03471, current rewards: 86.62976, mean: 0.10695
[32m[0906 14-17-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03471, current rewards: 90.03990, mean: 0.10470
[32m[0906 14-17-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03470, current rewards: 95.46706, mean: 0.10491
[32m[0906 14-17-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03469, current rewards: 100.88706, mean: 0.10509
[32m[0906 14-17-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03467, current rewards: 106.31036, mean: 0.10526
[32m[0906 14-17-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03467, current rewards: 111.73359, mean: 0.10541
[32m[0906 14-17-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03466, current rewards: 117.15676, mean: 0.10555
[32m[0906 14-17-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03462, current rewards: 122.58621, mean: 0.10568
[32m[0906 14-17-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03458, current rewards: 128.12307, mean: 0.10589
[32m[0906 14-17-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03454, current rewards: 133.54795, mean: 0.10599
[32m[0906 14-17-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03451, current rewards: 137.85836, mean: 0.10524
[32m[0906 14-17-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03448, current rewards: 143.36827, mean: 0.10542
[32m[0906 14-17-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03445, current rewards: 148.86844, mean: 0.10558
[32m[0906 14-17-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03445, current rewards: 154.36946, mean: 0.10573
[32m[0906 14-17-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03445, current rewards: 159.87604, mean: 0.10588
[32m[0906 14-17-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03445, current rewards: 165.38153, mean: 0.10601
[32m[0906 14-17-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03445, current rewards: 170.94026, mean: 0.10617
[32m[0906 14-17-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03445, current rewards: 176.36962, mean: 0.10625
[32m[0906 14-17-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03446, current rewards: 181.79106, mean: 0.10631
[32m[0906 14-17-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03447, current rewards: 187.21868, mean: 0.10637
[32m[0906 14-18-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03447, current rewards: 192.64363, mean: 0.10643
[32m[0906 14-18-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03447, current rewards: 198.07275, mean: 0.10649
[32m[0906 14-18-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03448, current rewards: 203.49761, mean: 0.10654
[32m[0906 14-18-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03448, current rewards: 208.92037, mean: 0.10659
[32m[0906 14-18-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03450, current rewards: 214.38221, mean: 0.10666
[32m[0906 14-18-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03452, current rewards: 219.81067, mean: 0.10670
[32m[0906 14-18-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03454, current rewards: 221.39433, mean: 0.10493
[32m[0906 14-18-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03456, current rewards: 227.17260, mean: 0.10517
[32m[0906 14-18-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03458, current rewards: 232.95685, mean: 0.10541
[32m[0906 14-18-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03460, current rewards: 236.88331, mean: 0.10482
[32m[0906 14-18-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03462, current rewards: 242.40857, mean: 0.10494
[32m[0906 14-18-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03464, current rewards: 247.89098, mean: 0.10504
[32m[0906 14-18-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03466, current rewards: 253.23887, mean: 0.10508
[32m[0906 14-18-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03470, current rewards: 258.66039, mean: 0.10515
[32m[0906 14-18-25 @Agent.py:117][0m Average action selection time: 0.0347
[32m[0906 14-18-25 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-18-25 @MBExp.py:227][0m Rewards obtained: [262.9991445976693], Lows: [4], Highs: [3], Total time: 1787.2164599999994
[32m[0906 14-19-08 @MBExp.py:144][0m ####################################################################
[32m[0906 14-19-08 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 14-19-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03517, current rewards: -2.18673, mean: -0.21867
[32m[0906 14-19-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03531, current rewards: 3.46994, mean: 0.05783
[32m[0906 14-19-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03529, current rewards: 9.04614, mean: 0.08224
[32m[0906 14-19-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03542, current rewards: 14.62126, mean: 0.09138
[32m[0906 14-19-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03523, current rewards: 20.19744, mean: 0.09618
[32m[0906 14-19-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03506, current rewards: 25.76991, mean: 0.09912
[32m[0906 14-19-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03494, current rewards: 29.25517, mean: 0.09437
[32m[0906 14-19-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03485, current rewards: 35.02190, mean: 0.09728
[32m[0906 14-19-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03480, current rewards: 40.76899, mean: 0.09944
[32m[0906 14-19-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03476, current rewards: 46.50500, mean: 0.10110
[32m[0906 14-19-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03475, current rewards: 52.25386, mean: 0.10246
[32m[0906 14-19-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03473, current rewards: 57.99785, mean: 0.10357
[32m[0906 14-19-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03471, current rewards: 63.74460, mean: 0.10450
[32m[0906 14-19-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03470, current rewards: 69.48903, mean: 0.10529
[32m[0906 14-19-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03468, current rewards: 75.22967, mean: 0.10596
[32m[0906 14-19-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03465, current rewards: 80.97630, mean: 0.10655
[32m[0906 14-19-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03464, current rewards: 84.59287, mean: 0.10444
[32m[0906 14-19-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03464, current rewards: 90.10186, mean: 0.10477
[32m[0906 14-19-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03463, current rewards: 95.60807, mean: 0.10506
[32m[0906 14-19-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03463, current rewards: 101.12185, mean: 0.10534
[32m[0906 14-19-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03463, current rewards: 106.63063, mean: 0.10557
[32m[0906 14-19-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03462, current rewards: 112.13553, mean: 0.10579
[32m[0906 14-19-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03461, current rewards: 117.64167, mean: 0.10598
[32m[0906 14-19-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03460, current rewards: 122.93002, mean: 0.10597
[32m[0906 14-19-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03456, current rewards: 128.27813, mean: 0.10601
[32m[0906 14-19-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03453, current rewards: 133.62540, mean: 0.10605
[32m[0906 14-19-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03450, current rewards: 138.97241, mean: 0.10609
[32m[0906 14-19-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03447, current rewards: 144.31776, mean: 0.10612
[32m[0906 14-19-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03444, current rewards: 149.65815, mean: 0.10614
[32m[0906 14-19-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03442, current rewards: 155.00940, mean: 0.10617
[32m[0906 14-20-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03440, current rewards: 160.36174, mean: 0.10620
[32m[0906 14-20-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03441, current rewards: 163.71035, mean: 0.10494
[32m[0906 14-20-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03442, current rewards: 169.45115, mean: 0.10525
[32m[0906 14-20-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03442, current rewards: 175.18779, mean: 0.10553
[32m[0906 14-20-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03443, current rewards: 180.92252, mean: 0.10580
[32m[0906 14-20-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03444, current rewards: 186.66017, mean: 0.10606
[32m[0906 14-20-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03445, current rewards: 192.39753, mean: 0.10630
[32m[0906 14-20-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03445, current rewards: 198.13431, mean: 0.10652
[32m[0906 14-20-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03445, current rewards: 203.52859, mean: 0.10656
[32m[0906 14-20-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03445, current rewards: 208.87645, mean: 0.10657
[32m[0906 14-20-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03446, current rewards: 214.23335, mean: 0.10658
[32m[0906 14-20-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03446, current rewards: 219.58836, mean: 0.10660
[32m[0906 14-20-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03449, current rewards: 224.94804, mean: 0.10661
[32m[0906 14-20-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03451, current rewards: 230.31349, mean: 0.10663
[32m[0906 14-20-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03454, current rewards: 235.66927, mean: 0.10664
[32m[0906 14-20-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03455, current rewards: 238.93374, mean: 0.10572
[32m[0906 14-20-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03458, current rewards: 244.33563, mean: 0.10577
[32m[0906 14-20-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03460, current rewards: 249.78793, mean: 0.10584
[32m[0906 14-20-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03462, current rewards: 255.03590, mean: 0.10582
[32m[0906 14-20-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03463, current rewards: 260.27946, mean: 0.10580
[32m[0906 14-20-36 @Agent.py:117][0m Average action selection time: 0.0346
[32m[0906 14-20-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-20-36 @MBExp.py:227][0m Rewards obtained: [264.47778964509314], Lows: [3], Highs: [5], Total time: 1874.4800119999995
[32m[0906 14-21-21 @MBExp.py:144][0m ####################################################################
[32m[0906 14-21-21 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 14-21-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03523, current rewards: 0.08123, mean: 0.00812
[32m[0906 14-21-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03515, current rewards: 5.62556, mean: 0.09376
[32m[0906 14-21-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03530, current rewards: 11.16504, mean: 0.10150
[32m[0906 14-21-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03531, current rewards: 16.70643, mean: 0.10442
[32m[0906 14-21-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03520, current rewards: 19.63874, mean: 0.09352
[32m[0906 14-21-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03504, current rewards: 28.61549, mean: 0.11006
[32m[0906 14-21-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03497, current rewards: -8.66831, mean: -0.02796
[32m[0906 14-21-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03487, current rewards: -58.66831, mean: -0.16297
[32m[0906 14-21-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03483, current rewards: -108.66831, mean: -0.26504
[32m[0906 14-21-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03480, current rewards: -158.66831, mean: -0.34493
[32m[0906 14-21-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03477, current rewards: -208.66831, mean: -0.40915
[32m[0906 14-21-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03474, current rewards: -258.66831, mean: -0.46191
[32m[0906 14-21-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03471, current rewards: -308.66831, mean: -0.50601
[32m[0906 14-21-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03469, current rewards: -358.66831, mean: -0.54344
[32m[0906 14-21-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03466, current rewards: -379.38240, mean: -0.53434
[32m[0906 14-21-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03463, current rewards: -373.46453, mean: -0.49140
[32m[0906 14-21-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03458, current rewards: -418.99110, mean: -0.51727
[32m[0906 14-21-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03458, current rewards: -468.99110, mean: -0.54534
[32m[0906 14-21-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03457, current rewards: -518.99110, mean: -0.57032
[32m[0906 14-21-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03456, current rewards: -568.99110, mean: -0.59270
[32m[0906 14-21-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03456, current rewards: -618.99110, mean: -0.61286
[32m[0906 14-21-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03455, current rewards: -668.99110, mean: -0.63112
[32m[0906 14-22-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03455, current rewards: -718.99110, mean: -0.64774
[32m[0906 14-22-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03455, current rewards: -768.99110, mean: -0.66292
[32m[0906 14-22-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03455, current rewards: -818.99110, mean: -0.67685
[32m[0906 14-22-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03452, current rewards: -868.99110, mean: -0.68968
[32m[0906 14-22-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03449, current rewards: -918.99110, mean: -0.70152
[32m[0906 14-22-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03447, current rewards: -968.99110, mean: -0.71249
[32m[0906 14-22-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03444, current rewards: -1018.99110, mean: -0.72269
[32m[0906 14-22-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03440, current rewards: -1068.99110, mean: -0.73219
[32m[0906 14-22-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03438, current rewards: -1118.99110, mean: -0.74105
[32m[0906 14-22-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03435, current rewards: -1168.99110, mean: -0.74935
[32m[0906 14-22-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03435, current rewards: -1218.99110, mean: -0.75714
[32m[0906 14-22-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03435, current rewards: -1268.99110, mean: -0.76445
[32m[0906 14-22-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03436, current rewards: -1318.99110, mean: -0.77134
[32m[0906 14-22-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03436, current rewards: -1368.99110, mean: -0.77784
[32m[0906 14-22-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03437, current rewards: -1418.99110, mean: -0.78397
[32m[0906 14-22-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03437, current rewards: -1468.99110, mean: -0.78978
[32m[0906 14-22-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03436, current rewards: -1518.99110, mean: -0.79528
[32m[0906 14-22-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03437, current rewards: -1568.99110, mean: -0.80051
[32m[0906 14-22-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03437, current rewards: -1618.99110, mean: -0.80547
[32m[0906 14-22-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03438, current rewards: -1668.99110, mean: -0.81019
[32m[0906 14-22-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03438, current rewards: -1718.99110, mean: -0.81469
[32m[0906 14-22-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03441, current rewards: -1768.99110, mean: -0.81898
[32m[0906 14-22-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03443, current rewards: -1818.99110, mean: -0.82307
[32m[0906 14-22-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03445, current rewards: -1868.99110, mean: -0.82699
[32m[0906 14-22-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03447, current rewards: -1918.99110, mean: -0.83073
[32m[0906 14-22-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03449, current rewards: -1968.99110, mean: -0.83432
[32m[0906 14-22-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03451, current rewards: -2018.99110, mean: -0.83776
[32m[0906 14-22-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03452, current rewards: -2068.99110, mean: -0.84105
[32m[0906 14-22-48 @Agent.py:117][0m Average action selection time: 0.0345
[32m[0906 14-22-48 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-22-48 @MBExp.py:227][0m Rewards obtained: [-2108.9910996609065], Lows: [2], Highs: [2148], Total time: 1961.4680069999995
[32m[0906 14-23-36 @MBExp.py:144][0m ####################################################################
[32m[0906 14-23-36 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 14-23-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03469, current rewards: -2.22498, mean: -0.22250
[32m[0906 14-23-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03521, current rewards: 2.97520, mean: 0.04959
[32m[0906 14-23-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03533, current rewards: 8.17492, mean: 0.07432
[32m[0906 14-23-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03534, current rewards: 13.37293, mean: 0.08358
[32m[0906 14-23-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03533, current rewards: 18.57172, mean: 0.08844
[32m[0906 14-23-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03516, current rewards: 24.10334, mean: 0.09271
[32m[0906 14-23-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03503, current rewards: 30.86742, mean: 0.09957
[32m[0906 14-23-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03497, current rewards: 37.63146, mean: 0.10453
[32m[0906 14-23-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03490, current rewards: 44.39550, mean: 0.10828
[32m[0906 14-23-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03484, current rewards: 51.15953, mean: 0.11122
[32m[0906 14-23-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03481, current rewards: 57.92357, mean: 0.11358
[32m[0906 14-23-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03477, current rewards: 24.95278, mean: 0.04456
[32m[0906 14-23-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03474, current rewards: -25.04722, mean: -0.04106
[32m[0906 14-23-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03473, current rewards: -75.04722, mean: -0.11371
[32m[0906 14-24-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03471, current rewards: -125.04722, mean: -0.17612
[32m[0906 14-24-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03469, current rewards: -175.04722, mean: -0.23033
[32m[0906 14-24-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03462, current rewards: -225.04722, mean: -0.27784
[32m[0906 14-24-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03456, current rewards: -275.04722, mean: -0.31982
[32m[0906 14-24-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03455, current rewards: -325.04722, mean: -0.35719
[32m[0906 14-24-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03455, current rewards: -375.04722, mean: -0.39067
[32m[0906 14-24-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03454, current rewards: -425.04722, mean: -0.42084
[32m[0906 14-24-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03454, current rewards: -475.04722, mean: -0.44816
[32m[0906 14-24-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03453, current rewards: -525.04722, mean: -0.47302
[32m[0906 14-24-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03454, current rewards: -575.04722, mean: -0.49573
[32m[0906 14-24-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03454, current rewards: -625.04722, mean: -0.51657
[32m[0906 14-24-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03453, current rewards: -675.04722, mean: -0.53575
[32m[0906 14-24-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03453, current rewards: -725.04722, mean: -0.55347
[32m[0906 14-24-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03450, current rewards: -775.04722, mean: -0.56989
[32m[0906 14-24-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03447, current rewards: -825.04722, mean: -0.58514
[32m[0906 14-24-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03446, current rewards: -875.04722, mean: -0.59935
[32m[0906 14-24-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03443, current rewards: -925.04722, mean: -0.61261
[32m[0906 14-24-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03441, current rewards: -975.04722, mean: -0.62503
[32m[0906 14-24-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03438, current rewards: -1025.04722, mean: -0.63668
[32m[0906 14-24-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03437, current rewards: -1075.04722, mean: -0.64762
[32m[0906 14-24-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03438, current rewards: -1125.04722, mean: -0.65792
[32m[0906 14-24-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03439, current rewards: -1175.04722, mean: -0.66764
[32m[0906 14-24-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03439, current rewards: -1225.04722, mean: -0.67682
[32m[0906 14-24-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03439, current rewards: -1275.04722, mean: -0.68551
[32m[0906 14-24-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03439, current rewards: -1325.04722, mean: -0.69374
[32m[0906 14-24-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03440, current rewards: -1375.04722, mean: -0.70155
[32m[0906 14-24-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03440, current rewards: -1425.04722, mean: -0.70898
[32m[0906 14-24-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03440, current rewards: -1475.04722, mean: -0.71604
[32m[0906 14-24-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03441, current rewards: -1525.04722, mean: -0.72277
[32m[0906 14-24-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03441, current rewards: -1575.04722, mean: -0.72919
[32m[0906 14-24-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03442, current rewards: -1625.04722, mean: -0.73532
[32m[0906 14-24-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03444, current rewards: -1675.04722, mean: -0.74117
[32m[0906 14-24-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03446, current rewards: -1725.04722, mean: -0.74677
[32m[0906 14-24-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03448, current rewards: -1775.04722, mean: -0.75214
[32m[0906 14-24-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03450, current rewards: -1825.04722, mean: -0.75728
[32m[0906 14-25-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03452, current rewards: -1875.04722, mean: -0.76221
[32m[0906 14-25-03 @Agent.py:117][0m Average action selection time: 0.0345
[32m[0906 14-25-03 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-25-03 @MBExp.py:227][0m Rewards obtained: [-1915.0472165727313], Lows: [0], Highs: [1978], Total time: 2048.4592649999995
[32m[0906 14-25-52 @MBExp.py:144][0m ####################################################################
[32m[0906 14-25-52 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 14-25-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03558, current rewards: -0.03198, mean: -0.00320
[32m[0906 14-25-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03545, current rewards: 5.43304, mean: 0.09055
[32m[0906 14-25-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03548, current rewards: 10.90282, mean: 0.09912
[32m[0906 14-25-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03545, current rewards: 16.36066, mean: 0.10225
[32m[0906 14-26-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03546, current rewards: 21.83767, mean: 0.10399
[32m[0906 14-26-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03537, current rewards: 27.30515, mean: 0.10502
[32m[0906 14-26-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03522, current rewards: 32.76782, mean: 0.10570
[32m[0906 14-26-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03512, current rewards: 38.23477, mean: 0.10621
[32m[0906 14-26-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03504, current rewards: 43.69829, mean: 0.10658
[32m[0906 14-26-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03499, current rewards: 49.16638, mean: 0.10688
[32m[0906 14-26-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03495, current rewards: 54.62402, mean: 0.10711
[32m[0906 14-26-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03490, current rewards: 60.07835, mean: 0.10728
[32m[0906 14-26-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03488, current rewards: 65.50132, mean: 0.10738
[32m[0906 14-26-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03486, current rewards: 68.84715, mean: 0.10431
[32m[0906 14-26-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03484, current rewards: 74.36437, mean: 0.10474
[32m[0906 14-26-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03482, current rewards: 79.88621, mean: 0.10511
[32m[0906 14-26-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03474, current rewards: 85.40273, mean: 0.10544
[32m[0906 14-26-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03468, current rewards: 90.91968, mean: 0.10572
[32m[0906 14-26-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03463, current rewards: 96.43697, mean: 0.10597
[32m[0906 14-26-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03457, current rewards: 101.95218, mean: 0.10620
[32m[0906 14-26-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03457, current rewards: 107.61926, mean: 0.10655
[32m[0906 14-26-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03457, current rewards: 113.19266, mean: 0.10679
[32m[0906 14-26-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03456, current rewards: 118.72151, mean: 0.10696
[32m[0906 14-26-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03456, current rewards: 124.24862, mean: 0.10711
[32m[0906 14-26-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03456, current rewards: 128.44732, mean: 0.10615
[32m[0906 14-26-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03456, current rewards: 134.28333, mean: 0.10657
[32m[0906 14-26-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03456, current rewards: 140.11932, mean: 0.10696
[32m[0906 14-26-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03456, current rewards: 145.95531, mean: 0.10732
[32m[0906 14-26-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03453, current rewards: 147.07724, mean: 0.10431
[32m[0906 14-26-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03451, current rewards: 152.63282, mean: 0.10454
[32m[0906 14-26-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03448, current rewards: 158.16686, mean: 0.10475
[32m[0906 14-26-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03446, current rewards: 163.69963, mean: 0.10494
[32m[0906 14-26-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03443, current rewards: 169.23186, mean: 0.10511
[32m[0906 14-26-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03441, current rewards: 174.69784, mean: 0.10524
[32m[0906 14-26-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03439, current rewards: 180.21221, mean: 0.10539
[32m[0906 14-26-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03439, current rewards: 185.73064, mean: 0.10553
[32m[0906 14-26-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03440, current rewards: 191.24794, mean: 0.10566
[32m[0906 14-26-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03441, current rewards: 196.63457, mean: 0.10572
[32m[0906 14-26-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03441, current rewards: 202.12606, mean: 0.10583
[32m[0906 14-27-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03442, current rewards: 207.62582, mean: 0.10593
[32m[0906 14-27-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03442, current rewards: 211.05043, mean: 0.10500
[32m[0906 14-27-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03442, current rewards: 216.57932, mean: 0.10514
[32m[0906 14-27-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03443, current rewards: 222.10512, mean: 0.10526
[32m[0906 14-27-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03443, current rewards: 227.63340, mean: 0.10539
[32m[0906 14-27-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03443, current rewards: 233.15846, mean: 0.10550
[32m[0906 14-27-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03443, current rewards: 238.64408, mean: 0.10559
[32m[0906 14-27-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03445, current rewards: 244.16568, mean: 0.10570
[32m[0906 14-27-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03447, current rewards: 249.68650, mean: 0.10580
[32m[0906 14-27-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03450, current rewards: 255.20442, mean: 0.10589
[32m[0906 14-27-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03452, current rewards: 260.73153, mean: 0.10599
[32m[0906 14-27-19 @Agent.py:117][0m Average action selection time: 0.0345
[32m[0906 14-27-19 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-27-19 @MBExp.py:227][0m Rewards obtained: [265.1444309911334], Lows: [3], Highs: [5], Total time: 2135.4174509999993
[32m[0906 14-28-11 @MBExp.py:144][0m ####################################################################
[32m[0906 14-28-11 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 14-28-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03458, current rewards: -1.14955, mean: -0.11496
[32m[0906 14-28-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03519, current rewards: 4.36232, mean: 0.07271
[32m[0906 14-28-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03532, current rewards: 9.86402, mean: 0.08967
[32m[0906 14-28-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03532, current rewards: 15.43909, mean: 0.09649
[32m[0906 14-28-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03537, current rewards: 20.99807, mean: 0.09999
[32m[0906 14-28-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03534, current rewards: 26.57675, mean: 0.10222
[32m[0906 14-28-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03521, current rewards: 32.15036, mean: 0.10371
[32m[0906 14-28-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03513, current rewards: 37.71948, mean: 0.10478
[32m[0906 14-28-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03504, current rewards: 43.29658, mean: 0.10560
[32m[0906 14-28-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03500, current rewards: 48.86002, mean: 0.10622
[32m[0906 14-28-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03495, current rewards: 54.43109, mean: 0.10673
[32m[0906 14-28-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03490, current rewards: 60.08301, mean: 0.10729
[32m[0906 14-28-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03487, current rewards: 65.92932, mean: 0.10808
[32m[0906 14-28-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03484, current rewards: 70.41771, mean: 0.10669
[32m[0906 14-28-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03480, current rewards: 75.88152, mean: 0.10688
[32m[0906 14-28-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03479, current rewards: 81.34495, mean: 0.10703
[32m[0906 14-28-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03472, current rewards: 86.81351, mean: 0.10718
[32m[0906 14-28-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03466, current rewards: 92.27632, mean: 0.10730
[32m[0906 14-28-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03461, current rewards: 97.73956, mean: 0.10741
[32m[0906 14-28-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03456, current rewards: 103.20763, mean: 0.10751
[32m[0906 14-28-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03452, current rewards: 108.64356, mean: 0.10757
[32m[0906 14-28-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03450, current rewards: 114.11197, mean: 0.10765
[32m[0906 14-28-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03450, current rewards: 117.46980, mean: 0.10583
[32m[0906 14-28-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03450, current rewards: 123.06027, mean: 0.10609
[32m[0906 14-28-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03451, current rewards: 128.68877, mean: 0.10635
[32m[0906 14-28-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03451, current rewards: 134.31756, mean: 0.10660
[32m[0906 14-28-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03450, current rewards: 139.94787, mean: 0.10683
[32m[0906 14-28-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03450, current rewards: 145.57845, mean: 0.10704
[32m[0906 14-29-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03451, current rewards: 151.31301, mean: 0.10731
[32m[0906 14-29-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03450, current rewards: 156.97827, mean: 0.10752
[32m[0906 14-29-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03447, current rewards: 161.17865, mean: 0.10674
[32m[0906 14-29-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03445, current rewards: 169.25293, mean: 0.10850
[32m[0906 14-29-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03442, current rewards: 177.32722, mean: 0.11014
[32m[0906 14-29-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03439, current rewards: 185.40150, mean: 0.11169
[32m[0906 14-29-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03437, current rewards: 193.47579, mean: 0.11314
[32m[0906 14-29-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03435, current rewards: 200.38859, mean: 0.11386
[32m[0906 14-29-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03433, current rewards: 150.38859, mean: 0.08309
[32m[0906 14-29-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03433, current rewards: 100.38859, mean: 0.05397
[32m[0906 14-29-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03434, current rewards: 50.38859, mean: 0.02638
[32m[0906 14-29-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03435, current rewards: 0.38859, mean: 0.00020
[32m[0906 14-29-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03435, current rewards: -49.61141, mean: -0.02468
[32m[0906 14-29-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03436, current rewards: -99.61141, mean: -0.04836
[32m[0906 14-29-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03437, current rewards: -149.61141, mean: -0.07091
[32m[0906 14-29-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03437, current rewards: -199.61141, mean: -0.09241
[32m[0906 14-29-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03437, current rewards: -249.61141, mean: -0.11295
[32m[0906 14-29-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03438, current rewards: -299.61141, mean: -0.13257
[32m[0906 14-29-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03438, current rewards: -349.61141, mean: -0.15135
[32m[0906 14-29-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03441, current rewards: -399.61141, mean: -0.16933
[32m[0906 14-29-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03443, current rewards: -449.61141, mean: -0.18656
[32m[0906 14-29-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03445, current rewards: -499.61141, mean: -0.20309
[32m[0906 14-29-38 @Agent.py:117][0m Average action selection time: 0.0345
[32m[0906 14-29-38 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-29-38 @MBExp.py:227][0m Rewards obtained: [-539.6114082902518], Lows: [2], Highs: [744], Total time: 2222.2191529999996
[32m[0906 14-30-31 @MBExp.py:144][0m ####################################################################
[32m[0906 14-30-31 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 14-30-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03535, current rewards: -1.04627, mean: -0.10463
[32m[0906 14-30-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03543, current rewards: 4.21812, mean: 0.07030
[32m[0906 14-30-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03537, current rewards: 9.45000, mean: 0.08591
[32m[0906 14-30-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03542, current rewards: 14.68278, mean: 0.09177
[32m[0906 14-30-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03541, current rewards: 19.91629, mean: 0.09484
[32m[0906 14-30-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03542, current rewards: 25.14942, mean: 0.09673
[32m[0906 14-30-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03527, current rewards: 30.38035, mean: 0.09800
[32m[0906 14-30-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03515, current rewards: 35.61150, mean: 0.09892
[32m[0906 14-30-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03505, current rewards: 40.84536, mean: 0.09962
[32m[0906 14-30-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03500, current rewards: 46.07815, mean: 0.10017
[32m[0906 14-30-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03494, current rewards: 51.30786, mean: 0.10060
[32m[0906 14-30-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03490, current rewards: 55.61562, mean: 0.09931
[32m[0906 14-30-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03485, current rewards: 60.93408, mean: 0.09989
[32m[0906 14-30-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03484, current rewards: 66.40851, mean: 0.10062
[32m[0906 14-30-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03482, current rewards: 71.88803, mean: 0.10125
[32m[0906 14-30-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03480, current rewards: 77.36630, mean: 0.10180
[32m[0906 14-31-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03473, current rewards: 82.84255, mean: 0.10227
[32m[0906 14-31-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03467, current rewards: 88.32806, mean: 0.10271
[32m[0906 14-31-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03461, current rewards: 93.81299, mean: 0.10309
[32m[0906 14-31-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03456, current rewards: 99.28743, mean: 0.10342
[32m[0906 14-31-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03452, current rewards: 104.75529, mean: 0.10372
[32m[0906 14-31-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03448, current rewards: 110.23184, mean: 0.10399
[32m[0906 14-31-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03446, current rewards: 115.65065, mean: 0.10419
[32m[0906 14-31-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03445, current rewards: 121.11698, mean: 0.10441
[32m[0906 14-31-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03446, current rewards: 126.57955, mean: 0.10461
[32m[0906 14-31-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03446, current rewards: 132.03852, mean: 0.10479
[32m[0906 14-31-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03446, current rewards: 137.50021, mean: 0.10496
[32m[0906 14-31-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03447, current rewards: 142.96119, mean: 0.10512
[32m[0906 14-31-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03447, current rewards: 148.75751, mean: 0.10550
[32m[0906 14-31-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03447, current rewards: 154.32769, mean: 0.10570
[32m[0906 14-31-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03447, current rewards: 159.86439, mean: 0.10587
[32m[0906 14-31-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03445, current rewards: 163.27393, mean: 0.10466
[32m[0906 14-31-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03443, current rewards: 168.65445, mean: 0.10475
[32m[0906 14-31-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03440, current rewards: 174.03993, mean: 0.10484
[32m[0906 14-31-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03438, current rewards: 179.42658, mean: 0.10493
[32m[0906 14-31-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03436, current rewards: 184.80812, mean: 0.10500
[32m[0906 14-31-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03434, current rewards: 190.18905, mean: 0.10508
[32m[0906 14-31-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03432, current rewards: 194.26430, mean: 0.10444
[32m[0906 14-31-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03432, current rewards: 199.57947, mean: 0.10449
[32m[0906 14-31-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03432, current rewards: 204.88739, mean: 0.10453
[32m[0906 14-31-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03433, current rewards: 210.20368, mean: 0.10458
[32m[0906 14-31-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03434, current rewards: 215.51387, mean: 0.10462
[32m[0906 14-31-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03434, current rewards: 220.82655, mean: 0.10466
[32m[0906 14-31-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03434, current rewards: 226.13137, mean: 0.10469
[32m[0906 14-31-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03434, current rewards: 231.44479, mean: 0.10473
[32m[0906 14-31-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03435, current rewards: 236.63271, mean: 0.10470
[32m[0906 14-31-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03435, current rewards: 241.93466, mean: 0.10473
[32m[0906 14-31-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03436, current rewards: 247.23544, mean: 0.10476
[32m[0906 14-31-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03437, current rewards: 248.31264, mean: 0.10303
[32m[0906 14-31-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03439, current rewards: 253.58688, mean: 0.10308
[32m[0906 14-31-58 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 14-31-58 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-31-58 @MBExp.py:227][0m Rewards obtained: [257.8087743890859], Lows: [3], Highs: [4], Total time: 2308.8834689999994
[32m[0906 14-32-54 @MBExp.py:144][0m ####################################################################
[32m[0906 14-32-54 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 14-32-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03459, current rewards: 0.11417, mean: 0.01142
[32m[0906 14-32-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03534, current rewards: 5.68806, mean: 0.09480
[32m[0906 14-32-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03534, current rewards: 11.26055, mean: 0.10237
[32m[0906 14-32-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03541, current rewards: 16.70289, mean: 0.10439
[32m[0906 14-33-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03540, current rewards: 22.24997, mean: 0.10595
[32m[0906 14-33-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03542, current rewards: 28.52911, mean: 0.10973
[32m[0906 14-33-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03531, current rewards: 34.10074, mean: 0.11000
[32m[0906 14-33-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03518, current rewards: 39.67691, mean: 0.11021
[32m[0906 14-33-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03508, current rewards: 45.25258, mean: 0.11037
[32m[0906 14-33-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03503, current rewards: 50.82204, mean: 0.11048
[32m[0906 14-33-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03497, current rewards: 56.39216, mean: 0.11057
[32m[0906 14-33-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03494, current rewards: 61.96049, mean: 0.11064
[32m[0906 14-33-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03490, current rewards: 65.39282, mean: 0.10720
[32m[0906 14-33-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03485, current rewards: 70.66944, mean: 0.10707
[32m[0906 14-33-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03482, current rewards: 75.94607, mean: 0.10697
[32m[0906 14-33-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03480, current rewards: 81.22491, mean: 0.10687
[32m[0906 14-33-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03475, current rewards: 86.49717, mean: 0.10679
[32m[0906 14-33-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03467, current rewards: 91.77490, mean: 0.10671
[32m[0906 14-33-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03461, current rewards: 97.05352, mean: 0.10665
[32m[0906 14-33-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03455, current rewards: 102.37870, mean: 0.10664
[32m[0906 14-33-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03451, current rewards: 107.64052, mean: 0.10657
[32m[0906 14-33-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03447, current rewards: 112.90447, mean: 0.10651
[32m[0906 14-33-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03444, current rewards: 118.16583, mean: 0.10646
[32m[0906 14-33-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03440, current rewards: 123.42950, mean: 0.10640
[32m[0906 14-33-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03440, current rewards: 128.69438, mean: 0.10636
[32m[0906 14-33-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03440, current rewards: 133.95835, mean: 0.10632
[32m[0906 14-33-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03440, current rewards: 137.10000, mean: 0.10466
[32m[0906 14-33-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03441, current rewards: 142.69519, mean: 0.10492
[32m[0906 14-33-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03441, current rewards: 148.30066, mean: 0.10518
[32m[0906 14-33-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03442, current rewards: 153.87336, mean: 0.10539
[32m[0906 14-33-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03442, current rewards: 159.44875, mean: 0.10560
[32m[0906 14-33-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03441, current rewards: 165.02365, mean: 0.10578
[32m[0906 14-33-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03440, current rewards: 168.57993, mean: 0.10471
[32m[0906 14-33-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03438, current rewards: 174.08654, mean: 0.10487
[32m[0906 14-33-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03435, current rewards: 179.59453, mean: 0.10503
[32m[0906 14-33-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03433, current rewards: 185.09986, mean: 0.10517
[32m[0906 14-33-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03431, current rewards: 190.60382, mean: 0.10531
[32m[0906 14-33-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03429, current rewards: 196.11115, mean: 0.10544
[32m[0906 14-34-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03428, current rewards: 201.61584, mean: 0.10556
[32m[0906 14-34-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03426, current rewards: 207.12073, mean: 0.10567
[32m[0906 14-34-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03427, current rewards: 212.62624, mean: 0.10578
[32m[0906 14-34-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03427, current rewards: 218.13206, mean: 0.10589
[32m[0906 14-34-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03428, current rewards: 223.63632, mean: 0.10599
[32m[0906 14-34-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03428, current rewards: 228.12514, mean: 0.10561
[32m[0906 14-34-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03429, current rewards: 233.86525, mean: 0.10582
[32m[0906 14-34-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03429, current rewards: 239.60637, mean: 0.10602
[32m[0906 14-34-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03430, current rewards: 245.34494, mean: 0.10621
[32m[0906 14-34-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03430, current rewards: 251.09056, mean: 0.10639
[32m[0906 14-34-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03430, current rewards: 256.83398, mean: 0.10657
[32m[0906 14-34-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03431, current rewards: 262.57656, mean: 0.10674
[32m[0906 14-34-20 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 14-34-20 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-34-20 @MBExp.py:227][0m Rewards obtained: [267.17037796380237], Lows: [2], Highs: [4], Total time: 2395.3521589999996
[32m[0906 14-35-18 @MBExp.py:144][0m ####################################################################
[32m[0906 14-35-18 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 14-35-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03459, current rewards: -0.87883, mean: -0.08788
[32m[0906 14-35-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03524, current rewards: 4.69638, mean: 0.07827
[32m[0906 14-35-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03529, current rewards: 10.17271, mean: 0.09248
[32m[0906 14-35-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03536, current rewards: 15.72916, mean: 0.09831
[32m[0906 14-35-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03538, current rewards: 21.28361, mean: 0.10135
[32m[0906 14-35-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03541, current rewards: 26.83573, mean: 0.10321
[32m[0906 14-35-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03540, current rewards: 32.38711, mean: 0.10447
[32m[0906 14-35-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03528, current rewards: 37.94010, mean: 0.10539
[32m[0906 14-35-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03520, current rewards: 43.49265, mean: 0.10608
[32m[0906 14-35-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03513, current rewards: 49.04483, mean: 0.10662
[32m[0906 14-35-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03507, current rewards: 54.64308, mean: 0.10714
[32m[0906 14-35-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03500, current rewards: 60.17245, mean: 0.10745
[32m[0906 14-35-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03498, current rewards: 63.61444, mean: 0.10429
[32m[0906 14-35-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03493, current rewards: 69.17298, mean: 0.10481
[32m[0906 14-35-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03491, current rewards: 74.72643, mean: 0.10525
[32m[0906 14-35-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03488, current rewards: 80.28150, mean: 0.10563
[32m[0906 14-35-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03485, current rewards: 85.84096, mean: 0.10598
[32m[0906 14-35-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03478, current rewards: 91.40357, mean: 0.10628
[32m[0906 14-35-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03473, current rewards: 96.94194, mean: 0.10653
[32m[0906 14-35-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03467, current rewards: 102.51945, mean: 0.10679
[32m[0906 14-35-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03461, current rewards: 108.10315, mean: 0.10703
[32m[0906 14-35-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03456, current rewards: 113.68692, mean: 0.10725
[32m[0906 14-35-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03451, current rewards: 116.86138, mean: 0.10528
[32m[0906 14-35-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03447, current rewards: 121.80337, mean: 0.10500
[32m[0906 14-36-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03444, current rewards: 126.74263, mean: 0.10475
[32m[0906 14-36-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03442, current rewards: 131.68219, mean: 0.10451
[32m[0906 14-36-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03443, current rewards: 136.61688, mean: 0.10429
[32m[0906 14-36-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03443, current rewards: 141.55567, mean: 0.10409
[32m[0906 14-36-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03444, current rewards: 146.49507, mean: 0.10390
[32m[0906 14-36-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03443, current rewards: 151.43283, mean: 0.10372
[32m[0906 14-36-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03444, current rewards: 156.37015, mean: 0.10356
[32m[0906 14-36-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03444, current rewards: 161.30837, mean: 0.10340
[32m[0906 14-36-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03445, current rewards: 166.24652, mean: 0.10326
[32m[0906 14-36-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03444, current rewards: 171.18601, mean: 0.10312
[32m[0906 14-36-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03442, current rewards: 176.21720, mean: 0.10305
[32m[0906 14-36-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03440, current rewards: 184.03297, mean: 0.10456
[32m[0906 14-36-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03438, current rewards: 135.20373, mean: 0.07470
[32m[0906 14-36-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03437, current rewards: 85.20373, mean: 0.04581
[32m[0906 14-36-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03435, current rewards: 35.20373, mean: 0.01843
[32m[0906 14-36-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03433, current rewards: -14.79627, mean: -0.00755
[32m[0906 14-36-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03432, current rewards: -64.79627, mean: -0.03224
[32m[0906 14-36-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03430, current rewards: -114.79627, mean: -0.05573
[32m[0906 14-36-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03431, current rewards: -151.17210, mean: -0.07165
[32m[0906 14-36-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03432, current rewards: -185.45189, mean: -0.08586
[32m[0906 14-36-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03432, current rewards: -235.45189, mean: -0.10654
[32m[0906 14-36-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03433, current rewards: -285.45189, mean: -0.12631
[32m[0906 14-36-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03434, current rewards: -335.45189, mean: -0.14522
[32m[0906 14-36-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03434, current rewards: -385.45189, mean: -0.16333
[32m[0906 14-36-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03435, current rewards: -435.45189, mean: -0.18069
[32m[0906 14-36-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03435, current rewards: -485.45189, mean: -0.19734
[32m[0906 14-36-44 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 14-36-44 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-36-44 @MBExp.py:227][0m Rewards obtained: [-525.4518940736239], Lows: [2], Highs: [713], Total time: 2481.8698029999996
[32m[0906 14-37-44 @MBExp.py:144][0m ####################################################################
[32m[0906 14-37-44 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 14-37-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03472, current rewards: 0.23926, mean: 0.02393
[32m[0906 14-37-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03537, current rewards: 5.66493, mean: 0.09442
[32m[0906 14-37-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03536, current rewards: 11.43596, mean: 0.10396
[32m[0906 14-37-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03547, current rewards: 16.94677, mean: 0.10592
[32m[0906 14-37-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03546, current rewards: 22.45384, mean: 0.10692
[32m[0906 14-37-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03546, current rewards: 27.96046, mean: 0.10754
[32m[0906 14-37-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03547, current rewards: 33.36612, mean: 0.10763
[32m[0906 14-37-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03540, current rewards: 38.80186, mean: 0.10778
[32m[0906 14-37-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03529, current rewards: 44.23725, mean: 0.10790
[32m[0906 14-38-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03522, current rewards: 48.49750, mean: 0.10543
[32m[0906 14-38-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03515, current rewards: 53.80426, mean: 0.10550
[32m[0906 14-38-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03509, current rewards: 59.07661, mean: 0.10549
[32m[0906 14-38-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03504, current rewards: 64.49506, mean: 0.10573
[32m[0906 14-38-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03501, current rewards: 69.91565, mean: 0.10593
[32m[0906 14-38-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03497, current rewards: 75.33515, mean: 0.10611
[32m[0906 14-38-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03494, current rewards: 80.75726, mean: 0.10626
[32m[0906 14-38-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03491, current rewards: 86.17222, mean: 0.10639
[32m[0906 14-38-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03484, current rewards: 91.59073, mean: 0.10650
[32m[0906 14-38-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03477, current rewards: 97.00570, mean: 0.10660
[32m[0906 14-38-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03471, current rewards: 102.55849, mean: 0.10683
[32m[0906 14-38-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03466, current rewards: 108.00495, mean: 0.10694
[32m[0906 14-38-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03461, current rewards: 113.44580, mean: 0.10702
[32m[0906 14-38-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03456, current rewards: 118.88902, mean: 0.10711
[32m[0906 14-38-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03454, current rewards: 124.33323, mean: 0.10718
[32m[0906 14-38-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03450, current rewards: 129.74034, mean: 0.10722
[32m[0906 14-38-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03446, current rewards: 135.21847, mean: 0.10732
[32m[0906 14-38-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03442, current rewards: 140.68617, mean: 0.10739
[32m[0906 14-38-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03443, current rewards: 146.29179, mean: 0.10757
[32m[0906 14-38-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03443, current rewards: 151.78396, mean: 0.10765
[32m[0906 14-38-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03443, current rewards: 157.27843, mean: 0.10772
[32m[0906 14-38-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03443, current rewards: 162.76970, mean: 0.10779
[32m[0906 14-38-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03443, current rewards: 164.29975, mean: 0.10532
[32m[0906 14-38-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03443, current rewards: 169.94889, mean: 0.10556
[32m[0906 14-38-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03444, current rewards: 175.59715, mean: 0.10578
[32m[0906 14-38-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03444, current rewards: 181.24546, mean: 0.10599
[32m[0906 14-38-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03443, current rewards: 186.78937, mean: 0.10613
[32m[0906 14-38-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03440, current rewards: 192.24368, mean: 0.10621
[32m[0906 14-38-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03438, current rewards: 196.60339, mean: 0.10570
[32m[0906 14-38-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03436, current rewards: 202.07119, mean: 0.10580
[32m[0906 14-38-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03434, current rewards: 207.53429, mean: 0.10588
[32m[0906 14-38-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03432, current rewards: 213.00021, mean: 0.10597
[32m[0906 14-38-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03431, current rewards: 218.46279, mean: 0.10605
[32m[0906 14-38-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03429, current rewards: 223.92426, mean: 0.10613
[32m[0906 14-38-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03429, current rewards: 229.38735, mean: 0.10620
[32m[0906 14-39-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03429, current rewards: 234.83654, mean: 0.10626
[32m[0906 14-39-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03430, current rewards: 240.29534, mean: 0.10633
[32m[0906 14-39-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03430, current rewards: 245.76036, mean: 0.10639
[32m[0906 14-39-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03431, current rewards: 251.22382, mean: 0.10645
[32m[0906 14-39-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03432, current rewards: 256.68307, mean: 0.10651
[32m[0906 14-39-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03433, current rewards: 261.17836, mean: 0.10617
[32m[0906 14-39-10 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 14-39-10 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-39-10 @MBExp.py:227][0m Rewards obtained: [265.5453022798856], Lows: [3], Highs: [3], Total time: 2568.3411149999997
[32m[0906 14-40-12 @MBExp.py:144][0m ####################################################################
[32m[0906 14-40-12 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 14-40-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03509, current rewards: 0.10599, mean: 0.01060
[32m[0906 14-40-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03521, current rewards: 5.57483, mean: 0.09291
[32m[0906 14-40-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03525, current rewards: 10.87568, mean: 0.09887
[32m[0906 14-40-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03530, current rewards: 16.32680, mean: 0.10204
[32m[0906 14-40-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03530, current rewards: 21.77073, mean: 0.10367
[32m[0906 14-40-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03531, current rewards: 27.21547, mean: 0.10467
[32m[0906 14-40-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03531, current rewards: 32.66657, mean: 0.10538
[32m[0906 14-40-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03529, current rewards: 38.10970, mean: 0.10586
[32m[0906 14-40-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03520, current rewards: 43.55602, mean: 0.10623
[32m[0906 14-40-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03513, current rewards: 49.00622, mean: 0.10654
[32m[0906 14-40-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03508, current rewards: 54.53388, mean: 0.10693
[32m[0906 14-40-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03504, current rewards: 58.94667, mean: 0.10526
[32m[0906 14-40-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03498, current rewards: 65.00379, mean: 0.10656
[32m[0906 14-40-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03496, current rewards: 71.06235, mean: 0.10767
[32m[0906 14-40-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03495, current rewards: 77.11699, mean: 0.10862
[32m[0906 14-40-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03493, current rewards: 83.17302, mean: 0.10944
[32m[0906 14-40-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03490, current rewards: 89.21995, mean: 0.11015
[32m[0906 14-40-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03483, current rewards: 95.27270, mean: 0.11078
[32m[0906 14-40-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03478, current rewards: 101.32531, mean: 0.11135
[32m[0906 14-40-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03472, current rewards: 104.72597, mean: 0.10909
[32m[0906 14-40-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03468, current rewards: 110.27147, mean: 0.10918
[32m[0906 14-40-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03462, current rewards: 115.81159, mean: 0.10926
[32m[0906 14-40-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03457, current rewards: 121.36077, mean: 0.10933
[32m[0906 14-40-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03454, current rewards: 126.89925, mean: 0.10940
[32m[0906 14-40-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03450, current rewards: 132.44120, mean: 0.10946
[32m[0906 14-40-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03447, current rewards: 137.99077, mean: 0.10952
[32m[0906 14-40-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03445, current rewards: 143.53299, mean: 0.10957
[32m[0906 14-40-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03443, current rewards: 149.00171, mean: 0.10956
[32m[0906 14-41-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03443, current rewards: 154.53756, mean: 0.10960
[32m[0906 14-41-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03444, current rewards: 160.07783, mean: 0.10964
[32m[0906 14-41-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03444, current rewards: 165.62013, mean: 0.10968
[32m[0906 14-41-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03445, current rewards: 169.12874, mean: 0.10842
[32m[0906 14-41-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03446, current rewards: 174.63535, mean: 0.10847
[32m[0906 14-41-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03446, current rewards: 180.14440, mean: 0.10852
[32m[0906 14-41-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03447, current rewards: 185.65472, mean: 0.10857
[32m[0906 14-41-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03447, current rewards: 191.30387, mean: 0.10870
[32m[0906 14-41-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03448, current rewards: 196.83625, mean: 0.10875
[32m[0906 14-41-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03446, current rewards: 202.37379, mean: 0.10880
[32m[0906 14-41-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03444, current rewards: 207.90992, mean: 0.10885
[32m[0906 14-41-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03443, current rewards: 213.44646, mean: 0.10890
[32m[0906 14-41-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03441, current rewards: 217.86836, mean: 0.10839
[32m[0906 14-41-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03440, current rewards: 223.40357, mean: 0.10845
[32m[0906 14-41-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03438, current rewards: 228.93990, mean: 0.10850
[32m[0906 14-41-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03436, current rewards: 234.53521, mean: 0.10858
[32m[0906 14-41-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03434, current rewards: 240.07806, mean: 0.10863
[32m[0906 14-41-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03435, current rewards: 245.56132, mean: 0.10866
[32m[0906 14-41-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03436, current rewards: 250.03781, mean: 0.10824
[32m[0906 14-41-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03436, current rewards: 255.72548, mean: 0.10836
[32m[0906 14-41-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03437, current rewards: 261.41773, mean: 0.10847
[32m[0906 14-41-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03438, current rewards: 267.09145, mean: 0.10857
[32m[0906 14-41-39 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 14-41-39 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-41-39 @MBExp.py:227][0m Rewards obtained: [270.074624027619], Lows: [3], Highs: [4], Total time: 2654.9340009999996
[32m[0906 14-42-42 @MBExp.py:144][0m ####################################################################
[32m[0906 14-42-42 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 14-42-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03447, current rewards: -1.76849, mean: -0.17685
[32m[0906 14-42-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03525, current rewards: 3.72496, mean: 0.06208
[32m[0906 14-42-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03527, current rewards: 9.18136, mean: 0.08347
[32m[0906 14-42-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03531, current rewards: 14.65770, mean: 0.09161
[32m[0906 14-42-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03537, current rewards: 20.13856, mean: 0.09590
[32m[0906 14-42-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03534, current rewards: 25.61069, mean: 0.09850
[32m[0906 14-42-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03534, current rewards: 31.08243, mean: 0.10027
[32m[0906 14-42-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03536, current rewards: 36.56071, mean: 0.10156
[32m[0906 14-42-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03527, current rewards: 37.81886, mean: 0.09224
[32m[0906 14-42-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03518, current rewards: 43.31620, mean: 0.09417
[32m[0906 14-43-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03509, current rewards: 49.09269, mean: 0.09626
[32m[0906 14-43-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03504, current rewards: 54.67404, mean: 0.09763
[32m[0906 14-43-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03500, current rewards: 60.25554, mean: 0.09878
[32m[0906 14-43-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03495, current rewards: 63.65388, mean: 0.09645
[32m[0906 14-43-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03492, current rewards: 69.30750, mean: 0.09762
[32m[0906 14-43-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03490, current rewards: 74.95785, mean: 0.09863
[32m[0906 14-43-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03487, current rewards: 80.60193, mean: 0.09951
[32m[0906 14-43-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03484, current rewards: 85.35107, mean: 0.09925
[32m[0906 14-43-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03478, current rewards: 91.09750, mean: 0.10011
[32m[0906 14-43-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03473, current rewards: 96.81740, mean: 0.10085
[32m[0906 14-43-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03466, current rewards: 102.53274, mean: 0.10152
[32m[0906 14-43-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03461, current rewards: 108.24726, mean: 0.10212
[32m[0906 14-43-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03457, current rewards: 113.96655, mean: 0.10267
[32m[0906 14-43-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03453, current rewards: 119.69250, mean: 0.10318
[32m[0906 14-43-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03450, current rewards: 125.40434, mean: 0.10364
[32m[0906 14-43-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03447, current rewards: 131.12437, mean: 0.10407
[32m[0906 14-43-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03443, current rewards: 136.75449, mean: 0.10439
[32m[0906 14-43-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03440, current rewards: 140.19302, mean: 0.10308
[32m[0906 14-43-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03438, current rewards: 145.67459, mean: 0.10332
[32m[0906 14-43-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03437, current rewards: 151.15729, mean: 0.10353
[32m[0906 14-43-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03437, current rewards: 156.63584, mean: 0.10373
[32m[0906 14-43-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03438, current rewards: 162.11903, mean: 0.10392
[32m[0906 14-43-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03438, current rewards: 167.59900, mean: 0.10410
[32m[0906 14-43-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03439, current rewards: 173.08354, mean: 0.10427
[32m[0906 14-43-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03439, current rewards: 177.60756, mean: 0.10386
[32m[0906 14-43-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03439, current rewards: 183.19974, mean: 0.10409
[32m[0906 14-43-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03439, current rewards: 188.71996, mean: 0.10427
[32m[0906 14-43-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03439, current rewards: 194.24295, mean: 0.10443
[32m[0906 14-43-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03438, current rewards: 199.76199, mean: 0.10459
[32m[0906 14-43-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03437, current rewards: 205.27983, mean: 0.10473
[32m[0906 14-43-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03435, current rewards: 210.80228, mean: 0.10488
[32m[0906 14-43-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03433, current rewards: 212.15856, mean: 0.10299
[32m[0906 14-43-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03431, current rewards: 217.74000, mean: 0.10319
[32m[0906 14-43-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03430, current rewards: 223.31095, mean: 0.10338
[32m[0906 14-43-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03428, current rewards: 228.88511, mean: 0.10357
[32m[0906 14-44-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03426, current rewards: 233.35622, mean: 0.10325
[32m[0906 14-44-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03426, current rewards: 238.81765, mean: 0.10338
[32m[0906 14-44-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03427, current rewards: 244.28738, mean: 0.10351
[32m[0906 14-44-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03427, current rewards: 249.75792, mean: 0.10363
[32m[0906 14-44-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03428, current rewards: 255.22663, mean: 0.10375
[32m[0906 14-44-09 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 14-44-09 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-44-09 @MBExp.py:227][0m Rewards obtained: [259.6048189145556], Lows: [6], Highs: [6], Total time: 2741.2750719999995
[32m[0906 14-45-15 @MBExp.py:144][0m ####################################################################
[32m[0906 14-45-15 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 14-45-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03622, current rewards: -1.13315, mean: -0.11331
[32m[0906 14-45-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03645, current rewards: 4.38317, mean: 0.07305
[32m[0906 14-45-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03636, current rewards: 9.76025, mean: 0.08873
[32m[0906 14-45-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03608, current rewards: 15.27354, mean: 0.09546
[32m[0906 14-45-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03588, current rewards: 20.78544, mean: 0.09898
[32m[0906 14-45-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03580, current rewards: 26.30352, mean: 0.10117
[32m[0906 14-45-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03578, current rewards: 31.81143, mean: 0.10262
[32m[0906 14-45-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03572, current rewards: 37.32625, mean: 0.10368
[32m[0906 14-45-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03563, current rewards: 42.83642, mean: 0.10448
[32m[0906 14-45-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03550, current rewards: 48.35537, mean: 0.10512
[32m[0906 14-45-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03539, current rewards: 54.10383, mean: 0.10609
[32m[0906 14-45-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03533, current rewards: 55.50104, mean: 0.09911
[32m[0906 14-45-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03527, current rewards: 61.25222, mean: 0.10041
[32m[0906 14-45-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03520, current rewards: 67.00027, mean: 0.10152
[32m[0906 14-45-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03514, current rewards: 72.74766, mean: 0.10246
[32m[0906 14-45-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03510, current rewards: 78.49786, mean: 0.10329
[32m[0906 14-45-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03506, current rewards: 84.24695, mean: 0.10401
[32m[0906 14-45-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03502, current rewards: 89.99587, mean: 0.10465
[32m[0906 14-45-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03494, current rewards: 95.59259, mean: 0.10505
[32m[0906 14-45-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03487, current rewards: 101.24081, mean: 0.10546
[32m[0906 14-45-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03482, current rewards: 106.88940, mean: 0.10583
[32m[0906 14-45-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03477, current rewards: 112.53764, mean: 0.10617
[32m[0906 14-45-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03473, current rewards: 118.18674, mean: 0.10647
[32m[0906 14-45-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03468, current rewards: 123.83566, mean: 0.10675
[32m[0906 14-45-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03463, current rewards: 129.48575, mean: 0.10701
[32m[0906 14-45-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03459, current rewards: 134.04616, mean: 0.10639
[32m[0906 14-46-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03455, current rewards: 139.79761, mean: 0.10672
[32m[0906 14-46-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03451, current rewards: 145.47975, mean: 0.10697
[32m[0906 14-46-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03448, current rewards: 151.16112, mean: 0.10721
[32m[0906 14-46-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03445, current rewards: 156.83693, mean: 0.10742
[32m[0906 14-46-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03444, current rewards: 162.51837, mean: 0.10763
[32m[0906 14-46-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03444, current rewards: 168.19522, mean: 0.10782
[32m[0906 14-46-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03445, current rewards: 173.87329, mean: 0.10800
[32m[0906 14-46-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03445, current rewards: 179.55083, mean: 0.10816
[32m[0906 14-46-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03445, current rewards: 185.18284, mean: 0.10829
[32m[0906 14-46-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03445, current rewards: 190.86404, mean: 0.10845
[32m[0906 14-46-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03446, current rewards: 195.46066, mean: 0.10799
[32m[0906 14-46-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03445, current rewards: 201.01841, mean: 0.10807
[32m[0906 14-46-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03446, current rewards: 206.57986, mean: 0.10816
[32m[0906 14-46-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03445, current rewards: 212.14674, mean: 0.10824
[32m[0906 14-46-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03444, current rewards: 217.70688, mean: 0.10831
[32m[0906 14-46-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03442, current rewards: 223.26307, mean: 0.10838
[32m[0906 14-46-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03441, current rewards: 228.82343, mean: 0.10845
[32m[0906 14-46-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03439, current rewards: 234.44270, mean: 0.10854
[32m[0906 14-46-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03437, current rewards: 240.01138, mean: 0.10860
[32m[0906 14-46-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03436, current rewards: 245.76214, mean: 0.10874
[32m[0906 14-46-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03435, current rewards: 251.63818, mean: 0.10893
[32m[0906 14-46-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03433, current rewards: 257.51607, mean: 0.10912
[32m[0906 14-46-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03433, current rewards: 263.38449, mean: 0.10929
[32m[0906 14-46-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03433, current rewards: 269.26629, mean: 0.10946
[32m[0906 14-46-41 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 14-46-41 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-46-41 @MBExp.py:227][0m Rewards obtained: [273.9676464528125], Lows: [2], Highs: [4], Total time: 2827.7685039999997
[32m[0906 14-47-49 @MBExp.py:144][0m ####################################################################
[32m[0906 14-47-49 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 14-47-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03536, current rewards: -1.19513, mean: -0.11951
[32m[0906 14-47-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03520, current rewards: 4.40941, mean: 0.07349
[32m[0906 14-47-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03526, current rewards: 9.89307, mean: 0.08994
[32m[0906 14-47-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03527, current rewards: 15.37753, mean: 0.09611
[32m[0906 14-47-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03530, current rewards: 20.86486, mean: 0.09936
[32m[0906 14-47-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03536, current rewards: 26.34878, mean: 0.10134
[32m[0906 14-48-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03537, current rewards: 31.83395, mean: 0.10269
[32m[0906 14-48-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03535, current rewards: 37.32111, mean: 0.10367
[32m[0906 14-48-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03537, current rewards: 42.80701, mean: 0.10441
[32m[0906 14-48-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03525, current rewards: 48.29817, mean: 0.10500
[32m[0906 14-48-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03519, current rewards: 53.78811, mean: 0.10547
[32m[0906 14-48-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03512, current rewards: 59.27421, mean: 0.10585
[32m[0906 14-48-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03506, current rewards: 63.63038, mean: 0.10431
[32m[0906 14-48-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03501, current rewards: 69.08274, mean: 0.10467
[32m[0906 14-48-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03496, current rewards: 74.53484, mean: 0.10498
[32m[0906 14-48-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03494, current rewards: 79.98959, mean: 0.10525
[32m[0906 14-48-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03491, current rewards: 85.43762, mean: 0.10548
[32m[0906 14-48-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03487, current rewards: 89.12261, mean: 0.10363
[32m[0906 14-48-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03481, current rewards: 94.78763, mean: 0.10416
[32m[0906 14-48-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03474, current rewards: 100.40139, mean: 0.10458
[32m[0906 14-48-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03468, current rewards: 106.01223, mean: 0.10496
[32m[0906 14-48-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03463, current rewards: 110.49608, mean: 0.10424
[32m[0906 14-48-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03458, current rewards: 116.12595, mean: 0.10462
[32m[0906 14-48-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03454, current rewards: 121.75580, mean: 0.10496
[32m[0906 14-48-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03450, current rewards: 127.38525, mean: 0.10528
[32m[0906 14-48-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03446, current rewards: 133.01700, mean: 0.10557
[32m[0906 14-48-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03443, current rewards: 138.69076, mean: 0.10587
[32m[0906 14-48-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03440, current rewards: 144.31162, mean: 0.10611
[32m[0906 14-48-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03437, current rewards: 149.82634, mean: 0.10626
[32m[0906 14-48-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03434, current rewards: 155.30543, mean: 0.10637
[32m[0906 14-48-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03432, current rewards: 160.78593, mean: 0.10648
[32m[0906 14-48-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03429, current rewards: 166.26384, mean: 0.10658
[32m[0906 14-48-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03429, current rewards: 171.73933, mean: 0.10667
[32m[0906 14-48-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03431, current rewards: 177.21708, mean: 0.10676
[32m[0906 14-48-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03432, current rewards: 182.69020, mean: 0.10684
[32m[0906 14-48-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03432, current rewards: 188.16811, mean: 0.10691
[32m[0906 14-48-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03433, current rewards: 190.06489, mean: 0.10501
[32m[0906 14-48-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03433, current rewards: 199.11832, mean: 0.10705
[32m[0906 14-48-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03433, current rewards: 208.17175, mean: 0.10899
[32m[0906 14-48-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03433, current rewards: 217.22519, mean: 0.11083
[32m[0906 14-48-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03434, current rewards: 226.27862, mean: 0.11258
[32m[0906 14-49-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03432, current rewards: 235.33205, mean: 0.11424
[32m[0906 14-49-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03431, current rewards: 244.38549, mean: 0.11582
[32m[0906 14-49-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03430, current rewards: 202.65297, mean: 0.09382
[32m[0906 14-49-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03429, current rewards: 152.65297, mean: 0.06907
[32m[0906 14-49-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03427, current rewards: 102.65297, mean: 0.04542
[32m[0906 14-49-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03426, current rewards: 52.65297, mean: 0.02279
[32m[0906 14-49-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03424, current rewards: 31.53917, mean: 0.01336
[32m[0906 14-49-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03423, current rewards: 37.16767, mean: 0.01542
[32m[0906 14-49-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03422, current rewards: 42.79414, mean: 0.01740
[32m[0906 14-49-15 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 14-49-15 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-49-15 @MBExp.py:227][0m Rewards obtained: [47.17699105006929], Lows: [3], Highs: [221], Total time: 2913.9920729999994
[32m[0906 14-50-25 @MBExp.py:144][0m ####################################################################
[32m[0906 14-50-25 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 14-50-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03489, current rewards: -1.14792, mean: -0.11479
[32m[0906 14-50-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03524, current rewards: 4.28209, mean: 0.07137
[32m[0906 14-50-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03529, current rewards: 9.71227, mean: 0.08829
[32m[0906 14-50-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03530, current rewards: 15.14864, mean: 0.09468
[32m[0906 14-50-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03533, current rewards: 20.57923, mean: 0.09800
[32m[0906 14-50-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03538, current rewards: 26.01180, mean: 0.10005
[32m[0906 14-50-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03538, current rewards: 31.44598, mean: 0.10144
[32m[0906 14-50-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03538, current rewards: 34.64064, mean: 0.09622
[32m[0906 14-50-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03540, current rewards: 39.86812, mean: 0.09724
[32m[0906 14-50-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03532, current rewards: 45.16115, mean: 0.09818
[32m[0906 14-50-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03523, current rewards: 50.45621, mean: 0.09893
[32m[0906 14-50-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03516, current rewards: 55.75092, mean: 0.09956
[32m[0906 14-50-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03512, current rewards: 61.04667, mean: 0.10008
[32m[0906 14-50-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03507, current rewards: 64.27504, mean: 0.09739
[32m[0906 14-50-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03503, current rewards: 69.59623, mean: 0.09802
[32m[0906 14-50-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03501, current rewards: 74.91409, mean: 0.09857
[32m[0906 14-50-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03497, current rewards: 80.15594, mean: 0.09896
[32m[0906 14-50-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03495, current rewards: 85.37475, mean: 0.09927
[32m[0906 14-50-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03487, current rewards: 90.65975, mean: 0.09963
[32m[0906 14-50-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03480, current rewards: 95.86603, mean: 0.09986
[32m[0906 14-51-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03474, current rewards: 101.13884, mean: 0.10014
[32m[0906 14-51-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03469, current rewards: 106.34958, mean: 0.10033
[32m[0906 14-51-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03465, current rewards: 110.82714, mean: 0.09984
[32m[0906 14-51-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03461, current rewards: 116.44464, mean: 0.10038
[32m[0906 14-51-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03457, current rewards: 122.05490, mean: 0.10087
[32m[0906 14-51-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03454, current rewards: 127.67475, mean: 0.10133
[32m[0906 14-51-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03450, current rewards: 133.29587, mean: 0.10175
[32m[0906 14-51-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03447, current rewards: 138.91305, mean: 0.10214
[32m[0906 14-51-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03444, current rewards: 144.53695, mean: 0.10251
[32m[0906 14-51-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03441, current rewards: 150.15718, mean: 0.10285
[32m[0906 14-51-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03439, current rewards: 155.78170, mean: 0.10317
[32m[0906 14-51-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03437, current rewards: 161.40678, mean: 0.10347
[32m[0906 14-51-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03435, current rewards: 167.03170, mean: 0.10375
[32m[0906 14-51-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03435, current rewards: 172.65398, mean: 0.10401
[32m[0906 14-51-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03435, current rewards: 178.27742, mean: 0.10426
[32m[0906 14-51-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03436, current rewards: 181.90824, mean: 0.10336
[32m[0906 14-51-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03436, current rewards: 187.66182, mean: 0.10368
[32m[0906 14-51-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03436, current rewards: 193.41724, mean: 0.10399
[32m[0906 14-51-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03437, current rewards: 199.17113, mean: 0.10428
[32m[0906 14-51-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03437, current rewards: 204.92526, mean: 0.10455
[32m[0906 14-51-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03437, current rewards: 210.83515, mean: 0.10489
[32m[0906 14-51-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03437, current rewards: 217.58686, mean: 0.10562
[32m[0906 14-51-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03437, current rewards: 224.35089, mean: 0.10633
[32m[0906 14-51-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03435, current rewards: 231.11493, mean: 0.10700
[32m[0906 14-51-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03433, current rewards: 237.87897, mean: 0.10764
[32m[0906 14-51-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03432, current rewards: 226.47852, mean: 0.10021
[32m[0906 14-51-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03430, current rewards: 176.47852, mean: 0.07640
[32m[0906 14-51-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03429, current rewards: 126.47852, mean: 0.05359
[32m[0906 14-51-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03428, current rewards: 76.47852, mean: 0.03173
[32m[0906 14-51-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03426, current rewards: 26.47852, mean: 0.01076
[32m[0906 14-51-51 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 14-51-51 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-51-51 @MBExp.py:227][0m Rewards obtained: [-13.521484391721572], Lows: [3], Highs: [259], Total time: 3000.2645669999993
[32m[0906 14-53-03 @MBExp.py:144][0m ####################################################################
[32m[0906 14-53-03 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 14-53-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03573, current rewards: 0.10365, mean: 0.01037
[32m[0906 14-53-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03557, current rewards: 5.99778, mean: 0.09996
[32m[0906 14-53-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03543, current rewards: 11.91566, mean: 0.10832
[32m[0906 14-53-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03547, current rewards: 17.83353, mean: 0.11146
[32m[0906 14-53-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03547, current rewards: 23.75141, mean: 0.11310
[32m[0906 14-53-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03550, current rewards: 29.66928, mean: 0.11411
[32m[0906 14-53-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03548, current rewards: 35.58715, mean: 0.11480
[32m[0906 14-53-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03546, current rewards: 6.83595, mean: 0.01899
[32m[0906 14-53-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03548, current rewards: -43.16405, mean: -0.10528
[32m[0906 14-53-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03540, current rewards: -93.16405, mean: -0.20253
[32m[0906 14-53-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03535, current rewards: -143.16405, mean: -0.28071
[32m[0906 14-53-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03528, current rewards: -193.16405, mean: -0.34494
[32m[0906 14-53-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03521, current rewards: -243.16405, mean: -0.39863
[32m[0906 14-53-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03515, current rewards: -293.16405, mean: -0.44419
[32m[0906 14-53-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03512, current rewards: -343.16405, mean: -0.48333
[32m[0906 14-53-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03507, current rewards: -393.16405, mean: -0.51732
[32m[0906 14-53-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03504, current rewards: -443.16405, mean: -0.54712
[32m[0906 14-53-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03503, current rewards: -493.16405, mean: -0.57345
[32m[0906 14-53-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03496, current rewards: -543.16405, mean: -0.59688
[32m[0906 14-53-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03489, current rewards: -593.16405, mean: -0.61788
[32m[0906 14-53-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03482, current rewards: -643.16405, mean: -0.63680
[32m[0906 14-53-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03476, current rewards: -693.16405, mean: -0.65393
[32m[0906 14-53-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03471, current rewards: -743.16405, mean: -0.66952
[32m[0906 14-53-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03467, current rewards: -793.16405, mean: -0.68376
[32m[0906 14-53-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03465, current rewards: -843.16405, mean: -0.69683
[32m[0906 14-53-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03460, current rewards: -893.16405, mean: -0.70886
[32m[0906 14-53-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03457, current rewards: -943.16405, mean: -0.71997
[32m[0906 14-53-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03455, current rewards: -993.16405, mean: -0.73027
[32m[0906 14-53-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03451, current rewards: -1043.16405, mean: -0.73983
[32m[0906 14-53-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03448, current rewards: -1093.16405, mean: -0.74874
[32m[0906 14-53-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03445, current rewards: -1143.16405, mean: -0.75706
[32m[0906 14-53-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03443, current rewards: -1193.16405, mean: -0.76485
[32m[0906 14-53-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03440, current rewards: -1243.16405, mean: -0.77215
[32m[0906 14-54-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03438, current rewards: -1293.16405, mean: -0.77901
[32m[0906 14-54-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03436, current rewards: -1343.16405, mean: -0.78548
[32m[0906 14-54-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03437, current rewards: -1393.16405, mean: -0.79157
[32m[0906 14-54-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03437, current rewards: -1443.16405, mean: -0.79733
[32m[0906 14-54-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03438, current rewards: -1493.16405, mean: -0.80278
[32m[0906 14-54-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03438, current rewards: -1543.16405, mean: -0.80794
[32m[0906 14-54-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03439, current rewards: -1593.16405, mean: -0.81284
[32m[0906 14-54-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03439, current rewards: -1643.16405, mean: -0.81749
[32m[0906 14-54-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03440, current rewards: -1693.16405, mean: -0.82192
[32m[0906 14-54-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03440, current rewards: -1743.16405, mean: -0.82614
[32m[0906 14-54-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03440, current rewards: -1793.16405, mean: -0.83017
[32m[0906 14-54-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03438, current rewards: -1843.16405, mean: -0.83401
[32m[0906 14-54-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03436, current rewards: -1893.16405, mean: -0.83768
[32m[0906 14-54-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03435, current rewards: -1943.16405, mean: -0.84120
[32m[0906 14-54-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03434, current rewards: -1993.16405, mean: -0.84456
[32m[0906 14-54-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03432, current rewards: -2043.16405, mean: -0.84779
[32m[0906 14-54-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03431, current rewards: -2093.16405, mean: -0.85088
[32m[0906 14-54-30 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 14-54-30 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-54-30 @MBExp.py:227][0m Rewards obtained: [-2133.1640529081856], Lows: [0], Highs: [2172], Total time: 3086.656582999999
[32m[0906 14-55-44 @MBExp.py:144][0m ####################################################################
[32m[0906 14-55-44 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 14-55-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03511, current rewards: -2.15225, mean: -0.21523
[32m[0906 14-55-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03540, current rewards: 3.34524, mean: 0.05575
[32m[0906 14-55-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03544, current rewards: 8.99730, mean: 0.08179
[32m[0906 14-55-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03541, current rewards: 14.64971, mean: 0.09156
[32m[0906 14-55-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03542, current rewards: 20.29439, mean: 0.09664
[32m[0906 14-55-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03544, current rewards: 25.94582, mean: 0.09979
[32m[0906 14-55-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03545, current rewards: 29.68064, mean: 0.09574
[32m[0906 14-55-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03545, current rewards: 35.36888, mean: 0.09825
[32m[0906 14-55-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03543, current rewards: 40.94030, mean: 0.09985
[32m[0906 14-56-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03538, current rewards: 46.51386, mean: 0.10112
[32m[0906 14-56-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03528, current rewards: 52.08695, mean: 0.10213
[32m[0906 14-56-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03521, current rewards: 57.65819, mean: 0.10296
[32m[0906 14-56-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03515, current rewards: 63.22609, mean: 0.10365
[32m[0906 14-56-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03510, current rewards: 68.79692, mean: 0.10424
[32m[0906 14-56-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03506, current rewards: 74.36833, mean: 0.10474
[32m[0906 14-56-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03502, current rewards: 80.00415, mean: 0.10527
[32m[0906 14-56-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03499, current rewards: 83.32790, mean: 0.10287
[32m[0906 14-56-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03496, current rewards: 88.90401, mean: 0.10338
[32m[0906 14-56-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03492, current rewards: 94.47724, mean: 0.10382
[32m[0906 14-56-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03486, current rewards: 100.05346, mean: 0.10422
[32m[0906 14-56-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03480, current rewards: 105.62876, mean: 0.10458
[32m[0906 14-56-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03475, current rewards: 111.19822, mean: 0.10490
[32m[0906 14-56-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03470, current rewards: 116.77100, mean: 0.10520
[32m[0906 14-56-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03466, current rewards: 122.29336, mean: 0.10543
[32m[0906 14-56-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03461, current rewards: 126.15300, mean: 0.10426
[32m[0906 14-56-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03458, current rewards: 131.79630, mean: 0.10460
[32m[0906 14-56-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03454, current rewards: 137.44196, mean: 0.10492
[32m[0906 14-56-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03450, current rewards: 143.08344, mean: 0.10521
[32m[0906 14-56-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03447, current rewards: 148.72455, mean: 0.10548
[32m[0906 14-56-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03444, current rewards: 154.35990, mean: 0.10573
[32m[0906 14-56-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03441, current rewards: 159.60007, mean: 0.10570
[32m[0906 14-56-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03438, current rewards: 165.14440, mean: 0.10586
[32m[0906 14-56-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03437, current rewards: 170.73789, mean: 0.10605
[32m[0906 14-56-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03435, current rewards: 176.29301, mean: 0.10620
[32m[0906 14-56-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03433, current rewards: 181.84886, mean: 0.10634
[32m[0906 14-56-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03431, current rewards: 187.40011, mean: 0.10648
[32m[0906 14-56-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03432, current rewards: 192.94795, mean: 0.10660
[32m[0906 14-56-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03433, current rewards: 198.49854, mean: 0.10672
[32m[0906 14-56-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03433, current rewards: 201.97525, mean: 0.10575
[32m[0906 14-56-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03434, current rewards: 207.55592, mean: 0.10590
[32m[0906 14-56-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03434, current rewards: 212.96948, mean: 0.10595
[32m[0906 14-56-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03435, current rewards: 218.54537, mean: 0.10609
[32m[0906 14-56-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03436, current rewards: 224.12512, mean: 0.10622
[32m[0906 14-56-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03436, current rewards: 229.70068, mean: 0.10634
[32m[0906 14-57-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03436, current rewards: 235.27660, mean: 0.10646
[32m[0906 14-57-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03435, current rewards: 240.85615, mean: 0.10657
[32m[0906 14-57-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03434, current rewards: 246.43464, mean: 0.10668
[32m[0906 14-57-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03432, current rewards: 252.01363, mean: 0.10679
[32m[0906 14-57-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03431, current rewards: 257.67349, mean: 0.10692
[32m[0906 14-57-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03430, current rewards: 263.24823, mean: 0.10701
[32m[0906 14-57-10 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 14-57-10 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-57-10 @MBExp.py:227][0m Rewards obtained: [267.7139046964424], Lows: [4], Highs: [4], Total time: 3173.034364999999
[32m[0906 14-58-26 @MBExp.py:144][0m ####################################################################
[32m[0906 14-58-26 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 14-58-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03539, current rewards: -0.98995, mean: -0.09899
[32m[0906 14-58-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03547, current rewards: 4.95160, mean: 0.08253
[32m[0906 14-58-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03543, current rewards: 10.83946, mean: 0.09854
[32m[0906 14-58-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03545, current rewards: 16.72682, mean: 0.10454
[32m[0906 14-58-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03546, current rewards: 22.61803, mean: 0.10770
[32m[0906 14-58-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03544, current rewards: 28.50855, mean: 0.10965
[32m[0906 14-58-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03542, current rewards: 34.38821, mean: 0.11093
[32m[0906 14-58-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03540, current rewards: 39.09637, mean: 0.10860
[32m[0906 14-58-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03541, current rewards: 44.96801, mean: 0.10968
[32m[0906 14-58-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03540, current rewards: 50.83497, mean: 0.11051
[32m[0906 14-58-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03530, current rewards: 56.70808, mean: 0.11119
[32m[0906 14-58-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03524, current rewards: 62.58378, mean: 0.11176
[32m[0906 14-58-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03518, current rewards: 68.46046, mean: 0.11223
[32m[0906 14-58-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03513, current rewards: 74.33035, mean: 0.11262
[32m[0906 14-58-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03508, current rewards: 80.20226, mean: 0.11296
[32m[0906 14-58-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03505, current rewards: 86.07552, mean: 0.11326
[32m[0906 14-58-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03501, current rewards: 91.94894, mean: 0.11352
[32m[0906 14-58-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03498, current rewards: 95.70292, mean: 0.11128
[32m[0906 14-58-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03493, current rewards: 101.36736, mean: 0.11139
[32m[0906 14-58-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03486, current rewards: 107.04860, mean: 0.11151
[32m[0906 14-59-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03480, current rewards: 112.73271, mean: 0.11162
[32m[0906 14-59-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03474, current rewards: 118.41449, mean: 0.11171
[32m[0906 14-59-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03469, current rewards: 124.09327, mean: 0.11180
[32m[0906 14-59-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03465, current rewards: 129.95945, mean: 0.11203
[32m[0906 14-59-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03462, current rewards: 135.61241, mean: 0.11208
[32m[0906 14-59-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03458, current rewards: 141.26552, mean: 0.11212
[32m[0906 14-59-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03455, current rewards: 144.79986, mean: 0.11053
[32m[0906 14-59-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03451, current rewards: 151.04438, mean: 0.11106
[32m[0906 14-59-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03447, current rewards: 156.72781, mean: 0.11115
[32m[0906 14-59-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03444, current rewards: 162.40954, mean: 0.11124
[32m[0906 14-59-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03442, current rewards: 166.41543, mean: 0.11021
[32m[0906 14-59-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03439, current rewards: 173.27881, mean: 0.11108
[32m[0906 14-59-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03437, current rewards: 137.07215, mean: 0.08514
[32m[0906 14-59-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03434, current rewards: 87.07215, mean: 0.05245
[32m[0906 14-59-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03433, current rewards: 37.07215, mean: 0.02168
[32m[0906 14-59-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03432, current rewards: -12.92785, mean: -0.00735
[32m[0906 14-59-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03430, current rewards: -62.92785, mean: -0.03477
[32m[0906 14-59-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03431, current rewards: -112.92785, mean: -0.06071
[32m[0906 14-59-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03431, current rewards: -162.92785, mean: -0.08530
[32m[0906 14-59-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03432, current rewards: -212.92785, mean: -0.10864
[32m[0906 14-59-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03432, current rewards: -262.92785, mean: -0.13081
[32m[0906 14-59-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03433, current rewards: -312.92785, mean: -0.15191
[32m[0906 14-59-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03433, current rewards: -362.92785, mean: -0.17200
[32m[0906 14-59-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03434, current rewards: -412.92785, mean: -0.19117
[32m[0906 14-59-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03435, current rewards: -462.92785, mean: -0.20947
[32m[0906 14-59-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03436, current rewards: -512.92785, mean: -0.22696
[32m[0906 14-59-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03436, current rewards: -562.92785, mean: -0.24369
[32m[0906 14-59-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03435, current rewards: -612.92785, mean: -0.25972
[32m[0906 14-59-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03434, current rewards: -662.92785, mean: -0.27507
[32m[0906 14-59-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03433, current rewards: -712.92785, mean: -0.28981
[32m[0906 14-59-52 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 14-59-52 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-59-52 @MBExp.py:227][0m Rewards obtained: [-752.9278483628419], Lows: [3], Highs: [930], Total time: 3259.483739999999
[32m[0906 15-01-10 @MBExp.py:144][0m ####################################################################
[32m[0906 15-01-10 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 15-01-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03503, current rewards: 1.28039, mean: 0.12804
[32m[0906 15-01-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03530, current rewards: 6.91628, mean: 0.11527
[32m[0906 15-01-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03539, current rewards: 12.55228, mean: 0.11411
[32m[0906 15-01-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03547, current rewards: 18.18697, mean: 0.11367
[32m[0906 15-01-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03545, current rewards: 23.82234, mean: 0.11344
[32m[0906 15-01-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03543, current rewards: 27.21008, mean: 0.10465
[32m[0906 15-01-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03544, current rewards: 32.70810, mean: 0.10551
[32m[0906 15-01-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03543, current rewards: 38.18124, mean: 0.10606
[32m[0906 15-01-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03542, current rewards: 43.71930, mean: 0.10663
[32m[0906 15-01-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03541, current rewards: 49.25596, mean: 0.10708
[32m[0906 15-01-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03533, current rewards: 54.79204, mean: 0.10744
[32m[0906 15-01-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03525, current rewards: 60.32997, mean: 0.10773
[32m[0906 15-01-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03518, current rewards: 65.86159, mean: 0.10797
[32m[0906 15-01-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03513, current rewards: 71.40735, mean: 0.10819
[32m[0906 15-01-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03509, current rewards: 76.95349, mean: 0.10839
[32m[0906 15-01-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03505, current rewards: 82.59953, mean: 0.10868
[32m[0906 15-01-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03503, current rewards: 86.17279, mean: 0.10639
[32m[0906 15-01-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03500, current rewards: 91.79966, mean: 0.10674
[32m[0906 15-01-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03497, current rewards: 97.42621, mean: 0.10706
[32m[0906 15-01-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03490, current rewards: 103.05057, mean: 0.10734
[32m[0906 15-01-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03486, current rewards: 108.67583, mean: 0.10760
[32m[0906 15-01-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03480, current rewards: 114.30131, mean: 0.10783
[32m[0906 15-01-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03475, current rewards: 119.92030, mean: 0.10804
[32m[0906 15-01-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03471, current rewards: 125.39347, mean: 0.10810
[32m[0906 15-01-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03467, current rewards: 129.02815, mean: 0.10663
[32m[0906 15-01-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03463, current rewards: 134.61340, mean: 0.10684
[32m[0906 15-01-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03460, current rewards: 140.19409, mean: 0.10702
[32m[0906 15-01-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03456, current rewards: 145.77693, mean: 0.10719
[32m[0906 15-01-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03453, current rewards: 151.35808, mean: 0.10735
[32m[0906 15-02-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03450, current rewards: 156.94212, mean: 0.10749
[32m[0906 15-02-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03448, current rewards: 162.52570, mean: 0.10763
[32m[0906 15-02-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03445, current rewards: 168.19349, mean: 0.10782
[32m[0906 15-02-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03442, current rewards: 173.78576, mean: 0.10794
[32m[0906 15-02-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03440, current rewards: 179.37364, mean: 0.10806
[32m[0906 15-02-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03438, current rewards: 184.95752, mean: 0.10816
[32m[0906 15-02-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03437, current rewards: 190.54487, mean: 0.10826
[32m[0906 15-02-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03434, current rewards: 196.13500, mean: 0.10836
[32m[0906 15-02-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03432, current rewards: 201.72628, mean: 0.10845
[32m[0906 15-02-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03433, current rewards: 206.34134, mean: 0.10803
[32m[0906 15-02-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03434, current rewards: 211.77662, mean: 0.10805
[32m[0906 15-02-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03434, current rewards: 217.25081, mean: 0.10808
[32m[0906 15-02-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03435, current rewards: 222.73406, mean: 0.10812
[32m[0906 15-02-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03435, current rewards: 228.22140, mean: 0.10816
[32m[0906 15-02-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03436, current rewards: 233.69721, mean: 0.10819
[32m[0906 15-02-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03437, current rewards: 239.18060, mean: 0.10823
[32m[0906 15-02-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03438, current rewards: 244.65871, mean: 0.10826
[32m[0906 15-02-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03438, current rewards: 250.66455, mean: 0.10851
[32m[0906 15-02-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03438, current rewards: 255.94861, mean: 0.10845
[32m[0906 15-02-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03437, current rewards: 261.49511, mean: 0.10850
[32m[0906 15-02-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03435, current rewards: 266.92229, mean: 0.10850
[32m[0906 15-02-36 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 15-02-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-02-37 @MBExp.py:227][0m Rewards obtained: [271.26682505223954], Lows: [2], Highs: [3], Total time: 3345.9989179999993
[32m[0906 15-03-57 @MBExp.py:144][0m ####################################################################
[32m[0906 15-03-57 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 15-03-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03567, current rewards: -0.99279, mean: -0.09928
[32m[0906 15-03-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03558, current rewards: 4.87886, mean: 0.08131
[32m[0906 15-04-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03570, current rewards: 10.60406, mean: 0.09640
[32m[0906 15-04-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03561, current rewards: 16.32940, mean: 0.10206
[32m[0906 15-04-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03564, current rewards: 22.05051, mean: 0.10500
[32m[0906 15-04-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03559, current rewards: 27.65960, mean: 0.10638
[32m[0906 15-04-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03558, current rewards: 33.19821, mean: 0.10709
[32m[0906 15-04-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03554, current rewards: 38.74229, mean: 0.10762
[32m[0906 15-04-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03553, current rewards: 42.72389, mean: 0.10420
[32m[0906 15-04-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03552, current rewards: 48.39119, mean: 0.10520
[32m[0906 15-04-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03540, current rewards: 53.97824, mean: 0.10584
[32m[0906 15-04-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03535, current rewards: 59.56236, mean: 0.10636
[32m[0906 15-04-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03528, current rewards: 65.14650, mean: 0.10680
[32m[0906 15-04-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03523, current rewards: 69.56401, mean: 0.10540
[32m[0906 15-04-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03518, current rewards: 75.05461, mean: 0.10571
[32m[0906 15-04-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03515, current rewards: 80.50066, mean: 0.10592
[32m[0906 15-04-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03512, current rewards: 86.06378, mean: 0.10625
[32m[0906 15-04-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03509, current rewards: 91.62454, mean: 0.10654
[32m[0906 15-04-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03503, current rewards: 97.18596, mean: 0.10680
[32m[0906 15-04-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03496, current rewards: 103.43266, mean: 0.10774
[32m[0906 15-04-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03489, current rewards: 108.98935, mean: 0.10791
[32m[0906 15-04-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03484, current rewards: 114.55473, mean: 0.10807
[32m[0906 15-04-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03478, current rewards: 120.11154, mean: 0.10821
[32m[0906 15-04-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03472, current rewards: 125.61810, mean: 0.10829
[32m[0906 15-04-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03468, current rewards: 131.17347, mean: 0.10841
[32m[0906 15-04-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03464, current rewards: 136.73552, mean: 0.10852
[32m[0906 15-04-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03460, current rewards: 142.29369, mean: 0.10862
[32m[0906 15-04-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03458, current rewards: 147.86080, mean: 0.10872
[32m[0906 15-04-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03455, current rewards: 153.42210, mean: 0.10881
[32m[0906 15-04-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03451, current rewards: 158.98074, mean: 0.10889
[32m[0906 15-04-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03449, current rewards: 164.54533, mean: 0.10897
[32m[0906 15-04-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03446, current rewards: 168.39030, mean: 0.10794
[32m[0906 15-04-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03443, current rewards: 174.31169, mean: 0.10827
[32m[0906 15-04-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03441, current rewards: 180.23443, mean: 0.10857
[32m[0906 15-04-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03439, current rewards: 186.15748, mean: 0.10886
[32m[0906 15-04-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03437, current rewards: 192.08028, mean: 0.10914
[32m[0906 15-04-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03435, current rewards: 198.00291, mean: 0.10939
[32m[0906 15-05-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03433, current rewards: 202.47251, mean: 0.10886
[32m[0906 15-05-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03431, current rewards: 208.02982, mean: 0.10892
[32m[0906 15-05-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03432, current rewards: 213.58716, mean: 0.10897
[32m[0906 15-05-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03433, current rewards: 219.14452, mean: 0.10903
[32m[0906 15-05-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03434, current rewards: 222.92688, mean: 0.10822
[32m[0906 15-05-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03434, current rewards: 228.84805, mean: 0.10846
[32m[0906 15-05-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03435, current rewards: 234.76974, mean: 0.10869
[32m[0906 15-05-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03435, current rewards: 240.69219, mean: 0.10891
[32m[0906 15-05-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03436, current rewards: 246.61457, mean: 0.10912
[32m[0906 15-05-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03436, current rewards: 250.02669, mean: 0.10824
[32m[0906 15-05-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03436, current rewards: 255.64199, mean: 0.10832
[32m[0906 15-05-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03437, current rewards: 261.21063, mean: 0.10839
[32m[0906 15-05-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03437, current rewards: 266.77487, mean: 0.10845
[32m[0906 15-05-23 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 15-05-23 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-05-23 @MBExp.py:227][0m Rewards obtained: [271.23007827431536], Lows: [3], Highs: [6], Total time: 3432.5560839999994
[32m[0906 15-06-45 @MBExp.py:144][0m ####################################################################
[32m[0906 15-06-45 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 15-06-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03455, current rewards: -1.20106, mean: -0.12011
[32m[0906 15-06-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03526, current rewards: 4.45197, mean: 0.07420
[32m[0906 15-06-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03525, current rewards: 10.12705, mean: 0.09206
[32m[0906 15-06-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03532, current rewards: 15.80357, mean: 0.09877
[32m[0906 15-06-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03535, current rewards: 21.47846, mean: 0.10228
[32m[0906 15-06-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03537, current rewards: 27.14628, mean: 0.10441
[32m[0906 15-06-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03538, current rewards: 32.78181, mean: 0.10575
[32m[0906 15-06-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03541, current rewards: 38.46503, mean: 0.10685
[32m[0906 15-07-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03541, current rewards: 44.15056, mean: 0.10768
[32m[0906 15-07-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03543, current rewards: 49.82896, mean: 0.10832
[32m[0906 15-07-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03536, current rewards: 55.51209, mean: 0.10885
[32m[0906 15-07-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03529, current rewards: 59.28220, mean: 0.10586
[32m[0906 15-07-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03523, current rewards: 65.04288, mean: 0.10663
[32m[0906 15-07-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03520, current rewards: 70.79674, mean: 0.10727
[32m[0906 15-07-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03514, current rewards: 76.58977, mean: 0.10787
[32m[0906 15-07-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03512, current rewards: 82.32292, mean: 0.10832
[32m[0906 15-07-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03508, current rewards: 88.05759, mean: 0.10871
[32m[0906 15-07-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03505, current rewards: 93.78512, mean: 0.10905
[32m[0906 15-07-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03502, current rewards: 99.52139, mean: 0.10936
[32m[0906 15-07-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03495, current rewards: 105.25514, mean: 0.10964
[32m[0906 15-07-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03488, current rewards: 110.98460, mean: 0.10989
[32m[0906 15-07-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03483, current rewards: 116.71726, mean: 0.11011
[32m[0906 15-07-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03478, current rewards: 122.44759, mean: 0.11031
[32m[0906 15-07-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03474, current rewards: 128.18176, mean: 0.11050
[32m[0906 15-07-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03471, current rewards: 133.91239, mean: 0.11067
[32m[0906 15-07-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03467, current rewards: 138.45312, mean: 0.10988
[32m[0906 15-07-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03462, current rewards: 144.07958, mean: 0.10998
[32m[0906 15-07-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03461, current rewards: 149.71142, mean: 0.11008
[32m[0906 15-07-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03457, current rewards: 155.33700, mean: 0.11017
[32m[0906 15-07-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03454, current rewards: 160.96791, mean: 0.11025
[32m[0906 15-07-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03451, current rewards: 166.61606, mean: 0.11034
[32m[0906 15-07-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03449, current rewards: 172.24729, mean: 0.11041
[32m[0906 15-07-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03446, current rewards: 177.87705, mean: 0.11048
[32m[0906 15-07-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03443, current rewards: 183.57101, mean: 0.11058
[32m[0906 15-07-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03441, current rewards: 189.55705, mean: 0.11085
[32m[0906 15-07-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03439, current rewards: 195.54787, mean: 0.11111
[32m[0906 15-07-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03438, current rewards: 201.54104, mean: 0.11135
[32m[0906 15-07-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03436, current rewards: 207.52588, mean: 0.11157
[32m[0906 15-07-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03435, current rewards: 213.73532, mean: 0.11190
[32m[0906 15-07-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03433, current rewards: 219.62280, mean: 0.11205
[32m[0906 15-07-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03433, current rewards: 223.33185, mean: 0.11111
[32m[0906 15-07-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03434, current rewards: 231.86977, mean: 0.11256
[32m[0906 15-07-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03434, current rewards: 240.40769, mean: 0.11394
[32m[0906 15-08-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03435, current rewards: 248.94561, mean: 0.11525
[32m[0906 15-08-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03436, current rewards: 257.48353, mean: 0.11651
[32m[0906 15-08-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03436, current rewards: 266.02145, mean: 0.11771
[32m[0906 15-08-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03436, current rewards: 274.46440, mean: 0.11882
[32m[0906 15-08-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03436, current rewards: 282.32393, mean: 0.11963
[32m[0906 15-08-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03436, current rewards: 241.58146, mean: 0.10024
[32m[0906 15-08-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03436, current rewards: 191.58146, mean: 0.07788
[32m[0906 15-08-12 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 15-08-12 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-08-12 @MBExp.py:227][0m Rewards obtained: [151.58146023651904], Lows: [3], Highs: [135], Total time: 3519.1295259999993
[32m[0906 15-09-36 @MBExp.py:144][0m ####################################################################
[32m[0906 15-09-36 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 15-09-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03352, current rewards: 1.08035, mean: 0.10803
[32m[0906 15-09-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03425, current rewards: 6.54025, mean: 0.10900
[32m[0906 15-09-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03477, current rewards: 12.07454, mean: 0.10977
[32m[0906 15-09-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03499, current rewards: 17.60786, mean: 0.11005
[32m[0906 15-09-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03508, current rewards: 23.14058, mean: 0.11019
[32m[0906 15-09-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03515, current rewards: 29.03458, mean: 0.11167
[32m[0906 15-09-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03520, current rewards: 33.59811, mean: 0.10838
[32m[0906 15-09-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03518, current rewards: -16.40189, mean: -0.04556
[32m[0906 15-09-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03521, current rewards: -66.40189, mean: -0.16196
[32m[0906 15-09-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03523, current rewards: -116.40189, mean: -0.25305
[32m[0906 15-09-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03517, current rewards: -166.40189, mean: -0.32628
[32m[0906 15-09-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03509, current rewards: -216.40189, mean: -0.38643
[32m[0906 15-09-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03504, current rewards: -244.08611, mean: -0.40014
[32m[0906 15-09-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03501, current rewards: -238.05262, mean: -0.36069
[32m[0906 15-10-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03498, current rewards: -232.08740, mean: -0.32688
[32m[0906 15-10-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03494, current rewards: -226.12222, mean: -0.29753
[32m[0906 15-10-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03491, current rewards: -220.16124, mean: -0.27180
[32m[0906 15-10-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03490, current rewards: -215.46916, mean: -0.25055
[32m[0906 15-10-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03489, current rewards: -209.93667, mean: -0.23070
[32m[0906 15-10-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03483, current rewards: -204.40503, mean: -0.21292
[32m[0906 15-10-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03478, current rewards: -198.86741, mean: -0.19690
[32m[0906 15-10-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03471, current rewards: -193.34412, mean: -0.18240
[32m[0906 15-10-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03465, current rewards: -187.81021, mean: -0.16920
[32m[0906 15-10-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03461, current rewards: -182.28025, mean: -0.15714
[32m[0906 15-10-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03456, current rewards: -176.75286, mean: -0.14608
[32m[0906 15-10-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03452, current rewards: -171.22197, mean: -0.13589
[32m[0906 15-10-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03448, current rewards: -167.51382, mean: -0.12787
[32m[0906 15-10-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03445, current rewards: -162.03021, mean: -0.11914
[32m[0906 15-10-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03442, current rewards: -156.54701, mean: -0.11103
[32m[0906 15-10-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03440, current rewards: -151.11775, mean: -0.10351
[32m[0906 15-10-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03437, current rewards: -146.80737, mean: -0.09722
[32m[0906 15-10-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03435, current rewards: -141.40118, mean: -0.09064
[32m[0906 15-10-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03433, current rewards: -136.00040, mean: -0.08447
[32m[0906 15-10-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03431, current rewards: -130.59771, mean: -0.07867
[32m[0906 15-10-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03430, current rewards: -125.19908, mean: -0.07322
[32m[0906 15-10-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03428, current rewards: -119.79905, mean: -0.06807
[32m[0906 15-10-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03426, current rewards: -116.33827, mean: -0.06428
[32m[0906 15-10-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03424, current rewards: -110.84317, mean: -0.05959
[32m[0906 15-10-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03423, current rewards: -105.36869, mean: -0.05517
[32m[0906 15-10-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03421, current rewards: -99.89739, mean: -0.05097
[32m[0906 15-10-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03419, current rewards: -94.42440, mean: -0.04698
[32m[0906 15-10-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03419, current rewards: -88.95284, mean: -0.04318
[32m[0906 15-10-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03420, current rewards: -83.48353, mean: -0.03957
[32m[0906 15-10-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03421, current rewards: -78.01078, mean: -0.03612
[32m[0906 15-10-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03422, current rewards: -73.66351, mean: -0.03333
[32m[0906 15-10-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03422, current rewards: -68.26304, mean: -0.03020
[32m[0906 15-10-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03422, current rewards: -63.03152, mean: -0.02729
[32m[0906 15-10-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03423, current rewards: -57.63289, mean: -0.02442
[32m[0906 15-10-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03424, current rewards: -52.23828, mean: -0.02168
[32m[0906 15-11-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03424, current rewards: -46.84572, mean: -0.01904
[32m[0906 15-11-02 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-11-02 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-11-02 @MBExp.py:227][0m Rewards obtained: [-42.528645128681], Lows: [2], Highs: [284], Total time: 3605.4002559999994
[32m[0906 15-12-28 @MBExp.py:144][0m ####################################################################
[32m[0906 15-12-28 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 15-12-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03449, current rewards: -0.91900, mean: -0.09190
[32m[0906 15-12-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03448, current rewards: 4.65934, mean: 0.07766
[32m[0906 15-12-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03453, current rewards: 10.22723, mean: 0.09297
[32m[0906 15-12-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03479, current rewards: 15.80005, mean: 0.09875
[32m[0906 15-12-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03492, current rewards: 21.34645, mean: 0.10165
[32m[0906 15-12-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03504, current rewards: 26.91876, mean: 0.10353
[32m[0906 15-12-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03514, current rewards: 30.98297, mean: 0.09995
[32m[0906 15-12-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03518, current rewards: 36.54650, mean: 0.10152
[32m[0906 15-12-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03522, current rewards: 42.11091, mean: 0.10271
[32m[0906 15-12-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03526, current rewards: 47.67239, mean: 0.10364
[32m[0906 15-12-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03520, current rewards: 53.23172, mean: 0.10438
[32m[0906 15-12-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03514, current rewards: 58.79275, mean: 0.10499
[32m[0906 15-12-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03509, current rewards: 64.49930, mean: 0.10574
[32m[0906 15-12-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03505, current rewards: 70.04150, mean: 0.10612
[32m[0906 15-12-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03502, current rewards: 74.49796, mean: 0.10493
[32m[0906 15-12-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03497, current rewards: 80.06317, mean: 0.10535
[32m[0906 15-12-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03493, current rewards: 85.62880, mean: 0.10571
[32m[0906 15-12-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03490, current rewards: 91.19185, mean: 0.10604
[32m[0906 15-13-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03486, current rewards: 96.76350, mean: 0.10633
[32m[0906 15-13-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03480, current rewards: 102.32637, mean: 0.10659
[32m[0906 15-13-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03475, current rewards: 107.92030, mean: 0.10685
[32m[0906 15-13-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03469, current rewards: 113.51488, mean: 0.10709
[32m[0906 15-13-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03464, current rewards: 117.35164, mean: 0.10572
[32m[0906 15-13-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03460, current rewards: 125.00672, mean: 0.10776
[32m[0906 15-13-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03456, current rewards: 132.66180, mean: 0.10964
[32m[0906 15-13-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03452, current rewards: 140.31688, mean: 0.11136
[32m[0906 15-13-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03448, current rewards: 147.97197, mean: 0.11296
[32m[0906 15-13-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03445, current rewards: 155.62705, mean: 0.11443
[32m[0906 15-13-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03442, current rewards: 163.28213, mean: 0.11580
[32m[0906 15-13-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03439, current rewards: 170.93721, mean: 0.11708
[32m[0906 15-13-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03436, current rewards: 154.37715, mean: 0.10224
[32m[0906 15-13-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03434, current rewards: 104.37715, mean: 0.06691
[32m[0906 15-13-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03432, current rewards: 54.37715, mean: 0.03377
[32m[0906 15-13-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03430, current rewards: 4.37715, mean: 0.00264
[32m[0906 15-13-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03428, current rewards: -45.62285, mean: -0.02668
[32m[0906 15-13-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03426, current rewards: -95.62285, mean: -0.05433
[32m[0906 15-13-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03424, current rewards: -145.62285, mean: -0.08045
[32m[0906 15-13-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03422, current rewards: -195.62285, mean: -0.10517
[32m[0906 15-13-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03421, current rewards: -245.62285, mean: -0.12860
[32m[0906 15-13-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03419, current rewards: -295.62285, mean: -0.15083
[32m[0906 15-13-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03418, current rewards: -345.62285, mean: -0.17195
[32m[0906 15-13-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03417, current rewards: -395.62285, mean: -0.19205
[32m[0906 15-13-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03417, current rewards: -445.62285, mean: -0.21120
[32m[0906 15-13-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03418, current rewards: -495.62285, mean: -0.22946
[32m[0906 15-13-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03419, current rewards: -545.62285, mean: -0.24689
[32m[0906 15-13-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03420, current rewards: -595.62285, mean: -0.26355
[32m[0906 15-13-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03421, current rewards: -645.62285, mean: -0.27949
[32m[0906 15-13-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03421, current rewards: -695.62285, mean: -0.29476
[32m[0906 15-13-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03422, current rewards: -745.62285, mean: -0.30939
[32m[0906 15-13-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03422, current rewards: -795.62285, mean: -0.32342
[32m[0906 15-13-54 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-13-54 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-13-54 @MBExp.py:227][0m Rewards obtained: [-835.6228456836368], Lows: [3], Highs: [1014], Total time: 3691.6383999999994
[32m[0906 15-15-22 @MBExp.py:144][0m ####################################################################
[32m[0906 15-15-22 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 15-15-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03495, current rewards: 0.16604, mean: 0.01660
[32m[0906 15-15-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03469, current rewards: 5.77613, mean: 0.09627
[32m[0906 15-15-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03462, current rewards: 11.33289, mean: 0.10303
[32m[0906 15-15-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03448, current rewards: 16.86309, mean: 0.10539
[32m[0906 15-15-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03453, current rewards: 22.22939, mean: 0.10585
[32m[0906 15-15-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03473, current rewards: 27.75813, mean: 0.10676
[32m[0906 15-15-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03483, current rewards: 33.28183, mean: 0.10736
[32m[0906 15-15-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03490, current rewards: 38.80442, mean: 0.10779
[32m[0906 15-15-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03494, current rewards: 44.33043, mean: 0.10812
[32m[0906 15-15-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03502, current rewards: 47.73810, mean: 0.10378
[32m[0906 15-15-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03500, current rewards: 53.26576, mean: 0.10444
[32m[0906 15-15-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03495, current rewards: 58.79136, mean: 0.10498
[32m[0906 15-15-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03492, current rewards: 64.50804, mean: 0.10575
[32m[0906 15-15-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03489, current rewards: 70.05753, mean: 0.10615
[32m[0906 15-15-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03488, current rewards: 75.60287, mean: 0.10648
[32m[0906 15-15-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03486, current rewards: 81.14950, mean: 0.10678
[32m[0906 15-15-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03484, current rewards: 86.69625, mean: 0.10703
[32m[0906 15-15-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03484, current rewards: 90.32498, mean: 0.10503
[32m[0906 15-15-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03482, current rewards: 96.23243, mean: 0.10575
[32m[0906 15-15-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03475, current rewards: 102.14669, mean: 0.10640
[32m[0906 15-15-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03470, current rewards: 108.02080, mean: 0.10695
[32m[0906 15-15-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03465, current rewards: 113.93762, mean: 0.10749
[32m[0906 15-16-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03461, current rewards: 119.85784, mean: 0.10798
[32m[0906 15-16-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03457, current rewards: 125.78050, mean: 0.10843
[32m[0906 15-16-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03453, current rewards: 131.70507, mean: 0.10885
[32m[0906 15-16-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03449, current rewards: 137.62320, mean: 0.10922
[32m[0906 15-16-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03446, current rewards: 139.40733, mean: 0.10642
[32m[0906 15-16-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03443, current rewards: 144.98465, mean: 0.10661
[32m[0906 15-16-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03440, current rewards: 150.52438, mean: 0.10675
[32m[0906 15-16-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03436, current rewards: 155.92336, mean: 0.10680
[32m[0906 15-16-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03433, current rewards: 161.43727, mean: 0.10691
[32m[0906 15-16-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03431, current rewards: 166.95627, mean: 0.10702
[32m[0906 15-16-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03428, current rewards: 172.47199, mean: 0.10713
[32m[0906 15-16-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03427, current rewards: 177.98896, mean: 0.10722
[32m[0906 15-16-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03425, current rewards: 183.50491, mean: 0.10731
[32m[0906 15-16-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03423, current rewards: 189.02032, mean: 0.10740
[32m[0906 15-16-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03421, current rewards: 194.53607, mean: 0.10748
[32m[0906 15-16-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03419, current rewards: 200.24829, mean: 0.10766
[32m[0906 15-16-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03418, current rewards: 205.82586, mean: 0.10776
[32m[0906 15-16-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03417, current rewards: 208.07044, mean: 0.10616
[32m[0906 15-16-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03416, current rewards: 213.64584, mean: 0.10629
[32m[0906 15-16-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03414, current rewards: 219.23194, mean: 0.10642
[32m[0906 15-16-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03413, current rewards: 224.81459, mean: 0.10655
[32m[0906 15-16-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03413, current rewards: 230.39365, mean: 0.10666
[32m[0906 15-16-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03414, current rewards: 235.97551, mean: 0.10678
[32m[0906 15-16-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03415, current rewards: 239.99867, mean: 0.10619
[32m[0906 15-16-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03416, current rewards: 245.58690, mean: 0.10631
[32m[0906 15-16-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03417, current rewards: 251.17788, mean: 0.10643
[32m[0906 15-16-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03418, current rewards: 256.76283, mean: 0.10654
[32m[0906 15-16-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03419, current rewards: 262.35315, mean: 0.10665
[32m[0906 15-16-48 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-16-48 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-16-48 @MBExp.py:227][0m Rewards obtained: [266.82129321021375], Lows: [5], Highs: [4], Total time: 3777.7752909999995
[32m[0906 15-18-18 @MBExp.py:144][0m ####################################################################
[32m[0906 15-18-18 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 15-18-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03336, current rewards: -0.00042, mean: -0.00004
[32m[0906 15-18-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03429, current rewards: 5.60797, mean: 0.09347
[32m[0906 15-18-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03437, current rewards: 11.08887, mean: 0.10081
[32m[0906 15-18-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03445, current rewards: 16.57062, mean: 0.10357
[32m[0906 15-18-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03446, current rewards: 21.91520, mean: 0.10436
[32m[0906 15-18-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03452, current rewards: 27.36538, mean: 0.10525
[32m[0906 15-18-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03466, current rewards: 32.81474, mean: 0.10585
[32m[0906 15-18-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03475, current rewards: 38.26008, mean: 0.10628
[32m[0906 15-18-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03485, current rewards: 43.70879, mean: 0.10661
[32m[0906 15-18-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03492, current rewards: 49.15652, mean: 0.10686
[32m[0906 15-18-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03493, current rewards: 54.60357, mean: 0.10707
[32m[0906 15-18-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03490, current rewards: 60.05267, mean: 0.10724
[32m[0906 15-18-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03486, current rewards: 64.51253, mean: 0.10576
[32m[0906 15-18-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03483, current rewards: 70.23113, mean: 0.10641
[32m[0906 15-18-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03480, current rewards: 75.95699, mean: 0.10698
[32m[0906 15-18-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03478, current rewards: 81.67620, mean: 0.10747
[32m[0906 15-18-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03476, current rewards: 87.39813, mean: 0.10790
[32m[0906 15-18-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03475, current rewards: 93.11548, mean: 0.10827
[32m[0906 15-18-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03473, current rewards: 98.83723, mean: 0.10861
[32m[0906 15-18-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03465, current rewards: 104.55744, mean: 0.10891
[32m[0906 15-18-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03459, current rewards: 110.42124, mean: 0.10933
[32m[0906 15-18-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03454, current rewards: 116.08377, mean: 0.10951
[32m[0906 15-18-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03450, current rewards: 121.75295, mean: 0.10969
[32m[0906 15-18-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03446, current rewards: 127.41869, mean: 0.10984
[32m[0906 15-19-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03443, current rewards: 133.08127, mean: 0.10998
[32m[0906 15-19-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03440, current rewards: 137.72450, mean: 0.10931
[32m[0906 15-19-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03437, current rewards: 143.43982, mean: 0.10950
[32m[0906 15-19-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03434, current rewards: 149.15410, mean: 0.10967
[32m[0906 15-19-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03431, current rewards: 154.95382, mean: 0.10990
[32m[0906 15-19-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03429, current rewards: 160.64405, mean: 0.11003
[32m[0906 15-19-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03426, current rewards: 166.33574, mean: 0.11016
[32m[0906 15-19-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03424, current rewards: 172.02419, mean: 0.11027
[32m[0906 15-19-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03422, current rewards: 175.72736, mean: 0.10915
[32m[0906 15-19-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03420, current rewards: 181.32776, mean: 0.10923
[32m[0906 15-19-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03418, current rewards: 186.93031, mean: 0.10932
[32m[0906 15-19-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03417, current rewards: 192.53986, mean: 0.10940
[32m[0906 15-19-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03416, current rewards: 198.09437, mean: 0.10944
[32m[0906 15-19-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03415, current rewards: 203.68222, mean: 0.10951
[32m[0906 15-19-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03414, current rewards: 209.29114, mean: 0.10958
[32m[0906 15-19-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03412, current rewards: 214.89393, mean: 0.10964
[32m[0906 15-19-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03410, current rewards: 220.50190, mean: 0.10970
[32m[0906 15-19-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03410, current rewards: 221.93900, mean: 0.10774
[32m[0906 15-19-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03409, current rewards: 227.71547, mean: 0.10792
[32m[0906 15-19-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03408, current rewards: 233.49459, mean: 0.10810
[32m[0906 15-19-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03408, current rewards: 239.27224, mean: 0.10827
[32m[0906 15-19-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03409, current rewards: 244.84326, mean: 0.10834
[32m[0906 15-19-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03410, current rewards: 249.64566, mean: 0.10807
[32m[0906 15-19-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03410, current rewards: 255.50495, mean: 0.10826
[32m[0906 15-19-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03411, current rewards: 261.36610, mean: 0.10845
[32m[0906 15-19-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03412, current rewards: 267.23218, mean: 0.10863
[32m[0906 15-19-44 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-19-44 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-19-44 @MBExp.py:227][0m Rewards obtained: [271.9196973485608], Lows: [3], Highs: [4], Total time: 3863.7307089999995
[32m[0906 15-21-16 @MBExp.py:144][0m ####################################################################
[32m[0906 15-21-16 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 15-21-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03401, current rewards: -1.14963, mean: -0.11496
[32m[0906 15-21-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03417, current rewards: 4.33219, mean: 0.07220
[32m[0906 15-21-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03422, current rewards: 9.81681, mean: 0.08924
[32m[0906 15-21-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03425, current rewards: 15.29858, mean: 0.09562
[32m[0906 15-21-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03429, current rewards: 20.77652, mean: 0.09894
[32m[0906 15-21-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03430, current rewards: 26.25523, mean: 0.10098
[32m[0906 15-21-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03434, current rewards: 31.73936, mean: 0.10239
[32m[0906 15-21-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03447, current rewards: 37.22027, mean: 0.10339
[32m[0906 15-21-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03460, current rewards: 42.66224, mean: 0.10405
[32m[0906 15-21-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03467, current rewards: 48.15490, mean: 0.10468
[32m[0906 15-21-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03470, current rewards: 53.64568, mean: 0.10519
[32m[0906 15-21-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03468, current rewards: 59.22527, mean: 0.10576
[32m[0906 15-21-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03466, current rewards: 64.71939, mean: 0.10610
[32m[0906 15-21-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03463, current rewards: 70.21374, mean: 0.10638
[32m[0906 15-21-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03461, current rewards: 75.70871, mean: 0.10663
[32m[0906 15-21-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03460, current rewards: 81.20555, mean: 0.10685
[32m[0906 15-21-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03459, current rewards: 86.69874, mean: 0.10704
[32m[0906 15-21-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03458, current rewards: 92.19074, mean: 0.10720
[32m[0906 15-21-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03457, current rewards: 97.66482, mean: 0.10732
[32m[0906 15-21-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03451, current rewards: 103.12962, mean: 0.10743
[32m[0906 15-21-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03446, current rewards: 108.49279, mean: 0.10742
[32m[0906 15-21-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03441, current rewards: 113.94562, mean: 0.10750
[32m[0906 15-21-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03438, current rewards: 119.39747, mean: 0.10757
[32m[0906 15-21-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03434, current rewards: 124.85009, mean: 0.10763
[32m[0906 15-21-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03431, current rewards: 130.30533, mean: 0.10769
[32m[0906 15-22-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03428, current rewards: 135.75374, mean: 0.10774
[32m[0906 15-22-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03425, current rewards: 141.20753, mean: 0.10779
[32m[0906 15-22-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03422, current rewards: 146.66099, mean: 0.10784
[32m[0906 15-22-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03419, current rewards: 152.39540, mean: 0.10808
[32m[0906 15-22-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03417, current rewards: 157.95297, mean: 0.10819
[32m[0906 15-22-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03415, current rewards: 163.50859, mean: 0.10828
[32m[0906 15-22-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03413, current rewards: 167.64044, mean: 0.10746
[32m[0906 15-22-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03411, current rewards: 174.73699, mean: 0.10853
[32m[0906 15-22-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03409, current rewards: 181.83354, mean: 0.10954
[32m[0906 15-22-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03407, current rewards: 188.93009, mean: 0.11049
[32m[0906 15-22-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03406, current rewards: 196.02664, mean: 0.11138
[32m[0906 15-22-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03404, current rewards: 203.15843, mean: 0.11224
[32m[0906 15-22-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03403, current rewards: 212.21187, mean: 0.11409
[32m[0906 15-22-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03402, current rewards: 220.47261, mean: 0.11543
[32m[0906 15-22-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03402, current rewards: 225.41837, mean: 0.11501
[32m[0906 15-22-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03401, current rewards: 230.81957, mean: 0.11484
[32m[0906 15-22-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03400, current rewards: 236.22235, mean: 0.11467
[32m[0906 15-22-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03399, current rewards: 241.62467, mean: 0.11451
[32m[0906 15-22-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03399, current rewards: 247.02770, mean: 0.11436
[32m[0906 15-22-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03397, current rewards: 251.29328, mean: 0.11371
[32m[0906 15-22-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03397, current rewards: 256.66571, mean: 0.11357
[32m[0906 15-22-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03399, current rewards: 262.15930, mean: 0.11349
[32m[0906 15-22-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03400, current rewards: 267.65962, mean: 0.11342
[32m[0906 15-22-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03401, current rewards: 273.15321, mean: 0.11334
[32m[0906 15-22-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03402, current rewards: 278.64727, mean: 0.11327
[32m[0906 15-22-42 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 15-22-42 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-22-42 @MBExp.py:227][0m Rewards obtained: [283.0405547095749], Lows: [1], Highs: [3], Total time: 3949.4522269999993
[32m[0906 15-24-16 @MBExp.py:144][0m ####################################################################
[32m[0906 15-24-16 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 15-24-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03382, current rewards: 0.08311, mean: 0.00831
[32m[0906 15-24-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03430, current rewards: 5.66650, mean: 0.09444
[32m[0906 15-24-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03420, current rewards: 11.21906, mean: 0.10199
[32m[0906 15-24-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03425, current rewards: 16.62340, mean: 0.10390
[32m[0906 15-24-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03432, current rewards: 22.11435, mean: 0.10531
[32m[0906 15-24-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03435, current rewards: 27.64185, mean: 0.10631
[32m[0906 15-24-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03435, current rewards: 33.16659, mean: 0.10699
[32m[0906 15-24-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03436, current rewards: 38.69176, mean: 0.10748
[32m[0906 15-24-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03450, current rewards: 42.08629, mean: 0.10265
[32m[0906 15-24-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03461, current rewards: 47.59780, mean: 0.10347
[32m[0906 15-24-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03467, current rewards: 53.11480, mean: 0.10415
[32m[0906 15-24-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03465, current rewards: 58.62985, mean: 0.10470
[32m[0906 15-24-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03463, current rewards: 64.37587, mean: 0.10553
[32m[0906 15-24-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03463, current rewards: 69.88976, mean: 0.10589
[32m[0906 15-24-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03462, current rewards: 75.40689, mean: 0.10621
[32m[0906 15-24-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03462, current rewards: 80.92104, mean: 0.10648
[32m[0906 15-24-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03462, current rewards: 86.43411, mean: 0.10671
[32m[0906 15-24-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03461, current rewards: 90.03379, mean: 0.10469
[32m[0906 15-24-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03461, current rewards: 95.64108, mean: 0.10510
[32m[0906 15-24-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03456, current rewards: 101.24645, mean: 0.10547
[32m[0906 15-24-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03451, current rewards: 106.66608, mean: 0.10561
[32m[0906 15-24-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03447, current rewards: 110.05875, mean: 0.10383
[32m[0906 15-24-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03443, current rewards: 115.60049, mean: 0.10414
[32m[0906 15-24-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03439, current rewards: 121.14855, mean: 0.10444
[32m[0906 15-24-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03436, current rewards: 126.69214, mean: 0.10470
[32m[0906 15-24-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03433, current rewards: 132.23670, mean: 0.10495
[32m[0906 15-25-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03430, current rewards: 137.78054, mean: 0.10518
[32m[0906 15-25-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03427, current rewards: 143.32342, mean: 0.10538
[32m[0906 15-25-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03425, current rewards: 148.86621, mean: 0.10558
[32m[0906 15-25-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03423, current rewards: 154.58496, mean: 0.10588
[32m[0906 15-25-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03420, current rewards: 160.12490, mean: 0.10604
[32m[0906 15-25-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03419, current rewards: 165.66394, mean: 0.10619
[32m[0906 15-25-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03418, current rewards: 171.19954, mean: 0.10634
[32m[0906 15-25-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03416, current rewards: 176.73788, mean: 0.10647
[32m[0906 15-25-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03415, current rewards: 182.27939, mean: 0.10660
[32m[0906 15-25-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03413, current rewards: 187.82242, mean: 0.10672
[32m[0906 15-25-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03412, current rewards: 192.14220, mean: 0.10616
[32m[0906 15-25-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03412, current rewards: 197.62232, mean: 0.10625
[32m[0906 15-25-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03411, current rewards: 203.01305, mean: 0.10629
[32m[0906 15-25-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03410, current rewards: 208.40448, mean: 0.10633
[32m[0906 15-25-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03409, current rewards: 213.79949, mean: 0.10637
[32m[0906 15-25-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03407, current rewards: 219.19171, mean: 0.10640
[32m[0906 15-25-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03406, current rewards: 222.96842, mean: 0.10567
[32m[0906 15-25-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03405, current rewards: 229.28385, mean: 0.10615
[32m[0906 15-25-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03404, current rewards: 235.59927, mean: 0.10661
[32m[0906 15-25-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03403, current rewards: 241.68665, mean: 0.10694
[32m[0906 15-25-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03402, current rewards: 205.47999, mean: 0.08895
[32m[0906 15-25-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03404, current rewards: 155.47999, mean: 0.06588
[32m[0906 15-25-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03404, current rewards: 105.47999, mean: 0.04377
[32m[0906 15-25-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03406, current rewards: 55.47999, mean: 0.02255
[32m[0906 15-25-42 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-25-42 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-25-42 @MBExp.py:227][0m Rewards obtained: [15.479992456233077], Lows: [4], Highs: [229], Total time: 4035.2845529999995
[32m[0906 15-27-18 @MBExp.py:144][0m ####################################################################
[32m[0906 15-27-18 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 15-27-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03441, current rewards: -0.00668, mean: -0.00067
[32m[0906 15-27-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03448, current rewards: 5.51047, mean: 0.09184
[32m[0906 15-27-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03444, current rewards: 11.02905, mean: 0.10026
[32m[0906 15-27-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03444, current rewards: 16.54970, mean: 0.10344
[32m[0906 15-27-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03449, current rewards: 22.20289, mean: 0.10573
[32m[0906 15-27-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03449, current rewards: 27.72799, mean: 0.10665
[32m[0906 15-27-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03448, current rewards: 33.25230, mean: 0.10727
[32m[0906 15-27-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03449, current rewards: 38.77212, mean: 0.10770
[32m[0906 15-27-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03448, current rewards: 44.29685, mean: 0.10804
[32m[0906 15-27-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03456, current rewards: 49.82269, mean: 0.10831
[32m[0906 15-27-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03462, current rewards: 55.35566, mean: 0.10854
[32m[0906 15-27-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03460, current rewards: 60.95195, mean: 0.10884
[32m[0906 15-27-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03459, current rewards: 66.44693, mean: 0.10893
[32m[0906 15-27-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03458, current rewards: 72.03862, mean: 0.10915
[32m[0906 15-27-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03458, current rewards: 77.62395, mean: 0.10933
[32m[0906 15-27-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03457, current rewards: 83.21000, mean: 0.10949
[32m[0906 15-27-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03458, current rewards: 88.79354, mean: 0.10962
[32m[0906 15-27-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03457, current rewards: 94.37411, mean: 0.10974
[32m[0906 15-27-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03455, current rewards: 97.84711, mean: 0.10752
[32m[0906 15-27-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03451, current rewards: 103.38860, mean: 0.10770
[32m[0906 15-27-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03447, current rewards: 108.93650, mean: 0.10786
[32m[0906 15-27-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03443, current rewards: 114.61466, mean: 0.10813
[32m[0906 15-27-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03440, current rewards: 120.19799, mean: 0.10829
[32m[0906 15-27-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03437, current rewards: 125.78041, mean: 0.10843
[32m[0906 15-28-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03433, current rewards: 130.13295, mean: 0.10755
[32m[0906 15-28-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03431, current rewards: 135.64389, mean: 0.10765
[32m[0906 15-28-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03427, current rewards: 141.15746, mean: 0.10775
[32m[0906 15-28-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03425, current rewards: 146.66738, mean: 0.10784
[32m[0906 15-28-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03423, current rewards: 152.18007, mean: 0.10793
[32m[0906 15-28-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03421, current rewards: 157.69413, mean: 0.10801
[32m[0906 15-28-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03419, current rewards: 163.20725, mean: 0.10808
[32m[0906 15-28-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03417, current rewards: 166.93385, mean: 0.10701
[32m[0906 15-28-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03415, current rewards: 172.49256, mean: 0.10714
[32m[0906 15-28-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03414, current rewards: 178.05818, mean: 0.10726
[32m[0906 15-28-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03412, current rewards: 183.62549, mean: 0.10738
[32m[0906 15-28-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03410, current rewards: 189.18672, mean: 0.10749
[32m[0906 15-28-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03409, current rewards: 194.74823, mean: 0.10760
[32m[0906 15-28-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03408, current rewards: 200.23707, mean: 0.10765
[32m[0906 15-28-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03407, current rewards: 205.79950, mean: 0.10775
[32m[0906 15-28-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03406, current rewards: 211.36793, mean: 0.10784
[32m[0906 15-28-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03405, current rewards: 216.93474, mean: 0.10793
[32m[0906 15-28-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03404, current rewards: 222.49777, mean: 0.10801
[32m[0906 15-28-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03403, current rewards: 227.08795, mean: 0.10762
[32m[0906 15-28-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03403, current rewards: 232.61667, mean: 0.10769
[32m[0906 15-28-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03402, current rewards: 238.14802, mean: 0.10776
[32m[0906 15-28-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03402, current rewards: 243.75643, mean: 0.10786
[32m[0906 15-28-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03401, current rewards: 249.24606, mean: 0.10790
[32m[0906 15-28-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03400, current rewards: 254.74294, mean: 0.10794
[32m[0906 15-28-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03402, current rewards: 260.24073, mean: 0.10798
[32m[0906 15-28-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03403, current rewards: 265.73630, mean: 0.10802
[32m[0906 15-28-44 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 15-28-44 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-28-44 @MBExp.py:227][0m Rewards obtained: [270.1337474224058], Lows: [2], Highs: [3], Total time: 4121.052492999999
[32m[0906 15-30-22 @MBExp.py:144][0m ####################################################################
[32m[0906 15-30-22 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 15-30-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03389, current rewards: -1.21696, mean: -0.12170
[32m[0906 15-30-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03434, current rewards: 4.06842, mean: 0.06781
[32m[0906 15-30-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03438, current rewards: 9.40800, mean: 0.08553
[32m[0906 15-30-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03442, current rewards: 14.77388, mean: 0.09234
[32m[0906 15-30-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03444, current rewards: 20.12447, mean: 0.09583
[32m[0906 15-30-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03444, current rewards: 25.47927, mean: 0.09800
[32m[0906 15-30-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03447, current rewards: 30.82098, mean: 0.09942
[32m[0906 15-30-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03447, current rewards: 36.16897, mean: 0.10047
[32m[0906 15-30-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03447, current rewards: 41.51765, mean: 0.10126
[32m[0906 15-30-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03446, current rewards: 46.87720, mean: 0.10191
[32m[0906 15-30-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03451, current rewards: 50.21170, mean: 0.09845
[32m[0906 15-30-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03455, current rewards: 55.81600, mean: 0.09967
[32m[0906 15-30-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03454, current rewards: 61.49238, mean: 0.10081
[32m[0906 15-30-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03453, current rewards: 67.06137, mean: 0.10161
[32m[0906 15-30-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03452, current rewards: 72.63413, mean: 0.10230
[32m[0906 15-30-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03454, current rewards: 78.20668, mean: 0.10290
[32m[0906 15-30-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03453, current rewards: 82.03503, mean: 0.10128
[32m[0906 15-30-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03453, current rewards: 87.63996, mean: 0.10191
[32m[0906 15-30-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03453, current rewards: 93.24456, mean: 0.10247
[32m[0906 15-30-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03450, current rewards: 98.84617, mean: 0.10296
[32m[0906 15-30-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03445, current rewards: 104.41834, mean: 0.10338
[32m[0906 15-30-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03441, current rewards: 110.02613, mean: 0.10380
[32m[0906 15-31-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03438, current rewards: 115.63177, mean: 0.10417
[32m[0906 15-31-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03434, current rewards: 120.07382, mean: 0.10351
[32m[0906 15-31-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03430, current rewards: 125.54140, mean: 0.10375
[32m[0906 15-31-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03428, current rewards: 131.00321, mean: 0.10397
[32m[0906 15-31-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03425, current rewards: 136.46873, mean: 0.10417
[32m[0906 15-31-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03422, current rewards: 141.93140, mean: 0.10436
[32m[0906 15-31-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03421, current rewards: 147.53471, mean: 0.10463
[32m[0906 15-31-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03419, current rewards: 153.05604, mean: 0.10483
[32m[0906 15-31-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03417, current rewards: 158.57523, mean: 0.10502
[32m[0906 15-31-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03415, current rewards: 162.10921, mean: 0.10392
[32m[0906 15-31-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03415, current rewards: 167.76051, mean: 0.10420
[32m[0906 15-31-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03414, current rewards: 173.40146, mean: 0.10446
[32m[0906 15-31-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03412, current rewards: 179.04663, mean: 0.10471
[32m[0906 15-31-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03411, current rewards: 184.69668, mean: 0.10494
[32m[0906 15-31-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03409, current rewards: 190.33998, mean: 0.10516
[32m[0906 15-31-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03408, current rewards: 192.25442, mean: 0.10336
[32m[0906 15-31-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03407, current rewards: 200.55454, mean: 0.10500
[32m[0906 15-31-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03406, current rewards: 208.85466, mean: 0.10656
[32m[0906 15-31-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03405, current rewards: 217.15478, mean: 0.10804
[32m[0906 15-31-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03404, current rewards: 225.45490, mean: 0.10944
[32m[0906 15-31-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03404, current rewards: 233.75502, mean: 0.11078
[32m[0906 15-31-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03403, current rewards: 242.05514, mean: 0.11206
[32m[0906 15-31-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03402, current rewards: 201.38316, mean: 0.09112
[32m[0906 15-31-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03401, current rewards: 151.38316, mean: 0.06698
[32m[0906 15-31-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03400, current rewards: 101.38316, mean: 0.04389
[32m[0906 15-31-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03399, current rewards: 51.38316, mean: 0.02177
[32m[0906 15-31-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03398, current rewards: 1.38316, mean: 0.00057
[32m[0906 15-31-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03399, current rewards: -48.61684, mean: -0.01976
[32m[0906 15-31-48 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 15-31-48 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-31-48 @MBExp.py:227][0m Rewards obtained: [-88.61683918388897], Lows: [5], Highs: [335], Total time: 4206.718904999999
[32m[0906 15-33-28 @MBExp.py:144][0m ####################################################################
[32m[0906 15-33-28 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 15-33-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03383, current rewards: -0.03259, mean: -0.00326
[32m[0906 15-33-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03428, current rewards: 5.51277, mean: 0.09188
[32m[0906 15-33-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03440, current rewards: 11.06027, mean: 0.10055
[32m[0906 15-33-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03447, current rewards: 16.78501, mean: 0.10491
[32m[0906 15-33-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03446, current rewards: 22.32964, mean: 0.10633
[32m[0906 15-33-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03447, current rewards: 27.85790, mean: 0.10715
[32m[0906 15-33-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03444, current rewards: 33.38536, mean: 0.10769
[32m[0906 15-33-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03447, current rewards: 38.90846, mean: 0.10808
[32m[0906 15-33-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03450, current rewards: 44.42954, mean: 0.10836
[32m[0906 15-33-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03451, current rewards: 49.96243, mean: 0.10861
[32m[0906 15-33-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03448, current rewards: 53.50172, mean: 0.10491
[32m[0906 15-33-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03453, current rewards: 58.92922, mean: 0.10523
[32m[0906 15-33-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03454, current rewards: 64.47827, mean: 0.10570
[32m[0906 15-33-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03454, current rewards: 70.02933, mean: 0.10611
[32m[0906 15-33-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03453, current rewards: 75.57933, mean: 0.10645
[32m[0906 15-33-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03456, current rewards: 81.12623, mean: 0.10675
[32m[0906 15-33-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03455, current rewards: 84.65287, mean: 0.10451
[32m[0906 15-33-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03456, current rewards: 90.14509, mean: 0.10482
[32m[0906 15-34-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03455, current rewards: 95.63637, mean: 0.10509
[32m[0906 15-34-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03452, current rewards: 101.10528, mean: 0.10532
[32m[0906 15-34-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03446, current rewards: 106.58770, mean: 0.10553
[32m[0906 15-34-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03442, current rewards: 112.06970, mean: 0.10573
[32m[0906 15-34-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03439, current rewards: 117.55016, mean: 0.10590
[32m[0906 15-34-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03437, current rewards: 123.03158, mean: 0.10606
[32m[0906 15-34-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03434, current rewards: 126.73100, mean: 0.10474
[32m[0906 15-34-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03430, current rewards: 132.03838, mean: 0.10479
[32m[0906 15-34-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03428, current rewards: 137.34824, mean: 0.10485
[32m[0906 15-34-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03425, current rewards: 142.65526, mean: 0.10489
[32m[0906 15-34-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03423, current rewards: 147.95840, mean: 0.10494
[32m[0906 15-34-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03421, current rewards: 153.26412, mean: 0.10498
[32m[0906 15-34-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03419, current rewards: 158.57241, mean: 0.10501
[32m[0906 15-34-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03418, current rewards: 163.87447, mean: 0.10505
[32m[0906 15-34-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03415, current rewards: 169.17902, mean: 0.10508
[32m[0906 15-34-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03415, current rewards: 174.48533, mean: 0.10511
[32m[0906 15-34-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03413, current rewards: 179.80205, mean: 0.10515
[32m[0906 15-34-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03412, current rewards: 185.11577, mean: 0.10518
[32m[0906 15-34-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03410, current rewards: 190.31679, mean: 0.10515
[32m[0906 15-34-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03408, current rewards: 195.55836, mean: 0.10514
[32m[0906 15-34-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03407, current rewards: 199.71200, mean: 0.10456
[32m[0906 15-34-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03406, current rewards: 200.97735, mean: 0.10254
[32m[0906 15-34-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03405, current rewards: 206.51945, mean: 0.10275
[32m[0906 15-34-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03404, current rewards: 212.05507, mean: 0.10294
[32m[0906 15-34-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03403, current rewards: 217.59420, mean: 0.10313
[32m[0906 15-34-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03402, current rewards: 223.12995, mean: 0.10330
[32m[0906 15-34-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03401, current rewards: 228.68707, mean: 0.10348
[32m[0906 15-34-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03400, current rewards: 234.21971, mean: 0.10364
[32m[0906 15-34-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03399, current rewards: 235.25407, mean: 0.10184
[32m[0906 15-34-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03399, current rewards: 240.51342, mean: 0.10191
[32m[0906 15-34-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03398, current rewards: 245.76625, mean: 0.10198
[32m[0906 15-34-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03397, current rewards: 251.02146, mean: 0.10204
[32m[0906 15-34-54 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 15-34-54 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-34-54 @MBExp.py:227][0m Rewards obtained: [255.2508296033648], Lows: [7], Highs: [2], Total time: 4292.325121999998
[32m[0906 15-36-36 @MBExp.py:144][0m ####################################################################
[32m[0906 15-36-36 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 15-36-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03362, current rewards: -1.14233, mean: -0.11423
[32m[0906 15-36-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03424, current rewards: 4.39991, mean: 0.07333
[32m[0906 15-36-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03438, current rewards: 9.97628, mean: 0.09069
[32m[0906 15-36-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03442, current rewards: 15.51262, mean: 0.09695
[32m[0906 15-36-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03442, current rewards: 21.04668, mean: 0.10022
[32m[0906 15-36-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03446, current rewards: 26.58394, mean: 0.10225
[32m[0906 15-36-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03446, current rewards: 32.12062, mean: 0.10361
[32m[0906 15-36-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03445, current rewards: 33.43605, mean: 0.09288
[32m[0906 15-36-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03447, current rewards: 38.83341, mean: 0.09472
[32m[0906 15-36-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03451, current rewards: 44.23193, mean: 0.09616
[32m[0906 15-36-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03451, current rewards: 49.73161, mean: 0.09751
[32m[0906 15-36-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03450, current rewards: 55.18543, mean: 0.09855
[32m[0906 15-36-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03448, current rewards: 60.64085, mean: 0.09941
[32m[0906 15-36-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03449, current rewards: 65.02619, mean: 0.09852
[32m[0906 15-37-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03449, current rewards: 70.66428, mean: 0.09953
[32m[0906 15-37-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03449, current rewards: 76.30071, mean: 0.10040
[32m[0906 15-37-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03449, current rewards: 81.93365, mean: 0.10115
[32m[0906 15-37-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03450, current rewards: 87.57363, mean: 0.10183
[32m[0906 15-37-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03450, current rewards: 93.27667, mean: 0.10250
[32m[0906 15-37-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03450, current rewards: 98.90923, mean: 0.10303
[32m[0906 15-37-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03444, current rewards: 104.54029, mean: 0.10351
[32m[0906 15-37-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03441, current rewards: 110.17676, mean: 0.10394
[32m[0906 15-37-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03438, current rewards: 115.81353, mean: 0.10434
[32m[0906 15-37-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03434, current rewards: 121.44841, mean: 0.10470
[32m[0906 15-37-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03432, current rewards: 127.08138, mean: 0.10503
[32m[0906 15-37-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03430, current rewards: 132.27047, mean: 0.10498
[32m[0906 15-37-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03427, current rewards: 138.62391, mean: 0.10582
[32m[0906 15-37-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03425, current rewards: 144.97127, mean: 0.10660
[32m[0906 15-37-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03423, current rewards: 151.31871, mean: 0.10732
[32m[0906 15-37-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03421, current rewards: 157.66597, mean: 0.10799
[32m[0906 15-37-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03419, current rewards: 164.01698, mean: 0.10862
[32m[0906 15-37-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03417, current rewards: 170.35743, mean: 0.10920
[32m[0906 15-37-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03416, current rewards: 176.70552, mean: 0.10975
[32m[0906 15-37-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03415, current rewards: 183.04696, mean: 0.11027
[32m[0906 15-37-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03414, current rewards: 187.32151, mean: 0.10954
[32m[0906 15-37-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03412, current rewards: 193.04902, mean: 0.10969
[32m[0906 15-37-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03411, current rewards: 198.77699, mean: 0.10982
[32m[0906 15-37-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03410, current rewards: 204.50853, mean: 0.10995
[32m[0906 15-37-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03408, current rewards: 209.77362, mean: 0.10983
[32m[0906 15-37-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03407, current rewards: 216.22940, mean: 0.11032
[32m[0906 15-37-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03407, current rewards: 222.68325, mean: 0.11079
[32m[0906 15-37-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03406, current rewards: 229.13170, mean: 0.11123
[32m[0906 15-37-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03405, current rewards: 235.50353, mean: 0.11161
[32m[0906 15-37-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03404, current rewards: 241.90386, mean: 0.11199
[32m[0906 15-37-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03402, current rewards: 248.41560, mean: 0.11241
[32m[0906 15-37-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03402, current rewards: 254.94083, mean: 0.11281
[32m[0906 15-37-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03402, current rewards: 261.46872, mean: 0.11319
[32m[0906 15-37-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03401, current rewards: 267.99446, mean: 0.11356
[32m[0906 15-37-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03400, current rewards: 274.52983, mean: 0.11391
[32m[0906 15-38-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03399, current rewards: 281.05501, mean: 0.11425
[32m[0906 15-38-01 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 15-38-01 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-38-02 @MBExp.py:227][0m Rewards obtained: [286.2745516095824], Lows: [3], Highs: [5], Total time: 4377.9689899999985
[32m[0906 15-39-46 @MBExp.py:144][0m ####################################################################
[32m[0906 15-39-46 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 15-39-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03420, current rewards: -0.00697, mean: -0.00070
[32m[0906 15-39-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03425, current rewards: 5.38807, mean: 0.08980
[32m[0906 15-39-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03436, current rewards: 10.90906, mean: 0.09917
[32m[0906 15-39-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03434, current rewards: 16.43050, mean: 0.10269
[32m[0906 15-39-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03438, current rewards: 21.95226, mean: 0.10453
[32m[0906 15-39-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03443, current rewards: 27.47594, mean: 0.10568
[32m[0906 15-39-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03442, current rewards: 32.99842, mean: 0.10645
[32m[0906 15-39-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03442, current rewards: 36.52270, mean: 0.10145
[32m[0906 15-40-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03444, current rewards: 42.04444, mean: 0.10255
[32m[0906 15-40-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03445, current rewards: 47.61002, mean: 0.10350
[32m[0906 15-40-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03447, current rewards: 53.13105, mean: 0.10418
[32m[0906 15-40-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03447, current rewards: 58.65828, mean: 0.10475
[32m[0906 15-40-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03444, current rewards: 64.18142, mean: 0.10522
[32m[0906 15-40-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03443, current rewards: 69.70197, mean: 0.10561
[32m[0906 15-40-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03443, current rewards: 75.22736, mean: 0.10595
[32m[0906 15-40-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03443, current rewards: 80.75182, mean: 0.10625
[32m[0906 15-40-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03444, current rewards: 85.19456, mean: 0.10518
[32m[0906 15-40-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03445, current rewards: 90.85252, mean: 0.10564
[32m[0906 15-40-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03445, current rewards: 96.48629, mean: 0.10603
[32m[0906 15-40-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03445, current rewards: 102.11665, mean: 0.10637
[32m[0906 15-40-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03441, current rewards: 107.75046, mean: 0.10668
[32m[0906 15-40-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03437, current rewards: 113.37921, mean: 0.10696
[32m[0906 15-40-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03434, current rewards: 117.31953, mean: 0.10569
[32m[0906 15-40-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03431, current rewards: 122.77029, mean: 0.10584
[32m[0906 15-40-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03428, current rewards: 128.22026, mean: 0.10597
[32m[0906 15-40-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03424, current rewards: 133.65331, mean: 0.10607
[32m[0906 15-40-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03422, current rewards: 138.95249, mean: 0.10607
[32m[0906 15-40-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03419, current rewards: 144.39791, mean: 0.10617
[32m[0906 15-40-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03417, current rewards: 149.84342, mean: 0.10627
[32m[0906 15-40-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03415, current rewards: 155.28957, mean: 0.10636
[32m[0906 15-40-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03413, current rewards: 160.73471, mean: 0.10645
[32m[0906 15-40-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03412, current rewards: 166.18182, mean: 0.10653
[32m[0906 15-40-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03410, current rewards: 170.64054, mean: 0.10599
[32m[0906 15-40-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03408, current rewards: 176.16429, mean: 0.10612
[32m[0906 15-40-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03407, current rewards: 181.85904, mean: 0.10635
[32m[0906 15-40-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03406, current rewards: 187.37549, mean: 0.10646
[32m[0906 15-40-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03405, current rewards: 192.89440, mean: 0.10657
[32m[0906 15-40-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03404, current rewards: 198.41179, mean: 0.10667
[32m[0906 15-40-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03403, current rewards: 203.92944, mean: 0.10677
[32m[0906 15-40-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03401, current rewards: 209.44668, mean: 0.10686
[32m[0906 15-40-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03401, current rewards: 214.94168, mean: 0.10694
[32m[0906 15-40-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03400, current rewards: 220.47570, mean: 0.10703
[32m[0906 15-40-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03399, current rewards: 225.83438, mean: 0.10703
[32m[0906 15-41-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03398, current rewards: 231.30746, mean: 0.10709
[32m[0906 15-41-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03398, current rewards: 236.83222, mean: 0.10716
[32m[0906 15-41-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03396, current rewards: 242.36410, mean: 0.10724
[32m[0906 15-41-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03396, current rewards: 247.89295, mean: 0.10731
[32m[0906 15-41-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03395, current rewards: 253.42277, mean: 0.10738
[32m[0906 15-41-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03395, current rewards: 258.95245, mean: 0.10745
[32m[0906 15-41-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03395, current rewards: 264.47732, mean: 0.10751
[32m[0906 15-41-12 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 15-41-12 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-41-12 @MBExp.py:227][0m Rewards obtained: [268.8976406110707], Lows: [2], Highs: [3], Total time: 4463.482122999999
[32m[0906 15-42-58 @MBExp.py:144][0m ####################################################################
[32m[0906 15-42-58 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 15-42-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03454, current rewards: -0.09473, mean: -0.00947
[32m[0906 15-43-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03450, current rewards: 5.34311, mean: 0.08905
[32m[0906 15-43-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03446, current rewards: 10.94183, mean: 0.09947
[32m[0906 15-43-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03441, current rewards: 16.53992, mean: 0.10337
[32m[0906 15-43-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03442, current rewards: 22.13388, mean: 0.10540
[32m[0906 15-43-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03443, current rewards: 27.72887, mean: 0.10665
[32m[0906 15-43-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03445, current rewards: 33.32710, mean: 0.10751
[32m[0906 15-43-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03446, current rewards: 38.92469, mean: 0.10812
[32m[0906 15-43-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03446, current rewards: 44.52035, mean: 0.10859
[32m[0906 15-43-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03445, current rewards: 50.35522, mean: 0.10947
[32m[0906 15-43-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03445, current rewards: 56.04170, mean: 0.10989
[32m[0906 15-43-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03445, current rewards: 61.63770, mean: 0.11007
[32m[0906 15-43-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03445, current rewards: 67.23878, mean: 0.11023
[32m[0906 15-43-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03437, current rewards: 71.91476, mean: 0.10896
[32m[0906 15-43-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03434, current rewards: 77.86963, mean: 0.10968
[32m[0906 15-43-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03434, current rewards: 83.82913, mean: 0.11030
[32m[0906 15-43-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03436, current rewards: 89.78928, mean: 0.11085
[32m[0906 15-43-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03436, current rewards: 94.67029, mean: 0.11008
[32m[0906 15-43-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03438, current rewards: 100.08169, mean: 0.10998
[32m[0906 15-43-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03439, current rewards: 105.70413, mean: 0.11011
[32m[0906 15-43-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03436, current rewards: 111.33026, mean: 0.11023
[32m[0906 15-43-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03433, current rewards: 116.94810, mean: 0.11033
[32m[0906 15-43-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03430, current rewards: 122.56598, mean: 0.11042
[32m[0906 15-43-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03427, current rewards: 128.18884, mean: 0.11051
[32m[0906 15-43-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03424, current rewards: 133.81065, mean: 0.11059
[32m[0906 15-43-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03421, current rewards: 139.43116, mean: 0.11066
[32m[0906 15-43-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03419, current rewards: 145.18417, mean: 0.11083
[32m[0906 15-43-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03417, current rewards: 148.76457, mean: 0.10939
[32m[0906 15-43-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03415, current rewards: 154.36992, mean: 0.10948
[32m[0906 15-43-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03413, current rewards: 159.97077, mean: 0.10957
[32m[0906 15-43-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03411, current rewards: 165.57413, mean: 0.10965
[32m[0906 15-43-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03410, current rewards: 171.17833, mean: 0.10973
[32m[0906 15-43-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03409, current rewards: 176.78304, mean: 0.10980
[32m[0906 15-43-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03407, current rewards: 182.38679, mean: 0.10987
[32m[0906 15-43-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03407, current rewards: 187.99132, mean: 0.10994
[32m[0906 15-43-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03406, current rewards: 193.57465, mean: 0.10999
[32m[0906 15-44-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03404, current rewards: 199.17725, mean: 0.11004
[32m[0906 15-44-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03404, current rewards: 204.77522, mean: 0.11009
[32m[0906 15-44-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03403, current rewards: 210.36976, mean: 0.11014
[32m[0906 15-44-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03402, current rewards: 216.08070, mean: 0.11025
[32m[0906 15-44-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03400, current rewards: 221.79265, mean: 0.11034
[32m[0906 15-44-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03400, current rewards: 227.50546, mean: 0.11044
[32m[0906 15-44-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03399, current rewards: 233.21065, mean: 0.11053
[32m[0906 15-44-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03399, current rewards: 239.02557, mean: 0.11066
[32m[0906 15-44-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03398, current rewards: 244.68632, mean: 0.11072
[32m[0906 15-44-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03397, current rewards: 247.18140, mean: 0.10937
[32m[0906 15-44-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03396, current rewards: 254.64159, mean: 0.11023
[32m[0906 15-44-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03396, current rewards: 262.10178, mean: 0.11106
[32m[0906 15-44-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03395, current rewards: 269.56197, mean: 0.11185
[32m[0906 15-44-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03394, current rewards: 277.02216, mean: 0.11261
[32m[0906 15-44-23 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 15-44-23 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-44-24 @MBExp.py:227][0m Rewards obtained: [282.9903147000399], Lows: [3], Highs: [3], Total time: 4548.987112999999
[32m[0906 15-46-12 @MBExp.py:144][0m ####################################################################
[32m[0906 15-46-12 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 15-46-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03361, current rewards: 1.07520, mean: 0.10752
[32m[0906 15-46-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03419, current rewards: 6.64431, mean: 0.11074
[32m[0906 15-46-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03422, current rewards: 12.24378, mean: 0.11131
[32m[0906 15-46-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03433, current rewards: 17.84168, mean: 0.11151
[32m[0906 15-46-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03439, current rewards: 23.43998, mean: 0.11162
[32m[0906 15-46-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03436, current rewards: 29.03808, mean: 0.11168
[32m[0906 15-46-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03436, current rewards: 34.63626, mean: 0.11173
[32m[0906 15-46-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03438, current rewards: 40.23248, mean: 0.11176
[32m[0906 15-46-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03441, current rewards: 45.82949, mean: 0.11178
[32m[0906 15-46-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03443, current rewards: 40.60234, mean: 0.08827
[32m[0906 15-46-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03445, current rewards: -9.39766, mean: -0.01843
[32m[0906 15-46-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03444, current rewards: -59.39766, mean: -0.10607
[32m[0906 15-46-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03444, current rewards: -109.39766, mean: -0.17934
[32m[0906 15-46-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03439, current rewards: -159.39766, mean: -0.24151
[32m[0906 15-46-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03433, current rewards: -209.39766, mean: -0.29493
[32m[0906 15-46-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03432, current rewards: -259.39766, mean: -0.34131
[32m[0906 15-46-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03433, current rewards: -309.39766, mean: -0.38197
[32m[0906 15-46-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03434, current rewards: -359.39766, mean: -0.41790
[32m[0906 15-46-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03435, current rewards: -409.39766, mean: -0.44989
[32m[0906 15-46-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03435, current rewards: -459.39766, mean: -0.47854
[32m[0906 15-46-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03434, current rewards: -509.39766, mean: -0.50435
[32m[0906 15-46-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03431, current rewards: -559.39766, mean: -0.52773
[32m[0906 15-46-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03429, current rewards: -609.39766, mean: -0.54901
[32m[0906 15-46-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03427, current rewards: -659.39766, mean: -0.56845
[32m[0906 15-46-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03425, current rewards: -709.39766, mean: -0.58628
[32m[0906 15-46-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03423, current rewards: -759.39766, mean: -0.60270
[32m[0906 15-46-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03420, current rewards: -809.39766, mean: -0.61786
[32m[0906 15-46-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03418, current rewards: -859.39766, mean: -0.63191
[32m[0906 15-47-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03417, current rewards: -909.39766, mean: -0.64496
[32m[0906 15-47-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03415, current rewards: -959.39766, mean: -0.65712
[32m[0906 15-47-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03414, current rewards: -1009.39766, mean: -0.66848
[32m[0906 15-47-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03412, current rewards: -1059.39766, mean: -0.67910
[32m[0906 15-47-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03411, current rewards: -1109.39766, mean: -0.68907
[32m[0906 15-47-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03409, current rewards: -1159.39766, mean: -0.69843
[32m[0906 15-47-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03408, current rewards: -1209.39766, mean: -0.70725
[32m[0906 15-47-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03407, current rewards: -1259.39766, mean: -0.71557
[32m[0906 15-47-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03406, current rewards: -1309.39766, mean: -0.72342
[32m[0906 15-47-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03405, current rewards: -1359.39766, mean: -0.73086
[32m[0906 15-47-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03404, current rewards: -1409.39766, mean: -0.73790
[32m[0906 15-47-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03403, current rewards: -1459.39766, mean: -0.74459
[32m[0906 15-47-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03403, current rewards: -1509.39766, mean: -0.75094
[32m[0906 15-47-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03402, current rewards: -1559.39766, mean: -0.75699
[32m[0906 15-47-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03401, current rewards: -1609.39766, mean: -0.76275
[32m[0906 15-47-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03400, current rewards: -1659.39766, mean: -0.76824
[32m[0906 15-47-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03400, current rewards: -1709.39766, mean: -0.77348
[32m[0906 15-47-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03399, current rewards: -1759.39766, mean: -0.77849
[32m[0906 15-47-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03398, current rewards: -1809.39766, mean: -0.78329
[32m[0906 15-47-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03398, current rewards: -1859.39766, mean: -0.78788
[32m[0906 15-47-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03397, current rewards: -1909.39766, mean: -0.79228
[32m[0906 15-47-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03397, current rewards: -1959.39766, mean: -0.79650
[32m[0906 15-47-37 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 15-47-37 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-47-38 @MBExp.py:227][0m Rewards obtained: [-1999.3976566186384], Lows: [0], Highs: [2050], Total time: 4634.566766999999
[32m[0906 15-49-28 @MBExp.py:144][0m ####################################################################
[32m[0906 15-49-28 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 15-49-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03382, current rewards: 0.09240, mean: 0.00924
[32m[0906 15-49-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03427, current rewards: 5.92055, mean: 0.09868
[32m[0906 15-49-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03431, current rewards: 11.70857, mean: 0.10644
[32m[0906 15-49-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03437, current rewards: 17.49622, mean: 0.10935
[32m[0906 15-49-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03443, current rewards: 23.28273, mean: 0.11087
[32m[0906 15-49-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03446, current rewards: 29.06625, mean: 0.11179
[32m[0906 15-49-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03447, current rewards: 34.85175, mean: 0.11243
[32m[0906 15-49-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03446, current rewards: 40.63495, mean: 0.11287
[32m[0906 15-49-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03447, current rewards: 46.42612, mean: 0.11323
[32m[0906 15-49-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03444, current rewards: 52.32236, mean: 0.11374
[32m[0906 15-49-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03444, current rewards: 58.03519, mean: 0.11379
[32m[0906 15-49-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03444, current rewards: 63.63581, mean: 0.11364
[32m[0906 15-49-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03443, current rewards: 69.09549, mean: 0.11327
[32m[0906 15-49-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03437, current rewards: 74.55274, mean: 0.11296
[32m[0906 15-49-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03434, current rewards: 80.01856, mean: 0.11270
[32m[0906 15-49-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03430, current rewards: 85.47848, mean: 0.11247
[32m[0906 15-49-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03427, current rewards: 90.97387, mean: 0.11231
[32m[0906 15-49-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03430, current rewards: 96.52261, mean: 0.11224
[32m[0906 15-49-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03432, current rewards: 102.01535, mean: 0.11210
[32m[0906 15-50-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03434, current rewards: 107.48071, mean: 0.11196
[32m[0906 15-50-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03435, current rewards: 112.93546, mean: 0.11182
[32m[0906 15-50-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03430, current rewards: 118.40165, mean: 0.11170
[32m[0906 15-50-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03427, current rewards: 123.94383, mean: 0.11166
[32m[0906 15-50-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03424, current rewards: 131.80337, mean: 0.11362
[32m[0906 15-50-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03422, current rewards: 139.66291, mean: 0.11542
[32m[0906 15-50-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03420, current rewards: 147.52245, mean: 0.11708
[32m[0906 15-50-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03418, current rewards: 152.24122, mean: 0.11621
[32m[0906 15-50-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03416, current rewards: 156.48250, mean: 0.11506
[32m[0906 15-50-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03414, current rewards: 160.72377, mean: 0.11399
[32m[0906 15-50-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03412, current rewards: 126.99616, mean: 0.08698
[32m[0906 15-50-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03409, current rewards: 76.99616, mean: 0.05099
[32m[0906 15-50-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03407, current rewards: 26.99616, mean: 0.01731
[32m[0906 15-50-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03406, current rewards: -23.00384, mean: -0.01429
[32m[0906 15-50-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03404, current rewards: -73.00384, mean: -0.04398
[32m[0906 15-50-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03403, current rewards: -123.00384, mean: -0.07193
[32m[0906 15-50-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03401, current rewards: -173.00384, mean: -0.09830
[32m[0906 15-50-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03399, current rewards: -223.00384, mean: -0.12321
[32m[0906 15-50-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03398, current rewards: -273.00384, mean: -0.14678
[32m[0906 15-50-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03397, current rewards: -323.00384, mean: -0.16911
[32m[0906 15-50-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03395, current rewards: -373.00384, mean: -0.19031
[32m[0906 15-50-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03395, current rewards: -423.00384, mean: -0.21045
[32m[0906 15-50-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03394, current rewards: -449.35136, mean: -0.21813
[32m[0906 15-50-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03393, current rewards: -444.75599, mean: -0.21078
[32m[0906 15-50-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03392, current rewards: -442.07494, mean: -0.20466
[32m[0906 15-50-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03392, current rewards: -439.39389, mean: -0.19882
[32m[0906 15-50-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03391, current rewards: -436.71284, mean: -0.19324
[32m[0906 15-50-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03390, current rewards: -434.03178, mean: -0.18789
[32m[0906 15-50-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03389, current rewards: -431.35073, mean: -0.18278
[32m[0906 15-50-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03388, current rewards: -428.66968, mean: -0.17787
[32m[0906 15-50-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03388, current rewards: -425.98863, mean: -0.17317
[32m[0906 15-50-53 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 15-50-53 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-50-53 @MBExp.py:227][0m Rewards obtained: [-423.8493148903531], Lows: [1], Highs: [615], Total time: 4719.920671999999
[32m[0906 15-52-46 @MBExp.py:144][0m ####################################################################
[32m[0906 15-52-46 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 15-52-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03402, current rewards: 1.77847, mean: 0.17785
[32m[0906 15-52-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03416, current rewards: 7.73339, mean: 0.12889
[32m[0906 15-52-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03425, current rewards: 13.65127, mean: 0.12410
[32m[0906 15-52-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03427, current rewards: 19.56914, mean: 0.12231
[32m[0906 15-52-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03428, current rewards: 25.48702, mean: 0.12137
[32m[0906 15-52-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03430, current rewards: 31.40489, mean: 0.12079
[32m[0906 15-52-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03431, current rewards: 37.32277, mean: 0.12040
[32m[0906 15-52-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03433, current rewards: 43.24064, mean: 0.12011
[32m[0906 15-53-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03433, current rewards: 49.15852, mean: 0.11990
[32m[0906 15-53-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03433, current rewards: 55.79512, mean: 0.12129
[32m[0906 15-53-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03435, current rewards: 12.60681, mean: 0.02472
[32m[0906 15-53-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03435, current rewards: -37.39319, mean: -0.06677
[32m[0906 15-53-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03436, current rewards: -87.39319, mean: -0.14327
[32m[0906 15-53-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03435, current rewards: -137.39319, mean: -0.20817
[32m[0906 15-53-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03429, current rewards: -187.39319, mean: -0.26393
[32m[0906 15-53-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03423, current rewards: -237.39319, mean: -0.31236
[32m[0906 15-53-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03420, current rewards: -287.39319, mean: -0.35481
[32m[0906 15-53-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03419, current rewards: -337.39319, mean: -0.39232
[32m[0906 15-53-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03420, current rewards: -387.39319, mean: -0.42571
[32m[0906 15-53-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03421, current rewards: -437.39319, mean: -0.45562
[32m[0906 15-53-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03422, current rewards: -487.39319, mean: -0.48257
[32m[0906 15-53-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03419, current rewards: -537.39319, mean: -0.50697
[32m[0906 15-53-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03416, current rewards: -587.39319, mean: -0.52918
[32m[0906 15-53-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03414, current rewards: -637.39319, mean: -0.54948
[32m[0906 15-53-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03411, current rewards: -687.39319, mean: -0.56809
[32m[0906 15-53-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03409, current rewards: -737.39319, mean: -0.58523
[32m[0906 15-53-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03407, current rewards: -787.39319, mean: -0.60106
[32m[0906 15-53-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03405, current rewards: -837.39319, mean: -0.61573
[32m[0906 15-53-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03404, current rewards: -887.39319, mean: -0.62936
[32m[0906 15-53-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03402, current rewards: -937.39319, mean: -0.64205
[32m[0906 15-53-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03401, current rewards: -987.39319, mean: -0.65390
[32m[0906 15-53-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03399, current rewards: -1037.39319, mean: -0.66500
[32m[0906 15-53-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03398, current rewards: -1087.39319, mean: -0.67540
[32m[0906 15-53-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03397, current rewards: -1137.39319, mean: -0.68518
[32m[0906 15-53-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03395, current rewards: -1187.39319, mean: -0.69438
[32m[0906 15-53-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03394, current rewards: -1237.39319, mean: -0.70306
[32m[0906 15-53-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03392, current rewards: -1287.39319, mean: -0.71127
[32m[0906 15-53-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03392, current rewards: -1337.39319, mean: -0.71903
[32m[0906 15-53-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03391, current rewards: -1387.39319, mean: -0.72638
[32m[0906 15-53-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03390, current rewards: -1437.39319, mean: -0.73336
[32m[0906 15-53-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03389, current rewards: -1487.39319, mean: -0.74000
[32m[0906 15-53-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03388, current rewards: -1537.39319, mean: -0.74631
[32m[0906 15-53-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03387, current rewards: -1587.39319, mean: -0.75232
[32m[0906 15-53-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03386, current rewards: -1637.39319, mean: -0.75805
[32m[0906 15-54-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03386, current rewards: -1687.39319, mean: -0.76353
[32m[0906 15-54-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03385, current rewards: -1737.39319, mean: -0.76876
[32m[0906 15-54-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03385, current rewards: -1787.39319, mean: -0.77376
[32m[0906 15-54-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03384, current rewards: -1837.39319, mean: -0.77856
[32m[0906 15-54-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03384, current rewards: -1887.39319, mean: -0.78315
[32m[0906 15-54-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03384, current rewards: -1937.39319, mean: -0.78756
[32m[0906 15-54-11 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 15-54-11 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-54-11 @MBExp.py:227][0m Rewards obtained: [-1977.3931927266622], Lows: [0], Highs: [2034], Total time: 4805.172801999999
[32m[0906 15-56-06 @MBExp.py:144][0m ####################################################################
[32m[0906 15-56-06 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 15-56-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03382, current rewards: 0.13613, mean: 0.01361
[32m[0906 15-56-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03429, current rewards: 5.65937, mean: 0.09432
[32m[0906 15-56-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03433, current rewards: 11.18430, mean: 0.10168
[32m[0906 15-56-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03440, current rewards: 16.70583, mean: 0.10441
[32m[0906 15-56-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03438, current rewards: 22.23095, mean: 0.10586
[32m[0906 15-56-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03440, current rewards: 27.75581, mean: 0.10675
[32m[0906 15-56-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03444, current rewards: 33.27842, mean: 0.10735
[32m[0906 15-56-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03447, current rewards: 38.80129, mean: 0.10778
[32m[0906 15-56-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03448, current rewards: 44.27057, mean: 0.10798
[32m[0906 15-56-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03448, current rewards: 48.79880, mean: 0.10608
[32m[0906 15-56-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03446, current rewards: 54.44820, mean: 0.10676
[32m[0906 15-56-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03445, current rewards: 60.09717, mean: 0.10732
[32m[0906 15-56-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03446, current rewards: 65.75020, mean: 0.10779
[32m[0906 15-56-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03446, current rewards: 71.40660, mean: 0.10819
[32m[0906 15-56-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03439, current rewards: 77.05718, mean: 0.10853
[32m[0906 15-56-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03437, current rewards: 82.70952, mean: 0.10883
[32m[0906 15-56-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03432, current rewards: 88.34425, mean: 0.10907
[32m[0906 15-56-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03427, current rewards: 93.98151, mean: 0.10928
[32m[0906 15-56-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03427, current rewards: 99.62017, mean: 0.10947
[32m[0906 15-56-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03428, current rewards: 105.25822, mean: 0.10964
[32m[0906 15-56-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03429, current rewards: 106.93336, mean: 0.10587
[32m[0906 15-56-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03427, current rewards: 112.50251, mean: 0.10613
[32m[0906 15-56-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03423, current rewards: 118.06959, mean: 0.10637
[32m[0906 15-56-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03421, current rewards: 123.63590, mean: 0.10658
[32m[0906 15-56-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03419, current rewards: 129.16953, mean: 0.10675
[32m[0906 15-56-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03417, current rewards: 134.75791, mean: 0.10695
[32m[0906 15-56-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03416, current rewards: 140.34479, mean: 0.10713
[32m[0906 15-56-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03414, current rewards: 145.93450, mean: 0.10730
[32m[0906 15-56-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03413, current rewards: 151.51832, mean: 0.10746
[32m[0906 15-56-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03411, current rewards: 157.10641, mean: 0.10761
[32m[0906 15-56-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03409, current rewards: 162.69376, mean: 0.10774
[32m[0906 15-56-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03408, current rewards: 168.27979, mean: 0.10787
[32m[0906 15-57-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03407, current rewards: 173.84599, mean: 0.10798
[32m[0906 15-57-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03406, current rewards: 179.41839, mean: 0.10808
[32m[0906 15-57-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03405, current rewards: 183.85624, mean: 0.10752
[32m[0906 15-57-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03403, current rewards: 189.40163, mean: 0.10761
[32m[0906 15-57-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03402, current rewards: 194.94925, mean: 0.10771
[32m[0906 15-57-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03401, current rewards: 200.49558, mean: 0.10779
[32m[0906 15-57-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03400, current rewards: 206.03914, mean: 0.10787
[32m[0906 15-57-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03399, current rewards: 211.58401, mean: 0.10795
[32m[0906 15-57-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03399, current rewards: 217.13046, mean: 0.10803
[32m[0906 15-57-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03398, current rewards: 222.85397, mean: 0.10818
[32m[0906 15-57-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03397, current rewards: 227.27163, mean: 0.10771
[32m[0906 15-57-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03396, current rewards: 232.82246, mean: 0.10779
[32m[0906 15-57-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03396, current rewards: 238.37319, mean: 0.10786
[32m[0906 15-57-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03395, current rewards: 243.93176, mean: 0.10793
[32m[0906 15-57-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03394, current rewards: 249.48862, mean: 0.10800
[32m[0906 15-57-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03394, current rewards: 255.04390, mean: 0.10807
[32m[0906 15-57-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03393, current rewards: 260.59743, mean: 0.10813
[32m[0906 15-57-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03392, current rewards: 266.25418, mean: 0.10823
[32m[0906 15-57-31 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 15-57-31 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-57-31 @MBExp.py:227][0m Rewards obtained: [270.7097821002787], Lows: [2], Highs: [4], Total time: 4890.667029999999
[32m[0906 15-59-28 @MBExp.py:144][0m ####################################################################
[32m[0906 15-59-28 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 15-59-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03442, current rewards: -0.09936, mean: -0.00994
[32m[0906 15-59-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03461, current rewards: 5.41568, mean: 0.09026
[32m[0906 15-59-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03460, current rewards: 10.96086, mean: 0.09964
[32m[0906 15-59-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03459, current rewards: 16.50918, mean: 0.10318
[32m[0906 15-59-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03456, current rewards: 22.04881, mean: 0.10499
[32m[0906 15-59-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03455, current rewards: 27.59477, mean: 0.10613
[32m[0906 15-59-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03457, current rewards: 33.13902, mean: 0.10690
[32m[0906 15-59-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03456, current rewards: 36.90731, mean: 0.10252
[32m[0906 15-59-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03456, current rewards: 42.51441, mean: 0.10369
[32m[0906 15-59-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03456, current rewards: 48.11696, mean: 0.10460
[32m[0906 15-59-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03456, current rewards: 53.71730, mean: 0.10533
[32m[0906 15-59-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03456, current rewards: 59.31983, mean: 0.10593
[32m[0906 15-59-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03457, current rewards: 64.92570, mean: 0.10644
[32m[0906 15-59-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03456, current rewards: 70.53027, mean: 0.10686
[32m[0906 15-59-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03449, current rewards: 76.59618, mean: 0.10788
[32m[0906 15-59-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03445, current rewards: 82.08186, mean: 0.10800
[32m[0906 15-59-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03441, current rewards: 87.70253, mean: 0.10827
[32m[0906 15-59-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03437, current rewards: 93.15934, mean: 0.10832
[32m[0906 15-59-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03433, current rewards: 98.61368, mean: 0.10837
[32m[0906 16-00-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03433, current rewards: 104.06636, mean: 0.10840
[32m[0906 16-00-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03435, current rewards: 109.51807, mean: 0.10843
[32m[0906 16-00-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03434, current rewards: 114.97014, mean: 0.10846
[32m[0906 16-00-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03431, current rewards: 120.42330, mean: 0.10849
[32m[0906 16-00-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03428, current rewards: 124.83788, mean: 0.10762
[32m[0906 16-00-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03425, current rewards: 130.28041, mean: 0.10767
[32m[0906 16-00-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03424, current rewards: 135.86595, mean: 0.10783
[32m[0906 16-00-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03422, current rewards: 141.45446, mean: 0.10798
[32m[0906 16-00-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03421, current rewards: 147.04625, mean: 0.10812
[32m[0906 16-00-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03418, current rewards: 152.63190, mean: 0.10825
[32m[0906 16-00-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03416, current rewards: 156.19704, mean: 0.10698
[32m[0906 16-00-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03414, current rewards: 161.62435, mean: 0.10704
[32m[0906 16-00-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03412, current rewards: 167.05035, mean: 0.10708
[32m[0906 16-00-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03411, current rewards: 172.47873, mean: 0.10713
[32m[0906 16-00-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03409, current rewards: 177.90279, mean: 0.10717
[32m[0906 16-00-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03407, current rewards: 183.32988, mean: 0.10721
[32m[0906 16-00-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03406, current rewards: 184.63419, mean: 0.10491
[32m[0906 16-00-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03405, current rewards: 190.34291, mean: 0.10516
[32m[0906 16-00-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03404, current rewards: 196.05615, mean: 0.10541
[32m[0906 16-00-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03403, current rewards: 201.76718, mean: 0.10564
[32m[0906 16-00-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03402, current rewards: 207.47655, mean: 0.10586
[32m[0906 16-00-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03401, current rewards: 213.20056, mean: 0.10607
[32m[0906 16-00-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03400, current rewards: 218.90157, mean: 0.10626
[32m[0906 16-00-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03400, current rewards: 223.48906, mean: 0.10592
[32m[0906 16-00-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03399, current rewards: 229.12414, mean: 0.10608
[32m[0906 16-00-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03398, current rewards: 234.73032, mean: 0.10621
[32m[0906 16-00-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03397, current rewards: 240.33446, mean: 0.10634
[32m[0906 16-00-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03397, current rewards: 245.94850, mean: 0.10647
[32m[0906 16-00-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03395, current rewards: 251.55686, mean: 0.10659
[32m[0906 16-00-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03395, current rewards: 257.10488, mean: 0.10668
[32m[0906 16-00-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03394, current rewards: 262.68520, mean: 0.10678
[32m[0906 16-00-53 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 16-00-53 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-00-53 @MBExp.py:227][0m Rewards obtained: [267.1482997681029], Lows: [4], Highs: [3], Total time: 4976.181410999999
[32m[0906 16-02-52 @MBExp.py:144][0m ####################################################################
[32m[0906 16-02-52 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 16-02-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03381, current rewards: -1.04745, mean: -0.10475
[32m[0906 16-02-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03421, current rewards: 4.66685, mean: 0.07778
[32m[0906 16-02-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03445, current rewards: 10.28813, mean: 0.09353
[32m[0906 16-02-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03448, current rewards: 15.91159, mean: 0.09945
[32m[0906 16-02-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03454, current rewards: 21.52984, mean: 0.10252
[32m[0906 16-03-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03457, current rewards: 27.15133, mean: 0.10443
[32m[0906 16-03-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03456, current rewards: 32.77259, mean: 0.10572
[32m[0906 16-03-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03455, current rewards: 38.13191, mean: 0.10592
[32m[0906 16-03-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03455, current rewards: 41.73619, mean: 0.10180
[32m[0906 16-03-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03457, current rewards: 47.30317, mean: 0.10283
[32m[0906 16-03-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03457, current rewards: 52.87212, mean: 0.10367
[32m[0906 16-03-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03457, current rewards: 58.43820, mean: 0.10435
[32m[0906 16-03-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03457, current rewards: 64.00789, mean: 0.10493
[32m[0906 16-03-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03457, current rewards: 69.57334, mean: 0.10541
[32m[0906 16-03-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03453, current rewards: 75.14489, mean: 0.10584
[32m[0906 16-03-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03448, current rewards: 80.95648, mean: 0.10652
[32m[0906 16-03-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03442, current rewards: 86.69240, mean: 0.10703
[32m[0906 16-03-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03439, current rewards: 89.11661, mean: 0.10362
[32m[0906 16-03-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03437, current rewards: 96.57680, mean: 0.10613
[32m[0906 16-03-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03433, current rewards: 104.03699, mean: 0.10837
[32m[0906 16-03-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03432, current rewards: 111.49718, mean: 0.11039
[32m[0906 16-03-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03434, current rewards: 93.67489, mean: 0.08837
[32m[0906 16-03-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03430, current rewards: 43.67489, mean: 0.03935
[32m[0906 16-03-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03427, current rewards: -6.32511, mean: -0.00545
[32m[0906 16-03-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03425, current rewards: -56.32511, mean: -0.04655
[32m[0906 16-03-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03423, current rewards: -106.32511, mean: -0.08439
[32m[0906 16-03-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03420, current rewards: -156.32511, mean: -0.11933
[32m[0906 16-03-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03418, current rewards: -206.32511, mean: -0.15171
[32m[0906 16-03-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03416, current rewards: -256.32511, mean: -0.18179
[32m[0906 16-03-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03415, current rewards: -306.32511, mean: -0.20981
[32m[0906 16-03-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03413, current rewards: -356.32511, mean: -0.23598
[32m[0906 16-03-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03411, current rewards: -406.32511, mean: -0.26046
[32m[0906 16-03-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03410, current rewards: -456.32511, mean: -0.28343
[32m[0906 16-03-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03409, current rewards: -506.32511, mean: -0.30502
[32m[0906 16-03-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03408, current rewards: -556.32511, mean: -0.32534
[32m[0906 16-03-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03407, current rewards: -606.32511, mean: -0.34450
[32m[0906 16-03-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03406, current rewards: -656.32511, mean: -0.36261
[32m[0906 16-03-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03406, current rewards: -706.32511, mean: -0.37974
[32m[0906 16-03-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03405, current rewards: -756.32511, mean: -0.39598
[32m[0906 16-03-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03405, current rewards: -806.32511, mean: -0.41139
[32m[0906 16-04-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03404, current rewards: -856.32511, mean: -0.42603
[32m[0906 16-04-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03404, current rewards: -906.32511, mean: -0.43996
[32m[0906 16-04-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03403, current rewards: -956.32511, mean: -0.45323
[32m[0906 16-04-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03402, current rewards: -1006.32511, mean: -0.46589
[32m[0906 16-04-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03401, current rewards: -1056.32511, mean: -0.47798
[32m[0906 16-04-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03401, current rewards: -1106.32511, mean: -0.48952
[32m[0906 16-04-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03400, current rewards: -1156.32511, mean: -0.50057
[32m[0906 16-04-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03400, current rewards: -1206.32511, mean: -0.51115
[32m[0906 16-04-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03400, current rewards: -1256.32511, mean: -0.52130
[32m[0906 16-04-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03398, current rewards: -1306.32511, mean: -0.53103
[32m[0906 16-04-17 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 16-04-17 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-04-18 @MBExp.py:227][0m Rewards obtained: [-1346.3251120568934], Lows: [3], Highs: [1464], Total time: 5061.789827999999
[32m[0906 16-06-18 @MBExp.py:144][0m ####################################################################
[32m[0906 16-06-18 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 16-06-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03331, current rewards: 0.11322, mean: 0.01132
[32m[0906 16-06-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03429, current rewards: 5.80579, mean: 0.09676
[32m[0906 16-06-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03433, current rewards: 11.35398, mean: 0.10322
[32m[0906 16-06-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03440, current rewards: 16.90070, mean: 0.10563
[32m[0906 16-06-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03444, current rewards: 22.44867, mean: 0.10690
[32m[0906 16-06-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03444, current rewards: 27.99152, mean: 0.10766
[32m[0906 16-06-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03442, current rewards: 33.53878, mean: 0.10819
[32m[0906 16-06-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03443, current rewards: 39.07926, mean: 0.10855
[32m[0906 16-06-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03444, current rewards: 40.99000, mean: 0.09998
[32m[0906 16-06-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03446, current rewards: 47.91666, mean: 0.10417
[32m[0906 16-06-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03447, current rewards: 54.84332, mean: 0.10754
[32m[0906 16-06-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03448, current rewards: 61.76997, mean: 0.11030
[32m[0906 16-06-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03448, current rewards: 68.69663, mean: 0.11262
[32m[0906 16-06-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03451, current rewards: 75.62329, mean: 0.11458
[32m[0906 16-06-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03449, current rewards: 82.54995, mean: 0.11627
[32m[0906 16-06-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03442, current rewards: 89.21246, mean: 0.11738
[32m[0906 16-06-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03437, current rewards: 54.09854, mean: 0.06679
[32m[0906 16-06-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03434, current rewards: 4.09854, mean: 0.00477
[32m[0906 16-06-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03430, current rewards: -45.90146, mean: -0.05044
[32m[0906 16-06-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03427, current rewards: -95.90146, mean: -0.09990
[32m[0906 16-06-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03425, current rewards: -145.90146, mean: -0.14446
[32m[0906 16-06-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03425, current rewards: -195.90146, mean: -0.18481
[32m[0906 16-06-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03422, current rewards: -245.90146, mean: -0.22153
[32m[0906 16-06-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03420, current rewards: -295.90146, mean: -0.25509
[32m[0906 16-07-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03418, current rewards: -345.90146, mean: -0.28587
[32m[0906 16-07-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03416, current rewards: -395.90146, mean: -0.31421
[32m[0906 16-07-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03414, current rewards: -445.90146, mean: -0.34038
[32m[0906 16-07-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03412, current rewards: -495.90146, mean: -0.36463
[32m[0906 16-07-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03411, current rewards: -545.90146, mean: -0.38716
[32m[0906 16-07-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03410, current rewards: -595.90146, mean: -0.40815
[32m[0906 16-07-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03409, current rewards: -645.90146, mean: -0.42775
[32m[0906 16-07-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03407, current rewards: -695.90146, mean: -0.44609
[32m[0906 16-07-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03406, current rewards: -745.90146, mean: -0.46329
[32m[0906 16-07-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03405, current rewards: -795.90146, mean: -0.47946
[32m[0906 16-07-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03403, current rewards: -845.90146, mean: -0.49468
[32m[0906 16-07-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03402, current rewards: -895.90146, mean: -0.50903
[32m[0906 16-07-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03401, current rewards: -945.90146, mean: -0.52260
[32m[0906 16-07-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03400, current rewards: -995.90146, mean: -0.53543
[32m[0906 16-07-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03399, current rewards: -1045.90146, mean: -0.54759
[32m[0906 16-07-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03398, current rewards: -1095.90146, mean: -0.55913
[32m[0906 16-07-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03397, current rewards: -1145.90146, mean: -0.57010
[32m[0906 16-07-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03396, current rewards: -1195.90146, mean: -0.58053
[32m[0906 16-07-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03395, current rewards: -1245.90146, mean: -0.59047
[32m[0906 16-07-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03395, current rewards: -1295.90146, mean: -0.59995
[32m[0906 16-07-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03394, current rewards: -1345.90146, mean: -0.60901
[32m[0906 16-07-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03393, current rewards: -1395.90146, mean: -0.61766
[32m[0906 16-07-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03392, current rewards: -1445.90146, mean: -0.62593
[32m[0906 16-07-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03392, current rewards: -1495.90146, mean: -0.63386
[32m[0906 16-07-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03391, current rewards: -1545.90146, mean: -0.64145
[32m[0906 16-07-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03390, current rewards: -1595.90146, mean: -0.64874
[32m[0906 16-07-44 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 16-07-44 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-07-44 @MBExp.py:227][0m Rewards obtained: [-1635.9014627681213], Lows: [2], Highs: [1727], Total time: 5147.224283999999
[32m[0906 16-09-46 @MBExp.py:144][0m ####################################################################
[32m[0906 16-09-46 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 16-09-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03343, current rewards: -0.05377, mean: -0.00538
[32m[0906 16-09-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03467, current rewards: 5.52995, mean: 0.09217
[32m[0906 16-09-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03459, current rewards: 11.11523, mean: 0.10105
[32m[0906 16-09-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03455, current rewards: 16.69659, mean: 0.10435
[32m[0906 16-09-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03453, current rewards: 22.28603, mean: 0.10612
[32m[0906 16-09-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03453, current rewards: 27.86320, mean: 0.10717
[32m[0906 16-09-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03457, current rewards: 33.44121, mean: 0.10787
[32m[0906 16-09-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03459, current rewards: 38.95865, mean: 0.10822
[32m[0906 16-10-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03459, current rewards: 44.54283, mean: 0.10864
[32m[0906 16-10-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03460, current rewards: 50.12595, mean: 0.10897
[32m[0906 16-10-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03459, current rewards: 55.70477, mean: 0.10923
[32m[0906 16-10-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03460, current rewards: 59.32841, mean: 0.10594
[32m[0906 16-10-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03460, current rewards: 64.85345, mean: 0.10632
[32m[0906 16-10-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03460, current rewards: 70.37644, mean: 0.10663
[32m[0906 16-10-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03460, current rewards: 75.90385, mean: 0.10691
[32m[0906 16-10-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03452, current rewards: 81.53481, mean: 0.10728
[32m[0906 16-10-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03447, current rewards: 83.36925, mean: 0.10293
[32m[0906 16-10-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03442, current rewards: 89.17159, mean: 0.10369
[32m[0906 16-10-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03439, current rewards: 94.97108, mean: 0.10436
[32m[0906 16-10-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03436, current rewards: 100.76984, mean: 0.10497
[32m[0906 16-10-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03433, current rewards: 106.56744, mean: 0.10551
[32m[0906 16-10-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03432, current rewards: 112.37031, mean: 0.10601
[32m[0906 16-10-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03428, current rewards: 118.17361, mean: 0.10646
[32m[0906 16-10-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03425, current rewards: 122.54825, mean: 0.10565
[32m[0906 16-10-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03422, current rewards: 128.21780, mean: 0.10597
[32m[0906 16-10-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03420, current rewards: 133.88657, mean: 0.10626
[32m[0906 16-10-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03417, current rewards: 139.55435, mean: 0.10653
[32m[0906 16-10-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03415, current rewards: 145.22122, mean: 0.10678
[32m[0906 16-10-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03413, current rewards: 150.88309, mean: 0.10701
[32m[0906 16-10-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03412, current rewards: 156.54144, mean: 0.10722
[32m[0906 16-10-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03410, current rewards: 162.20784, mean: 0.10742
[32m[0906 16-10-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03408, current rewards: 167.87721, mean: 0.10761
[32m[0906 16-10-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03406, current rewards: 173.77305, mean: 0.10793
[32m[0906 16-10-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03404, current rewards: 179.46907, mean: 0.10811
[32m[0906 16-10-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03403, current rewards: 183.69603, mean: 0.10742
[32m[0906 16-10-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03403, current rewards: 189.25251, mean: 0.10753
[32m[0906 16-10-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03402, current rewards: 194.80716, mean: 0.10763
[32m[0906 16-10-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03401, current rewards: 200.36281, mean: 0.10772
[32m[0906 16-10-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03400, current rewards: 205.91909, mean: 0.10781
[32m[0906 16-10-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03399, current rewards: 211.47973, mean: 0.10790
[32m[0906 16-10-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03397, current rewards: 216.84559, mean: 0.10788
[32m[0906 16-10-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03397, current rewards: 222.39011, mean: 0.10796
[32m[0906 16-10-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03396, current rewards: 227.93451, mean: 0.10803
[32m[0906 16-11-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03395, current rewards: 233.47955, mean: 0.10809
[32m[0906 16-11-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03395, current rewards: 239.03018, mean: 0.10816
[32m[0906 16-11-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03394, current rewards: 244.57861, mean: 0.10822
[32m[0906 16-11-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03393, current rewards: 250.12360, mean: 0.10828
[32m[0906 16-11-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03393, current rewards: 255.67233, mean: 0.10834
[32m[0906 16-11-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03393, current rewards: 259.32271, mean: 0.10760
[32m[0906 16-11-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03392, current rewards: 264.78687, mean: 0.10764
[32m[0906 16-11-12 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 16-11-12 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-11-12 @MBExp.py:227][0m Rewards obtained: [269.15323696291284], Lows: [5], Highs: [2], Total time: 5232.721148999999
[32m[0906 16-13-17 @MBExp.py:144][0m ####################################################################
[32m[0906 16-13-17 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 16-13-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03433, current rewards: -1.15280, mean: -0.11528
[32m[0906 16-13-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03446, current rewards: 4.11569, mean: 0.06859
[32m[0906 16-13-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03440, current rewards: 9.42232, mean: 0.08566
[32m[0906 16-13-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03444, current rewards: 14.73138, mean: 0.09207
[32m[0906 16-13-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03444, current rewards: 20.03126, mean: 0.09539
[32m[0906 16-13-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03447, current rewards: 25.34184, mean: 0.09747
[32m[0906 16-13-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03448, current rewards: 30.65136, mean: 0.09888
[32m[0906 16-13-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03444, current rewards: 35.95483, mean: 0.09987
[32m[0906 16-13-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03445, current rewards: 41.25745, mean: 0.10063
[32m[0906 16-13-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03446, current rewards: 46.56493, mean: 0.10123
[32m[0906 16-13-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03447, current rewards: 47.97512, mean: 0.09407
[32m[0906 16-13-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03446, current rewards: 53.49466, mean: 0.09553
[32m[0906 16-13-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03445, current rewards: 59.01037, mean: 0.09674
[32m[0906 16-13-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03446, current rewards: 64.52212, mean: 0.09776
[32m[0906 16-13-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03445, current rewards: 70.03751, mean: 0.09864
[32m[0906 16-13-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03440, current rewards: 75.49938, mean: 0.09934
[32m[0906 16-13-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03436, current rewards: 81.02113, mean: 0.10003
[32m[0906 16-13-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03431, current rewards: 86.54210, mean: 0.10063
[32m[0906 16-13-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03427, current rewards: 92.06858, mean: 0.10117
[32m[0906 16-13-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03424, current rewards: 97.59110, mean: 0.10166
[32m[0906 16-13-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03422, current rewards: 100.55466, mean: 0.09956
[32m[0906 16-13-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03420, current rewards: 108.20436, mean: 0.10208
[32m[0906 16-13-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03417, current rewards: 115.65045, mean: 0.10419
[32m[0906 16-13-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03414, current rewards: 123.14285, mean: 0.10616
[32m[0906 16-13-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03412, current rewards: 130.55342, mean: 0.10790
[32m[0906 16-14-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03411, current rewards: 138.04440, mean: 0.10956
[32m[0906 16-14-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03409, current rewards: 145.45196, mean: 0.11103
[32m[0906 16-14-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03407, current rewards: 149.65777, mean: 0.11004
[32m[0906 16-14-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03406, current rewards: 154.16496, mean: 0.10934
[32m[0906 16-14-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03405, current rewards: 158.67707, mean: 0.10868
[32m[0906 16-14-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03403, current rewards: 163.18579, mean: 0.10807
[32m[0906 16-14-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03403, current rewards: 167.99634, mean: 0.10769
[32m[0906 16-14-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03402, current rewards: 172.62328, mean: 0.10722
[32m[0906 16-14-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03401, current rewards: 177.24774, mean: 0.10678
[32m[0906 16-14-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03400, current rewards: 181.87175, mean: 0.10636
[32m[0906 16-14-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03399, current rewards: 184.00767, mean: 0.10455
[32m[0906 16-14-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03398, current rewards: 192.79634, mean: 0.10652
[32m[0906 16-14-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03397, current rewards: 201.58500, mean: 0.10838
[32m[0906 16-14-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03396, current rewards: 210.37366, mean: 0.11014
[32m[0906 16-14-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03395, current rewards: 219.08423, mean: 0.11178
[32m[0906 16-14-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03394, current rewards: 223.95834, mean: 0.11142
[32m[0906 16-14-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03394, current rewards: 214.49599, mean: 0.10412
[32m[0906 16-14-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03393, current rewards: 208.83488, mean: 0.09897
[32m[0906 16-14-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03392, current rewards: 214.12449, mean: 0.09913
[32m[0906 16-14-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03392, current rewards: 219.41612, mean: 0.09928
[32m[0906 16-14-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03392, current rewards: 224.70812, mean: 0.09943
[32m[0906 16-14-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03391, current rewards: 229.99512, mean: 0.09956
[32m[0906 16-14-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03390, current rewards: 235.28853, mean: 0.09970
[32m[0906 16-14-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03389, current rewards: 240.41256, mean: 0.09976
[32m[0906 16-14-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03389, current rewards: 245.76336, mean: 0.09990
[32m[0906 16-14-42 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 16-14-42 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-14-42 @MBExp.py:227][0m Rewards obtained: [250.01330476199138], Lows: [6], Highs: [26], Total time: 5318.110324999999
[32m[0906 16-16-49 @MBExp.py:144][0m ####################################################################
[32m[0906 16-16-49 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 16-16-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03403, current rewards: -1.07412, mean: -0.10741
[32m[0906 16-16-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03432, current rewards: 5.31887, mean: 0.08865
[32m[0906 16-16-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03433, current rewards: 11.81560, mean: 0.10741
[32m[0906 16-16-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03437, current rewards: 18.30356, mean: 0.11440
[32m[0906 16-16-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03439, current rewards: 24.79291, mean: 0.11806
[32m[0906 16-16-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03444, current rewards: 31.27419, mean: 0.12029
[32m[0906 16-16-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03441, current rewards: 37.76661, mean: 0.12183
[32m[0906 16-17-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03442, current rewards: 44.35921, mean: 0.12322
[32m[0906 16-17-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03441, current rewards: 50.70902, mean: 0.12368
[32m[0906 16-17-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03442, current rewards: 57.07339, mean: 0.12407
[32m[0906 16-17-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03444, current rewards: 63.42800, mean: 0.12437
[32m[0906 16-17-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03444, current rewards: 69.78542, mean: 0.12462
[32m[0906 16-17-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03444, current rewards: 74.15062, mean: 0.12156
[32m[0906 16-17-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03446, current rewards: 79.63936, mean: 0.12067
[32m[0906 16-17-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03446, current rewards: 85.12907, mean: 0.11990
[32m[0906 16-17-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03444, current rewards: 90.55932, mean: 0.11916
[32m[0906 16-17-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03439, current rewards: 96.00062, mean: 0.11852
[32m[0906 16-17-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03434, current rewards: 100.58009, mean: 0.11695
[32m[0906 16-17-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03430, current rewards: 106.35446, mean: 0.11687
[32m[0906 16-17-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03427, current rewards: 112.12291, mean: 0.11679
[32m[0906 16-17-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03424, current rewards: 117.89361, mean: 0.11673
[32m[0906 16-17-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03422, current rewards: 123.65877, mean: 0.11666
[32m[0906 16-17-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03415, current rewards: 129.43730, mean: 0.11661
[32m[0906 16-17-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03414, current rewards: 135.21609, mean: 0.11657
[32m[0906 16-17-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03412, current rewards: 140.98960, mean: 0.11652
[32m[0906 16-17-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03410, current rewards: 146.76171, mean: 0.11648
[32m[0906 16-17-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03409, current rewards: 152.54043, mean: 0.11644
[32m[0906 16-17-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03409, current rewards: 154.37334, mean: 0.11351
[32m[0906 16-17-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03407, current rewards: 160.07584, mean: 0.11353
[32m[0906 16-17-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03406, current rewards: 165.77720, mean: 0.11355
[32m[0906 16-17-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03404, current rewards: 171.47589, mean: 0.11356
[32m[0906 16-17-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03402, current rewards: 170.42417, mean: 0.10925
[32m[0906 16-17-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03401, current rewards: 159.09005, mean: 0.09881
[32m[0906 16-17-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03400, current rewards: 164.30971, mean: 0.09898
[32m[0906 16-17-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03399, current rewards: 169.53224, mean: 0.09914
[32m[0906 16-17-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03398, current rewards: 174.75247, mean: 0.09929
[32m[0906 16-17-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03398, current rewards: 179.97529, mean: 0.09943
[32m[0906 16-17-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03397, current rewards: 185.19641, mean: 0.09957
[32m[0906 16-17-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03396, current rewards: 190.42046, mean: 0.09970
[32m[0906 16-17-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03396, current rewards: 195.63925, mean: 0.09982
[32m[0906 16-17-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03394, current rewards: 201.01157, mean: 0.10001
[32m[0906 16-17-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03393, current rewards: 205.21856, mean: 0.09962
[32m[0906 16-18-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03392, current rewards: 210.81481, mean: 0.09991
[32m[0906 16-18-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03392, current rewards: 216.40900, mean: 0.10019
[32m[0906 16-18-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03391, current rewards: 222.00866, mean: 0.10046
[32m[0906 16-18-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03390, current rewards: 227.60735, mean: 0.10071
[32m[0906 16-18-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03390, current rewards: 233.20518, mean: 0.10095
[32m[0906 16-18-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03389, current rewards: 238.79785, mean: 0.10119
[32m[0906 16-18-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03388, current rewards: 244.29074, mean: 0.10137
[32m[0906 16-18-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03388, current rewards: 249.83692, mean: 0.10156
[32m[0906 16-18-14 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 16-18-14 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-18-14 @MBExp.py:227][0m Rewards obtained: [254.2735018585497], Lows: [4], Highs: [23], Total time: 5403.480204999999
[32m[0906 16-20-22 @MBExp.py:144][0m ####################################################################
[32m[0906 16-20-22 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 16-20-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03441, current rewards: -5.30556, mean: -0.53056
[32m[0906 16-20-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03459, current rewards: 0.33970, mean: 0.00566
[32m[0906 16-20-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03458, current rewards: 5.83378, mean: 0.05303
[32m[0906 16-20-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03454, current rewards: 11.33055, mean: 0.07082
[32m[0906 16-20-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03452, current rewards: 16.82247, mean: 0.08011
[32m[0906 16-20-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03455, current rewards: 20.76478, mean: 0.07986
[32m[0906 16-20-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03456, current rewards: 26.44826, mean: 0.08532
[32m[0906 16-20-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03454, current rewards: 33.03356, mean: 0.09176
[32m[0906 16-20-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03452, current rewards: 39.64179, mean: 0.09669
[32m[0906 16-20-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03453, current rewards: 46.25002, mean: 0.10054
[32m[0906 16-20-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03453, current rewards: 52.85826, mean: 0.10364
[32m[0906 16-20-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03454, current rewards: 59.46649, mean: 0.10619
[32m[0906 16-20-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03453, current rewards: 66.07472, mean: 0.10832
[32m[0906 16-20-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03453, current rewards: 52.30399, mean: 0.07925
[32m[0906 16-20-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03454, current rewards: 2.30399, mean: 0.00325
[32m[0906 16-20-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03453, current rewards: -47.69601, mean: -0.06276
[32m[0906 16-20-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03446, current rewards: -97.69601, mean: -0.12061
[32m[0906 16-20-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03441, current rewards: -147.69601, mean: -0.17174
[32m[0906 16-20-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03437, current rewards: -197.69601, mean: -0.21725
[32m[0906 16-20-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03433, current rewards: -247.69601, mean: -0.25802
[32m[0906 16-20-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03430, current rewards: -297.69601, mean: -0.29475
[32m[0906 16-20-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03427, current rewards: -347.69601, mean: -0.32802
[32m[0906 16-21-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03422, current rewards: -397.69601, mean: -0.35828
[32m[0906 16-21-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03418, current rewards: -447.69601, mean: -0.38594
[32m[0906 16-21-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03415, current rewards: -497.69601, mean: -0.41132
[32m[0906 16-21-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03413, current rewards: -547.69601, mean: -0.43468
[32m[0906 16-21-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03412, current rewards: -597.69601, mean: -0.45626
[32m[0906 16-21-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03411, current rewards: -647.69601, mean: -0.47625
[32m[0906 16-21-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03409, current rewards: -697.69601, mean: -0.49482
[32m[0906 16-21-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03407, current rewards: -747.69601, mean: -0.51212
[32m[0906 16-21-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03406, current rewards: -797.69601, mean: -0.52828
[32m[0906 16-21-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03404, current rewards: -847.69601, mean: -0.54339
[32m[0906 16-21-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03403, current rewards: -897.69601, mean: -0.55758
[32m[0906 16-21-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03402, current rewards: -947.69601, mean: -0.57090
[32m[0906 16-21-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03400, current rewards: -997.69601, mean: -0.58345
[32m[0906 16-21-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03399, current rewards: -1047.69601, mean: -0.59528
[32m[0906 16-21-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03399, current rewards: -1097.69601, mean: -0.60646
[32m[0906 16-21-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03398, current rewards: -1147.69601, mean: -0.61704
[32m[0906 16-21-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03397, current rewards: -1197.69601, mean: -0.62707
[32m[0906 16-21-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03396, current rewards: -1247.69601, mean: -0.63658
[32m[0906 16-21-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03395, current rewards: -1297.69601, mean: -0.64562
[32m[0906 16-21-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03395, current rewards: -1347.69601, mean: -0.65422
[32m[0906 16-21-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03394, current rewards: -1397.69601, mean: -0.66242
[32m[0906 16-21-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03394, current rewards: -1447.69601, mean: -0.67023
[32m[0906 16-21-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03393, current rewards: -1497.69601, mean: -0.67769
[32m[0906 16-21-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03392, current rewards: -1547.69601, mean: -0.68482
[32m[0906 16-21-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03391, current rewards: -1597.69601, mean: -0.69164
[32m[0906 16-21-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03390, current rewards: -1647.69601, mean: -0.69818
[32m[0906 16-21-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03389, current rewards: -1697.69601, mean: -0.70444
[32m[0906 16-21-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03389, current rewards: -1747.69601, mean: -0.71045
[32m[0906 16-21-48 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 16-21-48 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-21-48 @MBExp.py:227][0m Rewards obtained: [-1787.6960089094152], Lows: [3], Highs: [1860], Total time: 5488.867809999999
[32m[0906 16-23-58 @MBExp.py:144][0m ####################################################################
[32m[0906 16-23-58 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 16-23-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03472, current rewards: 0.22303, mean: 0.02230
[32m[0906 16-24-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03448, current rewards: 6.13853, mean: 0.10231
[32m[0906 16-24-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03446, current rewards: 12.04791, mean: 0.10953
[32m[0906 16-24-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03446, current rewards: 17.95903, mean: 0.11224
[32m[0906 16-24-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03444, current rewards: 23.87103, mean: 0.11367
[32m[0906 16-24-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03443, current rewards: 29.64514, mean: 0.11402
[32m[0906 16-24-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03444, current rewards: 35.49138, mean: 0.11449
[32m[0906 16-24-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03444, current rewards: 39.42039, mean: 0.10950
[32m[0906 16-24-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03443, current rewards: 45.58794, mean: 0.11119
[32m[0906 16-24-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03444, current rewards: 51.75038, mean: 0.11250
[32m[0906 16-24-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03445, current rewards: 57.91493, mean: 0.11356
[32m[0906 16-24-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03444, current rewards: 64.07816, mean: 0.11443
[32m[0906 16-24-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03445, current rewards: 70.24552, mean: 0.11516
[32m[0906 16-24-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03446, current rewards: 76.50905, mean: 0.11592
[32m[0906 16-24-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03447, current rewards: 80.73825, mean: 0.11372
[32m[0906 16-24-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03447, current rewards: 86.21724, mean: 0.11344
[32m[0906 16-24-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03444, current rewards: 91.69689, mean: 0.11321
[32m[0906 16-24-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03440, current rewards: 97.17305, mean: 0.11299
[32m[0906 16-24-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03435, current rewards: 102.65211, mean: 0.11280
[32m[0906 16-24-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03432, current rewards: 108.13139, mean: 0.11264
[32m[0906 16-24-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03427, current rewards: 112.56432, mean: 0.11145
[32m[0906 16-24-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03425, current rewards: 118.16671, mean: 0.11148
[32m[0906 16-24-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03421, current rewards: 123.51786, mean: 0.11128
[32m[0906 16-24-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03415, current rewards: 129.10178, mean: 0.11129
[32m[0906 16-24-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03412, current rewards: 134.70985, mean: 0.11133
[32m[0906 16-24-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03411, current rewards: 140.31435, mean: 0.11136
[32m[0906 16-24-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03410, current rewards: 145.92511, mean: 0.11139
[32m[0906 16-24-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03408, current rewards: 151.53975, mean: 0.11143
[32m[0906 16-24-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03407, current rewards: 157.15800, mean: 0.11146
[32m[0906 16-24-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03406, current rewards: 162.76516, mean: 0.11148
[32m[0906 16-24-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03405, current rewards: 168.37389, mean: 0.11151
[32m[0906 16-24-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03404, current rewards: 174.18945, mean: 0.11166
[32m[0906 16-24-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03402, current rewards: 178.61997, mean: 0.11094
[32m[0906 16-24-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03401, current rewards: 184.12560, mean: 0.11092
[32m[0906 16-24-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03400, current rewards: 189.63076, mean: 0.11090
[32m[0906 16-24-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03399, current rewards: 195.13952, mean: 0.11087
[32m[0906 16-25-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03397, current rewards: 200.64482, mean: 0.11085
[32m[0906 16-25-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03397, current rewards: 206.14989, mean: 0.11083
[32m[0906 16-25-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03395, current rewards: 211.66470, mean: 0.11082
[32m[0906 16-25-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03394, current rewards: 217.22976, mean: 0.11083
[32m[0906 16-25-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03394, current rewards: 221.21513, mean: 0.11006
[32m[0906 16-25-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03394, current rewards: 226.93105, mean: 0.11016
[32m[0906 16-25-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03393, current rewards: 232.65198, mean: 0.11026
[32m[0906 16-25-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03392, current rewards: 238.37509, mean: 0.11036
[32m[0906 16-25-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03392, current rewards: 244.09132, mean: 0.11045
[32m[0906 16-25-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03391, current rewards: 249.80422, mean: 0.11053
[32m[0906 16-25-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03390, current rewards: 255.51884, mean: 0.11061
[32m[0906 16-25-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03390, current rewards: 261.23840, mean: 0.11069
[32m[0906 16-25-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03390, current rewards: 266.75040, mean: 0.11068
[32m[0906 16-25-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03389, current rewards: 272.34698, mean: 0.11071
[32m[0906 16-25-23 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 16-25-23 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-25-23 @MBExp.py:227][0m Rewards obtained: [276.823115126599], Lows: [2], Highs: [5], Total time: 5574.262813999999
[32m[0906 16-27-36 @MBExp.py:144][0m ####################################################################
[32m[0906 16-27-36 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 16-27-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03445, current rewards: -0.96394, mean: -0.09639
[32m[0906 16-27-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03452, current rewards: 4.59563, mean: 0.07659
[32m[0906 16-27-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03446, current rewards: 10.15371, mean: 0.09231
[32m[0906 16-27-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03443, current rewards: 15.70702, mean: 0.09817
[32m[0906 16-27-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03438, current rewards: 21.26432, mean: 0.10126
[32m[0906 16-27-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03441, current rewards: 26.98610, mean: 0.10379
[32m[0906 16-27-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03441, current rewards: 32.58537, mean: 0.10511
[32m[0906 16-27-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03440, current rewards: 34.16124, mean: 0.09489
[32m[0906 16-27-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03442, current rewards: 39.75990, mean: 0.09698
[32m[0906 16-27-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03442, current rewards: 45.35948, mean: 0.09861
[32m[0906 16-27-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03443, current rewards: 50.95554, mean: 0.09991
[32m[0906 16-27-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03444, current rewards: 56.55778, mean: 0.10100
[32m[0906 16-27-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03445, current rewards: 62.15191, mean: 0.10189
[32m[0906 16-27-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03445, current rewards: 67.71608, mean: 0.10260
[32m[0906 16-28-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03445, current rewards: 72.11480, mean: 0.10157
[32m[0906 16-28-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03444, current rewards: 77.58652, mean: 0.10209
[32m[0906 16-28-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03443, current rewards: 83.05830, mean: 0.10254
[32m[0906 16-28-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03437, current rewards: 88.53306, mean: 0.10295
[32m[0906 16-28-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03431, current rewards: 93.99964, mean: 0.10330
[32m[0906 16-28-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03427, current rewards: 99.47512, mean: 0.10362
[32m[0906 16-28-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03424, current rewards: 104.94871, mean: 0.10391
[32m[0906 16-28-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03422, current rewards: 110.42110, mean: 0.10417
[32m[0906 16-28-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03417, current rewards: 115.87512, mean: 0.10439
[32m[0906 16-28-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03411, current rewards: 121.34717, mean: 0.10461
[32m[0906 16-28-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03406, current rewards: 126.81553, mean: 0.10481
[32m[0906 16-28-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03403, current rewards: 132.29064, mean: 0.10499
[32m[0906 16-28-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03403, current rewards: 137.76162, mean: 0.10516
[32m[0906 16-28-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03402, current rewards: 143.23735, mean: 0.10532
[32m[0906 16-28-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03400, current rewards: 149.36522, mean: 0.10593
[32m[0906 16-28-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03399, current rewards: 154.76736, mean: 0.10601
[32m[0906 16-28-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03399, current rewards: 160.10814, mean: 0.10603
[32m[0906 16-28-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03398, current rewards: 165.48663, mean: 0.10608
[32m[0906 16-28-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03397, current rewards: 170.86767, mean: 0.10613
[32m[0906 16-28-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03395, current rewards: 176.25081, mean: 0.10618
[32m[0906 16-28-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03394, current rewards: 181.62491, mean: 0.10621
[32m[0906 16-28-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03393, current rewards: 187.01078, mean: 0.10626
[32m[0906 16-28-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03392, current rewards: 192.39646, mean: 0.10630
[32m[0906 16-28-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03391, current rewards: 197.76708, mean: 0.10633
[32m[0906 16-28-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03390, current rewards: 203.15329, mean: 0.10636
[32m[0906 16-28-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03389, current rewards: 208.53303, mean: 0.10639
[32m[0906 16-28-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03389, current rewards: 213.91446, mean: 0.10643
[32m[0906 16-28-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03389, current rewards: 219.29946, mean: 0.10646
[32m[0906 16-28-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03388, current rewards: 224.68359, mean: 0.10649
[32m[0906 16-28-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03387, current rewards: 230.07628, mean: 0.10652
[32m[0906 16-28-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03386, current rewards: 235.46284, mean: 0.10654
[32m[0906 16-28-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03386, current rewards: 236.64015, mean: 0.10471
[32m[0906 16-28-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03385, current rewards: 242.17486, mean: 0.10484
[32m[0906 16-28-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03384, current rewards: 247.64134, mean: 0.10493
[32m[0906 16-28-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03384, current rewards: 253.10520, mean: 0.10502
[32m[0906 16-28-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03384, current rewards: 258.57387, mean: 0.10511
[32m[0906 16-29-01 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 16-29-01 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-29-01 @MBExp.py:227][0m Rewards obtained: [262.94690334343505], Lows: [4], Highs: [3], Total time: 5659.544293999998
[32m[0906 16-31-16 @MBExp.py:144][0m ####################################################################
[32m[0906 16-31-16 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 16-31-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03420, current rewards: -1.09660, mean: -0.10966
[32m[0906 16-31-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03429, current rewards: 4.49490, mean: 0.07492
[32m[0906 16-31-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03432, current rewards: 10.09198, mean: 0.09175
[32m[0906 16-31-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03432, current rewards: 15.68737, mean: 0.09805
[32m[0906 16-31-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03437, current rewards: 21.49589, mean: 0.10236
[32m[0906 16-31-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03436, current rewards: 27.10867, mean: 0.10426
[32m[0906 16-31-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03437, current rewards: 32.70808, mean: 0.10551
[32m[0906 16-31-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03439, current rewards: 37.10442, mean: 0.10307
[32m[0906 16-31-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03439, current rewards: 42.64546, mean: 0.10401
[32m[0906 16-31-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03438, current rewards: 48.19070, mean: 0.10476
[32m[0906 16-31-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03440, current rewards: 53.73330, mean: 0.10536
[32m[0906 16-31-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03442, current rewards: 59.27711, mean: 0.10585
[32m[0906 16-31-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03442, current rewards: 64.81692, mean: 0.10626
[32m[0906 16-31-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03443, current rewards: 70.24645, mean: 0.10643
[32m[0906 16-31-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03444, current rewards: 75.87191, mean: 0.10686
[32m[0906 16-31-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03445, current rewards: 81.49728, mean: 0.10723
[32m[0906 16-31-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03445, current rewards: 87.12777, mean: 0.10757
[32m[0906 16-31-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03440, current rewards: 92.75779, mean: 0.10786
[32m[0906 16-31-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03435, current rewards: 98.39142, mean: 0.10812
[32m[0906 16-31-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03432, current rewards: 104.01945, mean: 0.10835
[32m[0906 16-31-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03428, current rewards: 109.64680, mean: 0.10856
[32m[0906 16-31-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03425, current rewards: 115.37094, mean: 0.10884
[32m[0906 16-31-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03420, current rewards: 120.99416, mean: 0.10900
[32m[0906 16-31-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03413, current rewards: 126.61345, mean: 0.10915
[32m[0906 16-31-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03407, current rewards: 132.26295, mean: 0.10931
[32m[0906 16-31-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03402, current rewards: 138.01687, mean: 0.10954
[32m[0906 16-32-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03401, current rewards: 143.77633, mean: 0.10975
[32m[0906 16-32-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03399, current rewards: 149.53703, mean: 0.10995
[32m[0906 16-32-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03399, current rewards: 155.29220, mean: 0.11014
[32m[0906 16-32-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03397, current rewards: 160.80108, mean: 0.11014
[32m[0906 16-32-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03398, current rewards: 166.51167, mean: 0.11027
[32m[0906 16-32-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03397, current rewards: 172.22329, mean: 0.11040
[32m[0906 16-32-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03396, current rewards: 177.93594, mean: 0.11052
[32m[0906 16-32-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03395, current rewards: 183.64716, mean: 0.11063
[32m[0906 16-32-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03394, current rewards: 189.44155, mean: 0.11078
[32m[0906 16-32-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03393, current rewards: 195.16998, mean: 0.11089
[32m[0906 16-32-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03393, current rewards: 200.89542, mean: 0.11099
[32m[0906 16-32-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03392, current rewards: 206.62115, mean: 0.11109
[32m[0906 16-32-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03390, current rewards: 212.51162, mean: 0.11126
[32m[0906 16-32-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03389, current rewards: 218.26526, mean: 0.11136
[32m[0906 16-32-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03388, current rewards: 224.01369, mean: 0.11145
[32m[0906 16-32-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03387, current rewards: 229.76575, mean: 0.11154
[32m[0906 16-32-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03387, current rewards: 235.50713, mean: 0.11161
[32m[0906 16-32-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03386, current rewards: 237.06264, mean: 0.10975
[32m[0906 16-32-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03385, current rewards: 242.94514, mean: 0.10993
[32m[0906 16-32-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03385, current rewards: 248.82775, mean: 0.11010
[32m[0906 16-32-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03385, current rewards: 254.52122, mean: 0.11018
[32m[0906 16-32-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03384, current rewards: 260.32885, mean: 0.11031
[32m[0906 16-32-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03384, current rewards: 266.13998, mean: 0.11043
[32m[0906 16-32-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03383, current rewards: 271.94988, mean: 0.11055
[32m[0906 16-32-41 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 16-32-41 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-32-41 @MBExp.py:227][0m Rewards obtained: [276.5998370551995], Lows: [2], Highs: [3], Total time: 5744.823097999998
[32m[0906 16-34-57 @MBExp.py:144][0m ####################################################################
[32m[0906 16-34-57 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 16-34-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03371, current rewards: 0.45905, mean: 0.04590
[32m[0906 16-34-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03418, current rewards: 6.12629, mean: 0.10210
[32m[0906 16-35-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03428, current rewards: 11.69196, mean: 0.10629
[32m[0906 16-35-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03436, current rewards: 17.25577, mean: 0.10785
[32m[0906 16-35-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03438, current rewards: 18.64195, mean: 0.08877
[32m[0906 16-35-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03439, current rewards: 23.87990, mean: 0.09185
[32m[0906 16-35-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03442, current rewards: 29.47689, mean: 0.09509
[32m[0906 16-35-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03441, current rewards: 35.07364, mean: 0.09743
[32m[0906 16-35-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03442, current rewards: 40.66844, mean: 0.09919
[32m[0906 16-35-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03442, current rewards: 46.26382, mean: 0.10057
[32m[0906 16-35-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03441, current rewards: 51.85950, mean: 0.10169
[32m[0906 16-35-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03442, current rewards: 57.45864, mean: 0.10260
[32m[0906 16-35-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03443, current rewards: 63.05837, mean: 0.10337
[32m[0906 16-35-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03442, current rewards: 68.86237, mean: 0.10434
[32m[0906 16-35-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03441, current rewards: 76.79568, mean: 0.10816
[32m[0906 16-35-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03442, current rewards: 66.77197, mean: 0.08786
[32m[0906 16-35-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03443, current rewards: 71.20949, mean: 0.08791
[32m[0906 16-35-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03440, current rewards: 76.77553, mean: 0.08927
[32m[0906 16-35-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03436, current rewards: 82.33646, mean: 0.09048
[32m[0906 16-35-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03431, current rewards: 87.89526, mean: 0.09156
[32m[0906 16-35-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03428, current rewards: 93.46126, mean: 0.09254
[32m[0906 16-35-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03424, current rewards: 98.97627, mean: 0.09337
[32m[0906 16-35-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03420, current rewards: 104.44521, mean: 0.09409
[32m[0906 16-35-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03412, current rewards: 110.03103, mean: 0.09485
[32m[0906 16-35-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03406, current rewards: 115.61210, mean: 0.09555
[32m[0906 16-35-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03403, current rewards: 121.19241, mean: 0.09618
[32m[0906 16-35-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03400, current rewards: 126.77298, mean: 0.09677
[32m[0906 16-35-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03399, current rewards: 132.35554, mean: 0.09732
[32m[0906 16-35-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03398, current rewards: 137.94738, mean: 0.09784
[32m[0906 16-35-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03397, current rewards: 143.53535, mean: 0.09831
[32m[0906 16-35-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03396, current rewards: 149.21446, mean: 0.09882
[32m[0906 16-35-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03395, current rewards: 154.85834, mean: 0.09927
[32m[0906 16-35-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03393, current rewards: 160.47622, mean: 0.09967
[32m[0906 16-35-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03392, current rewards: 161.87038, mean: 0.09751
[32m[0906 16-35-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03391, current rewards: 167.40116, mean: 0.09790
[32m[0906 16-35-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03390, current rewards: 172.93256, mean: 0.09826
[32m[0906 16-35-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03389, current rewards: 177.36560, mean: 0.09799
[32m[0906 16-36-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03388, current rewards: 183.25209, mean: 0.09852
[32m[0906 16-36-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03387, current rewards: 189.13789, mean: 0.09903
[32m[0906 16-36-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03385, current rewards: 194.98128, mean: 0.09948
[32m[0906 16-36-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03385, current rewards: 200.86675, mean: 0.09993
[32m[0906 16-36-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03385, current rewards: 206.75039, mean: 0.10036
[32m[0906 16-36-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03385, current rewards: 212.63964, mean: 0.10078
[32m[0906 16-36-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03385, current rewards: 218.51371, mean: 0.10116
[32m[0906 16-36-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03384, current rewards: 224.39545, mean: 0.10154
[32m[0906 16-36-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03384, current rewards: 230.27778, mean: 0.10189
[32m[0906 16-36-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03384, current rewards: 236.15616, mean: 0.10223
[32m[0906 16-36-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03383, current rewards: 241.82470, mean: 0.10247
[32m[0906 16-36-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03383, current rewards: 247.62445, mean: 0.10275
[32m[0906 16-36-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03383, current rewards: 253.42854, mean: 0.10302
[32m[0906 16-36-22 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 16-36-22 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-36-22 @MBExp.py:227][0m Rewards obtained: [258.07491195747104], Lows: [4], Highs: [19], Total time: 5830.117723999998
[32m[0906 16-38-41 @MBExp.py:144][0m ####################################################################
[32m[0906 16-38-41 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 16-38-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03427, current rewards: -1.95339, mean: -0.19534
[32m[0906 16-38-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03454, current rewards: 3.41307, mean: 0.05688
[32m[0906 16-38-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03434, current rewards: 8.77236, mean: 0.07975
[32m[0906 16-38-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03442, current rewards: 14.13564, mean: 0.08835
[32m[0906 16-38-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03444, current rewards: 19.49475, mean: 0.09283
[32m[0906 16-38-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03442, current rewards: 24.92273, mean: 0.09586
[32m[0906 16-38-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03442, current rewards: 30.31525, mean: 0.09779
[32m[0906 16-38-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03441, current rewards: 35.69766, mean: 0.09916
[32m[0906 16-38-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03441, current rewards: 39.19171, mean: 0.09559
[32m[0906 16-38-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03440, current rewards: 45.50104, mean: 0.09892
[32m[0906 16-38-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03441, current rewards: 51.81441, mean: 0.10160
[32m[0906 16-39-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03440, current rewards: 58.12293, mean: 0.10379
[32m[0906 16-39-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03441, current rewards: 64.43511, mean: 0.10563
[32m[0906 16-39-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03441, current rewards: 70.80580, mean: 0.10728
[32m[0906 16-39-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03442, current rewards: 77.03640, mean: 0.10850
[32m[0906 16-39-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03443, current rewards: 83.29658, mean: 0.10960
[32m[0906 16-39-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03443, current rewards: 89.54756, mean: 0.11055
[32m[0906 16-39-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03444, current rewards: 95.79010, mean: 0.11138
[32m[0906 16-39-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03437, current rewards: 100.48400, mean: 0.11042
[32m[0906 16-39-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03434, current rewards: 106.10997, mean: 0.11053
[32m[0906 16-39-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03430, current rewards: 111.73439, mean: 0.11063
[32m[0906 16-39-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03428, current rewards: 117.40086, mean: 0.11076
[32m[0906 16-39-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03426, current rewards: 121.17985, mean: 0.10917
[32m[0906 16-39-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03417, current rewards: 126.84714, mean: 0.10935
[32m[0906 16-39-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03410, current rewards: 132.51361, mean: 0.10952
[32m[0906 16-39-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03404, current rewards: 138.18124, mean: 0.10967
[32m[0906 16-39-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03399, current rewards: 143.84303, mean: 0.10980
[32m[0906 16-39-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03397, current rewards: 149.50569, mean: 0.10993
[32m[0906 16-39-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03395, current rewards: 154.01395, mean: 0.10923
[32m[0906 16-39-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03393, current rewards: 159.56969, mean: 0.10929
[32m[0906 16-39-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03392, current rewards: 164.89310, mean: 0.10920
[32m[0906 16-39-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03391, current rewards: 170.38835, mean: 0.10922
[32m[0906 16-39-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03390, current rewards: 175.88381, mean: 0.10924
[32m[0906 16-39-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03389, current rewards: 181.37754, mean: 0.10926
[32m[0906 16-39-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03388, current rewards: 186.87386, mean: 0.10928
[32m[0906 16-39-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03387, current rewards: 192.36477, mean: 0.10930
[32m[0906 16-39-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03386, current rewards: 197.85962, mean: 0.10931
[32m[0906 16-39-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03385, current rewards: 203.35753, mean: 0.10933
[32m[0906 16-39-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03384, current rewards: 208.82458, mean: 0.10933
[32m[0906 16-39-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03382, current rewards: 213.06179, mean: 0.10870
[32m[0906 16-39-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03382, current rewards: 218.34068, mean: 0.10863
[32m[0906 16-39-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03381, current rewards: 223.62022, mean: 0.10855
[32m[0906 16-39-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03381, current rewards: 228.90255, mean: 0.10848
[32m[0906 16-39-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03381, current rewards: 234.17915, mean: 0.10842
[32m[0906 16-39-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03381, current rewards: 239.46118, mean: 0.10835
[32m[0906 16-39-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03380, current rewards: 244.74375, mean: 0.10829
[32m[0906 16-40-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03379, current rewards: 250.15507, mean: 0.10829
[32m[0906 16-40-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03379, current rewards: 255.46760, mean: 0.10825
[32m[0906 16-40-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03379, current rewards: 260.78704, mean: 0.10821
[32m[0906 16-40-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03378, current rewards: 266.10240, mean: 0.10817
[32m[0906 16-40-06 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 16-40-06 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-40-06 @MBExp.py:227][0m Rewards obtained: [270.3520770658422], Lows: [3], Highs: [4], Total time: 5915.277507999998
[32m[0906 16-42-26 @MBExp.py:144][0m ####################################################################
[32m[0906 16-42-26 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 16-42-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03398, current rewards: -0.96672, mean: -0.09667
[32m[0906 16-42-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03432, current rewards: 4.58177, mean: 0.07636
[32m[0906 16-42-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03437, current rewards: 10.12171, mean: 0.09202
[32m[0906 16-42-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03441, current rewards: 15.66709, mean: 0.09792
[32m[0906 16-42-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03444, current rewards: 21.17042, mean: 0.10081
[32m[0906 16-42-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03447, current rewards: 26.71599, mean: 0.10275
[32m[0906 16-42-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03450, current rewards: 32.26881, mean: 0.10409
[32m[0906 16-42-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03450, current rewards: 37.82110, mean: 0.10506
[32m[0906 16-42-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03450, current rewards: 43.37636, mean: 0.10580
[32m[0906 16-42-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03450, current rewards: 48.93118, mean: 0.10637
[32m[0906 16-42-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03448, current rewards: 54.48625, mean: 0.10684
[32m[0906 16-42-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03452, current rewards: 60.03816, mean: 0.10721
[32m[0906 16-42-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03451, current rewards: 65.58867, mean: 0.10752
[32m[0906 16-42-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03451, current rewards: 71.23965, mean: 0.10794
[32m[0906 16-42-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03452, current rewards: 76.77211, mean: 0.10813
[32m[0906 16-42-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03452, current rewards: 82.30156, mean: 0.10829
[32m[0906 16-42-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03452, current rewards: 87.83705, mean: 0.10844
[32m[0906 16-42-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03453, current rewards: 93.38265, mean: 0.10858
[32m[0906 16-42-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03448, current rewards: 99.33524, mean: 0.10916
[32m[0906 16-43-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03444, current rewards: 105.29554, mean: 0.10968
[32m[0906 16-43-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03439, current rewards: 111.25173, mean: 0.11015
[32m[0906 16-43-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03435, current rewards: 117.30851, mean: 0.11067
[32m[0906 16-43-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03432, current rewards: 123.18360, mean: 0.11098
[32m[0906 16-43-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03424, current rewards: 129.06086, mean: 0.11126
[32m[0906 16-43-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03419, current rewards: 134.93739, mean: 0.11152
[32m[0906 16-43-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03413, current rewards: 138.74956, mean: 0.11012
[32m[0906 16-43-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03408, current rewards: 144.27360, mean: 0.11013
[32m[0906 16-43-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03403, current rewards: 149.80060, mean: 0.11015
[32m[0906 16-43-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03403, current rewards: 155.32760, mean: 0.11016
[32m[0906 16-43-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03402, current rewards: 160.92938, mean: 0.11023
[32m[0906 16-43-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03400, current rewards: 165.66014, mean: 0.10971
[32m[0906 16-43-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03399, current rewards: 171.27384, mean: 0.10979
[32m[0906 16-43-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03397, current rewards: 176.88909, mean: 0.10987
[32m[0906 16-43-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03396, current rewards: 182.50297, mean: 0.10994
[32m[0906 16-43-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03395, current rewards: 188.12236, mean: 0.11001
[32m[0906 16-43-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03394, current rewards: 193.73160, mean: 0.11007
[32m[0906 16-43-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03393, current rewards: 199.34173, mean: 0.11013
[32m[0906 16-43-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03392, current rewards: 201.08255, mean: 0.10811
[32m[0906 16-43-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03392, current rewards: 206.58058, mean: 0.10816
[32m[0906 16-43-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03391, current rewards: 212.12664, mean: 0.10823
[32m[0906 16-43-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03391, current rewards: 217.66711, mean: 0.10829
[32m[0906 16-43-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03390, current rewards: 223.21062, mean: 0.10835
[32m[0906 16-43-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03389, current rewards: 228.76057, mean: 0.10842
[32m[0906 16-43-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03389, current rewards: 234.30493, mean: 0.10847
[32m[0906 16-43-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03388, current rewards: 235.50730, mean: 0.10656
[32m[0906 16-43-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03388, current rewards: 240.92412, mean: 0.10660
[32m[0906 16-43-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03388, current rewards: 246.21365, mean: 0.10659
[32m[0906 16-43-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03387, current rewards: 251.67417, mean: 0.10664
[32m[0906 16-43-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03387, current rewards: 257.13193, mean: 0.10669
[32m[0906 16-43-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03386, current rewards: 262.58823, mean: 0.10674
[32m[0906 16-43-52 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 16-43-52 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-43-52 @MBExp.py:227][0m Rewards obtained: [266.9509531878965], Lows: [5], Highs: [4], Total time: 6000.639229999998
[32m[0906 16-46-14 @MBExp.py:144][0m ####################################################################
[32m[0906 16-46-14 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 16-46-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03400, current rewards: -1.83543, mean: -0.18354
[32m[0906 16-46-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03425, current rewards: 3.76019, mean: 0.06267
[32m[0906 16-46-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03429, current rewards: 9.24647, mean: 0.08406
[32m[0906 16-46-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03429, current rewards: 14.73503, mean: 0.09209
[32m[0906 16-46-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03430, current rewards: 20.17447, mean: 0.09607
[32m[0906 16-46-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03432, current rewards: 25.65270, mean: 0.09866
[32m[0906 16-46-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03433, current rewards: 27.04693, mean: 0.08725
[32m[0906 16-46-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03435, current rewards: 32.59991, mean: 0.09056
[32m[0906 16-46-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03435, current rewards: 38.14673, mean: 0.09304
[32m[0906 16-46-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03438, current rewards: 43.69867, mean: 0.09500
[32m[0906 16-46-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03438, current rewards: 49.25334, mean: 0.09658
[32m[0906 16-46-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03439, current rewards: 54.80490, mean: 0.09787
[32m[0906 16-46-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03441, current rewards: 56.26747, mean: 0.09224
[32m[0906 16-46-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03441, current rewards: 61.81683, mean: 0.09366
[32m[0906 16-46-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03441, current rewards: 67.45471, mean: 0.09501
[32m[0906 16-46-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03441, current rewards: 73.09135, mean: 0.09617
[32m[0906 16-46-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03442, current rewards: 78.72869, mean: 0.09720
[32m[0906 16-46-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03442, current rewards: 84.36376, mean: 0.09810
[32m[0906 16-46-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03439, current rewards: 88.87976, mean: 0.09767
[32m[0906 16-46-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03435, current rewards: 94.42302, mean: 0.09836
[32m[0906 16-46-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03432, current rewards: 99.96619, mean: 0.09898
[32m[0906 16-46-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03428, current rewards: 105.45895, mean: 0.09949
[32m[0906 16-46-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03425, current rewards: 111.01009, mean: 0.10001
[32m[0906 16-46-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03418, current rewards: 116.55456, mean: 0.10048
[32m[0906 16-46-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03412, current rewards: 122.09836, mean: 0.10091
[32m[0906 16-46-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03406, current rewards: 127.64276, mean: 0.10130
[32m[0906 16-46-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03400, current rewards: 133.18962, mean: 0.10167
[32m[0906 16-47-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03395, current rewards: 138.73692, mean: 0.10201
[32m[0906 16-47-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03392, current rewards: 144.27782, mean: 0.10232
[32m[0906 16-47-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03391, current rewards: 149.90646, mean: 0.10268
[32m[0906 16-47-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03390, current rewards: 155.45646, mean: 0.10295
[32m[0906 16-47-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03389, current rewards: 160.55216, mean: 0.10292
[32m[0906 16-47-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03388, current rewards: 166.10226, mean: 0.10317
[32m[0906 16-47-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03387, current rewards: 171.65111, mean: 0.10340
[32m[0906 16-47-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03387, current rewards: 177.19484, mean: 0.10362
[32m[0906 16-47-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03386, current rewards: 182.73917, mean: 0.10383
[32m[0906 16-47-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03384, current rewards: 188.27877, mean: 0.10402
[32m[0906 16-47-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03383, current rewards: 193.74529, mean: 0.10416
[32m[0906 16-47-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03382, current rewards: 199.28177, mean: 0.10434
[32m[0906 16-47-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03382, current rewards: 205.48299, mean: 0.10484
[32m[0906 16-47-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03381, current rewards: 210.91241, mean: 0.10493
[32m[0906 16-47-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03380, current rewards: 216.34701, mean: 0.10502
[32m[0906 16-47-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03380, current rewards: 221.78035, mean: 0.10511
[32m[0906 16-47-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03379, current rewards: 227.21594, mean: 0.10519
[32m[0906 16-47-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03378, current rewards: 232.64416, mean: 0.10527
[32m[0906 16-47-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03378, current rewards: 238.02148, mean: 0.10532
[32m[0906 16-47-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03378, current rewards: 243.45916, mean: 0.10539
[32m[0906 16-47-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03378, current rewards: 248.89792, mean: 0.10547
[32m[0906 16-47-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03377, current rewards: 254.33808, mean: 0.10553
[32m[0906 16-47-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03377, current rewards: 258.08275, mean: 0.10491
[32m[0906 16-47-39 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 16-47-39 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-47-39 @MBExp.py:227][0m Rewards obtained: [262.4799614093847], Lows: [6], Highs: [3], Total time: 6085.787716999998
[32m[0906 16-50-04 @MBExp.py:144][0m ####################################################################
[32m[0906 16-50-04 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 16-50-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03397, current rewards: -0.08234, mean: -0.00823
[32m[0906 16-50-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03451, current rewards: 5.43279, mean: 0.09055
[32m[0906 16-50-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03449, current rewards: 10.95284, mean: 0.09957
[32m[0906 16-50-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03450, current rewards: 16.47178, mean: 0.10295
[32m[0906 16-50-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03449, current rewards: 21.99396, mean: 0.10473
[32m[0906 16-50-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03448, current rewards: 27.51463, mean: 0.10583
[32m[0906 16-50-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03447, current rewards: 31.87566, mean: 0.10282
[32m[0906 16-50-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03449, current rewards: 37.38957, mean: 0.10386
[32m[0906 16-50-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03450, current rewards: 42.90067, mean: 0.10464
[32m[0906 16-50-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03451, current rewards: 48.41070, mean: 0.10524
[32m[0906 16-50-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03450, current rewards: 53.92582, mean: 0.10574
[32m[0906 16-50-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03447, current rewards: 57.53329, mean: 0.10274
[32m[0906 16-50-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03448, current rewards: 63.06637, mean: 0.10339
[32m[0906 16-50-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03449, current rewards: 68.60284, mean: 0.10394
[32m[0906 16-50-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03449, current rewards: 74.13840, mean: 0.10442
[32m[0906 16-50-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03449, current rewards: 79.67461, mean: 0.10484
[32m[0906 16-50-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03449, current rewards: 85.21543, mean: 0.10520
[32m[0906 16-50-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03450, current rewards: 90.75039, mean: 0.10552
[32m[0906 16-50-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03451, current rewards: 96.28502, mean: 0.10581
[32m[0906 16-50-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03445, current rewards: 101.81913, mean: 0.10606
[32m[0906 16-50-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03440, current rewards: 107.35538, mean: 0.10629
[32m[0906 16-50-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03437, current rewards: 112.84753, mean: 0.10646
[32m[0906 16-50-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03434, current rewards: 118.88209, mean: 0.10710
[32m[0906 16-50-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03428, current rewards: 124.91754, mean: 0.10769
[32m[0906 16-50-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03421, current rewards: 130.94745, mean: 0.10822
[32m[0906 16-50-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03414, current rewards: 136.97944, mean: 0.10871
[32m[0906 16-50-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03409, current rewards: 143.01539, mean: 0.10917
[32m[0906 16-50-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03404, current rewards: 149.05168, mean: 0.10960
[32m[0906 16-50-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03399, current rewards: 155.12119, mean: 0.11002
[32m[0906 16-50-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03397, current rewards: 161.14633, mean: 0.11037
[32m[0906 16-50-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03396, current rewards: 167.18028, mean: 0.11072
[32m[0906 16-50-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03395, current rewards: 170.64011, mean: 0.10938
[32m[0906 16-50-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03395, current rewards: 176.04288, mean: 0.10934
[32m[0906 16-51-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03394, current rewards: 181.44293, mean: 0.10930
[32m[0906 16-51-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03393, current rewards: 186.84325, mean: 0.10927
[32m[0906 16-51-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03392, current rewards: 192.24539, mean: 0.10923
[32m[0906 16-51-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03391, current rewards: 197.59255, mean: 0.10917
[32m[0906 16-51-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03390, current rewards: 203.10922, mean: 0.10920
[32m[0906 16-51-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03390, current rewards: 208.63313, mean: 0.10923
[32m[0906 16-51-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03389, current rewards: 214.15350, mean: 0.10926
[32m[0906 16-51-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03388, current rewards: 217.71710, mean: 0.10832
[32m[0906 16-51-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03388, current rewards: 223.02502, mean: 0.10826
[32m[0906 16-51-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03387, current rewards: 228.31587, mean: 0.10821
[32m[0906 16-51-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03386, current rewards: 233.61331, mean: 0.10815
[32m[0906 16-51-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03385, current rewards: 239.02739, mean: 0.10816
[32m[0906 16-51-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03385, current rewards: 244.42895, mean: 0.10815
[32m[0906 16-51-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03384, current rewards: 249.83298, mean: 0.10815
[32m[0906 16-51-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03383, current rewards: 254.11773, mean: 0.10768
[32m[0906 16-51-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03383, current rewards: 259.64927, mean: 0.10774
[32m[0906 16-51-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03383, current rewards: 265.17385, mean: 0.10779
[32m[0906 16-51-29 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 16-51-29 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-51-29 @MBExp.py:227][0m Rewards obtained: [269.60059847827733], Lows: [3], Highs: [3], Total time: 6171.099579999998
[32m[0906 16-53-56 @MBExp.py:144][0m ####################################################################
[32m[0906 16-53-56 @MBExp.py:145][0m Starting training iteration 72.
[32m[0906 16-53-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03419, current rewards: -0.72685, mean: -0.07269
[32m[0906 16-53-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03445, current rewards: 5.15375, mean: 0.08590
[32m[0906 16-54-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03442, current rewards: 10.89670, mean: 0.09906
[32m[0906 16-54-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03445, current rewards: 16.65895, mean: 0.10412
[32m[0906 16-54-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03446, current rewards: 22.41310, mean: 0.10673
[32m[0906 16-54-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03444, current rewards: 28.17135, mean: 0.10835
[32m[0906 16-54-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03449, current rewards: 32.89788, mean: 0.10612
[32m[0906 16-54-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03451, current rewards: 38.59968, mean: 0.10722
[32m[0906 16-54-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03452, current rewards: 44.30739, mean: 0.10807
[32m[0906 16-54-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03452, current rewards: 50.01075, mean: 0.10872
[32m[0906 16-54-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03452, current rewards: 55.73876, mean: 0.10929
[32m[0906 16-54-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03452, current rewards: 61.49084, mean: 0.10981
[32m[0906 16-54-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03451, current rewards: 67.20184, mean: 0.11017
[32m[0906 16-54-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03452, current rewards: 72.90311, mean: 0.11046
[32m[0906 16-54-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03453, current rewards: 70.59489, mean: 0.09943
[32m[0906 16-54-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03453, current rewards: 77.86911, mean: 0.10246
[32m[0906 16-54-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03454, current rewards: 85.14333, mean: 0.10512
[32m[0906 16-54-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03454, current rewards: 92.41754, mean: 0.10746
[32m[0906 16-54-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03454, current rewards: 99.69176, mean: 0.10955
[32m[0906 16-54-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03449, current rewards: 103.44705, mean: 0.10776
[32m[0906 16-54-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03446, current rewards: 106.12810, mean: 0.10508
[32m[0906 16-54-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03442, current rewards: 108.80915, mean: 0.10265
[32m[0906 16-54-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03439, current rewards: 111.49020, mean: 0.10044
[32m[0906 16-54-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03432, current rewards: 114.17126, mean: 0.09842
[32m[0906 16-54-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03425, current rewards: 116.85231, mean: 0.09657
[32m[0906 16-54-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03418, current rewards: 87.92473, mean: 0.06978
[32m[0906 16-54-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03412, current rewards: 37.92473, mean: 0.02895
[32m[0906 16-54-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03408, current rewards: -12.07527, mean: -0.00888
[32m[0906 16-54-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03402, current rewards: -62.07527, mean: -0.04403
[32m[0906 16-54-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03398, current rewards: -112.07527, mean: -0.07676
[32m[0906 16-54-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03397, current rewards: -162.07527, mean: -0.10733
[32m[0906 16-54-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03396, current rewards: -212.07527, mean: -0.13595
[32m[0906 16-54-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03395, current rewards: -262.07527, mean: -0.16278
[32m[0906 16-54-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03394, current rewards: -312.07527, mean: -0.18800
[32m[0906 16-54-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03393, current rewards: -362.07527, mean: -0.21174
[32m[0906 16-54-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03393, current rewards: -412.07527, mean: -0.23413
[32m[0906 16-54-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03392, current rewards: -462.07527, mean: -0.25529
[32m[0906 16-54-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03391, current rewards: -512.07527, mean: -0.27531
[32m[0906 16-55-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03390, current rewards: -562.07527, mean: -0.29428
[32m[0906 16-55-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03390, current rewards: -612.07527, mean: -0.31228
[32m[0906 16-55-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03389, current rewards: -662.07527, mean: -0.32939
[32m[0906 16-55-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03388, current rewards: -712.07527, mean: -0.34567
[32m[0906 16-55-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03388, current rewards: -762.07527, mean: -0.36117
[32m[0906 16-55-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03388, current rewards: -812.07527, mean: -0.37596
[32m[0906 16-55-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03387, current rewards: -862.07527, mean: -0.39008
[32m[0906 16-55-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03387, current rewards: -912.07527, mean: -0.40357
[32m[0906 16-55-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03386, current rewards: -962.07527, mean: -0.41648
[32m[0906 16-55-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03385, current rewards: -1012.07527, mean: -0.42885
[32m[0906 16-55-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03385, current rewards: -1062.07527, mean: -0.44070
[32m[0906 16-55-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03384, current rewards: -1112.07527, mean: -0.45206
[32m[0906 16-55-21 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 16-55-21 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-55-21 @MBExp.py:227][0m Rewards obtained: [-1152.0752722123434], Lows: [4], Highs: [1273], Total time: 6256.414815999999
[32m[0906 16-57-50 @MBExp.py:144][0m ####################################################################
[32m[0906 16-57-50 @MBExp.py:145][0m Starting training iteration 73.
[32m[0906 16-57-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03392, current rewards: -0.01633, mean: -0.00163
[32m[0906 16-57-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03422, current rewards: 5.49542, mean: 0.09159
[32m[0906 16-57-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03442, current rewards: 11.21870, mean: 0.10199
[32m[0906 16-57-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03436, current rewards: 16.71553, mean: 0.10447
[32m[0906 16-57-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03439, current rewards: 22.23168, mean: 0.10587
[32m[0906 16-57-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03444, current rewards: 26.63176, mean: 0.10243
[32m[0906 16-58-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03443, current rewards: 32.19611, mean: 0.10386
[32m[0906 16-58-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03444, current rewards: 37.76029, mean: 0.10489
[32m[0906 16-58-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03447, current rewards: 43.32782, mean: 0.10568
[32m[0906 16-58-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03448, current rewards: 48.89449, mean: 0.10629
[32m[0906 16-58-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03448, current rewards: 54.41890, mean: 0.10670
[32m[0906 16-58-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03448, current rewards: 59.96657, mean: 0.10708
[32m[0906 16-58-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03450, current rewards: 65.51401, mean: 0.10740
[32m[0906 16-58-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03450, current rewards: 71.09907, mean: 0.10773
[32m[0906 16-58-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03451, current rewards: 76.63793, mean: 0.10794
[32m[0906 16-58-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03452, current rewards: 82.17485, mean: 0.10812
[32m[0906 16-58-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03453, current rewards: 87.71535, mean: 0.10829
[32m[0906 16-58-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03453, current rewards: 93.25208, mean: 0.10843
[32m[0906 16-58-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03452, current rewards: 94.55419, mean: 0.10391
[32m[0906 16-58-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03451, current rewards: 100.43231, mean: 0.10462
[32m[0906 16-58-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03446, current rewards: 106.30962, mean: 0.10526
[32m[0906 16-58-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03442, current rewards: 112.18808, mean: 0.10584
[32m[0906 16-58-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03439, current rewards: 118.06712, mean: 0.10637
[32m[0906 16-58-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03433, current rewards: 123.94452, mean: 0.10685
[32m[0906 16-58-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03427, current rewards: 129.81751, mean: 0.10729
[32m[0906 16-58-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03421, current rewards: 135.69122, mean: 0.10769
[32m[0906 16-58-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03415, current rewards: 140.17737, mean: 0.10701
[32m[0906 16-58-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03410, current rewards: 145.71986, mean: 0.10715
[32m[0906 16-58-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03406, current rewards: 151.25797, mean: 0.10728
[32m[0906 16-58-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03401, current rewards: 156.79722, mean: 0.10740
[32m[0906 16-58-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03397, current rewards: 162.33756, mean: 0.10751
[32m[0906 16-58-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03396, current rewards: 167.88281, mean: 0.10762
[32m[0906 16-58-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03395, current rewards: 173.42059, mean: 0.10771
[32m[0906 16-58-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03394, current rewards: 177.78223, mean: 0.10710
[32m[0906 16-58-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03394, current rewards: 183.35207, mean: 0.10722
[32m[0906 16-58-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03392, current rewards: 188.87968, mean: 0.10732
[32m[0906 16-58-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03392, current rewards: 194.40446, mean: 0.10741
[32m[0906 16-58-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03391, current rewards: 199.93018, mean: 0.10749
[32m[0906 16-58-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03390, current rewards: 205.55047, mean: 0.10762
[32m[0906 16-58-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03390, current rewards: 211.08182, mean: 0.10769
[32m[0906 16-58-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03389, current rewards: 216.61216, mean: 0.10777
[32m[0906 16-59-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03389, current rewards: 222.13813, mean: 0.10783
[32m[0906 16-59-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03388, current rewards: 227.75567, mean: 0.10794
[32m[0906 16-59-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03387, current rewards: 233.36407, mean: 0.10804
[32m[0906 16-59-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03387, current rewards: 236.87129, mean: 0.10718
[32m[0906 16-59-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03386, current rewards: 242.25732, mean: 0.10719
[32m[0906 16-59-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03386, current rewards: 247.64344, mean: 0.10720
[32m[0906 16-59-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03386, current rewards: 253.03051, mean: 0.10722
[32m[0906 16-59-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03385, current rewards: 258.41636, mean: 0.10723
[32m[0906 16-59-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03385, current rewards: 262.87699, mean: 0.10686
[32m[0906 16-59-15 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 16-59-15 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-59-15 @MBExp.py:227][0m Rewards obtained: [267.29584355029255], Lows: [3], Highs: [5], Total time: 6341.780642999998
[32m[0906 17-01-46 @MBExp.py:144][0m ####################################################################
[32m[0906 17-01-46 @MBExp.py:145][0m Starting training iteration 74.
[32m[0906 17-01-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03393, current rewards: -5.15028, mean: -0.51503
[32m[0906 17-01-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03432, current rewards: 0.27530, mean: 0.00459
[32m[0906 17-01-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03440, current rewards: 5.68020, mean: 0.05164
[32m[0906 17-01-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03443, current rewards: 11.08638, mean: 0.06929
[32m[0906 17-01-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03445, current rewards: 16.49862, mean: 0.07856
[32m[0906 17-01-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03446, current rewards: 21.90707, mean: 0.08426
[32m[0906 17-01-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03445, current rewards: 27.31280, mean: 0.08811
[32m[0906 17-01-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03448, current rewards: 32.72206, mean: 0.09089
[32m[0906 17-02-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03449, current rewards: 38.13088, mean: 0.09300
[32m[0906 17-02-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03448, current rewards: 43.62578, mean: 0.09484
[32m[0906 17-02-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03448, current rewards: 49.08719, mean: 0.09625
[32m[0906 17-02-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03450, current rewards: 54.52754, mean: 0.09737
[32m[0906 17-02-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03450, current rewards: 59.96587, mean: 0.09830
[32m[0906 17-02-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03448, current rewards: 65.41465, mean: 0.09911
[32m[0906 17-02-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03448, current rewards: 70.85725, mean: 0.09980
[32m[0906 17-02-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03448, current rewards: 74.64002, mean: 0.09821
[32m[0906 17-02-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03448, current rewards: 80.32805, mean: 0.09917
[32m[0906 17-02-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03448, current rewards: 86.01677, mean: 0.10002
[32m[0906 17-02-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03448, current rewards: 91.70254, mean: 0.10077
[32m[0906 17-02-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03448, current rewards: 97.38720, mean: 0.10145
[32m[0906 17-02-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03444, current rewards: 103.07555, mean: 0.10206
[32m[0906 17-02-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03441, current rewards: 108.76019, mean: 0.10260
[32m[0906 17-02-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03438, current rewards: 114.44226, mean: 0.10310
[32m[0906 17-02-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03433, current rewards: 120.13472, mean: 0.10356
[32m[0906 17-02-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03427, current rewards: 125.82148, mean: 0.10398
[32m[0906 17-02-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03421, current rewards: 131.50867, mean: 0.10437
[32m[0906 17-02-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03417, current rewards: 137.14241, mean: 0.10469
[32m[0906 17-02-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03411, current rewards: 142.87535, mean: 0.10506
[32m[0906 17-02-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03406, current rewards: 148.60560, mean: 0.10539
[32m[0906 17-02-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03402, current rewards: 154.33473, mean: 0.10571
[32m[0906 17-02-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03398, current rewards: 154.66469, mean: 0.10243
[32m[0906 17-02-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03395, current rewards: 160.26657, mean: 0.10273
[32m[0906 17-02-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03393, current rewards: 165.87503, mean: 0.10303
[32m[0906 17-02-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03391, current rewards: 171.47689, mean: 0.10330
[32m[0906 17-02-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03390, current rewards: 177.33513, mean: 0.10370
[32m[0906 17-02-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03389, current rewards: 182.96504, mean: 0.10396
[32m[0906 17-02-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03389, current rewards: 188.58550, mean: 0.10419
[32m[0906 17-02-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03387, current rewards: 194.21788, mean: 0.10442
[32m[0906 17-02-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03386, current rewards: 199.84395, mean: 0.10463
[32m[0906 17-02-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03386, current rewards: 201.22687, mean: 0.10267
[32m[0906 17-02-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03385, current rewards: 206.86379, mean: 0.10292
[32m[0906 17-02-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03384, current rewards: 212.50038, mean: 0.10316
[32m[0906 17-02-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03383, current rewards: 218.07816, mean: 0.10335
[32m[0906 17-03-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03384, current rewards: 223.72827, mean: 0.10358
[32m[0906 17-03-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03383, current rewards: 229.37684, mean: 0.10379
[32m[0906 17-03-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03382, current rewards: 235.02089, mean: 0.10399
[32m[0906 17-03-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03382, current rewards: 240.65973, mean: 0.10418
[32m[0906 17-03-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03382, current rewards: 246.30294, mean: 0.10437
[32m[0906 17-03-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03382, current rewards: 251.95186, mean: 0.10454
[32m[0906 17-03-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03381, current rewards: 257.58996, mean: 0.10471
[32m[0906 17-03-11 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-03-11 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-03-12 @MBExp.py:227][0m Rewards obtained: [260.1320174352163], Lows: [8], Highs: [3], Total time: 6427.0277289999985
[32m[0906 17-05-44 @MBExp.py:144][0m ####################################################################
[32m[0906 17-05-44 @MBExp.py:145][0m Starting training iteration 75.
[32m[0906 17-05-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03353, current rewards: -1.08937, mean: -0.10894
[32m[0906 17-05-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03429, current rewards: 4.52513, mean: 0.07542
[32m[0906 17-05-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03440, current rewards: 10.06052, mean: 0.09146
[32m[0906 17-05-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03442, current rewards: 15.59788, mean: 0.09749
[32m[0906 17-05-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03445, current rewards: 21.13880, mean: 0.10066
[32m[0906 17-05-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03444, current rewards: 26.67480, mean: 0.10260
[32m[0906 17-05-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03442, current rewards: 32.21198, mean: 0.10391
[32m[0906 17-05-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03441, current rewards: 37.74975, mean: 0.10486
[32m[0906 17-05-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03440, current rewards: 43.29080, mean: 0.10559
[32m[0906 17-06-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03441, current rewards: 48.89601, mean: 0.10630
[32m[0906 17-06-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03442, current rewards: 54.45854, mean: 0.10678
[32m[0906 17-06-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03443, current rewards: 57.97820, mean: 0.10353
[32m[0906 17-06-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03442, current rewards: 63.60889, mean: 0.10428
[32m[0906 17-06-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03442, current rewards: 69.23529, mean: 0.10490
[32m[0906 17-06-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03441, current rewards: 74.85878, mean: 0.10543
[32m[0906 17-06-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03442, current rewards: 76.34080, mean: 0.10045
[32m[0906 17-06-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03443, current rewards: 82.73218, mean: 0.10214
[32m[0906 17-06-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03442, current rewards: 88.07483, mean: 0.10241
[32m[0906 17-06-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03443, current rewards: 93.36642, mean: 0.10260
[32m[0906 17-06-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03443, current rewards: 98.72634, mean: 0.10284
[32m[0906 17-06-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03441, current rewards: 104.09026, mean: 0.10306
[32m[0906 17-06-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03437, current rewards: 109.45238, mean: 0.10326
[32m[0906 17-06-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03434, current rewards: 114.81226, mean: 0.10343
[32m[0906 17-06-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03431, current rewards: 120.17285, mean: 0.10360
[32m[0906 17-06-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03423, current rewards: 125.52995, mean: 0.10374
[32m[0906 17-06-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03418, current rewards: 130.89384, mean: 0.10388
[32m[0906 17-06-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03412, current rewards: 136.26951, mean: 0.10402
[32m[0906 17-06-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03407, current rewards: 140.58954, mean: 0.10337
[32m[0906 17-06-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03402, current rewards: 146.14345, mean: 0.10365
[32m[0906 17-06-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03397, current rewards: 151.69735, mean: 0.10390
[32m[0906 17-06-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03392, current rewards: 157.25350, mean: 0.10414
[32m[0906 17-06-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03388, current rewards: 162.81012, mean: 0.10437
[32m[0906 17-06-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03387, current rewards: 168.36499, mean: 0.10457
[32m[0906 17-06-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03386, current rewards: 173.92026, mean: 0.10477
[32m[0906 17-06-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03385, current rewards: 179.44206, mean: 0.10494
[32m[0906 17-06-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03385, current rewards: 184.99959, mean: 0.10511
[32m[0906 17-06-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03385, current rewards: 190.55840, mean: 0.10528
[32m[0906 17-06-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03384, current rewards: 196.11547, mean: 0.10544
[32m[0906 17-06-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03383, current rewards: 201.67108, mean: 0.10559
[32m[0906 17-06-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03383, current rewards: 207.22576, mean: 0.10573
[32m[0906 17-06-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03382, current rewards: 211.75926, mean: 0.10535
[32m[0906 17-06-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03382, current rewards: 217.44016, mean: 0.10555
[32m[0906 17-06-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03381, current rewards: 223.22925, mean: 0.10580
[32m[0906 17-06-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03380, current rewards: 228.92770, mean: 0.10599
[32m[0906 17-06-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03380, current rewards: 234.63232, mean: 0.10617
[32m[0906 17-07-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03380, current rewards: 240.33738, mean: 0.10634
[32m[0906 17-07-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03380, current rewards: 246.04637, mean: 0.10651
[32m[0906 17-07-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03379, current rewards: 251.74847, mean: 0.10667
[32m[0906 17-07-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03379, current rewards: 255.34371, mean: 0.10595
[32m[0906 17-07-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03379, current rewards: 260.85257, mean: 0.10604
[32m[0906 17-07-09 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-07-09 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-07-09 @MBExp.py:227][0m Rewards obtained: [265.21899954248977], Lows: [4], Highs: [4], Total time: 6512.232490999999
[32m[0906 17-09-45 @MBExp.py:144][0m ####################################################################
[32m[0906 17-09-45 @MBExp.py:145][0m Starting training iteration 76.
[32m[0906 17-09-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03217, current rewards: -0.09928, mean: -0.00993
[32m[0906 17-09-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03412, current rewards: 5.49061, mean: 0.09151
[32m[0906 17-09-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03431, current rewards: 11.14814, mean: 0.10135
[32m[0906 17-09-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03438, current rewards: 16.80990, mean: 0.10506
[32m[0906 17-09-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03441, current rewards: 22.46996, mean: 0.10700
[32m[0906 17-09-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03443, current rewards: 28.12712, mean: 0.10818
[32m[0906 17-09-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03445, current rewards: 33.78097, mean: 0.10897
[32m[0906 17-09-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03447, current rewards: 37.95279, mean: 0.10542
[32m[0906 17-09-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03447, current rewards: 43.79931, mean: 0.10683
[32m[0906 17-10-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03445, current rewards: 49.75388, mean: 0.10816
[32m[0906 17-10-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03447, current rewards: 55.51158, mean: 0.10885
[32m[0906 17-10-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03446, current rewards: 61.26870, mean: 0.10941
[32m[0906 17-10-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03446, current rewards: 65.83220, mean: 0.10792
[32m[0906 17-10-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03445, current rewards: 71.34865, mean: 0.10810
[32m[0906 17-10-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03446, current rewards: 76.80708, mean: 0.10818
[32m[0906 17-10-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03445, current rewards: 82.26381, mean: 0.10824
[32m[0906 17-10-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03445, current rewards: 87.72359, mean: 0.10830
[32m[0906 17-10-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03445, current rewards: 93.10729, mean: 0.10826
[32m[0906 17-10-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03445, current rewards: 98.60912, mean: 0.10836
[32m[0906 17-10-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03446, current rewards: 104.10738, mean: 0.10845
[32m[0906 17-10-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03445, current rewards: 109.61090, mean: 0.10853
[32m[0906 17-10-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03440, current rewards: 115.10275, mean: 0.10859
[32m[0906 17-10-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03437, current rewards: 120.60679, mean: 0.10865
[32m[0906 17-10-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03434, current rewards: 126.10960, mean: 0.10872
[32m[0906 17-10-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03426, current rewards: 131.61050, mean: 0.10877
[32m[0906 17-10-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03421, current rewards: 135.20182, mean: 0.10730
[32m[0906 17-10-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03414, current rewards: 91.72241, mean: 0.07002
[32m[0906 17-10-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03410, current rewards: 48.21258, mean: 0.03545
[32m[0906 17-10-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03405, current rewards: 4.69819, mean: 0.00333
[32m[0906 17-10-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03400, current rewards: -38.80406, mean: -0.02658
[32m[0906 17-10-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03396, current rewards: -82.27158, mean: -0.05448
[32m[0906 17-10-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03392, current rewards: -109.43572, mean: -0.07015
[32m[0906 17-10-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03390, current rewards: -104.08419, mean: -0.06465
[32m[0906 17-10-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03389, current rewards: -98.72568, mean: -0.05947
[32m[0906 17-10-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03389, current rewards: -93.50435, mean: -0.05468
[32m[0906 17-10-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03388, current rewards: -88.15552, mean: -0.05009
[32m[0906 17-10-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03387, current rewards: -82.80723, mean: -0.04575
[32m[0906 17-10-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03386, current rewards: -77.46379, mean: -0.04165
[32m[0906 17-10-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03386, current rewards: -72.11207, mean: -0.03776
[32m[0906 17-10-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03385, current rewards: -66.76074, mean: -0.03406
[32m[0906 17-10-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03384, current rewards: -61.40574, mean: -0.03055
[32m[0906 17-10-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03384, current rewards: -56.05820, mean: -0.02721
[32m[0906 17-10-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03383, current rewards: -50.53898, mean: -0.02395
[32m[0906 17-10-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03383, current rewards: -52.50434, mean: -0.02431
[32m[0906 17-11-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03383, current rewards: -44.84926, mean: -0.02029
[32m[0906 17-11-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03383, current rewards: -37.19418, mean: -0.01646
[32m[0906 17-11-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03382, current rewards: -29.53910, mean: -0.01279
[32m[0906 17-11-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03381, current rewards: -21.88402, mean: -0.00927
[32m[0906 17-11-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03381, current rewards: -14.22894, mean: -0.00590
[32m[0906 17-11-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03380, current rewards: -52.69792, mean: -0.02142
[32m[0906 17-11-10 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-11-10 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-11-10 @MBExp.py:227][0m Rewards obtained: [-92.69792430946536], Lows: [147], Highs: [83], Total time: 6597.463551999999
[32m[0906 17-13-46 @MBExp.py:144][0m ####################################################################
[32m[0906 17-13-46 @MBExp.py:145][0m Starting training iteration 77.
[32m[0906 17-13-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03300, current rewards: -0.11127, mean: -0.01113
[32m[0906 17-13-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03424, current rewards: 4.52181, mean: 0.07536
[32m[0906 17-13-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03431, current rewards: 9.47131, mean: 0.08610
[32m[0906 17-13-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03438, current rewards: 14.41829, mean: 0.09011
[32m[0906 17-13-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03439, current rewards: 19.33556, mean: 0.09207
[32m[0906 17-13-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03439, current rewards: 24.27102, mean: 0.09335
[32m[0906 17-13-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03439, current rewards: 29.24272, mean: 0.09433
[32m[0906 17-13-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03448, current rewards: 34.22230, mean: 0.09506
[32m[0906 17-14-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03447, current rewards: 39.15371, mean: 0.09550
[32m[0906 17-14-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03447, current rewards: 44.43829, mean: 0.09660
[32m[0906 17-14-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03449, current rewards: 49.42550, mean: 0.09691
[32m[0906 17-14-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03449, current rewards: 54.22931, mean: 0.09684
[32m[0906 17-14-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03449, current rewards: 59.24120, mean: 0.09712
[32m[0906 17-14-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03448, current rewards: 64.25642, mean: 0.09736
[32m[0906 17-14-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03447, current rewards: 69.27675, mean: 0.09757
[32m[0906 17-14-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03446, current rewards: 74.29635, mean: 0.09776
[32m[0906 17-14-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03446, current rewards: 79.31008, mean: 0.09791
[32m[0906 17-14-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03445, current rewards: 84.32849, mean: 0.09806
[32m[0906 17-14-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03446, current rewards: 89.23452, mean: 0.09806
[32m[0906 17-14-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03445, current rewards: 94.19909, mean: 0.09812
[32m[0906 17-14-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03445, current rewards: 99.16493, mean: 0.09818
[32m[0906 17-14-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03443, current rewards: 104.08975, mean: 0.09820
[32m[0906 17-14-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03439, current rewards: 109.09588, mean: 0.09828
[32m[0906 17-14-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03436, current rewards: 114.12089, mean: 0.09838
[32m[0906 17-14-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03434, current rewards: 119.15283, mean: 0.09847
[32m[0906 17-14-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03430, current rewards: 124.17120, mean: 0.09855
[32m[0906 17-14-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03423, current rewards: 129.04654, mean: 0.09851
[32m[0906 17-14-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03417, current rewards: 134.06242, mean: 0.09858
[32m[0906 17-14-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03411, current rewards: 139.07655, mean: 0.09864
[32m[0906 17-14-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03406, current rewards: 144.08682, mean: 0.09869
[32m[0906 17-14-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03402, current rewards: 149.09262, mean: 0.09874
[32m[0906 17-14-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03397, current rewards: 154.10534, mean: 0.09879
[32m[0906 17-14-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03393, current rewards: 154.87219, mean: 0.09619
[32m[0906 17-14-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03392, current rewards: 159.97937, mean: 0.09637
[32m[0906 17-14-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03392, current rewards: 165.11924, mean: 0.09656
[32m[0906 17-14-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03391, current rewards: 170.20431, mean: 0.09671
[32m[0906 17-14-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03390, current rewards: 175.29093, mean: 0.09685
[32m[0906 17-14-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03389, current rewards: 180.37676, mean: 0.09698
[32m[0906 17-14-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03389, current rewards: 185.49470, mean: 0.09712
[32m[0906 17-14-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03388, current rewards: 190.59225, mean: 0.09724
[32m[0906 17-14-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03387, current rewards: 195.69246, mean: 0.09736
[32m[0906 17-14-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03386, current rewards: 200.81022, mean: 0.09748
[32m[0906 17-14-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03386, current rewards: 206.02075, mean: 0.09764
[32m[0906 17-15-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03385, current rewards: 210.21751, mean: 0.09732
[32m[0906 17-15-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03385, current rewards: 215.73403, mean: 0.09762
[32m[0906 17-15-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03384, current rewards: 221.24917, mean: 0.09790
[32m[0906 17-15-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03384, current rewards: 226.76334, mean: 0.09817
[32m[0906 17-15-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03383, current rewards: 232.27807, mean: 0.09842
[32m[0906 17-15-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03383, current rewards: 237.78934, mean: 0.09867
[32m[0906 17-15-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03383, current rewards: 242.07591, mean: 0.09840
[32m[0906 17-15-12 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-15-12 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-15-12 @MBExp.py:227][0m Rewards obtained: [246.23807340372176], Lows: [2], Highs: [3], Total time: 6682.781179
[32m[0906 17-17-51 @MBExp.py:144][0m ####################################################################
[32m[0906 17-17-51 @MBExp.py:145][0m Starting training iteration 78.
[32m[0906 17-17-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03421, current rewards: -1.20739, mean: -0.12074
[32m[0906 17-17-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03450, current rewards: 4.33717, mean: 0.07229
[32m[0906 17-17-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03452, current rewards: 9.85290, mean: 0.08957
[32m[0906 17-17-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03452, current rewards: 15.36421, mean: 0.09603
[32m[0906 17-17-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03448, current rewards: 20.87078, mean: 0.09938
[32m[0906 17-18-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03451, current rewards: 26.37771, mean: 0.10145
[32m[0906 17-18-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03453, current rewards: 31.88646, mean: 0.10286
[32m[0906 17-18-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03450, current rewards: 37.39788, mean: 0.10388
[32m[0906 17-18-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03450, current rewards: 42.90403, mean: 0.10464
[32m[0906 17-18-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03451, current rewards: 48.38369, mean: 0.10518
[32m[0906 17-18-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03451, current rewards: 53.83395, mean: 0.10556
[32m[0906 17-18-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03451, current rewards: 59.26591, mean: 0.10583
[32m[0906 17-18-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03452, current rewards: 64.69573, mean: 0.10606
[32m[0906 17-18-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03452, current rewards: 70.11650, mean: 0.10624
[32m[0906 17-18-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03450, current rewards: 75.55236, mean: 0.10641
[32m[0906 17-18-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03451, current rewards: 80.98702, mean: 0.10656
[32m[0906 17-18-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03452, current rewards: 86.41403, mean: 0.10668
[32m[0906 17-18-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03453, current rewards: 91.74770, mean: 0.10668
[32m[0906 17-18-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03453, current rewards: 97.11233, mean: 0.10672
[32m[0906 17-18-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03452, current rewards: 98.28869, mean: 0.10238
[32m[0906 17-18-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03452, current rewards: 103.84044, mean: 0.10281
[32m[0906 17-18-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03449, current rewards: 109.38768, mean: 0.10320
[32m[0906 17-18-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03446, current rewards: 114.93646, mean: 0.10355
[32m[0906 17-18-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03443, current rewards: 120.48754, mean: 0.10387
[32m[0906 17-18-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03441, current rewards: 126.03335, mean: 0.10416
[32m[0906 17-18-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03438, current rewards: 131.57917, mean: 0.10443
[32m[0906 17-18-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03432, current rewards: 137.11959, mean: 0.10467
[32m[0906 17-18-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03426, current rewards: 142.64436, mean: 0.10489
[32m[0906 17-18-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03422, current rewards: 144.26014, mean: 0.10231
[32m[0906 17-18-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03417, current rewards: 150.40094, mean: 0.10301
[32m[0906 17-18-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03413, current rewards: 156.54157, mean: 0.10367
[32m[0906 17-18-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03409, current rewards: 162.68414, mean: 0.10428
[32m[0906 17-18-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03405, current rewards: 168.82812, mean: 0.10486
[32m[0906 17-18-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03403, current rewards: 174.96777, mean: 0.10540
[32m[0906 17-18-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03401, current rewards: 182.87892, mean: 0.10695
[32m[0906 17-18-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03400, current rewards: 191.93235, mean: 0.10905
[32m[0906 17-18-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03399, current rewards: 200.98579, mean: 0.11104
[32m[0906 17-18-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03398, current rewards: 210.03922, mean: 0.11292
[32m[0906 17-18-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03397, current rewards: 219.09266, mean: 0.11471
[32m[0906 17-18-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03396, current rewards: 228.14609, mean: 0.11640
[32m[0906 17-18-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03396, current rewards: 210.35003, mean: 0.10465
[32m[0906 17-19-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03396, current rewards: 215.97947, mean: 0.10484
[32m[0906 17-19-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03395, current rewards: 221.43357, mean: 0.10494
[32m[0906 17-19-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03395, current rewards: 226.91916, mean: 0.10506
[32m[0906 17-19-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03394, current rewards: 232.41955, mean: 0.10517
[32m[0906 17-19-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03393, current rewards: 237.91955, mean: 0.10527
[32m[0906 17-19-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03392, current rewards: 243.41587, mean: 0.10537
[32m[0906 17-19-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03392, current rewards: 248.91484, mean: 0.10547
[32m[0906 17-19-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03391, current rewards: 254.41696, mean: 0.10557
[32m[0906 17-19-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03391, current rewards: 259.92110, mean: 0.10566
[32m[0906 17-19-16 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 17-19-16 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-19-16 @MBExp.py:227][0m Rewards obtained: [264.3198540999337], Lows: [4], Highs: [23], Total time: 6768.290491
[32m[0906 17-21-57 @MBExp.py:144][0m ####################################################################
[32m[0906 17-21-57 @MBExp.py:145][0m Starting training iteration 79.
[32m[0906 17-21-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03301, current rewards: -0.01805, mean: -0.00180
[32m[0906 17-21-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03430, current rewards: 5.62010, mean: 0.09367
[32m[0906 17-22-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03449, current rewards: 11.19076, mean: 0.10173
[32m[0906 17-22-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03454, current rewards: 16.76218, mean: 0.10476
[32m[0906 17-22-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03448, current rewards: 22.33839, mean: 0.10637
[32m[0906 17-22-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03449, current rewards: 27.91902, mean: 0.10738
[32m[0906 17-22-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03448, current rewards: 36.45694, mean: 0.11760
[32m[0906 17-22-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03447, current rewards: 44.99486, mean: 0.12499
[32m[0906 17-22-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03447, current rewards: 53.53278, mean: 0.13057
[32m[0906 17-22-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03447, current rewards: 59.65966, mean: 0.12969
[32m[0906 17-22-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03447, current rewards: 32.35710, mean: 0.06345
[32m[0906 17-22-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03446, current rewards: -17.64290, mean: -0.03151
[32m[0906 17-22-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03444, current rewards: -67.64290, mean: -0.11089
[32m[0906 17-22-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03444, current rewards: -117.64290, mean: -0.17825
[32m[0906 17-22-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03444, current rewards: -167.64290, mean: -0.23612
[32m[0906 17-22-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03444, current rewards: -217.64290, mean: -0.28637
[32m[0906 17-22-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03442, current rewards: -267.64290, mean: -0.33042
[32m[0906 17-22-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03442, current rewards: -317.64290, mean: -0.36935
[32m[0906 17-22-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03441, current rewards: -367.64290, mean: -0.40400
[32m[0906 17-22-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03442, current rewards: -417.64290, mean: -0.43504
[32m[0906 17-22-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03442, current rewards: -467.64290, mean: -0.46301
[32m[0906 17-22-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03442, current rewards: -517.64290, mean: -0.48834
[32m[0906 17-22-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03436, current rewards: -567.64290, mean: -0.51139
[32m[0906 17-22-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03433, current rewards: -617.64290, mean: -0.53245
[32m[0906 17-22-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03429, current rewards: -667.64290, mean: -0.55177
[32m[0906 17-22-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03426, current rewards: -717.64290, mean: -0.56956
[32m[0906 17-22-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03420, current rewards: -767.64290, mean: -0.58599
[32m[0906 17-22-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03415, current rewards: -817.64290, mean: -0.60121
[32m[0906 17-22-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03411, current rewards: -867.64290, mean: -0.61535
[32m[0906 17-22-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03406, current rewards: -917.64290, mean: -0.62852
[32m[0906 17-22-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03402, current rewards: -967.64290, mean: -0.64082
[32m[0906 17-22-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03397, current rewards: -1017.64290, mean: -0.65234
[32m[0906 17-22-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03393, current rewards: -1067.64290, mean: -0.66313
[32m[0906 17-22-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03389, current rewards: -1117.64290, mean: -0.67328
[32m[0906 17-22-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03389, current rewards: -1167.64290, mean: -0.68283
[32m[0906 17-22-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03389, current rewards: -1217.64290, mean: -0.69184
[32m[0906 17-22-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03388, current rewards: -1267.64290, mean: -0.70036
[32m[0906 17-23-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03387, current rewards: -1317.64290, mean: -0.70841
[32m[0906 17-23-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03386, current rewards: -1367.64290, mean: -0.71604
[32m[0906 17-23-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03385, current rewards: -1417.64290, mean: -0.72329
[32m[0906 17-23-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03385, current rewards: -1467.64290, mean: -0.73017
[32m[0906 17-23-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03384, current rewards: -1517.64290, mean: -0.73672
[32m[0906 17-23-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03384, current rewards: -1567.64290, mean: -0.74296
[32m[0906 17-23-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03383, current rewards: -1617.64290, mean: -0.74891
[32m[0906 17-23-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03383, current rewards: -1667.64290, mean: -0.75459
[32m[0906 17-23-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03382, current rewards: -1717.64290, mean: -0.76002
[32m[0906 17-23-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03381, current rewards: -1767.64290, mean: -0.76521
[32m[0906 17-23-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03381, current rewards: -1817.64290, mean: -0.77019
[32m[0906 17-23-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03381, current rewards: -1867.64290, mean: -0.77496
[32m[0906 17-23-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03381, current rewards: -1917.64290, mean: -0.77953
[32m[0906 17-23-22 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-23-22 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-23-22 @MBExp.py:227][0m Rewards obtained: [-1957.6428994455762], Lows: [1], Highs: [2020], Total time: 6853.549231999999
[32m[0906 17-26-05 @MBExp.py:144][0m ####################################################################
[32m[0906 17-26-05 @MBExp.py:145][0m Starting training iteration 80.
[32m[0906 17-26-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03353, current rewards: 0.20069, mean: 0.02007
[32m[0906 17-26-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03450, current rewards: 5.88331, mean: 0.09806
[32m[0906 17-26-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03460, current rewards: 11.57160, mean: 0.10520
[32m[0906 17-26-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03453, current rewards: 17.25095, mean: 0.10782
[32m[0906 17-26-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03456, current rewards: 22.93562, mean: 0.10922
[32m[0906 17-26-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03455, current rewards: 28.61764, mean: 0.11007
[32m[0906 17-26-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03452, current rewards: 34.29857, mean: 0.11064
[32m[0906 17-26-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03452, current rewards: 39.98597, mean: 0.11107
[32m[0906 17-26-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03451, current rewards: 45.93229, mean: 0.11203
[32m[0906 17-26-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03449, current rewards: 51.84164, mean: 0.11270
[32m[0906 17-26-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03448, current rewards: 53.42440, mean: 0.10475
[32m[0906 17-26-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03447, current rewards: 59.25665, mean: 0.10582
[32m[0906 17-26-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03447, current rewards: 65.08100, mean: 0.10669
[32m[0906 17-26-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03448, current rewards: 70.90703, mean: 0.10743
[32m[0906 17-26-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03446, current rewards: 76.73407, mean: 0.10808
[32m[0906 17-26-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03445, current rewards: 82.56701, mean: 0.10864
[32m[0906 17-26-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03444, current rewards: 86.16875, mean: 0.10638
[32m[0906 17-26-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03445, current rewards: 91.66704, mean: 0.10659
[32m[0906 17-26-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03444, current rewards: 97.25635, mean: 0.10688
[32m[0906 17-26-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03444, current rewards: 102.84256, mean: 0.10713
[32m[0906 17-26-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03443, current rewards: 108.43094, mean: 0.10736
[32m[0906 17-26-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03445, current rewards: 114.02551, mean: 0.10757
[32m[0906 17-26-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03440, current rewards: 119.62174, mean: 0.10777
[32m[0906 17-26-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03436, current rewards: 125.21224, mean: 0.10794
[32m[0906 17-26-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03433, current rewards: 130.79858, mean: 0.10810
[32m[0906 17-26-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03431, current rewards: 136.40716, mean: 0.10826
[32m[0906 17-26-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03426, current rewards: 142.00230, mean: 0.10840
[32m[0906 17-26-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03420, current rewards: 147.59163, mean: 0.10852
[32m[0906 17-26-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03414, current rewards: 153.18518, mean: 0.10864
[32m[0906 17-26-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03409, current rewards: 158.77894, mean: 0.10875
[32m[0906 17-26-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03405, current rewards: 164.36972, mean: 0.10885
[32m[0906 17-26-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03401, current rewards: 167.04091, mean: 0.10708
[32m[0906 17-27-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03397, current rewards: 172.67610, mean: 0.10725
[32m[0906 17-27-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03394, current rewards: 178.31542, mean: 0.10742
[32m[0906 17-27-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03392, current rewards: 183.95324, mean: 0.10757
[32m[0906 17-27-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03391, current rewards: 189.58607, mean: 0.10772
[32m[0906 17-27-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03391, current rewards: 195.22338, mean: 0.10786
[32m[0906 17-27-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03390, current rewards: 200.85828, mean: 0.10799
[32m[0906 17-27-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03388, current rewards: 206.49102, mean: 0.10811
[32m[0906 17-27-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03388, current rewards: 212.12454, mean: 0.10823
[32m[0906 17-27-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03388, current rewards: 215.59694, mean: 0.10726
[32m[0906 17-27-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03387, current rewards: 221.15668, mean: 0.10736
[32m[0906 17-27-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03387, current rewards: 226.72223, mean: 0.10745
[32m[0906 17-27-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03386, current rewards: 232.27690, mean: 0.10754
[32m[0906 17-27-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03386, current rewards: 237.83888, mean: 0.10762
[32m[0906 17-27-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03385, current rewards: 243.40366, mean: 0.10770
[32m[0906 17-27-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03384, current rewards: 248.96123, mean: 0.10778
[32m[0906 17-27-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03383, current rewards: 254.52739, mean: 0.10785
[32m[0906 17-27-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03382, current rewards: 260.09141, mean: 0.10792
[32m[0906 17-27-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03382, current rewards: 265.65309, mean: 0.10799
[32m[0906 17-27-30 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-27-30 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-27-30 @MBExp.py:227][0m Rewards obtained: [270.1004870605624], Lows: [4], Highs: [4], Total time: 6938.836945999999
[32m[0906 17-30-15 @MBExp.py:144][0m ####################################################################
[32m[0906 17-30-15 @MBExp.py:145][0m Starting training iteration 81.
[32m[0906 17-30-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03391, current rewards: -1.73486, mean: -0.17349
[32m[0906 17-30-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03433, current rewards: 3.86246, mean: 0.06437
[32m[0906 17-30-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03435, current rewards: 9.44589, mean: 0.08587
[32m[0906 17-30-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03438, current rewards: 15.03428, mean: 0.09396
[32m[0906 17-30-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03440, current rewards: 20.62377, mean: 0.09821
[32m[0906 17-30-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03439, current rewards: 26.21380, mean: 0.10082
[32m[0906 17-30-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03436, current rewards: 31.80959, mean: 0.10261
[32m[0906 17-30-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03437, current rewards: 33.33663, mean: 0.09260
[32m[0906 17-30-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03439, current rewards: 38.91236, mean: 0.09491
[32m[0906 17-30-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03439, current rewards: 44.48673, mean: 0.09671
[32m[0906 17-30-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03441, current rewards: 50.05966, mean: 0.09816
[32m[0906 17-30-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03443, current rewards: 55.63417, mean: 0.09935
[32m[0906 17-30-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03444, current rewards: 61.20934, mean: 0.10034
[32m[0906 17-30-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03444, current rewards: 66.77842, mean: 0.10118
[32m[0906 17-30-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03445, current rewards: 70.49776, mean: 0.09929
[32m[0906 17-30-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03445, current rewards: 75.46327, mean: 0.09929
[32m[0906 17-30-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03446, current rewards: 26.51211, mean: 0.03273
[32m[0906 17-30-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03445, current rewards: -23.48789, mean: -0.02731
[32m[0906 17-30-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03445, current rewards: -73.48789, mean: -0.08076
[32m[0906 17-30-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03445, current rewards: -123.48789, mean: -0.12863
[32m[0906 17-30-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03444, current rewards: -173.48789, mean: -0.17177
[32m[0906 17-30-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03444, current rewards: -223.48789, mean: -0.21084
[32m[0906 17-30-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03440, current rewards: -273.48789, mean: -0.24639
[32m[0906 17-30-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03436, current rewards: -323.48789, mean: -0.27887
[32m[0906 17-30-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03433, current rewards: -373.48789, mean: -0.30867
[32m[0906 17-30-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03430, current rewards: -423.48789, mean: -0.33610
[32m[0906 17-31-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03429, current rewards: -473.48789, mean: -0.36144
[32m[0906 17-31-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03426, current rewards: -523.48789, mean: -0.38492
[32m[0906 17-31-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03423, current rewards: -573.48789, mean: -0.40673
[32m[0906 17-31-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03417, current rewards: -623.48789, mean: -0.42705
[32m[0906 17-31-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03413, current rewards: -673.48789, mean: -0.44602
[32m[0906 17-31-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03408, current rewards: -723.48789, mean: -0.46377
[32m[0906 17-31-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03404, current rewards: -773.48789, mean: -0.48043
[32m[0906 17-31-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03400, current rewards: -823.48789, mean: -0.49608
[32m[0906 17-31-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03396, current rewards: -873.48789, mean: -0.51081
[32m[0906 17-31-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03395, current rewards: -923.48789, mean: -0.52471
[32m[0906 17-31-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03394, current rewards: -973.48789, mean: -0.53784
[32m[0906 17-31-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03394, current rewards: -1023.48789, mean: -0.55026
[32m[0906 17-31-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03392, current rewards: -1073.48789, mean: -0.56204
[32m[0906 17-31-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03391, current rewards: -1123.48789, mean: -0.57321
[32m[0906 17-31-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03390, current rewards: -1173.48789, mean: -0.58382
[32m[0906 17-31-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03389, current rewards: -1223.48789, mean: -0.59393
[32m[0906 17-31-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03388, current rewards: -1273.48789, mean: -0.60355
[32m[0906 17-31-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03387, current rewards: -1323.48789, mean: -0.61273
[32m[0906 17-31-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03386, current rewards: -1373.48789, mean: -0.62149
[32m[0906 17-31-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03385, current rewards: -1423.48789, mean: -0.62986
[32m[0906 17-31-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03384, current rewards: -1473.48789, mean: -0.63787
[32m[0906 17-31-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03383, current rewards: -1523.48789, mean: -0.64555
[32m[0906 17-31-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03383, current rewards: -1573.48789, mean: -0.65290
[32m[0906 17-31-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03382, current rewards: -1623.48789, mean: -0.65995
[32m[0906 17-31-40 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-31-40 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-31-40 @MBExp.py:227][0m Rewards obtained: [-1663.4878859297569], Lows: [4], Highs: [1740], Total time: 7024.118742
[32m[0906 17-34-27 @MBExp.py:144][0m ####################################################################
[32m[0906 17-34-27 @MBExp.py:145][0m Starting training iteration 82.
[32m[0906 17-34-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03401, current rewards: -0.37910, mean: -0.03791
[32m[0906 17-34-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03445, current rewards: 6.88504, mean: 0.11475
[32m[0906 17-34-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03439, current rewards: 14.15925, mean: 0.12872
[32m[0906 17-34-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03445, current rewards: 21.43346, mean: 0.13396
[32m[0906 17-34-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03443, current rewards: 28.70768, mean: 0.13670
[32m[0906 17-34-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03438, current rewards: 35.98189, mean: 0.13839
[32m[0906 17-34-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03440, current rewards: 43.25611, mean: 0.13954
[32m[0906 17-34-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03438, current rewards: 46.49578, mean: 0.12915
[32m[0906 17-34-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03440, current rewards: 49.08301, mean: 0.11971
[32m[0906 17-34-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03439, current rewards: 23.27313, mean: 0.05059
[32m[0906 17-34-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03440, current rewards: -26.72687, mean: -0.05241
[32m[0906 17-34-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03441, current rewards: -76.72687, mean: -0.13701
[32m[0906 17-34-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03442, current rewards: -126.72687, mean: -0.20775
[32m[0906 17-34-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03444, current rewards: -176.72687, mean: -0.26777
[32m[0906 17-34-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03444, current rewards: -226.72687, mean: -0.31933
[32m[0906 17-34-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03443, current rewards: -276.72687, mean: -0.36411
[32m[0906 17-34-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03444, current rewards: -326.72687, mean: -0.40337
[32m[0906 17-34-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03443, current rewards: -376.72687, mean: -0.43805
[32m[0906 17-34-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03443, current rewards: -426.72687, mean: -0.46893
[32m[0906 17-35-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03444, current rewards: -476.72687, mean: -0.49659
[32m[0906 17-35-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03444, current rewards: -526.72687, mean: -0.52151
[32m[0906 17-35-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03444, current rewards: -576.72687, mean: -0.54408
[32m[0906 17-35-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03440, current rewards: -626.72687, mean: -0.56462
[32m[0906 17-35-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03436, current rewards: -676.72687, mean: -0.58339
[32m[0906 17-35-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03434, current rewards: -726.72687, mean: -0.60060
[32m[0906 17-35-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03432, current rewards: -776.72687, mean: -0.61645
[32m[0906 17-35-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03430, current rewards: -826.72687, mean: -0.63109
[32m[0906 17-35-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03428, current rewards: -876.72687, mean: -0.64465
[32m[0906 17-35-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03424, current rewards: -926.72687, mean: -0.65725
[32m[0906 17-35-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03419, current rewards: -976.72687, mean: -0.66899
[32m[0906 17-35-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03413, current rewards: -1026.72687, mean: -0.67995
[32m[0906 17-35-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03408, current rewards: -1076.72687, mean: -0.69021
[32m[0906 17-35-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03404, current rewards: -1126.72687, mean: -0.69983
[32m[0906 17-35-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03400, current rewards: -1176.72687, mean: -0.70887
[32m[0906 17-35-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03397, current rewards: -1226.72687, mean: -0.71738
[32m[0906 17-35-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03395, current rewards: -1276.72687, mean: -0.72541
[32m[0906 17-35-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03394, current rewards: -1326.72687, mean: -0.73300
[32m[0906 17-35-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03393, current rewards: -1376.72687, mean: -0.74018
[32m[0906 17-35-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03392, current rewards: -1426.72687, mean: -0.74698
[32m[0906 17-35-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03391, current rewards: -1476.72687, mean: -0.75343
[32m[0906 17-35-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03391, current rewards: -1526.72687, mean: -0.75957
[32m[0906 17-35-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03390, current rewards: -1576.72687, mean: -0.76540
[32m[0906 17-35-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03389, current rewards: -1626.72687, mean: -0.77096
[32m[0906 17-35-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03389, current rewards: -1676.72687, mean: -0.77626
[32m[0906 17-35-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03388, current rewards: -1726.72687, mean: -0.78132
[32m[0906 17-35-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03388, current rewards: -1776.72687, mean: -0.78616
[32m[0906 17-35-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03387, current rewards: -1826.72687, mean: -0.79079
[32m[0906 17-35-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03387, current rewards: -1876.72687, mean: -0.79522
[32m[0906 17-35-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03387, current rewards: -1926.72687, mean: -0.79947
[32m[0906 17-35-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03386, current rewards: -1976.72687, mean: -0.80355
[32m[0906 17-35-52 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 17-35-52 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-35-52 @MBExp.py:227][0m Rewards obtained: [-2016.7268690076817], Lows: [1], Highs: [2067], Total time: 7109.488743999999
[32m[0906 17-38-41 @MBExp.py:144][0m ####################################################################
[32m[0906 17-38-41 @MBExp.py:145][0m Starting training iteration 83.
[32m[0906 17-38-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03362, current rewards: -4.18092, mean: -0.41809
[32m[0906 17-38-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03424, current rewards: 1.51208, mean: 0.02520
[32m[0906 17-38-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03439, current rewards: 7.04042, mean: 0.06400
[32m[0906 17-38-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03442, current rewards: 12.56548, mean: 0.07853
[32m[0906 17-38-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03441, current rewards: 18.09794, mean: 0.08618
[32m[0906 17-38-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03443, current rewards: 23.62537, mean: 0.09087
[32m[0906 17-38-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03446, current rewards: 29.14815, mean: 0.09403
[32m[0906 17-38-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03444, current rewards: 34.44681, mean: 0.09569
[32m[0906 17-38-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03444, current rewards: 40.00691, mean: 0.09758
[32m[0906 17-38-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03444, current rewards: 45.56952, mean: 0.09906
[32m[0906 17-38-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03444, current rewards: 50.05254, mean: 0.09814
[32m[0906 17-39-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03445, current rewards: 55.83265, mean: 0.09970
[32m[0906 17-39-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03446, current rewards: 61.61660, mean: 0.10101
[32m[0906 17-39-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03446, current rewards: 67.40049, mean: 0.10212
[32m[0906 17-39-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03446, current rewards: 73.18283, mean: 0.10307
[32m[0906 17-39-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03445, current rewards: 79.09443, mean: 0.10407
[32m[0906 17-39-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03445, current rewards: 84.86337, mean: 0.10477
[32m[0906 17-39-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03443, current rewards: 90.62445, mean: 0.10538
[32m[0906 17-39-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03443, current rewards: 96.38355, mean: 0.10592
[32m[0906 17-39-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03442, current rewards: 102.14373, mean: 0.10640
[32m[0906 17-39-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03441, current rewards: 107.90345, mean: 0.10684
[32m[0906 17-39-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03441, current rewards: 107.31143, mean: 0.10124
[32m[0906 17-39-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03437, current rewards: 112.82675, mean: 0.10165
[32m[0906 17-39-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03433, current rewards: 118.34439, mean: 0.10202
[32m[0906 17-39-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03430, current rewards: 123.94873, mean: 0.10244
[32m[0906 17-39-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03428, current rewards: 129.44012, mean: 0.10273
[32m[0906 17-39-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03425, current rewards: 134.93741, mean: 0.10301
[32m[0906 17-39-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03423, current rewards: 140.43070, mean: 0.10326
[32m[0906 17-39-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03421, current rewards: 145.91722, mean: 0.10349
[32m[0906 17-39-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03419, current rewards: 151.41506, mean: 0.10371
[32m[0906 17-39-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03416, current rewards: 156.90749, mean: 0.10391
[32m[0906 17-39-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03411, current rewards: 162.39948, mean: 0.10410
[32m[0906 17-39-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03406, current rewards: 166.13935, mean: 0.10319
[32m[0906 17-39-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03402, current rewards: 171.83102, mean: 0.10351
[32m[0906 17-39-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03399, current rewards: 177.51816, mean: 0.10381
[32m[0906 17-39-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03396, current rewards: 183.21045, mean: 0.10410
[32m[0906 17-39-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03396, current rewards: 188.89939, mean: 0.10436
[32m[0906 17-39-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03394, current rewards: 194.59155, mean: 0.10462
[32m[0906 17-39-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03393, current rewards: 200.28304, mean: 0.10486
[32m[0906 17-39-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03392, current rewards: 205.97469, mean: 0.10509
[32m[0906 17-39-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03391, current rewards: 211.50477, mean: 0.10523
[32m[0906 17-39-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03390, current rewards: 214.98452, mean: 0.10436
[32m[0906 17-39-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03389, current rewards: 220.41917, mean: 0.10446
[32m[0906 17-39-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03388, current rewards: 225.85826, mean: 0.10456
[32m[0906 17-39-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03387, current rewards: 231.29668, mean: 0.10466
[32m[0906 17-39-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03387, current rewards: 236.73584, mean: 0.10475
[32m[0906 17-40-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03387, current rewards: 242.17564, mean: 0.10484
[32m[0906 17-40-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03386, current rewards: 247.61515, mean: 0.10492
[32m[0906 17-40-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03385, current rewards: 252.99341, mean: 0.10498
[32m[0906 17-40-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03385, current rewards: 258.44028, mean: 0.10506
[32m[0906 17-40-06 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-40-06 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-40-06 @MBExp.py:227][0m Rewards obtained: [262.8052142851549], Lows: [7], Highs: [3], Total time: 7194.857088999999
[32m[0906 17-42-57 @MBExp.py:144][0m ####################################################################
[32m[0906 17-42-57 @MBExp.py:145][0m Starting training iteration 84.
[32m[0906 17-42-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03458, current rewards: -0.08313, mean: -0.00831
[32m[0906 17-42-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03458, current rewards: 5.47932, mean: 0.09132
[32m[0906 17-43-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03464, current rewards: 11.03557, mean: 0.10032
[32m[0906 17-43-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03460, current rewards: 16.59544, mean: 0.10372
[32m[0906 17-43-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03457, current rewards: 22.15189, mean: 0.10549
[32m[0906 17-43-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03456, current rewards: 27.70874, mean: 0.10657
[32m[0906 17-43-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03456, current rewards: 33.20346, mean: 0.10711
[32m[0906 17-43-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03455, current rewards: 38.71312, mean: 0.10754
[32m[0906 17-43-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03452, current rewards: 44.32739, mean: 0.10812
[32m[0906 17-43-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03455, current rewards: 49.94172, mean: 0.10857
[32m[0906 17-43-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03455, current rewards: 55.55927, mean: 0.10894
[32m[0906 17-43-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03455, current rewards: 61.17524, mean: 0.10924
[32m[0906 17-43-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03454, current rewards: 66.78640, mean: 0.10949
[32m[0906 17-43-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03454, current rewards: 72.40317, mean: 0.10970
[32m[0906 17-43-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03454, current rewards: 78.01905, mean: 0.10989
[32m[0906 17-43-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03453, current rewards: 83.74092, mean: 0.11019
[32m[0906 17-43-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03452, current rewards: 89.35276, mean: 0.11031
[32m[0906 17-43-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03452, current rewards: 94.97037, mean: 0.11043
[32m[0906 17-43-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03452, current rewards: 100.58530, mean: 0.11053
[32m[0906 17-43-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03451, current rewards: 106.19575, mean: 0.11062
[32m[0906 17-43-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03451, current rewards: 111.80370, mean: 0.11070
[32m[0906 17-43-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03450, current rewards: 115.41754, mean: 0.10888
[32m[0906 17-43-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03444, current rewards: 120.27894, mean: 0.10836
[32m[0906 17-43-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03441, current rewards: 125.09377, mean: 0.10784
[32m[0906 17-43-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03438, current rewards: 129.99082, mean: 0.10743
[32m[0906 17-43-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03435, current rewards: 134.88748, mean: 0.10705
[32m[0906 17-43-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03432, current rewards: 139.78479, mean: 0.10671
[32m[0906 17-43-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03428, current rewards: 144.68244, mean: 0.10638
[32m[0906 17-43-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03426, current rewards: 149.58001, mean: 0.10609
[32m[0906 17-43-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03423, current rewards: 154.47794, mean: 0.10581
[32m[0906 17-43-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03418, current rewards: 159.37470, mean: 0.10555
[32m[0906 17-43-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03412, current rewards: 164.35829, mean: 0.10536
[32m[0906 17-43-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03408, current rewards: 169.10633, mean: 0.10503
[32m[0906 17-43-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03403, current rewards: 172.14666, mean: 0.10370
[32m[0906 17-43-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03399, current rewards: 177.68904, mean: 0.10391
[32m[0906 17-43-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03395, current rewards: 183.23449, mean: 0.10411
[32m[0906 17-43-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03394, current rewards: 188.77733, mean: 0.10430
[32m[0906 17-44-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03393, current rewards: 193.28738, mean: 0.10392
[32m[0906 17-44-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03393, current rewards: 198.71403, mean: 0.10404
[32m[0906 17-44-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03392, current rewards: 204.14138, mean: 0.10415
[32m[0906 17-44-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03391, current rewards: 209.57062, mean: 0.10426
[32m[0906 17-44-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03391, current rewards: 214.99683, mean: 0.10437
[32m[0906 17-44-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03391, current rewards: 220.41622, mean: 0.10446
[32m[0906 17-44-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03390, current rewards: 225.83820, mean: 0.10455
[32m[0906 17-44-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03389, current rewards: 231.25806, mean: 0.10464
[32m[0906 17-44-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03388, current rewards: 236.67631, mean: 0.10472
[32m[0906 17-44-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03388, current rewards: 242.10059, mean: 0.10481
[32m[0906 17-44-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03387, current rewards: 247.51927, mean: 0.10488
[32m[0906 17-44-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03387, current rewards: 253.62461, mean: 0.10524
[32m[0906 17-44-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03386, current rewards: 259.17160, mean: 0.10535
[32m[0906 17-44-22 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 17-44-22 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-44-22 @MBExp.py:227][0m Rewards obtained: [263.6094138476145], Lows: [1], Highs: [4], Total time: 7280.2458719999995
[32m[0906 17-47-15 @MBExp.py:144][0m ####################################################################
[32m[0906 17-47-15 @MBExp.py:145][0m Starting training iteration 85.
[32m[0906 17-47-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03564, current rewards: -1.08429, mean: -0.10843
[32m[0906 17-47-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03469, current rewards: 4.52018, mean: 0.07534
[32m[0906 17-47-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03449, current rewards: 10.12018, mean: 0.09200
[32m[0906 17-47-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03453, current rewards: 15.71212, mean: 0.09820
[32m[0906 17-47-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03449, current rewards: 21.30783, mean: 0.10147
[32m[0906 17-47-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03452, current rewards: 26.90166, mean: 0.10347
[32m[0906 17-47-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03451, current rewards: 32.43724, mean: 0.10464
[32m[0906 17-47-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03450, current rewards: 38.02909, mean: 0.10564
[32m[0906 17-47-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03449, current rewards: 43.61927, mean: 0.10639
[32m[0906 17-47-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03448, current rewards: 49.20728, mean: 0.10697
[32m[0906 17-47-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03450, current rewards: 54.79323, mean: 0.10744
[32m[0906 17-47-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03448, current rewards: 60.37826, mean: 0.10782
[32m[0906 17-47-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03447, current rewards: 61.89603, mean: 0.10147
[32m[0906 17-47-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03448, current rewards: 67.71359, mean: 0.10260
[32m[0906 17-47-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03448, current rewards: 73.60717, mean: 0.10367
[32m[0906 17-47-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03446, current rewards: 79.44771, mean: 0.10454
[32m[0906 17-47-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03446, current rewards: 85.28981, mean: 0.10530
[32m[0906 17-47-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03447, current rewards: 91.13147, mean: 0.10597
[32m[0906 17-47-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03447, current rewards: 96.97088, mean: 0.10656
[32m[0906 17-47-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03446, current rewards: 102.81142, mean: 0.10710
[32m[0906 17-47-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03447, current rewards: 108.65362, mean: 0.10758
[32m[0906 17-47-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03447, current rewards: 114.49508, mean: 0.10801
[32m[0906 17-47-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03442, current rewards: 120.83218, mean: 0.10886
[32m[0906 17-47-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03438, current rewards: 113.97428, mean: 0.09825
[32m[0906 17-47-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03435, current rewards: 94.82737, mean: 0.07837
[32m[0906 17-47-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03431, current rewards: 101.53244, mean: 0.08058
[32m[0906 17-48-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03429, current rewards: 108.24226, mean: 0.08263
[32m[0906 17-48-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03427, current rewards: 114.95063, mean: 0.08452
[32m[0906 17-48-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03425, current rewards: 121.65169, mean: 0.08628
[32m[0906 17-48-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03423, current rewards: 126.92258, mean: 0.08693
[32m[0906 17-48-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03416, current rewards: 132.46028, mean: 0.08772
[32m[0906 17-48-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03411, current rewards: 138.00864, mean: 0.08847
[32m[0906 17-48-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03407, current rewards: 143.56816, mean: 0.08917
[32m[0906 17-48-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03403, current rewards: 149.12231, mean: 0.08983
[32m[0906 17-48-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03399, current rewards: 154.68015, mean: 0.09046
[32m[0906 17-48-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03395, current rewards: 160.24222, mean: 0.09105
[32m[0906 17-48-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03393, current rewards: 163.77657, mean: 0.09048
[32m[0906 17-48-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03391, current rewards: 169.14871, mean: 0.09094
[32m[0906 17-48-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03391, current rewards: 174.51776, mean: 0.09137
[32m[0906 17-48-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03390, current rewards: 179.89811, mean: 0.09178
[32m[0906 17-48-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03389, current rewards: 185.27042, mean: 0.09217
[32m[0906 17-48-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03388, current rewards: 190.64540, mean: 0.09255
[32m[0906 17-48-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03388, current rewards: 196.02182, mean: 0.09290
[32m[0906 17-48-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03387, current rewards: 200.33594, mean: 0.09275
[32m[0906 17-48-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03386, current rewards: 205.94197, mean: 0.09319
[32m[0906 17-48-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03385, current rewards: 211.54921, mean: 0.09361
[32m[0906 17-48-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03385, current rewards: 217.12929, mean: 0.09400
[32m[0906 17-48-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03385, current rewards: 222.66582, mean: 0.09435
[32m[0906 17-48-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03385, current rewards: 228.25418, mean: 0.09471
[32m[0906 17-48-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03385, current rewards: 233.83726, mean: 0.09506
[32m[0906 17-48-40 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-48-40 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-48-40 @MBExp.py:227][0m Rewards obtained: [238.30135437897354], Lows: [3], Highs: [39], Total time: 7365.610368
[32m[0906 17-51-35 @MBExp.py:144][0m ####################################################################
[32m[0906 17-51-35 @MBExp.py:145][0m Starting training iteration 86.
[32m[0906 17-51-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03356, current rewards: -0.99404, mean: -0.09940
[32m[0906 17-51-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03406, current rewards: 4.54481, mean: 0.07575
[32m[0906 17-51-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03430, current rewards: 10.08231, mean: 0.09166
[32m[0906 17-51-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03436, current rewards: 15.62078, mean: 0.09763
[32m[0906 17-51-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03442, current rewards: 21.15867, mean: 0.10076
[32m[0906 17-51-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03445, current rewards: 26.45905, mean: 0.10177
[32m[0906 17-51-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03446, current rewards: 31.97133, mean: 0.10313
[32m[0906 17-51-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03448, current rewards: 37.48271, mean: 0.10412
[32m[0906 17-51-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03448, current rewards: 42.99752, mean: 0.10487
[32m[0906 17-51-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03448, current rewards: 48.50864, mean: 0.10545
[32m[0906 17-51-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03447, current rewards: 54.02627, mean: 0.10593
[32m[0906 17-51-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03447, current rewards: 58.41086, mean: 0.10431
[32m[0906 17-51-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03447, current rewards: 64.03634, mean: 0.10498
[32m[0906 17-51-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03447, current rewards: 69.73320, mean: 0.10566
[32m[0906 17-52-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03447, current rewards: 75.38180, mean: 0.10617
[32m[0906 17-52-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03444, current rewards: 81.02931, mean: 0.10662
[32m[0906 17-52-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03445, current rewards: 86.67984, mean: 0.10701
[32m[0906 17-52-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03446, current rewards: 91.34001, mean: 0.10621
[32m[0906 17-52-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03446, current rewards: 96.98607, mean: 0.10658
[32m[0906 17-52-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03446, current rewards: 102.62333, mean: 0.10690
[32m[0906 17-52-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03447, current rewards: 108.26496, mean: 0.10719
[32m[0906 17-52-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03444, current rewards: 114.02265, mean: 0.10757
[32m[0906 17-52-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03440, current rewards: 118.29348, mean: 0.10657
[32m[0906 17-52-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03439, current rewards: 124.07379, mean: 0.10696
[32m[0906 17-52-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03437, current rewards: 129.85139, mean: 0.10732
[32m[0906 17-52-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03435, current rewards: 135.63398, mean: 0.10765
[32m[0906 17-52-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03432, current rewards: 141.41230, mean: 0.10795
[32m[0906 17-52-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03430, current rewards: 146.08924, mean: 0.10742
[32m[0906 17-52-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03467, current rewards: 150.80285, mean: 0.10695
[32m[0906 17-52-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03499, current rewards: 155.43116, mean: 0.10646
[32m[0906 17-52-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03521, current rewards: 160.06591, mean: 0.10600
[32m[0906 17-52-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03543, current rewards: 164.96030, mean: 0.10574
[32m[0906 17-52-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03561, current rewards: 169.76048, mean: 0.10544
[32m[0906 17-52-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03578, current rewards: 174.55922, mean: 0.10516
[32m[0906 17-52-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03592, current rewards: 179.32590, mean: 0.10487
[32m[0906 17-52-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03610, current rewards: 184.10624, mean: 0.10461
[32m[0906 17-52-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03624, current rewards: 188.97758, mean: 0.10441
[32m[0906 17-52-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03642, current rewards: 193.81070, mean: 0.10420
[32m[0906 17-52-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03656, current rewards: 198.83930, mean: 0.10410
[32m[0906 17-52-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03669, current rewards: 203.52860, mean: 0.10384
[32m[0906 17-52-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03680, current rewards: 208.10631, mean: 0.10354
[32m[0906 17-52-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03679, current rewards: 213.45126, mean: 0.10362
[32m[0906 17-52-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03671, current rewards: 218.83519, mean: 0.10371
[32m[0906 17-52-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03663, current rewards: 224.22096, mean: 0.10381
[32m[0906 17-52-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03657, current rewards: 229.60420, mean: 0.10389
[32m[0906 17-52-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03650, current rewards: 234.98778, mean: 0.10398
[32m[0906 17-53-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03644, current rewards: 240.36785, mean: 0.10406
[32m[0906 17-53-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03638, current rewards: 243.47237, mean: 0.10317
[32m[0906 17-53-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03632, current rewards: 249.11897, mean: 0.10337
[32m[0906 17-53-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03626, current rewards: 254.73335, mean: 0.10355
[32m[0906 17-53-07 @Agent.py:117][0m Average action selection time: 0.0362
[32m[0906 17-53-07 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-53-07 @MBExp.py:227][0m Rewards obtained: [259.22705391075914], Lows: [3], Highs: [3], Total time: 7456.91291
[32m[0906 17-56-04 @MBExp.py:144][0m ####################################################################
[32m[0906 17-56-04 @MBExp.py:145][0m Starting training iteration 87.
[32m[0906 17-56-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03353, current rewards: -1.00651, mean: -0.10065
[32m[0906 17-56-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03428, current rewards: 4.40753, mean: 0.07346
[32m[0906 17-56-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03434, current rewards: 9.96847, mean: 0.09062
[32m[0906 17-56-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03450, current rewards: 15.52420, mean: 0.09703
[32m[0906 17-56-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03448, current rewards: 21.09125, mean: 0.10043
[32m[0906 17-56-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03453, current rewards: 26.65520, mean: 0.10252
[32m[0906 17-56-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03454, current rewards: 32.38263, mean: 0.10446
[32m[0906 17-56-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03455, current rewards: 37.93287, mean: 0.10537
[32m[0906 17-56-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03456, current rewards: 43.47712, mean: 0.10604
[32m[0906 17-56-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03456, current rewards: 49.02539, mean: 0.10658
[32m[0906 17-56-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03456, current rewards: 55.38909, mean: 0.10861
[32m[0906 17-56-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03456, current rewards: 60.92670, mean: 0.10880
[32m[0906 17-56-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03452, current rewards: 66.45791, mean: 0.10895
[32m[0906 17-56-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03453, current rewards: 71.99242, mean: 0.10908
[32m[0906 17-56-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03453, current rewards: 77.63192, mean: 0.10934
[32m[0906 17-56-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03452, current rewards: 83.13147, mean: 0.10938
[32m[0906 17-56-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03452, current rewards: 88.62725, mean: 0.10942
[32m[0906 17-56-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03453, current rewards: 94.12327, mean: 0.10945
[32m[0906 17-56-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03448, current rewards: 96.83041, mean: 0.10641
[32m[0906 17-56-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03443, current rewards: 105.88384, mean: 0.11030
[32m[0906 17-56-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03439, current rewards: 114.93727, mean: 0.11380
[32m[0906 17-56-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03436, current rewards: 123.99071, mean: 0.11697
[32m[0906 17-56-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03433, current rewards: 132.79038, mean: 0.11963
[32m[0906 17-56-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03430, current rewards: 136.44442, mean: 0.11762
[32m[0906 17-56-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03427, current rewards: 139.92376, mean: 0.11564
[32m[0906 17-56-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03425, current rewards: 143.40309, mean: 0.11381
[32m[0906 17-56-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03423, current rewards: 146.88242, mean: 0.11212
[32m[0906 17-56-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03418, current rewards: 150.36176, mean: 0.11056
[32m[0906 17-56-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03413, current rewards: 117.47514, mean: 0.08332
[32m[0906 17-56-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03408, current rewards: 67.47514, mean: 0.04622
[32m[0906 17-56-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03404, current rewards: 17.47514, mean: 0.01157
[32m[0906 17-56-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03399, current rewards: -32.52486, mean: -0.02085
[32m[0906 17-56-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03394, current rewards: -82.52486, mean: -0.05126
[32m[0906 17-57-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03390, current rewards: -132.52486, mean: -0.07983
[32m[0906 17-57-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03389, current rewards: -182.52486, mean: -0.10674
[32m[0906 17-57-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03389, current rewards: -232.52486, mean: -0.13212
[32m[0906 17-57-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03388, current rewards: -282.52486, mean: -0.15609
[32m[0906 17-57-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03387, current rewards: -332.52486, mean: -0.17878
[32m[0906 17-57-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03386, current rewards: -382.52486, mean: -0.20027
[32m[0906 17-57-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03384, current rewards: -432.52486, mean: -0.22068
[32m[0906 17-57-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03384, current rewards: -482.52486, mean: -0.24006
[32m[0906 17-57-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03383, current rewards: -532.52486, mean: -0.25851
[32m[0906 17-57-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03383, current rewards: -582.52486, mean: -0.27608
[32m[0906 17-57-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03382, current rewards: -632.52486, mean: -0.29284
[32m[0906 17-57-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03382, current rewards: -682.52486, mean: -0.30883
[32m[0906 17-57-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03382, current rewards: -732.52486, mean: -0.32413
[32m[0906 17-57-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03382, current rewards: -782.52486, mean: -0.33876
[32m[0906 17-57-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03382, current rewards: -832.52486, mean: -0.35276
[32m[0906 17-57-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03381, current rewards: -882.52486, mean: -0.36619
[32m[0906 17-57-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03381, current rewards: -904.45602, mean: -0.36767
[32m[0906 17-57-29 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 17-57-29 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-57-29 @MBExp.py:227][0m Rewards obtained: [-901.2732020415024], Lows: [2], Highs: [1060], Total time: 7542.189587
[32m[0906 18-00-28 @MBExp.py:144][0m ####################################################################
[32m[0906 18-00-28 @MBExp.py:145][0m Starting training iteration 88.
[32m[0906 18-00-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03431, current rewards: -5.35024, mean: -0.53502
[32m[0906 18-00-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03446, current rewards: 0.11986, mean: 0.00200
[32m[0906 18-00-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03449, current rewards: 5.59297, mean: 0.05085
[32m[0906 18-00-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03441, current rewards: 11.06583, mean: 0.06916
[32m[0906 18-00-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03443, current rewards: 16.53965, mean: 0.07876
[32m[0906 18-00-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03444, current rewards: 22.01289, mean: 0.08466
[32m[0906 18-00-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03445, current rewards: 27.48583, mean: 0.08866
[32m[0906 18-00-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03445, current rewards: 32.96276, mean: 0.09156
[32m[0906 18-00-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03446, current rewards: 38.43793, mean: 0.09375
[32m[0906 18-00-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03450, current rewards: 43.91174, mean: 0.09546
[32m[0906 18-00-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03453, current rewards: 49.38946, mean: 0.09684
[32m[0906 18-00-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03450, current rewards: 54.86815, mean: 0.09798
[32m[0906 18-00-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03450, current rewards: 60.34237, mean: 0.09892
[32m[0906 18-00-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03449, current rewards: 66.01984, mean: 0.10003
[32m[0906 18-00-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03450, current rewards: 71.68322, mean: 0.10096
[32m[0906 18-00-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03450, current rewards: 73.05834, mean: 0.09613
[32m[0906 18-00-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03450, current rewards: 78.65363, mean: 0.09710
[32m[0906 18-00-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03450, current rewards: 84.24977, mean: 0.09796
[32m[0906 18-01-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03444, current rewards: 89.84843, mean: 0.09873
[32m[0906 18-01-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03439, current rewards: 95.44959, mean: 0.09943
[32m[0906 18-01-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03435, current rewards: 101.04869, mean: 0.10005
[32m[0906 18-01-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03432, current rewards: 106.65272, mean: 0.10062
[32m[0906 18-01-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03429, current rewards: 112.28099, mean: 0.10115
[32m[0906 18-01-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03427, current rewards: 117.87992, mean: 0.10162
[32m[0906 18-01-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03424, current rewards: 122.55763, mean: 0.10129
[32m[0906 18-01-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03423, current rewards: 128.42374, mean: 0.10192
[32m[0906 18-01-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03421, current rewards: 134.31553, mean: 0.10253
[32m[0906 18-01-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03419, current rewards: 140.17543, mean: 0.10307
[32m[0906 18-01-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03417, current rewards: 146.05173, mean: 0.10358
[32m[0906 18-01-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03412, current rewards: 151.91311, mean: 0.10405
[32m[0906 18-01-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03408, current rewards: 157.59237, mean: 0.10437
[32m[0906 18-01-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03404, current rewards: 163.40640, mean: 0.10475
[32m[0906 18-01-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03400, current rewards: 164.67537, mean: 0.10228
[32m[0906 18-01-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03396, current rewards: 170.09787, mean: 0.10247
[32m[0906 18-01-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03396, current rewards: 175.52184, mean: 0.10264
[32m[0906 18-01-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03395, current rewards: 180.94314, mean: 0.10281
[32m[0906 18-01-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03395, current rewards: 186.36725, mean: 0.10297
[32m[0906 18-01-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03394, current rewards: 191.79138, mean: 0.10311
[32m[0906 18-01-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03393, current rewards: 197.32305, mean: 0.10331
[32m[0906 18-01-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03392, current rewards: 202.90443, mean: 0.10352
[32m[0906 18-01-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03391, current rewards: 208.41892, mean: 0.10369
[32m[0906 18-01-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03390, current rewards: 213.93324, mean: 0.10385
[32m[0906 18-01-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03389, current rewards: 219.44531, mean: 0.10400
[32m[0906 18-01-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03389, current rewards: 224.95837, mean: 0.10415
[32m[0906 18-01-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03388, current rewards: 228.63330, mean: 0.10345
[32m[0906 18-01-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03387, current rewards: 234.12976, mean: 0.10360
[32m[0906 18-01-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03387, current rewards: 239.63218, mean: 0.10374
[32m[0906 18-01-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03386, current rewards: 245.18389, mean: 0.10389
[32m[0906 18-01-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03386, current rewards: 250.68267, mean: 0.10402
[32m[0906 18-01-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03385, current rewards: 256.18292, mean: 0.10414
[32m[0906 18-01-53 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 18-01-53 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-01-53 @MBExp.py:227][0m Rewards obtained: [260.5843261882168], Lows: [6], Highs: [5], Total time: 7627.560617
[32m[0906 18-04-54 @MBExp.py:144][0m ####################################################################
[32m[0906 18-04-54 @MBExp.py:145][0m Starting training iteration 89.
[32m[0906 18-04-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03606, current rewards: -5.10545, mean: -0.51054
[32m[0906 18-04-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03495, current rewards: 0.54857, mean: 0.00914
[32m[0906 18-04-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03476, current rewards: 6.13111, mean: 0.05574
[32m[0906 18-05-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03474, current rewards: 11.71140, mean: 0.07320
[32m[0906 18-05-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03473, current rewards: 17.28733, mean: 0.08232
[32m[0906 18-05-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03467, current rewards: 20.03016, mean: 0.07704
[32m[0906 18-05-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03465, current rewards: 27.49036, mean: 0.08868
[32m[0906 18-05-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03465, current rewards: 34.95056, mean: 0.09708
[32m[0906 18-05-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03468, current rewards: 42.41076, mean: 0.10344
[32m[0906 18-05-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03467, current rewards: 49.87095, mean: 0.10842
[32m[0906 18-05-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03464, current rewards: 57.33114, mean: 0.11241
[32m[0906 18-05-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03461, current rewards: 64.79134, mean: 0.11570
[32m[0906 18-05-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03458, current rewards: 72.25154, mean: 0.11845
[32m[0906 18-05-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03459, current rewards: 78.72322, mean: 0.11928
[32m[0906 18-05-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03459, current rewards: 43.05951, mean: 0.06065
[32m[0906 18-05-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03462, current rewards: 48.72230, mean: 0.06411
[32m[0906 18-05-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03462, current rewards: 54.38150, mean: 0.06714
[32m[0906 18-05-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03457, current rewards: 60.03701, mean: 0.06981
[32m[0906 18-05-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03451, current rewards: 65.69644, mean: 0.07219
[32m[0906 18-05-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03447, current rewards: 71.35152, mean: 0.07432
[32m[0906 18-05-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03443, current rewards: 77.00610, mean: 0.07624
[32m[0906 18-05-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03440, current rewards: 82.66409, mean: 0.07798
[32m[0906 18-05-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03440, current rewards: 86.29615, mean: 0.07774
[32m[0906 18-05-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03438, current rewards: 89.94671, mean: 0.07754
[32m[0906 18-05-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03436, current rewards: 95.65857, mean: 0.07906
[32m[0906 18-05-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03434, current rewards: 101.37053, mean: 0.08045
[32m[0906 18-05-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03431, current rewards: 107.07960, mean: 0.08174
[32m[0906 18-05-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03429, current rewards: 112.79769, mean: 0.08294
[32m[0906 18-05-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03427, current rewards: 118.51086, mean: 0.08405
[32m[0906 18-05-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03425, current rewards: 124.22411, mean: 0.08509
[32m[0906 18-05-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03419, current rewards: 130.02541, mean: 0.08611
[32m[0906 18-05-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03414, current rewards: 135.75162, mean: 0.08702
[32m[0906 18-05-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03409, current rewards: 141.47999, mean: 0.08788
[32m[0906 18-05-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03406, current rewards: 147.21084, mean: 0.08868
[32m[0906 18-05-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03404, current rewards: 151.02792, mean: 0.08832
[32m[0906 18-05-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03403, current rewards: 156.95740, mean: 0.08918
[32m[0906 18-05-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03401, current rewards: 162.89131, mean: 0.09000
[32m[0906 18-05-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03400, current rewards: 168.82522, mean: 0.09077
[32m[0906 18-05-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03399, current rewards: 173.69060, mean: 0.09094
[32m[0906 18-06-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03398, current rewards: 179.38241, mean: 0.09152
[32m[0906 18-06-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03398, current rewards: 185.07648, mean: 0.09208
[32m[0906 18-06-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03397, current rewards: 190.76958, mean: 0.09261
[32m[0906 18-06-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03395, current rewards: 196.46125, mean: 0.09311
[32m[0906 18-06-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03395, current rewards: 202.15383, mean: 0.09359
[32m[0906 18-06-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03395, current rewards: 207.84205, mean: 0.09405
[32m[0906 18-06-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03394, current rewards: 213.53527, mean: 0.09448
[32m[0906 18-06-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03393, current rewards: 219.08235, mean: 0.09484
[32m[0906 18-06-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03393, current rewards: 224.68484, mean: 0.09521
[32m[0906 18-06-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03392, current rewards: 230.30843, mean: 0.09556
[32m[0906 18-06-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03392, current rewards: 235.93353, mean: 0.09591
[32m[0906 18-06-19 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 18-06-19 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-06-20 @MBExp.py:227][0m Rewards obtained: [240.4334917087108], Lows: [9], Highs: [36], Total time: 7713.104528
[32m[0906 18-09-22 @MBExp.py:144][0m ####################################################################
[32m[0906 18-09-22 @MBExp.py:145][0m Starting training iteration 90.
[32m[0906 18-09-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03450, current rewards: -5.35698, mean: -0.53570
[32m[0906 18-09-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03447, current rewards: 0.16055, mean: 0.00268
[32m[0906 18-09-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03455, current rewards: 5.67858, mean: 0.05162
[32m[0906 18-09-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03451, current rewards: 11.20145, mean: 0.07001
[32m[0906 18-09-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03450, current rewards: 16.71670, mean: 0.07960
[32m[0906 18-09-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03449, current rewards: 22.31928, mean: 0.08584
[32m[0906 18-09-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03451, current rewards: 27.83041, mean: 0.08978
[32m[0906 18-09-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03449, current rewards: 31.71325, mean: 0.08809
[32m[0906 18-09-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03448, current rewards: 38.27064, mean: 0.09334
[32m[0906 18-09-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03449, current rewards: 44.82012, mean: 0.09744
[32m[0906 18-09-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03448, current rewards: 51.37610, mean: 0.10074
[32m[0906 18-09-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03447, current rewards: 57.93818, mean: 0.10346
[32m[0906 18-09-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03446, current rewards: 64.48460, mean: 0.10571
[32m[0906 18-09-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03445, current rewards: 70.97109, mean: 0.10753
[32m[0906 18-09-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03446, current rewards: 77.52454, mean: 0.10919
[32m[0906 18-09-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03448, current rewards: 84.07097, mean: 0.11062
[32m[0906 18-09-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03448, current rewards: 90.61949, mean: 0.11188
[32m[0906 18-09-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03444, current rewards: 97.17010, mean: 0.11299
[32m[0906 18-09-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03440, current rewards: 103.71746, mean: 0.11398
[32m[0906 18-09-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03437, current rewards: 110.26612, mean: 0.11486
[32m[0906 18-09-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03433, current rewards: 116.81287, mean: 0.11566
[32m[0906 18-09-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03430, current rewards: 119.74000, mean: 0.11296
[32m[0906 18-10-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03427, current rewards: 125.40495, mean: 0.11298
[32m[0906 18-10-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03424, current rewards: 131.06789, mean: 0.11299
[32m[0906 18-10-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03422, current rewards: 136.72734, mean: 0.11300
[32m[0906 18-10-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03420, current rewards: 142.38847, mean: 0.11301
[32m[0906 18-10-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03418, current rewards: 148.05302, mean: 0.11302
[32m[0906 18-10-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03417, current rewards: 153.71328, mean: 0.11302
[32m[0906 18-10-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03415, current rewards: 159.37153, mean: 0.11303
[32m[0906 18-10-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03414, current rewards: 165.11665, mean: 0.11309
[32m[0906 18-10-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03412, current rewards: 169.89726, mean: 0.11251
[32m[0906 18-10-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03410, current rewards: 174.47148, mean: 0.11184
[32m[0906 18-10-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03406, current rewards: 179.04569, mean: 0.11121
[32m[0906 18-10-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03402, current rewards: 183.61384, mean: 0.11061
[32m[0906 18-10-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03398, current rewards: 188.18914, mean: 0.11005
[32m[0906 18-10-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03399, current rewards: 188.71243, mean: 0.10722
[32m[0906 18-10-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03398, current rewards: 194.23232, mean: 0.10731
[32m[0906 18-10-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03397, current rewards: 199.72063, mean: 0.10738
[32m[0906 18-10-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03396, current rewards: 205.25323, mean: 0.10746
[32m[0906 18-10-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03394, current rewards: 210.78411, mean: 0.10754
[32m[0906 18-10-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03393, current rewards: 216.31365, mean: 0.10762
[32m[0906 18-10-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03393, current rewards: 219.29364, mean: 0.10645
[32m[0906 18-10-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03392, current rewards: 226.34230, mean: 0.10727
[32m[0906 18-10-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03391, current rewards: 233.37445, mean: 0.10804
[32m[0906 18-10-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03391, current rewards: 240.40550, mean: 0.10878
[32m[0906 18-10-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03391, current rewards: 247.57337, mean: 0.10955
[32m[0906 18-10-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03390, current rewards: 254.64015, mean: 0.11023
[32m[0906 18-10-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03390, current rewards: 261.44132, mean: 0.11078
[32m[0906 18-10-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03389, current rewards: 268.24669, mean: 0.11131
[32m[0906 18-10-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03389, current rewards: 275.04698, mean: 0.11181
[32m[0906 18-10-48 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 18-10-48 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-10-48 @MBExp.py:227][0m Rewards obtained: [280.497368689599], Lows: [7], Highs: [4], Total time: 7798.584258
[32m[0906 18-13-52 @MBExp.py:144][0m ####################################################################
[32m[0906 18-13-52 @MBExp.py:145][0m Starting training iteration 91.
[32m[0906 18-13-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03398, current rewards: -0.04683, mean: -0.00468
[32m[0906 18-13-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03425, current rewards: 5.25533, mean: 0.08759
[32m[0906 18-13-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03427, current rewards: 10.55532, mean: 0.09596
[32m[0906 18-13-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03437, current rewards: 15.85864, mean: 0.09912
[32m[0906 18-14-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03435, current rewards: 21.13256, mean: 0.10063
[32m[0906 18-14-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03436, current rewards: 26.44571, mean: 0.10171
[32m[0906 18-14-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03437, current rewards: 31.75611, mean: 0.10244
[32m[0906 18-14-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03436, current rewards: 37.06723, mean: 0.10296
[32m[0906 18-14-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03436, current rewards: 42.37546, mean: 0.10335
[32m[0906 18-14-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03436, current rewards: 47.68386, mean: 0.10366
[32m[0906 18-14-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03436, current rewards: 52.99027, mean: 0.10390
[32m[0906 18-14-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03436, current rewards: 58.29372, mean: 0.10410
[32m[0906 18-14-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03433, current rewards: 63.84348, mean: 0.10466
[32m[0906 18-14-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03433, current rewards: 68.91461, mean: 0.10442
[32m[0906 18-14-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03434, current rewards: 74.43300, mean: 0.10484
[32m[0906 18-14-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03434, current rewards: 79.95360, mean: 0.10520
[32m[0906 18-14-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03435, current rewards: 85.46626, mean: 0.10551
[32m[0906 18-14-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03430, current rewards: 90.98726, mean: 0.10580
[32m[0906 18-14-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03426, current rewards: 96.50223, mean: 0.10605
[32m[0906 18-14-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03424, current rewards: 102.02630, mean: 0.10628
[32m[0906 18-14-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03422, current rewards: 107.49929, mean: 0.10643
[32m[0906 18-14-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03420, current rewards: 112.94164, mean: 0.10655
[32m[0906 18-14-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03416, current rewards: 114.29399, mean: 0.10297
[32m[0906 18-14-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03414, current rewards: 119.82709, mean: 0.10330
[32m[0906 18-14-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03411, current rewards: 125.35721, mean: 0.10360
[32m[0906 18-14-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03409, current rewards: 130.89044, mean: 0.10388
[32m[0906 18-14-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03407, current rewards: 136.42404, mean: 0.10414
[32m[0906 18-14-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03405, current rewards: 141.95388, mean: 0.10438
[32m[0906 18-14-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03403, current rewards: 147.48727, mean: 0.10460
[32m[0906 18-14-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03402, current rewards: 152.89168, mean: 0.10472
[32m[0906 18-14-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03401, current rewards: 158.42832, mean: 0.10492
[32m[0906 18-14-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03399, current rewards: 163.96566, mean: 0.10511
[32m[0906 18-14-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03396, current rewards: 169.50742, mean: 0.10528
[32m[0906 18-14-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03392, current rewards: 175.04635, mean: 0.10545
[32m[0906 18-14-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03387, current rewards: 180.58409, mean: 0.10560
[32m[0906 18-14-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03386, current rewards: 186.12115, mean: 0.10575
[32m[0906 18-14-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03386, current rewards: 191.65864, mean: 0.10589
[32m[0906 18-14-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03385, current rewards: 194.05194, mean: 0.10433
[32m[0906 18-14-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03384, current rewards: 199.75444, mean: 0.10458
[32m[0906 18-14-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03383, current rewards: 205.46249, mean: 0.10483
[32m[0906 18-15-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03382, current rewards: 211.16695, mean: 0.10506
[32m[0906 18-15-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03380, current rewards: 216.87867, mean: 0.10528
[32m[0906 18-15-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03380, current rewards: 222.58552, mean: 0.10549
[32m[0906 18-15-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03380, current rewards: 228.28968, mean: 0.10569
[32m[0906 18-15-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03380, current rewards: 233.99658, mean: 0.10588
[32m[0906 18-15-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03380, current rewards: 239.69953, mean: 0.10606
[32m[0906 18-15-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03379, current rewards: 245.40685, mean: 0.10624
[32m[0906 18-15-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03379, current rewards: 251.11522, mean: 0.10640
[32m[0906 18-15-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03378, current rewards: 252.56163, mean: 0.10480
[32m[0906 18-15-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03378, current rewards: 258.09520, mean: 0.10492
[32m[0906 18-15-17 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 18-15-17 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-15-18 @MBExp.py:227][0m Rewards obtained: [262.5184975347055], Lows: [5], Highs: [3], Total time: 7883.8013009999995
[32m[0906 18-18-24 @MBExp.py:144][0m ####################################################################
[32m[0906 18-18-24 @MBExp.py:145][0m Starting training iteration 92.
[32m[0906 18-18-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03370, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-18-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03437, current rewards: -60.00000, mean: -1.00000
[32m[0906 18-18-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03433, current rewards: -110.00000, mean: -1.00000
[32m[0906 18-18-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03439, current rewards: -160.00000, mean: -1.00000
[32m[0906 18-18-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03439, current rewards: -210.00000, mean: -1.00000
[32m[0906 18-18-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03439, current rewards: -260.00000, mean: -1.00000
[32m[0906 18-18-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03441, current rewards: -310.00000, mean: -1.00000
[32m[0906 18-18-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03443, current rewards: -360.00000, mean: -1.00000
[32m[0906 18-18-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03443, current rewards: -410.00000, mean: -1.00000
[32m[0906 18-18-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03445, current rewards: -460.00000, mean: -1.00000
[32m[0906 18-18-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03445, current rewards: -510.00000, mean: -1.00000
[32m[0906 18-18-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03442, current rewards: -525.56317, mean: -0.93851
[32m[0906 18-18-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03439, current rewards: -559.59087, mean: -0.91736
[32m[0906 18-18-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03441, current rewards: -609.59087, mean: -0.92362
[32m[0906 18-18-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03442, current rewards: -659.59087, mean: -0.92900
[32m[0906 18-18-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03443, current rewards: -709.59087, mean: -0.93367
[32m[0906 18-18-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03443, current rewards: -759.59087, mean: -0.93777
[32m[0906 18-18-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03438, current rewards: -809.59087, mean: -0.94138
[32m[0906 18-18-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03434, current rewards: -859.59087, mean: -0.94461
[32m[0906 18-18-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03431, current rewards: -909.59087, mean: -0.94749
[32m[0906 18-18-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03426, current rewards: -959.59087, mean: -0.95009
[32m[0906 18-19-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03423, current rewards: -1009.59087, mean: -0.95244
[32m[0906 18-19-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03421, current rewards: -1059.59087, mean: -0.95459
[32m[0906 18-19-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03418, current rewards: -1109.59087, mean: -0.95654
[32m[0906 18-19-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03415, current rewards: -1159.59087, mean: -0.95834
[32m[0906 18-19-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03414, current rewards: -1209.59087, mean: -0.95999
[32m[0906 18-19-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03410, current rewards: -1259.59087, mean: -0.96152
[32m[0906 18-19-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03408, current rewards: -1309.59087, mean: -0.96293
[32m[0906 18-19-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03407, current rewards: -1359.59087, mean: -0.96425
[32m[0906 18-19-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03405, current rewards: -1409.59087, mean: -0.96547
[32m[0906 18-19-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03403, current rewards: -1459.59087, mean: -0.96662
[32m[0906 18-19-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03402, current rewards: -1509.59087, mean: -0.96769
[32m[0906 18-19-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03397, current rewards: -1559.59087, mean: -0.96869
[32m[0906 18-19-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03393, current rewards: -1609.59087, mean: -0.96963
[32m[0906 18-19-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03388, current rewards: -1659.59087, mean: -0.97052
[32m[0906 18-19-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03386, current rewards: -1709.59087, mean: -0.97136
[32m[0906 18-19-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03386, current rewards: -1759.59087, mean: -0.97215
[32m[0906 18-19-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03385, current rewards: -1809.59087, mean: -0.97290
[32m[0906 18-19-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03384, current rewards: -1859.59087, mean: -0.97361
[32m[0906 18-19-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03383, current rewards: -1909.59087, mean: -0.97428
[32m[0906 18-19-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03382, current rewards: -1959.59087, mean: -0.97492
[32m[0906 18-19-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03382, current rewards: -2009.59087, mean: -0.97553
[32m[0906 18-19-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03382, current rewards: -2059.59087, mean: -0.97611
[32m[0906 18-19-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03382, current rewards: -2109.59087, mean: -0.97666
[32m[0906 18-19-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03382, current rewards: -2159.59087, mean: -0.97719
[32m[0906 18-19-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03381, current rewards: -2209.59087, mean: -0.97770
[32m[0906 18-19-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03380, current rewards: -2259.59087, mean: -0.97818
[32m[0906 18-19-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03379, current rewards: -2309.59087, mean: -0.97864
[32m[0906 18-19-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03379, current rewards: -2359.59087, mean: -0.97908
[32m[0906 18-19-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03379, current rewards: -2409.59087, mean: -0.97951
[32m[0906 18-19-49 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 18-19-49 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-19-50 @MBExp.py:227][0m Rewards obtained: [-2449.590868600489], Lows: [0], Highs: [2455], Total time: 7969.038946
[32m[0906 18-22-58 @MBExp.py:144][0m ####################################################################
[32m[0906 18-22-58 @MBExp.py:145][0m Starting training iteration 93.
[32m[0906 18-22-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03302, current rewards: -1.96048, mean: -0.19605
[32m[0906 18-23-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03408, current rewards: 5.10041, mean: 0.08501
[32m[0906 18-23-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03421, current rewards: 12.15026, mean: 0.11046
[32m[0906 18-23-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03430, current rewards: 18.71985, mean: 0.11700
[32m[0906 18-23-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03445, current rewards: 25.43778, mean: 0.12113
[32m[0906 18-23-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03447, current rewards: 32.13871, mean: 0.12361
[32m[0906 18-23-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03444, current rewards: 38.77466, mean: 0.12508
[32m[0906 18-23-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03445, current rewards: 15.74719, mean: 0.04374
[32m[0906 18-23-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03446, current rewards: 21.15944, mean: 0.05161
[32m[0906 18-23-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03446, current rewards: 26.57827, mean: 0.05778
[32m[0906 18-23-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03447, current rewards: 31.99926, mean: 0.06274
[32m[0906 18-23-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03445, current rewards: 37.53574, mean: 0.06703
[32m[0906 18-23-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03446, current rewards: 42.82834, mean: 0.07021
[32m[0906 18-23-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03447, current rewards: 48.12045, mean: 0.07291
[32m[0906 18-23-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03447, current rewards: 53.40997, mean: 0.07523
[32m[0906 18-23-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03446, current rewards: 58.70173, mean: 0.07724
[32m[0906 18-23-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03448, current rewards: 63.99534, mean: 0.07901
[32m[0906 18-23-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03441, current rewards: 69.28729, mean: 0.08057
[32m[0906 18-23-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03437, current rewards: 74.58127, mean: 0.08196
[32m[0906 18-23-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03434, current rewards: 79.86011, mean: 0.08319
[32m[0906 18-23-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03430, current rewards: 85.17000, mean: 0.08433
[32m[0906 18-23-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03427, current rewards: 88.49342, mean: 0.08348
[32m[0906 18-23-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03423, current rewards: 94.03871, mean: 0.08472
[32m[0906 18-23-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03421, current rewards: 99.57530, mean: 0.08584
[32m[0906 18-23-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03419, current rewards: 105.11430, mean: 0.08687
[32m[0906 18-23-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03417, current rewards: 110.65263, mean: 0.08782
[32m[0906 18-23-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03415, current rewards: 116.18827, mean: 0.08869
[32m[0906 18-23-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03414, current rewards: 121.72920, mean: 0.08951
[32m[0906 18-23-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03412, current rewards: 127.30147, mean: 0.09028
[32m[0906 18-23-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03409, current rewards: 132.85317, mean: 0.09100
[32m[0906 18-23-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03407, current rewards: 138.40003, mean: 0.09166
[32m[0906 18-23-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03406, current rewards: 143.95096, mean: 0.09228
[32m[0906 18-23-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03402, current rewards: 145.46105, mean: 0.09035
[32m[0906 18-23-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03399, current rewards: 151.12224, mean: 0.09104
[32m[0906 18-23-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03395, current rewards: 156.78637, mean: 0.09169
[32m[0906 18-23-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03392, current rewards: 162.45295, mean: 0.09230
[32m[0906 18-23-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03389, current rewards: 169.14497, mean: 0.09345
[32m[0906 18-24-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03386, current rewards: 120.28350, mean: 0.06467
[32m[0906 18-24-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03385, current rewards: 70.28350, mean: 0.03680
[32m[0906 18-24-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03384, current rewards: 20.28350, mean: 0.01035
[32m[0906 18-24-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03383, current rewards: -29.71650, mean: -0.01478
[32m[0906 18-24-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03383, current rewards: -79.71650, mean: -0.03870
[32m[0906 18-24-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03382, current rewards: -129.71650, mean: -0.06148
[32m[0906 18-24-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03381, current rewards: -179.71650, mean: -0.08320
[32m[0906 18-24-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03381, current rewards: -229.71650, mean: -0.10394
[32m[0906 18-24-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03381, current rewards: -279.71650, mean: -0.12377
[32m[0906 18-24-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03380, current rewards: -329.71650, mean: -0.14273
[32m[0906 18-24-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03380, current rewards: -379.71650, mean: -0.16090
[32m[0906 18-24-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03380, current rewards: -429.71650, mean: -0.17831
[32m[0906 18-24-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03380, current rewards: -479.71650, mean: -0.19501
[32m[0906 18-24-23 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 18-24-23 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-24-23 @MBExp.py:227][0m Rewards obtained: [-519.7164977889787], Lows: [17], Highs: [691], Total time: 8054.293933999999
[32m[0906 18-27-34 @MBExp.py:144][0m ####################################################################
[32m[0906 18-27-34 @MBExp.py:145][0m Starting training iteration 94.
[32m[0906 18-27-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03591, current rewards: -12.70050, mean: -1.27005
[32m[0906 18-27-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03464, current rewards: -17.12003, mean: -0.28533
[32m[0906 18-27-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03450, current rewards: -11.33659, mean: -0.10306
[32m[0906 18-27-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03448, current rewards: -5.54144, mean: -0.03463
[32m[0906 18-27-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03444, current rewards: 0.25713, mean: 0.00122
[32m[0906 18-27-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03608, current rewards: -56.71473, mean: -0.21813
[32m[0906 18-27-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03751, current rewards: -120.11549, mean: -0.38747
[32m[0906 18-27-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03878, current rewards: -185.78267, mean: -0.51606
[32m[0906 18-27-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03830, current rewards: -178.90764, mean: -0.43636
[32m[0906 18-27-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03790, current rewards: -177.29300, mean: -0.38542
[32m[0906 18-27-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03753, current rewards: -171.63196, mean: -0.33653
[32m[0906 18-27-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03725, current rewards: -166.26114, mean: -0.29689
[32m[0906 18-27-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03699, current rewards: -160.71771, mean: -0.26347
[32m[0906 18-27-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03678, current rewards: -155.17340, mean: -0.23511
[32m[0906 18-28-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03661, current rewards: -149.63166, mean: -0.21075
[32m[0906 18-28-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03644, current rewards: -144.08761, mean: -0.18959
[32m[0906 18-28-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03623, current rewards: -138.54453, mean: -0.17104
[32m[0906 18-28-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03608, current rewards: -132.99992, mean: -0.15465
[32m[0906 18-28-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03593, current rewards: -127.45786, mean: -0.14006
[32m[0906 18-28-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03581, current rewards: -121.74987, mean: -0.12682
[32m[0906 18-28-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03569, current rewards: -117.29886, mean: -0.11614
[32m[0906 18-28-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03559, current rewards: -111.83651, mean: -0.10551
[32m[0906 18-28-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03550, current rewards: -106.37157, mean: -0.09583
[32m[0906 18-28-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03542, current rewards: -100.90399, mean: -0.08699
[32m[0906 18-28-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03534, current rewards: -95.43751, mean: -0.07887
[32m[0906 18-28-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03527, current rewards: -89.97233, mean: -0.07141
[32m[0906 18-28-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03520, current rewards: -84.50778, mean: -0.06451
[32m[0906 18-28-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03514, current rewards: -78.91841, mean: -0.05803
[32m[0906 18-28-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03508, current rewards: -73.43360, mean: -0.05208
[32m[0906 18-28-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03505, current rewards: -72.21124, mean: -0.04946
[32m[0906 18-28-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03498, current rewards: -66.77734, mean: -0.04422
[32m[0906 18-28-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03490, current rewards: -61.34976, mean: -0.03933
[32m[0906 18-28-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03483, current rewards: -55.91903, mean: -0.03473
[32m[0906 18-28-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03475, current rewards: -50.48785, mean: -0.03041
[32m[0906 18-28-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03469, current rewards: -45.05701, mean: -0.02635
[32m[0906 18-28-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03462, current rewards: -39.67818, mean: -0.02254
[32m[0906 18-28-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03479, current rewards: -31.24848, mean: -0.01726
[32m[0906 18-28-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03500, current rewards: -20.64759, mean: -0.01110
[32m[0906 18-28-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03516, current rewards: -9.99640, mean: -0.00523
[32m[0906 18-28-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03535, current rewards: 1.06202, mean: 0.00054
[32m[0906 18-28-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03535, current rewards: 5.29752, mean: 0.00264
[32m[0906 18-28-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03530, current rewards: 10.78380, mean: 0.00523
[32m[0906 18-28-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03526, current rewards: 16.27425, mean: 0.00771
[32m[0906 18-28-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03522, current rewards: 21.77019, mean: 0.01008
[32m[0906 18-28-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03518, current rewards: 27.47402, mean: 0.01243
[32m[0906 18-28-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03514, current rewards: 32.99788, mean: 0.01460
[32m[0906 18-28-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03511, current rewards: 38.51642, mean: 0.01667
[32m[0906 18-28-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03507, current rewards: 44.03782, mean: 0.01866
[32m[0906 18-28-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03504, current rewards: 49.55625, mean: 0.02056
[32m[0906 18-29-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03502, current rewards: 55.08054, mean: 0.02239
[32m[0906 18-29-02 @Agent.py:117][0m Average action selection time: 0.0350
[32m[0906 18-29-02 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-29-02 @MBExp.py:227][0m Rewards obtained: [59.49998578470012], Lows: [113], Highs: [3], Total time: 8142.549848999999
[32m[0906 18-32-14 @MBExp.py:144][0m ####################################################################
[32m[0906 18-32-14 @MBExp.py:145][0m Starting training iteration 95.
[32m[0906 18-32-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03439, current rewards: -14.85780, mean: -1.48578
[32m[0906 18-32-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03475, current rewards: -8.49799, mean: -0.14163
[32m[0906 18-32-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03457, current rewards: -2.23547, mean: -0.02032
[32m[0906 18-32-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03463, current rewards: 3.92230, mean: 0.02451
[32m[0906 18-32-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03461, current rewards: 10.02737, mean: 0.04775
[32m[0906 18-32-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03462, current rewards: 16.12207, mean: 0.06201
[32m[0906 18-32-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03455, current rewards: 22.21348, mean: 0.07166
[32m[0906 18-32-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03453, current rewards: 28.30523, mean: 0.07863
[32m[0906 18-32-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03451, current rewards: 34.40325, mean: 0.08391
[32m[0906 18-32-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03449, current rewards: 40.49559, mean: 0.08803
[32m[0906 18-32-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03446, current rewards: 46.58781, mean: 0.09135
[32m[0906 18-32-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03445, current rewards: 52.64338, mean: 0.09401
[32m[0906 18-32-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03445, current rewards: 58.84917, mean: 0.09647
[32m[0906 18-32-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03445, current rewards: 65.04499, mean: 0.09855
[32m[0906 18-32-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03438, current rewards: 71.25349, mean: 0.10036
[32m[0906 18-32-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03432, current rewards: 77.46025, mean: 0.10192
[32m[0906 18-32-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03429, current rewards: 82.00293, mean: 0.10124
[32m[0906 18-32-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03425, current rewards: 90.27815, mean: 0.10497
[32m[0906 18-32-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03421, current rewards: 98.69847, mean: 0.10846
[32m[0906 18-32-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03418, current rewards: 106.52952, mean: 0.11097
[32m[0906 18-32-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03416, current rewards: 112.63850, mean: 0.11152
[32m[0906 18-32-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03414, current rewards: 117.52499, mean: 0.11087
[32m[0906 18-32-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03411, current rewards: 126.61720, mean: 0.11407
[32m[0906 18-32-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03408, current rewards: 135.67370, mean: 0.11696
[32m[0906 18-32-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03406, current rewards: 144.74145, mean: 0.11962
[32m[0906 18-32-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03405, current rewards: 153.80863, mean: 0.12207
[32m[0906 18-32-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03403, current rewards: 162.89024, mean: 0.12434
[32m[0906 18-33-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03402, current rewards: 171.84613, mean: 0.12636
[32m[0906 18-33-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03401, current rewards: 180.66569, mean: 0.12813
[32m[0906 18-33-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03398, current rewards: 184.19662, mean: 0.12616
[32m[0906 18-33-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03392, current rewards: 190.25462, mean: 0.12600
[32m[0906 18-33-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03389, current rewards: 196.32385, mean: 0.12585
[32m[0906 18-33-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03385, current rewards: 202.37257, mean: 0.12570
[32m[0906 18-33-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03380, current rewards: 208.42499, mean: 0.12556
[32m[0906 18-33-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03377, current rewards: 214.49528, mean: 0.12544
[32m[0906 18-33-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03373, current rewards: 220.55988, mean: 0.12532
[32m[0906 18-33-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03372, current rewards: 227.00079, mean: 0.12541
[32m[0906 18-33-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03372, current rewards: 232.48094, mean: 0.12499
[32m[0906 18-33-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03371, current rewards: 239.56021, mean: 0.12542
[32m[0906 18-33-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03371, current rewards: 246.63890, mean: 0.12584
[32m[0906 18-33-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03370, current rewards: 253.72609, mean: 0.12623
[32m[0906 18-33-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03369, current rewards: 260.80110, mean: 0.12660
[32m[0906 18-33-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03369, current rewards: 267.88018, mean: 0.12696
[32m[0906 18-33-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03369, current rewards: 274.95578, mean: 0.12729
[32m[0906 18-33-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03368, current rewards: 282.17830, mean: 0.12768
[32m[0906 18-33-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03368, current rewards: 289.07782, mean: 0.12791
[32m[0906 18-33-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03368, current rewards: 285.39603, mean: 0.12355
[32m[0906 18-33-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03368, current rewards: 292.40525, mean: 0.12390
[32m[0906 18-33-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03367, current rewards: 299.33191, mean: 0.12420
[32m[0906 18-33-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03368, current rewards: 306.25857, mean: 0.12450
[32m[0906 18-33-39 @Agent.py:117][0m Average action selection time: 0.0337
[32m[0906 18-33-39 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-33-39 @MBExp.py:227][0m Rewards obtained: [311.7998949841198], Lows: [15], Highs: [4], Total time: 8227.513948999998
[32m[0906 18-36-54 @MBExp.py:144][0m ####################################################################
[32m[0906 18-36-54 @MBExp.py:145][0m Starting training iteration 96.
[32m[0906 18-36-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03346, current rewards: -12.68201, mean: -1.26820
[32m[0906 18-36-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03437, current rewards: -7.18716, mean: -0.11979
[32m[0906 18-36-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03436, current rewards: -1.68655, mean: -0.01533
[32m[0906 18-37-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03438, current rewards: 3.49464, mean: 0.02184
[32m[0906 18-37-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03439, current rewards: 9.00260, mean: 0.04287
[32m[0906 18-37-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03440, current rewards: 14.50018, mean: 0.05577
[32m[0906 18-37-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03440, current rewards: 19.99040, mean: 0.06449
[32m[0906 18-37-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03442, current rewards: 25.49954, mean: 0.07083
[32m[0906 18-37-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03442, current rewards: 30.99564, mean: 0.07560
[32m[0906 18-37-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03444, current rewards: 36.49782, mean: 0.07934
[32m[0906 18-37-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03442, current rewards: 42.00321, mean: 0.08236
[32m[0906 18-37-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03443, current rewards: 43.44032, mean: 0.07757
[32m[0906 18-37-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03443, current rewards: 49.08002, mean: 0.08046
[32m[0906 18-37-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03442, current rewards: 54.61056, mean: 0.08274
[32m[0906 18-37-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03437, current rewards: 60.14273, mean: 0.08471
[32m[0906 18-37-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03432, current rewards: 65.67969, mean: 0.08642
[32m[0906 18-37-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03428, current rewards: 71.20929, mean: 0.08791
[32m[0906 18-37-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03424, current rewards: 76.73969, mean: 0.08923
[32m[0906 18-37-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03420, current rewards: 82.27178, mean: 0.09041
[32m[0906 18-37-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03417, current rewards: 87.80455, mean: 0.09146
[32m[0906 18-37-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03415, current rewards: 93.25706, mean: 0.09233
[32m[0906 18-37-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03412, current rewards: 93.71047, mean: 0.08841
[32m[0906 18-37-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03410, current rewards: 99.36683, mean: 0.08952
[32m[0906 18-37-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03408, current rewards: 105.02391, mean: 0.09054
[32m[0906 18-37-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03405, current rewards: 110.68160, mean: 0.09147
[32m[0906 18-37-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03403, current rewards: 116.33227, mean: 0.09233
[32m[0906 18-37-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03402, current rewards: 121.98646, mean: 0.09312
[32m[0906 18-37-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03401, current rewards: 127.64457, mean: 0.09386
[32m[0906 18-37-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03400, current rewards: 133.35181, mean: 0.09458
[32m[0906 18-37-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03396, current rewards: 139.01976, mean: 0.09522
[32m[0906 18-37-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03391, current rewards: 144.67594, mean: 0.09581
[32m[0906 18-37-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03387, current rewards: 150.34066, mean: 0.09637
[32m[0906 18-37-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03383, current rewards: 156.00137, mean: 0.09690
[32m[0906 18-37-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03379, current rewards: 157.44286, mean: 0.09485
[32m[0906 18-37-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03376, current rewards: 163.07368, mean: 0.09536
[32m[0906 18-37-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03373, current rewards: 168.66848, mean: 0.09583
[32m[0906 18-37-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03373, current rewards: 174.15386, mean: 0.09622
[32m[0906 18-37-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03371, current rewards: 179.74993, mean: 0.09664
[32m[0906 18-37-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03371, current rewards: 185.33942, mean: 0.09704
[32m[0906 18-38-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03371, current rewards: 190.92895, mean: 0.09741
[32m[0906 18-38-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03371, current rewards: 196.52081, mean: 0.09777
[32m[0906 18-38-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03370, current rewards: 202.11053, mean: 0.09811
[32m[0906 18-38-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03370, current rewards: 207.70270, mean: 0.09844
[32m[0906 18-38-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03369, current rewards: 213.29153, mean: 0.09875
[32m[0906 18-38-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03369, current rewards: 218.04141, mean: 0.09866
[32m[0906 18-38-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03369, current rewards: 223.67346, mean: 0.09897
[32m[0906 18-38-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03369, current rewards: 229.22220, mean: 0.09923
[32m[0906 18-38-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03369, current rewards: 233.63050, mean: 0.09900
[32m[0906 18-38-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03369, current rewards: 239.39008, mean: 0.09933
[32m[0906 18-38-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03369, current rewards: 245.13547, mean: 0.09965
[32m[0906 18-38-19 @Agent.py:117][0m Average action selection time: 0.0337
[32m[0906 18-38-19 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-38-19 @MBExp.py:227][0m Rewards obtained: [249.7333620715606], Lows: [12], Highs: [4], Total time: 8312.508984999999
[32m[0906 18-41-35 @MBExp.py:144][0m ####################################################################
[32m[0906 18-41-35 @MBExp.py:145][0m Starting training iteration 97.
[32m[0906 18-41-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03620, current rewards: -2.25844, mean: -0.22584
[32m[0906 18-41-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03480, current rewards: 3.17478, mean: 0.05291
[32m[0906 18-41-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03481, current rewards: 8.78908, mean: 0.07990
[32m[0906 18-41-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03470, current rewards: 14.52976, mean: 0.09081
[32m[0906 18-41-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03466, current rewards: 20.16106, mean: 0.09601
[32m[0906 18-41-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03458, current rewards: 25.74763, mean: 0.09903
[32m[0906 18-41-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03457, current rewards: 25.99060, mean: 0.08384
[32m[0906 18-41-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03455, current rewards: 31.38692, mean: 0.08719
[32m[0906 18-41-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03454, current rewards: 36.78290, mean: 0.08971
[32m[0906 18-41-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03452, current rewards: 42.17983, mean: 0.09170
[32m[0906 18-41-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03450, current rewards: 47.57725, mean: 0.09329
[32m[0906 18-41-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03448, current rewards: 52.96859, mean: 0.09459
[32m[0906 18-41-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03445, current rewards: 58.77694, mean: 0.09636
[32m[0906 18-41-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03444, current rewards: 64.31222, mean: 0.09744
[32m[0906 18-42-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03436, current rewards: 69.85023, mean: 0.09838
[32m[0906 18-42-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03431, current rewards: 75.39049, mean: 0.09920
[32m[0906 18-42-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03426, current rewards: 80.93029, mean: 0.09991
[32m[0906 18-42-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03422, current rewards: 86.47176, mean: 0.10055
[32m[0906 18-42-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03419, current rewards: 87.67186, mean: 0.09634
[32m[0906 18-42-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03416, current rewards: 92.94908, mean: 0.09682
[32m[0906 18-42-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03413, current rewards: 98.25493, mean: 0.09728
[32m[0906 18-42-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03410, current rewards: 103.52330, mean: 0.09766
[32m[0906 18-42-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03408, current rewards: 108.79286, mean: 0.09801
[32m[0906 18-42-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03406, current rewards: 114.06047, mean: 0.09833
[32m[0906 18-42-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03404, current rewards: 118.44301, mean: 0.09789
[32m[0906 18-42-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03403, current rewards: 124.26916, mean: 0.09863
[32m[0906 18-42-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03401, current rewards: 130.05419, mean: 0.09928
[32m[0906 18-42-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03399, current rewards: 135.83904, mean: 0.09988
[32m[0906 18-42-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03398, current rewards: 140.68748, mean: 0.09978
[32m[0906 18-42-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03393, current rewards: 146.34089, mean: 0.10023
[32m[0906 18-42-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03389, current rewards: 152.01586, mean: 0.10067
[32m[0906 18-42-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03385, current rewards: 157.69442, mean: 0.10109
[32m[0906 18-42-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03382, current rewards: 163.37563, mean: 0.10148
[32m[0906 18-42-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03378, current rewards: 166.42629, mean: 0.10026
[32m[0906 18-42-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03375, current rewards: 174.08137, mean: 0.10180
[32m[0906 18-42-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03372, current rewards: 181.73645, mean: 0.10326
[32m[0906 18-42-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03369, current rewards: 189.39154, mean: 0.10464
[32m[0906 18-42-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03369, current rewards: 197.04662, mean: 0.10594
[32m[0906 18-42-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03368, current rewards: 204.70170, mean: 0.10717
[32m[0906 18-42-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03368, current rewards: 212.35678, mean: 0.10835
[32m[0906 18-42-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03368, current rewards: 220.01186, mean: 0.10946
[32m[0906 18-42-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03368, current rewards: 194.22700, mean: 0.09428
[32m[0906 18-42-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03368, current rewards: 144.22700, mean: 0.06835
[32m[0906 18-42-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03367, current rewards: 94.22700, mean: 0.04362
[32m[0906 18-42-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03367, current rewards: 44.22700, mean: 0.02001
[32m[0906 18-42-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03367, current rewards: -5.77300, mean: -0.00255
[32m[0906 18-42-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03367, current rewards: -55.77300, mean: -0.02414
[32m[0906 18-42-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03367, current rewards: -105.77300, mean: -0.04482
[32m[0906 18-42-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03367, current rewards: -155.77300, mean: -0.06464
[32m[0906 18-42-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03367, current rewards: -205.77300, mean: -0.08365
[32m[0906 18-43-00 @Agent.py:117][0m Average action selection time: 0.0337
[32m[0906 18-43-00 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-43-00 @MBExp.py:227][0m Rewards obtained: [-245.77300065926852], Lows: [7], Highs: [473], Total time: 8397.467937
[32m[0906 18-46-19 @MBExp.py:144][0m ####################################################################
[32m[0906 18-46-19 @MBExp.py:145][0m Starting training iteration 98.
[32m[0906 18-46-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03355, current rewards: -8.23047, mean: -0.82305
[32m[0906 18-46-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03425, current rewards: -2.66462, mean: -0.04441
[32m[0906 18-46-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03423, current rewards: 2.89388, mean: 0.02631
[32m[0906 18-46-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03432, current rewards: 8.46216, mean: 0.05289
[32m[0906 18-46-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03434, current rewards: 14.03201, mean: 0.06682
[32m[0906 18-46-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03440, current rewards: 19.60765, mean: 0.07541
[32m[0906 18-46-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03440, current rewards: 25.17761, mean: 0.08122
[32m[0906 18-46-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03441, current rewards: 30.74870, mean: 0.08541
[32m[0906 18-46-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03441, current rewards: 36.31619, mean: 0.08858
[32m[0906 18-46-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03440, current rewards: 33.96910, mean: 0.07385
[32m[0906 18-46-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03442, current rewards: 38.88150, mean: 0.07624
[32m[0906 18-46-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03444, current rewards: 43.59360, mean: 0.07785
[32m[0906 18-46-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03446, current rewards: 48.23506, mean: 0.07907
[32m[0906 18-46-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03440, current rewards: 52.87781, mean: 0.08012
[32m[0906 18-46-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03435, current rewards: 57.51294, mean: 0.08100
[32m[0906 18-46-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03432, current rewards: 62.16861, mean: 0.08180
[32m[0906 18-46-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03429, current rewards: 66.81176, mean: 0.08248
[32m[0906 18-46-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03425, current rewards: 69.83675, mean: 0.08121
[32m[0906 18-46-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03422, current rewards: 74.63268, mean: 0.08201
[32m[0906 18-46-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03421, current rewards: 79.13281, mean: 0.08243
[32m[0906 18-46-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03418, current rewards: 83.70445, mean: 0.08288
[32m[0906 18-46-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03416, current rewards: 88.26962, mean: 0.08327
[32m[0906 18-46-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03416, current rewards: 92.81046, mean: 0.08361
[32m[0906 18-46-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03418, current rewards: 97.32744, mean: 0.08390
[32m[0906 18-47-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03417, current rewards: 101.88648, mean: 0.08420
[32m[0906 18-47-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03416, current rewards: 106.44144, mean: 0.08448
[32m[0906 18-47-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03414, current rewards: 111.00470, mean: 0.08474
[32m[0906 18-47-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03414, current rewards: 115.65872, mean: 0.08504
[32m[0906 18-47-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03413, current rewards: 117.64935, mean: 0.08344
[32m[0906 18-47-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03409, current rewards: 122.02896, mean: 0.08358
[32m[0906 18-47-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03404, current rewards: 126.37439, mean: 0.08369
[32m[0906 18-47-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03401, current rewards: 130.71714, mean: 0.08379
[32m[0906 18-47-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03396, current rewards: 135.06419, mean: 0.08389
[32m[0906 18-47-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03392, current rewards: 139.40654, mean: 0.08398
[32m[0906 18-47-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03388, current rewards: 143.74421, mean: 0.08406
[32m[0906 18-47-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03384, current rewards: 147.26835, mean: 0.08368
[32m[0906 18-47-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03381, current rewards: 152.95277, mean: 0.08450
[32m[0906 18-47-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03379, current rewards: 158.76541, mean: 0.08536
[32m[0906 18-47-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03379, current rewards: 164.58002, mean: 0.08617
[32m[0906 18-47-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03378, current rewards: 170.39500, mean: 0.08694
[32m[0906 18-47-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03378, current rewards: 176.20612, mean: 0.08766
[32m[0906 18-47-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03378, current rewards: 182.01755, mean: 0.08836
[32m[0906 18-47-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03377, current rewards: 187.83058, mean: 0.08902
[32m[0906 18-47-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03376, current rewards: 193.64294, mean: 0.08965
[32m[0906 18-47-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03377, current rewards: 199.39407, mean: 0.09022
[32m[0906 18-47-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03376, current rewards: 205.28583, mean: 0.09083
[32m[0906 18-47-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03376, current rewards: 211.18505, mean: 0.09142
[32m[0906 18-47-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03376, current rewards: 213.70708, mean: 0.09055
[32m[0906 18-47-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03376, current rewards: 218.97759, mean: 0.09086
[32m[0906 18-47-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03376, current rewards: 224.26006, mean: 0.09116
[32m[0906 18-47-44 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 18-47-44 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-47-44 @MBExp.py:227][0m Rewards obtained: [228.58380706206117], Lows: [11], Highs: [4], Total time: 8482.643728
[32m[0906 18-51-04 @MBExp.py:144][0m ####################################################################
[32m[0906 18-51-04 @MBExp.py:145][0m Starting training iteration 99.
[32m[0906 18-51-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03583, current rewards: -9.41441, mean: -0.94144
[32m[0906 18-51-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03488, current rewards: -8.98826, mean: -0.14980
[32m[0906 18-51-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03467, current rewards: -2.82939, mean: -0.02572
[32m[0906 18-51-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03459, current rewards: 3.32810, mean: 0.02080
[32m[0906 18-51-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03455, current rewards: 9.49348, mean: 0.04521
[32m[0906 18-51-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03451, current rewards: 15.65662, mean: 0.06022
[32m[0906 18-51-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03449, current rewards: 21.82256, mean: 0.07040
[32m[0906 18-51-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03448, current rewards: 27.97903, mean: 0.07772
[32m[0906 18-51-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03445, current rewards: 29.91464, mean: 0.07296
[32m[0906 18-51-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03446, current rewards: 36.10088, mean: 0.07848
[32m[0906 18-51-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03444, current rewards: 42.28633, mean: 0.08291
[32m[0906 18-51-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03445, current rewards: 49.28559, mean: 0.08801
[32m[0906 18-51-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03444, current rewards: 57.14513, mean: 0.09368
[32m[0906 18-51-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03431, current rewards: 65.00467, mean: 0.09849
[32m[0906 18-51-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03426, current rewards: 38.14849, mean: 0.05373
[32m[0906 18-51-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03421, current rewards: -11.85151, mean: -0.01559
[32m[0906 18-51-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03417, current rewards: -61.85151, mean: -0.07636
[32m[0906 18-51-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03414, current rewards: -111.85151, mean: -0.13006
[32m[0906 18-51-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03411, current rewards: -161.85151, mean: -0.17786
[32m[0906 18-51-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03407, current rewards: -211.85151, mean: -0.22068
[32m[0906 18-51-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03403, current rewards: -261.85151, mean: -0.25926
[32m[0906 18-51-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03402, current rewards: -311.85151, mean: -0.29420
[32m[0906 18-51-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03401, current rewards: -361.85151, mean: -0.32599
[32m[0906 18-51-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03400, current rewards: -411.85151, mean: -0.35504
[32m[0906 18-51-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03398, current rewards: -461.85151, mean: -0.38170
[32m[0906 18-51-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03396, current rewards: -511.85151, mean: -0.40623
[32m[0906 18-51-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03396, current rewards: -561.85151, mean: -0.42889
[32m[0906 18-51-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03395, current rewards: -611.85151, mean: -0.44989
[32m[0906 18-51-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03394, current rewards: -661.85151, mean: -0.46940
[32m[0906 18-51-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03391, current rewards: -711.85151, mean: -0.48757
[32m[0906 18-51-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03385, current rewards: -761.85151, mean: -0.50454
[32m[0906 18-51-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03382, current rewards: -811.85151, mean: -0.52042
[32m[0906 18-51-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03379, current rewards: -861.85151, mean: -0.53531
[32m[0906 18-52-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03375, current rewards: -911.85151, mean: -0.54931
[32m[0906 18-52-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03372, current rewards: -961.85151, mean: -0.56249
[32m[0906 18-52-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03369, current rewards: -1011.85151, mean: -0.57492
[32m[0906 18-52-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03366, current rewards: -1061.85151, mean: -0.58666
[32m[0906 18-52-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03363, current rewards: -1111.85151, mean: -0.59777
[32m[0906 18-52-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03364, current rewards: -1161.85151, mean: -0.60830
[32m[0906 18-52-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03364, current rewards: -1211.85151, mean: -0.61829
[32m[0906 18-52-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03363, current rewards: -1261.85151, mean: -0.62779
[32m[0906 18-52-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03364, current rewards: -1311.85151, mean: -0.63682
[32m[0906 18-52-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03363, current rewards: -1361.85151, mean: -0.64543
[32m[0906 18-52-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03364, current rewards: -1411.85151, mean: -0.65363
[32m[0906 18-52-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03363, current rewards: -1461.85151, mean: -0.66147
[32m[0906 18-52-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03363, current rewards: -1511.85151, mean: -0.66896
[32m[0906 18-52-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03363, current rewards: -1561.85151, mean: -0.67613
[32m[0906 18-52-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03363, current rewards: -1611.85151, mean: -0.68299
[32m[0906 18-52-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03363, current rewards: -1661.85151, mean: -0.68956
[32m[0906 18-52-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03363, current rewards: -1711.85151, mean: -0.69587
[32m[0906 18-52-29 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 18-52-29 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-52-29 @MBExp.py:227][0m Rewards obtained: [-1751.8515121819876], Lows: [10], Highs: [1820], Total time: 8567.500704999999
[32m[0906 18-55-51 @MBExp.py:144][0m ####################################################################
[32m[0906 18-55-51 @MBExp.py:145][0m Starting training iteration 100.
[32m[0906 18-55-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03344, current rewards: -1.01818, mean: -0.10182
[32m[0906 18-55-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03411, current rewards: 4.56021, mean: 0.07600
[32m[0906 18-55-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03433, current rewards: 10.10881, mean: 0.09190
[32m[0906 18-55-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03439, current rewards: 15.70203, mean: 0.09814
[32m[0906 18-55-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03437, current rewards: 21.24871, mean: 0.10118
[32m[0906 18-56-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03440, current rewards: 26.79350, mean: 0.10305
[32m[0906 18-56-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03443, current rewards: 32.33816, mean: 0.10432
[32m[0906 18-56-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03441, current rewards: 37.88552, mean: 0.10524
[32m[0906 18-56-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03438, current rewards: 43.42968, mean: 0.10593
[32m[0906 18-56-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03445, current rewards: 46.70599, mean: 0.10153
[32m[0906 18-56-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03446, current rewards: 52.27794, mean: 0.10251
[32m[0906 18-56-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03444, current rewards: 57.68809, mean: 0.10301
[32m[0906 18-56-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03438, current rewards: 63.24013, mean: 0.10367
[32m[0906 18-56-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03431, current rewards: 68.79348, mean: 0.10423
[32m[0906 18-56-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03423, current rewards: 74.34268, mean: 0.10471
[32m[0906 18-56-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03417, current rewards: 79.90075, mean: 0.10513
[32m[0906 18-56-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03414, current rewards: 85.45196, mean: 0.10550
[32m[0906 18-56-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03410, current rewards: 91.00186, mean: 0.10582
[32m[0906 18-56-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03406, current rewards: 96.56073, mean: 0.10611
[32m[0906 18-56-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03402, current rewards: 102.01523, mean: 0.10627
[32m[0906 18-56-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03400, current rewards: 107.52590, mean: 0.10646
[32m[0906 18-56-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03397, current rewards: 113.08700, mean: 0.10669
[32m[0906 18-56-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03396, current rewards: 118.64879, mean: 0.10689
[32m[0906 18-56-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03394, current rewards: 124.20700, mean: 0.10708
[32m[0906 18-56-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03394, current rewards: 129.77085, mean: 0.10725
[32m[0906 18-56-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03393, current rewards: 135.33176, mean: 0.10741
[32m[0906 18-56-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03391, current rewards: 140.89007, mean: 0.10755
[32m[0906 18-56-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03390, current rewards: 146.45487, mean: 0.10769
[32m[0906 18-56-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03390, current rewards: 152.01411, mean: 0.10781
[32m[0906 18-56-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03384, current rewards: 155.41222, mean: 0.10645
[32m[0906 18-56-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03380, current rewards: 160.95780, mean: 0.10659
[32m[0906 18-56-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03376, current rewards: 166.50686, mean: 0.10674
[32m[0906 18-56-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03372, current rewards: 172.05566, mean: 0.10687
[32m[0906 18-56-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03369, current rewards: 177.60191, mean: 0.10699
[32m[0906 18-56-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03365, current rewards: 183.14609, mean: 0.10710
[32m[0906 18-56-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03362, current rewards: 188.58282, mean: 0.10715
[32m[0906 18-56-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03360, current rewards: 194.08607, mean: 0.10723
[32m[0906 18-56-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03357, current rewards: 199.59407, mean: 0.10731
[32m[0906 18-56-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03354, current rewards: 205.09558, mean: 0.10738
[32m[0906 18-56-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03354, current rewards: 210.60313, mean: 0.10745
[32m[0906 18-56-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03354, current rewards: 216.10721, mean: 0.10752
[32m[0906 18-57-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03355, current rewards: 221.61288, mean: 0.10758
[32m[0906 18-57-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03354, current rewards: 227.12153, mean: 0.10764
[32m[0906 18-57-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03354, current rewards: 232.62712, mean: 0.10770
[32m[0906 18-57-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03355, current rewards: 238.13282, mean: 0.10775
[32m[0906 18-57-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03355, current rewards: 243.64022, mean: 0.10781
[32m[0906 18-57-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03355, current rewards: 243.91413, mean: 0.10559
[32m[0906 18-57-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03356, current rewards: 250.00408, mean: 0.10593
[32m[0906 18-57-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03356, current rewards: 256.08397, mean: 0.10626
[32m[0906 18-57-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03356, current rewards: 262.17059, mean: 0.10657
[32m[0906 18-57-15 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 18-57-15 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-57-16 @MBExp.py:227][0m Rewards obtained: [267.0316887221432], Lows: [3], Highs: [5], Total time: 8652.183124
[32m[0906 19-00-39 @MBExp.py:144][0m ####################################################################
[32m[0906 19-00-39 @MBExp.py:145][0m Starting training iteration 101.
[32m[0906 19-00-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03576, current rewards: -5.08091, mean: -0.50809
[32m[0906 19-00-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03460, current rewards: 0.86540, mean: 0.01442
[32m[0906 19-00-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03449, current rewards: 8.17887, mean: 0.07435
[32m[0906 19-00-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03440, current rewards: 15.51956, mean: 0.09700
[32m[0906 19-00-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03442, current rewards: 22.85491, mean: 0.10883
[32m[0906 19-00-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03443, current rewards: 30.19304, mean: 0.11613
[32m[0906 19-00-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03441, current rewards: 37.53745, mean: 0.12109
[32m[0906 19-00-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03440, current rewards: 44.87669, mean: 0.12466
[32m[0906 19-00-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03439, current rewards: 52.21373, mean: 0.12735
[32m[0906 19-00-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03439, current rewards: 59.55106, mean: 0.12946
[32m[0906 19-00-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03443, current rewards: 59.53320, mean: 0.11673
[32m[0906 19-00-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03443, current rewards: 66.39647, mean: 0.11857
[32m[0906 19-01-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03439, current rewards: 73.25837, mean: 0.12010
[32m[0906 19-01-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03430, current rewards: 80.13168, mean: 0.12141
[32m[0906 19-01-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03424, current rewards: 86.98740, mean: 0.12252
[32m[0906 19-01-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03420, current rewards: 93.85386, mean: 0.12349
[32m[0906 19-01-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03417, current rewards: 100.72604, mean: 0.12435
[32m[0906 19-01-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03414, current rewards: 107.59394, mean: 0.12511
[32m[0906 19-01-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03409, current rewards: 112.11204, mean: 0.12320
[32m[0906 19-01-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03406, current rewards: 118.46720, mean: 0.12340
[32m[0906 19-01-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03404, current rewards: 124.81756, mean: 0.12358
[32m[0906 19-01-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03402, current rewards: 131.18338, mean: 0.12376
[32m[0906 19-01-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03399, current rewards: 133.15501, mean: 0.11996
[32m[0906 19-01-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03397, current rewards: 139.16157, mean: 0.11997
[32m[0906 19-01-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03396, current rewards: 145.16936, mean: 0.11997
[32m[0906 19-01-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03394, current rewards: 151.18474, mean: 0.11999
[32m[0906 19-01-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03393, current rewards: 156.90875, mean: 0.11978
[32m[0906 19-01-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03392, current rewards: 162.83893, mean: 0.11973
[32m[0906 19-01-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03392, current rewards: 168.76856, mean: 0.11969
[32m[0906 19-01-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03388, current rewards: 174.69387, mean: 0.11965
[32m[0906 19-01-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03383, current rewards: 180.62722, mean: 0.11962
[32m[0906 19-01-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03380, current rewards: 185.52377, mean: 0.11893
[32m[0906 19-01-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03376, current rewards: 191.86377, mean: 0.11917
[32m[0906 19-01-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03372, current rewards: 198.19678, mean: 0.11940
[32m[0906 19-01-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03370, current rewards: 204.43553, mean: 0.11955
[32m[0906 19-01-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03366, current rewards: 210.89420, mean: 0.11983
[32m[0906 19-01-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03363, current rewards: 217.34989, mean: 0.12008
[32m[0906 19-01-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03361, current rewards: 223.81026, mean: 0.12033
[32m[0906 19-01-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03358, current rewards: 230.26645, mean: 0.12056
[32m[0906 19-01-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03356, current rewards: 236.71275, mean: 0.12077
[32m[0906 19-01-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03357, current rewards: 243.13757, mean: 0.12096
[32m[0906 19-01-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03357, current rewards: 249.57623, mean: 0.12115
[32m[0906 19-01-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03357, current rewards: 256.09135, mean: 0.12137
[32m[0906 19-01-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03358, current rewards: 262.75610, mean: 0.12165
[32m[0906 19-01-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03359, current rewards: 269.15134, mean: 0.12179
[32m[0906 19-01-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03359, current rewards: 274.76132, mean: 0.12158
[32m[0906 19-01-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03358, current rewards: 280.31584, mean: 0.12135
[32m[0906 19-01-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03358, current rewards: 285.87265, mean: 0.12113
[32m[0906 19-02-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03358, current rewards: 291.42845, mean: 0.12092
[32m[0906 19-02-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03358, current rewards: 295.76298, mean: 0.12023
[32m[0906 19-02-04 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 19-02-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-02-04 @MBExp.py:227][0m Rewards obtained: [300.8950622270659], Lows: [10], Highs: [4], Total time: 8736.924514999999
[32m[0906 19-05-30 @MBExp.py:144][0m ####################################################################
[32m[0906 19-05-30 @MBExp.py:145][0m Starting training iteration 102.
[32m[0906 19-05-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03495, current rewards: -2.34309, mean: -0.23431
[32m[0906 19-05-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03449, current rewards: 2.95323, mean: 0.04922
[32m[0906 19-05-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03436, current rewards: 8.30792, mean: 0.07553
[32m[0906 19-05-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03442, current rewards: 13.66213, mean: 0.08539
[32m[0906 19-05-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03440, current rewards: 19.02119, mean: 0.09058
[32m[0906 19-05-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03436, current rewards: 24.37875, mean: 0.09376
[32m[0906 19-05-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03437, current rewards: 29.73473, mean: 0.09592
[32m[0906 19-05-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03435, current rewards: 35.09366, mean: 0.09748
[32m[0906 19-05-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03437, current rewards: 40.45134, mean: 0.09866
[32m[0906 19-05-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03439, current rewards: 45.92309, mean: 0.09983
[32m[0906 19-05-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03438, current rewards: 51.30113, mean: 0.10059
[32m[0906 19-05-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03439, current rewards: 52.48596, mean: 0.09372
[32m[0906 19-05-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03433, current rewards: 57.83312, mean: 0.09481
[32m[0906 19-05-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03427, current rewards: 63.18028, mean: 0.09573
[32m[0906 19-05-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03419, current rewards: 68.52744, mean: 0.09652
[32m[0906 19-05-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03416, current rewards: 73.87460, mean: 0.09720
[32m[0906 19-05-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03412, current rewards: 79.22176, mean: 0.09780
[32m[0906 19-05-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03409, current rewards: 84.53541, mean: 0.09830
[32m[0906 19-06-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03405, current rewards: 87.78037, mean: 0.09646
[32m[0906 19-06-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03402, current rewards: 74.99218, mean: 0.07812
[32m[0906 19-06-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03400, current rewards: 24.99218, mean: 0.02474
[32m[0906 19-06-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03398, current rewards: -25.00782, mean: -0.02359
[32m[0906 19-06-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03397, current rewards: -75.00782, mean: -0.06757
[32m[0906 19-06-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03395, current rewards: -125.00782, mean: -0.10777
[32m[0906 19-06-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03393, current rewards: -175.00782, mean: -0.14463
[32m[0906 19-06-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03392, current rewards: -225.00782, mean: -0.17858
[32m[0906 19-06-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03393, current rewards: -271.74848, mean: -0.20744
[32m[0906 19-06-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03391, current rewards: -266.23053, mean: -0.19576
[32m[0906 19-06-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03391, current rewards: -260.71148, mean: -0.18490
[32m[0906 19-06-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03388, current rewards: -263.48183, mean: -0.18047
[32m[0906 19-06-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03384, current rewards: -258.26836, mean: -0.17104
[32m[0906 19-06-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03380, current rewards: -253.05986, mean: -0.16222
[32m[0906 19-06-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03376, current rewards: -247.84780, mean: -0.15394
[32m[0906 19-06-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03373, current rewards: -242.63582, mean: -0.14617
[32m[0906 19-06-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03370, current rewards: -237.39261, mean: -0.13883
[32m[0906 19-06-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03368, current rewards: -232.19545, mean: -0.13193
[32m[0906 19-06-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03365, current rewards: -226.99551, mean: -0.12541
[32m[0906 19-06-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03361, current rewards: -221.63277, mean: -0.11916
[32m[0906 19-06-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03359, current rewards: -216.40794, mean: -0.11330
[32m[0906 19-06-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03356, current rewards: -211.18594, mean: -0.10775
[32m[0906 19-06-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03356, current rewards: -205.96533, mean: -0.10247
[32m[0906 19-06-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03356, current rewards: -200.74384, mean: -0.09745
[32m[0906 19-06-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03357, current rewards: -195.60307, mean: -0.09270
[32m[0906 19-06-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03356, current rewards: -190.34564, mean: -0.08812
[32m[0906 19-06-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03356, current rewards: -185.09524, mean: -0.08375
[32m[0906 19-06-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03356, current rewards: -179.84412, mean: -0.07958
[32m[0906 19-06-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03357, current rewards: -174.59319, mean: -0.07558
[32m[0906 19-06-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03357, current rewards: -171.38194, mean: -0.07262
[32m[0906 19-06-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03357, current rewards: -166.18161, mean: -0.06896
[32m[0906 19-06-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03357, current rewards: -160.98326, mean: -0.06544
[32m[0906 19-06-54 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 19-06-54 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-06-54 @MBExp.py:227][0m Rewards obtained: [-156.82567800649105], Lows: [13], Highs: [354], Total time: 8821.609653999998
[32m[0906 19-10-22 @MBExp.py:144][0m ####################################################################
[32m[0906 19-10-22 @MBExp.py:145][0m Starting training iteration 103.
[32m[0906 19-10-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03361, current rewards: -5.32588, mean: -0.53259
[32m[0906 19-10-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03433, current rewards: 0.16404, mean: 0.00273
[32m[0906 19-10-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03439, current rewards: 5.68230, mean: 0.05166
[32m[0906 19-10-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03438, current rewards: 11.20179, mean: 0.07001
[32m[0906 19-10-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03442, current rewards: 16.72227, mean: 0.07963
[32m[0906 19-10-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03441, current rewards: 22.23771, mean: 0.08553
[32m[0906 19-10-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03441, current rewards: 27.76034, mean: 0.08955
[32m[0906 19-10-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03436, current rewards: 29.27855, mean: 0.08133
[32m[0906 19-10-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03438, current rewards: 35.03307, mean: 0.08545
[32m[0906 19-10-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03437, current rewards: 40.57981, mean: 0.08822
[32m[0906 19-10-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03441, current rewards: 46.26497, mean: 0.09072
[32m[0906 19-10-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03442, current rewards: 51.94579, mean: 0.09276
[32m[0906 19-10-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03434, current rewards: 57.63017, mean: 0.09448
[32m[0906 19-10-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03427, current rewards: 63.31320, mean: 0.09593
[32m[0906 19-10-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03423, current rewards: 68.03086, mean: 0.09582
[32m[0906 19-10-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03418, current rewards: 74.84564, mean: 0.09848
[32m[0906 19-10-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03414, current rewards: 81.70156, mean: 0.10087
[32m[0906 19-10-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03411, current rewards: 88.79825, mean: 0.10325
[32m[0906 19-10-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03407, current rewards: 95.03444, mean: 0.10443
[32m[0906 19-10-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03405, current rewards: 101.27837, mean: 0.10550
[32m[0906 19-10-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03402, current rewards: 107.51905, mean: 0.10645
[32m[0906 19-10-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03400, current rewards: 113.75986, mean: 0.10732
[32m[0906 19-11-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03398, current rewards: 120.00269, mean: 0.10811
[32m[0906 19-11-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03397, current rewards: 126.24149, mean: 0.10883
[32m[0906 19-11-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03396, current rewards: 132.48135, mean: 0.10949
[32m[0906 19-11-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03394, current rewards: 138.59789, mean: 0.11000
[32m[0906 19-11-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03392, current rewards: 135.05928, mean: 0.10310
[32m[0906 19-11-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03391, current rewards: 140.67388, mean: 0.10344
[32m[0906 19-11-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03390, current rewards: 146.27521, mean: 0.10374
[32m[0906 19-11-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03386, current rewards: 151.88601, mean: 0.10403
[32m[0906 19-11-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03382, current rewards: 157.49533, mean: 0.10430
[32m[0906 19-11-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03378, current rewards: 163.10106, mean: 0.10455
[32m[0906 19-11-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03372, current rewards: 168.71147, mean: 0.10479
[32m[0906 19-11-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03368, current rewards: 174.31330, mean: 0.10501
[32m[0906 19-11-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03366, current rewards: 178.12494, mean: 0.10417
[32m[0906 19-11-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03362, current rewards: 183.62239, mean: 0.10433
[32m[0906 19-11-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03360, current rewards: 189.11923, mean: 0.10449
[32m[0906 19-11-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03357, current rewards: 194.62042, mean: 0.10463
[32m[0906 19-11-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03354, current rewards: 200.11408, mean: 0.10477
[32m[0906 19-11-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03352, current rewards: 205.60702, mean: 0.10490
[32m[0906 19-11-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03350, current rewards: 211.10195, mean: 0.10503
[32m[0906 19-11-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03351, current rewards: 216.60094, mean: 0.10515
[32m[0906 19-11-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03353, current rewards: 220.06519, mean: 0.10430
[32m[0906 19-11-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03353, current rewards: 225.71441, mean: 0.10450
[32m[0906 19-11-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03353, current rewards: 231.36782, mean: 0.10469
[32m[0906 19-11-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03354, current rewards: 237.01762, mean: 0.10488
[32m[0906 19-11-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03354, current rewards: 242.67227, mean: 0.10505
[32m[0906 19-11-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03355, current rewards: 248.63874, mean: 0.10536
[32m[0906 19-11-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03355, current rewards: 254.15836, mean: 0.10546
[32m[0906 19-11-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03355, current rewards: 259.68062, mean: 0.10556
[32m[0906 19-11-46 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 19-11-46 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-11-46 @MBExp.py:227][0m Rewards obtained: [264.114819483085], Lows: [10], Highs: [4], Total time: 8906.271581999998
[32m[0906 19-15-17 @MBExp.py:144][0m ####################################################################
[32m[0906 19-15-17 @MBExp.py:145][0m Starting training iteration 104.
[32m[0906 19-15-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03662, current rewards: -6.69603, mean: -0.66960
[32m[0906 19-15-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03493, current rewards: -2.20386, mean: -0.03673
[32m[0906 19-15-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03485, current rewards: 2.25616, mean: 0.02051
[32m[0906 19-15-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03475, current rewards: 6.71937, mean: 0.04200
[32m[0906 19-15-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03466, current rewards: 11.18514, mean: 0.05326
[32m[0906 19-15-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03460, current rewards: 15.65007, mean: 0.06019
[32m[0906 19-15-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03457, current rewards: 20.10947, mean: 0.06487
[32m[0906 19-15-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03454, current rewards: 24.57107, mean: 0.06825
[32m[0906 19-15-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03455, current rewards: 28.96192, mean: 0.07064
[32m[0906 19-15-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03454, current rewards: 27.34214, mean: 0.05944
[32m[0906 19-15-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03452, current rewards: 32.17482, mean: 0.06309
[32m[0906 19-15-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03445, current rewards: 37.00877, mean: 0.06609
[32m[0906 19-15-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03437, current rewards: 41.84000, mean: 0.06859
[32m[0906 19-15-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03433, current rewards: 46.66891, mean: 0.07071
[32m[0906 19-15-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03428, current rewards: 51.50121, mean: 0.07254
[32m[0906 19-15-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03422, current rewards: 56.33054, mean: 0.07412
[32m[0906 19-15-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03418, current rewards: 61.19743, mean: 0.07555
[32m[0906 19-15-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03415, current rewards: 66.14512, mean: 0.07691
[32m[0906 19-15-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03412, current rewards: 71.03380, mean: 0.07806
[32m[0906 19-15-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03409, current rewards: 75.92083, mean: 0.07908
[32m[0906 19-15-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03408, current rewards: 80.80610, mean: 0.08001
[32m[0906 19-15-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03406, current rewards: 85.69203, mean: 0.08084
[32m[0906 19-15-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03405, current rewards: 90.57854, mean: 0.08160
[32m[0906 19-15-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03403, current rewards: 96.18061, mean: 0.08291
[32m[0906 19-15-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03402, current rewards: 101.64989, mean: 0.08401
[32m[0906 19-16-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03400, current rewards: 106.92147, mean: 0.08486
[32m[0906 19-16-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03399, current rewards: 112.37185, mean: 0.08578
[32m[0906 19-16-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03398, current rewards: 117.82552, mean: 0.08664
[32m[0906 19-16-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03397, current rewards: 123.27410, mean: 0.08743
[32m[0906 19-16-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03392, current rewards: 128.72831, mean: 0.08817
[32m[0906 19-16-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03388, current rewards: 134.17614, mean: 0.08886
[32m[0906 19-16-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03383, current rewards: 139.63025, mean: 0.08951
[32m[0906 19-16-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03378, current rewards: 145.08240, mean: 0.09011
[32m[0906 19-16-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03375, current rewards: 150.66681, mean: 0.09076
[32m[0906 19-16-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03371, current rewards: 156.17286, mean: 0.09133
[32m[0906 19-16-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03367, current rewards: 161.63816, mean: 0.09184
[32m[0906 19-16-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03365, current rewards: 167.10592, mean: 0.09232
[32m[0906 19-16-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03363, current rewards: 167.13080, mean: 0.08986
[32m[0906 19-16-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03360, current rewards: 170.89036, mean: 0.08947
[32m[0906 19-16-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03358, current rewards: 174.63331, mean: 0.08910
[32m[0906 19-16-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03355, current rewards: 178.38490, mean: 0.08875
[32m[0906 19-16-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03355, current rewards: 182.13988, mean: 0.08842
[32m[0906 19-16-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03355, current rewards: 185.89513, mean: 0.08810
[32m[0906 19-16-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03356, current rewards: 189.69450, mean: 0.08782
[32m[0906 19-16-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03355, current rewards: 193.49649, mean: 0.08755
[32m[0906 19-16-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03355, current rewards: 197.29657, mean: 0.08730
[32m[0906 19-16-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03355, current rewards: 201.09943, mean: 0.08706
[32m[0906 19-16-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03355, current rewards: 204.89732, mean: 0.08682
[32m[0906 19-16-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03355, current rewards: 208.69652, mean: 0.08660
[32m[0906 19-16-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03355, current rewards: 212.49463, mean: 0.08638
[32m[0906 19-16-41 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 19-16-41 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-16-41 @MBExp.py:227][0m Rewards obtained: [205.7785231012014], Lows: [9], Highs: [10], Total time: 8990.940181999998
[32m[0906 19-20-12 @MBExp.py:144][0m ####################################################################
[32m[0906 19-20-12 @MBExp.py:145][0m Starting training iteration 105.
[32m[0906 19-20-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03348, current rewards: -11.68770, mean: -1.16877
[32m[0906 19-20-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03432, current rewards: -5.94882, mean: -0.09915
[32m[0906 19-20-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03438, current rewards: -0.21490, mean: -0.00195
[32m[0906 19-20-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03434, current rewards: 5.51329, mean: 0.03446
[32m[0906 19-20-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03433, current rewards: 11.23582, mean: 0.05350
[32m[0906 19-20-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03433, current rewards: 16.97162, mean: 0.06528
[32m[0906 19-20-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03431, current rewards: 22.70130, mean: 0.07323
[32m[0906 19-20-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03430, current rewards: 28.43317, mean: 0.07898
[32m[0906 19-20-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03434, current rewards: 34.42550, mean: 0.08396
[32m[0906 19-20-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03435, current rewards: 40.08597, mean: 0.08714
[32m[0906 19-20-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03436, current rewards: 41.47924, mean: 0.08133
[32m[0906 19-20-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03432, current rewards: 47.04608, mean: 0.08401
[32m[0906 19-20-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03426, current rewards: 52.61102, mean: 0.08625
[32m[0906 19-20-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03420, current rewards: 53.95777, mean: 0.08175
[32m[0906 19-20-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03414, current rewards: 60.72895, mean: 0.08553
[32m[0906 19-20-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03409, current rewards: 67.49299, mean: 0.08881
[32m[0906 19-20-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03404, current rewards: 73.62373, mean: 0.09089
[32m[0906 19-20-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03403, current rewards: 78.87077, mean: 0.09171
[32m[0906 19-20-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03400, current rewards: 84.09102, mean: 0.09241
[32m[0906 19-20-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03401, current rewards: 82.02466, mean: 0.08544
[32m[0906 19-20-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03399, current rewards: 87.99517, mean: 0.08712
[32m[0906 19-20-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03397, current rewards: 93.96261, mean: 0.08864
[32m[0906 19-20-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03395, current rewards: 99.91709, mean: 0.09002
[32m[0906 19-20-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03394, current rewards: 105.86703, mean: 0.09126
[32m[0906 19-20-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03394, current rewards: 111.76996, mean: 0.09237
[32m[0906 19-20-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03392, current rewards: 117.70586, mean: 0.09342
[32m[0906 19-20-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03391, current rewards: 123.64208, mean: 0.09438
[32m[0906 19-20-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03389, current rewards: 129.58211, mean: 0.09528
[32m[0906 19-21-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03388, current rewards: 131.17164, mean: 0.09303
[32m[0906 19-21-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03387, current rewards: 136.61470, mean: 0.09357
[32m[0906 19-21-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03381, current rewards: 142.06401, mean: 0.09408
[32m[0906 19-21-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03377, current rewards: 147.51024, mean: 0.09456
[32m[0906 19-21-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03373, current rewards: 153.05937, mean: 0.09507
[32m[0906 19-21-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03369, current rewards: 158.52860, mean: 0.09550
[32m[0906 19-21-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03366, current rewards: 164.00262, mean: 0.09591
[32m[0906 19-21-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03363, current rewards: 169.47305, mean: 0.09629
[32m[0906 19-21-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03361, current rewards: 170.84918, mean: 0.09439
[32m[0906 19-21-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03359, current rewards: 176.47132, mean: 0.09488
[32m[0906 19-21-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03357, current rewards: 182.09287, mean: 0.09534
[32m[0906 19-21-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03355, current rewards: 187.70897, mean: 0.09577
[32m[0906 19-21-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03353, current rewards: 193.29726, mean: 0.09617
[32m[0906 19-21-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03351, current rewards: 198.66218, mean: 0.09644
[32m[0906 19-21-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03352, current rewards: 204.27404, mean: 0.09681
[32m[0906 19-21-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03351, current rewards: 209.88700, mean: 0.09717
[32m[0906 19-21-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03352, current rewards: 215.50460, mean: 0.09751
[32m[0906 19-21-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03352, current rewards: 221.12040, mean: 0.09784
[32m[0906 19-21-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03352, current rewards: 226.73639, mean: 0.09815
[32m[0906 19-21-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03351, current rewards: 232.34997, mean: 0.09845
[32m[0906 19-21-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03352, current rewards: 233.56667, mean: 0.09692
[32m[0906 19-21-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03352, current rewards: 239.24600, mean: 0.09725
[32m[0906 19-21-37 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 19-21-37 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-21-37 @MBExp.py:227][0m Rewards obtained: [243.44133754524137], Lows: [17], Highs: [5], Total time: 9075.529846999998
[32m[0906 19-25-10 @MBExp.py:144][0m ####################################################################
[32m[0906 19-25-10 @MBExp.py:145][0m Starting training iteration 106.
[32m[0906 19-25-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03359, current rewards: -7.83358, mean: -0.78336
[32m[0906 19-25-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03459, current rewards: -47.60155, mean: -0.79336
[32m[0906 19-25-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03445, current rewards: -84.71688, mean: -0.77015
[32m[0906 19-25-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03446, current rewards: -131.76528, mean: -0.82353
[32m[0906 19-25-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03445, current rewards: -173.15749, mean: -0.82456
[32m[0906 19-25-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03444, current rewards: -199.92715, mean: -0.76895
[32m[0906 19-25-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03450, current rewards: -248.55413, mean: -0.80179
[32m[0906 19-25-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03519, current rewards: -280.74626, mean: -0.77985
[32m[0906 19-25-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03635, current rewards: -304.10689, mean: -0.74172
[32m[0906 19-25-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03696, current rewards: -336.99083, mean: -0.73259
[32m[0906 19-25-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03746, current rewards: -367.85312, mean: -0.72128
[32m[0906 19-25-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03810, current rewards: -390.02947, mean: -0.69648
[32m[0906 19-25-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03851, current rewards: -413.44019, mean: -0.67777
[32m[0906 19-25-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03873, current rewards: -443.85191, mean: -0.67250
[32m[0906 19-25-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03884, current rewards: -462.70726, mean: -0.65170
[32m[0906 19-25-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03847, current rewards: -457.01131, mean: -0.60133
[32m[0906 19-25-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03817, current rewards: -451.10506, mean: -0.55692
[32m[0906 19-25-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03792, current rewards: -445.27725, mean: -0.51776
[32m[0906 19-25-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03768, current rewards: -439.42464, mean: -0.48288
[32m[0906 19-25-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03748, current rewards: -433.55140, mean: -0.45162
[32m[0906 19-25-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03730, current rewards: -427.69942, mean: -0.42346
[32m[0906 19-25-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03713, current rewards: -426.63887, mean: -0.40249
[32m[0906 19-25-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03698, current rewards: -419.98058, mean: -0.37836
[32m[0906 19-25-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03684, current rewards: -413.32165, mean: -0.35631
[32m[0906 19-25-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03670, current rewards: -406.86474, mean: -0.33625
[32m[0906 19-25-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03657, current rewards: -400.32918, mean: -0.31772
[32m[0906 19-25-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03647, current rewards: -393.79098, mean: -0.30060
[32m[0906 19-26-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03632, current rewards: -387.25920, mean: -0.28475
[32m[0906 19-26-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03619, current rewards: -380.72492, mean: -0.27002
[32m[0906 19-26-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03607, current rewards: -374.19157, mean: -0.25630
[32m[0906 19-26-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03596, current rewards: -374.04132, mean: -0.24771
[32m[0906 19-26-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03587, current rewards: -367.47032, mean: -0.23556
[32m[0906 19-26-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03581, current rewards: -360.76296, mean: -0.22408
[32m[0906 19-26-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03582, current rewards: -354.08879, mean: -0.21331
[32m[0906 19-26-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03583, current rewards: -347.52190, mean: -0.20323
[32m[0906 19-26-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03587, current rewards: -340.74566, mean: -0.19361
[32m[0906 19-26-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03591, current rewards: -334.22314, mean: -0.18465
[32m[0906 19-26-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03593, current rewards: -327.52317, mean: -0.17609
[32m[0906 19-26-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03594, current rewards: -320.88022, mean: -0.16800
[32m[0906 19-26-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03596, current rewards: -314.35270, mean: -0.16038
[32m[0906 19-26-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03598, current rewards: -307.79251, mean: -0.15313
[32m[0906 19-26-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03595, current rewards: -304.26915, mean: -0.14770
[32m[0906 19-26-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03589, current rewards: -298.63387, mean: -0.14153
[32m[0906 19-26-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03583, current rewards: -292.99495, mean: -0.13565
[32m[0906 19-26-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03578, current rewards: -287.35914, mean: -0.13003
[32m[0906 19-26-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03574, current rewards: -281.72331, mean: -0.12466
[32m[0906 19-26-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03570, current rewards: -276.08663, mean: -0.11952
[32m[0906 19-26-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03565, current rewards: -270.45119, mean: -0.11460
[32m[0906 19-26-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03561, current rewards: -264.81370, mean: -0.10988
[32m[0906 19-26-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03558, current rewards: -259.09886, mean: -0.10532
[32m[0906 19-26-40 @Agent.py:117][0m Average action selection time: 0.0356
[32m[0906 19-26-40 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-26-40 @MBExp.py:227][0m Rewards obtained: [-258.0784461680274], Lows: [296], Highs: [5], Total time: 9165.255939999997
[32m[0906 19-30-15 @MBExp.py:144][0m ####################################################################
[32m[0906 19-30-15 @MBExp.py:145][0m Starting training iteration 107.
[32m[0906 19-30-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03459, current rewards: -3.27545, mean: -0.32755
[32m[0906 19-30-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03455, current rewards: 0.99527, mean: 0.01659
[32m[0906 19-30-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03451, current rewards: 5.33192, mean: 0.04847
[32m[0906 19-30-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03453, current rewards: 9.66853, mean: 0.06043
[32m[0906 19-30-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03445, current rewards: 14.00477, mean: 0.06669
[32m[0906 19-30-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03447, current rewards: 18.34093, mean: 0.07054
[32m[0906 19-30-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03446, current rewards: 21.30383, mean: 0.06872
[32m[0906 19-30-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03446, current rewards: 25.32223, mean: 0.07034
[32m[0906 19-30-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03431, current rewards: 29.37749, mean: 0.07165
[32m[0906 19-30-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03421, current rewards: 33.37842, mean: 0.07256
[32m[0906 19-30-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03415, current rewards: 37.37607, mean: 0.07329
[32m[0906 19-30-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03410, current rewards: 41.37797, mean: 0.07389
[32m[0906 19-30-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03403, current rewards: 42.03981, mean: 0.06892
[32m[0906 19-30-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03397, current rewards: 47.04306, mean: 0.07128
[32m[0906 19-30-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03392, current rewards: 52.04644, mean: 0.07330
[32m[0906 19-30-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03389, current rewards: 57.04966, mean: 0.07507
[32m[0906 19-30-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03386, current rewards: 61.99086, mean: 0.07653
[32m[0906 19-30-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03385, current rewards: 66.99767, mean: 0.07790
[32m[0906 19-30-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03383, current rewards: 72.00422, mean: 0.07913
[32m[0906 19-30-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03382, current rewards: 74.81169, mean: 0.07793
[32m[0906 19-30-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03380, current rewards: 78.63138, mean: 0.07785
[32m[0906 19-30-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03379, current rewards: 82.38561, mean: 0.07772
[32m[0906 19-30-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03377, current rewards: 86.14251, mean: 0.07761
[32m[0906 19-30-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03376, current rewards: 89.89747, mean: 0.07750
[32m[0906 19-30-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03374, current rewards: 93.65353, mean: 0.07740
[32m[0906 19-30-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03373, current rewards: 97.41268, mean: 0.07731
[32m[0906 19-31-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03371, current rewards: 101.85356, mean: 0.07775
[32m[0906 19-31-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03366, current rewards: 106.33875, mean: 0.07819
[32m[0906 19-31-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03363, current rewards: 110.82421, mean: 0.07860
[32m[0906 19-31-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03359, current rewards: 115.30915, mean: 0.07898
[32m[0906 19-31-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03355, current rewards: 119.79442, mean: 0.07933
[32m[0906 19-31-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03352, current rewards: 124.27951, mean: 0.07967
[32m[0906 19-31-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03349, current rewards: 128.77901, mean: 0.07999
[32m[0906 19-31-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03346, current rewards: 133.27642, mean: 0.08029
[32m[0906 19-31-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03343, current rewards: 137.76936, mean: 0.08057
[32m[0906 19-31-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03340, current rewards: 138.09809, mean: 0.07846
[32m[0906 19-31-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03338, current rewards: 142.71168, mean: 0.07885
[32m[0906 19-31-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03335, current rewards: 147.32329, mean: 0.07921
[32m[0906 19-31-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03334, current rewards: 151.93755, mean: 0.07955
[32m[0906 19-31-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03332, current rewards: 156.54982, mean: 0.07987
[32m[0906 19-31-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03329, current rewards: 161.16651, mean: 0.08018
[32m[0906 19-31-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03330, current rewards: 165.75865, mean: 0.08047
[32m[0906 19-31-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03331, current rewards: 170.34975, mean: 0.08073
[32m[0906 19-31-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03331, current rewards: 174.94145, mean: 0.08099
[32m[0906 19-31-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03332, current rewards: 179.53196, mean: 0.08124
[32m[0906 19-31-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03333, current rewards: 184.12276, mean: 0.08147
[32m[0906 19-31-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03333, current rewards: 188.71426, mean: 0.08169
[32m[0906 19-31-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03333, current rewards: 193.30615, mean: 0.08191
[32m[0906 19-31-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03334, current rewards: 197.95034, mean: 0.08214
[32m[0906 19-31-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03334, current rewards: 201.42966, mean: 0.08188
[32m[0906 19-31-39 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 19-31-39 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-31-39 @MBExp.py:227][0m Rewards obtained: [205.05401735579844], Lows: [5], Highs: [6], Total time: 9249.410084999998
[32m[0906 19-35-17 @MBExp.py:144][0m ####################################################################
[32m[0906 19-35-17 @MBExp.py:145][0m Starting training iteration 108.
[32m[0906 19-35-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03356, current rewards: -10.59564, mean: -1.05956
[32m[0906 19-35-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03419, current rewards: -5.65601, mean: -0.09427
[32m[0906 19-35-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03424, current rewards: -0.72140, mean: -0.00656
[32m[0906 19-35-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03428, current rewards: 4.21915, mean: 0.02637
[32m[0906 19-35-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03427, current rewards: 9.15390, mean: 0.04359
[32m[0906 19-35-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03432, current rewards: 14.09528, mean: 0.05421
[32m[0906 19-35-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03435, current rewards: 19.11429, mean: 0.06166
[32m[0906 19-35-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03422, current rewards: 24.18024, mean: 0.06717
[32m[0906 19-35-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03416, current rewards: 24.00601, mean: 0.05855
[32m[0906 19-35-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03409, current rewards: 29.14761, mean: 0.06336
[32m[0906 19-35-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03403, current rewards: 34.29033, mean: 0.06724
[32m[0906 19-35-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03399, current rewards: 39.43249, mean: 0.07042
[32m[0906 19-35-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03397, current rewards: 44.57523, mean: 0.07307
[32m[0906 19-35-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03392, current rewards: 49.71510, mean: 0.07533
[32m[0906 19-35-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03389, current rewards: 50.67802, mean: 0.07138
[32m[0906 19-35-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03386, current rewards: 55.89079, mean: 0.07354
[32m[0906 19-35-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03384, current rewards: 61.10414, mean: 0.07544
[32m[0906 19-35-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03383, current rewards: 66.31756, mean: 0.07711
[32m[0906 19-35-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03382, current rewards: 71.53099, mean: 0.07861
[32m[0906 19-35-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03381, current rewards: 76.74465, mean: 0.07994
[32m[0906 19-35-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03380, current rewards: 81.95677, mean: 0.08115
[32m[0906 19-35-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03383, current rewards: 84.70661, mean: 0.07991
[32m[0906 19-35-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03387, current rewards: 89.23467, mean: 0.08039
[32m[0906 19-35-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03392, current rewards: 94.00033, mean: 0.08103
[32m[0906 19-35-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03396, current rewards: 99.05887, mean: 0.08187
[32m[0906 19-36-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03398, current rewards: 104.09219, mean: 0.08261
[32m[0906 19-36-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03402, current rewards: 109.06564, mean: 0.08326
[32m[0906 19-36-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03400, current rewards: 113.97282, mean: 0.08380
[32m[0906 19-36-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03400, current rewards: 119.15532, mean: 0.08451
[32m[0906 19-36-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03397, current rewards: 124.08475, mean: 0.08499
[32m[0906 19-36-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03395, current rewards: 129.16847, mean: 0.08554
[32m[0906 19-36-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03394, current rewards: 133.93094, mean: 0.08585
[32m[0906 19-36-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03391, current rewards: 139.08636, mean: 0.08639
[32m[0906 19-36-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03386, current rewards: 144.23994, mean: 0.08689
[32m[0906 19-36-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03382, current rewards: 149.40037, mean: 0.08737
[32m[0906 19-36-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03379, current rewards: 154.55558, mean: 0.08782
[32m[0906 19-36-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03375, current rewards: 159.70989, mean: 0.08824
[32m[0906 19-36-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03372, current rewards: 164.86573, mean: 0.08864
[32m[0906 19-36-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03369, current rewards: 170.01933, mean: 0.08902
[32m[0906 19-36-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03366, current rewards: 175.18668, mean: 0.08938
[32m[0906 19-36-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03364, current rewards: 180.34419, mean: 0.08972
[32m[0906 19-36-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03364, current rewards: 185.49777, mean: 0.09005
[32m[0906 19-36-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03363, current rewards: 190.65617, mean: 0.09036
[32m[0906 19-36-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03363, current rewards: 190.72084, mean: 0.08830
[32m[0906 19-36-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03362, current rewards: 195.93637, mean: 0.08866
[32m[0906 19-36-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03363, current rewards: 201.15375, mean: 0.08901
[32m[0906 19-36-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03363, current rewards: 206.36852, mean: 0.08934
[32m[0906 19-36-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03363, current rewards: 211.69873, mean: 0.08970
[32m[0906 19-36-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03363, current rewards: 217.10029, mean: 0.09008
[32m[0906 19-36-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03363, current rewards: 222.38412, mean: 0.09040
[32m[0906 19-36-42 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 19-36-42 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-36-42 @MBExp.py:227][0m Rewards obtained: [226.61136704370503], Lows: [11], Highs: [6], Total time: 9334.269581999997
[32m[0906 19-40-21 @MBExp.py:144][0m ####################################################################
[32m[0906 19-40-21 @MBExp.py:145][0m Starting training iteration 109.
[32m[0906 19-40-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03332, current rewards: -2.35358, mean: -0.23536
[32m[0906 19-40-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.04405, current rewards: 2.18896, mean: 0.03648
[32m[0906 19-40-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.04507, current rewards: 6.56159, mean: 0.05965
[32m[0906 19-40-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.04495, current rewards: 11.11990, mean: 0.06950
[32m[0906 19-40-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.04502, current rewards: 15.56813, mean: 0.07413
[32m[0906 19-40-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.04502, current rewards: 20.10548, mean: 0.07733
[32m[0906 19-40-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.04466, current rewards: 24.61828, mean: 0.07941
[32m[0906 19-40-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.04402, current rewards: 28.88474, mean: 0.08024
[32m[0906 19-40-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.04374, current rewards: 33.24704, mean: 0.08109
[32m[0906 19-40-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.04344, current rewards: 37.57993, mean: 0.08170
[32m[0906 19-40-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.04309, current rewards: 41.95595, mean: 0.08227
[32m[0906 19-40-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.04288, current rewards: 46.23397, mean: 0.08256
[32m[0906 19-40-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.04286, current rewards: 50.59494, mean: 0.08294
[32m[0906 19-40-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.04254, current rewards: 54.21947, mean: 0.08215
[32m[0906 19-40-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.04190, current rewards: 59.70892, mean: 0.08410
[32m[0906 19-40-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.04135, current rewards: 65.09614, mean: 0.08565
[32m[0906 19-40-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.04087, current rewards: 70.45580, mean: 0.08698
[32m[0906 19-40-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.04044, current rewards: 75.81298, mean: 0.08815
[32m[0906 19-40-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.04008, current rewards: 79.06847, mean: 0.08689
[32m[0906 19-41-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03974, current rewards: 84.86465, mean: 0.08840
[32m[0906 19-41-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03945, current rewards: 90.27803, mean: 0.08938
[32m[0906 19-41-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03918, current rewards: 95.69244, mean: 0.09028
[32m[0906 19-41-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03893, current rewards: 101.10548, mean: 0.09109
[32m[0906 19-41-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03870, current rewards: 106.51748, mean: 0.09183
[32m[0906 19-41-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03844, current rewards: 110.74345, mean: 0.09152
[32m[0906 19-41-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03821, current rewards: 116.34037, mean: 0.09233
[32m[0906 19-41-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03799, current rewards: 121.94198, mean: 0.09309
[32m[0906 19-41-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03779, current rewards: 127.53905, mean: 0.09378
[32m[0906 19-41-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03761, current rewards: 133.13701, mean: 0.09442
[32m[0906 19-41-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03744, current rewards: 138.73331, mean: 0.09502
[32m[0906 19-41-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03727, current rewards: 144.32691, mean: 0.09558
[32m[0906 19-41-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03712, current rewards: 149.89826, mean: 0.09609
[32m[0906 19-41-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03698, current rewards: 155.51774, mean: 0.09659
[32m[0906 19-41-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03685, current rewards: 161.14179, mean: 0.09707
[32m[0906 19-41-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03674, current rewards: 166.76156, mean: 0.09752
[32m[0906 19-41-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03663, current rewards: 168.27476, mean: 0.09561
[32m[0906 19-41-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03652, current rewards: 172.94782, mean: 0.09555
[32m[0906 19-41-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03643, current rewards: 177.62679, mean: 0.09550
[32m[0906 19-41-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03635, current rewards: 182.29700, mean: 0.09544
[32m[0906 19-41-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03628, current rewards: 187.69470, mean: 0.09576
[32m[0906 19-41-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03621, current rewards: 193.12226, mean: 0.09608
[32m[0906 19-41-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03615, current rewards: 198.54625, mean: 0.09638
[32m[0906 19-41-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03608, current rewards: 203.97871, mean: 0.09667
[32m[0906 19-41-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03602, current rewards: 209.40504, mean: 0.09695
[32m[0906 19-41-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03597, current rewards: 214.83124, mean: 0.09721
[32m[0906 19-41-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03605, current rewards: 215.67842, mean: 0.09543
[32m[0906 19-41-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03623, current rewards: 220.53711, mean: 0.09547
[32m[0906 19-41-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03640, current rewards: 225.21243, mean: 0.09543
[32m[0906 19-41-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03656, current rewards: 229.65550, mean: 0.09529
[32m[0906 19-41-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03668, current rewards: 234.10043, mean: 0.09516
[32m[0906 19-41-54 @Agent.py:117][0m Average action selection time: 0.0368
[32m[0906 19-41-54 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-41-54 @MBExp.py:227][0m Rewards obtained: [233.49217733548258], Lows: [3], Highs: [12], Total time: 9426.996137999997
[32m[0906 19-45-36 @MBExp.py:144][0m ####################################################################
[32m[0906 19-45-36 @MBExp.py:145][0m Starting training iteration 110.
[32m[0906 19-45-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.04287, current rewards: -9.27574, mean: -0.92757
[32m[0906 19-45-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03568, current rewards: -5.38383, mean: -0.08973
[32m[0906 19-45-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03465, current rewards: 0.04112, mean: 0.00037
[32m[0906 19-45-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03428, current rewards: 5.46588, mean: 0.03416
[32m[0906 19-45-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03409, current rewards: 10.89577, mean: 0.05188
[32m[0906 19-45-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03398, current rewards: 16.31886, mean: 0.06276
[32m[0906 19-45-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03390, current rewards: 21.74531, mean: 0.07015
[32m[0906 19-45-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03387, current rewards: 27.16696, mean: 0.07546
[32m[0906 19-45-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03384, current rewards: 32.59436, mean: 0.07950
[32m[0906 19-45-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03382, current rewards: 38.02387, mean: 0.08266
[32m[0906 19-45-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03377, current rewards: 43.44718, mean: 0.08519
[32m[0906 19-45-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03383, current rewards: 42.20698, mean: 0.07537
[32m[0906 19-45-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03396, current rewards: 37.86834, mean: 0.06208
[32m[0906 19-45-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03412, current rewards: 16.17909, mean: 0.02451
[32m[0906 19-46-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03418, current rewards: -37.18891, mean: -0.05238
[32m[0906 19-46-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03414, current rewards: -137.18891, mean: -0.18051
[32m[0906 19-46-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03411, current rewards: -237.18891, mean: -0.29283
[32m[0906 19-46-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03409, current rewards: -337.18891, mean: -0.39208
[32m[0906 19-46-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03406, current rewards: -437.18891, mean: -0.48043
[32m[0906 19-46-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03404, current rewards: -537.18891, mean: -0.55957
[32m[0906 19-46-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03402, current rewards: -637.18891, mean: -0.63088
[32m[0906 19-46-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03400, current rewards: -737.18891, mean: -0.69546
[32m[0906 19-46-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03392, current rewards: -837.18891, mean: -0.75422
[32m[0906 19-46-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03388, current rewards: -872.97537, mean: -0.75256
[32m[0906 19-46-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03382, current rewards: -867.50479, mean: -0.71695
[32m[0906 19-46-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03378, current rewards: -862.03796, mean: -0.68416
[32m[0906 19-46-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03372, current rewards: -856.56750, mean: -0.65387
[32m[0906 19-46-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03368, current rewards: -851.10203, mean: -0.62581
[32m[0906 19-46-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03363, current rewards: -845.62844, mean: -0.59974
[32m[0906 19-46-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03360, current rewards: -840.15719, mean: -0.57545
[32m[0906 19-46-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03357, current rewards: -834.49474, mean: -0.55265
[32m[0906 19-46-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03353, current rewards: -829.00204, mean: -0.53141
[32m[0906 19-46-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03351, current rewards: -823.50836, mean: -0.51150
[32m[0906 19-46-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03350, current rewards: -836.99044, mean: -0.50421
[32m[0906 19-46-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03350, current rewards: -852.70688, mean: -0.49866
[32m[0906 19-46-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03362, current rewards: -906.11712, mean: -0.51484
[32m[0906 19-46-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03371, current rewards: -972.38952, mean: -0.53723
[32m[0906 19-46-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03383, current rewards: -1026.68527, mean: -0.55198
[32m[0906 19-46-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03393, current rewards: -1053.63759, mean: -0.55164
[32m[0906 19-46-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03392, current rewards: -1052.06802, mean: -0.53677
[32m[0906 19-46-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03391, current rewards: -1046.35315, mean: -0.52057
[32m[0906 19-46-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03391, current rewards: -1040.64034, mean: -0.50517
[32m[0906 19-46-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03390, current rewards: -1034.92618, mean: -0.49049
[32m[0906 19-46-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03390, current rewards: -1029.21067, mean: -0.47649
[32m[0906 19-46-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03389, current rewards: -1023.49650, mean: -0.46312
[32m[0906 19-46-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03388, current rewards: -1017.78371, mean: -0.45035
[32m[0906 19-46-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03388, current rewards: -1014.30059, mean: -0.43909
[32m[0906 19-46-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03388, current rewards: -1014.88466, mean: -0.43004
[32m[0906 19-46-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03387, current rewards: -1009.29351, mean: -0.41879
[32m[0906 19-47-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03386, current rewards: -1003.66482, mean: -0.40799
[32m[0906 19-47-01 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 19-47-01 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-47-02 @MBExp.py:227][0m Rewards obtained: [-999.2147712305464], Lows: [611], Highs: [14], Total time: 9512.434291999996
[32m[0906 19-50-47 @MBExp.py:144][0m ####################################################################
[32m[0906 19-50-47 @MBExp.py:145][0m Starting training iteration 111.
[32m[0906 19-50-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03309, current rewards: 0.98086, mean: 0.09809
[32m[0906 19-50-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03364, current rewards: 6.16049, mean: 0.10267
[32m[0906 19-50-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03361, current rewards: 11.33734, mean: 0.10307
[32m[0906 19-50-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03351, current rewards: 16.51405, mean: 0.10321
[32m[0906 19-50-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03355, current rewards: 21.69177, mean: 0.10329
[32m[0906 19-50-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03347, current rewards: 26.75091, mean: 0.10289
[32m[0906 19-50-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03347, current rewards: 32.16536, mean: 0.10376
[32m[0906 19-50-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03348, current rewards: 37.63586, mean: 0.10454
[32m[0906 19-51-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03348, current rewards: 43.10265, mean: 0.10513
[32m[0906 19-51-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03348, current rewards: 48.56616, mean: 0.10558
[32m[0906 19-51-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03344, current rewards: 54.03159, mean: 0.10594
[32m[0906 19-51-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03347, current rewards: 59.49508, mean: 0.10624
[32m[0906 19-51-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03349, current rewards: 64.96018, mean: 0.10649
[32m[0906 19-51-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03348, current rewards: 62.94814, mean: 0.09538
[32m[0906 19-51-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03350, current rewards: 60.93076, mean: 0.08582
[32m[0906 19-51-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03351, current rewards: 66.32576, mean: 0.08727
[32m[0906 19-51-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03352, current rewards: 71.71337, mean: 0.08854
[32m[0906 19-51-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03352, current rewards: 77.10843, mean: 0.08966
[32m[0906 19-51-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03352, current rewards: 82.49984, mean: 0.09066
[32m[0906 19-51-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03352, current rewards: 87.89166, mean: 0.09155
[32m[0906 19-51-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03351, current rewards: 93.28799, mean: 0.09236
[32m[0906 19-51-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03353, current rewards: 98.68184, mean: 0.09310
[32m[0906 19-51-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03348, current rewards: 104.03471, mean: 0.09372
[32m[0906 19-51-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03345, current rewards: 109.49602, mean: 0.09439
[32m[0906 19-51-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03341, current rewards: 114.95309, mean: 0.09500
[32m[0906 19-51-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03338, current rewards: 120.41017, mean: 0.09556
[32m[0906 19-51-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03335, current rewards: 125.86450, mean: 0.09608
[32m[0906 19-51-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03331, current rewards: 131.26495, mean: 0.09652
[32m[0906 19-51-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03329, current rewards: 136.43541, mean: 0.09676
[32m[0906 19-51-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03328, current rewards: 141.59988, mean: 0.09699
[32m[0906 19-51-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03326, current rewards: 147.00423, mean: 0.09735
[32m[0906 19-51-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03323, current rewards: 152.35874, mean: 0.09767
[32m[0906 19-51-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03321, current rewards: 157.70907, mean: 0.09796
[32m[0906 19-51-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03319, current rewards: 163.05429, mean: 0.09823
[32m[0906 19-51-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03317, current rewards: 168.40481, mean: 0.09848
[32m[0906 19-51-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03316, current rewards: 173.74585, mean: 0.09872
[32m[0906 19-51-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03315, current rewards: 179.10013, mean: 0.09895
[32m[0906 19-51-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03314, current rewards: 184.44966, mean: 0.09917
[32m[0906 19-51-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03314, current rewards: 189.79769, mean: 0.09937
[32m[0906 19-51-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03316, current rewards: 195.14186, mean: 0.09956
[32m[0906 19-51-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03317, current rewards: 196.33541, mean: 0.09768
[32m[0906 19-51-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03318, current rewards: 201.74827, mean: 0.09794
[32m[0906 19-51-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03318, current rewards: 207.17126, mean: 0.09819
[32m[0906 19-51-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03319, current rewards: 212.58723, mean: 0.09842
[32m[0906 19-52-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03320, current rewards: 218.00929, mean: 0.09865
[32m[0906 19-52-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03321, current rewards: 223.44139, mean: 0.09887
[32m[0906 19-52-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03321, current rewards: 228.78447, mean: 0.09904
[32m[0906 19-52-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03323, current rewards: 234.20024, mean: 0.09924
[32m[0906 19-52-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03323, current rewards: 239.61791, mean: 0.09943
[32m[0906 19-52-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03323, current rewards: 245.03334, mean: 0.09961
[32m[0906 19-52-10 @Agent.py:117][0m Average action selection time: 0.0332
[32m[0906 19-52-10 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-52-10 @MBExp.py:227][0m Rewards obtained: [249.36121595731504], Lows: [8], Highs: [2], Total time: 9596.317955999997
[32m[0906 19-55-58 @MBExp.py:144][0m ####################################################################
[32m[0906 19-55-58 @MBExp.py:145][0m Starting training iteration 112.
[32m[0906 19-55-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03322, current rewards: -9.63211, mean: -0.96321
[32m[0906 19-56-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03345, current rewards: -5.26532, mean: -0.08776
[32m[0906 19-56-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03350, current rewards: -0.91228, mean: -0.00829
[32m[0906 19-56-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03350, current rewards: 3.43619, mean: 0.02148
[32m[0906 19-56-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03346, current rewards: 7.81957, mean: 0.03724
[32m[0906 19-56-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03349, current rewards: 12.18234, mean: 0.04686
[32m[0906 19-56-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03342, current rewards: 16.47472, mean: 0.05314
[32m[0906 19-56-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03347, current rewards: 20.76584, mean: 0.05768
[32m[0906 19-56-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03350, current rewards: 25.05828, mean: 0.06112
[32m[0906 19-56-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03350, current rewards: 29.34733, mean: 0.06380
[32m[0906 19-56-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03349, current rewards: 33.63483, mean: 0.06595
[32m[0906 19-56-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03350, current rewards: 37.92504, mean: 0.06772
[32m[0906 19-56-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03354, current rewards: 40.21301, mean: 0.06592
[32m[0906 19-56-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03355, current rewards: 44.71465, mean: 0.06775
[32m[0906 19-56-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03356, current rewards: 49.27904, mean: 0.06941
[32m[0906 19-56-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03355, current rewards: 53.84114, mean: 0.07084
[32m[0906 19-56-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03355, current rewards: 58.40033, mean: 0.07210
[32m[0906 19-56-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03355, current rewards: 62.96309, mean: 0.07321
[32m[0906 19-56-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03359, current rewards: 64.61171, mean: 0.07100
[32m[0906 19-56-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03359, current rewards: 68.07993, mean: 0.07092
[32m[0906 19-56-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03360, current rewards: 71.54442, mean: 0.07084
[32m[0906 19-56-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03359, current rewards: 75.31929, mean: 0.07106
[32m[0906 19-56-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03352, current rewards: 79.70344, mean: 0.07180
[32m[0906 19-56-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03349, current rewards: 84.08758, mean: 0.07249
[32m[0906 19-56-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03345, current rewards: 88.47172, mean: 0.07312
[32m[0906 19-56-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03342, current rewards: 92.85586, mean: 0.07370
[32m[0906 19-56-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03338, current rewards: 97.24001, mean: 0.07423
[32m[0906 19-56-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03334, current rewards: 101.62415, mean: 0.07472
[32m[0906 19-56-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03332, current rewards: 106.00829, mean: 0.07518
[32m[0906 19-56-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03330, current rewards: 110.13794, mean: 0.07544
[32m[0906 19-56-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03327, current rewards: 63.28624, mean: 0.04191
[32m[0906 19-56-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03326, current rewards: 13.28624, mean: 0.00852
[32m[0906 19-56-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03324, current rewards: -36.71376, mean: -0.02280
[32m[0906 19-56-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03321, current rewards: -86.71376, mean: -0.05224
[32m[0906 19-56-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03319, current rewards: -136.71376, mean: -0.07995
[32m[0906 19-56-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03318, current rewards: -186.71376, mean: -0.10609
[32m[0906 19-56-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03316, current rewards: -236.71376, mean: -0.13078
[32m[0906 19-57-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03315, current rewards: -286.71376, mean: -0.15415
[32m[0906 19-57-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03315, current rewards: -336.71376, mean: -0.17629
[32m[0906 19-57-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03316, current rewards: -386.71376, mean: -0.19730
[32m[0906 19-57-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03317, current rewards: -436.71376, mean: -0.21727
[32m[0906 19-57-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03317, current rewards: -486.71376, mean: -0.23627
[32m[0906 19-57-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03319, current rewards: -536.71376, mean: -0.25437
[32m[0906 19-57-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03320, current rewards: -586.71376, mean: -0.27163
[32m[0906 19-57-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03321, current rewards: -636.71376, mean: -0.28811
[32m[0906 19-57-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03321, current rewards: -686.71376, mean: -0.30386
[32m[0906 19-57-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03322, current rewards: -736.71376, mean: -0.31892
[32m[0906 19-57-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03322, current rewards: -786.71376, mean: -0.33335
[32m[0906 19-57-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03323, current rewards: -836.71376, mean: -0.34718
[32m[0906 19-57-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03323, current rewards: -886.71376, mean: -0.36045
[32m[0906 19-57-22 @Agent.py:117][0m Average action selection time: 0.0332
[32m[0906 19-57-22 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-57-22 @MBExp.py:227][0m Rewards obtained: [-926.7137624521182], Lows: [6], Highs: [1039], Total time: 9680.210933999997
[32m[0906 20-01-11 @MBExp.py:144][0m ####################################################################
[32m[0906 20-01-11 @MBExp.py:145][0m Starting training iteration 113.
[32m[0906 20-01-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03298, current rewards: -6.38532, mean: -0.63853
[32m[0906 20-01-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03335, current rewards: -1.55589, mean: -0.02593
[32m[0906 20-01-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03339, current rewards: 3.31668, mean: 0.03015
[32m[0906 20-01-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03351, current rewards: 8.18691, mean: 0.05117
[32m[0906 20-01-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03343, current rewards: 13.05769, mean: 0.06218
[32m[0906 20-01-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03348, current rewards: 18.05316, mean: 0.06944
[32m[0906 20-01-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03346, current rewards: 22.95191, mean: 0.07404
[32m[0906 20-01-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03346, current rewards: 27.84984, mean: 0.07736
[32m[0906 20-01-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03345, current rewards: 30.52766, mean: 0.07446
[32m[0906 20-01-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03348, current rewards: 35.03784, mean: 0.07617
[32m[0906 20-01-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03350, current rewards: 39.54662, mean: 0.07754
[32m[0906 20-01-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03347, current rewards: 44.05266, mean: 0.07867
[32m[0906 20-01-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03349, current rewards: 48.55904, mean: 0.07960
[32m[0906 20-01-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03351, current rewards: 53.01585, mean: 0.08033
[32m[0906 20-01-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03352, current rewards: 57.75068, mean: 0.08134
[32m[0906 20-01-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03354, current rewards: 57.45205, mean: 0.07559
[32m[0906 20-01-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03354, current rewards: 62.50473, mean: 0.07717
[32m[0906 20-01-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03354, current rewards: 67.56038, mean: 0.07856
[32m[0906 20-01-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03355, current rewards: 72.61225, mean: 0.07979
[32m[0906 20-01-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03355, current rewards: 77.66965, mean: 0.08091
[32m[0906 20-01-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03355, current rewards: 82.72477, mean: 0.08191
[32m[0906 20-01-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03356, current rewards: 87.78086, mean: 0.08281
[32m[0906 20-01-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03354, current rewards: 93.00581, mean: 0.08379
[32m[0906 20-01-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03370, current rewards: 98.08360, mean: 0.08455
[32m[0906 20-01-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03387, current rewards: 103.17013, mean: 0.08526
[32m[0906 20-01-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03398, current rewards: 102.64926, mean: 0.08147
[32m[0906 20-01-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03394, current rewards: 52.64926, mean: 0.04019
[32m[0906 20-01-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03388, current rewards: 2.64926, mean: 0.00195
[32m[0906 20-01-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03384, current rewards: -47.35074, mean: -0.03358
[32m[0906 20-02-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03380, current rewards: -97.35074, mean: -0.06668
[32m[0906 20-02-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03376, current rewards: -147.35074, mean: -0.09758
[32m[0906 20-02-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03372, current rewards: -197.35074, mean: -0.12651
[32m[0906 20-02-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03368, current rewards: -247.35074, mean: -0.15363
[32m[0906 20-02-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03365, current rewards: -289.70123, mean: -0.17452
[32m[0906 20-02-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03363, current rewards: -280.64779, mean: -0.16412
[32m[0906 20-02-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03360, current rewards: -271.59435, mean: -0.15431
[32m[0906 20-02-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03358, current rewards: -262.54092, mean: -0.14505
[32m[0906 20-02-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03355, current rewards: -253.48748, mean: -0.13628
[32m[0906 20-02-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03353, current rewards: -246.35088, mean: -0.12898
[32m[0906 20-02-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03354, current rewards: -243.60418, mean: -0.12429
[32m[0906 20-02-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03354, current rewards: -240.85749, mean: -0.11983
[32m[0906 20-02-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03354, current rewards: -238.11079, mean: -0.11559
[32m[0906 20-02-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03354, current rewards: -235.36410, mean: -0.11155
[32m[0906 20-02-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03354, current rewards: -277.97956, mean: -0.12869
[32m[0906 20-02-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03354, current rewards: -327.97956, mean: -0.14841
[32m[0906 20-02-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03355, current rewards: -377.97956, mean: -0.16725
[32m[0906 20-02-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03355, current rewards: -427.97956, mean: -0.18527
[32m[0906 20-02-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03355, current rewards: -477.97956, mean: -0.20253
[32m[0906 20-02-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03355, current rewards: -527.97956, mean: -0.21908
[32m[0906 20-02-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03354, current rewards: -577.97956, mean: -0.23495
[32m[0906 20-02-36 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 20-02-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-02-36 @MBExp.py:227][0m Rewards obtained: [-617.9795616034677], Lows: [9], Highs: [779], Total time: 9764.866280999997
[32m[0906 20-06-27 @MBExp.py:144][0m ####################################################################
[32m[0906 20-06-27 @MBExp.py:145][0m Starting training iteration 114.
[32m[0906 20-06-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03250, current rewards: -12.16712, mean: -1.21671
[32m[0906 20-06-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03345, current rewards: -5.12875, mean: -0.08548
[32m[0906 20-06-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03352, current rewards: 1.66051, mean: 0.01510
[32m[0906 20-06-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03349, current rewards: 8.43953, mean: 0.05275
[32m[0906 20-06-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03354, current rewards: 15.22834, mean: 0.07252
[32m[0906 20-06-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03357, current rewards: 21.87391, mean: 0.08413
[32m[0906 20-06-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03359, current rewards: 28.84340, mean: 0.09304
[32m[0906 20-06-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03355, current rewards: 35.80878, mean: 0.09947
[32m[0906 20-06-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03357, current rewards: 42.76463, mean: 0.10430
[32m[0906 20-06-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03357, current rewards: 49.73100, mean: 0.10811
[32m[0906 20-06-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03352, current rewards: 56.69231, mean: 0.11116
[32m[0906 20-06-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03360, current rewards: 60.78397, mean: 0.10854
[32m[0906 20-06-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03359, current rewards: 65.91155, mean: 0.10805
[32m[0906 20-06-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03358, current rewards: 71.00653, mean: 0.10759
[32m[0906 20-06-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03359, current rewards: 76.10159, mean: 0.10719
[32m[0906 20-06-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03359, current rewards: 81.22234, mean: 0.10687
[32m[0906 20-06-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03360, current rewards: 86.34099, mean: 0.10659
[32m[0906 20-06-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03361, current rewards: 91.46461, mean: 0.10635
[32m[0906 20-06-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03361, current rewards: 96.58377, mean: 0.10614
[32m[0906 20-06-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03361, current rewards: 101.70564, mean: 0.10594
[32m[0906 20-07-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03360, current rewards: 106.82307, mean: 0.10577
[32m[0906 20-07-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03356, current rewards: 111.94149, mean: 0.10561
[32m[0906 20-07-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03352, current rewards: 117.28245, mean: 0.10566
[32m[0906 20-07-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03347, current rewards: 122.44133, mean: 0.10555
[32m[0906 20-07-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03344, current rewards: 127.60000, mean: 0.10545
[32m[0906 20-07-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03347, current rewards: 130.95025, mean: 0.10393
[32m[0906 20-07-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03356, current rewards: 136.93916, mean: 0.10453
[32m[0906 20-07-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03352, current rewards: 143.04388, mean: 0.10518
[32m[0906 20-07-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03349, current rewards: 149.14556, mean: 0.10578
[32m[0906 20-07-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03346, current rewards: 155.24938, mean: 0.10634
[32m[0906 20-07-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03346, current rewards: 155.55627, mean: 0.10302
[32m[0906 20-07-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03343, current rewards: 161.81525, mean: 0.10373
[32m[0906 20-07-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03341, current rewards: 168.07887, mean: 0.10440
[32m[0906 20-07-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03339, current rewards: 174.33981, mean: 0.10502
[32m[0906 20-07-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03337, current rewards: 180.60348, mean: 0.10562
[32m[0906 20-07-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03334, current rewards: 186.86971, mean: 0.10618
[32m[0906 20-07-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03333, current rewards: 193.13410, mean: 0.10670
[32m[0906 20-07-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03332, current rewards: 199.40044, mean: 0.10720
[32m[0906 20-07-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03329, current rewards: 201.13262, mean: 0.10531
[32m[0906 20-07-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03330, current rewards: 207.31528, mean: 0.10577
[32m[0906 20-07-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03331, current rewards: 213.50468, mean: 0.10622
[32m[0906 20-07-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03333, current rewards: 219.69614, mean: 0.10665
[32m[0906 20-07-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03333, current rewards: 225.88391, mean: 0.10705
[32m[0906 20-07-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03334, current rewards: 232.06987, mean: 0.10744
[32m[0906 20-07-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03334, current rewards: 238.26088, mean: 0.10781
[32m[0906 20-07-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03335, current rewards: 244.45002, mean: 0.10816
[32m[0906 20-07-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03335, current rewards: 250.63843, mean: 0.10850
[32m[0906 20-07-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03336, current rewards: 256.00384, mean: 0.10848
[32m[0906 20-07-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03336, current rewards: 263.15890, mean: 0.10919
[32m[0906 20-07-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03336, current rewards: 270.31144, mean: 0.10988
[32m[0906 20-07-51 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 20-07-51 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-07-51 @MBExp.py:227][0m Rewards obtained: [276.02842882533383], Lows: [12], Highs: [4], Total time: 9849.059681999997
[32m[0906 20-11-43 @MBExp.py:144][0m ####################################################################
[32m[0906 20-11-43 @MBExp.py:145][0m Starting training iteration 115.
[32m[0906 20-11-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03764, current rewards: -14.69157, mean: -1.46916
[32m[0906 20-11-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03483, current rewards: -24.94155, mean: -0.41569
[32m[0906 20-11-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03428, current rewards: -18.06155, mean: -0.16420
[32m[0906 20-11-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03408, current rewards: -11.17959, mean: -0.06987
[32m[0906 20-11-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03393, current rewards: -4.30378, mean: -0.02049
[32m[0906 20-11-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03395, current rewards: -2.07898, mean: -0.00800
[32m[0906 20-11-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03390, current rewards: 4.36305, mean: 0.01407
[32m[0906 20-11-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03382, current rewards: 10.80437, mean: 0.03001
[32m[0906 20-11-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03381, current rewards: 17.24404, mean: 0.04206
[32m[0906 20-11-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03379, current rewards: 23.68176, mean: 0.05148
[32m[0906 20-12-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03377, current rewards: 30.12059, mean: 0.05906
[32m[0906 20-12-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03373, current rewards: 36.55823, mean: 0.06528
[32m[0906 20-12-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03373, current rewards: 43.00143, mean: 0.07049
[32m[0906 20-12-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03372, current rewards: 49.53582, mean: 0.07505
[32m[0906 20-12-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03374, current rewards: 52.44349, mean: 0.07386
[32m[0906 20-12-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03374, current rewards: 59.54004, mean: 0.07834
[32m[0906 20-12-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03373, current rewards: 66.63659, mean: 0.08227
[32m[0906 20-12-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03371, current rewards: 73.73314, mean: 0.08574
[32m[0906 20-12-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03371, current rewards: 80.82969, mean: 0.08882
[32m[0906 20-12-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03370, current rewards: 87.92624, mean: 0.09159
[32m[0906 20-12-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03371, current rewards: 48.20362, mean: 0.04773
[32m[0906 20-12-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03363, current rewards: -1.79638, mean: -0.00169
[32m[0906 20-12-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03359, current rewards: -51.79638, mean: -0.04666
[32m[0906 20-12-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03356, current rewards: -101.79638, mean: -0.08776
[32m[0906 20-12-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03353, current rewards: -151.79638, mean: -0.12545
[32m[0906 20-12-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03349, current rewards: -201.79638, mean: -0.16016
[32m[0906 20-12-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03345, current rewards: -251.79638, mean: -0.19221
[32m[0906 20-12-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03342, current rewards: -301.79638, mean: -0.22191
[32m[0906 20-12-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03339, current rewards: -351.79638, mean: -0.24950
[32m[0906 20-12-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03336, current rewards: -401.79638, mean: -0.27520
[32m[0906 20-12-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03333, current rewards: -451.79638, mean: -0.29920
[32m[0906 20-12-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03331, current rewards: -501.79638, mean: -0.32166
[32m[0906 20-12-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03329, current rewards: -551.79638, mean: -0.34273
[32m[0906 20-12-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03328, current rewards: -601.79638, mean: -0.36253
[32m[0906 20-12-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03326, current rewards: -651.79638, mean: -0.38117
[32m[0906 20-12-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03323, current rewards: -701.79638, mean: -0.39875
[32m[0906 20-12-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03322, current rewards: -751.79638, mean: -0.41536
[32m[0906 20-12-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03321, current rewards: -801.79638, mean: -0.43107
[32m[0906 20-12-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03319, current rewards: -851.79638, mean: -0.44597
[32m[0906 20-12-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03317, current rewards: -901.79638, mean: -0.46010
[32m[0906 20-12-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03318, current rewards: -951.79638, mean: -0.47353
[32m[0906 20-12-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03318, current rewards: -1001.79638, mean: -0.48631
[32m[0906 20-12-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03320, current rewards: -1051.79638, mean: -0.49848
[32m[0906 20-12-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03320, current rewards: -1101.79638, mean: -0.51009
[32m[0906 20-12-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03321, current rewards: -1151.79638, mean: -0.52117
[32m[0906 20-12-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03322, current rewards: -1201.79638, mean: -0.53177
[32m[0906 20-13-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03322, current rewards: -1251.79638, mean: -0.54190
[32m[0906 20-13-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03322, current rewards: -1301.79638, mean: -0.55161
[32m[0906 20-13-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03323, current rewards: -1351.79638, mean: -0.56091
[32m[0906 20-13-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03323, current rewards: -1401.79638, mean: -0.56984
[32m[0906 20-13-07 @Agent.py:117][0m Average action selection time: 0.0332
[32m[0906 20-13-07 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-13-07 @MBExp.py:227][0m Rewards obtained: [-1441.7963799148024], Lows: [19], Highs: [1533], Total time: 9932.956613999997
[32m[0906 20-17-03 @MBExp.py:144][0m ####################################################################
[32m[0906 20-17-03 @MBExp.py:145][0m Starting training iteration 116.
[32m[0906 20-17-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03466, current rewards: -10.25306, mean: -1.02531
[32m[0906 20-17-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03863, current rewards: -0.09585, mean: -0.00160
[32m[0906 20-17-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03635, current rewards: 7.33378, mean: 0.06667
[32m[0906 20-17-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03552, current rewards: 14.76596, mean: 0.09229
[32m[0906 20-17-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03509, current rewards: 22.19809, mean: 0.10571
[32m[0906 20-17-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03482, current rewards: 29.56935, mean: 0.11373
[32m[0906 20-17-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03462, current rewards: 36.95713, mean: 0.11922
[32m[0906 20-17-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03448, current rewards: 44.35070, mean: 0.12320
[32m[0906 20-17-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03437, current rewards: 51.73701, mean: 0.12619
[32m[0906 20-17-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03428, current rewards: 59.12760, mean: 0.12854
[32m[0906 20-17-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03425, current rewards: 66.51782, mean: 0.13043
[32m[0906 20-17-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03415, current rewards: 73.92347, mean: 0.13201
[32m[0906 20-17-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03409, current rewards: 84.15412, mean: 0.13796
[32m[0906 20-17-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03404, current rewards: 94.15120, mean: 0.14265
[32m[0906 20-17-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03402, current rewards: 104.83716, mean: 0.14766
[32m[0906 20-17-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03397, current rewards: 115.61514, mean: 0.15213
[32m[0906 20-17-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03394, current rewards: 126.14216, mean: 0.15573
[32m[0906 20-17-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03393, current rewards: 136.88230, mean: 0.15917
[32m[0906 20-17-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03392, current rewards: 147.67606, mean: 0.16228
[32m[0906 20-17-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03391, current rewards: 158.20495, mean: 0.16480
[32m[0906 20-17-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03385, current rewards: 168.98407, mean: 0.16731
[32m[0906 20-17-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03381, current rewards: 179.52845, mean: 0.16937
[32m[0906 20-17-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03374, current rewards: 190.77427, mean: 0.17187
[32m[0906 20-17-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03369, current rewards: 202.20408, mean: 0.17431
[32m[0906 20-17-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03364, current rewards: 213.61756, mean: 0.17654
[32m[0906 20-17-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03363, current rewards: 176.36128, mean: 0.13997
[32m[0906 20-17-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03369, current rewards: 122.63169, mean: 0.09361
[32m[0906 20-17-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03370, current rewards: 77.67263, mean: 0.05711
[32m[0906 20-17-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03372, current rewards: 21.83466, mean: 0.01549
[32m[0906 20-17-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03373, current rewards: -33.94497, mean: -0.02325
[32m[0906 20-17-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03373, current rewards: -43.21223, mean: -0.02862
[32m[0906 20-17-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03371, current rewards: -40.00343, mean: -0.02564
[32m[0906 20-17-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03368, current rewards: -33.11982, mean: -0.02057
[32m[0906 20-17-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03365, current rewards: -26.29323, mean: -0.01584
[32m[0906 20-18-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03362, current rewards: -19.46784, mean: -0.01138
[32m[0906 20-18-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03360, current rewards: -27.30408, mean: -0.01551
[32m[0906 20-18-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03357, current rewards: -21.62873, mean: -0.01195
[32m[0906 20-18-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03354, current rewards: -15.94070, mean: -0.00857
[32m[0906 20-18-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03358, current rewards: -27.31366, mean: -0.01430
[32m[0906 20-18-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03356, current rewards: -21.52350, mean: -0.01098
[32m[0906 20-18-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03358, current rewards: -18.39595, mean: -0.00915
[32m[0906 20-18-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03370, current rewards: -66.76805, mean: -0.03241
[32m[0906 20-18-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03371, current rewards: -69.44517, mean: -0.03291
[32m[0906 20-18-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03371, current rewards: -63.22258, mean: -0.02927
[32m[0906 20-18-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03371, current rewards: -57.00102, mean: -0.02579
[32m[0906 20-18-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03373, current rewards: -51.12656, mean: -0.02262
[32m[0906 20-18-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03381, current rewards: -52.72617, mean: -0.02283
[32m[0906 20-18-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03383, current rewards: -115.27206, mean: -0.04884
[32m[0906 20-18-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03387, current rewards: -174.65590, mean: -0.07247
[32m[0906 20-18-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03393, current rewards: -219.50408, mean: -0.08923
[32m[0906 20-18-28 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 20-18-28 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-18-29 @MBExp.py:227][0m Rewards obtained: [-245.23724007914845], Lows: [251], Highs: [96], Total time: 10018.657428999997
[32m[0906 20-22-25 @MBExp.py:144][0m ####################################################################
[32m[0906 20-22-25 @MBExp.py:145][0m Starting training iteration 117.
[32m[0906 20-22-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03295, current rewards: -8.38257, mean: -0.83826
[32m[0906 20-22-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03368, current rewards: -0.87054, mean: -0.01451
[32m[0906 20-22-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03363, current rewards: 6.57972, mean: 0.05982
[32m[0906 20-22-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03357, current rewards: 14.02167, mean: 0.08764
[32m[0906 20-22-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03353, current rewards: 21.46490, mean: 0.10221
[32m[0906 20-22-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03352, current rewards: 28.83882, mean: 0.11092
[32m[0906 20-22-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03351, current rewards: 33.85748, mean: 0.10922
[32m[0906 20-22-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03350, current rewards: 39.57606, mean: 0.10993
[32m[0906 20-22-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03348, current rewards: 45.29855, mean: 0.11048
[32m[0906 20-22-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03348, current rewards: 51.02182, mean: 0.11092
[32m[0906 20-22-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03344, current rewards: 56.74717, mean: 0.11127
[32m[0906 20-22-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03344, current rewards: 62.47382, mean: 0.11156
[32m[0906 20-22-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03346, current rewards: 68.18982, mean: 0.11179
[32m[0906 20-22-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03347, current rewards: 74.06508, mean: 0.11222
[32m[0906 20-22-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03348, current rewards: 79.86030, mean: 0.11248
[32m[0906 20-22-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03349, current rewards: 82.29760, mean: 0.10829
[32m[0906 20-22-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03348, current rewards: 89.51790, mean: 0.11052
[32m[0906 20-22-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03349, current rewards: 96.74336, mean: 0.11249
[32m[0906 20-22-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03351, current rewards: 103.96351, mean: 0.11425
[32m[0906 20-22-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03349, current rewards: 111.18667, mean: 0.11582
[32m[0906 20-22-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03345, current rewards: 118.40799, mean: 0.11724
[32m[0906 20-23-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03343, current rewards: 125.45491, mean: 0.11835
[32m[0906 20-23-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03339, current rewards: 132.55399, mean: 0.11942
[32m[0906 20-23-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03337, current rewards: 139.65490, mean: 0.12039
[32m[0906 20-23-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03345, current rewards: 142.48709, mean: 0.11776
[32m[0906 20-23-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03353, current rewards: 150.03725, mean: 0.11908
[32m[0906 20-23-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03364, current rewards: 157.42142, mean: 0.12017
[32m[0906 20-23-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03371, current rewards: 164.89479, mean: 0.12125
[32m[0906 20-23-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03380, current rewards: 171.86211, mean: 0.12189
[32m[0906 20-23-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03388, current rewards: 179.09979, mean: 0.12267
[32m[0906 20-23-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03399, current rewards: 185.37558, mean: 0.12277
[32m[0906 20-23-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03395, current rewards: 192.03226, mean: 0.12310
[32m[0906 20-23-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03391, current rewards: 198.66552, mean: 0.12339
[32m[0906 20-23-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03388, current rewards: 205.30495, mean: 0.12368
[32m[0906 20-23-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03384, current rewards: 211.94794, mean: 0.12395
[32m[0906 20-23-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03380, current rewards: 218.58792, mean: 0.12420
[32m[0906 20-23-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03377, current rewards: 225.22264, mean: 0.12443
[32m[0906 20-23-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03375, current rewards: 231.86202, mean: 0.12466
[32m[0906 20-23-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03371, current rewards: 238.50190, mean: 0.12487
[32m[0906 20-23-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03372, current rewards: 245.14442, mean: 0.12507
[32m[0906 20-23-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03371, current rewards: 250.44521, mean: 0.12460
[32m[0906 20-23-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03371, current rewards: 256.79417, mean: 0.12466
[32m[0906 20-23-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03370, current rewards: 263.14265, mean: 0.12471
[32m[0906 20-23-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03370, current rewards: 269.48970, mean: 0.12476
[32m[0906 20-23-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03370, current rewards: 275.83886, mean: 0.12481
[32m[0906 20-23-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03370, current rewards: 282.20860, mean: 0.12487
[32m[0906 20-23-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03369, current rewards: 288.59093, mean: 0.12493
[32m[0906 20-23-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03369, current rewards: 294.93882, mean: 0.12497
[32m[0906 20-23-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03368, current rewards: 301.28842, mean: 0.12502
[32m[0906 20-23-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03367, current rewards: 307.64053, mean: 0.12506
[32m[0906 20-23-50 @Agent.py:117][0m Average action selection time: 0.0337
[32m[0906 20-23-50 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-23-50 @MBExp.py:227][0m Rewards obtained: [312.7147252484786], Lows: [8], Highs: [4], Total time: 10103.636857999998
[32m[0906 20-27-50 @MBExp.py:144][0m ####################################################################
[32m[0906 20-27-50 @MBExp.py:145][0m Starting training iteration 118.
[32m[0906 20-27-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03480, current rewards: -13.82297, mean: -1.38230
[32m[0906 20-27-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03396, current rewards: -78.23775, mean: -1.30396
[32m[0906 20-27-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03376, current rewards: -70.76546, mean: -0.64332
[32m[0906 20-27-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03373, current rewards: -62.82704, mean: -0.39267
[32m[0906 20-27-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03358, current rewards: -56.56230, mean: -0.26934
[32m[0906 20-27-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03360, current rewards: -50.91015, mean: -0.19581
[32m[0906 20-28-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03361, current rewards: -45.26001, mean: -0.14600
[32m[0906 20-28-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03360, current rewards: -39.61518, mean: -0.11004
[32m[0906 20-28-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03358, current rewards: -33.97029, mean: -0.08285
[32m[0906 20-28-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03358, current rewards: -28.32619, mean: -0.06158
[32m[0906 20-28-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03362, current rewards: -21.32728, mean: -0.04182
[32m[0906 20-28-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03361, current rewards: -15.74501, mean: -0.02812
[32m[0906 20-28-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03357, current rewards: -10.15711, mean: -0.01665
[32m[0906 20-28-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03358, current rewards: -4.57470, mean: -0.00693
[32m[0906 20-28-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03359, current rewards: 1.00924, mean: 0.00142
[32m[0906 20-28-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03359, current rewards: 6.58990, mean: 0.00867
[32m[0906 20-28-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03359, current rewards: 12.17111, mean: 0.01503
[32m[0906 20-28-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03359, current rewards: 17.75572, mean: 0.02065
[32m[0906 20-28-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03354, current rewards: 21.60141, mean: 0.02374
[32m[0906 20-28-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03349, current rewards: 27.41842, mean: 0.02856
[32m[0906 20-28-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03346, current rewards: 33.27145, mean: 0.03294
[32m[0906 20-28-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03341, current rewards: 39.08485, mean: 0.03687
[32m[0906 20-28-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03338, current rewards: 44.90028, mean: 0.04045
[32m[0906 20-28-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03333, current rewards: 50.71368, mean: 0.04372
[32m[0906 20-28-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03329, current rewards: 56.53156, mean: 0.04672
[32m[0906 20-28-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03326, current rewards: 62.34953, mean: 0.04948
[32m[0906 20-28-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03323, current rewards: 64.05938, mean: 0.04890
[32m[0906 20-28-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03320, current rewards: 69.01233, mean: 0.05074
[32m[0906 20-28-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03318, current rewards: 74.49278, mean: 0.05283
[32m[0906 20-28-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03315, current rewards: 80.95161, mean: 0.05545
[32m[0906 20-28-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03314, current rewards: 87.41043, mean: 0.05789
[32m[0906 20-28-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03313, current rewards: 93.86926, mean: 0.06017
[32m[0906 20-28-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03310, current rewards: 100.32808, mean: 0.06232
[32m[0906 20-28-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03308, current rewards: 106.78690, mean: 0.06433
[32m[0906 20-28-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03308, current rewards: 91.79137, mean: 0.05368
[32m[0906 20-28-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03306, current rewards: 41.79137, mean: 0.02375
[32m[0906 20-28-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03304, current rewards: -8.20863, mean: -0.00454
[32m[0906 20-28-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03303, current rewards: -58.20863, mean: -0.03129
[32m[0906 20-28-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03301, current rewards: -108.20863, mean: -0.05665
[32m[0906 20-28-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03300, current rewards: -158.20863, mean: -0.08072
[32m[0906 20-28-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03298, current rewards: -208.20863, mean: -0.10359
[32m[0906 20-28-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03297, current rewards: -258.20863, mean: -0.12534
[32m[0906 20-29-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03299, current rewards: -308.20863, mean: -0.14607
[32m[0906 20-29-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03300, current rewards: -358.20863, mean: -0.16584
[32m[0906 20-29-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03301, current rewards: -408.20863, mean: -0.18471
[32m[0906 20-29-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03302, current rewards: -458.20863, mean: -0.20275
[32m[0906 20-29-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03303, current rewards: -508.20863, mean: -0.22000
[32m[0906 20-29-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03303, current rewards: -558.20863, mean: -0.23653
[32m[0906 20-29-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03304, current rewards: -608.20863, mean: -0.25237
[32m[0906 20-29-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03304, current rewards: -658.20863, mean: -0.26756
[32m[0906 20-29-13 @Agent.py:117][0m Average action selection time: 0.0330
[32m[0906 20-29-13 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-29-13 @MBExp.py:227][0m Rewards obtained: [-698.2086251203457], Lows: [42], Highs: [811], Total time: 10187.043299999998
[32m[0906 20-33-14 @MBExp.py:144][0m ####################################################################
[32m[0906 20-33-14 @MBExp.py:145][0m Starting training iteration 119.
[32m[0906 20-33-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03289, current rewards: -6.30080, mean: -0.63008
[32m[0906 20-33-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03336, current rewards: -0.25524, mean: -0.00425
[32m[0906 20-33-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03343, current rewards: 5.78714, mean: 0.05261
[32m[0906 20-33-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03339, current rewards: 11.82756, mean: 0.07392
[32m[0906 20-33-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03346, current rewards: 17.93640, mean: 0.08541
[32m[0906 20-33-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03352, current rewards: 24.04866, mean: 0.09249
[32m[0906 20-33-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03347, current rewards: 30.15354, mean: 0.09727
[32m[0906 20-33-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03348, current rewards: 36.26526, mean: 0.10074
[32m[0906 20-33-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03348, current rewards: 42.37668, mean: 0.10336
[32m[0906 20-33-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03346, current rewards: 48.48643, mean: 0.10541
[32m[0906 20-33-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03352, current rewards: 50.66516, mean: 0.09934
[32m[0906 20-33-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03354, current rewards: 57.27121, mean: 0.10227
[32m[0906 20-33-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03354, current rewards: 63.70134, mean: 0.10443
[32m[0906 20-33-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03354, current rewards: 70.13313, mean: 0.10626
[32m[0906 20-33-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03353, current rewards: 76.56919, mean: 0.10784
[32m[0906 20-33-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03353, current rewards: 83.00157, mean: 0.10921
[32m[0906 20-33-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03354, current rewards: 87.30447, mean: 0.10778
[32m[0906 20-33-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03355, current rewards: 91.70432, mean: 0.10663
[32m[0906 20-33-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03354, current rewards: 98.16314, mean: 0.10787
[32m[0906 20-33-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03346, current rewards: 103.50513, mean: 0.10782
[32m[0906 20-33-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03344, current rewards: 106.66487, mean: 0.10561
[32m[0906 20-33-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03339, current rewards: 109.82460, mean: 0.10361
[32m[0906 20-33-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03336, current rewards: 112.98434, mean: 0.10179
[32m[0906 20-33-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03333, current rewards: 116.14407, mean: 0.10012
[32m[0906 20-33-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03329, current rewards: 69.33365, mean: 0.05730
[32m[0906 20-33-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03326, current rewards: 19.33365, mean: 0.01534
[32m[0906 20-33-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03323, current rewards: -30.66635, mean: -0.02341
[32m[0906 20-34-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03320, current rewards: -80.66635, mean: -0.05931
[32m[0906 20-34-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03319, current rewards: -111.23482, mean: -0.07889
[32m[0906 20-34-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03316, current rewards: -104.84023, mean: -0.07181
[32m[0906 20-34-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03315, current rewards: -98.44806, mean: -0.06520
[32m[0906 20-34-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03313, current rewards: -92.05686, mean: -0.05901
[32m[0906 20-34-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03311, current rewards: -85.66260, mean: -0.05321
[32m[0906 20-34-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03311, current rewards: -84.82083, mean: -0.05110
[32m[0906 20-34-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03310, current rewards: -78.72663, mean: -0.04604
[32m[0906 20-34-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03309, current rewards: -72.67091, mean: -0.04129
[32m[0906 20-34-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03307, current rewards: -66.59628, mean: -0.03679
[32m[0906 20-34-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03306, current rewards: -60.57203, mean: -0.03257
[32m[0906 20-34-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03305, current rewards: -54.54759, mean: -0.02856
[32m[0906 20-34-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03304, current rewards: -48.56094, mean: -0.02478
[32m[0906 20-34-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03303, current rewards: -42.53595, mean: -0.02116
[32m[0906 20-34-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03302, current rewards: -36.51585, mean: -0.01773
[32m[0906 20-34-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03302, current rewards: -34.47369, mean: -0.01634
[32m[0906 20-34-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03304, current rewards: -28.05168, mean: -0.01299
[32m[0906 20-34-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03304, current rewards: -21.68639, mean: -0.00981
[32m[0906 20-34-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03305, current rewards: -15.06146, mean: -0.00666
[32m[0906 20-34-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03306, current rewards: -8.44225, mean: -0.00365
[32m[0906 20-34-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03307, current rewards: -1.81406, mean: -0.00077
[32m[0906 20-34-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03308, current rewards: 4.81264, mean: 0.00200
[32m[0906 20-34-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03309, current rewards: 11.43989, mean: 0.00465
[32m[0906 20-34-38 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 20-34-38 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-34-38 @MBExp.py:227][0m Rewards obtained: [16.74225361458218], Lows: [12], Highs: [230], Total time: 10270.608489999997
[32m[0906 20-38-15 @MBExp.py:144][0m ####################################################################
[32m[0906 20-38-15 @MBExp.py:145][0m Starting training iteration 120.
[32m[0906 20-38-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02804, current rewards: -7.77162, mean: -0.77716
[32m[0906 20-38-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02574, current rewards: -57.77162, mean: -0.96286
[32m[0906 20-38-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02513, current rewards: -107.77162, mean: -0.97974
[32m[0906 20-38-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02651, current rewards: -157.77162, mean: -0.98607
[32m[0906 20-38-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02696, current rewards: -207.77162, mean: -0.98939
[32m[0906 20-38-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02665, current rewards: -215.72232, mean: -0.82970
[32m[0906 20-38-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02628, current rewards: -208.58973, mean: -0.67287
[32m[0906 20-38-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02608, current rewards: -201.66106, mean: -0.56017
[32m[0906 20-38-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02592, current rewards: -194.06267, mean: -0.47332
[32m[0906 20-38-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02582, current rewards: -187.20305, mean: -0.40696
[32m[0906 20-38-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02570, current rewards: -182.90925, mean: -0.35865
[32m[0906 20-38-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02568, current rewards: -227.25102, mean: -0.40581
[32m[0906 20-38-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02558, current rewards: -277.25102, mean: -0.45451
[32m[0906 20-38-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02550, current rewards: -327.25102, mean: -0.49583
[32m[0906 20-38-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02542, current rewards: -377.25102, mean: -0.53134
[32m[0906 20-38-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02535, current rewards: -427.25102, mean: -0.56217
[32m[0906 20-38-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02531, current rewards: -477.25102, mean: -0.58920
[32m[0906 20-38-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02526, current rewards: -527.25102, mean: -0.61308
[32m[0906 20-38-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02503, current rewards: -577.25102, mean: -0.63434
[32m[0906 20-38-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02478, current rewards: -627.25102, mean: -0.65339
[32m[0906 20-38-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02454, current rewards: -677.25102, mean: -0.67055
[32m[0906 20-38-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02432, current rewards: -727.25102, mean: -0.68609
[32m[0906 20-38-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02413, current rewards: -777.25102, mean: -0.70023
[32m[0906 20-38-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02395, current rewards: -827.25102, mean: -0.71315
[32m[0906 20-38-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02378, current rewards: -877.25102, mean: -0.72500
[32m[0906 20-38-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02363, current rewards: -927.25102, mean: -0.73591
[32m[0906 20-38-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02349, current rewards: -977.25102, mean: -0.74599
[32m[0906 20-38-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02336, current rewards: -1027.25102, mean: -0.75533
[32m[0906 20-38-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02333, current rewards: -1073.78075, mean: -0.76155
[32m[0906 20-38-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02321, current rewards: -1123.78075, mean: -0.76971
[32m[0906 20-38-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02311, current rewards: -1173.78075, mean: -0.77734
[32m[0906 20-38-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02301, current rewards: -1223.78075, mean: -0.78447
[32m[0906 20-38-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02292, current rewards: -1263.30062, mean: -0.78466
[32m[0906 20-38-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02283, current rewards: -1260.89994, mean: -0.75958
[32m[0906 20-38-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02275, current rewards: -1258.49927, mean: -0.73596
[32m[0906 20-38-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02267, current rewards: -1256.09859, mean: -0.71369
[32m[0906 20-38-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02259, current rewards: -1302.95455, mean: -0.71986
[32m[0906 20-38-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02251, current rewards: -1352.95455, mean: -0.72739
[32m[0906 20-38-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02244, current rewards: -1402.95455, mean: -0.73453
[32m[0906 20-38-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02238, current rewards: -1452.95455, mean: -0.74130
[32m[0906 20-39-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02232, current rewards: -1502.95455, mean: -0.74774
[32m[0906 20-39-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02226, current rewards: -1552.95455, mean: -0.75386
[32m[0906 20-39-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02220, current rewards: -1602.95455, mean: -0.75969
[32m[0906 20-39-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02215, current rewards: -1652.95455, mean: -0.76526
[32m[0906 20-39-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02209, current rewards: -1702.95455, mean: -0.77057
[32m[0906 20-39-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02205, current rewards: -1752.95455, mean: -0.77564
[32m[0906 20-39-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02200, current rewards: -1802.95455, mean: -0.78050
[32m[0906 20-39-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02196, current rewards: -1852.95455, mean: -0.78515
[32m[0906 20-39-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02191, current rewards: -1865.49029, mean: -0.77406
[32m[0906 20-39-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02187, current rewards: -1858.72625, mean: -0.75558
[32m[0906 20-39-10 @Agent.py:117][0m Average action selection time: 0.0218
[32m[0906 20-39-10 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-39-10 @MBExp.py:227][0m Rewards obtained: [-1853.3150175929807], Lows: [22], Highs: [1874], Total time: 10325.798538999998
