[32m[0906 13-39-08 @logger.py:99][0m Log file set to /app/logs/dats-delay-1/zinc-coating-v0_0/Tuesday_06_September_2022_01-39PM.log
[32m[0906 13-39-08 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00001, current rewards: -11.83219, mean: -1.18322
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00001, current rewards: -65.52134, mean: -1.09202
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00001, current rewards: -124.82087, mean: -1.13474
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00001, current rewards: -181.27276, mean: -1.13295
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00001, current rewards: -238.54397, mean: -1.13592
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00001, current rewards: -288.59723, mean: -1.10999
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00001, current rewards: -346.84559, mean: -1.11886
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00001, current rewards: -398.02569, mean: -1.10563
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00001, current rewards: -445.62975, mean: -1.08690
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00001, current rewards: -502.81647, mean: -1.09308
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00001, current rewards: -560.64242, mean: -1.09930
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00001, current rewards: -622.03619, mean: -1.11078
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00001, current rewards: -675.08179, mean: -1.10669
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00001, current rewards: -726.79708, mean: -1.10121
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00001, current rewards: -788.18666, mean: -1.11012
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00001, current rewards: -845.83058, mean: -1.11293
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00001, current rewards: -912.81030, mean: -1.12693
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00001, current rewards: -968.53402, mean: -1.12620
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00001, current rewards: -1032.08559, mean: -1.13416
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00001, current rewards: -1091.93505, mean: -1.13743
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00001, current rewards: -1139.37898, mean: -1.12810
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00001, current rewards: -1183.88935, mean: -1.11688
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00001, current rewards: -1235.35362, mean: -1.11293
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00001, current rewards: -1281.51384, mean: -1.10475
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00001, current rewards: -1339.70988, mean: -1.10720
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00001, current rewards: -1406.15748, mean: -1.11600
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00001, current rewards: -1477.33450, mean: -1.12774
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00001, current rewards: -1565.77236, mean: -1.15130
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00001, current rewards: -1647.94256, mean: -1.16875
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00001, current rewards: -1724.71634, mean: -1.18131
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00001, current rewards: -1806.51454, mean: -1.19637
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00001, current rewards: -1882.67754, mean: -1.20684
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00001, current rewards: -1961.10179, mean: -1.21808
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00001, current rewards: -2039.19965, mean: -1.22843
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00001, current rewards: -2111.36405, mean: -1.23472
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00001, current rewards: -2173.68995, mean: -1.23505
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00001, current rewards: -2234.24279, mean: -1.23439
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00001, current rewards: -2301.63688, mean: -1.23744
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00001, current rewards: -2359.33585, mean: -1.23525
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00001, current rewards: -2419.51339, mean: -1.23445
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00001, current rewards: -2478.72181, mean: -1.23319
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00001, current rewards: -2539.04637, mean: -1.23255
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00001, current rewards: -2601.85035, mean: -1.23310
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00001, current rewards: -2661.96968, mean: -1.23239
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00001, current rewards: -2715.63557, mean: -1.22879
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00001, current rewards: -2787.19279, mean: -1.23327
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00001, current rewards: -2853.95876, mean: -1.23548
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00001, current rewards: -2916.83513, mean: -1.23595
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00001, current rewards: -2979.29608, mean: -1.23622
[32m[0906 13-39-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00001, current rewards: -3025.17759, mean: -1.22975
[32m[0906 13-39-08 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-39-08 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-39-10 @MBExp.py:144][0m ####################################################################
[32m[0906 13-39-10 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-39-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02959, current rewards: -1.05146, mean: -0.10515
[32m[0906 13-39-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02185, current rewards: 5.17352, mean: 0.08623
[32m[0906 13-39-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02124, current rewards: 11.38423, mean: 0.10349
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02100, current rewards: 17.60109, mean: 0.11001
[32m[0906 13-39-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02090, current rewards: 23.82056, mean: 0.11343
[32m[0906 13-39-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02083, current rewards: 30.02884, mean: 0.11550
[32m[0906 13-39-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02074, current rewards: 36.25592, mean: 0.11695
[32m[0906 13-39-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02067, current rewards: 42.46913, mean: 0.11797
[32m[0906 13-39-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02065, current rewards: 49.15441, mean: 0.11989
[32m[0906 13-39-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02062, current rewards: 58.20136, mean: 0.12652
[32m[0906 13-39-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02062, current rewards: 63.92331, mean: 0.12534
[32m[0906 13-39-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02059, current rewards: 75.42830, mean: 0.13469
[32m[0906 13-39-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02057, current rewards: 86.93797, mean: 0.14252
[32m[0906 13-39-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02057, current rewards: 98.43258, mean: 0.14914
[32m[0906 13-39-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02056, current rewards: 109.91281, mean: 0.15481
[32m[0906 13-39-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02055, current rewards: 121.41790, mean: 0.15976
[32m[0906 13-39-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02054, current rewards: 132.91653, mean: 0.16409
[32m[0906 13-39-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02053, current rewards: 144.93013, mean: 0.16852
[32m[0906 13-39-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02053, current rewards: 156.87666, mean: 0.17239
[32m[0906 13-39-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02051, current rewards: 166.58678, mean: 0.17353
[32m[0906 13-39-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02051, current rewards: 171.42086, mean: 0.16972
[32m[0906 13-39-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02050, current rewards: 176.25675, mean: 0.16628
[32m[0906 13-39-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02049, current rewards: 181.09702, mean: 0.16315
[32m[0906 13-39-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02048, current rewards: 185.93179, mean: 0.16029
[32m[0906 13-39-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02048, current rewards: 192.66341, mean: 0.15923
[32m[0906 13-39-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02047, current rewards: 205.01669, mean: 0.16271
[32m[0906 13-39-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02047, current rewards: 217.38133, mean: 0.16594
[32m[0906 13-39-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02046, current rewards: 229.71197, mean: 0.16891
[32m[0906 13-39-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02046, current rewards: 242.04058, mean: 0.17166
[32m[0906 13-39-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02045, current rewards: 254.39064, mean: 0.17424
[32m[0906 13-39-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02045, current rewards: 266.74989, mean: 0.17666
[32m[0906 13-39-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.02045, current rewards: 278.33426, mean: 0.17842
[32m[0906 13-39-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.02045, current rewards: 286.28519, mean: 0.17782
[32m[0906 13-39-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.02045, current rewards: 291.44548, mean: 0.17557
[32m[0906 13-39-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.02045, current rewards: 295.68880, mean: 0.17292
[32m[0906 13-39-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.02044, current rewards: 299.94075, mean: 0.17042
[32m[0906 13-39-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.02044, current rewards: 304.18956, mean: 0.16806
[32m[0906 13-39-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.02048, current rewards: 308.43350, mean: 0.16582
[32m[0906 13-39-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.02048, current rewards: 312.67677, mean: 0.16371
[32m[0906 13-39-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.02048, current rewards: 316.92464, mean: 0.16170
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.02049, current rewards: 321.17365, mean: 0.15979
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.02052, current rewards: 325.88661, mean: 0.15820
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.02058, current rewards: 331.75181, mean: 0.15723
[32m[0906 13-39-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.02068, current rewards: 337.62144, mean: 0.15631
[32m[0906 13-39-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.02078, current rewards: 343.49697, mean: 0.15543
[32m[0906 13-39-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.02087, current rewards: 345.05472, mean: 0.15268
[32m[0906 13-39-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.02095, current rewards: 350.08350, mean: 0.15155
[32m[0906 13-40-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.02103, current rewards: 355.11183, mean: 0.15047
[32m[0906 13-40-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.02111, current rewards: 360.13791, mean: 0.14943
[32m[0906 13-40-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.02119, current rewards: 362.99072, mean: 0.14756
[32m[0906 13-40-04 @Agent.py:117][0m Average action selection time: 0.0212
[32m[0906 13-40-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-40-04 @MBExp.py:227][0m Rewards obtained: [367.6928284381047], Lows: [4], Highs: [6], Total time: 53.572199
[32m[0906 13-40-07 @MBExp.py:144][0m ####################################################################
[32m[0906 13-40-07 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-40-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.02519, current rewards: -3.47525, mean: -0.34753
[32m[0906 13-40-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.02510, current rewards: 0.56587, mean: 0.00943
[32m[0906 13-40-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.02501, current rewards: 4.60747, mean: 0.04189
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.02532, current rewards: 8.65097, mean: 0.05407
[32m[0906 13-40-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.02580, current rewards: 12.69618, mean: 0.06046
[32m[0906 13-40-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.02635, current rewards: 16.73689, mean: 0.06437
[32m[0906 13-40-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.02673, current rewards: 20.77567, mean: 0.06702
[32m[0906 13-40-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.02698, current rewards: 24.80007, mean: 0.06889
[32m[0906 13-40-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.02718, current rewards: 27.65300, mean: 0.06745
[32m[0906 13-40-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.02734, current rewards: 31.81549, mean: 0.06916
[32m[0906 13-40-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.02747, current rewards: 35.97637, mean: 0.07054
[32m[0906 13-40-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.02758, current rewards: 40.14042, mean: 0.07168
[32m[0906 13-40-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.02766, current rewards: 44.30628, mean: 0.07263
[32m[0906 13-40-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.02774, current rewards: 48.46811, mean: 0.07344
[32m[0906 13-40-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.02789, current rewards: 52.63156, mean: 0.07413
[32m[0906 13-40-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.02796, current rewards: 56.78913, mean: 0.07472
[32m[0906 13-40-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.02803, current rewards: 56.50864, mean: 0.06976
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.02809, current rewards: 60.34572, mean: 0.07017
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.02821, current rewards: 64.18301, mean: 0.07053
[32m[0906 13-40-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.02838, current rewards: 68.01977, mean: 0.07085
[32m[0906 13-40-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.02860, current rewards: 71.85702, mean: 0.07115
[32m[0906 13-40-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.02880, current rewards: 75.69937, mean: 0.07141
[32m[0906 13-40-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.02897, current rewards: 79.53905, mean: 0.07166
[32m[0906 13-40-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.02912, current rewards: 83.37480, mean: 0.07187
[32m[0906 13-40-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.02927, current rewards: 88.31920, mean: 0.07299
[32m[0906 13-40-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.02940, current rewards: 93.61569, mean: 0.07430
[32m[0906 13-40-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.02952, current rewards: 98.90453, mean: 0.07550
[32m[0906 13-40-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.02964, current rewards: 104.19320, mean: 0.07661
[32m[0906 13-40-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.02975, current rewards: 109.48505, mean: 0.07765
[32m[0906 13-40-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.02984, current rewards: 114.77919, mean: 0.07862
[32m[0906 13-40-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.02993, current rewards: 117.88845, mean: 0.07807
[32m[0906 13-40-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03002, current rewards: 123.39956, mean: 0.07910
[32m[0906 13-40-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03010, current rewards: 128.90807, mean: 0.08007
[32m[0906 13-40-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03018, current rewards: 134.41500, mean: 0.08097
[32m[0906 13-40-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03024, current rewards: 139.92402, mean: 0.08183
[32m[0906 13-41-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03031, current rewards: 145.44205, mean: 0.08264
[32m[0906 13-41-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03037, current rewards: 150.94183, mean: 0.08339
[32m[0906 13-41-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03043, current rewards: 156.44401, mean: 0.08411
[32m[0906 13-41-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03048, current rewards: 161.95181, mean: 0.08479
[32m[0906 13-41-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03054, current rewards: 167.45768, mean: 0.08544
[32m[0906 13-41-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03058, current rewards: 172.59236, mean: 0.08587
[32m[0906 13-41-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03060, current rewards: 176.54626, mean: 0.08570
[32m[0906 13-41-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03062, current rewards: 180.54547, mean: 0.08557
[32m[0906 13-41-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03067, current rewards: 184.08826, mean: 0.08523
[32m[0906 13-41-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03072, current rewards: 187.63085, mean: 0.08490
[32m[0906 13-41-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03078, current rewards: 191.17670, mean: 0.08459
[32m[0906 13-41-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03083, current rewards: 194.72175, mean: 0.08430
[32m[0906 13-41-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03088, current rewards: 198.26708, mean: 0.08401
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03093, current rewards: 201.81271, mean: 0.08374
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03100, current rewards: 206.03717, mean: 0.08375
[32m[0906 13-41-25 @Agent.py:117][0m Average action selection time: 0.0311
[32m[0906 13-41-25 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-41-25 @MBExp.py:227][0m Rewards obtained: [209.60157420628232], Lows: [2], Highs: [7], Total time: 131.82835899999998
[32m[0906 13-41-31 @MBExp.py:144][0m ####################################################################
[32m[0906 13-41-31 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-41-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03643, current rewards: -1.06934, mean: -0.10693
[32m[0906 13-41-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03598, current rewards: 5.30095, mean: 0.08835
[32m[0906 13-41-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03579, current rewards: 11.66559, mean: 0.10605
[32m[0906 13-41-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03560, current rewards: 18.03476, mean: 0.11272
[32m[0906 13-41-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03571, current rewards: 24.41048, mean: 0.11624
[32m[0906 13-41-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03581, current rewards: 30.79379, mean: 0.11844
[32m[0906 13-41-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03584, current rewards: 37.17197, mean: 0.11991
[32m[0906 13-41-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03588, current rewards: 43.53761, mean: 0.12094
[32m[0906 13-41-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03593, current rewards: 48.82518, mean: 0.11909
[32m[0906 13-41-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03595, current rewards: 53.83826, mean: 0.11704
[32m[0906 13-41-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03600, current rewards: 56.88542, mean: 0.11154
[32m[0906 13-41-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03601, current rewards: 61.84893, mean: 0.11044
[32m[0906 13-41-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03603, current rewards: 66.81655, mean: 0.10954
[32m[0906 13-41-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03605, current rewards: 71.78601, mean: 0.10877
[32m[0906 13-41-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03605, current rewards: 76.75488, mean: 0.10811
[32m[0906 13-41-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03606, current rewards: 81.72331, mean: 0.10753
[32m[0906 13-42-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03604, current rewards: 86.73802, mean: 0.10708
[32m[0906 13-42-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03601, current rewards: 91.74640, mean: 0.10668
[32m[0906 13-42-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03598, current rewards: 96.75292, mean: 0.10632
[32m[0906 13-42-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03600, current rewards: 101.76156, mean: 0.10600
[32m[0906 13-42-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03602, current rewards: 106.77238, mean: 0.10572
[32m[0906 13-42-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03602, current rewards: 111.78475, mean: 0.10546
[32m[0906 13-42-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03605, current rewards: 116.79479, mean: 0.10522
[32m[0906 13-42-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03605, current rewards: 121.80360, mean: 0.10500
[32m[0906 13-42-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03606, current rewards: 126.81251, mean: 0.10480
[32m[0906 13-42-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03606, current rewards: 131.82661, mean: 0.10462
[32m[0906 13-42-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03607, current rewards: 136.05210, mean: 0.10386
[32m[0906 13-42-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03607, current rewards: 141.65858, mean: 0.10416
[32m[0906 13-42-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03608, current rewards: 147.27875, mean: 0.10445
[32m[0906 13-42-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03608, current rewards: 152.89077, mean: 0.10472
[32m[0906 13-42-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03609, current rewards: 158.50498, mean: 0.10497
[32m[0906 13-42-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03609, current rewards: 164.11039, mean: 0.10520
[32m[0906 13-42-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03610, current rewards: 169.91981, mean: 0.10554
[32m[0906 13-42-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03610, current rewards: 175.98450, mean: 0.10601
[32m[0906 13-42-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03610, current rewards: 177.71360, mean: 0.10393
[32m[0906 13-42-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03610, current rewards: 183.05918, mean: 0.10401
[32m[0906 13-42-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03611, current rewards: 188.39993, mean: 0.10409
[32m[0906 13-42-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03611, current rewards: 193.74140, mean: 0.10416
[32m[0906 13-42-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03611, current rewards: 199.08220, mean: 0.10423
[32m[0906 13-42-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03610, current rewards: 204.42409, mean: 0.10430
[32m[0906 13-42-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03609, current rewards: 209.90433, mean: 0.10443
[32m[0906 13-42-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03607, current rewards: 215.85333, mean: 0.10478
[32m[0906 13-42-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03606, current rewards: 221.67204, mean: 0.10506
[32m[0906 13-42-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03606, current rewards: 227.49701, mean: 0.10532
[32m[0906 13-42-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03606, current rewards: 233.32401, mean: 0.10558
[32m[0906 13-42-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03606, current rewards: 237.00029, mean: 0.10487
[32m[0906 13-42-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03606, current rewards: 243.71141, mean: 0.10550
[32m[0906 13-42-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03606, current rewards: 250.41736, mean: 0.10611
[32m[0906 13-42-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03605, current rewards: 257.13694, mean: 0.10670
[32m[0906 13-43-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03604, current rewards: 258.82555, mean: 0.10521
[32m[0906 13-43-02 @Agent.py:117][0m Average action selection time: 0.0360
[32m[0906 13-43-02 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-43-02 @MBExp.py:227][0m Rewards obtained: [263.3622160360023], Lows: [5], Highs: [5], Total time: 222.55406699999997
[32m[0906 13-43-11 @MBExp.py:144][0m ####################################################################
[32m[0906 13-43-11 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 13-43-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03489, current rewards: -1.03999, mean: -0.10400
[32m[0906 13-43-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03544, current rewards: 4.70224, mean: 0.07837
[32m[0906 13-43-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03548, current rewards: 10.44922, mean: 0.09499
[32m[0906 13-43-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03573, current rewards: 16.18943, mean: 0.10118
[32m[0906 13-43-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03581, current rewards: 21.92879, mean: 0.10442
[32m[0906 13-43-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03587, current rewards: 27.67192, mean: 0.10643
[32m[0906 13-43-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03590, current rewards: 33.42300, mean: 0.10782
[32m[0906 13-43-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03595, current rewards: 39.13192, mean: 0.10870
[32m[0906 13-43-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03598, current rewards: 44.68538, mean: 0.10899
[32m[0906 13-43-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03599, current rewards: 50.23804, mean: 0.10921
[32m[0906 13-43-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03601, current rewards: 55.79268, mean: 0.10940
[32m[0906 13-43-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03602, current rewards: 61.34754, mean: 0.10955
[32m[0906 13-43-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03602, current rewards: 66.89875, mean: 0.10967
[32m[0906 13-43-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03603, current rewards: 72.45018, mean: 0.10977
[32m[0906 13-43-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03600, current rewards: 78.00203, mean: 0.10986
[32m[0906 13-43-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03595, current rewards: 83.55948, mean: 0.10995
[32m[0906 13-43-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03591, current rewards: 90.21735, mean: 0.11138
[32m[0906 13-43-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03589, current rewards: 94.67227, mean: 0.11008
[32m[0906 13-43-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03591, current rewards: 100.86493, mean: 0.11084
[32m[0906 13-43-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03592, current rewards: 107.05945, mean: 0.11152
[32m[0906 13-43-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03594, current rewards: 113.25555, mean: 0.11213
[32m[0906 13-43-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03596, current rewards: 119.45755, mean: 0.11270
[32m[0906 13-43-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03597, current rewards: 125.65543, mean: 0.11320
[32m[0906 13-43-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03598, current rewards: 131.85157, mean: 0.11367
[32m[0906 13-43-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03599, current rewards: 136.70702, mean: 0.11298
[32m[0906 13-43-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03600, current rewards: 142.79142, mean: 0.11333
[32m[0906 13-43-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03601, current rewards: 148.87133, mean: 0.11364
[32m[0906 13-44-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03601, current rewards: 154.95111, mean: 0.11393
[32m[0906 13-44-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03602, current rewards: 161.02802, mean: 0.11420
[32m[0906 13-44-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03603, current rewards: 167.10763, mean: 0.11446
[32m[0906 13-44-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03603, current rewards: 173.19082, mean: 0.11470
[32m[0906 13-44-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03604, current rewards: 179.26695, mean: 0.11491
[32m[0906 13-44-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03604, current rewards: 185.13731, mean: 0.11499
[32m[0906 13-44-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03604, current rewards: 190.87072, mean: 0.11498
[32m[0906 13-44-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03604, current rewards: 196.61549, mean: 0.11498
[32m[0906 13-44-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03605, current rewards: 202.35442, mean: 0.11497
[32m[0906 13-44-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03606, current rewards: 208.09791, mean: 0.11497
[32m[0906 13-44-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03606, current rewards: 213.83511, mean: 0.11497
[32m[0906 13-44-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03605, current rewards: 219.56922, mean: 0.11496
[32m[0906 13-44-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03603, current rewards: 225.26250, mean: 0.11493
[32m[0906 13-44-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03601, current rewards: 231.04762, mean: 0.11495
[32m[0906 13-44-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03600, current rewards: 236.91841, mean: 0.11501
[32m[0906 13-44-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03599, current rewards: 242.79215, mean: 0.11507
[32m[0906 13-44-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03599, current rewards: 248.65911, mean: 0.11512
[32m[0906 13-44-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03600, current rewards: 254.52212, mean: 0.11517
[32m[0906 13-44-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03600, current rewards: 260.38410, mean: 0.11521
[32m[0906 13-44-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03599, current rewards: 264.28808, mean: 0.11441
[32m[0906 13-44-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03598, current rewards: 269.83409, mean: 0.11434
[32m[0906 13-44-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03597, current rewards: 275.46750, mean: 0.11430
[32m[0906 13-44-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03597, current rewards: 281.18729, mean: 0.11430
[32m[0906 13-44-41 @Agent.py:117][0m Average action selection time: 0.0360
[32m[0906 13-44-41 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-44-41 @MBExp.py:227][0m Rewards obtained: [285.75685857692633], Lows: [2], Highs: [3], Total time: 313.12625399999996
[32m[0906 13-44-52 @MBExp.py:144][0m ####################################################################
[32m[0906 13-44-52 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 13-44-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03614, current rewards: -3.31295, mean: -0.33129
[32m[0906 13-44-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03573, current rewards: 2.16733, mean: 0.03612
[32m[0906 13-44-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03600, current rewards: 7.64609, mean: 0.06951
[32m[0906 13-44-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03606, current rewards: 13.11956, mean: 0.08200
[32m[0906 13-44-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03611, current rewards: 18.59724, mean: 0.08856
[32m[0906 13-45-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03612, current rewards: 24.07370, mean: 0.09259
[32m[0906 13-45-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03615, current rewards: 29.55507, mean: 0.09534
[32m[0906 13-45-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03614, current rewards: 35.36378, mean: 0.09823
[32m[0906 13-45-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03614, current rewards: 40.83733, mean: 0.09960
[32m[0906 13-45-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03614, current rewards: 46.31860, mean: 0.10069
[32m[0906 13-45-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03614, current rewards: 51.79590, mean: 0.10156
[32m[0906 13-45-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03610, current rewards: 57.27252, mean: 0.10227
[32m[0906 13-45-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03605, current rewards: 61.97616, mean: 0.10160
[32m[0906 13-45-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03598, current rewards: 68.00625, mean: 0.10304
[32m[0906 13-45-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03593, current rewards: 74.04123, mean: 0.10428
[32m[0906 13-45-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03590, current rewards: 79.86021, mean: 0.10508
[32m[0906 13-45-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03591, current rewards: 85.17901, mean: 0.10516
[32m[0906 13-45-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03593, current rewards: 90.58648, mean: 0.10533
[32m[0906 13-45-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03594, current rewards: 96.00431, mean: 0.10550
[32m[0906 13-45-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03595, current rewards: 99.23692, mean: 0.10337
[32m[0906 13-45-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03597, current rewards: 104.62848, mean: 0.10359
[32m[0906 13-45-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03598, current rewards: 110.03197, mean: 0.10380
[32m[0906 13-45-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03599, current rewards: 115.42720, mean: 0.10399
[32m[0906 13-45-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03600, current rewards: 120.81807, mean: 0.10415
[32m[0906 13-45-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03602, current rewards: 126.33098, mean: 0.10441
[32m[0906 13-45-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03603, current rewards: 131.76223, mean: 0.10457
[32m[0906 13-45-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03603, current rewards: 137.19712, mean: 0.10473
[32m[0906 13-45-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03604, current rewards: 142.63937, mean: 0.10488
[32m[0906 13-45-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03604, current rewards: 148.07500, mean: 0.10502
[32m[0906 13-45-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03605, current rewards: 153.51042, mean: 0.10514
[32m[0906 13-45-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03606, current rewards: 158.94525, mean: 0.10526
[32m[0906 13-45-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03607, current rewards: 164.37653, mean: 0.10537
[32m[0906 13-45-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03607, current rewards: 169.92860, mean: 0.10555
[32m[0906 13-45-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03607, current rewards: 175.37924, mean: 0.10565
[32m[0906 13-45-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03608, current rewards: 178.72845, mean: 0.10452
[32m[0906 13-45-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03609, current rewards: 184.24559, mean: 0.10468
[32m[0906 13-45-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03609, current rewards: 189.76722, mean: 0.10484
[32m[0906 13-45-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03608, current rewards: 195.28468, mean: 0.10499
[32m[0906 13-46-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03606, current rewards: 200.80450, mean: 0.10513
[32m[0906 13-46-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03605, current rewards: 206.32770, mean: 0.10527
[32m[0906 13-46-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03603, current rewards: 212.01056, mean: 0.10548
[32m[0906 13-46-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03602, current rewards: 217.55497, mean: 0.10561
[32m[0906 13-46-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03600, current rewards: 223.07899, mean: 0.10572
[32m[0906 13-46-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03600, current rewards: 227.49077, mean: 0.10532
[32m[0906 13-46-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03599, current rewards: 233.11970, mean: 0.10548
[32m[0906 13-46-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03598, current rewards: 238.75261, mean: 0.10564
[32m[0906 13-46-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03597, current rewards: 244.38214, mean: 0.10579
[32m[0906 13-46-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03595, current rewards: 250.01163, mean: 0.10594
[32m[0906 13-46-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03596, current rewards: 251.45997, mean: 0.10434
[32m[0906 13-46-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03597, current rewards: 256.52968, mean: 0.10428
[32m[0906 13-46-22 @Agent.py:117][0m Average action selection time: 0.0360
[32m[0906 13-46-22 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-46-22 @MBExp.py:227][0m Rewards obtained: [260.86627511080746], Lows: [4], Highs: [6], Total time: 403.69096199999996
[32m[0906 13-46-35 @MBExp.py:144][0m ####################################################################
[32m[0906 13-46-35 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 13-46-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03696, current rewards: -3.31548, mean: -0.33155
[32m[0906 13-46-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03637, current rewards: 2.84857, mean: 0.04748
[32m[0906 13-46-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03631, current rewards: 9.01318, mean: 0.08194
[32m[0906 13-46-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03635, current rewards: 15.16924, mean: 0.09481
[32m[0906 13-46-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03627, current rewards: 21.33351, mean: 0.10159
[32m[0906 13-46-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03626, current rewards: 27.49484, mean: 0.10575
[32m[0906 13-46-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03624, current rewards: 33.66325, mean: 0.10859
[32m[0906 13-46-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03623, current rewards: 42.46161, mean: 0.11795
[32m[0906 13-46-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03619, current rewards: 53.14078, mean: 0.12961
[32m[0906 13-46-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03610, current rewards: 63.86532, mean: 0.13884
[32m[0906 13-46-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03604, current rewards: 74.59291, mean: 0.14626
[32m[0906 13-46-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03598, current rewards: 85.30005, mean: 0.15232
[32m[0906 13-46-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03593, current rewards: 96.00669, mean: 0.15739
[32m[0906 13-46-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03589, current rewards: 102.16214, mean: 0.15479
[32m[0906 13-47-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03586, current rewards: 108.63183, mean: 0.15300
[32m[0906 13-47-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03587, current rewards: 115.09641, mean: 0.15144
[32m[0906 13-47-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03589, current rewards: 121.58439, mean: 0.15010
[32m[0906 13-47-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03591, current rewards: 128.06855, mean: 0.14892
[32m[0906 13-47-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03591, current rewards: 134.55502, mean: 0.14786
[32m[0906 13-47-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03591, current rewards: 141.03215, mean: 0.14691
[32m[0906 13-47-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03592, current rewards: 147.51244, mean: 0.14605
[32m[0906 13-47-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03593, current rewards: 153.99978, mean: 0.14528
[32m[0906 13-47-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03594, current rewards: 160.48318, mean: 0.14458
[32m[0906 13-47-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03596, current rewards: 166.95780, mean: 0.14393
[32m[0906 13-47-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03597, current rewards: 173.48721, mean: 0.14338
[32m[0906 13-47-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03598, current rewards: 180.02712, mean: 0.14288
[32m[0906 13-47-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03600, current rewards: 182.07569, mean: 0.13899
[32m[0906 13-47-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03600, current rewards: 188.26039, mean: 0.13843
[32m[0906 13-47-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03600, current rewards: 194.44431, mean: 0.13790
[32m[0906 13-47-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03601, current rewards: 200.62980, mean: 0.13742
[32m[0906 13-47-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03602, current rewards: 206.81707, mean: 0.13696
[32m[0906 13-47-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03603, current rewards: 213.09380, mean: 0.13660
[32m[0906 13-47-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03604, current rewards: 219.15698, mean: 0.13612
[32m[0906 13-47-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03604, current rewards: 225.21644, mean: 0.13567
[32m[0906 13-47-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03605, current rewards: 229.14514, mean: 0.13400
[32m[0906 13-47-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03606, current rewards: 235.56410, mean: 0.13384
[32m[0906 13-47-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03603, current rewards: 241.97613, mean: 0.13369
[32m[0906 13-47-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03601, current rewards: 248.39287, mean: 0.13354
[32m[0906 13-47-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03601, current rewards: 254.79903, mean: 0.13340
[32m[0906 13-47-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03599, current rewards: 261.20506, mean: 0.13327
[32m[0906 13-47-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03597, current rewards: 267.62558, mean: 0.13315
[32m[0906 13-47-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03595, current rewards: 274.03814, mean: 0.13303
[32m[0906 13-47-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03591, current rewards: 276.18647, mean: 0.13089
[32m[0906 13-47-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03591, current rewards: 282.40735, mean: 0.13074
[32m[0906 13-47-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03589, current rewards: 288.62226, mean: 0.13060
[32m[0906 13-47-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03588, current rewards: 294.83740, mean: 0.13046
[32m[0906 13-47-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03587, current rewards: 301.06146, mean: 0.13033
[32m[0906 13-48-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03588, current rewards: 307.30621, mean: 0.13021
[32m[0906 13-48-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03588, current rewards: 313.47186, mean: 0.13007
[32m[0906 13-48-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03589, current rewards: 319.64342, mean: 0.12994
[32m[0906 13-48-05 @Agent.py:117][0m Average action selection time: 0.0359
[32m[0906 13-48-05 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-48-05 @MBExp.py:227][0m Rewards obtained: [324.5804094676024], Lows: [5], Highs: [7], Total time: 494.03536399999996
[32m[0906 13-48-20 @MBExp.py:144][0m ####################################################################
[32m[0906 13-48-20 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 13-48-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03598, current rewards: -3.34126, mean: -0.33413
[32m[0906 13-48-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03623, current rewards: 2.26695, mean: 0.03778
[32m[0906 13-48-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03604, current rewards: 7.90391, mean: 0.07185
[32m[0906 13-48-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03605, current rewards: 13.54345, mean: 0.08465
[32m[0906 13-48-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03610, current rewards: 19.18104, mean: 0.09134
[32m[0906 13-48-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03610, current rewards: 24.81562, mean: 0.09544
[32m[0906 13-48-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03597, current rewards: 30.44929, mean: 0.09822
[32m[0906 13-48-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03589, current rewards: 36.08626, mean: 0.10024
[32m[0906 13-48-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03583, current rewards: 39.47823, mean: 0.09629
[32m[0906 13-48-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03579, current rewards: 44.13658, mean: 0.09595
[32m[0906 13-48-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03575, current rewards: 48.79870, mean: 0.09568
[32m[0906 13-48-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03571, current rewards: 53.45931, mean: 0.09546
[32m[0906 13-48-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03566, current rewards: 58.11519, mean: 0.09527
[32m[0906 13-48-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03569, current rewards: 62.77450, mean: 0.09511
[32m[0906 13-48-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03573, current rewards: 67.10055, mean: 0.09451
[32m[0906 13-48-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03575, current rewards: 72.68794, mean: 0.09564
[32m[0906 13-48-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03577, current rewards: 78.27253, mean: 0.09663
[32m[0906 13-48-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03580, current rewards: 83.85624, mean: 0.09751
[32m[0906 13-48-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03581, current rewards: 89.44262, mean: 0.09829
[32m[0906 13-48-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03584, current rewards: 92.90865, mean: 0.09678
[32m[0906 13-48-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03586, current rewards: 98.43624, mean: 0.09746
[32m[0906 13-48-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03587, current rewards: 103.96044, mean: 0.09808
[32m[0906 13-49-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03588, current rewards: 109.43236, mean: 0.09859
[32m[0906 13-49-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03590, current rewards: 114.92826, mean: 0.09908
[32m[0906 13-49-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03591, current rewards: 120.42149, mean: 0.09952
[32m[0906 13-49-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03591, current rewards: 125.91353, mean: 0.09993
[32m[0906 13-49-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03592, current rewards: 130.38756, mean: 0.09953
[32m[0906 13-49-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03593, current rewards: 135.89961, mean: 0.09993
[32m[0906 13-49-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03594, current rewards: 141.41368, mean: 0.10029
[32m[0906 13-49-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03594, current rewards: 146.92156, mean: 0.10063
[32m[0906 13-49-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03595, current rewards: 152.41017, mean: 0.10093
[32m[0906 13-49-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03596, current rewards: 157.91164, mean: 0.10123
[32m[0906 13-49-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03597, current rewards: 163.40836, mean: 0.10150
[32m[0906 13-49-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03598, current rewards: 164.72776, mean: 0.09923
[32m[0906 13-49-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03598, current rewards: 169.99506, mean: 0.09941
[32m[0906 13-49-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03596, current rewards: 175.26221, mean: 0.09958
[32m[0906 13-49-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03595, current rewards: 180.52929, mean: 0.09974
[32m[0906 13-49-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03594, current rewards: 185.79663, mean: 0.09989
[32m[0906 13-49-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03592, current rewards: 188.09566, mean: 0.09848
[32m[0906 13-49-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03589, current rewards: 193.79377, mean: 0.09887
[32m[0906 13-49-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03586, current rewards: 199.48990, mean: 0.09925
[32m[0906 13-49-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03583, current rewards: 205.18200, mean: 0.09960
[32m[0906 13-49-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03580, current rewards: 210.87743, mean: 0.09994
[32m[0906 13-49-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03580, current rewards: 216.57791, mean: 0.10027
[32m[0906 13-49-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03579, current rewards: 222.04360, mean: 0.10047
[32m[0906 13-49-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03578, current rewards: 227.53003, mean: 0.10068
[32m[0906 13-49-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03579, current rewards: 233.01438, mean: 0.10087
[32m[0906 13-49-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03581, current rewards: 238.49781, mean: 0.10106
[32m[0906 13-49-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03581, current rewards: 243.97751, mean: 0.10124
[32m[0906 13-49-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03581, current rewards: 249.45933, mean: 0.10141
[32m[0906 13-49-50 @Agent.py:117][0m Average action selection time: 0.0358
[32m[0906 13-49-50 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-49-50 @MBExp.py:227][0m Rewards obtained: [253.84545194980618], Lows: [4], Highs: [9], Total time: 584.171284
[32m[0906 13-50-07 @MBExp.py:144][0m ####################################################################
[32m[0906 13-50-07 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 13-50-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03597, current rewards: -1.21487, mean: -0.12149
[32m[0906 13-50-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03616, current rewards: 4.03858, mean: 0.06731
[32m[0906 13-50-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03607, current rewards: 9.42706, mean: 0.08570
[32m[0906 13-50-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03592, current rewards: 14.81092, mean: 0.09257
[32m[0906 13-50-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03576, current rewards: 20.18770, mean: 0.09613
[32m[0906 13-50-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03565, current rewards: 25.83338, mean: 0.09936
[32m[0906 13-50-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03560, current rewards: 31.25083, mean: 0.10081
[32m[0906 13-50-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03557, current rewards: 36.66845, mean: 0.10186
[32m[0906 13-50-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03555, current rewards: 42.07707, mean: 0.10263
[32m[0906 13-50-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03551, current rewards: 45.43661, mean: 0.09878
[32m[0906 13-50-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03547, current rewards: 50.95527, mean: 0.09991
[32m[0906 13-50-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03549, current rewards: 56.48072, mean: 0.10086
[32m[0906 13-50-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03554, current rewards: 62.00860, mean: 0.10165
[32m[0906 13-50-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03559, current rewards: 67.40027, mean: 0.10212
[32m[0906 13-50-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03562, current rewards: 72.84965, mean: 0.10261
[32m[0906 13-50-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03565, current rewards: 78.30816, mean: 0.10304
[32m[0906 13-50-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03568, current rewards: 83.76881, mean: 0.10342
[32m[0906 13-50-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03570, current rewards: 89.23135, mean: 0.10376
[32m[0906 13-50-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03573, current rewards: 94.68683, mean: 0.10405
[32m[0906 13-50-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03576, current rewards: 98.43309, mean: 0.10253
[32m[0906 13-50-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03578, current rewards: 104.29030, mean: 0.10326
[32m[0906 13-50-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03580, current rewards: 110.14602, mean: 0.10391
[32m[0906 13-50-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03581, current rewards: 115.94948, mean: 0.10446
[32m[0906 13-50-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03583, current rewards: 121.78300, mean: 0.10499
[32m[0906 13-50-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03584, current rewards: 126.32731, mean: 0.10440
[32m[0906 13-50-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03584, current rewards: 131.79984, mean: 0.10460
[32m[0906 13-50-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03585, current rewards: 137.27645, mean: 0.10479
[32m[0906 13-50-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03586, current rewards: 142.75102, mean: 0.10496
[32m[0906 13-50-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03587, current rewards: 148.21731, mean: 0.10512
[32m[0906 13-50-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03587, current rewards: 153.68337, mean: 0.10526
[32m[0906 13-51-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03589, current rewards: 159.06248, mean: 0.10534
[32m[0906 13-51-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03589, current rewards: 164.52334, mean: 0.10546
[32m[0906 13-51-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03590, current rewards: 169.97372, mean: 0.10557
[32m[0906 13-51-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03589, current rewards: 175.42851, mean: 0.10568
[32m[0906 13-51-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03588, current rewards: 180.88294, mean: 0.10578
[32m[0906 13-51-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03587, current rewards: 185.14042, mean: 0.10519
[32m[0906 13-51-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03585, current rewards: 190.53984, mean: 0.10527
[32m[0906 13-51-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03581, current rewards: 195.93955, mean: 0.10534
[32m[0906 13-51-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03578, current rewards: 201.41973, mean: 0.10546
[32m[0906 13-51-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03576, current rewards: 206.81153, mean: 0.10552
[32m[0906 13-51-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03573, current rewards: 212.20146, mean: 0.10557
[32m[0906 13-51-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03570, current rewards: 217.59702, mean: 0.10563
[32m[0906 13-51-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03567, current rewards: 222.98526, mean: 0.10568
[32m[0906 13-51-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03566, current rewards: 228.37735, mean: 0.10573
[32m[0906 13-51-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03566, current rewards: 233.77079, mean: 0.10578
[32m[0906 13-51-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03567, current rewards: 239.16047, mean: 0.10582
[32m[0906 13-51-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03569, current rewards: 244.50200, mean: 0.10585
[32m[0906 13-51-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03570, current rewards: 249.90089, mean: 0.10589
[32m[0906 13-51-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03569, current rewards: 253.27285, mean: 0.10509
[32m[0906 13-51-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03569, current rewards: 258.79499, mean: 0.10520
[32m[0906 13-51-36 @Agent.py:117][0m Average action selection time: 0.0357
[32m[0906 13-51-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-51-36 @MBExp.py:227][0m Rewards obtained: [263.2114865171926], Lows: [3], Highs: [4], Total time: 674.005352
[32m[0906 13-51-55 @MBExp.py:144][0m ####################################################################
[32m[0906 13-51-55 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 13-51-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03587, current rewards: -2.29011, mean: -0.22901
[32m[0906 13-51-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03536, current rewards: 3.11108, mean: 0.05185
[32m[0906 13-51-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03535, current rewards: 8.52843, mean: 0.07753
[32m[0906 13-52-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03537, current rewards: 13.93941, mean: 0.08712
[32m[0906 13-52-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03541, current rewards: 19.45921, mean: 0.09266
[32m[0906 13-52-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03542, current rewards: 25.01035, mean: 0.09619
[32m[0906 13-52-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03545, current rewards: 30.50372, mean: 0.09840
[32m[0906 13-52-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03544, current rewards: 34.35516, mean: 0.09543
[32m[0906 13-52-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03541, current rewards: 39.90277, mean: 0.09732
[32m[0906 13-52-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03539, current rewards: 45.44911, mean: 0.09880
[32m[0906 13-52-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03545, current rewards: 50.99320, mean: 0.09999
[32m[0906 13-52-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03551, current rewards: 56.54080, mean: 0.10097
[32m[0906 13-52-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03558, current rewards: 62.08822, mean: 0.10178
[32m[0906 13-52-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03563, current rewards: 67.81442, mean: 0.10275
[32m[0906 13-52-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03567, current rewards: 73.39120, mean: 0.10337
[32m[0906 13-52-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03570, current rewards: 78.96678, mean: 0.10390
[32m[0906 13-52-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03573, current rewards: 83.43174, mean: 0.10300
[32m[0906 13-52-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03576, current rewards: 88.75304, mean: 0.10320
[32m[0906 13-52-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03578, current rewards: 94.12356, mean: 0.10343
[32m[0906 13-52-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03578, current rewards: 99.49622, mean: 0.10364
[32m[0906 13-52-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03579, current rewards: 104.86620, mean: 0.10383
[32m[0906 13-52-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03582, current rewards: 110.17505, mean: 0.10394
[32m[0906 13-52-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03584, current rewards: 115.63226, mean: 0.10417
[32m[0906 13-52-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03585, current rewards: 121.08719, mean: 0.10439
[32m[0906 13-52-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03586, current rewards: 126.54353, mean: 0.10458
[32m[0906 13-52-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03587, current rewards: 129.85505, mean: 0.10306
[32m[0906 13-52-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03589, current rewards: 135.24071, mean: 0.10324
[32m[0906 13-52-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03590, current rewards: 140.63103, mean: 0.10341
[32m[0906 13-52-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03591, current rewards: 146.01926, mean: 0.10356
[32m[0906 13-52-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03592, current rewards: 151.16667, mean: 0.10354
[32m[0906 13-52-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03594, current rewards: 156.51128, mean: 0.10365
[32m[0906 13-52-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03595, current rewards: 161.86469, mean: 0.10376
[32m[0906 13-52-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03593, current rewards: 167.21791, mean: 0.10386
[32m[0906 13-52-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03591, current rewards: 168.35800, mean: 0.10142
[32m[0906 13-52-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03588, current rewards: 173.83451, mean: 0.10166
[32m[0906 13-52-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03584, current rewards: 179.33546, mean: 0.10190
[32m[0906 13-53-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03580, current rewards: 184.83633, mean: 0.10212
[32m[0906 13-53-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03577, current rewards: 190.33778, mean: 0.10233
[32m[0906 13-53-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03574, current rewards: 195.85764, mean: 0.10254
[32m[0906 13-53-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03570, current rewards: 201.36751, mean: 0.10274
[32m[0906 13-53-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03567, current rewards: 206.87525, mean: 0.10292
[32m[0906 13-53-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03565, current rewards: 212.37994, mean: 0.10310
[32m[0906 13-53-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03562, current rewards: 217.88639, mean: 0.10326
[32m[0906 13-53-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03562, current rewards: 223.39209, mean: 0.10342
[32m[0906 13-53-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03564, current rewards: 228.90067, mean: 0.10357
[32m[0906 13-53-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03565, current rewards: 234.40756, mean: 0.10372
[32m[0906 13-53-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03566, current rewards: 239.88670, mean: 0.10385
[32m[0906 13-53-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03565, current rewards: 245.38524, mean: 0.10398
[32m[0906 13-53-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03564, current rewards: 250.88383, mean: 0.10410
[32m[0906 13-53-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03564, current rewards: 256.38634, mean: 0.10422
[32m[0906 13-53-25 @Agent.py:117][0m Average action selection time: 0.0356
[32m[0906 13-53-25 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-53-25 @MBExp.py:227][0m Rewards obtained: [260.78613371366333], Lows: [4], Highs: [4], Total time: 763.695452
[32m[0906 13-53-46 @MBExp.py:144][0m ####################################################################
[32m[0906 13-53-46 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 13-53-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03508, current rewards: -3.20208, mean: -0.32021
[32m[0906 13-53-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03538, current rewards: 1.91147, mean: 0.03186
[32m[0906 13-53-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03532, current rewards: 7.01860, mean: 0.06381
[32m[0906 13-53-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03536, current rewards: 12.11799, mean: 0.07574
[32m[0906 13-53-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03540, current rewards: 17.48807, mean: 0.08328
[32m[0906 13-53-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03540, current rewards: 22.71386, mean: 0.08736
[32m[0906 13-53-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03540, current rewards: 28.43023, mean: 0.09171
[32m[0906 13-53-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03538, current rewards: 33.62544, mean: 0.09340
[32m[0906 13-54-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03538, current rewards: 38.81904, mean: 0.09468
[32m[0906 13-54-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03548, current rewards: 44.01326, mean: 0.09568
[32m[0906 13-54-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03554, current rewards: 49.21091, mean: 0.09649
[32m[0906 13-54-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03559, current rewards: 54.40384, mean: 0.09715
[32m[0906 13-54-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03564, current rewards: 59.44999, mean: 0.09746
[32m[0906 13-54-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03569, current rewards: 64.58970, mean: 0.09786
[32m[0906 13-54-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03572, current rewards: 69.73995, mean: 0.09823
[32m[0906 13-54-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03574, current rewards: 74.88711, mean: 0.09854
[32m[0906 13-54-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03576, current rewards: 75.59537, mean: 0.09333
[32m[0906 13-54-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03577, current rewards: 80.33989, mean: 0.09342
[32m[0906 13-54-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03580, current rewards: 85.08501, mean: 0.09350
[32m[0906 13-54-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03582, current rewards: 89.82647, mean: 0.09357
[32m[0906 13-54-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03584, current rewards: 94.56836, mean: 0.09363
[32m[0906 13-54-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03585, current rewards: 99.27908, mean: 0.09366
[32m[0906 13-54-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03586, current rewards: 104.00469, mean: 0.09370
[32m[0906 13-54-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03588, current rewards: 108.73212, mean: 0.09373
[32m[0906 13-54-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03590, current rewards: 113.46121, mean: 0.09377
[32m[0906 13-54-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03591, current rewards: 118.18802, mean: 0.09380
[32m[0906 13-54-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03592, current rewards: 122.91607, mean: 0.09383
[32m[0906 13-54-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03593, current rewards: 127.64256, mean: 0.09385
[32m[0906 13-54-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03595, current rewards: 132.37135, mean: 0.09388
[32m[0906 13-54-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03595, current rewards: 137.26464, mean: 0.09402
[32m[0906 13-54-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03596, current rewards: 141.10868, mean: 0.09345
[32m[0906 13-54-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03594, current rewards: 146.14427, mean: 0.09368
[32m[0906 13-54-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03590, current rewards: 151.17908, mean: 0.09390
[32m[0906 13-54-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03585, current rewards: 156.21051, mean: 0.09410
[32m[0906 13-54-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03582, current rewards: 161.24773, mean: 0.09430
[32m[0906 13-54-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03578, current rewards: 166.28319, mean: 0.09448
[32m[0906 13-54-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03576, current rewards: 171.31953, mean: 0.09465
[32m[0906 13-54-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03572, current rewards: 175.22563, mean: 0.09421
[32m[0906 13-54-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03569, current rewards: 180.39867, mean: 0.09445
[32m[0906 13-54-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03566, current rewards: 185.56588, mean: 0.09468
[32m[0906 13-54-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03564, current rewards: 190.73497, mean: 0.09489
[32m[0906 13-55-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03562, current rewards: 195.90667, mean: 0.09510
[32m[0906 13-55-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03560, current rewards: 201.07303, mean: 0.09530
[32m[0906 13-55-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03562, current rewards: 206.23954, mean: 0.09548
[32m[0906 13-55-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03563, current rewards: 211.40681, mean: 0.09566
[32m[0906 13-55-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03564, current rewards: 216.69412, mean: 0.09588
[32m[0906 13-55-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03563, current rewards: 221.89608, mean: 0.09606
[32m[0906 13-55-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03563, current rewards: 227.02301, mean: 0.09620
[32m[0906 13-55-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03563, current rewards: 232.21169, mean: 0.09635
[32m[0906 13-55-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03562, current rewards: 237.40364, mean: 0.09651
[32m[0906 13-55-15 @Agent.py:117][0m Average action selection time: 0.0356
[32m[0906 13-55-15 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-55-15 @MBExp.py:227][0m Rewards obtained: [241.55933823204438], Lows: [3], Highs: [4], Total time: 853.3757800000001
[32m[0906 13-55-38 @MBExp.py:144][0m ####################################################################
[32m[0906 13-55-38 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 13-55-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03544, current rewards: -1.10151, mean: -0.11015
[32m[0906 13-55-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03541, current rewards: 4.50534, mean: 0.07509
[32m[0906 13-55-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03536, current rewards: 10.11703, mean: 0.09197
[32m[0906 13-55-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03534, current rewards: 15.70051, mean: 0.09813
[32m[0906 13-55-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03533, current rewards: 21.30006, mean: 0.10143
[32m[0906 13-55-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03535, current rewards: 26.90465, mean: 0.10348
[32m[0906 13-55-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03536, current rewards: 32.51096, mean: 0.10487
[32m[0906 13-55-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03546, current rewards: 38.11888, mean: 0.10589
[32m[0906 13-55-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03554, current rewards: 43.71856, mean: 0.10663
[32m[0906 13-55-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03559, current rewards: 49.32108, mean: 0.10722
[32m[0906 13-55-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03563, current rewards: 50.74619, mean: 0.09950
[32m[0906 13-55-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03566, current rewards: 56.28790, mean: 0.10051
[32m[0906 13-56-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03570, current rewards: 61.86337, mean: 0.10142
[32m[0906 13-56-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03575, current rewards: 67.43860, mean: 0.10218
[32m[0906 13-56-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03577, current rewards: 73.01493, mean: 0.10284
[32m[0906 13-56-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03578, current rewards: 78.58915, mean: 0.10341
[32m[0906 13-56-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03580, current rewards: 84.16450, mean: 0.10391
[32m[0906 13-56-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03581, current rewards: 89.74029, mean: 0.10435
[32m[0906 13-56-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03582, current rewards: 95.31718, mean: 0.10474
[32m[0906 13-56-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03584, current rewards: 100.90375, mean: 0.10511
[32m[0906 13-56-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03585, current rewards: 106.47691, mean: 0.10542
[32m[0906 13-56-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03587, current rewards: 110.89635, mean: 0.10462
[32m[0906 13-56-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03588, current rewards: 116.46481, mean: 0.10492
[32m[0906 13-56-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03589, current rewards: 122.03273, mean: 0.10520
[32m[0906 13-56-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03590, current rewards: 127.60368, mean: 0.10546
[32m[0906 13-56-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03591, current rewards: 133.16676, mean: 0.10569
[32m[0906 13-56-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03591, current rewards: 138.73583, mean: 0.10591
[32m[0906 13-56-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03593, current rewards: 144.31895, mean: 0.10612
[32m[0906 13-56-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03594, current rewards: 149.88943, mean: 0.10630
[32m[0906 13-56-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03594, current rewards: 155.45397, mean: 0.10648
[32m[0906 13-56-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03589, current rewards: 161.02009, mean: 0.10664
[32m[0906 13-56-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03585, current rewards: 165.47135, mean: 0.10607
[32m[0906 13-56-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03582, current rewards: 171.06865, mean: 0.10625
[32m[0906 13-56-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03578, current rewards: 176.67489, mean: 0.10643
[32m[0906 13-56-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03574, current rewards: 182.27743, mean: 0.10659
[32m[0906 13-56-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03570, current rewards: 187.81534, mean: 0.10671
[32m[0906 13-56-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03567, current rewards: 193.41312, mean: 0.10686
[32m[0906 13-56-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03564, current rewards: 199.01157, mean: 0.10700
[32m[0906 13-56-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03561, current rewards: 204.60733, mean: 0.10712
[32m[0906 13-56-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03558, current rewards: 210.20222, mean: 0.10725
[32m[0906 13-56-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03556, current rewards: 215.73142, mean: 0.10733
[32m[0906 13-56-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03554, current rewards: 221.32240, mean: 0.10744
[32m[0906 13-56-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03554, current rewards: 226.91562, mean: 0.10754
[32m[0906 13-56-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03555, current rewards: 232.45887, mean: 0.10762
[32m[0906 13-56-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03556, current rewards: 237.93624, mean: 0.10766
[32m[0906 13-56-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03556, current rewards: 243.48594, mean: 0.10774
[32m[0906 13-57-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03555, current rewards: 249.03181, mean: 0.10781
[32m[0906 13-57-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03555, current rewards: 254.58508, mean: 0.10788
[32m[0906 13-57-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03555, current rewards: 260.13497, mean: 0.10794
[32m[0906 13-57-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03554, current rewards: 265.68106, mean: 0.10800
[32m[0906 13-57-08 @Agent.py:117][0m Average action selection time: 0.0355
[32m[0906 13-57-08 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-57-08 @MBExp.py:227][0m Rewards obtained: [270.11707642187713], Lows: [2], Highs: [4], Total time: 942.849041
[32m[0906 13-57-33 @MBExp.py:144][0m ####################################################################
[32m[0906 13-57-33 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 13-57-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03550, current rewards: -1.26497, mean: -0.12650
[32m[0906 13-57-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03512, current rewards: 3.69874, mean: 0.06165
[32m[0906 13-57-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03530, current rewards: 8.65420, mean: 0.07867
[32m[0906 13-57-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03535, current rewards: 13.58042, mean: 0.08488
[32m[0906 13-57-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03534, current rewards: 18.51386, mean: 0.08816
[32m[0906 13-57-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03536, current rewards: 23.44789, mean: 0.09018
[32m[0906 13-57-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03551, current rewards: 28.38289, mean: 0.09156
[32m[0906 13-57-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03564, current rewards: 33.30492, mean: 0.09251
[32m[0906 13-57-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03570, current rewards: 38.23211, mean: 0.09325
[32m[0906 13-57-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03575, current rewards: 43.16228, mean: 0.09383
[32m[0906 13-57-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03577, current rewards: 48.07240, mean: 0.09426
[32m[0906 13-57-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03580, current rewards: 52.97497, mean: 0.09460
[32m[0906 13-57-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03582, current rewards: 57.88055, mean: 0.09489
[32m[0906 13-57-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03587, current rewards: 62.78876, mean: 0.09513
[32m[0906 13-57-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03589, current rewards: 67.69426, mean: 0.09534
[32m[0906 13-58-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03590, current rewards: 72.60105, mean: 0.09553
[32m[0906 13-58-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03590, current rewards: 75.55354, mean: 0.09328
[32m[0906 13-58-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03591, current rewards: 81.16003, mean: 0.09437
[32m[0906 13-58-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03593, current rewards: 86.79318, mean: 0.09538
[32m[0906 13-58-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03593, current rewards: 92.38012, mean: 0.09623
[32m[0906 13-58-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03594, current rewards: 97.97029, mean: 0.09700
[32m[0906 13-58-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03594, current rewards: 103.55024, mean: 0.09769
[32m[0906 13-58-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03595, current rewards: 109.14115, mean: 0.09833
[32m[0906 13-58-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03596, current rewards: 114.73126, mean: 0.09891
[32m[0906 13-58-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03597, current rewards: 120.31738, mean: 0.09944
[32m[0906 13-58-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03598, current rewards: 125.90223, mean: 0.09992
[32m[0906 13-58-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03599, current rewards: 131.47497, mean: 0.10036
[32m[0906 13-58-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03597, current rewards: 135.37434, mean: 0.09954
[32m[0906 13-58-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03594, current rewards: 140.91152, mean: 0.09994
[32m[0906 13-58-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03589, current rewards: 146.44541, mean: 0.10031
[32m[0906 13-58-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03585, current rewards: 151.98026, mean: 0.10065
[32m[0906 13-58-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03581, current rewards: 157.51678, mean: 0.10097
[32m[0906 13-58-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03577, current rewards: 163.05516, mean: 0.10128
[32m[0906 13-58-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03573, current rewards: 168.59593, mean: 0.10156
[32m[0906 13-58-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03570, current rewards: 174.14615, mean: 0.10184
[32m[0906 13-58-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03567, current rewards: 179.68305, mean: 0.10209
[32m[0906 13-58-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03564, current rewards: 185.22241, mean: 0.10233
[32m[0906 13-58-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03561, current rewards: 190.76219, mean: 0.10256
[32m[0906 13-58-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03558, current rewards: 196.29954, mean: 0.10277
[32m[0906 13-58-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03556, current rewards: 201.83945, mean: 0.10298
[32m[0906 13-58-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03554, current rewards: 207.38057, mean: 0.10317
[32m[0906 13-58-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03553, current rewards: 211.74409, mean: 0.10279
[32m[0906 13-58-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03553, current rewards: 217.11682, mean: 0.10290
[32m[0906 13-58-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03553, current rewards: 222.47227, mean: 0.10300
[32m[0906 13-58-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03553, current rewards: 227.82875, mean: 0.10309
[32m[0906 13-58-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03552, current rewards: 233.18746, mean: 0.10318
[32m[0906 13-58-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03553, current rewards: 238.54374, mean: 0.10327
[32m[0906 13-58-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03553, current rewards: 243.90149, mean: 0.10335
[32m[0906 13-58-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03552, current rewards: 249.25670, mean: 0.10343
[32m[0906 13-59-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03552, current rewards: 254.61481, mean: 0.10350
[32m[0906 13-59-02 @Agent.py:117][0m Average action selection time: 0.0355
[32m[0906 13-59-02 @Agent.py:118][0m Rollout length: 2501
[32m[0906 13-59-02 @MBExp.py:227][0m Rewards obtained: [256.8477752561998], Lows: [3], Highs: [3], Total time: 1032.261782
[32m[0906 13-59-29 @MBExp.py:144][0m ####################################################################
[32m[0906 13-59-29 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 13-59-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03502, current rewards: -1.19814, mean: -0.11981
[32m[0906 13-59-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03529, current rewards: 4.35404, mean: 0.07257
[32m[0906 13-59-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03531, current rewards: 9.95322, mean: 0.09048
[32m[0906 13-59-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03526, current rewards: 15.54320, mean: 0.09715
[32m[0906 13-59-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03536, current rewards: 21.13404, mean: 0.10064
[32m[0906 13-59-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03554, current rewards: 26.72681, mean: 0.10280
[32m[0906 13-59-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03565, current rewards: 31.14835, mean: 0.10048
[32m[0906 13-59-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03571, current rewards: 36.56364, mean: 0.10157
[32m[0906 13-59-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03576, current rewards: 41.97267, mean: 0.10237
[32m[0906 13-59-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03580, current rewards: 47.43350, mean: 0.10312
[32m[0906 13-59-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03583, current rewards: 52.84222, mean: 0.10361
[32m[0906 13-59-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03584, current rewards: 58.25837, mean: 0.10403
[32m[0906 13-59-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03586, current rewards: 63.67480, mean: 0.10438
[32m[0906 13-59-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03589, current rewards: 69.08886, mean: 0.10468
[32m[0906 13-59-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03591, current rewards: 74.50409, mean: 0.10494
[32m[0906 13-59-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03593, current rewards: 79.92002, mean: 0.10516
[32m[0906 13-59-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03594, current rewards: 85.33700, mean: 0.10535
[32m[0906 14-00-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03596, current rewards: 90.68215, mean: 0.10544
[32m[0906 14-00-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03598, current rewards: 96.08933, mean: 0.10559
[32m[0906 14-00-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03598, current rewards: 97.24936, mean: 0.10130
[32m[0906 14-00-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03599, current rewards: 102.80897, mean: 0.10179
[32m[0906 14-00-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03601, current rewards: 108.37385, mean: 0.10224
[32m[0906 14-00-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03602, current rewards: 113.93465, mean: 0.10264
[32m[0906 14-00-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03603, current rewards: 119.49812, mean: 0.10302
[32m[0906 14-00-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03604, current rewards: 125.06151, mean: 0.10336
[32m[0906 14-00-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03601, current rewards: 130.66452, mean: 0.10370
[32m[0906 14-00-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03598, current rewards: 136.22445, mean: 0.10399
[32m[0906 14-00-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03595, current rewards: 141.78248, mean: 0.10425
[32m[0906 14-00-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03590, current rewards: 147.33732, mean: 0.10449
[32m[0906 14-00-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03585, current rewards: 152.89689, mean: 0.10472
[32m[0906 14-00-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03581, current rewards: 158.45419, mean: 0.10494
[32m[0906 14-00-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03577, current rewards: 164.01301, mean: 0.10514
[32m[0906 14-00-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03573, current rewards: 168.42475, mean: 0.10461
[32m[0906 14-00-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03570, current rewards: 174.01992, mean: 0.10483
[32m[0906 14-00-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03567, current rewards: 179.60509, mean: 0.10503
[32m[0906 14-00-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03563, current rewards: 185.19234, mean: 0.10522
[32m[0906 14-00-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03560, current rewards: 190.78612, mean: 0.10541
[32m[0906 14-00-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03557, current rewards: 196.37940, mean: 0.10558
[32m[0906 14-00-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03554, current rewards: 201.97515, mean: 0.10575
[32m[0906 14-00-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03554, current rewards: 207.56779, mean: 0.10590
[32m[0906 14-00-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03554, current rewards: 213.15811, mean: 0.10605
[32m[0906 14-00-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03554, current rewards: 218.94885, mean: 0.10629
[32m[0906 14-00-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03551, current rewards: 222.72529, mean: 0.10556
[32m[0906 14-00-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03551, current rewards: 228.37089, mean: 0.10573
[32m[0906 14-00-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03550, current rewards: 234.01178, mean: 0.10589
[32m[0906 14-00-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03550, current rewards: 239.65506, mean: 0.10604
[32m[0906 14-00-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03550, current rewards: 244.11075, mean: 0.10568
[32m[0906 14-00-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03550, current rewards: 249.70301, mean: 0.10581
[32m[0906 14-00-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03549, current rewards: 255.29198, mean: 0.10593
[32m[0906 14-00-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03549, current rewards: 260.87954, mean: 0.10605
[32m[0906 14-00-58 @Agent.py:117][0m Average action selection time: 0.0355
[32m[0906 14-00-58 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-00-58 @MBExp.py:227][0m Rewards obtained: [265.09608522682817], Lows: [3], Highs: [5], Total time: 1121.611353
[32m[0906 14-01-27 @MBExp.py:144][0m ####################################################################
[32m[0906 14-01-27 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 14-01-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03610, current rewards: -0.14278, mean: -0.01428
[32m[0906 14-01-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03536, current rewards: 5.27595, mean: 0.08793
[32m[0906 14-01-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03532, current rewards: 10.77305, mean: 0.09794
[32m[0906 14-01-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03560, current rewards: 16.26845, mean: 0.10168
[32m[0906 14-01-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03585, current rewards: 21.76805, mean: 0.10366
[32m[0906 14-01-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03593, current rewards: 27.26327, mean: 0.10486
[32m[0906 14-01-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03598, current rewards: 32.75478, mean: 0.10566
[32m[0906 14-01-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03602, current rewards: 38.24705, mean: 0.10624
[32m[0906 14-01-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03603, current rewards: 43.74472, mean: 0.10669
[32m[0906 14-01-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03605, current rewards: 49.57758, mean: 0.10778
[32m[0906 14-01-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03607, current rewards: 55.06014, mean: 0.10796
[32m[0906 14-01-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03607, current rewards: 60.54312, mean: 0.10811
[32m[0906 14-01-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03606, current rewards: 66.03025, mean: 0.10825
[32m[0906 14-01-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03606, current rewards: 71.51578, mean: 0.10836
[32m[0906 14-01-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03607, current rewards: 74.94772, mean: 0.10556
[32m[0906 14-01-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03608, current rewards: 83.73639, mean: 0.11018
[32m[0906 14-01-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03608, current rewards: 92.52505, mean: 0.11423
[32m[0906 14-01-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03608, current rewards: 87.50240, mean: 0.10175
[32m[0906 14-02-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03610, current rewards: 92.96748, mean: 0.10216
[32m[0906 14-02-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03610, current rewards: 98.43126, mean: 0.10253
[32m[0906 14-02-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03611, current rewards: 103.89368, mean: 0.10287
[32m[0906 14-02-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03612, current rewards: 109.35637, mean: 0.10317
[32m[0906 14-02-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03610, current rewards: 114.81850, mean: 0.10344
[32m[0906 14-02-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03607, current rewards: 120.28159, mean: 0.10369
[32m[0906 14-02-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03604, current rewards: 125.74514, mean: 0.10392
[32m[0906 14-02-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03601, current rewards: 131.11499, mean: 0.10406
[32m[0906 14-02-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03596, current rewards: 136.48433, mean: 0.10419
[32m[0906 14-02-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03590, current rewards: 140.85837, mean: 0.10357
[32m[0906 14-02-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03585, current rewards: 146.42643, mean: 0.10385
[32m[0906 14-02-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03580, current rewards: 152.00010, mean: 0.10411
[32m[0906 14-02-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03576, current rewards: 157.56855, mean: 0.10435
[32m[0906 14-02-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03572, current rewards: 163.13354, mean: 0.10457
[32m[0906 14-02-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03568, current rewards: 168.70282, mean: 0.10478
[32m[0906 14-02-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03565, current rewards: 174.27698, mean: 0.10499
[32m[0906 14-02-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03561, current rewards: 179.79299, mean: 0.10514
[32m[0906 14-02-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03558, current rewards: 185.34320, mean: 0.10531
[32m[0906 14-02-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03555, current rewards: 190.89659, mean: 0.10547
[32m[0906 14-02-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03552, current rewards: 196.44631, mean: 0.10562
[32m[0906 14-02-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03552, current rewards: 201.99468, mean: 0.10576
[32m[0906 14-02-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03552, current rewards: 206.37259, mean: 0.10529
[32m[0906 14-02-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03551, current rewards: 211.80856, mean: 0.10538
[32m[0906 14-02-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03548, current rewards: 217.23221, mean: 0.10545
[32m[0906 14-02-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03546, current rewards: 222.93227, mean: 0.10566
[32m[0906 14-02-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03546, current rewards: 228.47574, mean: 0.10578
[32m[0906 14-02-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03546, current rewards: 234.02203, mean: 0.10589
[32m[0906 14-02-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03546, current rewards: 239.56614, mean: 0.10600
[32m[0906 14-02-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03546, current rewards: 245.10697, mean: 0.10611
[32m[0906 14-02-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03545, current rewards: 250.65199, mean: 0.10621
[32m[0906 14-02-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03545, current rewards: 257.03618, mean: 0.10665
[32m[0906 14-02-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03545, current rewards: 262.65854, mean: 0.10677
[32m[0906 14-02-56 @Agent.py:117][0m Average action selection time: 0.0354
[32m[0906 14-02-56 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-02-56 @MBExp.py:227][0m Rewards obtained: [267.1518222571707], Lows: [2], Highs: [14], Total time: 1210.862146
[32m[0906 14-03-27 @MBExp.py:144][0m ####################################################################
[32m[0906 14-03-27 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 14-03-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03486, current rewards: -1.01918, mean: -0.10192
[32m[0906 14-03-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03548, current rewards: 5.06927, mean: 0.08449
[32m[0906 14-03-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03578, current rewards: 10.88922, mean: 0.09899
[32m[0906 14-03-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03584, current rewards: 16.71528, mean: 0.10447
[32m[0906 14-03-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03586, current rewards: 22.54304, mean: 0.10735
[32m[0906 14-03-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03589, current rewards: 28.36857, mean: 0.10911
[32m[0906 14-03-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03590, current rewards: 32.29815, mean: 0.10419
[32m[0906 14-03-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03597, current rewards: 37.90708, mean: 0.10530
[32m[0906 14-03-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03598, current rewards: 43.50894, mean: 0.10612
[32m[0906 14-03-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03600, current rewards: 49.11243, mean: 0.10677
[32m[0906 14-03-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03601, current rewards: 54.71435, mean: 0.10728
[32m[0906 14-03-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03602, current rewards: 59.20242, mean: 0.10572
[32m[0906 14-03-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03603, current rewards: 64.85463, mean: 0.10632
[32m[0906 14-03-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03607, current rewards: 70.50335, mean: 0.10682
[32m[0906 14-03-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03609, current rewards: 76.15517, mean: 0.10726
[32m[0906 14-03-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03609, current rewards: 81.80050, mean: 0.10763
[32m[0906 14-03-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03609, current rewards: 87.45512, mean: 0.10797
[32m[0906 14-03-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03610, current rewards: 93.06191, mean: 0.10821
[32m[0906 14-04-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03610, current rewards: 98.73438, mean: 0.10850
[32m[0906 14-04-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03610, current rewards: 104.39998, mean: 0.10875
[32m[0906 14-04-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03606, current rewards: 110.06340, mean: 0.10897
[32m[0906 14-04-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03602, current rewards: 115.72902, mean: 0.10918
[32m[0906 14-04-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03601, current rewards: 118.56981, mean: 0.10682
[32m[0906 14-04-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03598, current rewards: 125.66636, mean: 0.10833
[32m[0906 14-04-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03595, current rewards: 132.76292, mean: 0.10972
[32m[0906 14-04-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03590, current rewards: 139.44540, mean: 0.11067
[32m[0906 14-04-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03585, current rewards: 145.62308, mean: 0.11116
[32m[0906 14-04-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03580, current rewards: 150.67721, mean: 0.11079
[32m[0906 14-04-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03576, current rewards: 100.67721, mean: 0.07140
[32m[0906 14-04-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03572, current rewards: 50.67721, mean: 0.03471
[32m[0906 14-04-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03568, current rewards: 0.67721, mean: 0.00045
[32m[0906 14-04-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03564, current rewards: -49.32279, mean: -0.03162
[32m[0906 14-04-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03561, current rewards: -99.32279, mean: -0.06169
[32m[0906 14-04-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03557, current rewards: -149.32279, mean: -0.08995
[32m[0906 14-04-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03554, current rewards: -184.33247, mean: -0.10780
[32m[0906 14-04-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03551, current rewards: -176.67739, mean: -0.10038
[32m[0906 14-04-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03549, current rewards: -169.02231, mean: -0.09338
[32m[0906 14-04-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03549, current rewards: -161.36723, mean: -0.08676
[32m[0906 14-04-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03548, current rewards: -153.71215, mean: -0.08048
[32m[0906 14-04-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03546, current rewards: -146.05707, mean: -0.07452
[32m[0906 14-04-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03544, current rewards: -147.62680, mean: -0.07345
[32m[0906 14-04-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03542, current rewards: -197.62680, mean: -0.09594
[32m[0906 14-04-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03540, current rewards: -247.62680, mean: -0.11736
[32m[0906 14-04-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03540, current rewards: -297.62680, mean: -0.13779
[32m[0906 14-04-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03540, current rewards: -347.62680, mean: -0.15730
[32m[0906 14-04-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03540, current rewards: -397.62680, mean: -0.17594
[32m[0906 14-04-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03540, current rewards: -447.62680, mean: -0.19378
[32m[0906 14-04-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03540, current rewards: -497.62680, mean: -0.21086
[32m[0906 14-04-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03540, current rewards: -547.62680, mean: -0.22723
[32m[0906 14-04-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03540, current rewards: -597.62680, mean: -0.24294
[32m[0906 14-04-56 @Agent.py:117][0m Average action selection time: 0.0354
[32m[0906 14-04-56 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-04-56 @MBExp.py:227][0m Rewards obtained: [-637.6268021150299], Lows: [3], Highs: [839], Total time: 1299.986441
[32m[0906 14-05-29 @MBExp.py:144][0m ####################################################################
[32m[0906 14-05-29 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 14-05-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03560, current rewards: 0.14504, mean: 0.01450
[32m[0906 14-05-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03592, current rewards: 5.82404, mean: 0.09707
[32m[0906 14-05-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03596, current rewards: 11.49884, mean: 0.10453
[32m[0906 14-05-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03607, current rewards: 17.17375, mean: 0.10734
[32m[0906 14-05-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03611, current rewards: 21.84700, mean: 0.10403
[32m[0906 14-05-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03615, current rewards: 27.65057, mean: 0.10635
[32m[0906 14-05-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03610, current rewards: 33.44524, mean: 0.10789
[32m[0906 14-05-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03611, current rewards: 39.24442, mean: 0.10901
[32m[0906 14-05-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03609, current rewards: 44.97922, mean: 0.10971
[32m[0906 14-05-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03608, current rewards: 48.57980, mean: 0.10561
[32m[0906 14-05-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03607, current rewards: 54.24853, mean: 0.10637
[32m[0906 14-05-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03606, current rewards: 59.92564, mean: 0.10701
[32m[0906 14-05-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03605, current rewards: 65.59672, mean: 0.10754
[32m[0906 14-05-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03606, current rewards: 71.26653, mean: 0.10798
[32m[0906 14-05-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03607, current rewards: 76.93770, mean: 0.10836
[32m[0906 14-05-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03607, current rewards: 82.60692, mean: 0.10869
[32m[0906 14-05-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03607, current rewards: 88.17964, mean: 0.10886
[32m[0906 14-06-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03605, current rewards: 93.67121, mean: 0.10892
[32m[0906 14-06-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03600, current rewards: 99.23935, mean: 0.10905
[32m[0906 14-06-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03596, current rewards: 104.80421, mean: 0.10917
[32m[0906 14-06-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03592, current rewards: 110.36952, mean: 0.10928
[32m[0906 14-06-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03589, current rewards: 115.93994, mean: 0.10938
[32m[0906 14-06-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03587, current rewards: 121.51212, mean: 0.10947
[32m[0906 14-06-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03584, current rewards: 125.03390, mean: 0.10779
[32m[0906 14-06-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03578, current rewards: 130.69943, mean: 0.10802
[32m[0906 14-06-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03574, current rewards: 136.57310, mean: 0.10839
[32m[0906 14-06-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03569, current rewards: 142.28701, mean: 0.10862
[32m[0906 14-06-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03565, current rewards: 147.99954, mean: 0.10882
[32m[0906 14-06-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03561, current rewards: 153.71341, mean: 0.10902
[32m[0906 14-06-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03557, current rewards: 159.42515, mean: 0.10920
[32m[0906 14-06-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03553, current rewards: 165.13330, mean: 0.10936
[32m[0906 14-06-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03550, current rewards: 170.84707, mean: 0.10952
[32m[0906 14-06-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03546, current rewards: 176.56302, mean: 0.10967
[32m[0906 14-06-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03542, current rewards: 181.00621, mean: 0.10904
[32m[0906 14-06-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03540, current rewards: 186.48805, mean: 0.10906
[32m[0906 14-06-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03539, current rewards: 191.96851, mean: 0.10907
[32m[0906 14-06-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03539, current rewards: 197.45283, mean: 0.10909
[32m[0906 14-06-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03538, current rewards: 202.93481, mean: 0.10910
[32m[0906 14-06-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03536, current rewards: 208.41686, mean: 0.10912
[32m[0906 14-06-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03535, current rewards: 213.89547, mean: 0.10913
[32m[0906 14-06-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03533, current rewards: 219.37489, mean: 0.10914
[32m[0906 14-06-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03532, current rewards: 224.84221, mean: 0.10915
[32m[0906 14-06-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03530, current rewards: 229.23443, mean: 0.10864
[32m[0906 14-06-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03530, current rewards: 234.89424, mean: 0.10875
[32m[0906 14-06-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03530, current rewards: 240.55194, mean: 0.10885
[32m[0906 14-06-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03531, current rewards: 246.21394, mean: 0.10894
[32m[0906 14-06-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03531, current rewards: 251.87256, mean: 0.10904
[32m[0906 14-06-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03531, current rewards: 257.53336, mean: 0.10912
[32m[0906 14-06-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03531, current rewards: 263.18921, mean: 0.10921
[32m[0906 14-06-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03531, current rewards: 268.90050, mean: 0.10931
[32m[0906 14-06-58 @Agent.py:117][0m Average action selection time: 0.0353
[32m[0906 14-06-58 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-06-58 @MBExp.py:227][0m Rewards obtained: [273.43372983238464], Lows: [2], Highs: [4], Total time: 1388.865249
[32m[0906 14-07-33 @MBExp.py:144][0m ####################################################################
[32m[0906 14-07-33 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 14-07-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03563, current rewards: -1.09080, mean: -0.10908
[32m[0906 14-07-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03610, current rewards: 4.49692, mean: 0.07495
[32m[0906 14-07-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03614, current rewards: 10.09145, mean: 0.09174
[32m[0906 14-07-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03614, current rewards: 15.68842, mean: 0.09805
[32m[0906 14-07-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03616, current rewards: 21.28581, mean: 0.10136
[32m[0906 14-07-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03619, current rewards: 26.87980, mean: 0.10338
[32m[0906 14-07-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03619, current rewards: 30.78516, mean: 0.09931
[32m[0906 14-07-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03618, current rewards: 36.52044, mean: 0.10145
[32m[0906 14-07-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03617, current rewards: 42.26573, mean: 0.10309
[32m[0906 14-07-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03617, current rewards: 48.01000, mean: 0.10437
[32m[0906 14-07-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03617, current rewards: 53.75518, mean: 0.10540
[32m[0906 14-07-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03614, current rewards: 59.50089, mean: 0.10625
[32m[0906 14-07-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03614, current rewards: 65.24580, mean: 0.10696
[32m[0906 14-07-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03615, current rewards: 70.99102, mean: 0.10756
[32m[0906 14-07-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03615, current rewards: 76.73551, mean: 0.10808
[32m[0906 14-08-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03607, current rewards: 82.49242, mean: 0.10854
[32m[0906 14-08-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03603, current rewards: 87.12170, mean: 0.10756
[32m[0906 14-08-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03599, current rewards: 91.70195, mean: 0.10663
[32m[0906 14-08-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03596, current rewards: 97.39187, mean: 0.10702
[32m[0906 14-08-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03593, current rewards: 103.07593, mean: 0.10737
[32m[0906 14-08-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03591, current rewards: 108.76260, mean: 0.10769
[32m[0906 14-08-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03589, current rewards: 114.45102, mean: 0.10797
[32m[0906 14-08-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03585, current rewards: 120.13941, mean: 0.10823
[32m[0906 14-08-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03580, current rewards: 125.76991, mean: 0.10842
[32m[0906 14-08-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03575, current rewards: 130.51664, mean: 0.10786
[32m[0906 14-08-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03570, current rewards: 136.10851, mean: 0.10802
[32m[0906 14-08-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03566, current rewards: 141.69876, mean: 0.10817
[32m[0906 14-08-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03561, current rewards: 147.29092, mean: 0.10830
[32m[0906 14-08-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03558, current rewards: 152.88482, mean: 0.10843
[32m[0906 14-08-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03554, current rewards: 158.47276, mean: 0.10854
[32m[0906 14-08-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03551, current rewards: 164.06501, mean: 0.10865
[32m[0906 14-08-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03547, current rewards: 169.65585, mean: 0.10875
[32m[0906 14-08-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03545, current rewards: 175.25003, mean: 0.10885
[32m[0906 14-08-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03542, current rewards: 181.55727, mean: 0.10937
[32m[0906 14-08-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03543, current rewards: 186.99037, mean: 0.10935
[32m[0906 14-08-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03542, current rewards: 192.46167, mean: 0.10935
[32m[0906 14-08-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03542, current rewards: 197.91652, mean: 0.10935
[32m[0906 14-08-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03539, current rewards: 203.35738, mean: 0.10933
[32m[0906 14-08-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03537, current rewards: 207.02182, mean: 0.10839
[32m[0906 14-08-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03535, current rewards: 213.09523, mean: 0.10872
[32m[0906 14-08-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03533, current rewards: 219.04003, mean: 0.10898
[32m[0906 14-08-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03532, current rewards: 224.95146, mean: 0.10920
[32m[0906 14-08-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03531, current rewards: 230.86582, mean: 0.10942
[32m[0906 14-08-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03532, current rewards: 236.77213, mean: 0.10962
[32m[0906 14-08-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03531, current rewards: 242.68422, mean: 0.10981
[32m[0906 14-08-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03531, current rewards: 248.59336, mean: 0.11000
[32m[0906 14-08-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03531, current rewards: 253.24638, mean: 0.10963
[32m[0906 14-08-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03531, current rewards: 258.65316, mean: 0.10960
[32m[0906 14-08-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03531, current rewards: 264.03951, mean: 0.10956
[32m[0906 14-09-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03529, current rewards: 269.42007, mean: 0.10952
[32m[0906 14-09-02 @Agent.py:117][0m Average action selection time: 0.0353
[32m[0906 14-09-02 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-09-02 @MBExp.py:227][0m Rewards obtained: [273.76049933644214], Lows: [2], Highs: [6], Total time: 1477.7023609999999
[32m[0906 14-09-39 @MBExp.py:144][0m ####################################################################
[32m[0906 14-09-39 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 14-09-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03568, current rewards: -1.07020, mean: -0.10702
[32m[0906 14-09-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03607, current rewards: 4.36653, mean: 0.07278
[32m[0906 14-09-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03620, current rewards: 9.71485, mean: 0.08832
[32m[0906 14-09-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03620, current rewards: 15.06122, mean: 0.09413
[32m[0906 14-09-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03624, current rewards: 20.40782, mean: 0.09718
[32m[0906 14-09-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03624, current rewards: 25.75377, mean: 0.09905
[32m[0906 14-09-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03622, current rewards: 31.04100, mean: 0.10013
[32m[0906 14-09-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03626, current rewards: 36.38210, mean: 0.10106
[32m[0906 14-09-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03625, current rewards: 41.72367, mean: 0.10177
[32m[0906 14-09-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03624, current rewards: 46.18805, mean: 0.10041
[32m[0906 14-09-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03624, current rewards: 51.73742, mean: 0.10145
[32m[0906 14-10-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03625, current rewards: 57.28250, mean: 0.10229
[32m[0906 14-10-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03621, current rewards: 62.83233, mean: 0.10300
[32m[0906 14-10-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03614, current rewards: 68.38268, mean: 0.10361
[32m[0906 14-10-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03609, current rewards: 73.98230, mean: 0.10420
[32m[0906 14-10-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03604, current rewards: 79.52371, mean: 0.10464
[32m[0906 14-10-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03601, current rewards: 85.06010, mean: 0.10501
[32m[0906 14-10-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03598, current rewards: 90.60200, mean: 0.10535
[32m[0906 14-10-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03595, current rewards: 96.14707, mean: 0.10566
[32m[0906 14-10-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03592, current rewards: 97.46845, mean: 0.10153
[32m[0906 14-10-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03590, current rewards: 102.90254, mean: 0.10188
[32m[0906 14-10-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03584, current rewards: 108.33641, mean: 0.10220
[32m[0906 14-10-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03577, current rewards: 113.77093, mean: 0.10250
[32m[0906 14-10-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03571, current rewards: 119.20580, mean: 0.10276
[32m[0906 14-10-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03566, current rewards: 124.64000, mean: 0.10301
[32m[0906 14-10-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03561, current rewards: 130.07557, mean: 0.10323
[32m[0906 14-10-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03557, current rewards: 135.50999, mean: 0.10344
[32m[0906 14-10-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03553, current rewards: 140.94457, mean: 0.10364
[32m[0906 14-10-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03550, current rewards: 146.37819, mean: 0.10381
[32m[0906 14-10-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03547, current rewards: 151.81253, mean: 0.10398
[32m[0906 14-10-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03544, current rewards: 155.00933, mean: 0.10266
[32m[0906 14-10-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03540, current rewards: 160.45105, mean: 0.10285
[32m[0906 14-10-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03539, current rewards: 165.89387, mean: 0.10304
[32m[0906 14-10-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03539, current rewards: 171.34088, mean: 0.10322
[32m[0906 14-10-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03539, current rewards: 176.78186, mean: 0.10338
[32m[0906 14-10-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03537, current rewards: 182.22541, mean: 0.10354
[32m[0906 14-10-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03535, current rewards: 187.66721, mean: 0.10368
[32m[0906 14-10-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03533, current rewards: 193.10937, mean: 0.10382
[32m[0906 14-10-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03530, current rewards: 198.58776, mean: 0.10397
[32m[0906 14-10-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03528, current rewards: 204.00972, mean: 0.10409
[32m[0906 14-10-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03527, current rewards: 209.46552, mean: 0.10421
[32m[0906 14-10-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03525, current rewards: 214.91414, mean: 0.10433
[32m[0906 14-10-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03524, current rewards: 220.35847, mean: 0.10444
[32m[0906 14-10-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03524, current rewards: 225.80501, mean: 0.10454
[32m[0906 14-10-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03525, current rewards: 229.12729, mean: 0.10368
[32m[0906 14-10-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03525, current rewards: 234.52183, mean: 0.10377
[32m[0906 14-11-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03525, current rewards: 239.91618, mean: 0.10386
[32m[0906 14-11-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03525, current rewards: 245.30582, mean: 0.10394
[32m[0906 14-11-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03523, current rewards: 250.70007, mean: 0.10402
[32m[0906 14-11-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03522, current rewards: 256.09459, mean: 0.10410
[32m[0906 14-11-08 @Agent.py:117][0m Average action selection time: 0.0352
[32m[0906 14-11-08 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-11-08 @MBExp.py:227][0m Rewards obtained: [260.4095997938133], Lows: [3], Highs: [5], Total time: 1566.350724
[32m[0906 14-11-47 @MBExp.py:144][0m ####################################################################
[32m[0906 14-11-47 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 14-11-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03575, current rewards: -0.10865, mean: -0.01087
[32m[0906 14-11-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03621, current rewards: 5.28508, mean: 0.08808
[32m[0906 14-11-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03611, current rewards: 10.75215, mean: 0.09775
[32m[0906 14-11-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03611, current rewards: 16.22192, mean: 0.10139
[32m[0906 14-11-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03614, current rewards: 21.69088, mean: 0.10329
[32m[0906 14-11-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03609, current rewards: 27.17380, mean: 0.10451
[32m[0906 14-11-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03608, current rewards: 32.62692, mean: 0.10525
[32m[0906 14-12-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03609, current rewards: 38.08068, mean: 0.10578
[32m[0906 14-12-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03604, current rewards: 43.53096, mean: 0.10617
[32m[0906 14-12-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03604, current rewards: 48.98371, mean: 0.10649
[32m[0906 14-12-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03597, current rewards: 54.43570, mean: 0.10674
[32m[0906 14-12-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03590, current rewards: 58.87843, mean: 0.10514
[32m[0906 14-12-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03587, current rewards: 64.24589, mean: 0.10532
[32m[0906 14-12-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03581, current rewards: 69.50347, mean: 0.10531
[32m[0906 14-12-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03578, current rewards: 74.85878, mean: 0.10543
[32m[0906 14-12-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03575, current rewards: 80.21820, mean: 0.10555
[32m[0906 14-12-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03573, current rewards: 85.57471, mean: 0.10565
[32m[0906 14-12-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03572, current rewards: 90.92876, mean: 0.10573
[32m[0906 14-12-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03570, current rewards: 96.28489, mean: 0.10581
[32m[0906 14-12-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03568, current rewards: 101.63293, mean: 0.10587
[32m[0906 14-12-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03562, current rewards: 106.98546, mean: 0.10593
[32m[0906 14-12-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03557, current rewards: 112.38108, mean: 0.10602
[32m[0906 14-12-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03552, current rewards: 117.73556, mean: 0.10607
[32m[0906 14-12-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03547, current rewards: 123.09421, mean: 0.10612
[32m[0906 14-12-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03542, current rewards: 128.45886, mean: 0.10616
[32m[0906 14-12-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03538, current rewards: 133.81282, mean: 0.10620
[32m[0906 14-12-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03534, current rewards: 139.17558, mean: 0.10624
[32m[0906 14-12-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03531, current rewards: 142.39437, mean: 0.10470
[32m[0906 14-12-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03528, current rewards: 147.82289, mean: 0.10484
[32m[0906 14-12-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03525, current rewards: 153.30837, mean: 0.10501
[32m[0906 14-12-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03522, current rewards: 158.74844, mean: 0.10513
[32m[0906 14-12-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03522, current rewards: 164.18348, mean: 0.10525
[32m[0906 14-12-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03522, current rewards: 169.62296, mean: 0.10536
[32m[0906 14-12-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03523, current rewards: 175.05909, mean: 0.10546
[32m[0906 14-12-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03521, current rewards: 180.49607, mean: 0.10555
[32m[0906 14-12-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03519, current rewards: 185.85482, mean: 0.10560
[32m[0906 14-12-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03517, current rewards: 191.26522, mean: 0.10567
[32m[0906 14-12-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03516, current rewards: 196.62335, mean: 0.10571
[32m[0906 14-12-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03515, current rewards: 202.01361, mean: 0.10577
[32m[0906 14-12-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03513, current rewards: 207.40879, mean: 0.10582
[32m[0906 14-12-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03512, current rewards: 212.79920, mean: 0.10587
[32m[0906 14-13-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03510, current rewards: 218.19603, mean: 0.10592
[32m[0906 14-13-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03510, current rewards: 223.58852, mean: 0.10597
[32m[0906 14-13-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03512, current rewards: 228.98475, mean: 0.10601
[32m[0906 14-13-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03512, current rewards: 234.37355, mean: 0.10605
[32m[0906 14-13-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03513, current rewards: 239.77145, mean: 0.10609
[32m[0906 14-13-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03512, current rewards: 245.24317, mean: 0.10617
[32m[0906 14-13-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03511, current rewards: 250.63520, mean: 0.10620
[32m[0906 14-13-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03509, current rewards: 256.02364, mean: 0.10623
[32m[0906 14-13-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03509, current rewards: 261.41461, mean: 0.10627
[32m[0906 14-13-15 @Agent.py:117][0m Average action selection time: 0.0351
[32m[0906 14-13-15 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-13-16 @MBExp.py:227][0m Rewards obtained: [265.7308373711726], Lows: [1], Highs: [2], Total time: 1654.6704069999998
[32m[0906 14-13-57 @MBExp.py:144][0m ####################################################################
[32m[0906 14-13-57 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 14-13-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03565, current rewards: -0.09020, mean: -0.00902
[32m[0906 14-13-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03600, current rewards: 5.43591, mean: 0.09060
[32m[0906 14-14-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03608, current rewards: 11.01229, mean: 0.10011
[32m[0906 14-14-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03611, current rewards: 16.59071, mean: 0.10369
[32m[0906 14-14-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03611, current rewards: 22.31737, mean: 0.10627
[32m[0906 14-14-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03611, current rewards: 27.91238, mean: 0.10736
[32m[0906 14-14-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03619, current rewards: 33.50459, mean: 0.10808
[32m[0906 14-14-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03610, current rewards: 39.09546, mean: 0.10860
[32m[0906 14-14-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03599, current rewards: 44.68546, mean: 0.10899
[32m[0906 14-14-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03594, current rewards: 49.14962, mean: 0.10685
[32m[0906 14-14-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03587, current rewards: 54.67026, mean: 0.10720
[32m[0906 14-14-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03582, current rewards: 60.18725, mean: 0.10748
[32m[0906 14-14-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03579, current rewards: 65.77187, mean: 0.10782
[32m[0906 14-14-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03575, current rewards: 71.30990, mean: 0.10805
[32m[0906 14-14-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03573, current rewards: 76.82748, mean: 0.10821
[32m[0906 14-14-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03569, current rewards: 82.34270, mean: 0.10835
[32m[0906 14-14-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03566, current rewards: 87.86229, mean: 0.10847
[32m[0906 14-14-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03564, current rewards: 93.37979, mean: 0.10858
[32m[0906 14-14-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03560, current rewards: 98.89869, mean: 0.10868
[32m[0906 14-14-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03553, current rewards: 103.43343, mean: 0.10774
[32m[0906 14-14-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03548, current rewards: 109.03763, mean: 0.10796
[32m[0906 14-14-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03543, current rewards: 114.42516, mean: 0.10795
[32m[0906 14-14-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03538, current rewards: 120.00091, mean: 0.10811
[32m[0906 14-14-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03534, current rewards: 125.58381, mean: 0.10826
[32m[0906 14-14-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03530, current rewards: 131.16926, mean: 0.10840
[32m[0906 14-14-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03527, current rewards: 136.75526, mean: 0.10854
[32m[0906 14-14-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03523, current rewards: 137.99074, mean: 0.10534
[32m[0906 14-14-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03520, current rewards: 143.49664, mean: 0.10551
[32m[0906 14-14-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03518, current rewards: 149.00045, mean: 0.10567
[32m[0906 14-14-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03516, current rewards: 154.50349, mean: 0.10582
[32m[0906 14-14-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03516, current rewards: 160.00281, mean: 0.10596
[32m[0906 14-14-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03516, current rewards: 165.50731, mean: 0.10609
[32m[0906 14-14-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03516, current rewards: 169.94293, mean: 0.10555
[32m[0906 14-14-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03514, current rewards: 175.48869, mean: 0.10572
[32m[0906 14-14-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03512, current rewards: 181.03092, mean: 0.10587
[32m[0906 14-14-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03510, current rewards: 186.57322, mean: 0.10601
[32m[0906 14-15-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03507, current rewards: 192.12030, mean: 0.10614
[32m[0906 14-15-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03506, current rewards: 197.80389, mean: 0.10635
[32m[0906 14-15-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03504, current rewards: 203.36577, mean: 0.10647
[32m[0906 14-15-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03503, current rewards: 208.92888, mean: 0.10660
[32m[0906 14-15-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03501, current rewards: 214.49795, mean: 0.10672
[32m[0906 14-15-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03500, current rewards: 220.06402, mean: 0.10683
[32m[0906 14-15-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03501, current rewards: 225.62394, mean: 0.10693
[32m[0906 14-15-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03501, current rewards: 231.18778, mean: 0.10703
[32m[0906 14-15-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03502, current rewards: 236.75067, mean: 0.10713
[32m[0906 14-15-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03501, current rewards: 242.34807, mean: 0.10723
[32m[0906 14-15-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03500, current rewards: 247.94744, mean: 0.10734
[32m[0906 14-15-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03499, current rewards: 253.47829, mean: 0.10741
[32m[0906 14-15-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03497, current rewards: 259.01398, mean: 0.10747
[32m[0906 14-15-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03497, current rewards: 264.54969, mean: 0.10754
[32m[0906 14-15-25 @Agent.py:117][0m Average action selection time: 0.0350
[32m[0906 14-15-25 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-15-25 @MBExp.py:227][0m Rewards obtained: [268.9796932688048], Lows: [2], Highs: [4], Total time: 1742.705092
[32m[0906 14-16-08 @MBExp.py:144][0m ####################################################################
[32m[0906 14-16-08 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 14-16-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03597, current rewards: 0.06713, mean: 0.00671
[32m[0906 14-16-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03605, current rewards: 5.79670, mean: 0.09661
[32m[0906 14-16-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03620, current rewards: 11.52896, mean: 0.10481
[32m[0906 14-16-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03619, current rewards: 17.25959, mean: 0.10787
[32m[0906 14-16-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03609, current rewards: 22.81504, mean: 0.10864
[32m[0906 14-16-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03590, current rewards: 28.41877, mean: 0.10930
[32m[0906 14-16-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03581, current rewards: 34.02488, mean: 0.10976
[32m[0906 14-16-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03578, current rewards: 39.63275, mean: 0.11009
[32m[0906 14-16-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03573, current rewards: 45.23733, mean: 0.11033
[32m[0906 14-16-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03570, current rewards: 46.72492, mean: 0.10158
[32m[0906 14-16-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03567, current rewards: 52.31433, mean: 0.10258
[32m[0906 14-16-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03565, current rewards: 57.90267, mean: 0.10340
[32m[0906 14-16-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03563, current rewards: 64.01812, mean: 0.10495
[32m[0906 14-16-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03561, current rewards: 70.62635, mean: 0.10701
[32m[0906 14-16-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03558, current rewards: 77.23459, mean: 0.10878
[32m[0906 14-16-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03556, current rewards: 83.84282, mean: 0.11032
[32m[0906 14-16-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03553, current rewards: 59.88261, mean: 0.07393
[32m[0906 14-16-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03548, current rewards: 9.88261, mean: 0.01149
[32m[0906 14-16-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03542, current rewards: -40.11739, mean: -0.04409
[32m[0906 14-16-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03536, current rewards: -90.11739, mean: -0.09387
[32m[0906 14-16-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03532, current rewards: -140.11739, mean: -0.13873
[32m[0906 14-16-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03529, current rewards: -190.11739, mean: -0.17936
[32m[0906 14-16-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03525, current rewards: -240.11739, mean: -0.21632
[32m[0906 14-16-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03522, current rewards: -290.11739, mean: -0.25010
[32m[0906 14-16-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03519, current rewards: -340.11739, mean: -0.28109
[32m[0906 14-16-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03517, current rewards: -390.11739, mean: -0.30962
[32m[0906 14-16-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03515, current rewards: -440.11739, mean: -0.33597
[32m[0906 14-16-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03512, current rewards: -490.11739, mean: -0.36038
[32m[0906 14-16-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03511, current rewards: -540.11739, mean: -0.38306
[32m[0906 14-17-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03511, current rewards: -590.11739, mean: -0.40419
[32m[0906 14-17-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03513, current rewards: -640.11739, mean: -0.42392
[32m[0906 14-17-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03512, current rewards: -690.11739, mean: -0.44238
[32m[0906 14-17-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03510, current rewards: -740.11739, mean: -0.45970
[32m[0906 14-17-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03508, current rewards: -790.11739, mean: -0.47597
[32m[0906 14-17-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03507, current rewards: -840.11739, mean: -0.49130
[32m[0906 14-17-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03504, current rewards: -890.11739, mean: -0.50575
[32m[0906 14-17-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03503, current rewards: -940.11739, mean: -0.51940
[32m[0906 14-17-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03501, current rewards: -990.11739, mean: -0.53232
[32m[0906 14-17-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03500, current rewards: -1040.11739, mean: -0.54456
[32m[0906 14-17-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03498, current rewards: -1090.11739, mean: -0.55618
[32m[0906 14-17-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03496, current rewards: -1140.11739, mean: -0.56722
[32m[0906 14-17-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03495, current rewards: -1190.11739, mean: -0.57773
[32m[0906 14-17-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03496, current rewards: -1240.11739, mean: -0.58773
[32m[0906 14-17-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03496, current rewards: -1290.11739, mean: -0.59728
[32m[0906 14-17-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03495, current rewards: -1340.11739, mean: -0.60639
[32m[0906 14-17-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03494, current rewards: -1390.11739, mean: -0.61510
[32m[0906 14-17-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03493, current rewards: -1440.11739, mean: -0.62343
[32m[0906 14-17-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03492, current rewards: -1490.11739, mean: -0.63141
[32m[0906 14-17-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03491, current rewards: -1540.11739, mean: -0.63905
[32m[0906 14-17-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03491, current rewards: -1590.11739, mean: -0.64639
[32m[0906 14-17-36 @Agent.py:117][0m Average action selection time: 0.0349
[32m[0906 14-17-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-17-36 @MBExp.py:227][0m Rewards obtained: [-1630.1173914280294], Lows: [2], Highs: [1718], Total time: 1830.597812
[32m[0906 14-18-22 @MBExp.py:144][0m ####################################################################
[32m[0906 14-18-22 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 14-18-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03584, current rewards: 0.03567, mean: 0.00357
[32m[0906 14-18-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03597, current rewards: 5.68859, mean: 0.09481
[32m[0906 14-18-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03575, current rewards: 11.23731, mean: 0.10216
[32m[0906 14-18-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03557, current rewards: 16.68102, mean: 0.10426
[32m[0906 14-18-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03551, current rewards: 22.28084, mean: 0.10610
[32m[0906 14-18-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03547, current rewards: 27.88823, mean: 0.10726
[32m[0906 14-18-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03543, current rewards: 33.49378, mean: 0.10804
[32m[0906 14-18-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03541, current rewards: 39.09569, mean: 0.10860
[32m[0906 14-18-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03538, current rewards: 44.70053, mean: 0.10903
[32m[0906 14-18-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03539, current rewards: 50.30259, mean: 0.10935
[32m[0906 14-18-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03540, current rewards: 53.76573, mean: 0.10542
[32m[0906 14-18-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03539, current rewards: 59.31643, mean: 0.10592
[32m[0906 14-18-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03537, current rewards: 64.94565, mean: 0.10647
[32m[0906 14-18-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03536, current rewards: 70.47058, mean: 0.10677
[32m[0906 14-18-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03537, current rewards: 75.99619, mean: 0.10704
[32m[0906 14-18-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03537, current rewards: 79.83071, mean: 0.10504
[32m[0906 14-18-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03532, current rewards: 85.42180, mean: 0.10546
[32m[0906 14-18-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03527, current rewards: 91.01097, mean: 0.10583
[32m[0906 14-18-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03522, current rewards: 96.60082, mean: 0.10615
[32m[0906 14-18-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03518, current rewards: 102.18636, mean: 0.10644
[32m[0906 14-18-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03513, current rewards: 105.62978, mean: 0.10458
[32m[0906 14-18-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03510, current rewards: 111.44086, mean: 0.10513
[32m[0906 14-19-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03508, current rewards: 117.24945, mean: 0.10563
[32m[0906 14-19-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03504, current rewards: 123.05848, mean: 0.10608
[32m[0906 14-19-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03502, current rewards: 128.86362, mean: 0.10650
[32m[0906 14-19-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03500, current rewards: 134.66887, mean: 0.10688
[32m[0906 14-19-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03499, current rewards: 140.47255, mean: 0.10723
[32m[0906 14-19-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03499, current rewards: 146.27332, mean: 0.10755
[32m[0906 14-19-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03501, current rewards: 152.06349, mean: 0.10785
[32m[0906 14-19-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03501, current rewards: 155.74849, mean: 0.10668
[32m[0906 14-19-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03502, current rewards: 161.35484, mean: 0.10686
[32m[0906 14-19-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03500, current rewards: 166.96001, mean: 0.10703
[32m[0906 14-19-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03498, current rewards: 172.56282, mean: 0.10718
[32m[0906 14-19-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03497, current rewards: 178.17426, mean: 0.10733
[32m[0906 14-19-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03496, current rewards: 183.78087, mean: 0.10747
[32m[0906 14-19-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03495, current rewards: 189.38585, mean: 0.10761
[32m[0906 14-19-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03494, current rewards: 195.05868, mean: 0.10777
[32m[0906 14-19-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03493, current rewards: 200.69404, mean: 0.10790
[32m[0906 14-19-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03492, current rewards: 206.33415, mean: 0.10803
[32m[0906 14-19-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03492, current rewards: 211.96785, mean: 0.10815
[32m[0906 14-19-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03491, current rewards: 215.45240, mean: 0.10719
[32m[0906 14-19-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03490, current rewards: 220.90879, mean: 0.10724
[32m[0906 14-19-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03488, current rewards: 226.36347, mean: 0.10728
[32m[0906 14-19-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03488, current rewards: 231.82494, mean: 0.10733
[32m[0906 14-19-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03487, current rewards: 237.33825, mean: 0.10739
[32m[0906 14-19-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03486, current rewards: 242.62344, mean: 0.10736
[32m[0906 14-19-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03486, current rewards: 247.90652, mean: 0.10732
[32m[0906 14-19-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03485, current rewards: 253.19124, mean: 0.10728
[32m[0906 14-19-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03484, current rewards: 258.47377, mean: 0.10725
[32m[0906 14-19-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03483, current rewards: 263.75658, mean: 0.10722
[32m[0906 14-19-49 @Agent.py:117][0m Average action selection time: 0.0348
[32m[0906 14-19-49 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-19-49 @MBExp.py:227][0m Rewards obtained: [267.9837424995638], Lows: [4], Highs: [3], Total time: 1918.288854
[32m[0906 14-20-37 @MBExp.py:144][0m ####################################################################
[32m[0906 14-20-37 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 14-20-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03612, current rewards: -0.07765, mean: -0.00776
[32m[0906 14-20-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03544, current rewards: 5.27146, mean: 0.08786
[32m[0906 14-20-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03538, current rewards: 10.67172, mean: 0.09702
[32m[0906 14-20-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03538, current rewards: 16.17525, mean: 0.10110
[32m[0906 14-20-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03538, current rewards: 21.56611, mean: 0.10270
[32m[0906 14-20-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03538, current rewards: 26.96086, mean: 0.10370
[32m[0906 14-20-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03538, current rewards: 31.34825, mean: 0.10112
[32m[0906 14-20-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03539, current rewards: 36.83605, mean: 0.10232
[32m[0906 14-20-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03538, current rewards: 42.31766, mean: 0.10321
[32m[0906 14-20-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03537, current rewards: 47.77021, mean: 0.10385
[32m[0906 14-20-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03534, current rewards: 53.18016, mean: 0.10427
[32m[0906 14-20-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03533, current rewards: 58.36609, mean: 0.10423
[32m[0906 14-20-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03532, current rewards: 63.76580, mean: 0.10453
[32m[0906 14-21-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03531, current rewards: 69.16725, mean: 0.10480
[32m[0906 14-21-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03532, current rewards: 74.56720, mean: 0.10502
[32m[0906 14-21-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03526, current rewards: 79.97013, mean: 0.10522
[32m[0906 14-21-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03520, current rewards: 84.32589, mean: 0.10411
[32m[0906 14-21-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03515, current rewards: 89.68036, mean: 0.10428
[32m[0906 14-21-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03510, current rewards: 95.02939, mean: 0.10443
[32m[0906 14-21-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03506, current rewards: 100.47266, mean: 0.10466
[32m[0906 14-21-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03503, current rewards: 105.93946, mean: 0.10489
[32m[0906 14-21-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03501, current rewards: 111.34154, mean: 0.10504
[32m[0906 14-21-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03498, current rewards: 116.74046, mean: 0.10517
[32m[0906 14-21-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03496, current rewards: 122.81099, mean: 0.10587
[32m[0906 14-21-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03495, current rewards: 128.24358, mean: 0.10599
[32m[0906 14-21-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03493, current rewards: 133.68614, mean: 0.10610
[32m[0906 14-21-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03494, current rewards: 139.12747, mean: 0.10620
[32m[0906 14-21-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03496, current rewards: 144.57316, mean: 0.10630
[32m[0906 14-21-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03497, current rewards: 149.73685, mean: 0.10620
[32m[0906 14-21-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03497, current rewards: 155.18820, mean: 0.10629
[32m[0906 14-21-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03495, current rewards: 160.63162, mean: 0.10638
[32m[0906 14-21-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03494, current rewards: 166.07845, mean: 0.10646
[32m[0906 14-21-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03492, current rewards: 171.52428, mean: 0.10654
[32m[0906 14-21-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03491, current rewards: 176.97622, mean: 0.10661
[32m[0906 14-21-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03490, current rewards: 182.41378, mean: 0.10667
[32m[0906 14-21-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03488, current rewards: 187.86907, mean: 0.10674
[32m[0906 14-21-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03487, current rewards: 193.43344, mean: 0.10687
[32m[0906 14-21-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03485, current rewards: 196.90079, mean: 0.10586
[32m[0906 14-21-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03485, current rewards: 202.39728, mean: 0.10597
[32m[0906 14-21-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03484, current rewards: 207.89090, mean: 0.10607
[32m[0906 14-21-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03482, current rewards: 213.38901, mean: 0.10616
[32m[0906 14-21-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03480, current rewards: 218.88518, mean: 0.10625
[32m[0906 14-21-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03479, current rewards: 224.38191, mean: 0.10634
[32m[0906 14-21-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03478, current rewards: 229.87544, mean: 0.10642
[32m[0906 14-21-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03477, current rewards: 235.37324, mean: 0.10650
[32m[0906 14-21-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03476, current rewards: 240.93741, mean: 0.10661
[32m[0906 14-21-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03475, current rewards: 246.42183, mean: 0.10668
[32m[0906 14-21-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03475, current rewards: 249.63643, mean: 0.10578
[32m[0906 14-22-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03475, current rewards: 255.03494, mean: 0.10582
[32m[0906 14-22-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03474, current rewards: 260.44055, mean: 0.10587
[32m[0906 14-22-04 @Agent.py:117][0m Average action selection time: 0.0347
[32m[0906 14-22-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-22-04 @MBExp.py:227][0m Rewards obtained: [264.7658653921135], Lows: [1], Highs: [5], Total time: 2005.746847
[32m[0906 14-22-54 @MBExp.py:144][0m ####################################################################
[32m[0906 14-22-54 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 14-22-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03486, current rewards: -1.04941, mean: -0.10494
[32m[0906 14-22-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03513, current rewards: 4.56431, mean: 0.07607
[32m[0906 14-22-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03519, current rewards: 10.09429, mean: 0.09177
[32m[0906 14-23-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03528, current rewards: 15.46248, mean: 0.09664
[32m[0906 14-23-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03529, current rewards: 20.91851, mean: 0.09961
[32m[0906 14-23-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03532, current rewards: 26.46304, mean: 0.10178
[32m[0906 14-23-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03534, current rewards: 32.01192, mean: 0.10326
[32m[0906 14-23-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03534, current rewards: 37.55985, mean: 0.10433
[32m[0906 14-23-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03533, current rewards: 43.10642, mean: 0.10514
[32m[0906 14-23-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03533, current rewards: 48.65744, mean: 0.10578
[32m[0906 14-23-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03534, current rewards: 54.20650, mean: 0.10629
[32m[0906 14-23-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03533, current rewards: 59.75599, mean: 0.10671
[32m[0906 14-23-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03532, current rewards: 65.45981, mean: 0.10731
[32m[0906 14-23-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03531, current rewards: 69.12817, mean: 0.10474
[32m[0906 14-23-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03525, current rewards: 74.66650, mean: 0.10516
[32m[0906 14-23-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03522, current rewards: 80.19741, mean: 0.10552
[32m[0906 14-23-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03517, current rewards: 85.73155, mean: 0.10584
[32m[0906 14-23-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03513, current rewards: 91.26733, mean: 0.10612
[32m[0906 14-23-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03509, current rewards: 96.80342, mean: 0.10638
[32m[0906 14-23-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03505, current rewards: 102.33802, mean: 0.10660
[32m[0906 14-23-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03502, current rewards: 107.96216, mean: 0.10689
[32m[0906 14-23-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03500, current rewards: 113.48769, mean: 0.10706
[32m[0906 14-23-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03498, current rewards: 117.84376, mean: 0.10617
[32m[0906 14-23-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03495, current rewards: 123.31916, mean: 0.10631
[32m[0906 14-23-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03494, current rewards: 128.79821, mean: 0.10644
[32m[0906 14-23-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03496, current rewards: 134.27843, mean: 0.10657
[32m[0906 14-23-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03497, current rewards: 139.76360, mean: 0.10669
[32m[0906 14-23-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03498, current rewards: 145.24298, mean: 0.10680
[32m[0906 14-23-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03498, current rewards: 146.59778, mean: 0.10397
[32m[0906 14-23-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03497, current rewards: 152.17789, mean: 0.10423
[32m[0906 14-23-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03496, current rewards: 157.69059, mean: 0.10443
[32m[0906 14-23-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03495, current rewards: 163.20319, mean: 0.10462
[32m[0906 14-23-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03494, current rewards: 168.71640, mean: 0.10479
[32m[0906 14-23-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03493, current rewards: 174.22919, mean: 0.10496
[32m[0906 14-23-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03491, current rewards: 179.74205, mean: 0.10511
[32m[0906 14-23-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03491, current rewards: 185.25460, mean: 0.10526
[32m[0906 14-23-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03490, current rewards: 188.54978, mean: 0.10417
[32m[0906 14-23-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03489, current rewards: 194.00058, mean: 0.10430
[32m[0906 14-24-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03488, current rewards: 199.53151, mean: 0.10447
[32m[0906 14-24-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03486, current rewards: 205.06479, mean: 0.10462
[32m[0906 14-24-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03484, current rewards: 210.59308, mean: 0.10477
[32m[0906 14-24-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03482, current rewards: 216.12541, mean: 0.10492
[32m[0906 14-24-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03481, current rewards: 221.65571, mean: 0.10505
[32m[0906 14-24-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03480, current rewards: 227.18648, mean: 0.10518
[32m[0906 14-24-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03479, current rewards: 232.71538, mean: 0.10530
[32m[0906 14-24-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03479, current rewards: 238.29997, mean: 0.10544
[32m[0906 14-24-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03478, current rewards: 243.82756, mean: 0.10555
[32m[0906 14-24-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03478, current rewards: 249.35529, mean: 0.10566
[32m[0906 14-24-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03477, current rewards: 253.78195, mean: 0.10530
[32m[0906 14-24-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03476, current rewards: 259.31123, mean: 0.10541
[32m[0906 14-24-21 @Agent.py:117][0m Average action selection time: 0.0348
[32m[0906 14-24-21 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-24-21 @MBExp.py:227][0m Rewards obtained: [263.73871646040453], Lows: [3], Highs: [6], Total time: 2093.284544
[32m[0906 14-25-13 @MBExp.py:144][0m ####################################################################
[32m[0906 14-25-13 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 14-25-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03462, current rewards: -1.01917, mean: -0.10192
[32m[0906 14-25-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03525, current rewards: 4.63612, mean: 0.07727
[32m[0906 14-25-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03529, current rewards: 10.22188, mean: 0.09293
[32m[0906 14-25-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03536, current rewards: 15.70589, mean: 0.09816
[32m[0906 14-25-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03536, current rewards: 21.26207, mean: 0.10125
[32m[0906 14-25-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03538, current rewards: 26.83291, mean: 0.10320
[32m[0906 14-25-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03536, current rewards: 32.41116, mean: 0.10455
[32m[0906 14-25-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03536, current rewards: 37.98462, mean: 0.10551
[32m[0906 14-25-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03536, current rewards: 43.55964, mean: 0.10624
[32m[0906 14-25-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03538, current rewards: 49.13648, mean: 0.10682
[32m[0906 14-25-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03537, current rewards: 54.70854, mean: 0.10727
[32m[0906 14-25-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03537, current rewards: 60.28357, mean: 0.10765
[32m[0906 14-25-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03534, current rewards: 65.78613, mean: 0.10785
[32m[0906 14-25-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03526, current rewards: 67.10343, mean: 0.10167
[32m[0906 14-25-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03520, current rewards: 72.76052, mean: 0.10248
[32m[0906 14-25-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03515, current rewards: 78.41395, mean: 0.10318
[32m[0906 14-25-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03511, current rewards: 84.07283, mean: 0.10379
[32m[0906 14-25-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03507, current rewards: 89.72533, mean: 0.10433
[32m[0906 14-25-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03505, current rewards: 95.38638, mean: 0.10482
[32m[0906 14-25-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03502, current rewards: 101.03961, mean: 0.10525
[32m[0906 14-25-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03501, current rewards: 106.69296, mean: 0.10564
[32m[0906 14-25-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03499, current rewards: 112.34604, mean: 0.10599
[32m[0906 14-25-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03497, current rewards: 117.99977, mean: 0.10631
[32m[0906 14-25-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03498, current rewards: 123.64957, mean: 0.10659
[32m[0906 14-25-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03499, current rewards: 129.30065, mean: 0.10686
[32m[0906 14-25-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03501, current rewards: 134.95131, mean: 0.10710
[32m[0906 14-25-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03503, current rewards: 140.60768, mean: 0.10733
[32m[0906 14-26-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03504, current rewards: 145.09575, mean: 0.10669
[32m[0906 14-26-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03502, current rewards: 150.73136, mean: 0.10690
[32m[0906 14-26-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03500, current rewards: 156.35354, mean: 0.10709
[32m[0906 14-26-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03498, current rewards: 161.97939, mean: 0.10727
[32m[0906 14-26-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03497, current rewards: 167.60327, mean: 0.10744
[32m[0906 14-26-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03496, current rewards: 173.23667, mean: 0.10760
[32m[0906 14-26-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03495, current rewards: 178.86267, mean: 0.10775
[32m[0906 14-26-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03493, current rewards: 183.37467, mean: 0.10724
[32m[0906 14-26-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03492, current rewards: 188.95814, mean: 0.10736
[32m[0906 14-26-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03491, current rewards: 194.61703, mean: 0.10752
[32m[0906 14-26-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03490, current rewards: 200.18603, mean: 0.10763
[32m[0906 14-26-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03487, current rewards: 205.75613, mean: 0.10773
[32m[0906 14-26-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03484, current rewards: 211.33051, mean: 0.10782
[32m[0906 14-26-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03481, current rewards: 216.90899, mean: 0.10791
[32m[0906 14-26-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03478, current rewards: 222.48922, mean: 0.10800
[32m[0906 14-26-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03477, current rewards: 226.08296, mean: 0.10715
[32m[0906 14-26-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03476, current rewards: 231.71468, mean: 0.10728
[32m[0906 14-26-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03476, current rewards: 237.30015, mean: 0.10738
[32m[0906 14-26-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03476, current rewards: 242.94505, mean: 0.10750
[32m[0906 14-26-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03475, current rewards: 248.59081, mean: 0.10762
[32m[0906 14-26-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03475, current rewards: 254.23606, mean: 0.10773
[32m[0906 14-26-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03475, current rewards: 259.88309, mean: 0.10784
[32m[0906 14-26-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03475, current rewards: 265.52822, mean: 0.10794
[32m[0906 14-26-40 @Agent.py:117][0m Average action selection time: 0.0347
[32m[0906 14-26-40 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-26-40 @MBExp.py:227][0m Rewards obtained: [270.04340837591224], Lows: [3], Highs: [4], Total time: 2180.778402
[32m[0906 14-27-34 @MBExp.py:144][0m ####################################################################
[32m[0906 14-27-34 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 14-27-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03568, current rewards: -0.99064, mean: -0.09906
[32m[0906 14-27-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03556, current rewards: 4.54642, mean: 0.07577
[32m[0906 14-27-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03545, current rewards: 10.17245, mean: 0.09248
[32m[0906 14-27-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03542, current rewards: 15.70256, mean: 0.09814
[32m[0906 14-27-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03539, current rewards: 21.23467, mean: 0.10112
[32m[0906 14-27-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03543, current rewards: 26.76893, mean: 0.10296
[32m[0906 14-27-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03545, current rewards: 32.29794, mean: 0.10419
[32m[0906 14-27-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03543, current rewards: 37.82366, mean: 0.10507
[32m[0906 14-27-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03540, current rewards: 43.35044, mean: 0.10573
[32m[0906 14-27-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03537, current rewards: 48.87787, mean: 0.10626
[32m[0906 14-27-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03536, current rewards: 54.44164, mean: 0.10675
[32m[0906 14-27-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03529, current rewards: 59.96853, mean: 0.10709
[32m[0906 14-27-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03522, current rewards: 64.47384, mean: 0.10569
[32m[0906 14-27-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03516, current rewards: 69.87845, mean: 0.10588
[32m[0906 14-27-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03512, current rewards: 75.28619, mean: 0.10604
[32m[0906 14-28-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03508, current rewards: 80.69420, mean: 0.10618
[32m[0906 14-28-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03504, current rewards: 86.09760, mean: 0.10629
[32m[0906 14-28-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03500, current rewards: 91.49846, mean: 0.10639
[32m[0906 14-28-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03497, current rewards: 96.87499, mean: 0.10646
[32m[0906 14-28-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03497, current rewards: 102.27333, mean: 0.10653
[32m[0906 14-28-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03494, current rewards: 107.67126, mean: 0.10661
[32m[0906 14-28-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03493, current rewards: 113.06788, mean: 0.10667
[32m[0906 14-28-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03495, current rewards: 118.46713, mean: 0.10673
[32m[0906 14-28-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03498, current rewards: 123.86648, mean: 0.10678
[32m[0906 14-28-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03500, current rewards: 129.26342, mean: 0.10683
[32m[0906 14-28-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03502, current rewards: 132.72381, mean: 0.10534
[32m[0906 14-28-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03501, current rewards: 138.38273, mean: 0.10564
[32m[0906 14-28-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03500, current rewards: 144.01461, mean: 0.10589
[32m[0906 14-28-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03499, current rewards: 149.65153, mean: 0.10614
[32m[0906 14-28-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03496, current rewards: 155.28517, mean: 0.10636
[32m[0906 14-28-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03495, current rewards: 160.92417, mean: 0.10657
[32m[0906 14-28-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03493, current rewards: 166.55767, mean: 0.10677
[32m[0906 14-28-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03492, current rewards: 172.19371, mean: 0.10695
[32m[0906 14-28-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03491, current rewards: 176.26328, mean: 0.10618
[32m[0906 14-28-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03489, current rewards: 181.86353, mean: 0.10635
[32m[0906 14-28-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03488, current rewards: 187.46499, mean: 0.10651
[32m[0906 14-28-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03488, current rewards: 193.06951, mean: 0.10667
[32m[0906 14-28-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03485, current rewards: 198.67179, mean: 0.10681
[32m[0906 14-28-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03482, current rewards: 204.27297, mean: 0.10695
[32m[0906 14-28-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03478, current rewards: 209.87506, mean: 0.10708
[32m[0906 14-28-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03476, current rewards: 215.47813, mean: 0.10720
[32m[0906 14-28-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03473, current rewards: 221.07957, mean: 0.10732
[32m[0906 14-28-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03473, current rewards: 226.68934, mean: 0.10744
[32m[0906 14-28-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03472, current rewards: 230.21557, mean: 0.10658
[32m[0906 14-28-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03472, current rewards: 235.75287, mean: 0.10668
[32m[0906 14-28-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03472, current rewards: 241.30039, mean: 0.10677
[32m[0906 14-28-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03471, current rewards: 246.84606, mean: 0.10686
[32m[0906 14-28-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03471, current rewards: 252.38997, mean: 0.10694
[32m[0906 14-28-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03470, current rewards: 257.93048, mean: 0.10703
[32m[0906 14-29-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03470, current rewards: 263.47064, mean: 0.10710
[32m[0906 14-29-01 @Agent.py:117][0m Average action selection time: 0.0347
[32m[0906 14-29-01 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-29-02 @MBExp.py:227][0m Rewards obtained: [264.1495203485162], Lows: [4], Highs: [5], Total time: 2268.1604629999997
[32m[0906 14-29-57 @MBExp.py:144][0m ####################################################################
[32m[0906 14-29-57 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 14-29-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03485, current rewards: -0.08534, mean: -0.00853
[32m[0906 14-29-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03513, current rewards: 5.45380, mean: 0.09090
[32m[0906 14-30-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03527, current rewards: 10.88986, mean: 0.09900
[32m[0906 14-30-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03527, current rewards: 16.32705, mean: 0.10204
[32m[0906 14-30-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03528, current rewards: 21.76793, mean: 0.10366
[32m[0906 14-30-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03528, current rewards: 27.21127, mean: 0.10466
[32m[0906 14-30-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03531, current rewards: 32.65389, mean: 0.10534
[32m[0906 14-30-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03528, current rewards: 38.09673, mean: 0.10582
[32m[0906 14-30-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03528, current rewards: 43.53172, mean: 0.10617
[32m[0906 14-30-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03527, current rewards: 48.97079, mean: 0.10646
[32m[0906 14-30-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03518, current rewards: 52.28322, mean: 0.10252
[32m[0906 14-30-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03512, current rewards: 57.68459, mean: 0.10301
[32m[0906 14-30-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03507, current rewards: 63.08993, mean: 0.10343
[32m[0906 14-30-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03502, current rewards: 68.49123, mean: 0.10377
[32m[0906 14-30-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03497, current rewards: 73.89227, mean: 0.10407
[32m[0906 14-30-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03493, current rewards: 79.29847, mean: 0.10434
[32m[0906 14-30-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03491, current rewards: 82.50173, mean: 0.10185
[32m[0906 14-30-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03488, current rewards: 87.71263, mean: 0.10199
[32m[0906 14-30-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03485, current rewards: 92.83453, mean: 0.10202
[32m[0906 14-30-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03484, current rewards: 97.95803, mean: 0.10204
[32m[0906 14-30-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03488, current rewards: 103.07904, mean: 0.10206
[32m[0906 14-30-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03490, current rewards: 108.20136, mean: 0.10208
[32m[0906 14-30-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03492, current rewards: 113.32460, mean: 0.10209
[32m[0906 14-30-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03493, current rewards: 118.44835, mean: 0.10211
[32m[0906 14-30-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03495, current rewards: 121.39742, mean: 0.10033
[32m[0906 14-30-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03494, current rewards: 126.97471, mean: 0.10077
[32m[0906 14-30-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03492, current rewards: 132.51162, mean: 0.10115
[32m[0906 14-30-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03491, current rewards: 138.04055, mean: 0.10150
[32m[0906 14-30-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03489, current rewards: 143.56550, mean: 0.10182
[32m[0906 14-30-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03488, current rewards: 149.08795, mean: 0.10212
[32m[0906 14-30-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03487, current rewards: 154.60991, mean: 0.10239
[32m[0906 14-30-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03486, current rewards: 160.13703, mean: 0.10265
[32m[0906 14-30-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03484, current rewards: 165.66620, mean: 0.10290
[32m[0906 14-30-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03483, current rewards: 171.72169, mean: 0.10345
[32m[0906 14-30-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03482, current rewards: 177.75798, mean: 0.10395
[32m[0906 14-30-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03481, current rewards: 183.90201, mean: 0.10449
[32m[0906 14-31-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03478, current rewards: 190.05112, mean: 0.10500
[32m[0906 14-31-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03475, current rewards: 196.18646, mean: 0.10548
[32m[0906 14-31-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03472, current rewards: 202.32487, mean: 0.10593
[32m[0906 14-31-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03470, current rewards: 208.46487, mean: 0.10636
[32m[0906 14-31-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03467, current rewards: 211.76926, mean: 0.10536
[32m[0906 14-31-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03464, current rewards: 217.00130, mean: 0.10534
[32m[0906 14-31-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03463, current rewards: 222.13705, mean: 0.10528
[32m[0906 14-31-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03463, current rewards: 227.32375, mean: 0.10524
[32m[0906 14-31-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03463, current rewards: 232.50875, mean: 0.10521
[32m[0906 14-31-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03463, current rewards: 237.69456, mean: 0.10517
[32m[0906 14-31-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03463, current rewards: 242.88104, mean: 0.10514
[32m[0906 14-31-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03463, current rewards: 248.07187, mean: 0.10512
[32m[0906 14-31-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03462, current rewards: 253.26512, mean: 0.10509
[32m[0906 14-31-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03462, current rewards: 258.45098, mean: 0.10506
[32m[0906 14-31-24 @Agent.py:117][0m Average action selection time: 0.0346
[32m[0906 14-31-24 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-31-24 @MBExp.py:227][0m Rewards obtained: [262.5668492125241], Lows: [3], Highs: [3], Total time: 2355.3423759999996
[32m[0906 14-32-22 @MBExp.py:144][0m ####################################################################
[32m[0906 14-32-22 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 14-32-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03507, current rewards: 1.27552, mean: 0.12755
[32m[0906 14-32-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03542, current rewards: 8.03956, mean: 0.13399
[32m[0906 14-32-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03523, current rewards: 14.80360, mean: 0.13458
[32m[0906 14-32-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03523, current rewards: 21.56764, mean: 0.13480
[32m[0906 14-32-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03523, current rewards: 28.33168, mean: 0.13491
[32m[0906 14-32-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03520, current rewards: 35.09571, mean: 0.13498
[32m[0906 14-32-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03523, current rewards: -10.36316, mean: -0.03343
[32m[0906 14-32-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03523, current rewards: -60.36316, mean: -0.16768
[32m[0906 14-32-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03521, current rewards: -110.36316, mean: -0.26918
[32m[0906 14-32-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03510, current rewards: -160.36316, mean: -0.34862
[32m[0906 14-32-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03506, current rewards: -210.36316, mean: -0.41248
[32m[0906 14-32-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03499, current rewards: -260.36316, mean: -0.46493
[32m[0906 14-32-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03492, current rewards: -310.36316, mean: -0.50879
[32m[0906 14-32-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03488, current rewards: -360.36316, mean: -0.54600
[32m[0906 14-32-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03485, current rewards: -410.36316, mean: -0.57798
[32m[0906 14-32-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03481, current rewards: -460.36316, mean: -0.60574
[32m[0906 14-32-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03478, current rewards: -510.36316, mean: -0.63008
[32m[0906 14-32-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03478, current rewards: -560.36316, mean: -0.65159
[32m[0906 14-32-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03477, current rewards: -610.36316, mean: -0.67073
[32m[0906 14-32-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03480, current rewards: -660.36316, mean: -0.68788
[32m[0906 14-32-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03482, current rewards: -710.36316, mean: -0.70333
[32m[0906 14-32-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03486, current rewards: -760.36316, mean: -0.71732
[32m[0906 14-33-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03488, current rewards: -810.36316, mean: -0.73006
[32m[0906 14-33-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03490, current rewards: -860.36316, mean: -0.74169
[32m[0906 14-33-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03489, current rewards: -910.36316, mean: -0.75237
[32m[0906 14-33-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03488, current rewards: -960.36316, mean: -0.76219
[32m[0906 14-33-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03487, current rewards: -1010.36316, mean: -0.77127
[32m[0906 14-33-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03485, current rewards: -1060.36316, mean: -0.77968
[32m[0906 14-33-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03484, current rewards: -1110.36316, mean: -0.78749
[32m[0906 14-33-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03482, current rewards: -1160.36316, mean: -0.79477
[32m[0906 14-33-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03481, current rewards: -1210.36316, mean: -0.80157
[32m[0906 14-33-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03480, current rewards: -1260.36316, mean: -0.80793
[32m[0906 14-33-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03479, current rewards: -1310.36316, mean: -0.81389
[32m[0906 14-33-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03478, current rewards: -1360.36316, mean: -0.81950
[32m[0906 14-33-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03475, current rewards: -1410.36316, mean: -0.82477
[32m[0906 14-33-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03472, current rewards: -1460.36316, mean: -0.82975
[32m[0906 14-33-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03469, current rewards: -1510.36316, mean: -0.83445
[32m[0906 14-33-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03466, current rewards: -1560.36316, mean: -0.83890
[32m[0906 14-33-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03464, current rewards: -1610.36316, mean: -0.84312
[32m[0906 14-33-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03461, current rewards: -1660.36316, mean: -0.84712
[32m[0906 14-33-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03459, current rewards: -1710.36316, mean: -0.85093
[32m[0906 14-33-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03456, current rewards: -1760.36316, mean: -0.85455
[32m[0906 14-33-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03456, current rewards: -1810.36316, mean: -0.85799
[32m[0906 14-33-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03455, current rewards: -1860.36316, mean: -0.86128
[32m[0906 14-33-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03455, current rewards: -1910.36316, mean: -0.86442
[32m[0906 14-33-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03455, current rewards: -1960.36316, mean: -0.86742
[32m[0906 14-33-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03455, current rewards: -2010.36316, mean: -0.87029
[32m[0906 14-33-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03454, current rewards: -2060.36316, mean: -0.87304
[32m[0906 14-33-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03454, current rewards: -2110.36316, mean: -0.87567
[32m[0906 14-33-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03454, current rewards: -2160.36316, mean: -0.87820
[32m[0906 14-33-49 @Agent.py:117][0m Average action selection time: 0.0345
[32m[0906 14-33-49 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-33-49 @MBExp.py:227][0m Rewards obtained: [-2200.363162239505], Lows: [0], Highs: [2236], Total time: 2442.3153439999996
[32m[0906 14-34-49 @MBExp.py:144][0m ####################################################################
[32m[0906 14-34-49 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 14-34-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03501, current rewards: 0.03253, mean: 0.00325
[32m[0906 14-34-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03518, current rewards: 5.79001, mean: 0.09650
[32m[0906 14-34-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03516, current rewards: 11.33716, mean: 0.10307
[32m[0906 14-34-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03523, current rewards: 16.88274, mean: 0.10552
[32m[0906 14-34-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03521, current rewards: 22.43404, mean: 0.10683
[32m[0906 14-34-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03524, current rewards: 27.98452, mean: 0.10763
[32m[0906 14-35-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03524, current rewards: 33.53629, mean: 0.10818
[32m[0906 14-35-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03520, current rewards: 39.08697, mean: 0.10857
[32m[0906 14-35-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03510, current rewards: 44.63261, mean: 0.10886
[32m[0906 14-35-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03500, current rewards: 49.12813, mean: 0.10680
[32m[0906 14-35-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03494, current rewards: 54.70385, mean: 0.10726
[32m[0906 14-35-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03493, current rewards: 60.26917, mean: 0.10762
[32m[0906 14-35-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03490, current rewards: 65.84332, mean: 0.10794
[32m[0906 14-35-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03488, current rewards: 71.42017, mean: 0.10821
[32m[0906 14-35-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03485, current rewards: 75.31158, mean: 0.10607
[32m[0906 14-35-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03483, current rewards: 80.73728, mean: 0.10623
[32m[0906 14-35-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03481, current rewards: 86.16290, mean: 0.10637
[32m[0906 14-35-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03482, current rewards: 91.37435, mean: 0.10625
[32m[0906 14-35-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03485, current rewards: 96.73513, mean: 0.10630
[32m[0906 14-35-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03487, current rewards: 102.09313, mean: 0.10635
[32m[0906 14-35-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03489, current rewards: 107.45131, mean: 0.10639
[32m[0906 14-35-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03490, current rewards: 112.80989, mean: 0.10642
[32m[0906 14-35-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03493, current rewards: 117.20767, mean: 0.10559
[32m[0906 14-35-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03492, current rewards: 122.75966, mean: 0.10583
[32m[0906 14-35-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03491, current rewards: 128.30760, mean: 0.10604
[32m[0906 14-35-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03489, current rewards: 133.77227, mean: 0.10617
[32m[0906 14-35-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03486, current rewards: 139.23582, mean: 0.10629
[32m[0906 14-35-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03485, current rewards: 144.72263, mean: 0.10641
[32m[0906 14-35-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03484, current rewards: 150.21173, mean: 0.10653
[32m[0906 14-35-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03482, current rewards: 155.69937, mean: 0.10664
[32m[0906 14-35-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03482, current rewards: 160.08525, mean: 0.10602
[32m[0906 14-35-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03481, current rewards: 165.51670, mean: 0.10610
[32m[0906 14-35-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03480, current rewards: 170.94514, mean: 0.10618
[32m[0906 14-35-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03476, current rewards: 176.38423, mean: 0.10626
[32m[0906 14-35-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03473, current rewards: 182.08366, mean: 0.10648
[32m[0906 14-35-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03470, current rewards: 187.62912, mean: 0.10661
[32m[0906 14-35-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03467, current rewards: 193.17517, mean: 0.10673
[32m[0906 14-35-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03463, current rewards: 198.71899, mean: 0.10684
[32m[0906 14-35-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03460, current rewards: 204.26651, mean: 0.10695
[32m[0906 14-35-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03458, current rewards: 209.81360, mean: 0.10705
[32m[0906 14-35-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03456, current rewards: 211.14884, mean: 0.10505
[32m[0906 14-36-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03454, current rewards: 216.63167, mean: 0.10516
[32m[0906 14-36-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03454, current rewards: 222.11651, mean: 0.10527
[32m[0906 14-36-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03453, current rewards: 227.60084, mean: 0.10537
[32m[0906 14-36-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03453, current rewards: 233.08449, mean: 0.10547
[32m[0906 14-36-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03453, current rewards: 238.56822, mean: 0.10556
[32m[0906 14-36-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03454, current rewards: 244.05288, mean: 0.10565
[32m[0906 14-36-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03454, current rewards: 249.53784, mean: 0.10574
[32m[0906 14-36-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03454, current rewards: 255.02269, mean: 0.10582
[32m[0906 14-36-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03453, current rewards: 257.19872, mean: 0.10455
[32m[0906 14-36-16 @Agent.py:117][0m Average action selection time: 0.0345
[32m[0906 14-36-16 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-36-16 @MBExp.py:227][0m Rewards obtained: [261.68246295025716], Lows: [3], Highs: [7], Total time: 2529.280606
[32m[0906 14-37-17 @MBExp.py:144][0m ####################################################################
[32m[0906 14-37-17 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 14-37-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03428, current rewards: -1.13663, mean: -0.11366
[32m[0906 14-37-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03512, current rewards: 4.40225, mean: 0.07337
[32m[0906 14-37-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03512, current rewards: 9.94476, mean: 0.09041
[32m[0906 14-37-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03518, current rewards: 15.48515, mean: 0.09678
[32m[0906 14-37-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03519, current rewards: 21.02501, mean: 0.10012
[32m[0906 14-37-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03519, current rewards: 26.56556, mean: 0.10218
[32m[0906 14-37-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03509, current rewards: 32.10589, mean: 0.10357
[32m[0906 14-37-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03500, current rewards: 37.64571, mean: 0.10457
[32m[0906 14-37-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03493, current rewards: 43.28890, mean: 0.10558
[32m[0906 14-37-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03487, current rewards: 48.84011, mean: 0.10617
[32m[0906 14-37-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03482, current rewards: 54.39422, mean: 0.10666
[32m[0906 14-37-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03477, current rewards: 58.85500, mean: 0.10510
[32m[0906 14-37-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03473, current rewards: 64.43233, mean: 0.10563
[32m[0906 14-37-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03471, current rewards: 70.01165, mean: 0.10608
[32m[0906 14-37-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03469, current rewards: 75.59178, mean: 0.10647
[32m[0906 14-37-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03468, current rewards: 81.16997, mean: 0.10680
[32m[0906 14-37-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03471, current rewards: 86.79645, mean: 0.10716
[32m[0906 14-37-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03475, current rewards: 92.37718, mean: 0.10742
[32m[0906 14-37-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03477, current rewards: 97.95274, mean: 0.10764
[32m[0906 14-37-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03480, current rewards: 103.52885, mean: 0.10784
[32m[0906 14-37-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03483, current rewards: 109.10798, mean: 0.10803
[32m[0906 14-37-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03486, current rewards: 114.68229, mean: 0.10819
[32m[0906 14-37-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03486, current rewards: 118.21003, mean: 0.10650
[32m[0906 14-37-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03484, current rewards: 123.78328, mean: 0.10671
[32m[0906 14-38-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03483, current rewards: 129.42044, mean: 0.10696
[32m[0906 14-38-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03482, current rewards: 135.03470, mean: 0.10717
[32m[0906 14-38-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03480, current rewards: 140.59116, mean: 0.10732
[32m[0906 14-38-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03480, current rewards: 146.14808, mean: 0.10746
[32m[0906 14-38-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03478, current rewards: 150.58723, mean: 0.10680
[32m[0906 14-38-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03477, current rewards: 156.21374, mean: 0.10700
[32m[0906 14-38-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03476, current rewards: 161.83765, mean: 0.10718
[32m[0906 14-38-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03475, current rewards: 167.46439, mean: 0.10735
[32m[0906 14-38-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03471, current rewards: 171.98390, mean: 0.10682
[32m[0906 14-38-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03468, current rewards: 177.68794, mean: 0.10704
[32m[0906 14-38-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03465, current rewards: 183.40542, mean: 0.10725
[32m[0906 14-38-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03462, current rewards: 189.12162, mean: 0.10746
[32m[0906 14-38-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03459, current rewards: 194.84172, mean: 0.10765
[32m[0906 14-38-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03456, current rewards: 200.56159, mean: 0.10783
[32m[0906 14-38-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03453, current rewards: 206.28929, mean: 0.10800
[32m[0906 14-38-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03451, current rewards: 212.00644, mean: 0.10817
[32m[0906 14-38-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03449, current rewards: 217.72699, mean: 0.10832
[32m[0906 14-38-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03447, current rewards: 221.28306, mean: 0.10742
[32m[0906 14-38-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03447, current rewards: 226.86661, mean: 0.10752
[32m[0906 14-38-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03447, current rewards: 232.44622, mean: 0.10761
[32m[0906 14-38-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03447, current rewards: 238.02668, mean: 0.10770
[32m[0906 14-38-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03447, current rewards: 243.60778, mean: 0.10779
[32m[0906 14-38-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03446, current rewards: 249.19232, mean: 0.10788
[32m[0906 14-38-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03447, current rewards: 254.77950, mean: 0.10796
[32m[0906 14-38-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03447, current rewards: 260.36025, mean: 0.10803
[32m[0906 14-38-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03447, current rewards: 265.02474, mean: 0.10773
[32m[0906 14-38-44 @Agent.py:117][0m Average action selection time: 0.0345
[32m[0906 14-38-44 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-38-44 @MBExp.py:227][0m Rewards obtained: [269.6022951218075], Lows: [2], Highs: [6], Total time: 2616.091097
[32m[0906 14-39-48 @MBExp.py:144][0m ####################################################################
[32m[0906 14-39-48 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 14-39-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03497, current rewards: -1.12404, mean: -0.11240
[32m[0906 14-39-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03546, current rewards: 4.31856, mean: 0.07198
[32m[0906 14-39-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03544, current rewards: 9.76050, mean: 0.08873
[32m[0906 14-39-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03541, current rewards: 15.20648, mean: 0.09504
[32m[0906 14-39-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03540, current rewards: 20.64598, mean: 0.09831
[32m[0906 14-39-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03523, current rewards: 26.08899, mean: 0.10034
[32m[0906 14-39-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03514, current rewards: 31.53688, mean: 0.10173
[32m[0906 14-40-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03507, current rewards: 37.13721, mean: 0.10316
[32m[0906 14-40-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03499, current rewards: 42.60296, mean: 0.10391
[32m[0906 14-40-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03495, current rewards: 48.06915, mean: 0.10450
[32m[0906 14-40-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03490, current rewards: 52.46910, mean: 0.10288
[32m[0906 14-40-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03489, current rewards: 57.86248, mean: 0.10333
[32m[0906 14-40-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03484, current rewards: 63.25212, mean: 0.10369
[32m[0906 14-40-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03482, current rewards: 68.64302, mean: 0.10400
[32m[0906 14-40-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03485, current rewards: 74.03869, mean: 0.10428
[32m[0906 14-40-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03488, current rewards: 75.27656, mean: 0.09905
[32m[0906 14-40-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03491, current rewards: 80.75124, mean: 0.09969
[32m[0906 14-40-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03494, current rewards: 86.22673, mean: 0.10026
[32m[0906 14-40-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03495, current rewards: 91.70320, mean: 0.10077
[32m[0906 14-40-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03499, current rewards: 97.17827, mean: 0.10123
[32m[0906 14-40-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03501, current rewards: 102.65147, mean: 0.10164
[32m[0906 14-40-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03500, current rewards: 108.12621, mean: 0.10201
[32m[0906 14-40-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03498, current rewards: 113.60104, mean: 0.10234
[32m[0906 14-40-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03496, current rewards: 118.92424, mean: 0.10252
[32m[0906 14-40-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03495, current rewards: 123.32725, mean: 0.10192
[32m[0906 14-40-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03494, current rewards: 128.77008, mean: 0.10220
[32m[0906 14-40-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03492, current rewards: 134.20680, mean: 0.10245
[32m[0906 14-40-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03491, current rewards: 139.65296, mean: 0.10269
[32m[0906 14-40-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03490, current rewards: 145.08915, mean: 0.10290
[32m[0906 14-40-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03489, current rewards: 150.53129, mean: 0.10310
[32m[0906 14-40-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03487, current rewards: 155.96708, mean: 0.10329
[32m[0906 14-40-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03483, current rewards: 161.44238, mean: 0.10349
[32m[0906 14-40-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03480, current rewards: 166.95527, mean: 0.10370
[32m[0906 14-40-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03476, current rewards: 172.40859, mean: 0.10386
[32m[0906 14-40-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03474, current rewards: 175.77981, mean: 0.10280
[32m[0906 14-40-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03471, current rewards: 181.27250, mean: 0.10300
[32m[0906 14-40-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03469, current rewards: 186.76896, mean: 0.10319
[32m[0906 14-40-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03467, current rewards: 192.26090, mean: 0.10337
[32m[0906 14-40-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03465, current rewards: 197.75373, mean: 0.10354
[32m[0906 14-40-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03463, current rewards: 203.24865, mean: 0.10370
[32m[0906 14-40-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03461, current rewards: 207.05832, mean: 0.10301
[32m[0906 14-41-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03459, current rewards: 212.55020, mean: 0.10318
[32m[0906 14-41-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03459, current rewards: 218.05092, mean: 0.10334
[32m[0906 14-41-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03459, current rewards: 223.54610, mean: 0.10349
[32m[0906 14-41-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03459, current rewards: 229.04578, mean: 0.10364
[32m[0906 14-41-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03459, current rewards: 233.37126, mean: 0.10326
[32m[0906 14-41-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03459, current rewards: 238.77372, mean: 0.10337
[32m[0906 14-41-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03458, current rewards: 244.18037, mean: 0.10347
[32m[0906 14-41-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03458, current rewards: 249.62418, mean: 0.10358
[32m[0906 14-41-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03458, current rewards: 255.03483, mean: 0.10367
[32m[0906 14-41-15 @Agent.py:117][0m Average action selection time: 0.0346
[32m[0906 14-41-15 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-41-15 @MBExp.py:227][0m Rewards obtained: [259.3580652271002], Lows: [4], Highs: [5], Total time: 2703.16483
[32m[0906 14-42-21 @MBExp.py:144][0m ####################################################################
[32m[0906 14-42-21 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 14-42-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03470, current rewards: -1.22761, mean: -0.12276
[32m[0906 14-42-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03511, current rewards: 4.22928, mean: 0.07049
[32m[0906 14-42-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03513, current rewards: 9.68169, mean: 0.08802
[32m[0906 14-42-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03505, current rewards: 15.12909, mean: 0.09456
[32m[0906 14-42-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03488, current rewards: 20.57710, mean: 0.09799
[32m[0906 14-42-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03481, current rewards: 26.02871, mean: 0.10011
[32m[0906 14-42-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03472, current rewards: 31.64012, mean: 0.10206
[32m[0906 14-42-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03469, current rewards: 37.02890, mean: 0.10286
[32m[0906 14-42-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03466, current rewards: 41.31912, mean: 0.10078
[32m[0906 14-42-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03466, current rewards: 46.75027, mean: 0.10163
[32m[0906 14-42-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03464, current rewards: 52.17201, mean: 0.10230
[32m[0906 14-42-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03461, current rewards: 57.59898, mean: 0.10286
[32m[0906 14-42-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03460, current rewards: 63.02121, mean: 0.10331
[32m[0906 14-42-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03466, current rewards: 68.44390, mean: 0.10370
[32m[0906 14-42-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03470, current rewards: 73.86886, mean: 0.10404
[32m[0906 14-42-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03474, current rewards: 75.11747, mean: 0.09884
[32m[0906 14-42-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03477, current rewards: 80.64979, mean: 0.09957
[32m[0906 14-42-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03480, current rewards: 86.17637, mean: 0.10021
[32m[0906 14-42-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03482, current rewards: 91.70490, mean: 0.10077
[32m[0906 14-42-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03485, current rewards: 97.23833, mean: 0.10129
[32m[0906 14-42-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03486, current rewards: 101.52438, mean: 0.10052
[32m[0906 14-42-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03484, current rewards: 106.96569, mean: 0.10091
[32m[0906 14-43-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03482, current rewards: 112.40794, mean: 0.10127
[32m[0906 14-43-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03480, current rewards: 117.88315, mean: 0.10162
[32m[0906 14-43-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03478, current rewards: 123.34221, mean: 0.10194
[32m[0906 14-43-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03477, current rewards: 128.80411, mean: 0.10223
[32m[0906 14-43-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03476, current rewards: 133.14979, mean: 0.10164
[32m[0906 14-43-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03476, current rewards: 138.58414, mean: 0.10190
[32m[0906 14-43-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03475, current rewards: 144.01610, mean: 0.10214
[32m[0906 14-43-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03473, current rewards: 149.45135, mean: 0.10236
[32m[0906 14-43-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03470, current rewards: 154.88544, mean: 0.10257
[32m[0906 14-43-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03467, current rewards: 160.26638, mean: 0.10273
[32m[0906 14-43-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03465, current rewards: 165.68427, mean: 0.10291
[32m[0906 14-43-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03461, current rewards: 171.05273, mean: 0.10304
[32m[0906 14-43-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03458, current rewards: 176.30723, mean: 0.10310
[32m[0906 14-43-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03456, current rewards: 181.55888, mean: 0.10316
[32m[0906 14-43-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03454, current rewards: 186.81169, mean: 0.10321
[32m[0906 14-43-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03451, current rewards: 192.05956, mean: 0.10326
[32m[0906 14-43-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03449, current rewards: 197.31445, mean: 0.10331
[32m[0906 14-43-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03446, current rewards: 202.79721, mean: 0.10347
[32m[0906 14-43-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03444, current rewards: 208.20104, mean: 0.10358
[32m[0906 14-43-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03443, current rewards: 213.60271, mean: 0.10369
[32m[0906 14-43-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03444, current rewards: 219.00994, mean: 0.10380
[32m[0906 14-43-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03444, current rewards: 224.42081, mean: 0.10390
[32m[0906 14-43-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03444, current rewards: 229.87604, mean: 0.10402
[32m[0906 14-43-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03444, current rewards: 235.33656, mean: 0.10413
[32m[0906 14-43-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03444, current rewards: 240.79524, mean: 0.10424
[32m[0906 14-43-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03445, current rewards: 246.18095, mean: 0.10431
[32m[0906 14-43-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03445, current rewards: 251.29117, mean: 0.10427
[32m[0906 14-43-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03445, current rewards: 256.50793, mean: 0.10427
[32m[0906 14-43-48 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 14-43-48 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-43-48 @MBExp.py:227][0m Rewards obtained: [260.67630672644486], Lows: [2], Highs: [5], Total time: 2789.9231720000002
[32m[0906 14-44-56 @MBExp.py:144][0m ####################################################################
[32m[0906 14-44-56 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 14-44-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03432, current rewards: -1.07658, mean: -0.10766
[32m[0906 14-44-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03505, current rewards: 4.46559, mean: 0.07443
[32m[0906 14-44-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03493, current rewards: 10.00171, mean: 0.09092
[32m[0906 14-45-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03492, current rewards: 15.54860, mean: 0.09718
[32m[0906 14-45-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03508, current rewards: 21.08711, mean: 0.10041
[32m[0906 14-45-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03519, current rewards: 26.62716, mean: 0.10241
[32m[0906 14-45-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03527, current rewards: 32.21918, mean: 0.10393
[32m[0906 14-45-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03533, current rewards: 37.74798, mean: 0.10486
[32m[0906 14-45-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03540, current rewards: 43.28066, mean: 0.10556
[32m[0906 14-45-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03541, current rewards: 48.80989, mean: 0.10611
[32m[0906 14-45-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03540, current rewards: 54.33820, mean: 0.10655
[32m[0906 14-45-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03544, current rewards: 59.87299, mean: 0.10692
[32m[0906 14-45-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03552, current rewards: 63.33476, mean: 0.10383
[32m[0906 14-45-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03553, current rewards: 68.84691, mean: 0.10431
[32m[0906 14-45-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03551, current rewards: 74.28248, mean: 0.10462
[32m[0906 14-45-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03548, current rewards: 79.80007, mean: 0.10500
[32m[0906 14-45-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03547, current rewards: 85.32058, mean: 0.10533
[32m[0906 14-45-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03546, current rewards: 90.83951, mean: 0.10563
[32m[0906 14-45-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03545, current rewards: 96.36109, mean: 0.10589
[32m[0906 14-45-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03542, current rewards: 101.88326, mean: 0.10613
[32m[0906 14-45-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03536, current rewards: 107.40683, mean: 0.10634
[32m[0906 14-45-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03533, current rewards: 112.92742, mean: 0.10654
[32m[0906 14-45-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03528, current rewards: 118.45311, mean: 0.10671
[32m[0906 14-45-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03525, current rewards: 123.97474, mean: 0.10687
[32m[0906 14-45-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03522, current rewards: 129.49208, mean: 0.10702
[32m[0906 14-45-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03519, current rewards: 135.01892, mean: 0.10716
[32m[0906 14-45-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03516, current rewards: 140.53727, mean: 0.10728
[32m[0906 14-45-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03513, current rewards: 146.06085, mean: 0.10740
[32m[0906 14-45-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03509, current rewards: 151.58470, mean: 0.10751
[32m[0906 14-45-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03504, current rewards: 155.25998, mean: 0.10634
[32m[0906 14-45-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03499, current rewards: 160.83159, mean: 0.10651
[32m[0906 14-45-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03495, current rewards: 166.39901, mean: 0.10667
[32m[0906 14-45-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03491, current rewards: 171.96550, mean: 0.10681
[32m[0906 14-45-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03487, current rewards: 177.53341, mean: 0.10695
[32m[0906 14-45-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03484, current rewards: 183.10161, mean: 0.10708
[32m[0906 14-45-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03480, current rewards: 188.66959, mean: 0.10720
[32m[0906 14-45-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03477, current rewards: 194.24203, mean: 0.10732
[32m[0906 14-46-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03474, current rewards: 199.81044, mean: 0.10742
[32m[0906 14-46-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03470, current rewards: 205.41388, mean: 0.10755
[32m[0906 14-46-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03468, current rewards: 208.83961, mean: 0.10655
[32m[0906 14-46-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03466, current rewards: 214.25624, mean: 0.10660
[32m[0906 14-46-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03464, current rewards: 219.66955, mean: 0.10664
[32m[0906 14-46-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03464, current rewards: 225.07934, mean: 0.10667
[32m[0906 14-46-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03463, current rewards: 230.49791, mean: 0.10671
[32m[0906 14-46-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03463, current rewards: 235.91642, mean: 0.10675
[32m[0906 14-46-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03462, current rewards: 241.32880, mean: 0.10678
[32m[0906 14-46-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03462, current rewards: 246.74171, mean: 0.10681
[32m[0906 14-46-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03461, current rewards: 252.11658, mean: 0.10683
[32m[0906 14-46-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03461, current rewards: 257.52831, mean: 0.10686
[32m[0906 14-46-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03460, current rewards: 260.84666, mean: 0.10604
[32m[0906 14-46-23 @Agent.py:117][0m Average action selection time: 0.0346
[32m[0906 14-46-23 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-46-23 @MBExp.py:227][0m Rewards obtained: [265.256938833277], Lows: [3], Highs: [4], Total time: 2877.064616
[32m[0906 14-47-33 @MBExp.py:144][0m ####################################################################
[32m[0906 14-47-33 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 14-47-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03440, current rewards: 0.03064, mean: 0.00306
[32m[0906 14-47-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03426, current rewards: 5.62802, mean: 0.09380
[32m[0906 14-47-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03440, current rewards: 11.22147, mean: 0.10201
[32m[0906 14-47-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03437, current rewards: 16.81160, mean: 0.10507
[32m[0906 14-47-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03436, current rewards: 22.40407, mean: 0.10669
[32m[0906 14-47-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03438, current rewards: 28.21853, mean: 0.10853
[32m[0906 14-47-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03442, current rewards: 33.89443, mean: 0.10934
[32m[0906 14-47-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03441, current rewards: 39.48829, mean: 0.10969
[32m[0906 14-47-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03440, current rewards: 45.08797, mean: 0.10997
[32m[0906 14-47-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03441, current rewards: 50.68814, mean: 0.11019
[32m[0906 14-47-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03449, current rewards: 54.31841, mean: 0.10651
[32m[0906 14-47-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03456, current rewards: 59.92066, mean: 0.10700
[32m[0906 14-47-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03462, current rewards: 65.52183, mean: 0.10741
[32m[0906 14-47-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03466, current rewards: 71.12308, mean: 0.10776
[32m[0906 14-47-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03470, current rewards: 76.66064, mean: 0.10797
[32m[0906 14-47-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03472, current rewards: 82.26506, mean: 0.10824
[32m[0906 14-48-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03478, current rewards: 86.00202, mean: 0.10618
[32m[0906 14-48-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03479, current rewards: 91.46149, mean: 0.10635
[32m[0906 14-48-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03478, current rewards: 96.92298, mean: 0.10651
[32m[0906 14-48-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03476, current rewards: 102.38300, mean: 0.10665
[32m[0906 14-48-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03475, current rewards: 107.84038, mean: 0.10677
[32m[0906 14-48-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03473, current rewards: 113.29587, mean: 0.10688
[32m[0906 14-48-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03472, current rewards: 117.21310, mean: 0.10560
[32m[0906 14-48-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03470, current rewards: 122.89018, mean: 0.10594
[32m[0906 14-48-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03469, current rewards: 128.56726, mean: 0.10625
[32m[0906 14-48-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03468, current rewards: 134.24434, mean: 0.10654
[32m[0906 14-48-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03466, current rewards: 127.61493, mean: 0.09742
[32m[0906 14-48-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03463, current rewards: 133.22662, mean: 0.09796
[32m[0906 14-48-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03459, current rewards: 138.83989, mean: 0.09847
[32m[0906 14-48-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03456, current rewards: 144.45265, mean: 0.09894
[32m[0906 14-48-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03452, current rewards: 150.05348, mean: 0.09937
[32m[0906 14-48-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03450, current rewards: 155.66337, mean: 0.09978
[32m[0906 14-48-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03447, current rewards: 159.14275, mean: 0.09885
[32m[0906 14-48-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03444, current rewards: 164.71860, mean: 0.09923
[32m[0906 14-48-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03442, current rewards: 170.29399, mean: 0.09959
[32m[0906 14-48-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03439, current rewards: 175.87280, mean: 0.09993
[32m[0906 14-48-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03436, current rewards: 181.45156, mean: 0.10025
[32m[0906 14-48-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03434, current rewards: 187.03171, mean: 0.10055
[32m[0906 14-48-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03433, current rewards: 192.40813, mean: 0.10074
[32m[0906 14-48-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03432, current rewards: 198.01411, mean: 0.10103
[32m[0906 14-48-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03430, current rewards: 203.60780, mean: 0.10130
[32m[0906 14-48-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03430, current rewards: 209.21047, mean: 0.10156
[32m[0906 14-48-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03430, current rewards: 214.81147, mean: 0.10181
[32m[0906 14-48-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03431, current rewards: 220.41829, mean: 0.10205
[32m[0906 14-48-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03431, current rewards: 226.03279, mean: 0.10228
[32m[0906 14-48-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03432, current rewards: 231.64134, mean: 0.10250
[32m[0906 14-48-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03432, current rewards: 237.28847, mean: 0.10272
[32m[0906 14-48-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03433, current rewards: 242.88622, mean: 0.10292
[32m[0906 14-48-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03433, current rewards: 248.50172, mean: 0.10311
[32m[0906 14-48-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03434, current rewards: 254.11265, mean: 0.10330
[32m[0906 14-48-59 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 14-48-59 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-48-59 @MBExp.py:227][0m Rewards obtained: [256.5229068759897], Lows: [5], Highs: [12], Total time: 2963.543224
[32m[0906 14-50-11 @MBExp.py:144][0m ####################################################################
[32m[0906 14-50-11 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 14-50-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03423, current rewards: -3.23035, mean: -0.32303
[32m[0906 14-50-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03443, current rewards: 1.59678, mean: 0.02661
[32m[0906 14-50-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03443, current rewards: 6.37252, mean: 0.05793
[32m[0906 14-50-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03445, current rewards: 11.14124, mean: 0.06963
[32m[0906 14-50-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03451, current rewards: 15.91244, mean: 0.07577
[32m[0906 14-50-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03444, current rewards: 20.66122, mean: 0.07947
[32m[0906 14-50-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03444, current rewards: 25.41613, mean: 0.08199
[32m[0906 14-50-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03443, current rewards: 28.49439, mean: 0.07915
[32m[0906 14-50-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03444, current rewards: 34.04000, mean: 0.08302
[32m[0906 14-50-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03454, current rewards: 39.58120, mean: 0.08605
[32m[0906 14-50-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03460, current rewards: 45.12614, mean: 0.08848
[32m[0906 14-50-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03467, current rewards: 50.67360, mean: 0.09049
[32m[0906 14-50-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03472, current rewards: 56.21805, mean: 0.09216
[32m[0906 14-50-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03476, current rewards: 60.74030, mean: 0.09203
[32m[0906 14-50-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03480, current rewards: 66.23503, mean: 0.09329
[32m[0906 14-50-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03483, current rewards: 71.72635, mean: 0.09438
[32m[0906 14-50-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03486, current rewards: 77.22111, mean: 0.09533
[32m[0906 14-50-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03485, current rewards: 82.71654, mean: 0.09618
[32m[0906 14-50-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03484, current rewards: 88.21185, mean: 0.09694
[32m[0906 14-50-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03482, current rewards: 93.70286, mean: 0.09761
[32m[0906 14-50-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03479, current rewards: 99.20024, mean: 0.09822
[32m[0906 14-50-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03478, current rewards: 104.53329, mean: 0.09862
[32m[0906 14-50-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03476, current rewards: 110.01326, mean: 0.09911
[32m[0906 14-50-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03475, current rewards: 115.51050, mean: 0.09958
[32m[0906 14-50-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03473, current rewards: 118.86523, mean: 0.09824
[32m[0906 14-50-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03473, current rewards: 124.36747, mean: 0.09870
[32m[0906 14-50-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03470, current rewards: 129.87349, mean: 0.09914
[32m[0906 14-50-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03467, current rewards: 135.38412, mean: 0.09955
[32m[0906 14-51-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03463, current rewards: 140.89737, mean: 0.09993
[32m[0906 14-51-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03460, current rewards: 146.40862, mean: 0.10028
[32m[0906 14-51-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03458, current rewards: 152.01671, mean: 0.10067
[32m[0906 14-51-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03454, current rewards: 157.53346, mean: 0.10098
[32m[0906 14-51-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03451, current rewards: 163.05284, mean: 0.10128
[32m[0906 14-51-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03448, current rewards: 168.57283, mean: 0.10155
[32m[0906 14-51-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03446, current rewards: 174.09528, mean: 0.10181
[32m[0906 14-51-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03444, current rewards: 179.61461, mean: 0.10205
[32m[0906 14-51-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03443, current rewards: 183.93302, mean: 0.10162
[32m[0906 14-51-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03440, current rewards: 189.33865, mean: 0.10179
[32m[0906 14-51-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03438, current rewards: 194.87218, mean: 0.10203
[32m[0906 14-51-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03436, current rewards: 200.31415, mean: 0.10220
[32m[0906 14-51-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03434, current rewards: 205.75404, mean: 0.10237
[32m[0906 14-51-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03434, current rewards: 211.18615, mean: 0.10252
[32m[0906 14-51-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03435, current rewards: 216.62333, mean: 0.10267
[32m[0906 14-51-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03435, current rewards: 222.06300, mean: 0.10281
[32m[0906 14-51-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03435, current rewards: 227.50380, mean: 0.10294
[32m[0906 14-51-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03436, current rewards: 230.89326, mean: 0.10217
[32m[0906 14-51-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03436, current rewards: 236.24326, mean: 0.10227
[32m[0906 14-51-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03436, current rewards: 241.79814, mean: 0.10246
[32m[0906 14-51-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03436, current rewards: 247.34796, mean: 0.10263
[32m[0906 14-51-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03437, current rewards: 252.90077, mean: 0.10281
[32m[0906 14-51-38 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 14-51-38 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-51-38 @MBExp.py:227][0m Rewards obtained: [257.34352205135696], Lows: [4], Highs: [4], Total time: 3050.106615
[32m[0906 14-52-52 @MBExp.py:144][0m ####################################################################
[32m[0906 14-52-52 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 14-52-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03387, current rewards: -0.16577, mean: -0.01658
[32m[0906 14-52-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03431, current rewards: 5.36971, mean: 0.08950
[32m[0906 14-52-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03438, current rewards: 10.93705, mean: 0.09943
[32m[0906 14-52-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03434, current rewards: 16.50036, mean: 0.10313
[32m[0906 14-52-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03438, current rewards: 22.06672, mean: 0.10508
[32m[0906 14-53-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03441, current rewards: 27.89903, mean: 0.10730
[32m[0906 14-53-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03444, current rewards: 33.47650, mean: 0.10799
[32m[0906 14-53-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03448, current rewards: 39.05398, mean: 0.10848
[32m[0906 14-53-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03459, current rewards: 44.63240, mean: 0.10886
[32m[0906 14-53-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03467, current rewards: 50.20996, mean: 0.10915
[32m[0906 14-53-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03473, current rewards: 55.78499, mean: 0.10938
[32m[0906 14-53-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03479, current rewards: 59.35121, mean: 0.10598
[32m[0906 14-53-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03483, current rewards: 64.95880, mean: 0.10649
[32m[0906 14-53-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03486, current rewards: 70.55164, mean: 0.10690
[32m[0906 14-53-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03490, current rewards: 76.14841, mean: 0.10725
[32m[0906 14-53-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03492, current rewards: 81.75320, mean: 0.10757
[32m[0906 14-53-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03489, current rewards: 87.35442, mean: 0.10784
[32m[0906 14-53-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03488, current rewards: 92.96060, mean: 0.10809
[32m[0906 14-53-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03486, current rewards: 98.56534, mean: 0.10831
[32m[0906 14-53-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03484, current rewards: 104.17284, mean: 0.10851
[32m[0906 14-53-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03483, current rewards: 109.77808, mean: 0.10869
[32m[0906 14-53-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03481, current rewards: 115.23047, mean: 0.10871
[32m[0906 14-53-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03481, current rewards: 119.64046, mean: 0.10778
[32m[0906 14-53-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03480, current rewards: 125.04984, mean: 0.10780
[32m[0906 14-53-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03479, current rewards: 130.45854, mean: 0.10782
[32m[0906 14-53-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03474, current rewards: 135.87243, mean: 0.10784
[32m[0906 14-53-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03470, current rewards: 141.28100, mean: 0.10785
[32m[0906 14-53-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03466, current rewards: 146.68991, mean: 0.10786
[32m[0906 14-53-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03464, current rewards: 150.01206, mean: 0.10639
[32m[0906 14-53-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03460, current rewards: 155.62356, mean: 0.10659
[32m[0906 14-53-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03457, current rewards: 161.31509, mean: 0.10683
[32m[0906 14-53-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03454, current rewards: 166.89721, mean: 0.10699
[32m[0906 14-53-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03451, current rewards: 172.47736, mean: 0.10713
[32m[0906 14-53-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03449, current rewards: 178.05844, mean: 0.10726
[32m[0906 14-53-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03446, current rewards: 181.73600, mean: 0.10628
[32m[0906 14-53-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03444, current rewards: 187.36404, mean: 0.10646
[32m[0906 14-53-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03442, current rewards: 192.99176, mean: 0.10663
[32m[0906 14-53-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03440, current rewards: 198.61850, mean: 0.10678
[32m[0906 14-53-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03438, current rewards: 206.73903, mean: 0.10824
[32m[0906 14-54-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03436, current rewards: 216.07247, mean: 0.11024
[32m[0906 14-54-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03435, current rewards: 225.40591, mean: 0.11214
[32m[0906 14-54-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03435, current rewards: 184.89926, mean: 0.08976
[32m[0906 14-54-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03435, current rewards: 167.10130, mean: 0.07919
[32m[0906 14-54-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03436, current rewards: 172.69919, mean: 0.07995
[32m[0906 14-54-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03436, current rewards: 178.29871, mean: 0.08068
[32m[0906 14-54-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03437, current rewards: 183.89592, mean: 0.08137
[32m[0906 14-54-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03437, current rewards: 189.37370, mean: 0.08198
[32m[0906 14-54-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03437, current rewards: 194.96757, mean: 0.08261
[32m[0906 14-54-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03437, current rewards: 200.54990, mean: 0.08322
[32m[0906 14-54-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03437, current rewards: 206.13879, mean: 0.08380
[32m[0906 14-54-18 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 14-54-18 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-54-18 @MBExp.py:227][0m Rewards obtained: [208.58360712137485], Lows: [4], Highs: [65], Total time: 3136.7022730000003
[32m[0906 14-55-34 @MBExp.py:144][0m ####################################################################
[32m[0906 14-55-34 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 14-55-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03297, current rewards: 0.06358, mean: 0.00636
[32m[0906 14-55-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03424, current rewards: 5.55559, mean: 0.09259
[32m[0906 14-55-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03437, current rewards: 11.04672, mean: 0.10042
[32m[0906 14-55-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03441, current rewards: 16.53792, mean: 0.10336
[32m[0906 14-55-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03445, current rewards: 22.02507, mean: 0.10488
[32m[0906 14-55-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03440, current rewards: 27.51437, mean: 0.10582
[32m[0906 14-55-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03455, current rewards: 33.00805, mean: 0.10648
[32m[0906 14-55-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03465, current rewards: 38.49956, mean: 0.10694
[32m[0906 14-55-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03472, current rewards: 43.94737, mean: 0.10719
[32m[0906 14-55-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03478, current rewards: 49.43526, mean: 0.10747
[32m[0906 14-55-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03485, current rewards: 54.91844, mean: 0.10768
[32m[0906 14-55-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03491, current rewards: 60.39539, mean: 0.10785
[32m[0906 14-55-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03494, current rewards: 65.90076, mean: 0.10803
[32m[0906 14-55-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03497, current rewards: 71.39098, mean: 0.10817
[32m[0906 14-55-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03501, current rewards: 76.87025, mean: 0.10827
[32m[0906 14-56-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03498, current rewards: 82.34964, mean: 0.10835
[32m[0906 14-56-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03495, current rewards: 87.83364, mean: 0.10844
[32m[0906 14-56-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03492, current rewards: 93.32069, mean: 0.10851
[32m[0906 14-56-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03489, current rewards: 98.73742, mean: 0.10850
[32m[0906 14-56-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03488, current rewards: 104.14968, mean: 0.10849
[32m[0906 14-56-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03486, current rewards: 109.65891, mean: 0.10857
[32m[0906 14-56-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03484, current rewards: 115.12781, mean: 0.10861
[32m[0906 14-56-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03482, current rewards: 120.55166, mean: 0.10861
[32m[0906 14-56-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03480, current rewards: 125.97186, mean: 0.10860
[32m[0906 14-56-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03475, current rewards: 131.39760, mean: 0.10859
[32m[0906 14-56-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03471, current rewards: 136.81638, mean: 0.10858
[32m[0906 14-56-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03468, current rewards: 142.23896, mean: 0.10858
[32m[0906 14-56-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03464, current rewards: 147.66734, mean: 0.10858
[32m[0906 14-56-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03461, current rewards: 149.79560, mean: 0.10624
[32m[0906 14-56-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03458, current rewards: 154.74990, mean: 0.10599
[32m[0906 14-56-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03455, current rewards: 160.25166, mean: 0.10613
[32m[0906 14-56-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03452, current rewards: 165.75262, mean: 0.10625
[32m[0906 14-56-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03449, current rewards: 171.24902, mean: 0.10637
[32m[0906 14-56-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03446, current rewards: 176.74646, mean: 0.10647
[32m[0906 14-56-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03444, current rewards: 182.24729, mean: 0.10658
[32m[0906 14-56-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03442, current rewards: 187.75183, mean: 0.10668
[32m[0906 14-56-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03439, current rewards: 193.25082, mean: 0.10677
[32m[0906 14-56-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03437, current rewards: 198.95538, mean: 0.10697
[32m[0906 14-56-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03435, current rewards: 205.67825, mean: 0.10768
[32m[0906 14-56-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03434, current rewards: 212.60491, mean: 0.10847
[32m[0906 14-56-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03432, current rewards: 217.25450, mean: 0.10809
[32m[0906 14-56-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03432, current rewards: 193.82019, mean: 0.09409
[32m[0906 14-56-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03433, current rewards: 199.30809, mean: 0.09446
[32m[0906 14-56-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03434, current rewards: 204.80641, mean: 0.09482
[32m[0906 14-56-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03434, current rewards: 210.29833, mean: 0.09516
[32m[0906 14-56-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03434, current rewards: 213.85685, mean: 0.09463
[32m[0906 14-56-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03435, current rewards: 219.38507, mean: 0.09497
[32m[0906 14-56-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03435, current rewards: 224.90095, mean: 0.09530
[32m[0906 14-56-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03436, current rewards: 230.41697, mean: 0.09561
[32m[0906 14-56-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03436, current rewards: 235.92779, mean: 0.09591
[32m[0906 14-57-01 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 14-57-01 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-57-01 @MBExp.py:227][0m Rewards obtained: [240.33579324847568], Lows: [3], Highs: [29], Total time: 3223.2543410000003
[32m[0906 14-58-19 @MBExp.py:144][0m ####################################################################
[32m[0906 14-58-19 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 14-58-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03468, current rewards: 0.98521, mean: 0.09852
[32m[0906 14-58-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03454, current rewards: 6.51751, mean: 0.10863
[32m[0906 14-58-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03455, current rewards: 12.07522, mean: 0.10977
[32m[0906 14-58-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03452, current rewards: 17.63564, mean: 0.11022
[32m[0906 14-58-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03462, current rewards: 23.19877, mean: 0.11047
[32m[0906 14-58-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03477, current rewards: 28.75588, mean: 0.11060
[32m[0906 14-58-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03488, current rewards: 34.31211, mean: 0.11068
[32m[0906 14-58-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03493, current rewards: 39.87108, mean: 0.11075
[32m[0906 14-58-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03500, current rewards: 45.42639, mean: 0.11080
[32m[0906 14-58-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03506, current rewards: 49.83440, mean: 0.10834
[32m[0906 14-58-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03510, current rewards: 55.38271, mean: 0.10859
[32m[0906 14-58-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03511, current rewards: 60.93387, mean: 0.10881
[32m[0906 14-58-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03512, current rewards: 66.41776, mean: 0.10888
[32m[0906 14-58-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03512, current rewards: 71.96139, mean: 0.10903
[32m[0906 14-58-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03507, current rewards: 77.50717, mean: 0.10917
[32m[0906 14-58-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03503, current rewards: 83.04910, mean: 0.10928
[32m[0906 14-58-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03500, current rewards: 88.59309, mean: 0.10937
[32m[0906 14-58-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03497, current rewards: 94.13866, mean: 0.10946
[32m[0906 14-58-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03495, current rewards: 98.62654, mean: 0.10838
[32m[0906 14-58-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03492, current rewards: 104.14531, mean: 0.10848
[32m[0906 14-58-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03490, current rewards: 109.63253, mean: 0.10855
[32m[0906 14-58-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03488, current rewards: 115.15530, mean: 0.10864
[32m[0906 14-58-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03484, current rewards: 120.67620, mean: 0.10872
[32m[0906 14-59-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03479, current rewards: 126.19884, mean: 0.10879
[32m[0906 14-59-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03475, current rewards: 131.72220, mean: 0.10886
[32m[0906 14-59-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03471, current rewards: 137.24507, mean: 0.10892
[32m[0906 14-59-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03467, current rewards: 142.76559, mean: 0.10898
[32m[0906 14-59-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03464, current rewards: 146.18175, mean: 0.10749
[32m[0906 14-59-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03461, current rewards: 151.82119, mean: 0.10767
[32m[0906 14-59-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03458, current rewards: 157.37533, mean: 0.10779
[32m[0906 14-59-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03454, current rewards: 162.91184, mean: 0.10789
[32m[0906 14-59-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03451, current rewards: 168.44667, mean: 0.10798
[32m[0906 14-59-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03449, current rewards: 173.97847, mean: 0.10806
[32m[0906 14-59-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03446, current rewards: 179.51273, mean: 0.10814
[32m[0906 14-59-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03444, current rewards: 185.05060, mean: 0.10822
[32m[0906 14-59-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03442, current rewards: 190.58641, mean: 0.10829
[32m[0906 14-59-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03440, current rewards: 195.03280, mean: 0.10775
[32m[0906 14-59-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03438, current rewards: 200.39675, mean: 0.10774
[32m[0906 14-59-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03437, current rewards: 205.77620, mean: 0.10774
[32m[0906 14-59-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03435, current rewards: 211.14978, mean: 0.10773
[32m[0906 14-59-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03435, current rewards: 216.52918, mean: 0.10773
[32m[0906 14-59-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03435, current rewards: 221.90564, mean: 0.10772
[32m[0906 14-59-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03436, current rewards: 227.28903, mean: 0.10772
[32m[0906 14-59-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03437, current rewards: 232.66880, mean: 0.10772
[32m[0906 14-59-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03438, current rewards: 238.04619, mean: 0.10771
[32m[0906 14-59-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03438, current rewards: 243.42631, mean: 0.10771
[32m[0906 14-59-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03438, current rewards: 248.80425, mean: 0.10771
[32m[0906 14-59-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03438, current rewards: 254.18781, mean: 0.10771
[32m[0906 14-59-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03439, current rewards: 257.54093, mean: 0.10686
[32m[0906 14-59-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03439, current rewards: 263.07358, mean: 0.10694
[32m[0906 14-59-46 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 14-59-46 @Agent.py:118][0m Rollout length: 2501
[32m[0906 14-59-46 @MBExp.py:227][0m Rewards obtained: [267.4991507260491], Lows: [2], Highs: [3], Total time: 3309.899588
[32m[0906 15-01-06 @MBExp.py:144][0m ####################################################################
[32m[0906 15-01-06 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 15-01-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03357, current rewards: 1.03662, mean: 0.10366
[32m[0906 15-01-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03421, current rewards: 6.57850, mean: 0.10964
[32m[0906 15-01-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03428, current rewards: 12.12177, mean: 0.11020
[32m[0906 15-01-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03458, current rewards: 17.42562, mean: 0.10891
[32m[0906 15-01-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03474, current rewards: 22.94202, mean: 0.10925
[32m[0906 15-01-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03485, current rewards: 28.45943, mean: 0.10946
[32m[0906 15-01-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03493, current rewards: 33.98102, mean: 0.10962
[32m[0906 15-01-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03498, current rewards: 39.50192, mean: 0.10973
[32m[0906 15-01-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03502, current rewards: 45.02144, mean: 0.10981
[32m[0906 15-01-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03508, current rewards: 50.53788, mean: 0.10986
[32m[0906 15-01-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03512, current rewards: 56.05896, mean: 0.10992
[32m[0906 15-01-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03515, current rewards: 61.83663, mean: 0.11042
[32m[0906 15-01-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03512, current rewards: 67.37708, mean: 0.11045
[32m[0906 15-01-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03507, current rewards: 70.73168, mean: 0.10717
[32m[0906 15-01-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03502, current rewards: 76.30246, mean: 0.10747
[32m[0906 15-01-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03498, current rewards: 81.86687, mean: 0.10772
[32m[0906 15-01-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03496, current rewards: 87.43734, mean: 0.10795
[32m[0906 15-01-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03494, current rewards: 90.93680, mean: 0.10574
[32m[0906 15-01-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03491, current rewards: 96.44673, mean: 0.10599
[32m[0906 15-01-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03489, current rewards: 101.87266, mean: 0.10612
[32m[0906 15-01-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03489, current rewards: 107.37465, mean: 0.10631
[32m[0906 15-01-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03485, current rewards: 112.87743, mean: 0.10649
[32m[0906 15-01-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03480, current rewards: 118.38224, mean: 0.10665
[32m[0906 15-01-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03475, current rewards: 123.88647, mean: 0.10680
[32m[0906 15-01-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03471, current rewards: 129.38914, mean: 0.10693
[32m[0906 15-01-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03467, current rewards: 134.89555, mean: 0.10706
[32m[0906 15-01-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03463, current rewards: 140.39710, mean: 0.10717
[32m[0906 15-01-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03460, current rewards: 145.89885, mean: 0.10728
[32m[0906 15-01-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03456, current rewards: 151.34300, mean: 0.10734
[32m[0906 15-01-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03454, current rewards: 157.04631, mean: 0.10757
[32m[0906 15-01-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03451, current rewards: 162.54713, mean: 0.10765
[32m[0906 15-02-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03449, current rewards: 168.04120, mean: 0.10772
[32m[0906 15-02-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03446, current rewards: 173.52994, mean: 0.10778
[32m[0906 15-02-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03443, current rewards: 179.02395, mean: 0.10785
[32m[0906 15-02-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03441, current rewards: 184.52340, mean: 0.10791
[32m[0906 15-02-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03439, current rewards: 190.02104, mean: 0.10797
[32m[0906 15-02-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03437, current rewards: 195.53299, mean: 0.10803
[32m[0906 15-02-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03434, current rewards: 201.02917, mean: 0.10808
[32m[0906 15-02-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03433, current rewards: 206.52534, mean: 0.10813
[32m[0906 15-02-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03432, current rewards: 212.01634, mean: 0.10817
[32m[0906 15-02-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03431, current rewards: 215.43084, mean: 0.10718
[32m[0906 15-02-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03432, current rewards: 220.94219, mean: 0.10725
[32m[0906 15-02-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03433, current rewards: 226.45711, mean: 0.10733
[32m[0906 15-02-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03433, current rewards: 231.97399, mean: 0.10740
[32m[0906 15-02-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03434, current rewards: 237.48448, mean: 0.10746
[32m[0906 15-02-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03434, current rewards: 242.99175, mean: 0.10752
[32m[0906 15-02-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03435, current rewards: 248.50784, mean: 0.10758
[32m[0906 15-02-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03436, current rewards: 254.01721, mean: 0.10763
[32m[0906 15-02-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03436, current rewards: 258.42848, mean: 0.10723
[32m[0906 15-02-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03436, current rewards: 263.92338, mean: 0.10729
[32m[0906 15-02-32 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 15-02-32 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-02-32 @MBExp.py:227][0m Rewards obtained: [268.31623615789994], Lows: [2], Highs: [3], Total time: 3396.46608
[32m[0906 15-03-55 @MBExp.py:144][0m ####################################################################
[32m[0906 15-03-55 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 15-03-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03401, current rewards: -1.10745, mean: -0.11074
[32m[0906 15-03-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03441, current rewards: 4.35093, mean: 0.07252
[32m[0906 15-03-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03478, current rewards: 9.75241, mean: 0.08866
[32m[0906 15-04-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03499, current rewards: 15.20244, mean: 0.09502
[32m[0906 15-04-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03509, current rewards: 20.65461, mean: 0.09836
[32m[0906 15-04-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03515, current rewards: 26.10829, mean: 0.10042
[32m[0906 15-04-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03520, current rewards: 31.55934, mean: 0.10180
[32m[0906 15-04-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03523, current rewards: 37.01285, mean: 0.10281
[32m[0906 15-04-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03529, current rewards: 42.46318, mean: 0.10357
[32m[0906 15-04-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03531, current rewards: 47.91103, mean: 0.10415
[32m[0906 15-04-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03532, current rewards: 53.41216, mean: 0.10473
[32m[0906 15-04-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03525, current rewards: 58.87357, mean: 0.10513
[32m[0906 15-04-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03520, current rewards: 64.33115, mean: 0.10546
[32m[0906 15-04-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03514, current rewards: 67.78111, mean: 0.10270
[32m[0906 15-04-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03510, current rewards: 73.34327, mean: 0.10330
[32m[0906 15-04-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03507, current rewards: 78.90674, mean: 0.10382
[32m[0906 15-04-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03503, current rewards: 84.47024, mean: 0.10428
[32m[0906 15-04-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03502, current rewards: 90.03307, mean: 0.10469
[32m[0906 15-04-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03499, current rewards: 93.05838, mean: 0.10226
[32m[0906 15-04-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03497, current rewards: 97.70107, mean: 0.10177
[32m[0906 15-04-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03489, current rewards: 102.33809, mean: 0.10132
[32m[0906 15-04-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03483, current rewards: 106.97610, mean: 0.10092
[32m[0906 15-04-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03478, current rewards: 110.52057, mean: 0.09957
[32m[0906 15-04-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03473, current rewards: 116.09048, mean: 0.10008
[32m[0906 15-04-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03469, current rewards: 121.66233, mean: 0.10055
[32m[0906 15-04-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03465, current rewards: 127.23298, mean: 0.10098
[32m[0906 15-04-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03461, current rewards: 132.71292, mean: 0.10131
[32m[0906 15-04-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03458, current rewards: 138.17739, mean: 0.10160
[32m[0906 15-04-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03454, current rewards: 143.72312, mean: 0.10193
[32m[0906 15-04-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03452, current rewards: 149.26908, mean: 0.10224
[32m[0906 15-04-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03450, current rewards: 154.81851, mean: 0.10253
[32m[0906 15-04-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03448, current rewards: 160.36621, mean: 0.10280
[32m[0906 15-04-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03446, current rewards: 164.82440, mean: 0.10238
[32m[0906 15-04-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03443, current rewards: 170.36308, mean: 0.10263
[32m[0906 15-04-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03441, current rewards: 175.90576, mean: 0.10287
[32m[0906 15-04-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03439, current rewards: 181.67585, mean: 0.10322
[32m[0906 15-04-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03437, current rewards: 187.23794, mean: 0.10345
[32m[0906 15-04-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03435, current rewards: 192.79722, mean: 0.10365
[32m[0906 15-05-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03434, current rewards: 198.36137, mean: 0.10385
[32m[0906 15-05-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03432, current rewards: 203.92359, mean: 0.10404
[32m[0906 15-05-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03432, current rewards: 209.48463, mean: 0.10422
[32m[0906 15-05-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03432, current rewards: 213.95989, mean: 0.10386
[32m[0906 15-05-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03433, current rewards: 219.50968, mean: 0.10403
[32m[0906 15-05-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03434, current rewards: 225.09301, mean: 0.10421
[32m[0906 15-05-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03435, current rewards: 230.64479, mean: 0.10436
[32m[0906 15-05-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03436, current rewards: 236.20244, mean: 0.10451
[32m[0906 15-05-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03436, current rewards: 241.75364, mean: 0.10466
[32m[0906 15-05-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03436, current rewards: 247.30680, mean: 0.10479
[32m[0906 15-05-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03437, current rewards: 250.76873, mean: 0.10405
[32m[0906 15-05-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03437, current rewards: 256.33480, mean: 0.10420
[32m[0906 15-05-21 @Agent.py:117][0m Average action selection time: 0.0344
[32m[0906 15-05-21 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-05-21 @MBExp.py:227][0m Rewards obtained: [260.7875165444249], Lows: [3], Highs: [6], Total time: 3483.037065
[32m[0906 15-06-45 @MBExp.py:144][0m ####################################################################
[32m[0906 15-06-45 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 15-06-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03495, current rewards: -1.14971, mean: -0.11497
[32m[0906 15-06-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03534, current rewards: 4.22510, mean: 0.07042
[32m[0906 15-06-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03538, current rewards: 9.70391, mean: 0.08822
[32m[0906 15-06-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03539, current rewards: 15.11416, mean: 0.09446
[32m[0906 15-06-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03541, current rewards: 20.52152, mean: 0.09772
[32m[0906 15-06-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03542, current rewards: 25.92404, mean: 0.09971
[32m[0906 15-06-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03541, current rewards: 31.32875, mean: 0.10106
[32m[0906 15-06-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03539, current rewards: 36.73722, mean: 0.10205
[32m[0906 15-07-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03537, current rewards: 42.14907, mean: 0.10280
[32m[0906 15-07-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03539, current rewards: 47.54983, mean: 0.10337
[32m[0906 15-07-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03531, current rewards: 52.98834, mean: 0.10390
[32m[0906 15-07-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03522, current rewards: 58.39817, mean: 0.10428
[32m[0906 15-07-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03516, current rewards: 63.80488, mean: 0.10460
[32m[0906 15-07-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03511, current rewards: 67.19595, mean: 0.10181
[32m[0906 15-07-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03507, current rewards: 72.68556, mean: 0.10237
[32m[0906 15-07-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03504, current rewards: 78.16727, mean: 0.10285
[32m[0906 15-07-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03501, current rewards: 83.65320, mean: 0.10328
[32m[0906 15-07-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03497, current rewards: 89.13705, mean: 0.10365
[32m[0906 15-07-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03494, current rewards: 92.98351, mean: 0.10218
[32m[0906 15-07-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03488, current rewards: 98.48010, mean: 0.10258
[32m[0906 15-07-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03482, current rewards: 103.97864, mean: 0.10295
[32m[0906 15-07-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03476, current rewards: 109.46924, mean: 0.10327
[32m[0906 15-07-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03471, current rewards: 114.95917, mean: 0.10357
[32m[0906 15-07-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03466, current rewards: 120.45440, mean: 0.10384
[32m[0906 15-07-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03462, current rewards: 125.94904, mean: 0.10409
[32m[0906 15-07-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03458, current rewards: 131.44423, mean: 0.10432
[32m[0906 15-07-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03456, current rewards: 136.89887, mean: 0.10450
[32m[0906 15-07-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03453, current rewards: 142.38000, mean: 0.10469
[32m[0906 15-07-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03450, current rewards: 146.78588, mean: 0.10410
[32m[0906 15-07-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03447, current rewards: 152.26891, mean: 0.10429
[32m[0906 15-07-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03445, current rewards: 157.75078, mean: 0.10447
[32m[0906 15-07-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03442, current rewards: 163.23433, mean: 0.10464
[32m[0906 15-07-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03440, current rewards: 168.71143, mean: 0.10479
[32m[0906 15-07-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03438, current rewards: 174.19447, mean: 0.10494
[32m[0906 15-07-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03436, current rewards: 179.67744, mean: 0.10507
[32m[0906 15-07-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03435, current rewards: 185.15814, mean: 0.10520
[32m[0906 15-07-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03433, current rewards: 190.63633, mean: 0.10532
[32m[0906 15-07-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03432, current rewards: 196.13203, mean: 0.10545
[32m[0906 15-07-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03431, current rewards: 201.60876, mean: 0.10555
[32m[0906 15-07-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03429, current rewards: 207.09445, mean: 0.10566
[32m[0906 15-07-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03430, current rewards: 212.57118, mean: 0.10576
[32m[0906 15-07-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03430, current rewards: 216.68142, mean: 0.10519
[32m[0906 15-07-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03431, current rewards: 222.89715, mean: 0.10564
[32m[0906 15-08-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03432, current rewards: 229.99370, mean: 0.10648
[32m[0906 15-08-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03432, current rewards: 237.09025, mean: 0.10728
[32m[0906 15-08-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03433, current rewards: 244.18680, mean: 0.10805
[32m[0906 15-08-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03433, current rewards: 251.28335, mean: 0.10878
[32m[0906 15-08-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03434, current rewards: 258.37990, mean: 0.10948
[32m[0906 15-08-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03434, current rewards: 265.47645, mean: 0.11016
[32m[0906 15-08-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03434, current rewards: 272.57300, mean: 0.11080
[32m[0906 15-08-12 @Agent.py:117][0m Average action selection time: 0.0343
[32m[0906 15-08-12 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-08-12 @MBExp.py:227][0m Rewards obtained: [278.2502422284355], Lows: [3], Highs: [3], Total time: 3569.507358
[32m[0906 15-09-38 @MBExp.py:144][0m ####################################################################
[32m[0906 15-09-38 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 15-09-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03392, current rewards: 0.09891, mean: 0.00989
[32m[0906 15-09-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03514, current rewards: 5.82079, mean: 0.09701
[32m[0906 15-09-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03529, current rewards: 11.32252, mean: 0.10293
[32m[0906 15-09-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03530, current rewards: 16.82482, mean: 0.10516
[32m[0906 15-09-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03534, current rewards: 22.32712, mean: 0.10632
[32m[0906 15-09-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03530, current rewards: 27.83136, mean: 0.10704
[32m[0906 15-09-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03532, current rewards: 33.33412, mean: 0.10753
[32m[0906 15-09-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03530, current rewards: 37.74853, mean: 0.10486
[32m[0906 15-09-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03531, current rewards: 43.31995, mean: 0.10566
[32m[0906 15-09-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03519, current rewards: 48.93003, mean: 0.10637
[32m[0906 15-09-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03512, current rewards: 54.50633, mean: 0.10688
[32m[0906 15-09-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03508, current rewards: 60.07897, mean: 0.10728
[32m[0906 15-10-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03503, current rewards: 65.64775, mean: 0.10762
[32m[0906 15-10-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03501, current rewards: 71.20980, mean: 0.10789
[32m[0906 15-10-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03496, current rewards: 76.77337, mean: 0.10813
[32m[0906 15-10-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03491, current rewards: 82.33579, mean: 0.10834
[32m[0906 15-10-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03487, current rewards: 87.90097, mean: 0.10852
[32m[0906 15-10-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03481, current rewards: 93.35018, mean: 0.10855
[32m[0906 15-10-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03475, current rewards: 98.91593, mean: 0.10870
[32m[0906 15-10-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03470, current rewards: 104.46970, mean: 0.10882
[32m[0906 15-10-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03463, current rewards: 110.02424, mean: 0.10893
[32m[0906 15-10-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03458, current rewards: 115.57672, mean: 0.10903
[32m[0906 15-10-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03453, current rewards: 121.12890, mean: 0.10913
[32m[0906 15-10-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03448, current rewards: 124.55571, mean: 0.10738
[32m[0906 15-10-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03445, current rewards: 130.10260, mean: 0.10752
[32m[0906 15-10-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03441, current rewards: 135.59652, mean: 0.10762
[32m[0906 15-10-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03439, current rewards: 141.13573, mean: 0.10774
[32m[0906 15-10-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03435, current rewards: 146.67584, mean: 0.10785
[32m[0906 15-10-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03433, current rewards: 152.21437, mean: 0.10795
[32m[0906 15-10-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03431, current rewards: 157.75071, mean: 0.10805
[32m[0906 15-10-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03428, current rewards: 161.35676, mean: 0.10686
[32m[0906 15-10-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03426, current rewards: 166.94352, mean: 0.10702
[32m[0906 15-10-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03424, current rewards: 172.52578, mean: 0.10716
[32m[0906 15-10-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03423, current rewards: 178.32804, mean: 0.10743
[32m[0906 15-10-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03421, current rewards: 187.19643, mean: 0.10947
[32m[0906 15-10-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03419, current rewards: 196.24986, mean: 0.11151
[32m[0906 15-10-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03418, current rewards: 205.30329, mean: 0.11343
[32m[0906 15-10-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03415, current rewards: 214.35673, mean: 0.11525
[32m[0906 15-10-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03414, current rewards: 223.41016, mean: 0.11697
[32m[0906 15-10-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03413, current rewards: 227.73932, mean: 0.11619
[32m[0906 15-10-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03414, current rewards: 177.73932, mean: 0.08843
[32m[0906 15-10-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03415, current rewards: 127.73932, mean: 0.06201
[32m[0906 15-10-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03415, current rewards: 77.73932, mean: 0.03684
[32m[0906 15-10-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03416, current rewards: 27.73932, mean: 0.01284
[32m[0906 15-10-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03417, current rewards: -22.26068, mean: -0.01007
[32m[0906 15-10-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03417, current rewards: -72.26068, mean: -0.03197
[32m[0906 15-10-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03418, current rewards: -122.26068, mean: -0.05293
[32m[0906 15-10-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03419, current rewards: -172.26068, mean: -0.07299
[32m[0906 15-11-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03420, current rewards: -222.26068, mean: -0.09222
[32m[0906 15-11-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03419, current rewards: -272.26068, mean: -0.11068
[32m[0906 15-11-04 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-11-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-11-04 @MBExp.py:227][0m Rewards obtained: [-312.2606824147198], Lows: [2], Highs: [546], Total time: 3655.609903
[32m[0906 15-12-32 @MBExp.py:144][0m ####################################################################
[32m[0906 15-12-32 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 15-12-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03550, current rewards: 0.02881, mean: 0.00288
[32m[0906 15-12-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03532, current rewards: 5.52580, mean: 0.09210
[32m[0906 15-12-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03528, current rewards: 11.01659, mean: 0.10015
[32m[0906 15-12-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03536, current rewards: 16.50751, mean: 0.10317
[32m[0906 15-12-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03541, current rewards: 22.00302, mean: 0.10478
[32m[0906 15-12-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03544, current rewards: 27.47611, mean: 0.10568
[32m[0906 15-12-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03542, current rewards: 33.25539, mean: 0.10728
[32m[0906 15-12-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03541, current rewards: 39.02802, mean: 0.10841
[32m[0906 15-12-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03526, current rewards: 44.89031, mean: 0.10949
[32m[0906 15-12-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03518, current rewards: 50.75270, mean: 0.11033
[32m[0906 15-12-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03509, current rewards: 56.54222, mean: 0.11087
[32m[0906 15-12-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03505, current rewards: 62.33514, mean: 0.11131
[32m[0906 15-12-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03500, current rewards: 68.13791, mean: 0.11170
[32m[0906 15-12-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03496, current rewards: 73.94077, mean: 0.11203
[32m[0906 15-12-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03492, current rewards: 79.73704, mean: 0.11231
[32m[0906 15-12-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03491, current rewards: 83.36900, mean: 0.10970
[32m[0906 15-13-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03484, current rewards: 88.80379, mean: 0.10963
[32m[0906 15-13-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03477, current rewards: 94.11556, mean: 0.10944
[32m[0906 15-13-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03473, current rewards: 99.55378, mean: 0.10940
[32m[0906 15-13-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03468, current rewards: 104.99620, mean: 0.10937
[32m[0906 15-13-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03463, current rewards: 110.40104, mean: 0.10931
[32m[0906 15-13-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03458, current rewards: 115.86961, mean: 0.10931
[32m[0906 15-13-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03455, current rewards: 121.33378, mean: 0.10931
[32m[0906 15-13-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03451, current rewards: 126.79803, mean: 0.10931
[32m[0906 15-13-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03448, current rewards: 132.26344, mean: 0.10931
[32m[0906 15-13-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03445, current rewards: 137.71723, mean: 0.10930
[32m[0906 15-13-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03442, current rewards: 143.18986, mean: 0.10931
[32m[0906 15-13-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03440, current rewards: 148.66293, mean: 0.10931
[32m[0906 15-13-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03438, current rewards: 154.12842, mean: 0.10931
[32m[0906 15-13-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03436, current rewards: 157.45742, mean: 0.10785
[32m[0906 15-13-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03434, current rewards: 162.75903, mean: 0.10779
[32m[0906 15-13-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03432, current rewards: 168.05546, mean: 0.10773
[32m[0906 15-13-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03430, current rewards: 173.35404, mean: 0.10767
[32m[0906 15-13-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03428, current rewards: 178.64923, mean: 0.10762
[32m[0906 15-13-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03426, current rewards: 183.94456, mean: 0.10757
[32m[0906 15-13-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03425, current rewards: 187.22265, mean: 0.10638
[32m[0906 15-13-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03423, current rewards: 192.46706, mean: 0.10634
[32m[0906 15-13-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03422, current rewards: 197.71194, mean: 0.10630
[32m[0906 15-13-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03421, current rewards: 202.95413, mean: 0.10626
[32m[0906 15-13-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03420, current rewards: 208.19844, mean: 0.10622
[32m[0906 15-13-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03420, current rewards: 213.44334, mean: 0.10619
[32m[0906 15-13-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03421, current rewards: 218.84218, mean: 0.10623
[32m[0906 15-13-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03422, current rewards: 224.12573, mean: 0.10622
[32m[0906 15-13-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03423, current rewards: 229.40939, mean: 0.10621
[32m[0906 15-13-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03424, current rewards: 234.69370, mean: 0.10620
[32m[0906 15-13-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03425, current rewards: 239.97777, mean: 0.10618
[32m[0906 15-13-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03425, current rewards: 245.26016, mean: 0.10617
[32m[0906 15-13-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03426, current rewards: 250.54411, mean: 0.10616
[32m[0906 15-13-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03425, current rewards: 255.82708, mean: 0.10615
[32m[0906 15-13-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03423, current rewards: 259.04702, mean: 0.10530
[32m[0906 15-13-59 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 15-13-59 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-13-59 @MBExp.py:227][0m Rewards obtained: [263.38916054439386], Lows: [3], Highs: [3], Total time: 3741.844089
[32m[0906 15-15-29 @MBExp.py:144][0m ####################################################################
[32m[0906 15-15-29 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 15-15-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03477, current rewards: -0.15623, mean: -0.01562
[32m[0906 15-15-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03512, current rewards: 5.36318, mean: 0.08939
[32m[0906 15-15-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03530, current rewards: 10.88745, mean: 0.09898
[32m[0906 15-15-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03531, current rewards: 16.40740, mean: 0.10255
[32m[0906 15-15-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03539, current rewards: 21.93160, mean: 0.10444
[32m[0906 15-15-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03536, current rewards: 27.45266, mean: 0.10559
[32m[0906 15-15-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03530, current rewards: 32.97462, mean: 0.10637
[32m[0906 15-15-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03518, current rewards: 38.49788, mean: 0.10694
[32m[0906 15-15-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03507, current rewards: 44.02299, mean: 0.10737
[32m[0906 15-15-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03499, current rewards: 49.54257, mean: 0.10770
[32m[0906 15-15-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03494, current rewards: 55.06965, mean: 0.10798
[32m[0906 15-15-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03491, current rewards: 58.37976, mean: 0.10425
[32m[0906 15-15-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03487, current rewards: 63.81322, mean: 0.10461
[32m[0906 15-15-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03483, current rewards: 69.23650, mean: 0.10490
[32m[0906 15-15-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03481, current rewards: 74.65867, mean: 0.10515
[32m[0906 15-15-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03472, current rewards: 80.02471, mean: 0.10530
[32m[0906 15-15-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03466, current rewards: 85.43686, mean: 0.10548
[32m[0906 15-15-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03461, current rewards: 90.85150, mean: 0.10564
[32m[0906 15-16-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03456, current rewards: 96.26437, mean: 0.10579
[32m[0906 15-16-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03451, current rewards: 101.67874, mean: 0.10592
[32m[0906 15-16-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03447, current rewards: 107.09357, mean: 0.10603
[32m[0906 15-16-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03442, current rewards: 112.50372, mean: 0.10614
[32m[0906 15-16-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03438, current rewards: 117.91237, mean: 0.10623
[32m[0906 15-16-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03435, current rewards: 123.31612, mean: 0.10631
[32m[0906 15-16-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03432, current rewards: 126.55837, mean: 0.10459
[32m[0906 15-16-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03428, current rewards: 132.02997, mean: 0.10479
[32m[0906 15-16-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03426, current rewards: 137.49607, mean: 0.10496
[32m[0906 15-16-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03423, current rewards: 142.96943, mean: 0.10512
[32m[0906 15-16-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03422, current rewards: 148.44551, mean: 0.10528
[32m[0906 15-16-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03420, current rewards: 153.92385, mean: 0.10543
[32m[0906 15-16-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03418, current rewards: 159.39845, mean: 0.10556
[32m[0906 15-16-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03417, current rewards: 164.91236, mean: 0.10571
[32m[0906 15-16-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03415, current rewards: 168.25935, mean: 0.10451
[32m[0906 15-16-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03413, current rewards: 173.73184, mean: 0.10466
[32m[0906 15-16-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03411, current rewards: 179.20485, mean: 0.10480
[32m[0906 15-16-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03410, current rewards: 184.68614, mean: 0.10494
[32m[0906 15-16-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03408, current rewards: 190.16716, mean: 0.10506
[32m[0906 15-16-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03408, current rewards: 195.64731, mean: 0.10519
[32m[0906 15-16-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03407, current rewards: 201.12249, mean: 0.10530
[32m[0906 15-16-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03407, current rewards: 204.52699, mean: 0.10435
[32m[0906 15-16-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03408, current rewards: 210.17941, mean: 0.10457
[32m[0906 15-16-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03409, current rewards: 215.69676, mean: 0.10471
[32m[0906 15-16-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03409, current rewards: 221.20698, mean: 0.10484
[32m[0906 15-16-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03410, current rewards: 226.72320, mean: 0.10496
[32m[0906 15-16-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03411, current rewards: 232.23024, mean: 0.10508
[32m[0906 15-16-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03412, current rewards: 237.74633, mean: 0.10520
[32m[0906 15-16-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03413, current rewards: 243.25241, mean: 0.10530
[32m[0906 15-16-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03412, current rewards: 248.77087, mean: 0.10541
[32m[0906 15-16-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03411, current rewards: 253.22254, mean: 0.10507
[32m[0906 15-16-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03410, current rewards: 258.69874, mean: 0.10516
[32m[0906 15-16-55 @Agent.py:117][0m Average action selection time: 0.0341
[32m[0906 15-16-55 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-16-55 @MBExp.py:227][0m Rewards obtained: [263.0864564729078], Lows: [3], Highs: [4], Total time: 3827.710253
[32m[0906 15-18-27 @MBExp.py:144][0m ####################################################################
[32m[0906 15-18-27 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 15-18-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03498, current rewards: -1.06085, mean: -0.10609
[32m[0906 15-18-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03519, current rewards: 4.75354, mean: 0.07923
[32m[0906 15-18-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03522, current rewards: 10.28954, mean: 0.09354
[32m[0906 15-18-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03525, current rewards: 15.82588, mean: 0.09891
[32m[0906 15-18-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03520, current rewards: 21.36343, mean: 0.10173
[32m[0906 15-18-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03520, current rewards: 26.89876, mean: 0.10346
[32m[0906 15-18-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03508, current rewards: 32.43635, mean: 0.10463
[32m[0906 15-18-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03499, current rewards: 37.97313, mean: 0.10548
[32m[0906 15-18-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03493, current rewards: 43.50508, mean: 0.10611
[32m[0906 15-18-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03488, current rewards: 47.88950, mean: 0.10411
[32m[0906 15-18-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03483, current rewards: 53.39842, mean: 0.10470
[32m[0906 15-18-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03480, current rewards: 58.90850, mean: 0.10519
[32m[0906 15-18-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03478, current rewards: 64.41646, mean: 0.10560
[32m[0906 15-18-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03475, current rewards: 69.92581, mean: 0.10595
[32m[0906 15-18-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03465, current rewards: 75.42494, mean: 0.10623
[32m[0906 15-18-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03457, current rewards: 80.88465, mean: 0.10643
[32m[0906 15-18-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03451, current rewards: 86.38886, mean: 0.10665
[32m[0906 15-18-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03446, current rewards: 91.89134, mean: 0.10685
[32m[0906 15-18-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03441, current rewards: 97.39918, mean: 0.10703
[32m[0906 15-19-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03438, current rewards: 102.89297, mean: 0.10718
[32m[0906 15-19-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03434, current rewards: 108.40972, mean: 0.10734
[32m[0906 15-19-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03430, current rewards: 113.93155, mean: 0.10748
[32m[0906 15-19-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03428, current rewards: 119.45459, mean: 0.10762
[32m[0906 15-19-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03424, current rewards: 124.94316, mean: 0.10771
[32m[0906 15-19-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03421, current rewards: 130.46859, mean: 0.10783
[32m[0906 15-19-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03419, current rewards: 131.87412, mean: 0.10466
[32m[0906 15-19-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03416, current rewards: 137.43764, mean: 0.10491
[32m[0906 15-19-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03414, current rewards: 143.00771, mean: 0.10515
[32m[0906 15-19-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03413, current rewards: 148.57510, mean: 0.10537
[32m[0906 15-19-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03411, current rewards: 154.14336, mean: 0.10558
[32m[0906 15-19-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03410, current rewards: 159.71353, mean: 0.10577
[32m[0906 15-19-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03409, current rewards: 165.03729, mean: 0.10579
[32m[0906 15-19-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03408, current rewards: 170.57973, mean: 0.10595
[32m[0906 15-19-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03406, current rewards: 176.12297, mean: 0.10610
[32m[0906 15-19-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03404, current rewards: 181.66384, mean: 0.10624
[32m[0906 15-19-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03403, current rewards: 187.20518, mean: 0.10637
[32m[0906 15-19-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03402, current rewards: 192.74797, mean: 0.10649
[32m[0906 15-19-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03401, current rewards: 198.29072, mean: 0.10661
[32m[0906 15-19-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03400, current rewards: 202.66890, mean: 0.10611
[32m[0906 15-19-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03400, current rewards: 208.14941, mean: 0.10620
[32m[0906 15-19-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03401, current rewards: 213.64193, mean: 0.10629
[32m[0906 15-19-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03402, current rewards: 219.14159, mean: 0.10638
[32m[0906 15-19-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03403, current rewards: 224.63500, mean: 0.10646
[32m[0906 15-19-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03404, current rewards: 230.13622, mean: 0.10654
[32m[0906 15-19-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03405, current rewards: 235.63453, mean: 0.10662
[32m[0906 15-19-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03405, current rewards: 241.13291, mean: 0.10670
[32m[0906 15-19-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03404, current rewards: 246.63493, mean: 0.10677
[32m[0906 15-19-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03403, current rewards: 252.36187, mean: 0.10693
[32m[0906 15-19-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03403, current rewards: 257.88224, mean: 0.10701
[32m[0906 15-19-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03402, current rewards: 263.38566, mean: 0.10707
[32m[0906 15-19-52 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 15-19-52 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-19-53 @MBExp.py:227][0m Rewards obtained: [267.7907043909261], Lows: [2], Highs: [4], Total time: 3913.372135
[32m[0906 15-21-27 @MBExp.py:144][0m ####################################################################
[32m[0906 15-21-27 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 15-21-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03522, current rewards: -0.13273, mean: -0.01327
[32m[0906 15-21-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03516, current rewards: 5.31597, mean: 0.08860
[32m[0906 15-21-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03512, current rewards: 10.84170, mean: 0.09856
[32m[0906 15-21-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03516, current rewards: 16.36695, mean: 0.10229
[32m[0906 15-21-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03508, current rewards: 21.89346, mean: 0.10425
[32m[0906 15-21-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03496, current rewards: 27.41975, mean: 0.10546
[32m[0906 15-21-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03487, current rewards: 31.93521, mean: 0.10302
[32m[0906 15-21-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03484, current rewards: 37.62164, mean: 0.10450
[32m[0906 15-21-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03481, current rewards: 43.31117, mean: 0.10564
[32m[0906 15-21-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03479, current rewards: 48.99719, mean: 0.10652
[32m[0906 15-21-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03475, current rewards: 54.68277, mean: 0.10722
[32m[0906 15-21-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03472, current rewards: 60.37525, mean: 0.10781
[32m[0906 15-21-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03470, current rewards: 66.05770, mean: 0.10829
[32m[0906 15-21-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03461, current rewards: 71.73883, mean: 0.10870
[32m[0906 15-21-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03454, current rewards: 77.57855, mean: 0.10927
[32m[0906 15-21-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03446, current rewards: 80.97966, mean: 0.10655
[32m[0906 15-21-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03440, current rewards: 86.50256, mean: 0.10679
[32m[0906 15-21-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03435, current rewards: 92.02783, mean: 0.10701
[32m[0906 15-21-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03431, current rewards: 97.54356, mean: 0.10719
[32m[0906 15-22-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03427, current rewards: 103.06277, mean: 0.10736
[32m[0906 15-22-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03424, current rewards: 108.58538, mean: 0.10751
[32m[0906 15-22-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03422, current rewards: 114.10623, mean: 0.10765
[32m[0906 15-22-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03419, current rewards: 119.54604, mean: 0.10770
[32m[0906 15-22-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03416, current rewards: 125.09452, mean: 0.10784
[32m[0906 15-22-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03413, current rewards: 130.66708, mean: 0.10799
[32m[0906 15-22-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03411, current rewards: 136.23515, mean: 0.10812
[32m[0906 15-22-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03409, current rewards: 141.80525, mean: 0.10825
[32m[0906 15-22-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03407, current rewards: 146.23579, mean: 0.10753
[32m[0906 15-22-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03405, current rewards: 151.54230, mean: 0.10748
[32m[0906 15-22-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03403, current rewards: 156.84633, mean: 0.10743
[32m[0906 15-22-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03401, current rewards: 162.16661, mean: 0.10740
[32m[0906 15-22-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03399, current rewards: 167.44264, mean: 0.10734
[32m[0906 15-22-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03398, current rewards: 172.73252, mean: 0.10729
[32m[0906 15-22-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03397, current rewards: 178.02400, mean: 0.10724
[32m[0906 15-22-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03396, current rewards: 183.31754, mean: 0.10720
[32m[0906 15-22-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03395, current rewards: 188.60956, mean: 0.10716
[32m[0906 15-22-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03395, current rewards: 191.91747, mean: 0.10603
[32m[0906 15-22-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03395, current rewards: 197.40772, mean: 0.10613
[32m[0906 15-22-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03394, current rewards: 202.90078, mean: 0.10623
[32m[0906 15-22-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03394, current rewards: 208.35434, mean: 0.10630
[32m[0906 15-22-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03395, current rewards: 213.82782, mean: 0.10638
[32m[0906 15-22-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03396, current rewards: 219.29164, mean: 0.10645
[32m[0906 15-22-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03397, current rewards: 224.76870, mean: 0.10653
[32m[0906 15-22-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03399, current rewards: 230.24102, mean: 0.10659
[32m[0906 15-22-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03399, current rewards: 235.71415, mean: 0.10666
[32m[0906 15-22-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03399, current rewards: 241.18606, mean: 0.10672
[32m[0906 15-22-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03398, current rewards: 246.66140, mean: 0.10678
[32m[0906 15-22-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03398, current rewards: 252.39019, mean: 0.10694
[32m[0906 15-22-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03398, current rewards: 257.97783, mean: 0.10704
[32m[0906 15-22-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03397, current rewards: 263.56368, mean: 0.10714
[32m[0906 15-22-52 @Agent.py:117][0m Average action selection time: 0.0340
[32m[0906 15-22-52 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-22-52 @MBExp.py:227][0m Rewards obtained: [268.03218797736315], Lows: [2], Highs: [3], Total time: 3998.923836
[32m[0906 15-24-29 @MBExp.py:144][0m ####################################################################
[32m[0906 15-24-29 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 15-24-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03452, current rewards: -1.14270, mean: -0.11427
[32m[0906 15-24-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03507, current rewards: 4.30925, mean: 0.07182
[32m[0906 15-24-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03527, current rewards: 9.77248, mean: 0.08884
[32m[0906 15-24-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03516, current rewards: 15.24394, mean: 0.09527
[32m[0906 15-24-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03500, current rewards: 20.70229, mean: 0.09858
[32m[0906 15-24-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03489, current rewards: 26.03428, mean: 0.10013
[32m[0906 15-24-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03484, current rewards: 31.46925, mean: 0.10151
[32m[0906 15-24-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03478, current rewards: 34.85202, mean: 0.09681
[32m[0906 15-24-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03473, current rewards: 40.40546, mean: 0.09855
[32m[0906 15-24-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03470, current rewards: 45.96273, mean: 0.09992
[32m[0906 15-24-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03468, current rewards: 51.51500, mean: 0.10101
[32m[0906 15-24-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03466, current rewards: 57.06923, mean: 0.10191
[32m[0906 15-24-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03459, current rewards: 62.62156, mean: 0.10266
[32m[0906 15-24-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03453, current rewards: 68.21455, mean: 0.10336
[32m[0906 15-24-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03447, current rewards: 73.77713, mean: 0.10391
[32m[0906 15-24-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03441, current rewards: 79.38473, mean: 0.10445
[32m[0906 15-24-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03436, current rewards: 84.98723, mean: 0.10492
[32m[0906 15-24-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03432, current rewards: 90.59517, mean: 0.10534
[32m[0906 15-25-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03429, current rewards: 96.19511, mean: 0.10571
[32m[0906 15-25-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03425, current rewards: 101.79610, mean: 0.10604
[32m[0906 15-25-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03422, current rewards: 107.40180, mean: 0.10634
[32m[0906 15-25-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03420, current rewards: 113.00348, mean: 0.10661
[32m[0906 15-25-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03417, current rewards: 118.62181, mean: 0.10687
[32m[0906 15-25-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03413, current rewards: 124.22185, mean: 0.10709
[32m[0906 15-25-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03410, current rewards: 129.82407, mean: 0.10729
[32m[0906 15-25-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03408, current rewards: 133.30470, mean: 0.10580
[32m[0906 15-25-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03407, current rewards: 138.68157, mean: 0.10586
[32m[0906 15-25-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03405, current rewards: 144.01793, mean: 0.10590
[32m[0906 15-25-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03404, current rewards: 149.35158, mean: 0.10592
[32m[0906 15-25-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03402, current rewards: 154.68909, mean: 0.10595
[32m[0906 15-25-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03401, current rewards: 160.02690, mean: 0.10598
[32m[0906 15-25-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03400, current rewards: 165.36472, mean: 0.10600
[32m[0906 15-25-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03399, current rewards: 170.70029, mean: 0.10603
[32m[0906 15-25-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03397, current rewards: 176.03521, mean: 0.10605
[32m[0906 15-25-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03396, current rewards: 181.37190, mean: 0.10607
[32m[0906 15-25-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03395, current rewards: 186.70677, mean: 0.10608
[32m[0906 15-25-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03394, current rewards: 192.04303, mean: 0.10610
[32m[0906 15-25-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03393, current rewards: 196.24523, mean: 0.10551
[32m[0906 15-25-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03392, current rewards: 201.85090, mean: 0.10568
[32m[0906 15-25-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03393, current rewards: 207.44986, mean: 0.10584
[32m[0906 15-25-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03395, current rewards: 213.04813, mean: 0.10599
[32m[0906 15-25-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03396, current rewards: 218.65337, mean: 0.10614
[32m[0906 15-25-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03398, current rewards: 224.24808, mean: 0.10628
[32m[0906 15-25-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03398, current rewards: 229.83984, mean: 0.10641
[32m[0906 15-25-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03398, current rewards: 235.43680, mean: 0.10653
[32m[0906 15-25-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03397, current rewards: 238.71624, mean: 0.10563
[32m[0906 15-25-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03396, current rewards: 243.83589, mean: 0.10556
[32m[0906 15-25-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03396, current rewards: 249.25954, mean: 0.10562
[32m[0906 15-25-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03395, current rewards: 254.69139, mean: 0.10568
[32m[0906 15-25-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03395, current rewards: 260.11604, mean: 0.10574
[32m[0906 15-25-54 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 15-25-54 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-25-54 @MBExp.py:227][0m Rewards obtained: [264.46429672981947], Lows: [3], Highs: [3], Total time: 4084.442884
[32m[0906 15-27-33 @MBExp.py:144][0m ####################################################################
[32m[0906 15-27-33 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 15-27-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03478, current rewards: 1.07440, mean: 0.10744
[32m[0906 15-27-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03536, current rewards: 6.64055, mean: 0.11068
[32m[0906 15-27-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03523, current rewards: 12.20733, mean: 0.11098
[32m[0906 15-27-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03497, current rewards: 17.77153, mean: 0.11107
[32m[0906 15-27-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03486, current rewards: 23.27601, mean: 0.11084
[32m[0906 15-27-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03479, current rewards: 28.82758, mean: 0.11088
[32m[0906 15-27-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03477, current rewards: 33.05556, mean: 0.10663
[32m[0906 15-27-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03473, current rewards: 38.43223, mean: 0.10676
[32m[0906 15-27-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03471, current rewards: 43.80252, mean: 0.10684
[32m[0906 15-27-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03469, current rewards: 49.17291, mean: 0.10690
[32m[0906 15-27-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03463, current rewards: 54.54383, mean: 0.10695
[32m[0906 15-27-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03456, current rewards: 59.91347, mean: 0.10699
[32m[0906 15-27-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03450, current rewards: 64.22128, mean: 0.10528
[32m[0906 15-27-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03445, current rewards: 69.73310, mean: 0.10566
[32m[0906 15-27-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03438, current rewards: 75.23953, mean: 0.10597
[32m[0906 15-27-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03436, current rewards: 80.74607, mean: 0.10624
[32m[0906 15-28-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03431, current rewards: 86.25033, mean: 0.10648
[32m[0906 15-28-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03427, current rewards: 91.75494, mean: 0.10669
[32m[0906 15-28-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03422, current rewards: 97.26369, mean: 0.10688
[32m[0906 15-28-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03421, current rewards: 101.62694, mean: 0.10586
[32m[0906 15-28-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03417, current rewards: 107.17768, mean: 0.10612
[32m[0906 15-28-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03414, current rewards: 112.74069, mean: 0.10636
[32m[0906 15-28-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03412, current rewards: 118.20975, mean: 0.10650
[32m[0906 15-28-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03412, current rewards: 123.68471, mean: 0.10662
[32m[0906 15-28-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03411, current rewards: 129.15612, mean: 0.10674
[32m[0906 15-28-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03409, current rewards: 134.62787, mean: 0.10685
[32m[0906 15-28-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03407, current rewards: 140.10606, mean: 0.10695
[32m[0906 15-28-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03405, current rewards: 145.58175, mean: 0.10705
[32m[0906 15-28-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03404, current rewards: 148.92516, mean: 0.10562
[32m[0906 15-28-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03402, current rewards: 154.40834, mean: 0.10576
[32m[0906 15-28-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03401, current rewards: 159.91818, mean: 0.10591
[32m[0906 15-28-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03400, current rewards: 165.42670, mean: 0.10604
[32m[0906 15-28-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03399, current rewards: 170.93475, mean: 0.10617
[32m[0906 15-28-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03398, current rewards: 176.44575, mean: 0.10629
[32m[0906 15-28-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03397, current rewards: 180.84144, mean: 0.10576
[32m[0906 15-28-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03396, current rewards: 186.35743, mean: 0.10588
[32m[0906 15-28-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03395, current rewards: 191.86928, mean: 0.10601
[32m[0906 15-28-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03395, current rewards: 197.20318, mean: 0.10602
[32m[0906 15-28-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03394, current rewards: 202.70818, mean: 0.10613
[32m[0906 15-28-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03395, current rewards: 208.21270, mean: 0.10623
[32m[0906 15-28-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03397, current rewards: 213.71378, mean: 0.10633
[32m[0906 15-28-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03398, current rewards: 219.21238, mean: 0.10641
[32m[0906 15-28-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03398, current rewards: 224.71127, mean: 0.10650
[32m[0906 15-28-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03397, current rewards: 230.20772, mean: 0.10658
[32m[0906 15-28-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03396, current rewards: 235.70874, mean: 0.10666
[32m[0906 15-28-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03396, current rewards: 241.20657, mean: 0.10673
[32m[0906 15-28-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03395, current rewards: 246.66555, mean: 0.10678
[32m[0906 15-28-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03394, current rewards: 252.12982, mean: 0.10683
[32m[0906 15-28-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03394, current rewards: 257.58758, mean: 0.10688
[32m[0906 15-28-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03394, current rewards: 263.04345, mean: 0.10693
[32m[0906 15-28-58 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 15-28-58 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-28-58 @MBExp.py:227][0m Rewards obtained: [267.40535892513805], Lows: [1], Highs: [4], Total time: 4169.926814
[32m[0906 15-30-39 @MBExp.py:144][0m ####################################################################
[32m[0906 15-30-39 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 15-30-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03453, current rewards: -1.07727, mean: -0.10773
[32m[0906 15-30-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03519, current rewards: 4.36687, mean: 0.07278
[32m[0906 15-30-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03478, current rewards: 9.82200, mean: 0.08929
[32m[0906 15-30-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03471, current rewards: 15.26925, mean: 0.09543
[32m[0906 15-30-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03466, current rewards: 20.71462, mean: 0.09864
[32m[0906 15-30-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03462, current rewards: 26.16484, mean: 0.10063
[32m[0906 15-30-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03461, current rewards: 31.62107, mean: 0.10200
[32m[0906 15-30-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03459, current rewards: 37.06778, mean: 0.10297
[32m[0906 15-30-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03459, current rewards: 42.52118, mean: 0.10371
[32m[0906 15-30-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03455, current rewards: 46.08529, mean: 0.10019
[32m[0906 15-30-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03446, current rewards: 51.59114, mean: 0.10116
[32m[0906 15-30-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03439, current rewards: 57.09973, mean: 0.10196
[32m[0906 15-31-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03433, current rewards: 62.39632, mean: 0.10229
[32m[0906 15-31-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03426, current rewards: 67.85985, mean: 0.10282
[32m[0906 15-31-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03422, current rewards: 73.31856, mean: 0.10327
[32m[0906 15-31-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03419, current rewards: 78.77680, mean: 0.10365
[32m[0906 15-31-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03416, current rewards: 84.23799, mean: 0.10400
[32m[0906 15-31-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03413, current rewards: 89.69961, mean: 0.10430
[32m[0906 15-31-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03410, current rewards: 95.15939, mean: 0.10457
[32m[0906 15-31-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03408, current rewards: 100.62087, mean: 0.10481
[32m[0906 15-31-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03406, current rewards: 106.20000, mean: 0.10515
[32m[0906 15-31-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03404, current rewards: 111.67863, mean: 0.10536
[32m[0906 15-31-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03402, current rewards: 116.10040, mean: 0.10459
[32m[0906 15-31-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03401, current rewards: 121.61206, mean: 0.10484
[32m[0906 15-31-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03400, current rewards: 127.12995, mean: 0.10507
[32m[0906 15-31-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03398, current rewards: 132.64932, mean: 0.10528
[32m[0906 15-31-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03397, current rewards: 138.16053, mean: 0.10547
[32m[0906 15-31-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03395, current rewards: 143.67744, mean: 0.10565
[32m[0906 15-31-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03395, current rewards: 149.27135, mean: 0.10587
[32m[0906 15-31-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03394, current rewards: 154.79312, mean: 0.10602
[32m[0906 15-31-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03394, current rewards: 160.29929, mean: 0.10616
[32m[0906 15-31-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03392, current rewards: 165.80052, mean: 0.10628
[32m[0906 15-31-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03392, current rewards: 171.30940, mean: 0.10640
[32m[0906 15-31-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03391, current rewards: 176.81885, mean: 0.10652
[32m[0906 15-31-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03391, current rewards: 182.33106, mean: 0.10663
[32m[0906 15-31-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03390, current rewards: 187.81802, mean: 0.10671
[32m[0906 15-31-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03389, current rewards: 193.28949, mean: 0.10679
[32m[0906 15-31-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03388, current rewards: 198.80128, mean: 0.10688
[32m[0906 15-31-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03388, current rewards: 204.31475, mean: 0.10697
[32m[0906 15-31-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03388, current rewards: 209.83303, mean: 0.10706
[32m[0906 15-31-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03390, current rewards: 215.35117, mean: 0.10714
[32m[0906 15-31-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03389, current rewards: 220.86585, mean: 0.10722
[32m[0906 15-31-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03389, current rewards: 226.38324, mean: 0.10729
[32m[0906 15-31-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03389, current rewards: 231.89827, mean: 0.10736
[32m[0906 15-31-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03389, current rewards: 233.40382, mean: 0.10561
[32m[0906 15-31-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03388, current rewards: 240.62147, mean: 0.10647
[32m[0906 15-31-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03388, current rewards: 248.08166, mean: 0.10739
[32m[0906 15-31-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03388, current rewards: 255.54185, mean: 0.10828
[32m[0906 15-32-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03387, current rewards: 263.00204, mean: 0.10913
[32m[0906 15-32-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03386, current rewards: 270.46223, mean: 0.10994
[32m[0906 15-32-04 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 15-32-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-32-04 @MBExp.py:227][0m Rewards obtained: [251.14790262887055], Lows: [3], Highs: [25], Total time: 4255.2151730000005
[32m[0906 15-33-47 @MBExp.py:144][0m ####################################################################
[32m[0906 15-33-47 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 15-33-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03536, current rewards: 0.21447, mean: 0.02145
[32m[0906 15-33-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03495, current rewards: 5.93023, mean: 0.09884
[32m[0906 15-33-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03468, current rewards: 11.48876, mean: 0.10444
[32m[0906 15-33-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03460, current rewards: 17.10022, mean: 0.10688
[32m[0906 15-33-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03462, current rewards: 20.75265, mean: 0.09882
[32m[0906 15-33-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03460, current rewards: 29.80608, mean: 0.11464
[32m[0906 15-33-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03460, current rewards: 38.85952, mean: 0.12535
[32m[0906 15-33-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03458, current rewards: 47.91295, mean: 0.13309
[32m[0906 15-34-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03456, current rewards: 56.96638, mean: 0.13894
[32m[0906 15-34-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03442, current rewards: 66.01981, mean: 0.14352
[32m[0906 15-34-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03436, current rewards: 75.07325, mean: 0.14720
[32m[0906 15-34-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03428, current rewards: 83.99560, mean: 0.14999
[32m[0906 15-34-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03422, current rewards: 86.31086, mean: 0.14149
[32m[0906 15-34-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03416, current rewards: 36.31086, mean: 0.05502
[32m[0906 15-34-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03413, current rewards: -13.68914, mean: -0.01928
[32m[0906 15-34-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03409, current rewards: -63.68914, mean: -0.08380
[32m[0906 15-34-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03405, current rewards: -113.68914, mean: -0.14036
[32m[0906 15-34-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03403, current rewards: -163.68914, mean: -0.19034
[32m[0906 15-34-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03401, current rewards: -213.68914, mean: -0.23482
[32m[0906 15-34-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03399, current rewards: -263.68914, mean: -0.27468
[32m[0906 15-34-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03397, current rewards: -313.68914, mean: -0.31058
[32m[0906 15-34-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03395, current rewards: -363.68914, mean: -0.34310
[32m[0906 15-34-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03394, current rewards: -413.68914, mean: -0.37269
[32m[0906 15-34-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03393, current rewards: -463.68914, mean: -0.39973
[32m[0906 15-34-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03392, current rewards: -513.68914, mean: -0.42454
[32m[0906 15-34-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03390, current rewards: -563.68914, mean: -0.44737
[32m[0906 15-34-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03389, current rewards: -613.68914, mean: -0.46846
[32m[0906 15-34-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03388, current rewards: -663.68914, mean: -0.48801
[32m[0906 15-34-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03387, current rewards: -713.68914, mean: -0.50616
[32m[0906 15-34-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03386, current rewards: -763.68914, mean: -0.52307
[32m[0906 15-34-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03386, current rewards: -813.68914, mean: -0.53887
[32m[0906 15-34-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03385, current rewards: -863.68914, mean: -0.55365
[32m[0906 15-34-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03384, current rewards: -913.68914, mean: -0.56751
[32m[0906 15-34-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03384, current rewards: -963.68914, mean: -0.58054
[32m[0906 15-34-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03384, current rewards: -1013.68914, mean: -0.59280
[32m[0906 15-34-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03384, current rewards: -1063.68914, mean: -0.60437
[32m[0906 15-34-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03384, current rewards: -1113.68914, mean: -0.61530
[32m[0906 15-34-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03383, current rewards: -1163.68914, mean: -0.62564
[32m[0906 15-34-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03383, current rewards: -1213.68914, mean: -0.63544
[32m[0906 15-34-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03383, current rewards: -1263.68914, mean: -0.64474
[32m[0906 15-34-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03383, current rewards: -1313.68914, mean: -0.65358
[32m[0906 15-34-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03383, current rewards: -1363.68914, mean: -0.66199
[32m[0906 15-34-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03383, current rewards: -1413.68914, mean: -0.66999
[32m[0906 15-35-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03383, current rewards: -1463.68914, mean: -0.67763
[32m[0906 15-35-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03383, current rewards: -1513.68914, mean: -0.68493
[32m[0906 15-35-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03382, current rewards: -1563.68914, mean: -0.69190
[32m[0906 15-35-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03382, current rewards: -1613.68914, mean: -0.69857
[32m[0906 15-35-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03382, current rewards: -1663.68914, mean: -0.70495
[32m[0906 15-35-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03382, current rewards: -1713.68914, mean: -0.71107
[32m[0906 15-35-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03382, current rewards: -1763.68914, mean: -0.71695
[32m[0906 15-35-12 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 15-35-12 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-35-12 @MBExp.py:227][0m Rewards obtained: [-1803.6891394450563], Lows: [2], Highs: [1892], Total time: 4340.419885
[32m[0906 15-36-56 @MBExp.py:144][0m ####################################################################
[32m[0906 15-36-56 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 15-36-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03247, current rewards: -0.01999, mean: -0.00200
[32m[0906 15-36-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03416, current rewards: 5.56429, mean: 0.09274
[32m[0906 15-37-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03426, current rewards: 11.15468, mean: 0.10141
[32m[0906 15-37-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03437, current rewards: 16.94564, mean: 0.10591
[32m[0906 15-37-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03443, current rewards: 22.54272, mean: 0.10735
[32m[0906 15-37-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03446, current rewards: 28.13743, mean: 0.10822
[32m[0906 15-37-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03443, current rewards: 33.73107, mean: 0.10881
[32m[0906 15-37-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03445, current rewards: 39.32747, mean: 0.10924
[32m[0906 15-37-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03433, current rewards: 44.92546, mean: 0.10957
[32m[0906 15-37-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03427, current rewards: 50.51906, mean: 0.10982
[32m[0906 15-37-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03421, current rewards: 54.15571, mean: 0.10619
[32m[0906 15-37-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03416, current rewards: 59.84932, mean: 0.10687
[32m[0906 15-37-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03413, current rewards: 67.91132, mean: 0.11133
[32m[0906 15-37-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03411, current rewards: 75.98561, mean: 0.11513
[32m[0906 15-37-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03408, current rewards: 84.05990, mean: 0.11839
[32m[0906 15-37-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03404, current rewards: 44.51327, mean: 0.05857
[32m[0906 15-37-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03401, current rewards: -5.48673, mean: -0.00677
[32m[0906 15-37-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03400, current rewards: -55.48673, mean: -0.06452
[32m[0906 15-37-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03397, current rewards: -105.48673, mean: -0.11592
[32m[0906 15-37-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03396, current rewards: -155.48673, mean: -0.16197
[32m[0906 15-37-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03396, current rewards: -205.48673, mean: -0.20345
[32m[0906 15-37-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03395, current rewards: -255.48673, mean: -0.24103
[32m[0906 15-37-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03394, current rewards: -305.48673, mean: -0.27521
[32m[0906 15-37-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03393, current rewards: -355.48673, mean: -0.30645
[32m[0906 15-37-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03392, current rewards: -405.48673, mean: -0.33511
[32m[0906 15-37-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03391, current rewards: -455.48673, mean: -0.36150
[32m[0906 15-37-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03390, current rewards: -505.48673, mean: -0.38587
[32m[0906 15-37-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03389, current rewards: -555.48673, mean: -0.40845
[32m[0906 15-37-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03389, current rewards: -605.48673, mean: -0.42942
[32m[0906 15-37-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03388, current rewards: -655.48673, mean: -0.44896
[32m[0906 15-37-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03387, current rewards: -705.48673, mean: -0.46721
[32m[0906 15-37-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03387, current rewards: -755.48673, mean: -0.48429
[32m[0906 15-37-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03386, current rewards: -805.48673, mean: -0.50030
[32m[0906 15-37-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03385, current rewards: -855.48673, mean: -0.51535
[32m[0906 15-37-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03385, current rewards: -905.48673, mean: -0.52952
[32m[0906 15-37-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03384, current rewards: -955.48673, mean: -0.54289
[32m[0906 15-37-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03383, current rewards: -1005.48673, mean: -0.55552
[32m[0906 15-38-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03383, current rewards: -1055.48673, mean: -0.56747
[32m[0906 15-38-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03382, current rewards: -1105.48673, mean: -0.57879
[32m[0906 15-38-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03380, current rewards: -1155.48673, mean: -0.58953
[32m[0906 15-38-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03379, current rewards: -1205.48673, mean: -0.59974
[32m[0906 15-38-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03380, current rewards: -1255.48673, mean: -0.60946
[32m[0906 15-38-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03380, current rewards: -1305.48673, mean: -0.61871
[32m[0906 15-38-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03380, current rewards: -1355.48673, mean: -0.62754
[32m[0906 15-38-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03380, current rewards: -1405.48673, mean: -0.63597
[32m[0906 15-38-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03379, current rewards: -1455.48673, mean: -0.64402
[32m[0906 15-38-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03379, current rewards: -1505.48673, mean: -0.65173
[32m[0906 15-38-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03379, current rewards: -1555.48673, mean: -0.65910
[32m[0906 15-38-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03379, current rewards: -1605.48673, mean: -0.66618
[32m[0906 15-38-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03379, current rewards: -1655.48673, mean: -0.67296
[32m[0906 15-38-21 @Agent.py:117][0m Average action selection time: 0.0338
[32m[0906 15-38-21 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-38-21 @MBExp.py:227][0m Rewards obtained: [-1695.486732671413], Lows: [1], Highs: [1782], Total time: 4425.523762
[32m[0906 15-40-08 @MBExp.py:144][0m ####################################################################
[32m[0906 15-40-08 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 15-40-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03382, current rewards: 0.25394, mean: 0.02539
[32m[0906 15-40-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03429, current rewards: 5.75301, mean: 0.09588
[32m[0906 15-40-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03448, current rewards: 11.25096, mean: 0.10228
[32m[0906 15-40-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03446, current rewards: 16.69819, mean: 0.10436
[32m[0906 15-40-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03447, current rewards: 22.19654, mean: 0.10570
[32m[0906 15-40-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03446, current rewards: 27.69435, mean: 0.10652
[32m[0906 15-40-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03445, current rewards: 33.19163, mean: 0.10707
[32m[0906 15-40-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03435, current rewards: 38.68624, mean: 0.10746
[32m[0906 15-40-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03424, current rewards: 44.18182, mean: 0.10776
[32m[0906 15-40-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03418, current rewards: 48.55288, mean: 0.10555
[32m[0906 15-40-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03411, current rewards: 54.11211, mean: 0.10610
[32m[0906 15-40-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03407, current rewards: 59.49250, mean: 0.10624
[32m[0906 15-40-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03402, current rewards: 65.04323, mean: 0.10663
[32m[0906 15-40-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03400, current rewards: 70.59353, mean: 0.10696
[32m[0906 15-40-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03398, current rewards: 76.13877, mean: 0.10724
[32m[0906 15-40-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03396, current rewards: 81.68604, mean: 0.10748
[32m[0906 15-40-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03394, current rewards: 87.22911, mean: 0.10769
[32m[0906 15-40-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03391, current rewards: 92.77998, mean: 0.10788
[32m[0906 15-40-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03391, current rewards: 98.32733, mean: 0.10805
[32m[0906 15-40-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03389, current rewards: 101.68695, mean: 0.10592
[32m[0906 15-40-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03388, current rewards: 107.24083, mean: 0.10618
[32m[0906 15-40-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03386, current rewards: 112.79479, mean: 0.10641
[32m[0906 15-40-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03385, current rewards: 118.35090, mean: 0.10662
[32m[0906 15-40-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03384, current rewards: 123.91117, mean: 0.10682
[32m[0906 15-40-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03384, current rewards: 129.47343, mean: 0.10700
[32m[0906 15-40-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03383, current rewards: 135.02915, mean: 0.10717
[32m[0906 15-40-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03382, current rewards: 140.58317, mean: 0.10732
[32m[0906 15-40-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03381, current rewards: 146.14414, mean: 0.10746
[32m[0906 15-40-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03382, current rewards: 151.70667, mean: 0.10759
[32m[0906 15-40-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03382, current rewards: 157.26417, mean: 0.10772
[32m[0906 15-41-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03382, current rewards: 162.81960, mean: 0.10783
[32m[0906 15-41-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03382, current rewards: 168.37067, mean: 0.10793
[32m[0906 15-41-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03380, current rewards: 173.92931, mean: 0.10803
[32m[0906 15-41-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03380, current rewards: 179.48423, mean: 0.10812
[32m[0906 15-41-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03379, current rewards: 185.03738, mean: 0.10821
[32m[0906 15-41-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03379, current rewards: 190.61131, mean: 0.10830
[32m[0906 15-41-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03379, current rewards: 196.16866, mean: 0.10838
[32m[0906 15-41-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03378, current rewards: 200.63418, mean: 0.10787
[32m[0906 15-41-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03375, current rewards: 206.19260, mean: 0.10795
[32m[0906 15-41-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03373, current rewards: 211.75078, mean: 0.10804
[32m[0906 15-41-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03373, current rewards: 217.30679, mean: 0.10811
[32m[0906 15-41-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03373, current rewards: 222.86078, mean: 0.10818
[32m[0906 15-41-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03373, current rewards: 228.41982, mean: 0.10826
[32m[0906 15-41-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03373, current rewards: 233.97460, mean: 0.10832
[32m[0906 15-41-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03373, current rewards: 239.63663, mean: 0.10843
[32m[0906 15-41-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03373, current rewards: 245.19822, mean: 0.10849
[32m[0906 15-41-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03373, current rewards: 250.75396, mean: 0.10855
[32m[0906 15-41-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03373, current rewards: 256.31687, mean: 0.10861
[32m[0906 15-41-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03373, current rewards: 261.80542, mean: 0.10863
[32m[0906 15-41-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03373, current rewards: 267.22458, mean: 0.10863
[32m[0906 15-41-33 @Agent.py:117][0m Average action selection time: 0.0337
[32m[0906 15-41-33 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-41-33 @MBExp.py:227][0m Rewards obtained: [271.5560422181282], Lows: [1], Highs: [3], Total time: 4510.480691
[32m[0906 15-43-22 @MBExp.py:144][0m ####################################################################
[32m[0906 15-43-22 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 15-43-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03356, current rewards: -0.03854, mean: -0.00385
[32m[0906 15-43-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03422, current rewards: 5.37636, mean: 0.08961
[32m[0906 15-43-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03433, current rewards: 10.99935, mean: 0.09999
[32m[0906 15-43-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03441, current rewards: 16.54229, mean: 0.10339
[32m[0906 15-43-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03442, current rewards: 22.08542, mean: 0.10517
[32m[0906 15-43-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03438, current rewards: 27.62873, mean: 0.10626
[32m[0906 15-43-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03430, current rewards: 32.13168, mean: 0.10365
[32m[0906 15-43-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03422, current rewards: 37.82804, mean: 0.10508
[32m[0906 15-43-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03413, current rewards: 43.52761, mean: 0.10616
[32m[0906 15-43-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03408, current rewards: 47.30238, mean: 0.10283
[32m[0906 15-43-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03405, current rewards: 52.73741, mean: 0.10341
[32m[0906 15-43-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03400, current rewards: 58.34354, mean: 0.10418
[32m[0906 15-43-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03396, current rewards: 63.98730, mean: 0.10490
[32m[0906 15-43-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03393, current rewards: 69.63039, mean: 0.10550
[32m[0906 15-43-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03391, current rewards: 75.34622, mean: 0.10612
[32m[0906 15-43-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03389, current rewards: 81.05108, mean: 0.10665
[32m[0906 15-43-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03388, current rewards: 86.76138, mean: 0.10711
[32m[0906 15-43-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03387, current rewards: 92.46857, mean: 0.10752
[32m[0906 15-43-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03387, current rewards: 98.17418, mean: 0.10788
[32m[0906 15-43-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03385, current rewards: 103.87965, mean: 0.10821
[32m[0906 15-43-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03385, current rewards: 107.48536, mean: 0.10642
[32m[0906 15-43-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03384, current rewards: 113.03144, mean: 0.10663
[32m[0906 15-44-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03383, current rewards: 118.57352, mean: 0.10682
[32m[0906 15-44-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03382, current rewards: 124.11634, mean: 0.10700
[32m[0906 15-44-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03381, current rewards: 129.65983, mean: 0.10716
[32m[0906 15-44-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03380, current rewards: 135.20177, mean: 0.10730
[32m[0906 15-44-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03379, current rewards: 140.74463, mean: 0.10744
[32m[0906 15-44-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03379, current rewards: 145.29624, mean: 0.10684
[32m[0906 15-44-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03378, current rewards: 150.78290, mean: 0.10694
[32m[0906 15-44-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03377, current rewards: 156.28166, mean: 0.10704
[32m[0906 15-44-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03376, current rewards: 161.77577, mean: 0.10714
[32m[0906 15-44-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03376, current rewards: 167.27508, mean: 0.10723
[32m[0906 15-44-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03375, current rewards: 172.77405, mean: 0.10731
[32m[0906 15-44-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03375, current rewards: 178.27027, mean: 0.10739
[32m[0906 15-44-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03374, current rewards: 183.76662, mean: 0.10747
[32m[0906 15-44-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03373, current rewards: 189.36869, mean: 0.10760
[32m[0906 15-44-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03373, current rewards: 194.87784, mean: 0.10767
[32m[0906 15-44-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03369, current rewards: 198.47675, mean: 0.10671
[32m[0906 15-44-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03367, current rewards: 203.94615, mean: 0.10678
[32m[0906 15-44-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03366, current rewards: 209.41812, mean: 0.10685
[32m[0906 15-44-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03365, current rewards: 213.78610, mean: 0.10636
[32m[0906 15-44-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03366, current rewards: 219.48158, mean: 0.10654
[32m[0906 15-44-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03366, current rewards: 225.17965, mean: 0.10672
[32m[0906 15-44-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03366, current rewards: 230.75303, mean: 0.10683
[32m[0906 15-44-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03366, current rewards: 236.42977, mean: 0.10698
[32m[0906 15-44-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03366, current rewards: 242.10694, mean: 0.10713
[32m[0906 15-44-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03366, current rewards: 247.78887, mean: 0.10727
[32m[0906 15-44-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03366, current rewards: 253.46454, mean: 0.10740
[32m[0906 15-44-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03366, current rewards: 256.94587, mean: 0.10662
[32m[0906 15-44-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03366, current rewards: 262.43884, mean: 0.10668
[32m[0906 15-44-47 @Agent.py:117][0m Average action selection time: 0.0337
[32m[0906 15-44-47 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-44-47 @MBExp.py:227][0m Rewards obtained: [266.8310638050722], Lows: [4], Highs: [4], Total time: 4595.297248
[32m[0906 15-46-37 @MBExp.py:144][0m ####################################################################
[32m[0906 15-46-37 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 15-46-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03381, current rewards: -0.12530, mean: -0.01253
[32m[0906 15-46-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03439, current rewards: 5.16122, mean: 0.08602
[32m[0906 15-46-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03449, current rewards: 10.77500, mean: 0.09795
[32m[0906 15-46-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03453, current rewards: 16.16507, mean: 0.10103
[32m[0906 15-46-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03452, current rewards: 21.55729, mean: 0.10265
[32m[0906 15-46-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03451, current rewards: 26.94723, mean: 0.10364
[32m[0906 15-46-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03432, current rewards: 32.34054, mean: 0.10432
[32m[0906 15-46-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03421, current rewards: 37.73314, mean: 0.10481
[32m[0906 15-46-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03413, current rewards: 40.34662, mean: 0.09841
[32m[0906 15-46-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03412, current rewards: 47.62083, mean: 0.10352
[32m[0906 15-46-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03406, current rewards: 54.66583, mean: 0.10719
[32m[0906 15-46-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03404, current rewards: 58.08724, mean: 0.10373
[32m[0906 15-46-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03400, current rewards: 63.68435, mean: 0.10440
[32m[0906 15-47-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03398, current rewards: 66.97927, mean: 0.10148
[32m[0906 15-47-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03396, current rewards: 72.41286, mean: 0.10199
[32m[0906 15-47-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03395, current rewards: 77.84037, mean: 0.10242
[32m[0906 15-47-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03392, current rewards: 83.26795, mean: 0.10280
[32m[0906 15-47-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03391, current rewards: 88.69490, mean: 0.10313
[32m[0906 15-47-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03389, current rewards: 94.11783, mean: 0.10343
[32m[0906 15-47-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03388, current rewards: 99.48732, mean: 0.10363
[32m[0906 15-47-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03388, current rewards: 104.92555, mean: 0.10389
[32m[0906 15-47-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03387, current rewards: 110.36795, mean: 0.10412
[32m[0906 15-47-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03387, current rewards: 115.80831, mean: 0.10433
[32m[0906 15-47-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03386, current rewards: 121.24792, mean: 0.10452
[32m[0906 15-47-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03384, current rewards: 126.68261, mean: 0.10470
[32m[0906 15-47-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03384, current rewards: 132.11982, mean: 0.10486
[32m[0906 15-47-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03383, current rewards: 137.49770, mean: 0.10496
[32m[0906 15-47-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03383, current rewards: 143.14261, mean: 0.10525
[32m[0906 15-47-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03382, current rewards: 148.73999, mean: 0.10549
[32m[0906 15-47-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03382, current rewards: 154.33773, mean: 0.10571
[32m[0906 15-47-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03383, current rewards: 159.93663, mean: 0.10592
[32m[0906 15-47-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03382, current rewards: 165.53354, mean: 0.10611
[32m[0906 15-47-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03381, current rewards: 171.13441, mean: 0.10629
[32m[0906 15-47-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03382, current rewards: 174.52431, mean: 0.10514
[32m[0906 15-47-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03382, current rewards: 179.92590, mean: 0.10522
[32m[0906 15-47-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03382, current rewards: 185.23288, mean: 0.10525
[32m[0906 15-47-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03378, current rewards: 190.55408, mean: 0.10528
[32m[0906 15-47-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03375, current rewards: 194.06554, mean: 0.10434
[32m[0906 15-47-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03372, current rewards: 199.68830, mean: 0.10455
[32m[0906 15-47-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03371, current rewards: 205.30977, mean: 0.10475
[32m[0906 15-47-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03371, current rewards: 210.92813, mean: 0.10494
[32m[0906 15-47-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03371, current rewards: 216.54898, mean: 0.10512
[32m[0906 15-47-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03371, current rewards: 222.16597, mean: 0.10529
[32m[0906 15-47-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03372, current rewards: 227.78183, mean: 0.10545
[32m[0906 15-47-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03372, current rewards: 233.31615, mean: 0.10557
[32m[0906 15-47-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03372, current rewards: 237.59837, mean: 0.10513
[32m[0906 15-47-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03371, current rewards: 242.93688, mean: 0.10517
[32m[0906 15-47-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03372, current rewards: 248.27738, mean: 0.10520
[32m[0906 15-47-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03371, current rewards: 253.61998, mean: 0.10524
[32m[0906 15-48-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03371, current rewards: 258.96471, mean: 0.10527
[32m[0906 15-48-02 @Agent.py:117][0m Average action selection time: 0.0337
[32m[0906 15-48-02 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-48-02 @MBExp.py:227][0m Rewards obtained: [263.23554799243817], Lows: [4], Highs: [4], Total time: 4680.239676
[32m[0906 15-49-55 @MBExp.py:144][0m ####################################################################
[32m[0906 15-49-55 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 15-49-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03325, current rewards: -1.04243, mean: -0.10424
[32m[0906 15-49-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03414, current rewards: 4.66777, mean: 0.07780
[32m[0906 15-49-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03436, current rewards: 10.17119, mean: 0.09247
[32m[0906 15-50-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03438, current rewards: 15.58043, mean: 0.09738
[32m[0906 15-50-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03439, current rewards: 21.09571, mean: 0.10046
[32m[0906 15-50-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03422, current rewards: 26.61506, mean: 0.10237
[32m[0906 15-50-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03414, current rewards: 32.13230, mean: 0.10365
[32m[0906 15-50-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03408, current rewards: 37.62429, mean: 0.10451
[32m[0906 15-50-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03403, current rewards: 43.09778, mean: 0.10512
[32m[0906 15-50-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03396, current rewards: 48.56863, mean: 0.10558
[32m[0906 15-50-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03394, current rewards: 54.04046, mean: 0.10596
[32m[0906 15-50-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03389, current rewards: 59.48956, mean: 0.10623
[32m[0906 15-50-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03386, current rewards: 62.86807, mean: 0.10306
[32m[0906 15-50-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03382, current rewards: 68.40012, mean: 0.10364
[32m[0906 15-50-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03380, current rewards: 73.93175, mean: 0.10413
[32m[0906 15-50-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03379, current rewards: 79.46530, mean: 0.10456
[32m[0906 15-50-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03379, current rewards: 84.99976, mean: 0.10494
[32m[0906 15-50-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03378, current rewards: 90.53633, mean: 0.10527
[32m[0906 15-50-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03377, current rewards: 96.07020, mean: 0.10557
[32m[0906 15-50-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03376, current rewards: 102.03277, mean: 0.10628
[32m[0906 15-50-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03374, current rewards: 108.21045, mean: 0.10714
[32m[0906 15-50-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03373, current rewards: 88.54640, mean: 0.08353
[32m[0906 15-50-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03372, current rewards: 38.54640, mean: 0.03473
[32m[0906 15-50-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03372, current rewards: -11.45360, mean: -0.00987
[32m[0906 15-50-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03371, current rewards: -61.45360, mean: -0.05079
[32m[0906 15-50-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03370, current rewards: -111.45360, mean: -0.08846
[32m[0906 15-50-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03370, current rewards: -161.45360, mean: -0.12325
[32m[0906 15-50-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03371, current rewards: -211.45360, mean: -0.15548
[32m[0906 15-50-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03372, current rewards: -261.45360, mean: -0.18543
[32m[0906 15-50-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03370, current rewards: -311.45360, mean: -0.21332
[32m[0906 15-50-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03370, current rewards: -361.45360, mean: -0.23937
[32m[0906 15-50-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03369, current rewards: -411.45360, mean: -0.26375
[32m[0906 15-50-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03369, current rewards: -461.45360, mean: -0.28662
[32m[0906 15-50-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03369, current rewards: -511.45360, mean: -0.30810
[32m[0906 15-50-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03369, current rewards: -561.45360, mean: -0.32834
[32m[0906 15-50-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03365, current rewards: -611.45360, mean: -0.34742
[32m[0906 15-50-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03363, current rewards: -661.45360, mean: -0.36544
[32m[0906 15-50-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03360, current rewards: -711.45360, mean: -0.38250
[32m[0906 15-51-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03358, current rewards: -761.45360, mean: -0.39867
[32m[0906 15-51-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03356, current rewards: -811.45360, mean: -0.41401
[32m[0906 15-51-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03357, current rewards: -861.45360, mean: -0.42858
[32m[0906 15-51-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03356, current rewards: -911.45360, mean: -0.44245
[32m[0906 15-51-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03357, current rewards: -961.45360, mean: -0.45567
[32m[0906 15-51-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03358, current rewards: -1011.45360, mean: -0.46827
[32m[0906 15-51-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03357, current rewards: -1061.45360, mean: -0.48030
[32m[0906 15-51-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03358, current rewards: -1111.45360, mean: -0.49179
[32m[0906 15-51-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03358, current rewards: -1161.45360, mean: -0.50279
[32m[0906 15-51-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03358, current rewards: -1211.45360, mean: -0.51333
[32m[0906 15-51-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03358, current rewards: -1261.45360, mean: -0.52342
[32m[0906 15-51-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03359, current rewards: -1311.45360, mean: -0.53311
[32m[0906 15-51-20 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 15-51-20 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-51-20 @MBExp.py:227][0m Rewards obtained: [-1351.4536018069505], Lows: [1], Highs: [1465], Total time: 4764.855063
[32m[0906 15-53-14 @MBExp.py:144][0m ####################################################################
[32m[0906 15-53-14 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 15-53-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03327, current rewards: -0.04508, mean: -0.00451
[32m[0906 15-53-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03436, current rewards: 5.36922, mean: 0.08949
[32m[0906 15-53-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03437, current rewards: 10.90358, mean: 0.09912
[32m[0906 15-53-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03439, current rewards: 16.34755, mean: 0.10217
[32m[0906 15-53-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03428, current rewards: 21.78590, mean: 0.10374
[32m[0906 15-53-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03412, current rewards: 27.23109, mean: 0.10473
[32m[0906 15-53-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03405, current rewards: 32.67589, mean: 0.10541
[32m[0906 15-53-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03396, current rewards: 38.11766, mean: 0.10588
[32m[0906 15-53-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03393, current rewards: 43.55889, mean: 0.10624
[32m[0906 15-53-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03390, current rewards: 49.00324, mean: 0.10653
[32m[0906 15-53-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03386, current rewards: 54.39984, mean: 0.10667
[32m[0906 15-53-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03384, current rewards: 60.60494, mean: 0.10822
[32m[0906 15-53-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03381, current rewards: 66.08533, mean: 0.10834
[32m[0906 15-53-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03380, current rewards: 71.57068, mean: 0.10844
[32m[0906 15-53-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03379, current rewards: 77.05300, mean: 0.10853
[32m[0906 15-53-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03378, current rewards: 82.53678, mean: 0.10860
[32m[0906 15-53-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03377, current rewards: 88.02063, mean: 0.10867
[32m[0906 15-53-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03377, current rewards: 93.49821, mean: 0.10872
[32m[0906 15-53-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03375, current rewards: 98.97882, mean: 0.10877
[32m[0906 15-53-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03374, current rewards: 104.38836, mean: 0.10874
[32m[0906 15-53-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03375, current rewards: 109.86526, mean: 0.10878
[32m[0906 15-53-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03375, current rewards: 113.22989, mean: 0.10682
[32m[0906 15-53-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03375, current rewards: 118.72289, mean: 0.10696
[32m[0906 15-53-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03374, current rewards: 124.22162, mean: 0.10709
[32m[0906 15-53-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03373, current rewards: 129.71740, mean: 0.10720
[32m[0906 15-53-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03372, current rewards: 135.21078, mean: 0.10731
[32m[0906 15-53-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03372, current rewards: 140.70374, mean: 0.10741
[32m[0906 15-54-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03371, current rewards: 146.20823, mean: 0.10751
[32m[0906 15-54-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03371, current rewards: 151.70480, mean: 0.10759
[32m[0906 15-54-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03371, current rewards: 157.20552, mean: 0.10768
[32m[0906 15-54-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03370, current rewards: 162.70736, mean: 0.10775
[32m[0906 15-54-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03370, current rewards: 168.20486, mean: 0.10782
[32m[0906 15-54-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03370, current rewards: 173.70262, mean: 0.10789
[32m[0906 15-54-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03370, current rewards: 179.20311, mean: 0.10795
[32m[0906 15-54-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03367, current rewards: 184.70343, mean: 0.10801
[32m[0906 15-54-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03364, current rewards: 188.06527, mean: 0.10686
[32m[0906 15-54-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03362, current rewards: 193.53978, mean: 0.10693
[32m[0906 15-54-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03359, current rewards: 199.01394, mean: 0.10700
[32m[0906 15-54-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03357, current rewards: 204.49290, mean: 0.10706
[32m[0906 15-54-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03354, current rewards: 209.96464, mean: 0.10712
[32m[0906 15-54-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03355, current rewards: 215.43466, mean: 0.10718
[32m[0906 15-54-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03356, current rewards: 220.90852, mean: 0.10724
[32m[0906 15-54-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03357, current rewards: 226.38484, mean: 0.10729
[32m[0906 15-54-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03358, current rewards: 232.06642, mean: 0.10744
[32m[0906 15-54-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03358, current rewards: 237.58177, mean: 0.10750
[32m[0906 15-54-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03358, current rewards: 243.09294, mean: 0.10756
[32m[0906 15-54-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03358, current rewards: 248.60110, mean: 0.10762
[32m[0906 15-54-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03358, current rewards: 254.10897, mean: 0.10767
[32m[0906 15-54-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03359, current rewards: 259.61963, mean: 0.10773
[32m[0906 15-54-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03359, current rewards: 263.20857, mean: 0.10700
[32m[0906 15-54-39 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 15-54-39 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-54-39 @MBExp.py:227][0m Rewards obtained: [267.6305528366664], Lows: [3], Highs: [1], Total time: 4849.485531
[32m[0906 15-56-36 @MBExp.py:144][0m ####################################################################
[32m[0906 15-56-36 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 15-56-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03378, current rewards: 0.09134, mean: 0.00913
[32m[0906 15-56-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03434, current rewards: 5.59776, mean: 0.09330
[32m[0906 15-56-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03442, current rewards: 11.12627, mean: 0.10115
[32m[0906 15-56-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03440, current rewards: 16.65221, mean: 0.10408
[32m[0906 15-56-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03416, current rewards: 20.08834, mean: 0.09566
[32m[0906 15-56-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03404, current rewards: 25.60295, mean: 0.09847
[32m[0906 15-56-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03397, current rewards: 31.10838, mean: 0.10035
[32m[0906 15-56-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03395, current rewards: 36.61548, mean: 0.10171
[32m[0906 15-56-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03392, current rewards: 40.95834, mean: 0.09990
[32m[0906 15-56-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03392, current rewards: 46.33157, mean: 0.10072
[32m[0906 15-56-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03388, current rewards: 51.40131, mean: 0.10079
[32m[0906 15-56-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03387, current rewards: 56.64030, mean: 0.10114
[32m[0906 15-56-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03384, current rewards: 61.87677, mean: 0.10144
[32m[0906 15-56-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03384, current rewards: 67.11660, mean: 0.10169
[32m[0906 15-57-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03383, current rewards: 72.35469, mean: 0.10191
[32m[0906 15-57-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03382, current rewards: 77.58709, mean: 0.10209
[32m[0906 15-57-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03380, current rewards: 82.81975, mean: 0.10225
[32m[0906 15-57-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03379, current rewards: 85.93823, mean: 0.09993
[32m[0906 15-57-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03378, current rewards: 91.44750, mean: 0.10049
[32m[0906 15-57-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03378, current rewards: 96.87490, mean: 0.10091
[32m[0906 15-57-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03377, current rewards: 102.29873, mean: 0.10129
[32m[0906 15-57-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03377, current rewards: 107.71997, mean: 0.10162
[32m[0906 15-57-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03376, current rewards: 113.14004, mean: 0.10193
[32m[0906 15-57-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03376, current rewards: 118.56434, mean: 0.10221
[32m[0906 15-57-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03375, current rewards: 123.98450, mean: 0.10247
[32m[0906 15-57-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03375, current rewards: 129.40843, mean: 0.10271
[32m[0906 15-57-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03374, current rewards: 135.00277, mean: 0.10306
[32m[0906 15-57-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03374, current rewards: 140.44806, mean: 0.10327
[32m[0906 15-57-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03374, current rewards: 145.79053, mean: 0.10340
[32m[0906 15-57-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03373, current rewards: 151.12915, mean: 0.10351
[32m[0906 15-57-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03374, current rewards: 155.35882, mean: 0.10289
[32m[0906 15-57-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03373, current rewards: 160.87658, mean: 0.10313
[32m[0906 15-57-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03373, current rewards: 166.39334, mean: 0.10335
[32m[0906 15-57-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03370, current rewards: 171.91528, mean: 0.10356
[32m[0906 15-57-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03367, current rewards: 173.21622, mean: 0.10130
[32m[0906 15-57-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03364, current rewards: 162.15968, mean: 0.09214
[32m[0906 15-57-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03362, current rewards: 112.15968, mean: 0.06197
[32m[0906 15-57-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03360, current rewards: 62.15968, mean: 0.03342
[32m[0906 15-57-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03357, current rewards: 12.15968, mean: 0.00637
[32m[0906 15-57-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03355, current rewards: -37.84032, mean: -0.01931
[32m[0906 15-57-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03356, current rewards: -87.84032, mean: -0.04370
[32m[0906 15-57-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03357, current rewards: -137.84032, mean: -0.06691
[32m[0906 15-57-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03357, current rewards: -187.84032, mean: -0.08902
[32m[0906 15-57-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03357, current rewards: -237.84032, mean: -0.11011
[32m[0906 15-57-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03357, current rewards: -287.84032, mean: -0.13024
[32m[0906 15-57-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03357, current rewards: -337.84032, mean: -0.14949
[32m[0906 15-57-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03358, current rewards: -387.84032, mean: -0.16790
[32m[0906 15-57-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03358, current rewards: -437.84032, mean: -0.18553
[32m[0906 15-57-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03358, current rewards: -487.84032, mean: -0.20242
[32m[0906 15-57-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03358, current rewards: -537.84032, mean: -0.21863
[32m[0906 15-58-00 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 15-58-00 @Agent.py:118][0m Rollout length: 2501
[32m[0906 15-58-00 @MBExp.py:227][0m Rewards obtained: [-577.840317889173], Lows: [4], Highs: [758], Total time: 4934.105813
[32m[0906 15-59-59 @MBExp.py:144][0m ####################################################################
[32m[0906 15-59-59 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 16-00-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03346, current rewards: 0.04708, mean: 0.00471
[32m[0906 16-00-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03422, current rewards: 5.60735, mean: 0.09346
[32m[0906 16-00-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03432, current rewards: 11.08182, mean: 0.10074
[32m[0906 16-00-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03418, current rewards: 16.65736, mean: 0.10411
[32m[0906 16-00-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03409, current rewards: 22.23011, mean: 0.10586
[32m[0906 16-00-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03398, current rewards: 27.80314, mean: 0.10694
[32m[0906 16-00-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03396, current rewards: 33.38063, mean: 0.10768
[32m[0906 16-00-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03392, current rewards: 38.95641, mean: 0.10821
[32m[0906 16-00-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03386, current rewards: 44.52874, mean: 0.10861
[32m[0906 16-00-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03380, current rewards: 50.10351, mean: 0.10892
[32m[0906 16-00-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03380, current rewards: 56.11100, mean: 0.11002
[32m[0906 16-00-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03378, current rewards: 26.33496, mean: 0.04703
[32m[0906 16-00-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03376, current rewards: -23.66504, mean: -0.03880
[32m[0906 16-00-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03374, current rewards: -73.66504, mean: -0.11161
[32m[0906 16-00-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03373, current rewards: -123.66504, mean: -0.17418
[32m[0906 16-00-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03371, current rewards: -173.66504, mean: -0.22851
[32m[0906 16-00-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03373, current rewards: -223.66504, mean: -0.27613
[32m[0906 16-00-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03372, current rewards: -273.66504, mean: -0.31822
[32m[0906 16-00-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03372, current rewards: -323.66504, mean: -0.35568
[32m[0906 16-00-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03371, current rewards: -373.66504, mean: -0.38923
[32m[0906 16-00-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03370, current rewards: -423.66504, mean: -0.41947
[32m[0906 16-00-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03370, current rewards: -473.66504, mean: -0.44685
[32m[0906 16-00-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03369, current rewards: -523.66504, mean: -0.47177
[32m[0906 16-00-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03369, current rewards: -573.66504, mean: -0.49454
[32m[0906 16-00-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03368, current rewards: -623.66504, mean: -0.51543
[32m[0906 16-00-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03369, current rewards: -673.66504, mean: -0.53465
[32m[0906 16-00-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03368, current rewards: -723.66504, mean: -0.55242
[32m[0906 16-00-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03368, current rewards: -773.66504, mean: -0.56887
[32m[0906 16-00-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03368, current rewards: -823.66504, mean: -0.58416
[32m[0906 16-00-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03367, current rewards: -873.66504, mean: -0.59840
[32m[0906 16-00-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03367, current rewards: -923.66504, mean: -0.61170
[32m[0906 16-00-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03367, current rewards: -973.66504, mean: -0.62414
[32m[0906 16-00-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03365, current rewards: -1023.66504, mean: -0.63582
[32m[0906 16-00-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03362, current rewards: -1073.66504, mean: -0.64679
[32m[0906 16-00-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03360, current rewards: -1123.66504, mean: -0.65711
[32m[0906 16-00-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03357, current rewards: -1173.66504, mean: -0.66686
[32m[0906 16-01-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03355, current rewards: -1223.66504, mean: -0.67606
[32m[0906 16-01-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03352, current rewards: -1273.66504, mean: -0.68477
[32m[0906 16-01-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03350, current rewards: -1323.66504, mean: -0.69302
[32m[0906 16-01-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03348, current rewards: -1373.66504, mean: -0.70085
[32m[0906 16-01-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03348, current rewards: -1423.66504, mean: -0.70829
[32m[0906 16-01-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03348, current rewards: -1473.66504, mean: -0.71537
[32m[0906 16-01-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03348, current rewards: -1523.66504, mean: -0.72212
[32m[0906 16-01-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03349, current rewards: -1573.66504, mean: -0.72855
[32m[0906 16-01-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03349, current rewards: -1623.66504, mean: -0.73469
[32m[0906 16-01-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03350, current rewards: -1673.66504, mean: -0.74056
[32m[0906 16-01-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03350, current rewards: -1723.66504, mean: -0.74618
[32m[0906 16-01-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03351, current rewards: -1773.66504, mean: -0.75155
[32m[0906 16-01-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03351, current rewards: -1823.66504, mean: -0.75671
[32m[0906 16-01-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03352, current rewards: -1873.66504, mean: -0.76165
[32m[0906 16-01-24 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 16-01-24 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-01-24 @MBExp.py:227][0m Rewards obtained: [-1913.6650357388964], Lows: [0], Highs: [1973], Total time: 5018.56102
[32m[0906 16-03-25 @MBExp.py:144][0m ####################################################################
[32m[0906 16-03-25 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 16-03-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03394, current rewards: 0.09387, mean: 0.00939
[32m[0906 16-03-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03432, current rewards: 5.59656, mean: 0.09328
[32m[0906 16-03-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03432, current rewards: 11.14113, mean: 0.10128
[32m[0906 16-03-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03412, current rewards: 16.62435, mean: 0.10390
[32m[0906 16-03-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03401, current rewards: 22.11613, mean: 0.10531
[32m[0906 16-03-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03394, current rewards: 27.60294, mean: 0.10617
[32m[0906 16-03-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03388, current rewards: 33.08493, mean: 0.10673
[32m[0906 16-03-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03387, current rewards: 38.57075, mean: 0.10714
[32m[0906 16-03-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03385, current rewards: 41.94989, mean: 0.10232
[32m[0906 16-03-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03382, current rewards: 47.71869, mean: 0.10374
[32m[0906 16-03-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03381, current rewards: 52.97841, mean: 0.10388
[32m[0906 16-03-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03381, current rewards: 58.43963, mean: 0.10436
[32m[0906 16-03-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03380, current rewards: 63.90095, mean: 0.10476
[32m[0906 16-03-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03379, current rewards: 69.36189, mean: 0.10509
[32m[0906 16-03-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03382, current rewards: 74.82075, mean: 0.10538
[32m[0906 16-03-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03381, current rewards: 80.28241, mean: 0.10563
[32m[0906 16-03-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03380, current rewards: 84.64676, mean: 0.10450
[32m[0906 16-03-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03379, current rewards: 90.14651, mean: 0.10482
[32m[0906 16-03-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03379, current rewards: 95.74307, mean: 0.10521
[32m[0906 16-03-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03379, current rewards: 101.24812, mean: 0.10547
[32m[0906 16-03-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03378, current rewards: 106.74681, mean: 0.10569
[32m[0906 16-04-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03378, current rewards: 112.25467, mean: 0.10590
[32m[0906 16-04-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03378, current rewards: 117.75709, mean: 0.10609
[32m[0906 16-04-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03377, current rewards: 123.26122, mean: 0.10626
[32m[0906 16-04-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03377, current rewards: 128.76606, mean: 0.10642
[32m[0906 16-04-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03378, current rewards: 132.29609, mean: 0.10500
[32m[0906 16-04-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03377, current rewards: 137.80736, mean: 0.10520
[32m[0906 16-04-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03377, current rewards: 143.28005, mean: 0.10535
[32m[0906 16-04-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03376, current rewards: 148.75170, mean: 0.10550
[32m[0906 16-04-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03377, current rewards: 154.22113, mean: 0.10563
[32m[0906 16-04-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03376, current rewards: 159.68776, mean: 0.10575
[32m[0906 16-04-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03375, current rewards: 165.15582, mean: 0.10587
[32m[0906 16-04-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03372, current rewards: 170.62947, mean: 0.10598
[32m[0906 16-04-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03369, current rewards: 176.09850, mean: 0.10608
[32m[0906 16-04-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03367, current rewards: 181.47887, mean: 0.10613
[32m[0906 16-04-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03364, current rewards: 186.88879, mean: 0.10619
[32m[0906 16-04-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03361, current rewards: 191.25410, mean: 0.10567
[32m[0906 16-04-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03359, current rewards: 196.74902, mean: 0.10578
[32m[0906 16-04-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03357, current rewards: 202.25574, mean: 0.10589
[32m[0906 16-04-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03355, current rewards: 207.75811, mean: 0.10600
[32m[0906 16-04-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03353, current rewards: 213.26727, mean: 0.10610
[32m[0906 16-04-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03353, current rewards: 218.77663, mean: 0.10620
[32m[0906 16-04-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03354, current rewards: 224.28393, mean: 0.10630
[32m[0906 16-04-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03354, current rewards: 229.84366, mean: 0.10641
[32m[0906 16-04-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03354, current rewards: 234.25529, mean: 0.10600
[32m[0906 16-04-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03354, current rewards: 239.72093, mean: 0.10607
[32m[0906 16-04-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03354, current rewards: 245.20684, mean: 0.10615
[32m[0906 16-04-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03355, current rewards: 250.69008, mean: 0.10622
[32m[0906 16-04-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03356, current rewards: 256.16529, mean: 0.10629
[32m[0906 16-04-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03356, current rewards: 261.65151, mean: 0.10636
[32m[0906 16-04-49 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 16-04-49 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-04-50 @MBExp.py:227][0m Rewards obtained: [266.0399385720773], Lows: [2], Highs: [4], Total time: 5103.157668
[32m[0906 16-06-53 @MBExp.py:144][0m ####################################################################
[32m[0906 16-06-53 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 16-06-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03429, current rewards: -0.09239, mean: -0.00924
[32m[0906 16-06-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03432, current rewards: 5.52198, mean: 0.09203
[32m[0906 16-06-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03388, current rewards: 11.20224, mean: 0.10184
[32m[0906 16-06-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03377, current rewards: 16.88394, mean: 0.10552
[32m[0906 16-07-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03374, current rewards: 22.56249, mean: 0.10744
[32m[0906 16-07-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03371, current rewards: 28.24627, mean: 0.10864
[32m[0906 16-07-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03370, current rewards: 33.92709, mean: 0.10944
[32m[0906 16-07-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03370, current rewards: 39.60024, mean: 0.11000
[32m[0906 16-07-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03369, current rewards: 45.28123, mean: 0.11044
[32m[0906 16-07-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03367, current rewards: 51.07028, mean: 0.11102
[32m[0906 16-07-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03367, current rewards: 56.73634, mean: 0.11125
[32m[0906 16-07-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03367, current rewards: 62.40640, mean: 0.11144
[32m[0906 16-07-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03368, current rewards: 68.06977, mean: 0.11159
[32m[0906 16-07-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03368, current rewards: 73.77992, mean: 0.11179
[32m[0906 16-07-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03369, current rewards: 79.49409, mean: 0.11196
[32m[0906 16-07-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03369, current rewards: 85.20278, mean: 0.11211
[32m[0906 16-07-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03368, current rewards: 90.91415, mean: 0.11224
[32m[0906 16-07-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03368, current rewards: 96.53903, mean: 0.11225
[32m[0906 16-07-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03366, current rewards: 102.26419, mean: 0.11238
[32m[0906 16-07-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03365, current rewards: 108.01947, mean: 0.11252
[32m[0906 16-07-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03365, current rewards: 113.77003, mean: 0.11264
[32m[0906 16-07-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03366, current rewards: 119.51825, mean: 0.11275
[32m[0906 16-07-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03366, current rewards: 125.27860, mean: 0.11286
[32m[0906 16-07-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03366, current rewards: 131.03072, mean: 0.11296
[32m[0906 16-07-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03366, current rewards: 136.77594, mean: 0.11304
[32m[0906 16-07-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03366, current rewards: 142.47390, mean: 0.11307
[32m[0906 16-07-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03366, current rewards: 148.52594, mean: 0.11338
[32m[0906 16-07-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03367, current rewards: 154.37849, mean: 0.11351
[32m[0906 16-07-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03366, current rewards: 160.22865, mean: 0.11364
[32m[0906 16-07-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03366, current rewards: 166.07950, mean: 0.11375
[32m[0906 16-07-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03366, current rewards: 171.92829, mean: 0.11386
[32m[0906 16-07-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03363, current rewards: 175.79883, mean: 0.11269
[32m[0906 16-07-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03359, current rewards: 181.54707, mean: 0.11276
[32m[0906 16-07-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03357, current rewards: 187.29147, mean: 0.11283
[32m[0906 16-07-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03354, current rewards: 192.91561, mean: 0.11282
[32m[0906 16-07-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03352, current rewards: 198.58917, mean: 0.11283
[32m[0906 16-07-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03350, current rewards: 204.31131, mean: 0.11288
[32m[0906 16-07-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03348, current rewards: 210.03086, mean: 0.11292
[32m[0906 16-07-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03346, current rewards: 215.75267, mean: 0.11296
[32m[0906 16-07-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03344, current rewards: 221.47277, mean: 0.11300
[32m[0906 16-08-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03343, current rewards: 227.19443, mean: 0.11303
[32m[0906 16-08-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03344, current rewards: 232.91757, mean: 0.11307
[32m[0906 16-08-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03344, current rewards: 238.63791, mean: 0.11310
[32m[0906 16-08-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03344, current rewards: 242.56362, mean: 0.11230
[32m[0906 16-08-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03345, current rewards: 248.42026, mean: 0.11241
[32m[0906 16-08-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03345, current rewards: 254.27537, mean: 0.11251
[32m[0906 16-08-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03345, current rewards: 260.13379, mean: 0.11261
[32m[0906 16-08-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03345, current rewards: 265.98903, mean: 0.11271
[32m[0906 16-08-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03346, current rewards: 271.84661, mean: 0.11280
[32m[0906 16-08-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03347, current rewards: 276.45958, mean: 0.11238
[32m[0906 16-08-17 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 16-08-17 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-08-17 @MBExp.py:227][0m Rewards obtained: [280.98136203508835], Lows: [2], Highs: [2], Total time: 5187.499346
[32m[0906 16-10-22 @MBExp.py:144][0m ####################################################################
[32m[0906 16-10-22 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 16-10-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03393, current rewards: -0.02867, mean: -0.00287
[32m[0906 16-10-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03373, current rewards: 5.44077, mean: 0.09068
[32m[0906 16-10-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03372, current rewards: 10.96044, mean: 0.09964
[32m[0906 16-10-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03369, current rewards: 16.47559, mean: 0.10297
[32m[0906 16-10-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03368, current rewards: 21.99552, mean: 0.10474
[32m[0906 16-10-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03362, current rewards: 27.51705, mean: 0.10583
[32m[0906 16-10-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03362, current rewards: 33.03807, mean: 0.10657
[32m[0906 16-10-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03365, current rewards: 38.55480, mean: 0.10710
[32m[0906 16-10-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03364, current rewards: 44.07337, mean: 0.10750
[32m[0906 16-10-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03365, current rewards: 49.60084, mean: 0.10783
[32m[0906 16-10-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03362, current rewards: 53.95849, mean: 0.10580
[32m[0906 16-10-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03361, current rewards: 59.46957, mean: 0.10620
[32m[0906 16-10-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03361, current rewards: 64.98741, mean: 0.10654
[32m[0906 16-10-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03360, current rewards: 70.50074, mean: 0.10682
[32m[0906 16-10-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03359, current rewards: 76.01742, mean: 0.10707
[32m[0906 16-10-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03359, current rewards: 81.53001, mean: 0.10728
[32m[0906 16-10-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03358, current rewards: 87.04593, mean: 0.10746
[32m[0906 16-10-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03359, current rewards: 92.58022, mean: 0.10765
[32m[0906 16-10-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03358, current rewards: 96.21131, mean: 0.10573
[32m[0906 16-10-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03358, current rewards: 101.73763, mean: 0.10598
[32m[0906 16-10-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03358, current rewards: 107.26653, mean: 0.10620
[32m[0906 16-10-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03358, current rewards: 112.79189, mean: 0.10641
[32m[0906 16-11-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03359, current rewards: 118.31781, mean: 0.10659
[32m[0906 16-11-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03359, current rewards: 123.85001, mean: 0.10677
[32m[0906 16-11-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03359, current rewards: 129.38257, mean: 0.10693
[32m[0906 16-11-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03359, current rewards: 131.63241, mean: 0.10447
[32m[0906 16-11-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03359, current rewards: 121.17107, mean: 0.09250
[32m[0906 16-11-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03359, current rewards: 71.17107, mean: 0.05233
[32m[0906 16-11-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03359, current rewards: 21.17107, mean: 0.01501
[32m[0906 16-11-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03360, current rewards: -28.82893, mean: -0.01975
[32m[0906 16-11-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03357, current rewards: -78.82893, mean: -0.05220
[32m[0906 16-11-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03355, current rewards: -128.82893, mean: -0.08258
[32m[0906 16-11-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03352, current rewards: -178.82893, mean: -0.11107
[32m[0906 16-11-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03349, current rewards: -228.82893, mean: -0.13785
[32m[0906 16-11-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03347, current rewards: -277.78009, mean: -0.16244
[32m[0906 16-11-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03344, current rewards: -293.16829, mean: -0.16657
[32m[0906 16-11-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03342, current rewards: -343.16829, mean: -0.18960
[32m[0906 16-11-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03340, current rewards: -393.16829, mean: -0.21138
[32m[0906 16-11-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03339, current rewards: -443.16829, mean: -0.23203
[32m[0906 16-11-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03337, current rewards: -493.16829, mean: -0.25162
[32m[0906 16-11-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03335, current rewards: -543.16829, mean: -0.27023
[32m[0906 16-11-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03336, current rewards: -593.16829, mean: -0.28795
[32m[0906 16-11-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03336, current rewards: -643.16829, mean: -0.30482
[32m[0906 16-11-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03337, current rewards: -693.16829, mean: -0.32091
[32m[0906 16-11-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03338, current rewards: -743.16829, mean: -0.33628
[32m[0906 16-11-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03338, current rewards: -793.16829, mean: -0.35096
[32m[0906 16-11-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03338, current rewards: -843.16829, mean: -0.36501
[32m[0906 16-11-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03339, current rewards: -893.16829, mean: -0.37846
[32m[0906 16-11-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03340, current rewards: -943.16829, mean: -0.39136
[32m[0906 16-11-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03341, current rewards: -993.16829, mean: -0.40373
[32m[0906 16-11-46 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 16-11-46 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-11-46 @MBExp.py:227][0m Rewards obtained: [-1033.168294792973], Lows: [3], Highs: [1172], Total time: 5271.687472
[32m[0906 16-13-53 @MBExp.py:144][0m ####################################################################
[32m[0906 16-13-53 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 16-13-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03419, current rewards: 0.20598, mean: 0.02060
[32m[0906 16-13-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03351, current rewards: 5.59050, mean: 0.09317
[32m[0906 16-13-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03358, current rewards: 11.17691, mean: 0.10161
[32m[0906 16-13-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03359, current rewards: 16.76096, mean: 0.10476
[32m[0906 16-14-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03358, current rewards: 22.35122, mean: 0.10643
[32m[0906 16-14-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03361, current rewards: 27.94095, mean: 0.10747
[32m[0906 16-14-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03366, current rewards: 33.52792, mean: 0.10815
[32m[0906 16-14-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03367, current rewards: 39.11347, mean: 0.10865
[32m[0906 16-14-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03368, current rewards: 44.69930, mean: 0.10902
[32m[0906 16-14-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03369, current rewards: 50.32080, mean: 0.10939
[32m[0906 16-14-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03370, current rewards: 56.09967, mean: 0.11000
[32m[0906 16-14-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03371, current rewards: 61.67212, mean: 0.11013
[32m[0906 16-14-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03370, current rewards: 67.25144, mean: 0.11025
[32m[0906 16-14-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03373, current rewards: 72.82985, mean: 0.11035
[32m[0906 16-14-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03372, current rewards: 78.39874, mean: 0.11042
[32m[0906 16-14-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03371, current rewards: 83.96766, mean: 0.11048
[32m[0906 16-14-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03370, current rewards: 89.53975, mean: 0.11054
[32m[0906 16-14-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03369, current rewards: 95.08915, mean: 0.11057
[32m[0906 16-14-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03369, current rewards: 100.66115, mean: 0.11062
[32m[0906 16-14-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03368, current rewards: 106.23617, mean: 0.11066
[32m[0906 16-14-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03368, current rewards: 111.81200, mean: 0.11070
[32m[0906 16-14-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03368, current rewards: 117.38526, mean: 0.11074
[32m[0906 16-14-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03367, current rewards: 122.95903, mean: 0.11077
[32m[0906 16-14-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03367, current rewards: 128.53358, mean: 0.11080
[32m[0906 16-14-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03368, current rewards: 134.11359, mean: 0.11084
[32m[0906 16-14-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03367, current rewards: 139.68827, mean: 0.11086
[32m[0906 16-14-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03367, current rewards: 143.36709, mean: 0.10944
[32m[0906 16-14-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03367, current rewards: 148.80714, mean: 0.10942
[32m[0906 16-14-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03368, current rewards: 154.24584, mean: 0.10939
[32m[0906 16-14-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03366, current rewards: 159.68472, mean: 0.10937
[32m[0906 16-14-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03362, current rewards: 165.12511, mean: 0.10935
[32m[0906 16-14-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03359, current rewards: 170.56176, mean: 0.10933
[32m[0906 16-14-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03356, current rewards: 173.94213, mean: 0.10804
[32m[0906 16-14-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03354, current rewards: 179.42053, mean: 0.10808
[32m[0906 16-14-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03351, current rewards: 184.90419, mean: 0.10813
[32m[0906 16-14-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03350, current rewards: 190.37930, mean: 0.10817
[32m[0906 16-14-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03347, current rewards: 195.85328, mean: 0.10821
[32m[0906 16-14-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03345, current rewards: 199.42427, mean: 0.10722
[32m[0906 16-14-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03344, current rewards: 204.96638, mean: 0.10731
[32m[0906 16-14-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03342, current rewards: 210.50366, mean: 0.10740
[32m[0906 16-15-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03340, current rewards: 216.04228, mean: 0.10748
[32m[0906 16-15-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03341, current rewards: 221.58044, mean: 0.10756
[32m[0906 16-15-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03341, current rewards: 226.96595, mean: 0.10757
[32m[0906 16-15-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03342, current rewards: 230.57549, mean: 0.10675
[32m[0906 16-15-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03342, current rewards: 236.17434, mean: 0.10687
[32m[0906 16-15-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03343, current rewards: 241.77072, mean: 0.10698
[32m[0906 16-15-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03343, current rewards: 247.37063, mean: 0.10709
[32m[0906 16-15-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03343, current rewards: 252.96928, mean: 0.10719
[32m[0906 16-15-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03344, current rewards: 258.56706, mean: 0.10729
[32m[0906 16-15-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03344, current rewards: 264.16586, mean: 0.10738
[32m[0906 16-15-17 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 16-15-17 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-15-17 @MBExp.py:227][0m Rewards obtained: [268.64899934215566], Lows: [4], Highs: [1], Total time: 5355.9653069999995
[32m[0906 16-17-27 @MBExp.py:144][0m ####################################################################
[32m[0906 16-17-27 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 16-17-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03242, current rewards: -1.19097, mean: -0.11910
[32m[0906 16-17-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03329, current rewards: 4.29989, mean: 0.07166
[32m[0906 16-17-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03348, current rewards: 9.79029, mean: 0.08900
[32m[0906 16-17-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03353, current rewards: 15.28225, mean: 0.09551
[32m[0906 16-17-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03354, current rewards: 20.76936, mean: 0.09890
[32m[0906 16-17-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03353, current rewards: 26.25685, mean: 0.10099
[32m[0906 16-17-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03354, current rewards: 31.74452, mean: 0.10240
[32m[0906 16-17-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03354, current rewards: 37.23234, mean: 0.10342
[32m[0906 16-17-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03353, current rewards: 42.71438, mean: 0.10418
[32m[0906 16-17-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03356, current rewards: 48.20169, mean: 0.10479
[32m[0906 16-17-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03355, current rewards: 53.69021, mean: 0.10527
[32m[0906 16-17-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03357, current rewards: 59.18240, mean: 0.10568
[32m[0906 16-17-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03357, current rewards: 64.67223, mean: 0.10602
[32m[0906 16-17-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03357, current rewards: 69.03255, mean: 0.10459
[32m[0906 16-17-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03359, current rewards: 74.53909, mean: 0.10498
[32m[0906 16-17-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03358, current rewards: 80.04598, mean: 0.10532
[32m[0906 16-17-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03357, current rewards: 85.57096, mean: 0.10564
[32m[0906 16-17-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03357, current rewards: 91.08585, mean: 0.10591
[32m[0906 16-17-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03357, current rewards: 96.59861, mean: 0.10615
[32m[0906 16-17-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03358, current rewards: 102.10065, mean: 0.10635
[32m[0906 16-18-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03359, current rewards: 108.20525, mean: 0.10713
[32m[0906 16-18-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03359, current rewards: 113.74774, mean: 0.10731
[32m[0906 16-18-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03361, current rewards: 119.28923, mean: 0.10747
[32m[0906 16-18-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03361, current rewards: 124.83586, mean: 0.10762
[32m[0906 16-18-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03362, current rewards: 130.43629, mean: 0.10780
[32m[0906 16-18-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03362, current rewards: 136.09159, mean: 0.10801
[32m[0906 16-18-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03362, current rewards: 141.61956, mean: 0.10811
[32m[0906 16-18-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03362, current rewards: 147.15278, mean: 0.10820
[32m[0906 16-18-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03360, current rewards: 152.67789, mean: 0.10828
[32m[0906 16-18-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03358, current rewards: 158.20682, mean: 0.10836
[32m[0906 16-18-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03355, current rewards: 161.63870, mean: 0.10705
[32m[0906 16-18-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03352, current rewards: 167.14535, mean: 0.10714
[32m[0906 16-18-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03349, current rewards: 172.65429, mean: 0.10724
[32m[0906 16-18-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03347, current rewards: 178.09242, mean: 0.10728
[32m[0906 16-18-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03345, current rewards: 183.59833, mean: 0.10737
[32m[0906 16-18-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03343, current rewards: 189.04151, mean: 0.10741
[32m[0906 16-18-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03341, current rewards: 194.56510, mean: 0.10749
[32m[0906 16-18-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03339, current rewards: 200.08090, mean: 0.10757
[32m[0906 16-18-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03338, current rewards: 205.59690, mean: 0.10764
[32m[0906 16-18-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03336, current rewards: 211.11822, mean: 0.10771
[32m[0906 16-18-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03334, current rewards: 216.63650, mean: 0.10778
[32m[0906 16-18-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03334, current rewards: 222.22824, mean: 0.10788
[32m[0906 16-18-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03335, current rewards: 227.74749, mean: 0.10794
[32m[0906 16-18-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03336, current rewards: 233.26431, mean: 0.10799
[32m[0906 16-18-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03337, current rewards: 237.24618, mean: 0.10735
[32m[0906 16-18-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03338, current rewards: 242.92324, mean: 0.10749
[32m[0906 16-18-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03338, current rewards: 248.60031, mean: 0.10762
[32m[0906 16-18-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03338, current rewards: 254.27738, mean: 0.10774
[32m[0906 16-18-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03339, current rewards: 259.95445, mean: 0.10786
[32m[0906 16-18-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03339, current rewards: 265.06584, mean: 0.10775
[32m[0906 16-18-51 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 16-18-51 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-18-51 @MBExp.py:227][0m Rewards obtained: [269.2381274523184], Lows: [2], Highs: [3], Total time: 5440.120918999999
[32m[0906 16-21-02 @MBExp.py:144][0m ####################################################################
[32m[0906 16-21-02 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 16-21-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03253, current rewards: 1.03846, mean: 0.10385
[32m[0906 16-21-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03349, current rewards: 6.53535, mean: 0.10892
[32m[0906 16-21-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03359, current rewards: 12.03304, mean: 0.10939
[32m[0906 16-21-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03365, current rewards: 17.53051, mean: 0.10957
[32m[0906 16-21-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03369, current rewards: 23.02774, mean: 0.10966
[32m[0906 16-21-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03368, current rewards: 28.52423, mean: 0.10971
[32m[0906 16-21-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03366, current rewards: 34.02219, mean: 0.10975
[32m[0906 16-21-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03367, current rewards: 39.51824, mean: 0.10977
[32m[0906 16-21-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03365, current rewards: 44.73406, mean: 0.10911
[32m[0906 16-21-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03365, current rewards: 50.12750, mean: 0.10897
[32m[0906 16-21-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03364, current rewards: 55.51576, mean: 0.10885
[32m[0906 16-21-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03366, current rewards: 60.90655, mean: 0.10876
[32m[0906 16-21-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03368, current rewards: 66.29990, mean: 0.10869
[32m[0906 16-21-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03368, current rewards: 70.62068, mean: 0.10700
[32m[0906 16-21-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03368, current rewards: 76.24742, mean: 0.10739
[32m[0906 16-21-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03366, current rewards: 81.88020, mean: 0.10774
[32m[0906 16-21-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03366, current rewards: 87.63105, mean: 0.10819
[32m[0906 16-21-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03365, current rewards: 93.30582, mean: 0.10850
[32m[0906 16-21-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03366, current rewards: 98.82848, mean: 0.10860
[32m[0906 16-21-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03366, current rewards: 104.35468, mean: 0.10870
[32m[0906 16-21-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03366, current rewards: 109.88154, mean: 0.10879
[32m[0906 16-21-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03366, current rewards: 114.26955, mean: 0.10780
[32m[0906 16-21-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03366, current rewards: 119.72326, mean: 0.10786
[32m[0906 16-21-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03366, current rewards: 125.18050, mean: 0.10791
[32m[0906 16-21-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03366, current rewards: 130.63651, mean: 0.10796
[32m[0906 16-21-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03365, current rewards: 134.34996, mean: 0.10663
[32m[0906 16-21-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03365, current rewards: 139.93711, mean: 0.10682
[32m[0906 16-21-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03363, current rewards: 145.52199, mean: 0.10700
[32m[0906 16-21-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03359, current rewards: 151.10970, mean: 0.10717
[32m[0906 16-21-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03358, current rewards: 156.69600, mean: 0.10733
[32m[0906 16-21-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03355, current rewards: 162.28210, mean: 0.10747
[32m[0906 16-21-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03352, current rewards: 167.87049, mean: 0.10761
[32m[0906 16-21-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03350, current rewards: 173.45676, mean: 0.10774
[32m[0906 16-21-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03347, current rewards: 177.81774, mean: 0.10712
[32m[0906 16-21-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03345, current rewards: 183.38360, mean: 0.10724
[32m[0906 16-22-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03343, current rewards: 188.94543, mean: 0.10736
[32m[0906 16-22-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03342, current rewards: 194.51129, mean: 0.10746
[32m[0906 16-22-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03339, current rewards: 200.07415, mean: 0.10757
[32m[0906 16-22-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03338, current rewards: 205.64059, mean: 0.10767
[32m[0906 16-22-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03336, current rewards: 211.20611, mean: 0.10776
[32m[0906 16-22-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03334, current rewards: 216.77099, mean: 0.10785
[32m[0906 16-22-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03334, current rewards: 222.26675, mean: 0.10790
[32m[0906 16-22-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03335, current rewards: 227.83867, mean: 0.10798
[32m[0906 16-22-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03335, current rewards: 233.40990, mean: 0.10806
[32m[0906 16-22-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03336, current rewards: 238.98176, mean: 0.10814
[32m[0906 16-22-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03337, current rewards: 243.46001, mean: 0.10773
[32m[0906 16-22-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03337, current rewards: 249.07792, mean: 0.10783
[32m[0906 16-22-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03338, current rewards: 254.68758, mean: 0.10792
[32m[0906 16-22-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03339, current rewards: 260.30304, mean: 0.10801
[32m[0906 16-22-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03339, current rewards: 265.85634, mean: 0.10807
[32m[0906 16-22-26 @Agent.py:117][0m Average action selection time: 0.0334
[32m[0906 16-22-26 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-22-26 @MBExp.py:227][0m Rewards obtained: [270.35871711189344], Lows: [1], Highs: [4], Total time: 5524.291156999999
[32m[0906 16-24-39 @MBExp.py:144][0m ####################################################################
[32m[0906 16-24-39 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 16-24-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03320, current rewards: -0.00379, mean: -0.00038
[32m[0906 16-24-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03360, current rewards: 5.58068, mean: 0.09301
[32m[0906 16-24-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03355, current rewards: 11.16572, mean: 0.10151
[32m[0906 16-24-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03356, current rewards: 16.75473, mean: 0.10472
[32m[0906 16-24-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03360, current rewards: 22.34377, mean: 0.10640
[32m[0906 16-24-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03363, current rewards: 27.93455, mean: 0.10744
[32m[0906 16-24-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03364, current rewards: 31.65860, mean: 0.10212
[32m[0906 16-24-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03364, current rewards: 37.30168, mean: 0.10362
[32m[0906 16-24-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03361, current rewards: 42.71763, mean: 0.10419
[32m[0906 16-24-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03360, current rewards: 48.27516, mean: 0.10495
[32m[0906 16-24-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03362, current rewards: 53.83501, mean: 0.10556
[32m[0906 16-24-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03361, current rewards: 57.63255, mean: 0.10292
[32m[0906 16-24-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03362, current rewards: 63.20413, mean: 0.10361
[32m[0906 16-25-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03361, current rewards: 68.77566, mean: 0.10421
[32m[0906 16-25-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03360, current rewards: 74.34466, mean: 0.10471
[32m[0906 16-25-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03360, current rewards: 79.91608, mean: 0.10515
[32m[0906 16-25-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03360, current rewards: 85.44727, mean: 0.10549
[32m[0906 16-25-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03361, current rewards: 91.04274, mean: 0.10586
[32m[0906 16-25-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03360, current rewards: 96.63732, mean: 0.10619
[32m[0906 16-25-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03361, current rewards: 100.06875, mean: 0.10424
[32m[0906 16-25-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03361, current rewards: 105.68827, mean: 0.10464
[32m[0906 16-25-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03361, current rewards: 111.25850, mean: 0.10496
[32m[0906 16-25-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03360, current rewards: 116.82888, mean: 0.10525
[32m[0906 16-25-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03361, current rewards: 122.39615, mean: 0.10551
[32m[0906 16-25-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03361, current rewards: 128.01194, mean: 0.10579
[32m[0906 16-25-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03361, current rewards: 133.57493, mean: 0.10601
[32m[0906 16-25-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03361, current rewards: 139.13835, mean: 0.10621
[32m[0906 16-25-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03356, current rewards: 144.70517, mean: 0.10640
[32m[0906 16-25-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03353, current rewards: 150.26809, mean: 0.10657
[32m[0906 16-25-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03351, current rewards: 155.82712, mean: 0.10673
[32m[0906 16-25-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03348, current rewards: 161.38720, mean: 0.10688
[32m[0906 16-25-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03346, current rewards: 166.94971, mean: 0.10702
[32m[0906 16-25-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03343, current rewards: 172.44370, mean: 0.10711
[32m[0906 16-25-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03341, current rewards: 175.89720, mean: 0.10596
[32m[0906 16-25-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03338, current rewards: 181.47456, mean: 0.10613
[32m[0906 16-25-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03336, current rewards: 187.03155, mean: 0.10627
[32m[0906 16-25-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03334, current rewards: 192.58835, mean: 0.10640
[32m[0906 16-25-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03332, current rewards: 198.14534, mean: 0.10653
[32m[0906 16-25-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03330, current rewards: 203.69925, mean: 0.10665
[32m[0906 16-25-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03328, current rewards: 209.25933, mean: 0.10676
[32m[0906 16-25-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03327, current rewards: 214.84124, mean: 0.10689
[32m[0906 16-25-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03327, current rewards: 220.39468, mean: 0.10699
[32m[0906 16-25-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03328, current rewards: 225.95327, mean: 0.10709
[32m[0906 16-25-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03329, current rewards: 231.50839, mean: 0.10718
[32m[0906 16-25-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03330, current rewards: 237.05988, mean: 0.10727
[32m[0906 16-25-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03330, current rewards: 242.61697, mean: 0.10735
[32m[0906 16-25-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03331, current rewards: 248.17290, mean: 0.10743
[32m[0906 16-25-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03332, current rewards: 253.72653, mean: 0.10751
[32m[0906 16-26-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03333, current rewards: 258.26403, mean: 0.10716
[32m[0906 16-26-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03334, current rewards: 264.08517, mean: 0.10735
[32m[0906 16-26-03 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 16-26-03 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-26-03 @MBExp.py:227][0m Rewards obtained: [268.6111047173229], Lows: [3], Highs: [4], Total time: 5608.342157999999
[32m[0906 16-28-18 @MBExp.py:144][0m ####################################################################
[32m[0906 16-28-18 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 16-28-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03275, current rewards: -1.12457, mean: -0.11246
[32m[0906 16-28-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03340, current rewards: 4.54752, mean: 0.07579
[32m[0906 16-28-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03357, current rewards: 10.21346, mean: 0.09285
[32m[0906 16-28-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03352, current rewards: 15.88747, mean: 0.09930
[32m[0906 16-28-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03353, current rewards: 21.55445, mean: 0.10264
[32m[0906 16-28-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03354, current rewards: 27.22841, mean: 0.10472
[32m[0906 16-28-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03355, current rewards: 28.76076, mean: 0.09278
[32m[0906 16-28-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03355, current rewards: 35.70175, mean: 0.09917
[32m[0906 16-28-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03358, current rewards: 44.00187, mean: 0.10732
[32m[0906 16-28-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03356, current rewards: 52.30199, mean: 0.11370
[32m[0906 16-28-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03356, current rewards: 60.60211, mean: 0.11883
[32m[0906 16-28-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03356, current rewards: 68.90223, mean: 0.12304
[32m[0906 16-28-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03356, current rewards: 77.20235, mean: 0.12656
[32m[0906 16-28-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03358, current rewards: 59.85041, mean: 0.09068
[32m[0906 16-28-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03359, current rewards: 9.85041, mean: 0.01387
[32m[0906 16-28-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03359, current rewards: -40.14959, mean: -0.05283
[32m[0906 16-28-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03360, current rewards: -90.14959, mean: -0.11130
[32m[0906 16-28-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03360, current rewards: -140.14959, mean: -0.16296
[32m[0906 16-28-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03359, current rewards: -190.14959, mean: -0.20896
[32m[0906 16-28-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03359, current rewards: -240.14959, mean: -0.25016
[32m[0906 16-28-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03359, current rewards: -290.14959, mean: -0.28728
[32m[0906 16-28-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03359, current rewards: -340.14959, mean: -0.32090
[32m[0906 16-28-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03359, current rewards: -390.14959, mean: -0.35149
[32m[0906 16-28-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03360, current rewards: -440.14959, mean: -0.37944
[32m[0906 16-28-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03359, current rewards: -490.14959, mean: -0.40508
[32m[0906 16-29-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03359, current rewards: -540.14959, mean: -0.42869
[32m[0906 16-29-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03354, current rewards: -590.14959, mean: -0.45050
[32m[0906 16-29-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03351, current rewards: -640.14959, mean: -0.47070
[32m[0906 16-29-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03347, current rewards: -690.14959, mean: -0.48947
[32m[0906 16-29-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03343, current rewards: -740.14959, mean: -0.50695
[32m[0906 16-29-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03340, current rewards: -790.14959, mean: -0.52328
[32m[0906 16-29-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03337, current rewards: -840.14959, mean: -0.53856
[32m[0906 16-29-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03335, current rewards: -890.14959, mean: -0.55289
[32m[0906 16-29-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03333, current rewards: -940.14959, mean: -0.56636
[32m[0906 16-29-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03331, current rewards: -990.14959, mean: -0.57903
[32m[0906 16-29-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03330, current rewards: -1040.14959, mean: -0.59099
[32m[0906 16-29-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03328, current rewards: -1090.14959, mean: -0.60229
[32m[0906 16-29-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03326, current rewards: -1140.14959, mean: -0.61298
[32m[0906 16-29-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03325, current rewards: -1190.14959, mean: -0.62311
[32m[0906 16-29-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03323, current rewards: -1240.14959, mean: -0.63273
[32m[0906 16-29-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03322, current rewards: -1290.14959, mean: -0.64187
[32m[0906 16-29-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03321, current rewards: -1340.14959, mean: -0.65056
[32m[0906 16-29-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03321, current rewards: -1390.14959, mean: -0.65884
[32m[0906 16-29-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03322, current rewards: -1440.14959, mean: -0.66674
[32m[0906 16-29-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03323, current rewards: -1490.14959, mean: -0.67428
[32m[0906 16-29-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03324, current rewards: -1540.14959, mean: -0.68148
[32m[0906 16-29-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03325, current rewards: -1590.14959, mean: -0.68838
[32m[0906 16-29-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03325, current rewards: -1640.14959, mean: -0.69498
[32m[0906 16-29-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03326, current rewards: -1690.14959, mean: -0.70131
[32m[0906 16-29-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03326, current rewards: -1740.14959, mean: -0.70738
[32m[0906 16-29-41 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 16-29-41 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-29-42 @MBExp.py:227][0m Rewards obtained: [-1780.1495854110292], Lows: [2], Highs: [1864], Total time: 5692.193560999998
[32m[0906 16-31-58 @MBExp.py:144][0m ####################################################################
[32m[0906 16-31-58 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 16-31-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03339, current rewards: -3.21763, mean: -0.32176
[32m[0906 16-32-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03347, current rewards: 2.29531, mean: 0.03826
[32m[0906 16-32-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03357, current rewards: 7.73949, mean: 0.07036
[32m[0906 16-32-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03355, current rewards: 13.18435, mean: 0.08240
[32m[0906 16-32-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03353, current rewards: 18.63188, mean: 0.08872
[32m[0906 16-32-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03360, current rewards: 24.07597, mean: 0.09260
[32m[0906 16-32-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03365, current rewards: 29.51708, mean: 0.09522
[32m[0906 16-32-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03369, current rewards: 35.06880, mean: 0.09741
[32m[0906 16-32-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03369, current rewards: 36.99506, mean: 0.09023
[32m[0906 16-32-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03365, current rewards: 43.04033, mean: 0.09357
[32m[0906 16-32-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03363, current rewards: 49.08560, mean: 0.09625
[32m[0906 16-32-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03364, current rewards: 55.13087, mean: 0.09845
[32m[0906 16-32-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03364, current rewards: 61.17614, mean: 0.10029
[32m[0906 16-32-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03363, current rewards: 67.22142, mean: 0.10185
[32m[0906 16-32-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03362, current rewards: 73.26669, mean: 0.10319
[32m[0906 16-32-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03362, current rewards: 68.87528, mean: 0.09063
[32m[0906 16-32-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03361, current rewards: 74.45883, mean: 0.09192
[32m[0906 16-32-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03360, current rewards: 80.04257, mean: 0.09307
[32m[0906 16-32-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03361, current rewards: 85.62414, mean: 0.09409
[32m[0906 16-32-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03360, current rewards: 91.20855, mean: 0.09501
[32m[0906 16-32-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03361, current rewards: 96.78874, mean: 0.09583
[32m[0906 16-32-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03361, current rewards: 102.36991, mean: 0.09658
[32m[0906 16-32-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03362, current rewards: 107.95267, mean: 0.09725
[32m[0906 16-32-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03361, current rewards: 112.36968, mean: 0.09687
[32m[0906 16-32-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03361, current rewards: 117.98025, mean: 0.09750
[32m[0906 16-32-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03359, current rewards: 123.59132, mean: 0.09809
[32m[0906 16-32-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03356, current rewards: 129.20930, mean: 0.09863
[32m[0906 16-32-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03353, current rewards: 134.82467, mean: 0.09914
[32m[0906 16-32-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03350, current rewards: 138.30643, mean: 0.09809
[32m[0906 16-32-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03347, current rewards: 143.90158, mean: 0.09856
[32m[0906 16-32-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03344, current rewards: 149.49855, mean: 0.09901
[32m[0906 16-32-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03341, current rewards: 155.02130, mean: 0.09937
[32m[0906 16-32-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03340, current rewards: 160.52405, mean: 0.09970
[32m[0906 16-32-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03338, current rewards: 166.12524, mean: 0.10008
[32m[0906 16-32-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03335, current rewards: 171.73914, mean: 0.10043
[32m[0906 16-32-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03333, current rewards: 176.24472, mean: 0.10014
[32m[0906 16-32-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03331, current rewards: 181.84685, mean: 0.10047
[32m[0906 16-33-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03330, current rewards: 187.44355, mean: 0.10078
[32m[0906 16-33-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03328, current rewards: 193.04048, mean: 0.10107
[32m[0906 16-33-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03326, current rewards: 198.63720, mean: 0.10135
[32m[0906 16-33-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03325, current rewards: 204.23735, mean: 0.10161
[32m[0906 16-33-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03323, current rewards: 209.84229, mean: 0.10187
[32m[0906 16-33-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03323, current rewards: 215.43726, mean: 0.10210
[32m[0906 16-33-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03323, current rewards: 221.03051, mean: 0.10233
[32m[0906 16-33-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03325, current rewards: 226.63345, mean: 0.10255
[32m[0906 16-33-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03325, current rewards: 232.23862, mean: 0.10276
[32m[0906 16-33-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03326, current rewards: 237.84400, mean: 0.10296
[32m[0906 16-33-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03327, current rewards: 243.44348, mean: 0.10315
[32m[0906 16-33-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03327, current rewards: 249.06818, mean: 0.10335
[32m[0906 16-33-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03330, current rewards: 254.66987, mean: 0.10352
[32m[0906 16-33-22 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 16-33-22 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-33-22 @MBExp.py:227][0m Rewards obtained: [259.15231561938174], Lows: [4], Highs: [13], Total time: 5776.135572999999
[32m[0906 16-35-41 @MBExp.py:144][0m ####################################################################
[32m[0906 16-35-41 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 16-35-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03244, current rewards: 0.11957, mean: 0.01196
[32m[0906 16-35-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03330, current rewards: 5.68874, mean: 0.09481
[32m[0906 16-35-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03341, current rewards: 11.25745, mean: 0.10234
[32m[0906 16-35-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03353, current rewards: 16.81932, mean: 0.10512
[32m[0906 16-35-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03350, current rewards: 22.38256, mean: 0.10658
[32m[0906 16-35-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03349, current rewards: 27.94553, mean: 0.10748
[32m[0906 16-35-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03349, current rewards: 33.32721, mean: 0.10751
[32m[0906 16-35-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03351, current rewards: 38.89454, mean: 0.10804
[32m[0906 16-35-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03352, current rewards: 43.30964, mean: 0.10563
[32m[0906 16-35-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03350, current rewards: 48.60473, mean: 0.10566
[32m[0906 16-35-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03351, current rewards: 53.90224, mean: 0.10569
[32m[0906 16-36-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03351, current rewards: 59.20181, mean: 0.10572
[32m[0906 16-36-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03351, current rewards: 64.49798, mean: 0.10573
[32m[0906 16-36-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03351, current rewards: 69.79130, mean: 0.10574
[32m[0906 16-36-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03351, current rewards: 75.19817, mean: 0.10591
[32m[0906 16-36-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03352, current rewards: 80.79794, mean: 0.10631
[32m[0906 16-36-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03352, current rewards: 86.27321, mean: 0.10651
[32m[0906 16-36-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03354, current rewards: 91.74970, mean: 0.10669
[32m[0906 16-36-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03355, current rewards: 97.22411, mean: 0.10684
[32m[0906 16-36-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03356, current rewards: 101.93691, mean: 0.10618
[32m[0906 16-36-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03357, current rewards: 107.34863, mean: 0.10629
[32m[0906 16-36-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03357, current rewards: 112.76611, mean: 0.10638
[32m[0906 16-36-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03358, current rewards: 118.18184, mean: 0.10647
[32m[0906 16-36-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03359, current rewards: 123.53721, mean: 0.10650
[32m[0906 16-36-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03360, current rewards: 124.71855, mean: 0.10307
[32m[0906 16-36-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03355, current rewards: 129.97891, mean: 0.10316
[32m[0906 16-36-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03351, current rewards: 135.23976, mean: 0.10324
[32m[0906 16-36-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03348, current rewards: 140.49912, mean: 0.10331
[32m[0906 16-36-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03345, current rewards: 145.75674, mean: 0.10337
[32m[0906 16-36-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03342, current rewards: 151.01599, mean: 0.10344
[32m[0906 16-36-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03340, current rewards: 156.27679, mean: 0.10349
[32m[0906 16-36-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03338, current rewards: 161.33607, mean: 0.10342
[32m[0906 16-36-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03336, current rewards: 166.45288, mean: 0.10339
[32m[0906 16-36-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03334, current rewards: 171.56593, mean: 0.10335
[32m[0906 16-36-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03332, current rewards: 176.68092, mean: 0.10332
[32m[0906 16-36-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03331, current rewards: 180.82761, mean: 0.10274
[32m[0906 16-36-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03329, current rewards: 186.32314, mean: 0.10294
[32m[0906 16-36-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03327, current rewards: 191.81418, mean: 0.10313
[32m[0906 16-36-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03327, current rewards: 197.30925, mean: 0.10330
[32m[0906 16-36-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03325, current rewards: 202.90711, mean: 0.10352
[32m[0906 16-36-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03324, current rewards: 208.47922, mean: 0.10372
[32m[0906 16-36-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03323, current rewards: 214.01209, mean: 0.10389
[32m[0906 16-36-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03322, current rewards: 219.54113, mean: 0.10405
[32m[0906 16-36-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03324, current rewards: 225.06946, mean: 0.10420
[32m[0906 16-36-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03324, current rewards: 230.59661, mean: 0.10434
[32m[0906 16-36-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03325, current rewards: 236.12428, mean: 0.10448
[32m[0906 16-36-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03327, current rewards: 240.23637, mean: 0.10400
[32m[0906 16-37-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03327, current rewards: 245.41016, mean: 0.10399
[32m[0906 16-37-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03328, current rewards: 250.36618, mean: 0.10389
[32m[0906 16-37-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03328, current rewards: 255.43809, mean: 0.10384
[32m[0906 16-37-05 @Agent.py:117][0m Average action selection time: 0.0333
[32m[0906 16-37-05 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-37-05 @MBExp.py:227][0m Rewards obtained: [259.4965382683522], Lows: [2], Highs: [5], Total time: 5860.053783999999
[32m[0906 16-39-26 @MBExp.py:144][0m ####################################################################
[32m[0906 16-39-26 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 16-39-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03262, current rewards: -1.09351, mean: -0.10935
[32m[0906 16-39-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03328, current rewards: 4.38029, mean: 0.07300
[32m[0906 16-39-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03338, current rewards: 9.79500, mean: 0.08905
[32m[0906 16-39-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03339, current rewards: 15.21426, mean: 0.09509
[32m[0906 16-39-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03341, current rewards: 20.63098, mean: 0.09824
[32m[0906 16-39-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03346, current rewards: 26.04703, mean: 0.10018
[32m[0906 16-39-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03344, current rewards: 31.45355, mean: 0.10146
[32m[0906 16-39-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03347, current rewards: 36.86064, mean: 0.10239
[32m[0906 16-39-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03348, current rewards: 42.26780, mean: 0.10309
[32m[0906 16-39-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03351, current rewards: 47.67867, mean: 0.10365
[32m[0906 16-39-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03351, current rewards: 51.02695, mean: 0.10005
[32m[0906 16-39-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03351, current rewards: 56.49566, mean: 0.10089
[32m[0906 16-39-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03351, current rewards: 61.96845, mean: 0.10159
[32m[0906 16-39-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03352, current rewards: 67.43772, mean: 0.10218
[32m[0906 16-39-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03351, current rewards: 73.01101, mean: 0.10283
[32m[0906 16-39-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03351, current rewards: 78.52297, mean: 0.10332
[32m[0906 16-39-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03351, current rewards: 83.96729, mean: 0.10366
[32m[0906 16-39-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03352, current rewards: 89.47133, mean: 0.10404
[32m[0906 16-39-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03353, current rewards: 94.97244, mean: 0.10437
[32m[0906 16-39-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03354, current rewards: 100.48237, mean: 0.10467
[32m[0906 16-40-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03354, current rewards: 105.99445, mean: 0.10494
[32m[0906 16-40-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03354, current rewards: 111.49818, mean: 0.10519
[32m[0906 16-40-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03355, current rewards: 116.99958, mean: 0.10541
[32m[0906 16-40-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03355, current rewards: 121.37236, mean: 0.10463
[32m[0906 16-40-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03353, current rewards: 126.95831, mean: 0.10492
[32m[0906 16-40-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03348, current rewards: 132.54134, mean: 0.10519
[32m[0906 16-40-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03344, current rewards: 138.11700, mean: 0.10543
[32m[0906 16-40-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03341, current rewards: 143.69296, mean: 0.10566
[32m[0906 16-40-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03338, current rewards: 149.27303, mean: 0.10587
[32m[0906 16-40-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03336, current rewards: 154.84376, mean: 0.10606
[32m[0906 16-40-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03333, current rewards: 160.40565, mean: 0.10623
[32m[0906 16-40-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03330, current rewards: 165.75742, mean: 0.10625
[32m[0906 16-40-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03329, current rewards: 171.21474, mean: 0.10634
[32m[0906 16-40-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03327, current rewards: 176.67262, mean: 0.10643
[32m[0906 16-40-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03325, current rewards: 177.82875, mean: 0.10399
[32m[0906 16-40-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03324, current rewards: 183.01739, mean: 0.10399
[32m[0906 16-40-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03322, current rewards: 188.20663, mean: 0.10398
[32m[0906 16-40-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03321, current rewards: 193.39160, mean: 0.10397
[32m[0906 16-40-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03320, current rewards: 198.57690, mean: 0.10397
[32m[0906 16-40-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03319, current rewards: 204.25291, mean: 0.10421
[32m[0906 16-40-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03317, current rewards: 210.56834, mean: 0.10476
[32m[0906 16-40-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03316, current rewards: 216.88376, mean: 0.10528
[32m[0906 16-40-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03314, current rewards: 223.19919, mean: 0.10578
[32m[0906 16-40-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03315, current rewards: 229.51461, mean: 0.10626
[32m[0906 16-40-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03316, current rewards: 235.83004, mean: 0.10671
[32m[0906 16-40-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03317, current rewards: 206.10359, mean: 0.09120
[32m[0906 16-40-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03318, current rewards: 156.10359, mean: 0.06758
[32m[0906 16-40-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03319, current rewards: 106.10359, mean: 0.04496
[32m[0906 16-40-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03320, current rewards: 56.10359, mean: 0.02328
[32m[0906 16-40-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03321, current rewards: 6.10359, mean: 0.00248
[32m[0906 16-40-49 @Agent.py:117][0m Average action selection time: 0.0332
[32m[0906 16-40-49 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-40-50 @MBExp.py:227][0m Rewards obtained: [-33.89641199922855], Lows: [3], Highs: [275], Total time: 5943.792077999999
[32m[0906 16-43-13 @MBExp.py:144][0m ####################################################################
[32m[0906 16-43-13 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 16-43-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03275, current rewards: 0.02601, mean: 0.00260
[32m[0906 16-43-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03361, current rewards: 5.55803, mean: 0.09263
[32m[0906 16-43-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03352, current rewards: 11.08521, mean: 0.10077
[32m[0906 16-43-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03350, current rewards: 16.61252, mean: 0.10383
[32m[0906 16-43-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03351, current rewards: 22.14262, mean: 0.10544
[32m[0906 16-43-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03353, current rewards: 27.67433, mean: 0.10644
[32m[0906 16-43-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03353, current rewards: 33.20994, mean: 0.10713
[32m[0906 16-43-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03356, current rewards: 38.74032, mean: 0.10761
[32m[0906 16-43-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03357, current rewards: 44.27194, mean: 0.10798
[32m[0906 16-43-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03357, current rewards: 49.80230, mean: 0.10827
[32m[0906 16-43-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03356, current rewards: 55.33161, mean: 0.10849
[32m[0906 16-43-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03357, current rewards: 60.82147, mean: 0.10861
[32m[0906 16-43-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03359, current rewards: 66.38308, mean: 0.10882
[32m[0906 16-43-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03358, current rewards: 71.95052, mean: 0.10902
[32m[0906 16-43-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03360, current rewards: 77.48905, mean: 0.10914
[32m[0906 16-43-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03361, current rewards: 83.05484, mean: 0.10928
[32m[0906 16-43-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03361, current rewards: 88.62244, mean: 0.10941
[32m[0906 16-43-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03361, current rewards: 94.19122, mean: 0.10952
[32m[0906 16-43-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03361, current rewards: 99.76018, mean: 0.10963
[32m[0906 16-43-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03361, current rewards: 103.26880, mean: 0.10757
[32m[0906 16-43-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03360, current rewards: 108.80983, mean: 0.10773
[32m[0906 16-43-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03360, current rewards: 114.34478, mean: 0.10787
[32m[0906 16-43-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03360, current rewards: 119.76612, mean: 0.10790
[32m[0906 16-43-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03356, current rewards: 125.29869, mean: 0.10802
[32m[0906 16-43-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03351, current rewards: 130.83520, mean: 0.10813
[32m[0906 16-43-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03347, current rewards: 136.36721, mean: 0.10823
[32m[0906 16-43-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03345, current rewards: 141.90696, mean: 0.10833
[32m[0906 16-43-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03342, current rewards: 147.43497, mean: 0.10841
[32m[0906 16-44-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03339, current rewards: 152.97387, mean: 0.10849
[32m[0906 16-44-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03338, current rewards: 158.50365, mean: 0.10856
[32m[0906 16-44-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03335, current rewards: 164.14459, mean: 0.10871
[32m[0906 16-44-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03333, current rewards: 169.68119, mean: 0.10877
[32m[0906 16-44-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03330, current rewards: 174.06551, mean: 0.10812
[32m[0906 16-44-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03327, current rewards: 179.59400, mean: 0.10819
[32m[0906 16-44-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03325, current rewards: 185.13117, mean: 0.10826
[32m[0906 16-44-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03323, current rewards: 190.66394, mean: 0.10833
[32m[0906 16-44-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03322, current rewards: 196.20035, mean: 0.10840
[32m[0906 16-44-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03320, current rewards: 201.73134, mean: 0.10846
[32m[0906 16-44-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03319, current rewards: 207.18217, mean: 0.10847
[32m[0906 16-44-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03318, current rewards: 212.70902, mean: 0.10853
[32m[0906 16-44-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03317, current rewards: 218.23841, mean: 0.10858
[32m[0906 16-44-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03316, current rewards: 223.76983, mean: 0.10863
[32m[0906 16-44-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03314, current rewards: 227.08218, mean: 0.10762
[32m[0906 16-44-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03314, current rewards: 232.17733, mean: 0.10749
[32m[0906 16-44-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03315, current rewards: 237.27243, mean: 0.10736
[32m[0906 16-44-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03316, current rewards: 242.36405, mean: 0.10724
[32m[0906 16-44-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03317, current rewards: 247.38979, mean: 0.10710
[32m[0906 16-44-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03317, current rewards: 252.40532, mean: 0.10695
[32m[0906 16-44-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03318, current rewards: 256.34712, mean: 0.10637
[32m[0906 16-44-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03319, current rewards: 261.87677, mean: 0.10645
[32m[0906 16-44-36 @Agent.py:117][0m Average action selection time: 0.0332
[32m[0906 16-44-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-44-36 @MBExp.py:227][0m Rewards obtained: [266.296650716068], Lows: [2], Highs: [3], Total time: 6027.474027999999
[32m[0906 16-47-01 @MBExp.py:144][0m ####################################################################
[32m[0906 16-47-01 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 16-47-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03236, current rewards: -1.16406, mean: -0.11641
[32m[0906 16-47-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03337, current rewards: 4.25376, mean: 0.07090
[32m[0906 16-47-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03347, current rewards: 9.66417, mean: 0.08786
[32m[0906 16-47-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03354, current rewards: 15.08434, mean: 0.09428
[32m[0906 16-47-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03349, current rewards: 20.50413, mean: 0.09764
[32m[0906 16-47-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03353, current rewards: 25.90951, mean: 0.09965
[32m[0906 16-47-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03356, current rewards: 31.32645, mean: 0.10105
[32m[0906 16-47-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03359, current rewards: 36.74822, mean: 0.10208
[32m[0906 16-47-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03355, current rewards: 42.17640, mean: 0.10287
[32m[0906 16-47-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03357, current rewards: 47.60099, mean: 0.10348
[32m[0906 16-47-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03359, current rewards: 51.09122, mean: 0.10018
[32m[0906 16-47-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03361, current rewards: 56.64651, mean: 0.10115
[32m[0906 16-47-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03360, current rewards: 62.19702, mean: 0.10196
[32m[0906 16-47-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03359, current rewards: 67.71703, mean: 0.10260
[32m[0906 16-47-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03358, current rewards: 73.38073, mean: 0.10335
[32m[0906 16-47-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03359, current rewards: 79.04738, mean: 0.10401
[32m[0906 16-47-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03358, current rewards: 84.70917, mean: 0.10458
[32m[0906 16-47-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03358, current rewards: 90.37386, mean: 0.10509
[32m[0906 16-47-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03358, current rewards: 96.03560, mean: 0.10553
[32m[0906 16-47-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03358, current rewards: 101.70027, mean: 0.10594
[32m[0906 16-47-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03359, current rewards: 106.20693, mean: 0.10516
[32m[0906 16-47-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03359, current rewards: 111.98996, mean: 0.10565
[32m[0906 16-47-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03360, current rewards: 117.44848, mean: 0.10581
[32m[0906 16-47-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03356, current rewards: 122.90935, mean: 0.10596
[32m[0906 16-47-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03353, current rewards: 128.36864, mean: 0.10609
[32m[0906 16-47-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03349, current rewards: 133.83008, mean: 0.10621
[32m[0906 16-47-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03345, current rewards: 139.28740, mean: 0.10633
[32m[0906 16-47-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03342, current rewards: 143.89011, mean: 0.10580
[32m[0906 16-47-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03339, current rewards: 151.96440, mean: 0.10778
[32m[0906 16-47-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03337, current rewards: 160.03868, mean: 0.10962
[32m[0906 16-47-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03334, current rewards: 166.13815, mean: 0.11003
[32m[0906 16-47-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03332, current rewards: 172.18341, mean: 0.11037
[32m[0906 16-47-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03329, current rewards: 178.22868, mean: 0.11070
[32m[0906 16-47-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03328, current rewards: 184.27394, mean: 0.11101
[32m[0906 16-47-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03326, current rewards: 184.71468, mean: 0.10802
[32m[0906 16-48-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03325, current rewards: 134.71468, mean: 0.07654
[32m[0906 16-48-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03324, current rewards: 84.71468, mean: 0.04680
[32m[0906 16-48-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03322, current rewards: 34.71468, mean: 0.01866
[32m[0906 16-48-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03320, current rewards: -15.28532, mean: -0.00800
[32m[0906 16-48-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03319, current rewards: -65.28532, mean: -0.03331
[32m[0906 16-48-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03318, current rewards: -115.28532, mean: -0.05736
[32m[0906 16-48-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03317, current rewards: -165.28532, mean: -0.08024
[32m[0906 16-48-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03316, current rewards: -215.28532, mean: -0.10203
[32m[0906 16-48-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03316, current rewards: -265.28532, mean: -0.12282
[32m[0906 16-48-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03317, current rewards: -315.28532, mean: -0.14266
[32m[0906 16-48-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03319, current rewards: -365.28532, mean: -0.16163
[32m[0906 16-48-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03320, current rewards: -415.28532, mean: -0.17978
[32m[0906 16-48-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03321, current rewards: -465.28532, mean: -0.19715
[32m[0906 16-48-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03322, current rewards: -515.28532, mean: -0.21381
[32m[0906 16-48-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03323, current rewards: -565.28532, mean: -0.22979
[32m[0906 16-48-25 @Agent.py:117][0m Average action selection time: 0.0332
[32m[0906 16-48-25 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-48-25 @MBExp.py:227][0m Rewards obtained: [-605.2853197824409], Lows: [2], Highs: [798], Total time: 6111.264565999999
[32m[0906 16-50-52 @MBExp.py:144][0m ####################################################################
[32m[0906 16-50-52 @MBExp.py:145][0m Starting training iteration 72.
[32m[0906 16-50-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03240, current rewards: 1.19194, mean: 0.11919
[32m[0906 16-50-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03348, current rewards: 6.71643, mean: 0.11194
[32m[0906 16-50-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03349, current rewards: 12.23657, mean: 0.11124
[32m[0906 16-50-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03354, current rewards: 17.75878, mean: 0.11099
[32m[0906 16-51-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03360, current rewards: 23.25077, mean: 0.11072
[32m[0906 16-51-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03358, current rewards: 28.75434, mean: 0.11059
[32m[0906 16-51-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03361, current rewards: 34.25759, mean: 0.11051
[32m[0906 16-51-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03359, current rewards: 38.57954, mean: 0.10717
[32m[0906 16-51-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03355, current rewards: 44.11903, mean: 0.10761
[32m[0906 16-51-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03358, current rewards: 49.64946, mean: 0.10793
[32m[0906 16-51-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03358, current rewards: 55.17742, mean: 0.10819
[32m[0906 16-51-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03358, current rewards: 60.70383, mean: 0.10840
[32m[0906 16-51-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03359, current rewards: 66.33266, mean: 0.10874
[32m[0906 16-51-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03361, current rewards: 71.85339, mean: 0.10887
[32m[0906 16-51-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03360, current rewards: 76.25981, mean: 0.10741
[32m[0906 16-51-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03360, current rewards: 81.79794, mean: 0.10763
[32m[0906 16-51-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03360, current rewards: 87.33275, mean: 0.10782
[32m[0906 16-51-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03361, current rewards: 92.86487, mean: 0.10798
[32m[0906 16-51-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03361, current rewards: 98.39459, mean: 0.10813
[32m[0906 16-51-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03362, current rewards: 103.92338, mean: 0.10825
[32m[0906 16-51-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03362, current rewards: 109.43196, mean: 0.10835
[32m[0906 16-51-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03362, current rewards: 114.97104, mean: 0.10846
[32m[0906 16-51-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03357, current rewards: 120.51679, mean: 0.10857
[32m[0906 16-51-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03353, current rewards: 126.06173, mean: 0.10867
[32m[0906 16-51-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03351, current rewards: 131.61094, mean: 0.10877
[32m[0906 16-51-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03347, current rewards: 135.20405, mean: 0.10730
[32m[0906 16-51-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03343, current rewards: 140.73119, mean: 0.10743
[32m[0906 16-51-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03341, current rewards: 146.26410, mean: 0.10755
[32m[0906 16-51-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03338, current rewards: 151.76220, mean: 0.10763
[32m[0906 16-51-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03336, current rewards: 157.10755, mean: 0.10761
[32m[0906 16-51-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03333, current rewards: 161.48667, mean: 0.10694
[32m[0906 16-51-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03332, current rewards: 167.00279, mean: 0.10705
[32m[0906 16-51-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03329, current rewards: 172.52165, mean: 0.10716
[32m[0906 16-51-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03327, current rewards: 178.04279, mean: 0.10725
[32m[0906 16-51-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03325, current rewards: 183.56236, mean: 0.10735
[32m[0906 16-51-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03324, current rewards: 189.08484, mean: 0.10743
[32m[0906 16-51-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03323, current rewards: 194.60255, mean: 0.10752
[32m[0906 16-51-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03322, current rewards: 200.18835, mean: 0.10763
[32m[0906 16-51-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03320, current rewards: 205.70789, mean: 0.10770
[32m[0906 16-51-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03319, current rewards: 211.22593, mean: 0.10777
[32m[0906 16-52-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03317, current rewards: 216.74240, mean: 0.10783
[32m[0906 16-52-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03316, current rewards: 222.25586, mean: 0.10789
[32m[0906 16-52-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03315, current rewards: 227.75413, mean: 0.10794
[32m[0906 16-52-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03315, current rewards: 233.29722, mean: 0.10801
[32m[0906 16-52-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03316, current rewards: 238.83892, mean: 0.10807
[32m[0906 16-52-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03317, current rewards: 244.54145, mean: 0.10820
[32m[0906 16-52-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03318, current rewards: 250.05606, mean: 0.10825
[32m[0906 16-52-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03318, current rewards: 255.53065, mean: 0.10828
[32m[0906 16-52-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03319, current rewards: 261.06211, mean: 0.10832
[32m[0906 16-52-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03320, current rewards: 266.59116, mean: 0.10837
[32m[0906 16-52-16 @Agent.py:117][0m Average action selection time: 0.0332
[32m[0906 16-52-16 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-52-16 @MBExp.py:227][0m Rewards obtained: [271.02057925353625], Lows: [1], Highs: [3], Total time: 6194.984443999999
[32m[0906 16-54-45 @MBExp.py:144][0m ####################################################################
[32m[0906 16-54-45 @MBExp.py:145][0m Starting training iteration 73.
[32m[0906 16-54-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03272, current rewards: 0.04039, mean: 0.00404
[32m[0906 16-54-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03342, current rewards: 5.60029, mean: 0.09334
[32m[0906 16-54-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03355, current rewards: 11.12754, mean: 0.10116
[32m[0906 16-54-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03352, current rewards: 16.64099, mean: 0.10401
[32m[0906 16-54-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03355, current rewards: 22.25699, mean: 0.10599
[32m[0906 16-54-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03357, current rewards: 27.84231, mean: 0.10709
[32m[0906 16-54-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03360, current rewards: 33.38745, mean: 0.10770
[32m[0906 16-54-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03359, current rewards: 38.93356, mean: 0.10815
[32m[0906 16-54-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03358, current rewards: 32.92280, mean: 0.08030
[32m[0906 16-55-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03366, current rewards: 24.26599, mean: 0.05275
[32m[0906 16-55-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03369, current rewards: 17.63872, mean: 0.03459
[32m[0906 16-55-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03377, current rewards: 11.05231, mean: 0.01974
[32m[0906 16-55-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03379, current rewards: 4.29624, mean: 0.00704
[32m[0906 16-55-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03400, current rewards: -9.65253, mean: -0.01463
[32m[0906 16-55-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03418, current rewards: -16.64578, mean: -0.02344
[32m[0906 16-55-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03422, current rewards: -25.54490, mean: -0.03361
[32m[0906 16-55-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03418, current rewards: -21.74565, mean: -0.02685
[32m[0906 16-55-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03414, current rewards: -17.94640, mean: -0.02087
[32m[0906 16-55-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03410, current rewards: -14.14716, mean: -0.01555
[32m[0906 16-55-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03408, current rewards: -10.34791, mean: -0.01078
[32m[0906 16-55-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03406, current rewards: -19.70986, mean: -0.01951
[32m[0906 16-55-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03402, current rewards: -69.70986, mean: -0.06576
[32m[0906 16-55-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03396, current rewards: -119.70986, mean: -0.10785
[32m[0906 16-55-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03391, current rewards: -169.70986, mean: -0.14630
[32m[0906 16-55-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03387, current rewards: -219.70986, mean: -0.18158
[32m[0906 16-55-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03379, current rewards: -269.70986, mean: -0.21406
[32m[0906 16-55-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03376, current rewards: -319.70986, mean: -0.24405
[32m[0906 16-55-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03372, current rewards: -369.70986, mean: -0.27185
[32m[0906 16-55-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03368, current rewards: -419.70986, mean: -0.29767
[32m[0906 16-55-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03364, current rewards: -469.70986, mean: -0.32172
[32m[0906 16-55-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03361, current rewards: -519.70986, mean: -0.34418
[32m[0906 16-55-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03358, current rewards: -569.70986, mean: -0.36520
[32m[0906 16-55-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03355, current rewards: -619.70986, mean: -0.38491
[32m[0906 16-55-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03352, current rewards: -669.70986, mean: -0.40344
[32m[0906 16-55-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03350, current rewards: -719.70986, mean: -0.42088
[32m[0906 16-55-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03347, current rewards: -769.70986, mean: -0.43734
[32m[0906 16-55-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03345, current rewards: -819.70986, mean: -0.45288
[32m[0906 16-55-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03342, current rewards: -869.70986, mean: -0.46759
[32m[0906 16-55-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03341, current rewards: -919.70986, mean: -0.48152
[32m[0906 16-55-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03339, current rewards: -969.70986, mean: -0.49475
[32m[0906 16-55-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03337, current rewards: -1019.70986, mean: -0.50732
[32m[0906 16-55-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03336, current rewards: -1069.70986, mean: -0.51928
[32m[0906 16-55-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03335, current rewards: -1119.70986, mean: -0.53067
[32m[0906 16-55-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03334, current rewards: -1169.70986, mean: -0.54153
[32m[0906 16-55-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03335, current rewards: -1219.70986, mean: -0.55190
[32m[0906 16-56-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03345, current rewards: -1231.79408, mean: -0.54504
[32m[0906 16-56-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03358, current rewards: -1221.58661, mean: -0.52883
[32m[0906 16-56-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03372, current rewards: -1212.37020, mean: -0.51372
[32m[0906 16-56-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03381, current rewards: -1210.70235, mean: -0.50237
[32m[0906 16-56-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03388, current rewards: -1213.70194, mean: -0.49337
[32m[0906 16-56-11 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 16-56-11 @Agent.py:118][0m Rollout length: 2501
[32m[0906 16-56-11 @MBExp.py:227][0m Rewards obtained: [-1210.4024190388245], Lows: [66], Highs: [1233], Total time: 6280.392009999999
[32m[0906 16-58-42 @MBExp.py:144][0m ####################################################################
[32m[0906 16-58-42 @MBExp.py:145][0m Starting training iteration 74.
[32m[0906 16-58-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03291, current rewards: -0.12727, mean: -0.01273
[32m[0906 16-58-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03347, current rewards: 5.10429, mean: 0.08507
[32m[0906 16-58-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03359, current rewards: 10.33349, mean: 0.09394
[32m[0906 16-58-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03365, current rewards: 15.65797, mean: 0.09786
[32m[0906 16-58-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03361, current rewards: 20.93695, mean: 0.09970
[32m[0906 16-58-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03364, current rewards: 26.21296, mean: 0.10082
[32m[0906 16-58-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03361, current rewards: 27.51595, mean: 0.08876
[32m[0906 16-58-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03360, current rewards: 33.32654, mean: 0.09257
[32m[0906 16-58-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03360, current rewards: 39.13367, mean: 0.09545
[32m[0906 16-58-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03361, current rewards: 44.94450, mean: 0.09771
[32m[0906 16-58-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03361, current rewards: 50.75671, mean: 0.09952
[32m[0906 16-59-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03360, current rewards: 56.56774, mean: 0.10101
[32m[0906 16-59-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03361, current rewards: 62.21667, mean: 0.10199
[32m[0906 16-59-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03362, current rewards: 67.92503, mean: 0.10292
[32m[0906 16-59-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03363, current rewards: 73.63334, mean: 0.10371
[32m[0906 16-59-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03363, current rewards: 79.34510, mean: 0.10440
[32m[0906 16-59-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03363, current rewards: 85.05134, mean: 0.10500
[32m[0906 16-59-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03363, current rewards: 90.75990, mean: 0.10553
[32m[0906 16-59-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03363, current rewards: 96.47023, mean: 0.10601
[32m[0906 16-59-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03363, current rewards: 102.18031, mean: 0.10644
[32m[0906 16-59-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03359, current rewards: 106.42520, mean: 0.10537
[32m[0906 16-59-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03354, current rewards: 111.78276, mean: 0.10546
[32m[0906 16-59-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03349, current rewards: 117.13802, mean: 0.10553
[32m[0906 16-59-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03346, current rewards: 122.48837, mean: 0.10559
[32m[0906 16-59-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03344, current rewards: 127.84102, mean: 0.10565
[32m[0906 16-59-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03339, current rewards: 133.17518, mean: 0.10569
[32m[0906 16-59-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03337, current rewards: 138.45482, mean: 0.10569
[32m[0906 16-59-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03335, current rewards: 143.74052, mean: 0.10569
[32m[0906 16-59-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03331, current rewards: 149.05399, mean: 0.10571
[32m[0906 16-59-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03329, current rewards: 154.27165, mean: 0.10567
[32m[0906 16-59-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03327, current rewards: 159.49178, mean: 0.10562
[32m[0906 16-59-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03325, current rewards: 164.71165, mean: 0.10558
[32m[0906 16-59-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03324, current rewards: 169.92093, mean: 0.10554
[32m[0906 16-59-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03321, current rewards: 175.13962, mean: 0.10551
[32m[0906 16-59-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03320, current rewards: 180.34939, mean: 0.10547
[32m[0906 16-59-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03318, current rewards: 183.69668, mean: 0.10437
[32m[0906 16-59-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03316, current rewards: 189.31407, mean: 0.10459
[32m[0906 16-59-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03315, current rewards: 195.02590, mean: 0.10485
[32m[0906 16-59-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03313, current rewards: 200.73756, mean: 0.10510
[32m[0906 16-59-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03313, current rewards: 206.45319, mean: 0.10533
[32m[0906 16-59-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03311, current rewards: 212.16964, mean: 0.10556
[32m[0906 16-59-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03309, current rewards: 217.88345, mean: 0.10577
[32m[0906 16-59-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03309, current rewards: 223.60158, mean: 0.10597
[32m[0906 16-59-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03309, current rewards: 229.31203, mean: 0.10616
[32m[0906 16-59-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03310, current rewards: 235.12201, mean: 0.10639
[32m[0906 16-59-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03312, current rewards: 240.39493, mean: 0.10637
[32m[0906 16-59-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03313, current rewards: 245.60130, mean: 0.10632
[32m[0906 17-00-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03314, current rewards: 250.79425, mean: 0.10627
[32m[0906 17-00-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03315, current rewards: 255.98806, mean: 0.10622
[32m[0906 17-00-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03316, current rewards: 261.16651, mean: 0.10617
[32m[0906 17-00-06 @Agent.py:117][0m Average action selection time: 0.0332
[32m[0906 17-00-06 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-00-06 @MBExp.py:227][0m Rewards obtained: [265.31565154065424], Lows: [3], Highs: [3], Total time: 6364.032125999998
[32m[0906 17-02-39 @MBExp.py:144][0m ####################################################################
[32m[0906 17-02-39 @MBExp.py:145][0m Starting training iteration 75.
[32m[0906 17-02-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03284, current rewards: 1.07783, mean: 0.10778
[32m[0906 17-02-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03340, current rewards: 7.00682, mean: 0.11678
[32m[0906 17-02-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03349, current rewards: 13.03680, mean: 0.11852
[32m[0906 17-02-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03354, current rewards: 19.65016, mean: 0.12281
[32m[0906 17-02-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03357, current rewards: 27.50970, mean: 0.13100
[32m[0906 17-02-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03357, current rewards: 35.36924, mean: 0.13604
[32m[0906 17-02-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03355, current rewards: 43.22878, mean: 0.13945
[32m[0906 17-02-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03351, current rewards: -6.77122, mean: -0.01881
[32m[0906 17-02-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03354, current rewards: -56.77122, mean: -0.13847
[32m[0906 17-02-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03355, current rewards: -106.77122, mean: -0.23211
[32m[0906 17-02-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03356, current rewards: -156.77122, mean: -0.30739
[32m[0906 17-02-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03355, current rewards: -206.77122, mean: -0.36923
[32m[0906 17-03-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03355, current rewards: -237.63011, mean: -0.38956
[32m[0906 17-03-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03354, current rewards: -232.06836, mean: -0.35162
[32m[0906 17-03-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03355, current rewards: -228.62979, mean: -0.32201
[32m[0906 17-03-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03355, current rewards: -223.01125, mean: -0.29344
[32m[0906 17-03-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03357, current rewards: -217.39294, mean: -0.26839
[32m[0906 17-03-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03358, current rewards: -211.77781, mean: -0.24625
[32m[0906 17-03-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03358, current rewards: -206.16521, mean: -0.22656
[32m[0906 17-03-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03356, current rewards: -200.54604, mean: -0.20890
[32m[0906 17-03-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03351, current rewards: -194.68527, mean: -0.19276
[32m[0906 17-03-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03347, current rewards: -189.06744, mean: -0.17837
[32m[0906 17-03-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03344, current rewards: -183.48677, mean: -0.16530
[32m[0906 17-03-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03340, current rewards: -177.84550, mean: -0.15332
[32m[0906 17-03-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03338, current rewards: -172.20919, mean: -0.14232
[32m[0906 17-03-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03335, current rewards: -166.56964, mean: -0.13220
[32m[0906 17-03-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03331, current rewards: -160.93432, mean: -0.12285
[32m[0906 17-03-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03329, current rewards: -155.29405, mean: -0.11419
[32m[0906 17-03-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03326, current rewards: -149.66144, mean: -0.10614
[32m[0906 17-03-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03324, current rewards: -144.19480, mean: -0.09876
[32m[0906 17-03-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03322, current rewards: -138.56006, mean: -0.09176
[32m[0906 17-03-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03320, current rewards: -132.93034, mean: -0.08521
[32m[0906 17-03-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03319, current rewards: -127.30006, mean: -0.07907
[32m[0906 17-03-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03317, current rewards: -121.67626, mean: -0.07330
[32m[0906 17-03-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03315, current rewards: -116.05137, mean: -0.06787
[32m[0906 17-03-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03314, current rewards: -110.43325, mean: -0.06275
[32m[0906 17-03-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03313, current rewards: -104.81054, mean: -0.05791
[32m[0906 17-03-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03312, current rewards: -99.01318, mean: -0.05323
[32m[0906 17-03-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03311, current rewards: -93.37607, mean: -0.04889
[32m[0906 17-03-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03309, current rewards: -87.73904, mean: -0.04476
[32m[0906 17-03-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03309, current rewards: -84.07485, mean: -0.04183
[32m[0906 17-03-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03307, current rewards: -78.41227, mean: -0.03806
[32m[0906 17-03-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03306, current rewards: -72.74122, mean: -0.03447
[32m[0906 17-03-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03306, current rewards: -67.07094, mean: -0.03105
[32m[0906 17-03-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03307, current rewards: -61.40623, mean: -0.02779
[32m[0906 17-03-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03308, current rewards: -55.72381, mean: -0.02466
[32m[0906 17-03-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03309, current rewards: -52.16944, mean: -0.02258
[32m[0906 17-03-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03310, current rewards: -45.42393, mean: -0.01925
[32m[0906 17-03-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03312, current rewards: -39.39064, mean: -0.01634
[32m[0906 17-04-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03313, current rewards: -33.35417, mean: -0.01356
[32m[0906 17-04-02 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 17-04-02 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-04-03 @MBExp.py:227][0m Rewards obtained: [-28.52793401593454], Lows: [3], Highs: [283], Total time: 6447.602473999998
[32m[0906 17-06-38 @MBExp.py:144][0m ####################################################################
[32m[0906 17-06-38 @MBExp.py:145][0m Starting training iteration 76.
[32m[0906 17-06-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03302, current rewards: -15.93841, mean: -1.59384
[32m[0906 17-06-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03343, current rewards: -115.93841, mean: -1.93231
[32m[0906 17-06-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03354, current rewards: -215.93841, mean: -1.96308
[32m[0906 17-06-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03363, current rewards: -315.93841, mean: -1.97462
[32m[0906 17-06-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03362, current rewards: -415.93841, mean: -1.98066
[32m[0906 17-06-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03368, current rewards: -515.93841, mean: -1.98438
[32m[0906 17-06-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03366, current rewards: -615.93841, mean: -1.98690
[32m[0906 17-06-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03365, current rewards: -715.93841, mean: -1.98872
[32m[0906 17-06-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03363, current rewards: -813.59081, mean: -1.98437
[32m[0906 17-06-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03364, current rewards: -913.59081, mean: -1.98607
[32m[0906 17-06-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03364, current rewards: -1013.59081, mean: -1.98743
[32m[0906 17-06-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03363, current rewards: -1113.59081, mean: -1.98856
[32m[0906 17-06-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03363, current rewards: -1213.59081, mean: -1.98949
[32m[0906 17-07-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03364, current rewards: -1288.52897, mean: -1.95232
[32m[0906 17-07-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03363, current rewards: -1278.07246, mean: -1.80010
[32m[0906 17-07-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03364, current rewards: -1268.58562, mean: -1.66919
[32m[0906 17-07-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03363, current rewards: -1259.09751, mean: -1.55444
[32m[0906 17-07-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03364, current rewards: -1249.60468, mean: -1.45303
[32m[0906 17-07-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03364, current rewards: -1240.09077, mean: -1.36274
[32m[0906 17-07-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03359, current rewards: -1230.60491, mean: -1.28188
[32m[0906 17-07-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03355, current rewards: -1221.11721, mean: -1.20903
[32m[0906 17-07-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03351, current rewards: -1214.23634, mean: -1.14551
[32m[0906 17-07-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03348, current rewards: -1208.71969, mean: -1.08894
[32m[0906 17-07-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03344, current rewards: -1203.20473, mean: -1.03725
[32m[0906 17-07-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03342, current rewards: -1197.68485, mean: -0.98982
[32m[0906 17-07-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03339, current rewards: -1267.99288, mean: -1.00634
[32m[0906 17-07-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03336, current rewards: -1367.99288, mean: -1.04427
[32m[0906 17-07-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03333, current rewards: -1467.99288, mean: -1.07941
[32m[0906 17-07-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03332, current rewards: -1567.99288, mean: -1.11205
[32m[0906 17-07-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03328, current rewards: -1667.99288, mean: -1.14246
[32m[0906 17-07-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03326, current rewards: -1767.99288, mean: -1.17086
[32m[0906 17-07-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03325, current rewards: -1867.99288, mean: -1.19743
[32m[0906 17-07-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03323, current rewards: -1967.99288, mean: -1.22236
[32m[0906 17-07-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03321, current rewards: -2032.55116, mean: -1.22443
[32m[0906 17-07-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03320, current rewards: -2077.02742, mean: -1.21464
[32m[0906 17-07-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03319, current rewards: -2121.50084, mean: -1.20540
[32m[0906 17-07-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03317, current rewards: -2165.98269, mean: -1.19668
[32m[0906 17-07-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03316, current rewards: -2210.56125, mean: -1.18847
[32m[0906 17-07-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03314, current rewards: -2256.46636, mean: -1.18140
[32m[0906 17-07-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03314, current rewards: -2302.36782, mean: -1.17468
[32m[0906 17-07-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03313, current rewards: -2348.26295, mean: -1.16829
[32m[0906 17-07-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03312, current rewards: -2394.17308, mean: -1.16222
[32m[0906 17-07-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03312, current rewards: -2473.26689, mean: -1.17216
[32m[0906 17-07-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03312, current rewards: -2573.26689, mean: -1.19133
[32m[0906 17-07-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03313, current rewards: -2673.26689, mean: -1.20962
[32m[0906 17-07-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03314, current rewards: -2773.26689, mean: -1.22711
[32m[0906 17-07-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03315, current rewards: -2873.26689, mean: -1.24384
[32m[0906 17-07-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03317, current rewards: -2973.26689, mean: -1.25986
[32m[0906 17-07-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03318, current rewards: -3073.26689, mean: -1.27521
[32m[0906 17-08-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03319, current rewards: -3173.26689, mean: -1.28995
[32m[0906 17-08-01 @Agent.py:117][0m Average action selection time: 0.0332
[32m[0906 17-08-01 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-08-01 @MBExp.py:227][0m Rewards obtained: [-3253.266890110469], Lows: [1694], Highs: [4], Total time: 6531.312064999998
[32m[0906 17-10-39 @MBExp.py:144][0m ####################################################################
[32m[0906 17-10-39 @MBExp.py:145][0m Starting training iteration 77.
[32m[0906 17-10-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03269, current rewards: 0.01403, mean: 0.00140
[32m[0906 17-10-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03347, current rewards: 5.56404, mean: 0.09273
[32m[0906 17-10-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03361, current rewards: 11.11329, mean: 0.10103
[32m[0906 17-10-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03358, current rewards: 16.66270, mean: 0.10414
[32m[0906 17-10-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03357, current rewards: 20.98853, mean: 0.09995
[32m[0906 17-10-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03361, current rewards: 26.53343, mean: 0.10205
[32m[0906 17-10-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03358, current rewards: 32.07792, mean: 0.10348
[32m[0906 17-10-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03356, current rewards: 37.62411, mean: 0.10451
[32m[0906 17-10-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03353, current rewards: 43.16850, mean: 0.10529
[32m[0906 17-10-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03353, current rewards: 46.79296, mean: 0.10172
[32m[0906 17-10-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03355, current rewards: 52.31071, mean: 0.10257
[32m[0906 17-10-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03355, current rewards: 57.82782, mean: 0.10326
[32m[0906 17-10-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03358, current rewards: 63.61556, mean: 0.10429
[32m[0906 17-11-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03358, current rewards: 69.53343, mean: 0.10535
[32m[0906 17-11-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03358, current rewards: 75.45131, mean: 0.10627
[32m[0906 17-11-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03357, current rewards: 81.36918, mean: 0.10706
[32m[0906 17-11-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03357, current rewards: 87.28705, mean: 0.10776
[32m[0906 17-11-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03357, current rewards: 93.20493, mean: 0.10838
[32m[0906 17-11-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03357, current rewards: 99.12280, mean: 0.10893
[32m[0906 17-11-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03351, current rewards: 105.04068, mean: 0.10942
[32m[0906 17-11-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03346, current rewards: 55.04068, mean: 0.05450
[32m[0906 17-11-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03341, current rewards: 5.04068, mean: 0.00476
[32m[0906 17-11-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03338, current rewards: -44.95932, mean: -0.04050
[32m[0906 17-11-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03335, current rewards: -94.95932, mean: -0.08186
[32m[0906 17-11-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03333, current rewards: -144.95932, mean: -0.11980
[32m[0906 17-11-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03329, current rewards: -194.95932, mean: -0.15473
[32m[0906 17-11-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03326, current rewards: -244.95932, mean: -0.18699
[32m[0906 17-11-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03323, current rewards: -294.95932, mean: -0.21688
[32m[0906 17-11-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03321, current rewards: -344.95932, mean: -0.24465
[32m[0906 17-11-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03319, current rewards: -394.95932, mean: -0.27052
[32m[0906 17-11-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03317, current rewards: -444.95932, mean: -0.29468
[32m[0906 17-11-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03317, current rewards: -494.95932, mean: -0.31728
[32m[0906 17-11-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03316, current rewards: -544.95932, mean: -0.33848
[32m[0906 17-11-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03315, current rewards: -594.95932, mean: -0.35841
[32m[0906 17-11-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03314, current rewards: -644.95932, mean: -0.37717
[32m[0906 17-11-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03313, current rewards: -694.95932, mean: -0.39486
[32m[0906 17-11-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03312, current rewards: -744.95932, mean: -0.41158
[32m[0906 17-11-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03310, current rewards: -794.95932, mean: -0.42740
[32m[0906 17-11-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03309, current rewards: -844.95932, mean: -0.44239
[32m[0906 17-11-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03308, current rewards: -894.95932, mean: -0.45661
[32m[0906 17-11-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03307, current rewards: -944.95932, mean: -0.47013
[32m[0906 17-11-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03306, current rewards: -994.95932, mean: -0.48299
[32m[0906 17-11-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03306, current rewards: -1044.95932, mean: -0.49524
[32m[0906 17-11-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03305, current rewards: -1094.95932, mean: -0.50693
[32m[0906 17-11-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03306, current rewards: -1144.95932, mean: -0.51808
[32m[0906 17-11-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03307, current rewards: -1194.95932, mean: -0.52874
[32m[0906 17-11-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03308, current rewards: -1244.95932, mean: -0.53894
[32m[0906 17-11-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03310, current rewards: -1294.95932, mean: -0.54871
[32m[0906 17-11-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03312, current rewards: -1344.95932, mean: -0.55807
[32m[0906 17-12-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03313, current rewards: -1394.95932, mean: -0.56706
[32m[0906 17-12-02 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 17-12-02 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-12-02 @MBExp.py:227][0m Rewards obtained: [-1434.9593214818121], Lows: [1], Highs: [1542], Total time: 6614.861893999998
[32m[0906 17-14-42 @MBExp.py:144][0m ####################################################################
[32m[0906 17-14-42 @MBExp.py:145][0m Starting training iteration 78.
[32m[0906 17-14-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03388, current rewards: 1.00056, mean: 0.10006
[32m[0906 17-14-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03360, current rewards: 6.46078, mean: 0.10768
[32m[0906 17-14-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03358, current rewards: 11.99583, mean: 0.10905
[32m[0906 17-14-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03362, current rewards: 17.53038, mean: 0.10956
[32m[0906 17-14-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03355, current rewards: 23.15246, mean: 0.11025
[32m[0906 17-14-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03356, current rewards: 28.68595, mean: 0.11033
[32m[0906 17-14-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03354, current rewards: 34.21632, mean: 0.11038
[32m[0906 17-14-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03355, current rewards: 39.74775, mean: 0.11041
[32m[0906 17-14-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03352, current rewards: 44.12567, mean: 0.10762
[32m[0906 17-14-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03353, current rewards: 49.65506, mean: 0.10795
[32m[0906 17-14-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03354, current rewards: 55.18905, mean: 0.10821
[32m[0906 17-15-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03355, current rewards: 60.72030, mean: 0.10843
[32m[0906 17-15-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03355, current rewards: 66.14050, mean: 0.10843
[32m[0906 17-15-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03354, current rewards: 71.66325, mean: 0.10858
[32m[0906 17-15-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03356, current rewards: 77.19163, mean: 0.10872
[32m[0906 17-15-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03355, current rewards: 82.71988, mean: 0.10884
[32m[0906 17-15-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03357, current rewards: 88.24764, mean: 0.10895
[32m[0906 17-15-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03357, current rewards: 93.77446, mean: 0.10904
[32m[0906 17-15-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03353, current rewards: 99.30528, mean: 0.10913
[32m[0906 17-15-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03349, current rewards: 104.83538, mean: 0.10920
[32m[0906 17-15-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03346, current rewards: 110.60342, mean: 0.10951
[32m[0906 17-15-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03344, current rewards: 116.14586, mean: 0.10957
[32m[0906 17-15-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03340, current rewards: 120.55474, mean: 0.10861
[32m[0906 17-15-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03337, current rewards: 126.08130, mean: 0.10869
[32m[0906 17-15-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03334, current rewards: 131.60858, mean: 0.10877
[32m[0906 17-15-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03331, current rewards: 137.13510, mean: 0.10884
[32m[0906 17-15-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03328, current rewards: 142.66473, mean: 0.10890
[32m[0906 17-15-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03325, current rewards: 148.19094, mean: 0.10896
[32m[0906 17-15-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03324, current rewards: 153.70949, mean: 0.10901
[32m[0906 17-15-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03322, current rewards: 159.19940, mean: 0.10904
[32m[0906 17-15-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03320, current rewards: 164.71938, mean: 0.10909
[32m[0906 17-15-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03319, current rewards: 170.24613, mean: 0.10913
[32m[0906 17-15-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03316, current rewards: 175.77257, mean: 0.10918
[32m[0906 17-15-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03315, current rewards: 181.29545, mean: 0.10921
[32m[0906 17-15-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03314, current rewards: 186.58388, mean: 0.10911
[32m[0906 17-15-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03312, current rewards: 191.84456, mean: 0.10900
[32m[0906 17-15-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03311, current rewards: 197.10110, mean: 0.10890
[32m[0906 17-15-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03310, current rewards: 202.58781, mean: 0.10892
[32m[0906 17-15-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03310, current rewards: 207.87668, mean: 0.10884
[32m[0906 17-15-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03309, current rewards: 211.42741, mean: 0.10787
[32m[0906 17-15-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03308, current rewards: 216.99156, mean: 0.10796
[32m[0906 17-15-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03307, current rewards: 222.55497, mean: 0.10804
[32m[0906 17-15-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03307, current rewards: 228.11946, mean: 0.10811
[32m[0906 17-15-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03306, current rewards: 232.60026, mean: 0.10769
[32m[0906 17-15-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03307, current rewards: 238.09509, mean: 0.10774
[32m[0906 17-15-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03308, current rewards: 243.60188, mean: 0.10779
[32m[0906 17-15-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03309, current rewards: 249.10451, mean: 0.10784
[32m[0906 17-16-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03310, current rewards: 254.60732, mean: 0.10788
[32m[0906 17-16-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03311, current rewards: 260.11292, mean: 0.10793
[32m[0906 17-16-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03312, current rewards: 265.61383, mean: 0.10797
[32m[0906 17-16-05 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 17-16-05 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-16-05 @MBExp.py:227][0m Rewards obtained: [270.01747041923505], Lows: [1], Highs: [3], Total time: 6698.410141999998
[32m[0906 17-18-46 @MBExp.py:144][0m ####################################################################
[32m[0906 17-18-46 @MBExp.py:145][0m Starting training iteration 79.
[32m[0906 17-18-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03308, current rewards: -3.20588, mean: -0.32059
[32m[0906 17-18-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03362, current rewards: 2.30036, mean: 0.03834
[32m[0906 17-18-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03354, current rewards: 7.81053, mean: 0.07100
[32m[0906 17-18-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03358, current rewards: 13.44964, mean: 0.08406
[32m[0906 17-18-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03361, current rewards: 19.01478, mean: 0.09055
[32m[0906 17-18-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03356, current rewards: 24.59224, mean: 0.09459
[32m[0906 17-18-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03358, current rewards: 30.17116, mean: 0.09733
[32m[0906 17-18-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03360, current rewards: 35.74974, mean: 0.09930
[32m[0906 17-19-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03358, current rewards: 41.32158, mean: 0.10078
[32m[0906 17-19-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03360, current rewards: 46.89993, mean: 0.10196
[32m[0906 17-19-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03361, current rewards: 52.47289, mean: 0.10289
[32m[0906 17-19-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03361, current rewards: 58.02047, mean: 0.10361
[32m[0906 17-19-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03362, current rewards: 63.58288, mean: 0.10423
[32m[0906 17-19-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03360, current rewards: 69.83503, mean: 0.10581
[32m[0906 17-19-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03361, current rewards: 75.38911, mean: 0.10618
[32m[0906 17-19-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03362, current rewards: 80.94502, mean: 0.10651
[32m[0906 17-19-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03361, current rewards: 86.49937, mean: 0.10679
[32m[0906 17-19-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03361, current rewards: 92.06296, mean: 0.10705
[32m[0906 17-19-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03354, current rewards: 97.61637, mean: 0.10727
[32m[0906 17-19-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03350, current rewards: 101.08170, mean: 0.10529
[32m[0906 17-19-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03346, current rewards: 106.86880, mean: 0.10581
[32m[0906 17-19-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03343, current rewards: 112.44557, mean: 0.10608
[32m[0906 17-19-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03341, current rewards: 118.02323, mean: 0.10633
[32m[0906 17-19-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03339, current rewards: 123.60028, mean: 0.10655
[32m[0906 17-19-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03335, current rewards: 129.17901, mean: 0.10676
[32m[0906 17-19-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03332, current rewards: 134.75469, mean: 0.10695
[32m[0906 17-19-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03330, current rewards: 140.33194, mean: 0.10712
[32m[0906 17-19-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03327, current rewards: 144.73790, mean: 0.10642
[32m[0906 17-19-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03325, current rewards: 150.29967, mean: 0.10660
[32m[0906 17-19-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03324, current rewards: 155.86580, mean: 0.10676
[32m[0906 17-19-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03323, current rewards: 161.43819, mean: 0.10691
[32m[0906 17-19-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03322, current rewards: 167.00829, mean: 0.10706
[32m[0906 17-19-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03320, current rewards: 172.57960, mean: 0.10719
[32m[0906 17-19-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03319, current rewards: 178.14745, mean: 0.10732
[32m[0906 17-19-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03318, current rewards: 183.71511, mean: 0.10744
[32m[0906 17-19-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03316, current rewards: 189.28613, mean: 0.10755
[32m[0906 17-19-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03315, current rewards: 194.73716, mean: 0.10759
[32m[0906 17-19-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03314, current rewards: 200.29392, mean: 0.10768
[32m[0906 17-19-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03312, current rewards: 205.85705, mean: 0.10778
[32m[0906 17-19-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03312, current rewards: 211.42028, mean: 0.10787
[32m[0906 17-19-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03312, current rewards: 216.98560, mean: 0.10795
[32m[0906 17-19-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03310, current rewards: 222.54537, mean: 0.10803
[32m[0906 17-19-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03310, current rewards: 228.10956, mean: 0.10811
[32m[0906 17-19-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03309, current rewards: 233.67988, mean: 0.10819
[32m[0906 17-20-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03310, current rewards: 239.12760, mean: 0.10820
[32m[0906 17-20-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03311, current rewards: 244.66961, mean: 0.10826
[32m[0906 17-20-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03312, current rewards: 250.21444, mean: 0.10832
[32m[0906 17-20-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03313, current rewards: 255.75615, mean: 0.10837
[32m[0906 17-20-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03314, current rewards: 259.35882, mean: 0.10762
[32m[0906 17-20-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03315, current rewards: 264.95262, mean: 0.10770
[32m[0906 17-20-10 @Agent.py:117][0m Average action selection time: 0.0332
[32m[0906 17-20-10 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-20-10 @MBExp.py:227][0m Rewards obtained: [269.4254502637008], Lows: [3], Highs: [3], Total time: 6782.030726999998
[32m[0906 17-22-53 @MBExp.py:144][0m ####################################################################
[32m[0906 17-22-53 @MBExp.py:145][0m Starting training iteration 80.
[32m[0906 17-22-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03318, current rewards: -1.27908, mean: -0.12791
[32m[0906 17-22-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03331, current rewards: 4.28402, mean: 0.07140
[32m[0906 17-22-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03341, current rewards: 9.89496, mean: 0.08995
[32m[0906 17-22-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03345, current rewards: 15.57787, mean: 0.09736
[32m[0906 17-23-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03347, current rewards: 21.16307, mean: 0.10078
[32m[0906 17-23-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03348, current rewards: 26.75133, mean: 0.10289
[32m[0906 17-23-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03352, current rewards: 32.33330, mean: 0.10430
[32m[0906 17-23-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03354, current rewards: 37.92033, mean: 0.10533
[32m[0906 17-23-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03353, current rewards: 41.35654, mean: 0.10087
[32m[0906 17-23-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03354, current rewards: 47.02188, mean: 0.10222
[32m[0906 17-23-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03353, current rewards: 52.68460, mean: 0.10330
[32m[0906 17-23-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03355, current rewards: 58.10631, mean: 0.10376
[32m[0906 17-23-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03355, current rewards: 63.75354, mean: 0.10451
[32m[0906 17-23-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03354, current rewards: 69.40120, mean: 0.10515
[32m[0906 17-23-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03355, current rewards: 75.05327, mean: 0.10571
[32m[0906 17-23-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03356, current rewards: 80.70397, mean: 0.10619
[32m[0906 17-23-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03356, current rewards: 86.35297, mean: 0.10661
[32m[0906 17-23-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03352, current rewards: 90.71080, mean: 0.10548
[32m[0906 17-23-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03348, current rewards: 96.19711, mean: 0.10571
[32m[0906 17-23-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03344, current rewards: 101.76091, mean: 0.10600
[32m[0906 17-23-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03341, current rewards: 107.26577, mean: 0.10620
[32m[0906 17-23-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03338, current rewards: 112.76714, mean: 0.10638
[32m[0906 17-23-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03335, current rewards: 118.27486, mean: 0.10655
[32m[0906 17-23-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03334, current rewards: 123.78002, mean: 0.10671
[32m[0906 17-23-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03330, current rewards: 129.28286, mean: 0.10685
[32m[0906 17-23-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03328, current rewards: 134.78527, mean: 0.10697
[32m[0906 17-23-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03325, current rewards: 140.28523, mean: 0.10709
[32m[0906 17-23-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03323, current rewards: 145.78288, mean: 0.10719
[32m[0906 17-23-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03321, current rewards: 151.28703, mean: 0.10730
[32m[0906 17-23-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03318, current rewards: 156.78975, mean: 0.10739
[32m[0906 17-23-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03316, current rewards: 162.62900, mean: 0.10770
[32m[0906 17-23-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03315, current rewards: 168.15732, mean: 0.10779
[32m[0906 17-23-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03313, current rewards: 173.67656, mean: 0.10787
[32m[0906 17-23-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03311, current rewards: 179.19593, mean: 0.10795
[32m[0906 17-23-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03310, current rewards: 184.71609, mean: 0.10802
[32m[0906 17-23-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03309, current rewards: 190.24591, mean: 0.10809
[32m[0906 17-23-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03308, current rewards: 195.76640, mean: 0.10816
[32m[0906 17-23-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03306, current rewards: 201.28476, mean: 0.10822
[32m[0906 17-23-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03305, current rewards: 203.51401, mean: 0.10655
[32m[0906 17-23-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03305, current rewards: 209.06418, mean: 0.10667
[32m[0906 17-24-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03304, current rewards: 214.61765, mean: 0.10677
[32m[0906 17-24-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03303, current rewards: 220.17675, mean: 0.10688
[32m[0906 17-24-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03303, current rewards: 225.73160, mean: 0.10698
[32m[0906 17-24-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03302, current rewards: 231.39156, mean: 0.10713
[32m[0906 17-24-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03302, current rewards: 236.96986, mean: 0.10723
[32m[0906 17-24-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03304, current rewards: 242.53767, mean: 0.10732
[32m[0906 17-24-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03305, current rewards: 248.10775, mean: 0.10741
[32m[0906 17-24-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03306, current rewards: 253.67516, mean: 0.10749
[32m[0906 17-24-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03307, current rewards: 259.24299, mean: 0.10757
[32m[0906 17-24-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03308, current rewards: 264.83831, mean: 0.10766
[32m[0906 17-24-17 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 17-24-17 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-24-17 @MBExp.py:227][0m Rewards obtained: [269.29457879238606], Lows: [2], Highs: [4], Total time: 6865.476825999997
[32m[0906 17-27-02 @MBExp.py:144][0m ####################################################################
[32m[0906 17-27-02 @MBExp.py:145][0m Starting training iteration 81.
[32m[0906 17-27-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03348, current rewards: -1.08260, mean: -0.10826
[32m[0906 17-27-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03357, current rewards: 4.62136, mean: 0.07702
[32m[0906 17-27-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03360, current rewards: 10.14369, mean: 0.09222
[32m[0906 17-27-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03358, current rewards: 15.72216, mean: 0.09826
[32m[0906 17-27-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03360, current rewards: 21.30253, mean: 0.10144
[32m[0906 17-27-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03364, current rewards: 26.88287, mean: 0.10340
[32m[0906 17-27-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03363, current rewards: 32.46078, mean: 0.10471
[32m[0906 17-27-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03363, current rewards: 38.04486, mean: 0.10568
[32m[0906 17-27-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03360, current rewards: 43.62716, mean: 0.10641
[32m[0906 17-27-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03358, current rewards: 49.21013, mean: 0.10698
[32m[0906 17-27-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03360, current rewards: 51.60928, mean: 0.10119
[32m[0906 17-27-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03361, current rewards: 57.13350, mean: 0.10202
[32m[0906 17-27-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03358, current rewards: 62.66735, mean: 0.10273
[32m[0906 17-27-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03361, current rewards: 68.19700, mean: 0.10333
[32m[0906 17-27-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03363, current rewards: 69.57938, mean: 0.09800
[32m[0906 17-27-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03363, current rewards: 75.14723, mean: 0.09888
[32m[0906 17-27-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03363, current rewards: 80.71504, mean: 0.09965
[32m[0906 17-27-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03356, current rewards: 86.28287, mean: 0.10033
[32m[0906 17-27-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03352, current rewards: 91.85069, mean: 0.10093
[32m[0906 17-27-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03349, current rewards: 97.41849, mean: 0.10148
[32m[0906 17-27-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03347, current rewards: 102.98629, mean: 0.10197
[32m[0906 17-27-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03343, current rewards: 101.78448, mean: 0.09602
[32m[0906 17-27-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03339, current rewards: 107.32813, mean: 0.09669
[32m[0906 17-27-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03335, current rewards: 112.86271, mean: 0.09730
[32m[0906 17-27-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03331, current rewards: 118.40120, mean: 0.09785
[32m[0906 17-27-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03330, current rewards: 119.79362, mean: 0.09507
[32m[0906 17-27-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03327, current rewards: 125.40820, mean: 0.09573
[32m[0906 17-27-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03324, current rewards: 131.02601, mean: 0.09634
[32m[0906 17-27-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03322, current rewards: 136.63858, mean: 0.09691
[32m[0906 17-27-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03320, current rewards: 142.25124, mean: 0.09743
[32m[0906 17-27-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03319, current rewards: 147.86514, mean: 0.09792
[32m[0906 17-27-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03317, current rewards: 152.28776, mean: 0.09762
[32m[0906 17-27-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03315, current rewards: 157.83953, mean: 0.09804
[32m[0906 17-27-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03314, current rewards: 163.39074, mean: 0.09843
[32m[0906 17-27-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03313, current rewards: 168.93601, mean: 0.09879
[32m[0906 17-28-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03312, current rewards: 174.48591, mean: 0.09914
[32m[0906 17-28-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03311, current rewards: 180.03995, mean: 0.09947
[32m[0906 17-28-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03311, current rewards: 185.59392, mean: 0.09978
[32m[0906 17-28-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03310, current rewards: 191.14941, mean: 0.10008
[32m[0906 17-28-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03309, current rewards: 196.70128, mean: 0.10036
[32m[0906 17-28-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03308, current rewards: 202.25514, mean: 0.10062
[32m[0906 17-28-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03307, current rewards: 207.80946, mean: 0.10088
[32m[0906 17-28-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03307, current rewards: 213.26232, mean: 0.10107
[32m[0906 17-28-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03306, current rewards: 218.80746, mean: 0.10130
[32m[0906 17-28-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03307, current rewards: 224.35305, mean: 0.10152
[32m[0906 17-28-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03308, current rewards: 229.89479, mean: 0.10172
[32m[0906 17-28-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03309, current rewards: 235.43504, mean: 0.10192
[32m[0906 17-28-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03310, current rewards: 240.97537, mean: 0.10211
[32m[0906 17-28-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03311, current rewards: 246.52342, mean: 0.10229
[32m[0906 17-28-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03312, current rewards: 252.06340, mean: 0.10246
[32m[0906 17-28-26 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 17-28-26 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-28-26 @MBExp.py:227][0m Rewards obtained: [256.4993659496368], Lows: [5], Highs: [10], Total time: 6949.0295499999975
[32m[0906 17-31-13 @MBExp.py:144][0m ####################################################################
[32m[0906 17-31-13 @MBExp.py:145][0m Starting training iteration 82.
[32m[0906 17-31-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03357, current rewards: -1.03799, mean: -0.10380
[32m[0906 17-31-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03364, current rewards: 4.69188, mean: 0.07820
[32m[0906 17-31-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03364, current rewards: 10.31339, mean: 0.09376
[32m[0906 17-31-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03354, current rewards: 15.93250, mean: 0.09958
[32m[0906 17-31-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03354, current rewards: 21.55572, mean: 0.10265
[32m[0906 17-31-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03354, current rewards: 25.10104, mean: 0.09654
[32m[0906 17-31-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03352, current rewards: 30.61558, mean: 0.09876
[32m[0906 17-31-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03352, current rewards: 36.13226, mean: 0.10037
[32m[0906 17-31-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03349, current rewards: 41.64217, mean: 0.10157
[32m[0906 17-31-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03348, current rewards: 47.03705, mean: 0.10225
[32m[0906 17-31-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03347, current rewards: 52.55209, mean: 0.10304
[32m[0906 17-31-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03347, current rewards: 58.06922, mean: 0.10370
[32m[0906 17-31-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03347, current rewards: 63.58691, mean: 0.10424
[32m[0906 17-31-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03349, current rewards: 69.10885, mean: 0.10471
[32m[0906 17-31-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03349, current rewards: 74.62244, mean: 0.10510
[32m[0906 17-31-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03349, current rewards: 80.14109, mean: 0.10545
[32m[0906 17-31-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03347, current rewards: 81.33443, mean: 0.10041
[32m[0906 17-31-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03341, current rewards: 81.01367, mean: 0.09420
[32m[0906 17-31-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03336, current rewards: 78.52045, mean: 0.08629
[32m[0906 17-31-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03334, current rewards: 70.64228, mean: 0.07359
[32m[0906 17-31-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03331, current rewards: 66.42912, mean: 0.06577
[32m[0906 17-31-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03328, current rewards: 60.78005, mean: 0.05734
[32m[0906 17-31-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03324, current rewards: 58.56273, mean: 0.05276
[32m[0906 17-31-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03321, current rewards: 52.44025, mean: 0.04521
[32m[0906 17-31-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03319, current rewards: 52.89589, mean: 0.04372
[32m[0906 17-31-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03317, current rewards: 50.05103, mean: 0.03972
[32m[0906 17-31-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03315, current rewards: 55.67748, mean: 0.04250
[32m[0906 17-31-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03313, current rewards: 61.30247, mean: 0.04508
[32m[0906 17-32-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03312, current rewards: 66.92962, mean: 0.04747
[32m[0906 17-32-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03311, current rewards: 72.55455, mean: 0.04969
[32m[0906 17-32-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03310, current rewards: 78.18000, mean: 0.05177
[32m[0906 17-32-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03309, current rewards: 83.80034, mean: 0.05372
[32m[0906 17-32-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03307, current rewards: 89.43125, mean: 0.05555
[32m[0906 17-32-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03306, current rewards: 95.04754, mean: 0.05726
[32m[0906 17-32-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03304, current rewards: 100.67030, mean: 0.05887
[32m[0906 17-32-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03302, current rewards: 104.14004, mean: 0.05917
[32m[0906 17-32-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03301, current rewards: 109.49675, mean: 0.06050
[32m[0906 17-32-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03300, current rewards: 114.85639, mean: 0.06175
[32m[0906 17-32-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03299, current rewards: 120.21856, mean: 0.06294
[32m[0906 17-32-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03298, current rewards: 125.58693, mean: 0.06407
[32m[0906 17-32-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03297, current rewards: 130.94233, mean: 0.06515
[32m[0906 17-32-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03296, current rewards: 136.30472, mean: 0.06617
[32m[0906 17-32-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03296, current rewards: 141.66430, mean: 0.06714
[32m[0906 17-32-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03296, current rewards: 147.02209, mean: 0.06807
[32m[0906 17-32-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03297, current rewards: 152.38125, mean: 0.06895
[32m[0906 17-32-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03298, current rewards: 156.62728, mean: 0.06930
[32m[0906 17-32-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03299, current rewards: 162.21265, mean: 0.07022
[32m[0906 17-32-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03300, current rewards: 167.79330, mean: 0.07110
[32m[0906 17-32-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03300, current rewards: 173.37937, mean: 0.07194
[32m[0906 17-32-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03301, current rewards: 177.82900, mean: 0.07229
[32m[0906 17-32-36 @Agent.py:117][0m Average action selection time: 0.0330
[32m[0906 17-32-36 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-32-37 @MBExp.py:227][0m Rewards obtained: [181.9122786876617], Lows: [38], Highs: [20], Total time: 7032.308812999998
[32m[0906 17-35-26 @MBExp.py:144][0m ####################################################################
[32m[0906 17-35-26 @MBExp.py:145][0m Starting training iteration 83.
[32m[0906 17-35-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03277, current rewards: -2.07007, mean: -0.20701
[32m[0906 17-35-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03362, current rewards: 3.53674, mean: 0.05895
[32m[0906 17-35-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03353, current rewards: 9.14523, mean: 0.08314
[32m[0906 17-35-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03353, current rewards: 14.75720, mean: 0.09223
[32m[0906 17-35-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03356, current rewards: 20.36589, mean: 0.09698
[32m[0906 17-35-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03355, current rewards: 25.97376, mean: 0.09990
[32m[0906 17-35-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03354, current rewards: 31.58345, mean: 0.10188
[32m[0906 17-35-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03358, current rewards: 37.19713, mean: 0.10333
[32m[0906 17-35-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03356, current rewards: 42.85146, mean: 0.10452
[32m[0906 17-35-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03357, current rewards: 48.47261, mean: 0.10538
[32m[0906 17-35-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03357, current rewards: 51.94405, mean: 0.10185
[32m[0906 17-35-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03357, current rewards: 57.50592, mean: 0.10269
[32m[0906 17-35-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03358, current rewards: 63.06399, mean: 0.10338
[32m[0906 17-35-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03359, current rewards: 68.62206, mean: 0.10397
[32m[0906 17-35-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03360, current rewards: 74.18089, mean: 0.10448
[32m[0906 17-35-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03360, current rewards: 77.67926, mean: 0.10221
[32m[0906 17-35-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03354, current rewards: 82.98542, mean: 0.10245
[32m[0906 17-35-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03349, current rewards: 88.53978, mean: 0.10295
[32m[0906 17-35-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03344, current rewards: 94.09693, mean: 0.10340
[32m[0906 17-35-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03339, current rewards: 99.64943, mean: 0.10380
[32m[0906 17-36-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03336, current rewards: 105.20169, mean: 0.10416
[32m[0906 17-36-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03333, current rewards: 110.75452, mean: 0.10449
[32m[0906 17-36-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03330, current rewards: 115.21037, mean: 0.10379
[32m[0906 17-36-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03326, current rewards: 120.72065, mean: 0.10407
[32m[0906 17-36-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03324, current rewards: 126.37794, mean: 0.10444
[32m[0906 17-36-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03322, current rewards: 131.92069, mean: 0.10470
[32m[0906 17-36-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03319, current rewards: 137.45854, mean: 0.10493
[32m[0906 17-36-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03317, current rewards: 141.79764, mean: 0.10426
[32m[0906 17-36-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03314, current rewards: 147.26603, mean: 0.10444
[32m[0906 17-36-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03314, current rewards: 152.72909, mean: 0.10461
[32m[0906 17-36-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03312, current rewards: 158.19686, mean: 0.10477
[32m[0906 17-36-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03310, current rewards: 159.55426, mean: 0.10228
[32m[0906 17-36-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03308, current rewards: 165.52606, mean: 0.10281
[32m[0906 17-36-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03307, current rewards: 173.08254, mean: 0.10427
[32m[0906 17-36-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03305, current rewards: 180.73762, mean: 0.10569
[32m[0906 17-36-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03305, current rewards: 188.39270, mean: 0.10704
[32m[0906 17-36-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03303, current rewards: 196.04778, mean: 0.10831
[32m[0906 17-36-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03302, current rewards: 203.70286, mean: 0.10952
[32m[0906 17-36-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03302, current rewards: 211.35794, mean: 0.11066
[32m[0906 17-36-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03301, current rewards: 219.01302, mean: 0.11174
[32m[0906 17-36-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03300, current rewards: 226.66810, mean: 0.11277
[32m[0906 17-36-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03300, current rewards: 183.58671, mean: 0.08912
[32m[0906 17-36-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03299, current rewards: 133.58671, mean: 0.06331
[32m[0906 17-36-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03298, current rewards: 83.58671, mean: 0.03870
[32m[0906 17-36-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03300, current rewards: 33.58671, mean: 0.01520
[32m[0906 17-36-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03301, current rewards: -16.41329, mean: -0.00726
[32m[0906 17-36-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03302, current rewards: -66.41329, mean: -0.02875
[32m[0906 17-36-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03304, current rewards: -116.41329, mean: -0.04933
[32m[0906 17-36-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03304, current rewards: -166.41329, mean: -0.06905
[32m[0906 17-36-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03306, current rewards: -216.41329, mean: -0.08797
[32m[0906 17-36-49 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 17-36-49 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-36-49 @MBExp.py:227][0m Rewards obtained: [-256.4132900712468], Lows: [5], Highs: [487], Total time: 7115.711955999997
[32m[0906 17-39-41 @MBExp.py:144][0m ####################################################################
[32m[0906 17-39-41 @MBExp.py:145][0m Starting training iteration 84.
[32m[0906 17-39-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03293, current rewards: 1.13479, mean: 0.11348
[32m[0906 17-39-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03333, current rewards: 6.51882, mean: 0.10865
[32m[0906 17-39-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03341, current rewards: 12.04375, mean: 0.10949
[32m[0906 17-39-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03343, current rewards: 17.56793, mean: 0.10980
[32m[0906 17-39-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03347, current rewards: 23.09055, mean: 0.10995
[32m[0906 17-39-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03350, current rewards: 28.61069, mean: 0.11004
[32m[0906 17-39-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03352, current rewards: 34.13798, mean: 0.11012
[32m[0906 17-39-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03350, current rewards: 39.77084, mean: 0.11047
[32m[0906 17-39-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03350, current rewards: 45.82144, mean: 0.11176
[32m[0906 17-39-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03351, current rewards: 51.86671, mean: 0.11275
[32m[0906 17-39-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03351, current rewards: 57.91197, mean: 0.11355
[32m[0906 17-40-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03352, current rewards: 63.95724, mean: 0.11421
[32m[0906 17-40-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03354, current rewards: 70.00251, mean: 0.11476
[32m[0906 17-40-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03355, current rewards: 37.93699, mean: 0.05748
[32m[0906 17-40-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03356, current rewards: -12.06301, mean: -0.01699
[32m[0906 17-40-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03351, current rewards: -62.06301, mean: -0.08166
[32m[0906 17-40-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03346, current rewards: -112.06301, mean: -0.13835
[32m[0906 17-40-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03342, current rewards: -162.06301, mean: -0.18845
[32m[0906 17-40-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03338, current rewards: -212.06301, mean: -0.23304
[32m[0906 17-40-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03334, current rewards: -262.06301, mean: -0.27298
[32m[0906 17-40-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03331, current rewards: -312.06301, mean: -0.30897
[32m[0906 17-40-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03329, current rewards: -362.06301, mean: -0.34157
[32m[0906 17-40-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03327, current rewards: -412.06301, mean: -0.37123
[32m[0906 17-40-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03324, current rewards: -462.06301, mean: -0.39833
[32m[0906 17-40-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03322, current rewards: -512.06301, mean: -0.42319
[32m[0906 17-40-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03319, current rewards: -562.06301, mean: -0.44608
[32m[0906 17-40-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03316, current rewards: -612.06301, mean: -0.46722
[32m[0906 17-40-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03314, current rewards: -662.06301, mean: -0.48681
[32m[0906 17-40-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03311, current rewards: -712.06301, mean: -0.50501
[32m[0906 17-40-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03309, current rewards: -762.06301, mean: -0.52196
[32m[0906 17-40-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03309, current rewards: -812.06301, mean: -0.53779
[32m[0906 17-40-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03308, current rewards: -862.06301, mean: -0.55260
[32m[0906 17-40-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03306, current rewards: -912.06301, mean: -0.56650
[32m[0906 17-40-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03305, current rewards: -962.06301, mean: -0.57956
[32m[0906 17-40-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03303, current rewards: -1012.06301, mean: -0.59185
[32m[0906 17-40-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03302, current rewards: -1062.06301, mean: -0.60344
[32m[0906 17-40-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03300, current rewards: -1112.06301, mean: -0.61440
[32m[0906 17-40-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03299, current rewards: -1162.06301, mean: -0.62477
[32m[0906 17-40-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03297, current rewards: -1212.06301, mean: -0.63459
[32m[0906 17-40-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03297, current rewards: -1262.06301, mean: -0.64391
[32m[0906 17-40-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03296, current rewards: -1312.06301, mean: -0.65277
[32m[0906 17-40-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03296, current rewards: -1362.06301, mean: -0.66120
[32m[0906 17-40-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03295, current rewards: -1412.06301, mean: -0.66922
[32m[0906 17-40-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03295, current rewards: -1462.06301, mean: -0.67688
[32m[0906 17-40-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03296, current rewards: -1512.06301, mean: -0.68419
[32m[0906 17-40-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03297, current rewards: -1562.06301, mean: -0.69118
[32m[0906 17-40-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03299, current rewards: -1612.06301, mean: -0.69786
[32m[0906 17-40-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03300, current rewards: -1662.06301, mean: -0.70426
[32m[0906 17-41-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03301, current rewards: -1712.06301, mean: -0.71040
[32m[0906 17-41-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03302, current rewards: -1762.06301, mean: -0.71629
[32m[0906 17-41-04 @Agent.py:117][0m Average action selection time: 0.0330
[32m[0906 17-41-04 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-41-04 @MBExp.py:227][0m Rewards obtained: [-1802.0630098083711], Lows: [0], Highs: [1874], Total time: 7199.012163999997
[32m[0906 17-43-57 @MBExp.py:144][0m ####################################################################
[32m[0906 17-43-57 @MBExp.py:145][0m Starting training iteration 85.
[32m[0906 17-43-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03250, current rewards: 0.05516, mean: 0.00552
[32m[0906 17-43-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03342, current rewards: 5.87200, mean: 0.09787
[32m[0906 17-44-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03346, current rewards: 11.52162, mean: 0.10474
[32m[0906 17-44-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03358, current rewards: 17.17297, mean: 0.10733
[32m[0906 17-44-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03355, current rewards: 22.82906, mean: 0.10871
[32m[0906 17-44-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03357, current rewards: 28.31004, mean: 0.10888
[32m[0906 17-44-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03362, current rewards: 33.78982, mean: 0.10900
[32m[0906 17-44-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03362, current rewards: 39.27360, mean: 0.10909
[32m[0906 17-44-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03360, current rewards: 44.72559, mean: 0.10909
[32m[0906 17-44-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03359, current rewards: 50.19236, mean: 0.10911
[32m[0906 17-44-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03360, current rewards: 55.66367, mean: 0.10914
[32m[0906 17-44-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03361, current rewards: 61.13319, mean: 0.10917
[32m[0906 17-44-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03362, current rewards: 66.59825, mean: 0.10918
[32m[0906 17-44-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03362, current rewards: 72.06625, mean: 0.10919
[32m[0906 17-44-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03361, current rewards: 75.98854, mean: 0.10703
[32m[0906 17-44-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03355, current rewards: 81.65956, mean: 0.10745
[32m[0906 17-44-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03349, current rewards: 87.25298, mean: 0.10772
[32m[0906 17-44-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03343, current rewards: 92.89698, mean: 0.10802
[32m[0906 17-44-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03339, current rewards: 98.53948, mean: 0.10829
[32m[0906 17-44-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03334, current rewards: 104.18058, mean: 0.10852
[32m[0906 17-44-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03331, current rewards: 109.82139, mean: 0.10873
[32m[0906 17-44-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03328, current rewards: 115.46272, mean: 0.10893
[32m[0906 17-44-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03323, current rewards: 121.10386, mean: 0.10910
[32m[0906 17-44-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03321, current rewards: 125.60651, mean: 0.10828
[32m[0906 17-44-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03319, current rewards: 131.27099, mean: 0.10849
[32m[0906 17-44-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03317, current rewards: 136.99840, mean: 0.10873
[32m[0906 17-44-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03313, current rewards: 142.64717, mean: 0.10889
[32m[0906 17-44-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03311, current rewards: 148.29803, mean: 0.10904
[32m[0906 17-44-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03309, current rewards: 153.94830, mean: 0.10918
[32m[0906 17-44-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03308, current rewards: 159.60154, mean: 0.10932
[32m[0906 17-44-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03307, current rewards: 165.25199, mean: 0.10944
[32m[0906 17-44-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03305, current rewards: 169.59498, mean: 0.10871
[32m[0906 17-44-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03304, current rewards: 174.98954, mean: 0.10869
[32m[0906 17-44-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03303, current rewards: 180.39774, mean: 0.10867
[32m[0906 17-44-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03303, current rewards: 185.79637, mean: 0.10865
[32m[0906 17-44-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03302, current rewards: 191.20231, mean: 0.10864
[32m[0906 17-44-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03299, current rewards: 196.61310, mean: 0.10863
[32m[0906 17-44-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03298, current rewards: 202.05956, mean: 0.10863
[32m[0906 17-45-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03297, current rewards: 207.55663, mean: 0.10867
[32m[0906 17-45-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03296, current rewards: 213.05025, mean: 0.10870
[32m[0906 17-45-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03295, current rewards: 218.55006, mean: 0.10873
[32m[0906 17-45-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03294, current rewards: 223.99317, mean: 0.10873
[32m[0906 17-45-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03294, current rewards: 229.48537, mean: 0.10876
[32m[0906 17-45-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03293, current rewards: 234.97895, mean: 0.10879
[32m[0906 17-45-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03294, current rewards: 238.57027, mean: 0.10795
[32m[0906 17-45-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03296, current rewards: 244.22068, mean: 0.10806
[32m[0906 17-45-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03297, current rewards: 249.86920, mean: 0.10817
[32m[0906 17-45-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03299, current rewards: 255.52182, mean: 0.10827
[32m[0906 17-45-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03300, current rewards: 261.17263, mean: 0.10837
[32m[0906 17-45-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03301, current rewards: 266.80435, mean: 0.10846
[32m[0906 17-45-20 @Agent.py:117][0m Average action selection time: 0.0330
[32m[0906 17-45-20 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-45-20 @MBExp.py:227][0m Rewards obtained: [271.51302210729693], Lows: [2], Highs: [3], Total time: 7282.294438999997
[32m[0906 17-48-16 @MBExp.py:144][0m ####################################################################
[32m[0906 17-48-16 @MBExp.py:145][0m Starting training iteration 86.
[32m[0906 17-48-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03314, current rewards: -1.75812, mean: -0.17581
[32m[0906 17-48-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03328, current rewards: 3.73565, mean: 0.06226
[32m[0906 17-48-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03352, current rewards: 9.17466, mean: 0.08341
[32m[0906 17-48-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03351, current rewards: 14.61377, mean: 0.09134
[32m[0906 17-48-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03351, current rewards: 20.05691, mean: 0.09551
[32m[0906 17-48-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03355, current rewards: 25.49860, mean: 0.09807
[32m[0906 17-48-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03357, current rewards: 29.01978, mean: 0.09361
[32m[0906 17-48-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03355, current rewards: 34.51750, mean: 0.09588
[32m[0906 17-48-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03356, current rewards: 39.74072, mean: 0.09693
[32m[0906 17-48-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03355, current rewards: 45.17357, mean: 0.09820
[32m[0906 17-48-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03354, current rewards: 50.60487, mean: 0.09923
[32m[0906 17-48-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03354, current rewards: 56.03679, mean: 0.10007
[32m[0906 17-48-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03356, current rewards: 61.46500, mean: 0.10076
[32m[0906 17-48-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03356, current rewards: 66.89524, mean: 0.10136
[32m[0906 17-48-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03358, current rewards: 72.32583, mean: 0.10187
[32m[0906 17-48-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03347, current rewards: 77.75206, mean: 0.10231
[32m[0906 17-48-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03341, current rewards: 81.51295, mean: 0.10063
[32m[0906 17-48-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03338, current rewards: 87.03858, mean: 0.10121
[32m[0906 17-48-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03333, current rewards: 92.56656, mean: 0.10172
[32m[0906 17-48-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03328, current rewards: 98.09629, mean: 0.10218
[32m[0906 17-48-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03326, current rewards: 103.62434, mean: 0.10260
[32m[0906 17-48-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03323, current rewards: 109.15532, mean: 0.10298
[32m[0906 17-48-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03321, current rewards: 112.41956, mean: 0.10128
[32m[0906 17-48-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03319, current rewards: 117.96618, mean: 0.10169
[32m[0906 17-48-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03316, current rewards: 123.44619, mean: 0.10202
[32m[0906 17-48-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03315, current rewards: 128.94939, mean: 0.10234
[32m[0906 17-48-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03313, current rewards: 134.47871, mean: 0.10266
[32m[0906 17-49-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03312, current rewards: 140.00364, mean: 0.10294
[32m[0906 17-49-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03310, current rewards: 145.53758, mean: 0.10322
[32m[0906 17-49-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03307, current rewards: 151.06712, mean: 0.10347
[32m[0906 17-49-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03307, current rewards: 155.63755, mean: 0.10307
[32m[0906 17-49-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03305, current rewards: 160.98966, mean: 0.10320
[32m[0906 17-49-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03304, current rewards: 166.34496, mean: 0.10332
[32m[0906 17-49-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03303, current rewards: 171.84623, mean: 0.10352
[32m[0906 17-49-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03301, current rewards: 177.24337, mean: 0.10365
[32m[0906 17-49-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03302, current rewards: 182.63600, mean: 0.10377
[32m[0906 17-49-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03299, current rewards: 188.02695, mean: 0.10388
[32m[0906 17-49-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03299, current rewards: 193.41749, mean: 0.10399
[32m[0906 17-49-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03299, current rewards: 198.81028, mean: 0.10409
[32m[0906 17-49-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03298, current rewards: 204.19585, mean: 0.10418
[32m[0906 17-49-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03297, current rewards: 209.58624, mean: 0.10427
[32m[0906 17-49-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03296, current rewards: 215.02785, mean: 0.10438
[32m[0906 17-49-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03296, current rewards: 218.37715, mean: 0.10350
[32m[0906 17-49-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03296, current rewards: 223.90451, mean: 0.10366
[32m[0906 17-49-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03297, current rewards: 229.43112, mean: 0.10381
[32m[0906 17-49-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03299, current rewards: 234.95537, mean: 0.10396
[32m[0906 17-49-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03300, current rewards: 240.48405, mean: 0.10411
[32m[0906 17-49-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03302, current rewards: 246.01087, mean: 0.10424
[32m[0906 17-49-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03303, current rewards: 251.53875, mean: 0.10437
[32m[0906 17-49-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03304, current rewards: 256.88526, mean: 0.10442
[32m[0906 17-49-39 @Agent.py:117][0m Average action selection time: 0.0330
[32m[0906 17-49-39 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-49-39 @MBExp.py:227][0m Rewards obtained: [261.25411492738243], Lows: [4], Highs: [4], Total time: 7365.643316999996
[32m[0906 17-52-37 @MBExp.py:144][0m ####################################################################
[32m[0906 17-52-37 @MBExp.py:145][0m Starting training iteration 87.
[32m[0906 17-52-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03318, current rewards: -0.13086, mean: -0.01309
[32m[0906 17-52-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03347, current rewards: 5.34216, mean: 0.08904
[32m[0906 17-52-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03347, current rewards: 10.86993, mean: 0.09882
[32m[0906 17-52-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03349, current rewards: 16.40308, mean: 0.10252
[32m[0906 17-52-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03344, current rewards: 21.93035, mean: 0.10443
[32m[0906 17-52-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03347, current rewards: 27.46019, mean: 0.10562
[32m[0906 17-52-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03343, current rewards: 32.98939, mean: 0.10642
[32m[0906 17-52-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03343, current rewards: 38.52154, mean: 0.10700
[32m[0906 17-52-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03344, current rewards: 44.34733, mean: 0.10816
[32m[0906 17-52-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03347, current rewards: 49.03607, mean: 0.10660
[32m[0906 17-52-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03349, current rewards: 54.76229, mean: 0.10738
[32m[0906 17-52-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03349, current rewards: 60.48273, mean: 0.10800
[32m[0906 17-52-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03351, current rewards: 66.21054, mean: 0.10854
[32m[0906 17-52-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03352, current rewards: 71.93243, mean: 0.10899
[32m[0906 17-53-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03353, current rewards: 77.65996, mean: 0.10938
[32m[0906 17-53-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03353, current rewards: 83.29760, mean: 0.10960
[32m[0906 17-53-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03352, current rewards: 88.87775, mean: 0.10973
[32m[0906 17-53-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03353, current rewards: 94.43607, mean: 0.10981
[32m[0906 17-53-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03347, current rewards: 100.00401, mean: 0.10989
[32m[0906 17-53-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03343, current rewards: 105.57657, mean: 0.10998
[32m[0906 17-53-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03337, current rewards: 109.19156, mean: 0.10811
[32m[0906 17-53-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03334, current rewards: 114.87466, mean: 0.10837
[32m[0906 17-53-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03330, current rewards: 120.55735, mean: 0.10861
[32m[0906 17-53-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03326, current rewards: 126.24192, mean: 0.10883
[32m[0906 17-53-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03323, current rewards: 127.89527, mean: 0.10570
[32m[0906 17-53-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03320, current rewards: 133.39240, mean: 0.10587
[32m[0906 17-53-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03319, current rewards: 138.93030, mean: 0.10605
[32m[0906 17-53-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03318, current rewards: 144.47275, mean: 0.10623
[32m[0906 17-53-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03315, current rewards: 150.01627, mean: 0.10639
[32m[0906 17-53-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03313, current rewards: 154.18999, mean: 0.10561
[32m[0906 17-53-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03313, current rewards: 159.67189, mean: 0.10574
[32m[0906 17-53-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03312, current rewards: 165.15403, mean: 0.10587
[32m[0906 17-53-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03312, current rewards: 170.63567, mean: 0.10598
[32m[0906 17-53-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03311, current rewards: 176.04968, mean: 0.10605
[32m[0906 17-53-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03309, current rewards: 181.53316, mean: 0.10616
[32m[0906 17-53-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03308, current rewards: 187.01905, mean: 0.10626
[32m[0906 17-53-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03307, current rewards: 192.50220, mean: 0.10635
[32m[0906 17-53-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03306, current rewards: 197.98581, mean: 0.10644
[32m[0906 17-53-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03305, current rewards: 201.44847, mean: 0.10547
[32m[0906 17-53-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03304, current rewards: 206.99195, mean: 0.10561
[32m[0906 17-53-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03303, current rewards: 212.53303, mean: 0.10574
[32m[0906 17-53-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03302, current rewards: 217.92979, mean: 0.10579
[32m[0906 17-53-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03302, current rewards: 223.43037, mean: 0.10589
[32m[0906 17-53-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03302, current rewards: 228.91948, mean: 0.10598
[32m[0906 17-53-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03303, current rewards: 234.40812, mean: 0.10607
[32m[0906 17-53-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03305, current rewards: 239.90487, mean: 0.10615
[32m[0906 17-53-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03307, current rewards: 245.39686, mean: 0.10623
[32m[0906 17-53-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03308, current rewards: 250.88866, mean: 0.10631
[32m[0906 17-53-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03309, current rewards: 256.38596, mean: 0.10638
[32m[0906 17-53-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03310, current rewards: 262.01790, mean: 0.10651
[32m[0906 17-54-00 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 17-54-00 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-54-00 @MBExp.py:227][0m Rewards obtained: [266.44634932967534], Lows: [4], Highs: [4], Total time: 7449.126726999996
[32m[0906 17-57-00 @MBExp.py:144][0m ####################################################################
[32m[0906 17-57-00 @MBExp.py:145][0m Starting training iteration 88.
[32m[0906 17-57-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03291, current rewards: -1.22529, mean: -0.12253
[32m[0906 17-57-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03340, current rewards: 4.31749, mean: 0.07196
[32m[0906 17-57-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03357, current rewards: 9.85830, mean: 0.08962
[32m[0906 17-57-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03357, current rewards: 15.40229, mean: 0.09626
[32m[0906 17-57-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03353, current rewards: 20.93988, mean: 0.09971
[32m[0906 17-57-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03351, current rewards: 26.47763, mean: 0.10184
[32m[0906 17-57-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03348, current rewards: 32.01361, mean: 0.10327
[32m[0906 17-57-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03349, current rewards: 37.56160, mean: 0.10434
[32m[0906 17-57-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03351, current rewards: 43.27410, mean: 0.10555
[32m[0906 17-57-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03353, current rewards: 48.83882, mean: 0.10617
[32m[0906 17-57-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03354, current rewards: 52.17691, mean: 0.10231
[32m[0906 17-57-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03355, current rewards: 57.58773, mean: 0.10284
[32m[0906 17-57-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03355, current rewards: 63.02161, mean: 0.10331
[32m[0906 17-57-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03356, current rewards: 68.45501, mean: 0.10372
[32m[0906 17-57-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03356, current rewards: 73.89590, mean: 0.10408
[32m[0906 17-57-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03356, current rewards: 79.33452, mean: 0.10439
[32m[0906 17-57-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03355, current rewards: 84.77120, mean: 0.10466
[32m[0906 17-57-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03355, current rewards: 90.20604, mean: 0.10489
[32m[0906 17-57-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03349, current rewards: 95.64550, mean: 0.10510
[32m[0906 17-57-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03343, current rewards: 101.07981, mean: 0.10529
[32m[0906 17-57-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03340, current rewards: 106.52172, mean: 0.10547
[32m[0906 17-57-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03336, current rewards: 111.95523, mean: 0.10562
[32m[0906 17-57-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03334, current rewards: 117.39185, mean: 0.10576
[32m[0906 17-57-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03331, current rewards: 122.74736, mean: 0.10582
[32m[0906 17-57-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03329, current rewards: 128.37297, mean: 0.10609
[32m[0906 17-57-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03327, current rewards: 133.86017, mean: 0.10624
[32m[0906 17-57-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03325, current rewards: 139.35174, mean: 0.10638
[32m[0906 17-57-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03323, current rewards: 144.83597, mean: 0.10650
[32m[0906 17-57-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03320, current rewards: 150.32365, mean: 0.10661
[32m[0906 17-57-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03318, current rewards: 155.81688, mean: 0.10672
[32m[0906 17-57-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03317, current rewards: 161.31564, mean: 0.10683
[32m[0906 17-57-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03315, current rewards: 162.72858, mean: 0.10431
[32m[0906 17-57-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03313, current rewards: 167.83045, mean: 0.10424
[32m[0906 17-57-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03313, current rewards: 173.44333, mean: 0.10448
[32m[0906 17-57-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03311, current rewards: 179.05293, mean: 0.10471
[32m[0906 17-57-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03309, current rewards: 184.66531, mean: 0.10492
[32m[0906 17-58-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03308, current rewards: 190.27832, mean: 0.10513
[32m[0906 17-58-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03307, current rewards: 195.89110, mean: 0.10532
[32m[0906 17-58-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03306, current rewards: 201.50572, mean: 0.10550
[32m[0906 17-58-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03304, current rewards: 207.11870, mean: 0.10567
[32m[0906 17-58-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03303, current rewards: 212.55273, mean: 0.10575
[32m[0906 17-58-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03302, current rewards: 215.82230, mean: 0.10477
[32m[0906 17-58-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03302, current rewards: 221.35857, mean: 0.10491
[32m[0906 17-58-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03301, current rewards: 226.90570, mean: 0.10505
[32m[0906 17-58-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03302, current rewards: 232.44664, mean: 0.10518
[32m[0906 17-58-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03304, current rewards: 237.99242, mean: 0.10531
[32m[0906 17-58-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03305, current rewards: 243.53744, mean: 0.10543
[32m[0906 17-58-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03305, current rewards: 249.08460, mean: 0.10554
[32m[0906 17-58-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03306, current rewards: 254.63155, mean: 0.10566
[32m[0906 17-58-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03308, current rewards: 260.19648, mean: 0.10577
[32m[0906 17-58-23 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 17-58-23 @Agent.py:118][0m Rollout length: 2501
[32m[0906 17-58-23 @MBExp.py:227][0m Rewards obtained: [264.63575209349415], Lows: [2], Highs: [6], Total time: 7532.559369999996
[32m[0906 18-01-25 @MBExp.py:144][0m ####################################################################
[32m[0906 18-01-25 @MBExp.py:145][0m Starting training iteration 89.
[32m[0906 18-01-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03343, current rewards: -3.10042, mean: -0.31004
[32m[0906 18-01-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03343, current rewards: 2.39677, mean: 0.03995
[32m[0906 18-01-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03352, current rewards: 7.89528, mean: 0.07178
[32m[0906 18-01-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03347, current rewards: 13.38340, mean: 0.08365
[32m[0906 18-01-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03354, current rewards: 18.87235, mean: 0.08987
[32m[0906 18-01-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03355, current rewards: 24.36171, mean: 0.09370
[32m[0906 18-01-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03357, current rewards: 29.84946, mean: 0.09629
[32m[0906 18-01-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03354, current rewards: 35.58262, mean: 0.09884
[32m[0906 18-01-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03356, current rewards: 41.07203, mean: 0.10018
[32m[0906 18-01-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03356, current rewards: 46.56109, mean: 0.10122
[32m[0906 18-01-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03355, current rewards: 52.06029, mean: 0.10208
[32m[0906 18-01-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03357, current rewards: 53.64275, mean: 0.09579
[32m[0906 18-01-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03358, current rewards: 59.56062, mean: 0.09764
[32m[0906 18-01-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03361, current rewards: 65.47850, mean: 0.09921
[32m[0906 18-01-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03360, current rewards: 71.39638, mean: 0.10056
[32m[0906 18-01-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03360, current rewards: 68.34683, mean: 0.08993
[32m[0906 18-01-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03360, current rewards: 27.21178, mean: 0.03359
[32m[0906 18-01-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03356, current rewards: 32.70419, mean: 0.03803
[32m[0906 18-01-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03349, current rewards: 38.19530, mean: 0.04197
[32m[0906 18-01-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03344, current rewards: 43.68751, mean: 0.04551
[32m[0906 18-01-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03341, current rewards: 49.18041, mean: 0.04869
[32m[0906 18-02-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03336, current rewards: 54.66915, mean: 0.05157
[32m[0906 18-02-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03332, current rewards: 60.16059, mean: 0.05420
[32m[0906 18-02-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03329, current rewards: 65.60280, mean: 0.05655
[32m[0906 18-02-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03326, current rewards: 70.91035, mean: 0.05860
[32m[0906 18-02-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03324, current rewards: 76.39786, mean: 0.06063
[32m[0906 18-02-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03322, current rewards: 79.84599, mean: 0.06095
[32m[0906 18-02-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03322, current rewards: 85.37028, mean: 0.06277
[32m[0906 18-02-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03319, current rewards: 90.89465, mean: 0.06446
[32m[0906 18-02-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03318, current rewards: 96.42339, mean: 0.06604
[32m[0906 18-02-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03316, current rewards: 101.94543, mean: 0.06751
[32m[0906 18-02-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03314, current rewards: 107.47409, mean: 0.06889
[32m[0906 18-02-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03313, current rewards: 113.05403, mean: 0.07022
[32m[0906 18-02-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03312, current rewards: 118.56372, mean: 0.07142
[32m[0906 18-02-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03310, current rewards: 124.08000, mean: 0.07256
[32m[0906 18-02-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03309, current rewards: 128.86041, mean: 0.07322
[32m[0906 18-02-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03308, current rewards: 134.32406, mean: 0.07421
[32m[0906 18-02-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03307, current rewards: 139.78944, mean: 0.07516
[32m[0906 18-02-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03306, current rewards: 145.25015, mean: 0.07605
[32m[0906 18-02-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03305, current rewards: 150.71594, mean: 0.07690
[32m[0906 18-02-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03304, current rewards: 156.32429, mean: 0.07777
[32m[0906 18-02-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03303, current rewards: 161.79797, mean: 0.07854
[32m[0906 18-02-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03303, current rewards: 167.27479, mean: 0.07928
[32m[0906 18-02-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03303, current rewards: 172.74854, mean: 0.07998
[32m[0906 18-02-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03304, current rewards: 178.21979, mean: 0.08064
[32m[0906 18-02-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03306, current rewards: 180.57305, mean: 0.07990
[32m[0906 18-02-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03307, current rewards: 186.00821, mean: 0.08052
[32m[0906 18-02-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03308, current rewards: 191.43380, mean: 0.08112
[32m[0906 18-02-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03309, current rewards: 196.92151, mean: 0.08171
[32m[0906 18-02-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03310, current rewards: 202.35553, mean: 0.08226
[32m[0906 18-02-48 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 18-02-48 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-02-48 @MBExp.py:227][0m Rewards obtained: [206.7007949553604], Lows: [5], Highs: [54], Total time: 7616.066361999996
[32m[0906 18-05-52 @MBExp.py:144][0m ####################################################################
[32m[0906 18-05-52 @MBExp.py:145][0m Starting training iteration 90.
[32m[0906 18-05-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03263, current rewards: -0.16047, mean: -0.01605
[32m[0906 18-05-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03358, current rewards: 5.22143, mean: 0.08702
[32m[0906 18-05-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03358, current rewards: 10.74302, mean: 0.09766
[32m[0906 18-05-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03361, current rewards: 16.27437, mean: 0.10171
[32m[0906 18-05-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03357, current rewards: 21.80382, mean: 0.10383
[32m[0906 18-06-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03367, current rewards: 27.32550, mean: 0.10510
[32m[0906 18-06-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03362, current rewards: 32.85718, mean: 0.10599
[32m[0906 18-06-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03362, current rewards: 38.54726, mean: 0.10708
[32m[0906 18-06-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03360, current rewards: 44.09218, mean: 0.10754
[32m[0906 18-06-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03360, current rewards: 49.63133, mean: 0.10789
[32m[0906 18-06-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03364, current rewards: 55.17588, mean: 0.10819
[32m[0906 18-06-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03363, current rewards: 60.72094, mean: 0.10843
[32m[0906 18-06-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03361, current rewards: 66.26664, mean: 0.10863
[32m[0906 18-06-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03361, current rewards: 71.81055, mean: 0.10880
[32m[0906 18-06-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03363, current rewards: 75.37603, mean: 0.10616
[32m[0906 18-06-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03363, current rewards: 80.93978, mean: 0.10650
[32m[0906 18-06-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03363, current rewards: 86.50624, mean: 0.10680
[32m[0906 18-06-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03358, current rewards: 92.06508, mean: 0.10705
[32m[0906 18-06-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03352, current rewards: 97.62700, mean: 0.10728
[32m[0906 18-06-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03348, current rewards: 103.18998, mean: 0.10749
[32m[0906 18-06-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03345, current rewards: 107.66227, mean: 0.10660
[32m[0906 18-06-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03339, current rewards: 113.21168, mean: 0.10680
[32m[0906 18-06-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03335, current rewards: 118.75154, mean: 0.10698
[32m[0906 18-06-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03333, current rewards: 124.23864, mean: 0.10710
[32m[0906 18-06-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03330, current rewards: 129.78000, mean: 0.10726
[32m[0906 18-06-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03327, current rewards: 135.32908, mean: 0.10740
[32m[0906 18-06-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03325, current rewards: 140.87136, mean: 0.10754
[32m[0906 18-06-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03322, current rewards: 145.65775, mean: 0.10710
[32m[0906 18-06-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03320, current rewards: 151.18926, mean: 0.10723
[32m[0906 18-06-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03319, current rewards: 156.71728, mean: 0.10734
[32m[0906 18-06-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03318, current rewards: 162.24455, mean: 0.10745
[32m[0906 18-06-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03316, current rewards: 167.78235, mean: 0.10755
[32m[0906 18-06-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03315, current rewards: 174.01737, mean: 0.10809
[32m[0906 18-06-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03314, current rewards: 179.54744, mean: 0.10816
[32m[0906 18-06-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03312, current rewards: 185.07087, mean: 0.10823
[32m[0906 18-06-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03311, current rewards: 190.59501, mean: 0.10829
[32m[0906 18-06-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03311, current rewards: 196.12048, mean: 0.10835
[32m[0906 18-06-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03310, current rewards: 201.64529, mean: 0.10841
[32m[0906 18-06-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03309, current rewards: 207.16630, mean: 0.10846
[32m[0906 18-06-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03307, current rewards: 212.69190, mean: 0.10852
[32m[0906 18-06-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03306, current rewards: 218.06557, mean: 0.10849
[32m[0906 18-07-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03305, current rewards: 223.57538, mean: 0.10853
[32m[0906 18-07-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03305, current rewards: 229.07630, mean: 0.10857
[32m[0906 18-07-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03304, current rewards: 234.58979, mean: 0.10861
[32m[0906 18-07-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03306, current rewards: 240.09341, mean: 0.10864
[32m[0906 18-07-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03307, current rewards: 245.60238, mean: 0.10867
[32m[0906 18-07-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03309, current rewards: 248.96314, mean: 0.10778
[32m[0906 18-07-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03310, current rewards: 254.36943, mean: 0.10778
[32m[0906 18-07-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03311, current rewards: 260.01893, mean: 0.10789
[32m[0906 18-07-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03312, current rewards: 265.40535, mean: 0.10789
[32m[0906 18-07-15 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 18-07-15 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-07-15 @MBExp.py:227][0m Rewards obtained: [269.7153752652063], Lows: [2], Highs: [3], Total time: 7699.612446999996
[32m[0906 18-10-21 @MBExp.py:144][0m ####################################################################
[32m[0906 18-10-21 @MBExp.py:145][0m Starting training iteration 91.
[32m[0906 18-10-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03313, current rewards: -1.02640, mean: -0.10264
[32m[0906 18-10-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03363, current rewards: -6.24745, mean: -0.10412
[32m[0906 18-10-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03357, current rewards: -8.83872, mean: -0.08035
[32m[0906 18-10-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03355, current rewards: -10.87250, mean: -0.06795
[32m[0906 18-10-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03357, current rewards: -15.96707, mean: -0.07603
[32m[0906 18-10-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03350, current rewards: -23.80181, mean: -0.09155
[32m[0906 18-10-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03356, current rewards: -29.14052, mean: -0.09400
[32m[0906 18-10-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03355, current rewards: -25.58381, mean: -0.07107
[32m[0906 18-10-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03354, current rewards: -20.15754, mean: -0.04916
[32m[0906 18-10-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03354, current rewards: -14.72990, mean: -0.03202
[32m[0906 18-10-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03354, current rewards: -12.02086, mean: -0.02357
[32m[0906 18-10-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03355, current rewards: -6.42583, mean: -0.01147
[32m[0906 18-10-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03356, current rewards: -0.86640, mean: -0.00142
[32m[0906 18-10-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03358, current rewards: 4.69273, mean: 0.00711
[32m[0906 18-10-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03357, current rewards: 10.25498, mean: 0.01444
[32m[0906 18-10-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03358, current rewards: 15.85825, mean: 0.02087
[32m[0906 18-10-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03355, current rewards: 21.37975, mean: 0.02639
[32m[0906 18-10-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03350, current rewards: 26.90278, mean: 0.03128
[32m[0906 18-10-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03345, current rewards: 32.42841, mean: 0.03564
[32m[0906 18-10-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03341, current rewards: 37.95227, mean: 0.03953
[32m[0906 18-10-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03336, current rewards: 43.47937, mean: 0.04305
[32m[0906 18-10-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03333, current rewards: 49.00824, mean: 0.04623
[32m[0906 18-10-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03330, current rewards: 49.57022, mean: 0.04466
[32m[0906 18-10-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03326, current rewards: 54.91282, mean: 0.04734
[32m[0906 18-11-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03324, current rewards: 60.44978, mean: 0.04996
[32m[0906 18-11-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03323, current rewards: 65.98675, mean: 0.05237
[32m[0906 18-11-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03320, current rewards: 71.51669, mean: 0.05459
[32m[0906 18-11-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03319, current rewards: 77.05493, mean: 0.05666
[32m[0906 18-11-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03316, current rewards: 82.59610, mean: 0.05858
[32m[0906 18-11-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03315, current rewards: 88.13893, mean: 0.06037
[32m[0906 18-11-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03314, current rewards: 93.67605, mean: 0.06204
[32m[0906 18-11-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03312, current rewards: 99.23638, mean: 0.06361
[32m[0906 18-11-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03311, current rewards: 104.74652, mean: 0.06506
[32m[0906 18-11-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03310, current rewards: 110.26225, mean: 0.06642
[32m[0906 18-11-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03308, current rewards: 105.26638, mean: 0.06156
[32m[0906 18-11-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03307, current rewards: 59.15644, mean: 0.03361
[32m[0906 18-11-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03306, current rewards: 13.05611, mean: 0.00721
[32m[0906 18-11-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03305, current rewards: -33.04998, mean: -0.01777
[32m[0906 18-11-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03304, current rewards: -79.13405, mean: -0.04143
[32m[0906 18-11-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03303, current rewards: -125.00704, mean: -0.06378
[32m[0906 18-11-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03301, current rewards: -119.94250, mean: -0.05967
[32m[0906 18-11-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03301, current rewards: -114.97635, mean: -0.05581
[32m[0906 18-11-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03301, current rewards: -110.01266, mean: -0.05214
[32m[0906 18-11-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03301, current rewards: -105.04833, mean: -0.04863
[32m[0906 18-11-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03303, current rewards: -100.08520, mean: -0.04529
[32m[0906 18-11-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03304, current rewards: -95.11942, mean: -0.04209
[32m[0906 18-11-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03306, current rewards: -90.15426, mean: -0.03903
[32m[0906 18-11-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03307, current rewards: -85.06151, mean: -0.03604
[32m[0906 18-11-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03309, current rewards: -77.99311, mean: -0.03236
[32m[0906 18-11-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03310, current rewards: -70.89656, mean: -0.02882
[32m[0906 18-11-44 @Agent.py:117][0m Average action selection time: 0.0331
[32m[0906 18-11-44 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-11-44 @MBExp.py:227][0m Rewards obtained: [-93.76759037473417], Lows: [178], Highs: [26], Total time: 7783.110667999996
[32m[0906 18-14-51 @MBExp.py:144][0m ####################################################################
[32m[0906 18-14-51 @MBExp.py:145][0m Starting training iteration 92.
[32m[0906 18-14-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03279, current rewards: -2.17469, mean: -0.21747
[32m[0906 18-14-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03335, current rewards: 3.22819, mean: 0.05380
[32m[0906 18-14-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03341, current rewards: 8.74729, mean: 0.07952
[32m[0906 18-14-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03349, current rewards: 14.26375, mean: 0.08915
[32m[0906 18-14-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03350, current rewards: 19.78088, mean: 0.09419
[32m[0906 18-15-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03346, current rewards: 25.29801, mean: 0.09730
[32m[0906 18-15-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03347, current rewards: 30.81454, mean: 0.09940
[32m[0906 18-15-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03344, current rewards: 36.33234, mean: 0.10092
[32m[0906 18-15-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03344, current rewards: 39.73696, mean: 0.09692
[32m[0906 18-15-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03347, current rewards: 45.24449, mean: 0.09836
[32m[0906 18-15-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03348, current rewards: 50.75669, mean: 0.09952
[32m[0906 18-15-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03349, current rewards: 56.26525, mean: 0.10047
[32m[0906 18-15-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03349, current rewards: 61.77826, mean: 0.10128
[32m[0906 18-15-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03350, current rewards: 67.28989, mean: 0.10195
[32m[0906 18-15-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03351, current rewards: 72.72219, mean: 0.10243
[32m[0906 18-15-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03353, current rewards: 78.22855, mean: 0.10293
[32m[0906 18-15-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03348, current rewards: 83.73479, mean: 0.10338
[32m[0906 18-15-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03342, current rewards: 89.24016, mean: 0.10377
[32m[0906 18-15-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03338, current rewards: 94.74784, mean: 0.10412
[32m[0906 18-15-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03335, current rewards: 100.25231, mean: 0.10443
[32m[0906 18-15-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03330, current rewards: 105.75831, mean: 0.10471
[32m[0906 18-15-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03327, current rewards: 111.26567, mean: 0.10497
[32m[0906 18-15-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03322, current rewards: 116.90982, mean: 0.10532
[32m[0906 18-15-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03319, current rewards: 119.38031, mean: 0.10291
[32m[0906 18-15-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03318, current rewards: 124.90113, mean: 0.10322
[32m[0906 18-15-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03316, current rewards: 130.42292, mean: 0.10351
[32m[0906 18-15-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03315, current rewards: 135.94256, mean: 0.10377
[32m[0906 18-15-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03313, current rewards: 141.46340, mean: 0.10402
[32m[0906 18-15-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03312, current rewards: 146.98274, mean: 0.10424
[32m[0906 18-15-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03309, current rewards: 152.50430, mean: 0.10446
[32m[0906 18-15-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03307, current rewards: 158.02220, mean: 0.10465
[32m[0906 18-15-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03307, current rewards: 163.50545, mean: 0.10481
[32m[0906 18-15-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03306, current rewards: 169.02837, mean: 0.10499
[32m[0906 18-15-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03305, current rewards: 174.54715, mean: 0.10515
[32m[0906 18-15-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03305, current rewards: 180.72219, mean: 0.10569
[32m[0906 18-15-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03304, current rewards: 186.22468, mean: 0.10581
[32m[0906 18-15-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03303, current rewards: 191.72239, mean: 0.10592
[32m[0906 18-15-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03302, current rewards: 197.22689, mean: 0.10604
[32m[0906 18-15-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03300, current rewards: 202.72964, mean: 0.10614
[32m[0906 18-15-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03299, current rewards: 208.16048, mean: 0.10620
[32m[0906 18-15-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03298, current rewards: 213.66115, mean: 0.10630
[32m[0906 18-16-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03298, current rewards: 219.16367, mean: 0.10639
[32m[0906 18-16-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03298, current rewards: 224.66471, mean: 0.10648
[32m[0906 18-16-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03297, current rewards: 228.05338, mean: 0.10558
[32m[0906 18-16-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03296, current rewards: 233.45569, mean: 0.10564
[32m[0906 18-16-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03297, current rewards: 238.95451, mean: 0.10573
[32m[0906 18-16-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03299, current rewards: 244.45271, mean: 0.10582
[32m[0906 18-16-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03300, current rewards: 249.91479, mean: 0.10590
[32m[0906 18-16-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03301, current rewards: 255.41123, mean: 0.10598
[32m[0906 18-16-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03302, current rewards: 260.90504, mean: 0.10606
[32m[0906 18-16-14 @Agent.py:117][0m Average action selection time: 0.0330
[32m[0906 18-16-14 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-16-14 @MBExp.py:227][0m Rewards obtained: [265.29891600152604], Lows: [4], Highs: [2], Total time: 7866.421998999996
[32m[0906 18-19-23 @MBExp.py:144][0m ####################################################################
[32m[0906 18-19-23 @MBExp.py:145][0m Starting training iteration 93.
[32m[0906 18-19-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03295, current rewards: -5.80056, mean: -0.58006
[32m[0906 18-19-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03359, current rewards: -0.61568, mean: -0.01026
[32m[0906 18-19-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03353, current rewards: 4.86511, mean: 0.04423
[32m[0906 18-19-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03348, current rewards: 10.33497, mean: 0.06459
[32m[0906 18-19-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03353, current rewards: 15.81587, mean: 0.07531
[32m[0906 18-19-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03357, current rewards: 21.48334, mean: 0.08263
[32m[0906 18-19-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03358, current rewards: 25.15416, mean: 0.08114
[32m[0906 18-19-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03386, current rewards: 18.78762, mean: 0.05219
[32m[0906 18-19-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03411, current rewards: 23.22947, mean: 0.05666
[32m[0906 18-19-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03445, current rewards: 27.80144, mean: 0.06044
[32m[0906 18-19-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03468, current rewards: 32.36130, mean: 0.06345
[32m[0906 18-19-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03497, current rewards: 36.95174, mean: 0.06599
[32m[0906 18-19-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03514, current rewards: 41.50683, mean: 0.06804
[32m[0906 18-19-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03520, current rewards: 45.98474, mean: 0.06967
[32m[0906 18-19-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03539, current rewards: 51.03636, mean: 0.07188
[32m[0906 18-19-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03532, current rewards: 48.10194, mean: 0.06329
[32m[0906 18-19-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03516, current rewards: 40.66727, mean: 0.05021
[32m[0906 18-19-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03503, current rewards: 34.58449, mean: 0.04021
[32m[0906 18-19-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03500, current rewards: 27.14689, mean: 0.02983
[32m[0906 18-19-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03489, current rewards: 21.00548, mean: 0.02188
[32m[0906 18-19-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03485, current rewards: 13.72536, mean: 0.01359
[32m[0906 18-20-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03477, current rewards: 7.44907, mean: 0.00703
[32m[0906 18-20-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03479, current rewards: -1.92246, mean: -0.00173
[32m[0906 18-20-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03494, current rewards: -5.72074, mean: -0.00493
[32m[0906 18-20-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03500, current rewards: -16.04164, mean: -0.01326
[32m[0906 18-20-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03492, current rewards: -56.64371, mean: -0.04496
[32m[0906 18-20-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03482, current rewards: -106.64371, mean: -0.08141
[32m[0906 18-20-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03474, current rewards: -156.64371, mean: -0.11518
[32m[0906 18-20-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03467, current rewards: -206.64371, mean: -0.14656
[32m[0906 18-20-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03459, current rewards: -256.64371, mean: -0.17578
[32m[0906 18-20-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03452, current rewards: -306.64371, mean: -0.20308
[32m[0906 18-20-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03446, current rewards: -356.64371, mean: -0.22862
[32m[0906 18-20-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03440, current rewards: -406.64371, mean: -0.25257
[32m[0906 18-20-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03434, current rewards: -456.64371, mean: -0.27509
[32m[0906 18-20-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03430, current rewards: -506.64371, mean: -0.29628
[32m[0906 18-20-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03425, current rewards: -556.64371, mean: -0.31627
[32m[0906 18-20-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03421, current rewards: -606.64371, mean: -0.33516
[32m[0906 18-20-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03416, current rewards: -656.64371, mean: -0.35303
[32m[0906 18-20-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03412, current rewards: -706.64371, mean: -0.36997
[32m[0906 18-20-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03408, current rewards: -756.64371, mean: -0.38604
[32m[0906 18-20-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03403, current rewards: -806.64371, mean: -0.40132
[32m[0906 18-20-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03399, current rewards: -856.64371, mean: -0.41585
[32m[0906 18-20-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03396, current rewards: -906.64371, mean: -0.42969
[32m[0906 18-20-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03394, current rewards: -956.64371, mean: -0.44289
[32m[0906 18-20-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03393, current rewards: -1006.64371, mean: -0.45549
[32m[0906 18-20-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03392, current rewards: -1056.64371, mean: -0.46754
[32m[0906 18-20-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03391, current rewards: -1106.64371, mean: -0.47907
[32m[0906 18-20-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03390, current rewards: -1156.64371, mean: -0.49010
[32m[0906 18-20-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03390, current rewards: -1206.64371, mean: -0.50068
[32m[0906 18-20-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03388, current rewards: -1256.64371, mean: -0.51083
[32m[0906 18-20-49 @Agent.py:117][0m Average action selection time: 0.0339
[32m[0906 18-20-49 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-20-49 @MBExp.py:227][0m Rewards obtained: [-1296.643705565701], Lows: [1], Highs: [1420], Total time: 7951.845171999996
[32m[0906 18-24-00 @MBExp.py:144][0m ####################################################################
[32m[0906 18-24-00 @MBExp.py:145][0m Starting training iteration 94.
[32m[0906 18-24-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03283, current rewards: 0.81433, mean: 0.08143
[32m[0906 18-24-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03330, current rewards: 6.25524, mean: 0.10425
[32m[0906 18-24-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03346, current rewards: 11.78617, mean: 0.10715
[32m[0906 18-24-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03344, current rewards: 17.31282, mean: 0.10821
[32m[0906 18-24-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03347, current rewards: 22.83686, mean: 0.10875
[32m[0906 18-24-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03353, current rewards: 28.35982, mean: 0.10908
[32m[0906 18-24-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03353, current rewards: 34.20155, mean: 0.11033
[32m[0906 18-24-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03354, current rewards: 39.79362, mean: 0.11054
[32m[0906 18-24-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03354, current rewards: 45.38329, mean: 0.11069
[32m[0906 18-24-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03354, current rewards: 50.97222, mean: 0.11081
[32m[0906 18-24-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03357, current rewards: 56.56243, mean: 0.11091
[32m[0906 18-24-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03358, current rewards: 62.15423, mean: 0.11099
[32m[0906 18-24-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03358, current rewards: 65.41486, mean: 0.10724
[32m[0906 18-24-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03359, current rewards: 70.95696, mean: 0.10751
[32m[0906 18-24-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03352, current rewards: 76.39327, mean: 0.10760
[32m[0906 18-24-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03347, current rewards: 81.89875, mean: 0.10776
[32m[0906 18-24-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03343, current rewards: 87.42595, mean: 0.10793
[32m[0906 18-24-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03339, current rewards: 92.95108, mean: 0.10808
[32m[0906 18-24-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03334, current rewards: 96.29804, mean: 0.10582
[32m[0906 18-24-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03331, current rewards: 101.65787, mean: 0.10589
[32m[0906 18-24-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03328, current rewards: 107.02284, mean: 0.10596
[32m[0906 18-24-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03326, current rewards: 112.38459, mean: 0.10602
[32m[0906 18-24-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03322, current rewards: 117.75196, mean: 0.10608
[32m[0906 18-24-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03319, current rewards: 122.99374, mean: 0.10603
[32m[0906 18-24-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03315, current rewards: 128.32009, mean: 0.10605
[32m[0906 18-24-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03313, current rewards: 133.65899, mean: 0.10608
[32m[0906 18-24-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03310, current rewards: 138.99425, mean: 0.10610
[32m[0906 18-24-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03309, current rewards: 144.33459, mean: 0.10613
[32m[0906 18-24-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03308, current rewards: 149.67062, mean: 0.10615
[32m[0906 18-24-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03406, current rewards: 155.00999, mean: 0.10617
[32m[0906 18-24-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03401, current rewards: 160.34078, mean: 0.10619
[32m[0906 18-24-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03396, current rewards: 165.67857, mean: 0.10620
[32m[0906 18-24-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03391, current rewards: 171.01667, mean: 0.10622
[32m[0906 18-24-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03387, current rewards: 176.35220, mean: 0.10624
[32m[0906 18-24-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03383, current rewards: 181.68316, mean: 0.10625
[32m[0906 18-25-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03379, current rewards: 187.01921, mean: 0.10626
[32m[0906 18-25-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03374, current rewards: 192.34652, mean: 0.10627
[32m[0906 18-25-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03371, current rewards: 197.71699, mean: 0.10630
[32m[0906 18-25-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03368, current rewards: 203.13198, mean: 0.10635
[32m[0906 18-25-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03365, current rewards: 208.56397, mean: 0.10641
[32m[0906 18-25-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03361, current rewards: 213.98456, mean: 0.10646
[32m[0906 18-25-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03358, current rewards: 219.40932, mean: 0.10651
[32m[0906 18-25-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03356, current rewards: 224.82814, mean: 0.10655
[32m[0906 18-25-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03353, current rewards: 230.25415, mean: 0.10660
[32m[0906 18-25-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03353, current rewards: 235.67145, mean: 0.10664
[32m[0906 18-25-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03353, current rewards: 241.09686, mean: 0.10668
[32m[0906 18-25-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03352, current rewards: 246.51813, mean: 0.10672
[32m[0906 18-25-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03353, current rewards: 252.10073, mean: 0.10682
[32m[0906 18-25-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03353, current rewards: 257.53515, mean: 0.10686
[32m[0906 18-25-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03353, current rewards: 262.97347, mean: 0.10690
[32m[0906 18-25-24 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 18-25-24 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-25-24 @MBExp.py:227][0m Rewards obtained: [265.3247977595351], Lows: [2], Highs: [2], Total time: 8036.417032999996
[32m[0906 18-28-36 @MBExp.py:144][0m ####################################################################
[32m[0906 18-28-36 @MBExp.py:145][0m Starting training iteration 95.
[32m[0906 18-28-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03308, current rewards: -1.95836, mean: -0.19584
[32m[0906 18-28-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03338, current rewards: 3.56675, mean: 0.05945
[32m[0906 18-28-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03330, current rewards: 9.06637, mean: 0.08242
[32m[0906 18-28-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03324, current rewards: 14.56000, mean: 0.09100
[32m[0906 18-28-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03336, current rewards: 20.05269, mean: 0.09549
[32m[0906 18-28-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03335, current rewards: 25.41977, mean: 0.09777
[32m[0906 18-28-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03337, current rewards: 31.17940, mean: 0.10058
[32m[0906 18-28-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03336, current rewards: 37.14193, mean: 0.10317
[32m[0906 18-28-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03338, current rewards: 43.03832, mean: 0.10497
[32m[0906 18-28-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03339, current rewards: 49.05514, mean: 0.10664
[32m[0906 18-28-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03339, current rewards: 54.98207, mean: 0.10781
[32m[0906 18-28-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03339, current rewards: 61.00040, mean: 0.10893
[32m[0906 18-28-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03339, current rewards: 66.85264, mean: 0.10959
[32m[0906 18-28-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03339, current rewards: 72.84181, mean: 0.11037
[32m[0906 18-29-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03340, current rewards: 76.60703, mean: 0.10790
[32m[0906 18-29-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03342, current rewards: 82.25327, mean: 0.10823
[32m[0906 18-29-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03334, current rewards: 87.87737, mean: 0.10849
[32m[0906 18-29-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03328, current rewards: 93.54348, mean: 0.10877
[32m[0906 18-29-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03323, current rewards: 99.17995, mean: 0.10899
[32m[0906 18-29-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03318, current rewards: 104.80890, mean: 0.10918
[32m[0906 18-29-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03317, current rewards: 110.45599, mean: 0.10936
[32m[0906 18-29-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03313, current rewards: 116.11775, mean: 0.10955
[32m[0906 18-29-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03311, current rewards: 122.03654, mean: 0.10994
[32m[0906 18-29-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03308, current rewards: 127.95290, mean: 0.11030
[32m[0906 18-29-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03304, current rewards: 131.14033, mean: 0.10838
[32m[0906 18-29-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03302, current rewards: 138.60052, mean: 0.11000
[32m[0906 18-29-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03301, current rewards: 146.06072, mean: 0.11150
[32m[0906 18-29-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03300, current rewards: 153.52091, mean: 0.11288
[32m[0906 18-29-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03298, current rewards: 160.98110, mean: 0.11417
[32m[0906 18-29-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03297, current rewards: 168.44129, mean: 0.11537
[32m[0906 18-29-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03295, current rewards: 174.82222, mean: 0.11578
[32m[0906 18-29-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03294, current rewards: 130.08454, mean: 0.08339
[32m[0906 18-29-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03293, current rewards: 80.08454, mean: 0.04974
[32m[0906 18-29-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03293, current rewards: 30.08454, mean: 0.01812
[32m[0906 18-29-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03292, current rewards: -19.91546, mean: -0.01165
[32m[0906 18-29-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03291, current rewards: -69.91546, mean: -0.03972
[32m[0906 18-29-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03290, current rewards: -119.91546, mean: -0.06625
[32m[0906 18-29-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03289, current rewards: -169.91546, mean: -0.09135
[32m[0906 18-29-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03289, current rewards: -219.91546, mean: -0.11514
[32m[0906 18-29-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03287, current rewards: -238.61125, mean: -0.12174
[32m[0906 18-29-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03287, current rewards: -232.99137, mean: -0.11592
[32m[0906 18-29-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03286, current rewards: -227.24157, mean: -0.11031
[32m[0906 18-29-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03286, current rewards: -221.12592, mean: -0.10480
[32m[0906 18-29-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03286, current rewards: -215.76378, mean: -0.09989
[32m[0906 18-29-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03285, current rewards: -210.41068, mean: -0.09521
[32m[0906 18-29-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03285, current rewards: -205.05910, mean: -0.09073
[32m[0906 18-29-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03286, current rewards: -199.70515, mean: -0.08645
[32m[0906 18-29-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03287, current rewards: -194.51401, mean: -0.08242
[32m[0906 18-29-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03289, current rewards: -189.36805, mean: -0.07858
[32m[0906 18-29-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03289, current rewards: -184.24533, mean: -0.07490
[32m[0906 18-29-59 @Agent.py:117][0m Average action selection time: 0.0329
[32m[0906 18-29-59 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-29-59 @MBExp.py:227][0m Rewards obtained: [-180.14937588283615], Lows: [4], Highs: [418], Total time: 8119.418505999996
[32m[0906 18-33-14 @MBExp.py:144][0m ####################################################################
[32m[0906 18-33-14 @MBExp.py:145][0m Starting training iteration 96.
[32m[0906 18-33-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03254, current rewards: -0.10564, mean: -0.01056
[32m[0906 18-33-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03336, current rewards: 5.49985, mean: 0.09166
[32m[0906 18-33-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03345, current rewards: 11.11717, mean: 0.10107
[32m[0906 18-33-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03352, current rewards: 16.73391, mean: 0.10459
[32m[0906 18-33-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03357, current rewards: 22.35141, mean: 0.10644
[32m[0906 18-33-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03355, current rewards: 27.96986, mean: 0.10758
[32m[0906 18-33-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03354, current rewards: 33.77568, mean: 0.10895
[32m[0906 18-33-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03357, current rewards: 38.20619, mean: 0.10613
[32m[0906 18-33-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03357, current rewards: 43.78753, mean: 0.10680
[32m[0906 18-33-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03360, current rewards: 49.36491, mean: 0.10732
[32m[0906 18-33-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03360, current rewards: 54.94546, mean: 0.10774
[32m[0906 18-33-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03358, current rewards: 60.53103, mean: 0.10809
[32m[0906 18-33-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03359, current rewards: 66.07952, mean: 0.10833
[32m[0906 18-33-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03360, current rewards: 71.68173, mean: 0.10861
[32m[0906 18-33-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03360, current rewards: 77.05173, mean: 0.10852
[32m[0906 18-33-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03354, current rewards: 82.64664, mean: 0.10875
[32m[0906 18-33-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03349, current rewards: 88.29360, mean: 0.10900
[32m[0906 18-33-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03346, current rewards: 93.94464, mean: 0.10924
[32m[0906 18-33-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03340, current rewards: 99.59226, mean: 0.10944
[32m[0906 18-33-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03336, current rewards: 105.23976, mean: 0.10962
[32m[0906 18-33-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03333, current rewards: 110.88773, mean: 0.10979
[32m[0906 18-33-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03330, current rewards: 116.54143, mean: 0.10994
[32m[0906 18-33-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03326, current rewards: 122.19285, mean: 0.11008
[32m[0906 18-33-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03323, current rewards: 128.10042, mean: 0.11043
[32m[0906 18-33-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03321, current rewards: 133.71241, mean: 0.11051
[32m[0906 18-33-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03318, current rewards: 139.31497, mean: 0.11057
[32m[0906 18-33-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03314, current rewards: 144.86475, mean: 0.11058
[32m[0906 18-34-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03312, current rewards: 150.41739, mean: 0.11060
[32m[0906 18-34-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03310, current rewards: 155.96819, mean: 0.11062
[32m[0906 18-34-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03308, current rewards: 161.52368, mean: 0.11063
[32m[0906 18-34-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03306, current rewards: 167.07211, mean: 0.11064
[32m[0906 18-34-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03305, current rewards: 172.48964, mean: 0.11057
[32m[0906 18-34-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03303, current rewards: 178.06260, mean: 0.11060
[32m[0906 18-34-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03302, current rewards: 183.64128, mean: 0.11063
[32m[0906 18-34-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03302, current rewards: 189.22597, mean: 0.11066
[32m[0906 18-34-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03301, current rewards: 194.80588, mean: 0.11069
[32m[0906 18-34-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03300, current rewards: 196.18245, mean: 0.10839
[32m[0906 18-34-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03299, current rewards: 201.74000, mean: 0.10846
[32m[0906 18-34-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03298, current rewards: 207.29688, mean: 0.10853
[32m[0906 18-34-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03297, current rewards: 212.85179, mean: 0.10860
[32m[0906 18-34-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03297, current rewards: 218.60201, mean: 0.10876
[32m[0906 18-34-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03295, current rewards: 224.14247, mean: 0.10881
[32m[0906 18-34-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03294, current rewards: 229.68254, mean: 0.10885
[32m[0906 18-34-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03292, current rewards: 235.22269, mean: 0.10890
[32m[0906 18-34-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03293, current rewards: 240.76285, mean: 0.10894
[32m[0906 18-34-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03292, current rewards: 246.30274, mean: 0.10898
[32m[0906 18-34-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03293, current rewards: 251.84271, mean: 0.10902
[32m[0906 18-34-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03294, current rewards: 254.03875, mean: 0.10764
[32m[0906 18-34-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03296, current rewards: 259.46633, mean: 0.10766
[32m[0906 18-34-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03296, current rewards: 265.01244, mean: 0.10773
[32m[0906 18-34-37 @Agent.py:117][0m Average action selection time: 0.0330
[32m[0906 18-34-37 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-34-37 @MBExp.py:227][0m Rewards obtained: [269.45019215608136], Lows: [2], Highs: [5], Total time: 8202.594572999997
[32m[0906 18-37-54 @MBExp.py:144][0m ####################################################################
[32m[0906 18-37-54 @MBExp.py:145][0m Starting training iteration 97.
[32m[0906 18-37-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03256, current rewards: -1.12317, mean: -0.11232
[32m[0906 18-37-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03329, current rewards: 4.37162, mean: 0.07286
[32m[0906 18-37-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03331, current rewards: 9.85766, mean: 0.08962
[32m[0906 18-38-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03337, current rewards: 15.35145, mean: 0.09595
[32m[0906 18-38-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03348, current rewards: 20.84849, mean: 0.09928
[32m[0906 18-38-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03347, current rewards: 26.34296, mean: 0.10132
[32m[0906 18-38-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03349, current rewards: 23.86893, mean: 0.07700
[32m[0906 18-38-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03352, current rewards: 30.63297, mean: 0.08509
[32m[0906 18-38-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03352, current rewards: 37.39702, mean: 0.09121
[32m[0906 18-38-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03353, current rewards: 44.16107, mean: 0.09600
[32m[0906 18-38-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03352, current rewards: 50.92512, mean: 0.09985
[32m[0906 18-38-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03353, current rewards: 56.55389, mean: 0.10099
[32m[0906 18-38-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03352, current rewards: 6.55389, mean: 0.01074
[32m[0906 18-38-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03353, current rewards: -43.44611, mean: -0.06583
[32m[0906 18-38-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03354, current rewards: -93.44611, mean: -0.13161
[32m[0906 18-38-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03347, current rewards: -143.44611, mean: -0.18874
[32m[0906 18-38-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03340, current rewards: -193.44611, mean: -0.23882
[32m[0906 18-38-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03333, current rewards: -243.44611, mean: -0.28308
[32m[0906 18-38-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03329, current rewards: -293.44611, mean: -0.32247
[32m[0906 18-38-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03324, current rewards: -343.44611, mean: -0.35776
[32m[0906 18-38-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03320, current rewards: -393.44611, mean: -0.38955
[32m[0906 18-38-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03318, current rewards: -443.44611, mean: -0.41835
[32m[0906 18-38-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03315, current rewards: -493.44611, mean: -0.44455
[32m[0906 18-38-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03312, current rewards: -543.44611, mean: -0.46849
[32m[0906 18-38-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03309, current rewards: -593.44611, mean: -0.49045
[32m[0906 18-38-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03307, current rewards: -643.44611, mean: -0.51067
[32m[0906 18-38-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03304, current rewards: -693.44611, mean: -0.52935
[32m[0906 18-38-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03303, current rewards: -743.44611, mean: -0.54665
[32m[0906 18-38-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03302, current rewards: -793.44611, mean: -0.56273
[32m[0906 18-38-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03301, current rewards: -843.44611, mean: -0.57770
[32m[0906 18-38-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03299, current rewards: -893.44611, mean: -0.59169
[32m[0906 18-38-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03298, current rewards: -943.44611, mean: -0.60477
[32m[0906 18-38-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03297, current rewards: -959.08662, mean: -0.59571
[32m[0906 18-38-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03295, current rewards: -953.62485, mean: -0.57447
[32m[0906 18-38-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03294, current rewards: -948.16788, mean: -0.55448
[32m[0906 18-38-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03294, current rewards: -942.70657, mean: -0.53563
[32m[0906 18-38-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03293, current rewards: -937.24554, mean: -0.51782
[32m[0906 18-38-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03291, current rewards: -931.78613, mean: -0.50096
[32m[0906 18-38-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03291, current rewards: -926.32860, mean: -0.48499
[32m[0906 18-38-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03289, current rewards: -920.97796, mean: -0.46989
[32m[0906 18-39-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03289, current rewards: -915.50202, mean: -0.45547
[32m[0906 18-39-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03288, current rewards: -913.76715, mean: -0.44358
[32m[0906 18-39-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03287, current rewards: -907.73939, mean: -0.43021
[32m[0906 18-39-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03286, current rewards: -901.70947, mean: -0.41746
[32m[0906 18-39-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03286, current rewards: -895.67965, mean: -0.40528
[32m[0906 18-39-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03286, current rewards: -889.65005, mean: -0.39365
[32m[0906 18-39-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03288, current rewards: -883.62473, mean: -0.38252
[32m[0906 18-39-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03290, current rewards: -877.56825, mean: -0.37185
[32m[0906 18-39-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03291, current rewards: -875.22736, mean: -0.36316
[32m[0906 18-39-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03292, current rewards: -868.66792, mean: -0.35312
[32m[0906 18-39-17 @Agent.py:117][0m Average action selection time: 0.0329
[32m[0906 18-39-17 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-39-17 @MBExp.py:227][0m Rewards obtained: [-863.4203146569678], Lows: [8], Highs: [1022], Total time: 8285.640116999997
[32m[0906 18-42-36 @MBExp.py:144][0m ####################################################################
[32m[0906 18-42-36 @MBExp.py:145][0m Starting training iteration 98.
[32m[0906 18-42-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03362, current rewards: -2.14756, mean: -0.21476
[32m[0906 18-42-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03317, current rewards: 3.37799, mean: 0.05630
[32m[0906 18-42-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03329, current rewards: 8.89198, mean: 0.08084
[32m[0906 18-42-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03339, current rewards: 14.40635, mean: 0.09004
[32m[0906 18-42-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03338, current rewards: 19.91837, mean: 0.09485
[32m[0906 18-42-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03343, current rewards: 25.43086, mean: 0.09781
[32m[0906 18-42-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03344, current rewards: 30.94546, mean: 0.09982
[32m[0906 18-42-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03346, current rewards: 36.45689, mean: 0.10127
[32m[0906 18-42-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03345, current rewards: 41.97215, mean: 0.10237
[32m[0906 18-42-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03346, current rewards: 47.48548, mean: 0.10323
[32m[0906 18-42-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03347, current rewards: 52.99750, mean: 0.10392
[32m[0906 18-42-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03348, current rewards: 56.38144, mean: 0.10068
[32m[0906 18-42-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03348, current rewards: 61.92712, mean: 0.10152
[32m[0906 18-42-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03350, current rewards: 67.47053, mean: 0.10223
[32m[0906 18-43-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03347, current rewards: 73.38927, mean: 0.10337
[32m[0906 18-43-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03340, current rewards: 80.04926, mean: 0.10533
[32m[0906 18-43-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03333, current rewards: 86.72471, mean: 0.10707
[32m[0906 18-43-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03328, current rewards: 93.43719, mean: 0.10865
[32m[0906 18-43-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03326, current rewards: 97.62638, mean: 0.10728
[32m[0906 18-43-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03321, current rewards: 102.92285, mean: 0.10721
[32m[0906 18-43-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03319, current rewards: 108.21953, mean: 0.10715
[32m[0906 18-43-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03315, current rewards: 112.14622, mean: 0.10580
[32m[0906 18-43-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03313, current rewards: 118.16159, mean: 0.10645
[32m[0906 18-43-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03311, current rewards: 123.50914, mean: 0.10647
[32m[0906 18-43-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03309, current rewards: 128.92138, mean: 0.10655
[32m[0906 18-43-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03307, current rewards: 134.32955, mean: 0.10661
[32m[0906 18-43-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03306, current rewards: 139.74308, mean: 0.10667
[32m[0906 18-43-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03304, current rewards: 145.15051, mean: 0.10673
[32m[0906 18-43-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03304, current rewards: 150.55989, mean: 0.10678
[32m[0906 18-43-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03303, current rewards: 152.89281, mean: 0.10472
[32m[0906 18-43-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03301, current rewards: 158.27697, mean: 0.10482
[32m[0906 18-43-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03300, current rewards: 163.80164, mean: 0.10500
[32m[0906 18-43-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03300, current rewards: 169.22644, mean: 0.10511
[32m[0906 18-43-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03299, current rewards: 174.64577, mean: 0.10521
[32m[0906 18-43-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03297, current rewards: 180.06928, mean: 0.10530
[32m[0906 18-43-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03297, current rewards: 185.48973, mean: 0.10539
[32m[0906 18-43-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03296, current rewards: 190.90828, mean: 0.10547
[32m[0906 18-43-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03295, current rewards: 196.32710, mean: 0.10555
[32m[0906 18-43-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03293, current rewards: 201.74766, mean: 0.10563
[32m[0906 18-43-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03293, current rewards: 205.75801, mean: 0.10498
[32m[0906 18-43-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03292, current rewards: 211.49804, mean: 0.10522
[32m[0906 18-43-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03292, current rewards: 217.22073, mean: 0.10545
[32m[0906 18-43-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03291, current rewards: 222.94675, mean: 0.10566
[32m[0906 18-43-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03290, current rewards: 228.67180, mean: 0.10587
[32m[0906 18-43-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03290, current rewards: 231.14582, mean: 0.10459
[32m[0906 18-43-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03289, current rewards: 236.56760, mean: 0.10468
[32m[0906 18-43-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03291, current rewards: 241.99306, mean: 0.10476
[32m[0906 18-43-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03292, current rewards: 247.32054, mean: 0.10480
[32m[0906 18-43-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03294, current rewards: 252.71255, mean: 0.10486
[32m[0906 18-43-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03295, current rewards: 258.09911, mean: 0.10492
[32m[0906 18-43-59 @Agent.py:117][0m Average action selection time: 0.0330
[32m[0906 18-43-59 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-43-59 @MBExp.py:227][0m Rewards obtained: [262.41330403909177], Lows: [5], Highs: [6], Total time: 8368.771040999996
[32m[0906 18-47-21 @MBExp.py:144][0m ####################################################################
[32m[0906 18-47-21 @MBExp.py:145][0m Starting training iteration 99.
[32m[0906 18-47-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03195, current rewards: -5.40121, mean: -0.54012
[32m[0906 18-47-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03291, current rewards: 0.11107, mean: 0.00185
[32m[0906 18-47-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03329, current rewards: 5.62674, mean: 0.05115
[32m[0906 18-47-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03338, current rewards: 11.14079, mean: 0.06963
[32m[0906 18-47-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03344, current rewards: 16.65183, mean: 0.07929
[32m[0906 18-47-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03344, current rewards: 22.16495, mean: 0.08525
[32m[0906 18-47-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03347, current rewards: 27.91651, mean: 0.09005
[32m[0906 18-47-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03351, current rewards: 33.45028, mean: 0.09292
[32m[0906 18-47-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03352, current rewards: 38.97985, mean: 0.09507
[32m[0906 18-47-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03354, current rewards: 44.65876, mean: 0.09708
[32m[0906 18-47-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03355, current rewards: 50.14793, mean: 0.09833
[32m[0906 18-47-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03355, current rewards: 55.64080, mean: 0.09936
[32m[0906 18-47-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03355, current rewards: 61.12607, mean: 0.10021
[32m[0906 18-47-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03356, current rewards: 66.61283, mean: 0.10093
[32m[0906 18-47-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03347, current rewards: 69.80999, mean: 0.09832
[32m[0906 18-47-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03340, current rewards: 75.33095, mean: 0.09912
[32m[0906 18-47-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03335, current rewards: 80.84729, mean: 0.09981
[32m[0906 18-47-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03329, current rewards: 86.36219, mean: 0.10042
[32m[0906 18-47-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03326, current rewards: 91.87563, mean: 0.10096
[32m[0906 18-47-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03323, current rewards: 97.39051, mean: 0.10145
[32m[0906 18-47-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03319, current rewards: 102.90526, mean: 0.10189
[32m[0906 18-47-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03315, current rewards: 108.42003, mean: 0.10228
[32m[0906 18-47-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03311, current rewards: 113.93903, mean: 0.10265
[32m[0906 18-47-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03309, current rewards: 117.80317, mean: 0.10155
[32m[0906 18-48-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03308, current rewards: 123.23592, mean: 0.10185
[32m[0906 18-48-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03305, current rewards: 128.66787, mean: 0.10212
[32m[0906 18-48-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03303, current rewards: 134.10041, mean: 0.10237
[32m[0906 18-48-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03301, current rewards: 138.51304, mean: 0.10185
[32m[0906 18-48-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03299, current rewards: 144.08338, mean: 0.10219
[32m[0906 18-48-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03299, current rewards: 149.65190, mean: 0.10250
[32m[0906 18-48-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03297, current rewards: 155.22264, mean: 0.10280
[32m[0906 18-48-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03297, current rewards: 160.59878, mean: 0.10295
[32m[0906 18-48-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03295, current rewards: 166.12852, mean: 0.10319
[32m[0906 18-48-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03294, current rewards: 171.68568, mean: 0.10343
[32m[0906 18-48-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03294, current rewards: 177.24576, mean: 0.10365
[32m[0906 18-48-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03293, current rewards: 182.80835, mean: 0.10387
[32m[0906 18-48-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03293, current rewards: 188.36602, mean: 0.10407
[32m[0906 18-48-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03292, current rewards: 193.92656, mean: 0.10426
[32m[0906 18-48-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03291, current rewards: 199.48350, mean: 0.10444
[32m[0906 18-48-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03291, current rewards: 202.91895, mean: 0.10353
[32m[0906 18-48-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03290, current rewards: 208.79551, mean: 0.10388
[32m[0906 18-48-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03290, current rewards: 214.40698, mean: 0.10408
[32m[0906 18-48-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03290, current rewards: 220.02162, mean: 0.10428
[32m[0906 18-48-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03289, current rewards: 225.63677, mean: 0.10446
[32m[0906 18-48-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03289, current rewards: 224.80182, mean: 0.10172
[32m[0906 18-48-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03289, current rewards: 230.52208, mean: 0.10200
[32m[0906 18-48-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03291, current rewards: 236.00766, mean: 0.10217
[32m[0906 18-48-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03292, current rewards: 241.49632, mean: 0.10233
[32m[0906 18-48-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03294, current rewards: 247.02032, mean: 0.10250
[32m[0906 18-48-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03294, current rewards: 252.50496, mean: 0.10264
[32m[0906 18-48-44 @Agent.py:117][0m Average action selection time: 0.0330
[32m[0906 18-48-44 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-48-44 @MBExp.py:227][0m Rewards obtained: [252.81131208955708], Lows: [9], Highs: [5], Total time: 8451.915192999997
[32m[0906 18-52-07 @MBExp.py:144][0m ####################################################################
[32m[0906 18-52-07 @MBExp.py:145][0m Starting training iteration 100.
[32m[0906 18-52-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03682, current rewards: -7.90108, mean: -0.79011
[32m[0906 18-52-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03400, current rewards: -54.41171, mean: -0.90686
[32m[0906 18-52-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03378, current rewards: -96.51021, mean: -0.87737
[32m[0906 18-52-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03372, current rewards: -143.02605, mean: -0.89391
[32m[0906 18-52-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03369, current rewards: -187.31892, mean: -0.89199
[32m[0906 18-52-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03367, current rewards: -234.16712, mean: -0.90064
[32m[0906 18-52-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03369, current rewards: -265.56070, mean: -0.85665
[32m[0906 18-52-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03370, current rewards: -260.23823, mean: -0.72288
[32m[0906 18-52-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03367, current rewards: -254.84799, mean: -0.62158
[32m[0906 18-52-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03365, current rewards: -249.45584, mean: -0.54230
[32m[0906 18-52-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03364, current rewards: -244.00583, mean: -0.47844
[32m[0906 18-52-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03362, current rewards: -238.57128, mean: -0.42602
[32m[0906 18-52-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03360, current rewards: -233.13129, mean: -0.38218
[32m[0906 18-52-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03356, current rewards: -227.68730, mean: -0.34498
[32m[0906 18-52-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03351, current rewards: -222.24833, mean: -0.31303
[32m[0906 18-52-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03344, current rewards: -216.64173, mean: -0.28505
[32m[0906 18-52-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03340, current rewards: -211.08979, mean: -0.26060
[32m[0906 18-52-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03333, current rewards: -205.55409, mean: -0.23902
[32m[0906 18-52-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03329, current rewards: -200.01388, mean: -0.21980
[32m[0906 18-52-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03331, current rewards: -206.31469, mean: -0.21491
[32m[0906 18-52-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03325, current rewards: -200.88794, mean: -0.19890
[32m[0906 18-52-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03322, current rewards: -195.46585, mean: -0.18440
[32m[0906 18-52-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03319, current rewards: -190.04117, mean: -0.17121
[32m[0906 18-52-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03316, current rewards: -183.77611, mean: -0.15843
[32m[0906 18-52-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03314, current rewards: -176.12103, mean: -0.14555
[32m[0906 18-52-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03311, current rewards: -168.46595, mean: -0.13370
[32m[0906 18-52-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03309, current rewards: -160.81086, mean: -0.12276
[32m[0906 18-52-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03308, current rewards: -180.70285, mean: -0.13287
[32m[0906 18-52-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03306, current rewards: -175.22679, mean: -0.12427
[32m[0906 18-52-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03304, current rewards: -169.74853, mean: -0.11627
[32m[0906 18-52-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03304, current rewards: -164.26879, mean: -0.10879
[32m[0906 18-52-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03303, current rewards: -158.91215, mean: -0.10187
[32m[0906 18-53-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03301, current rewards: -153.80118, mean: -0.09553
[32m[0906 18-53-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03300, current rewards: -148.46945, mean: -0.08944
[32m[0906 18-53-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03299, current rewards: -143.14124, mean: -0.08371
[32m[0906 18-53-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03299, current rewards: -137.80861, mean: -0.07830
[32m[0906 18-53-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03298, current rewards: -132.48331, mean: -0.07320
[32m[0906 18-53-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03297, current rewards: -127.14779, mean: -0.06836
[32m[0906 18-53-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03295, current rewards: -121.81311, mean: -0.06378
[32m[0906 18-53-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03295, current rewards: -119.53970, mean: -0.06099
[32m[0906 18-53-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03294, current rewards: -114.09390, mean: -0.05676
[32m[0906 18-53-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03293, current rewards: -108.66017, mean: -0.05275
[32m[0906 18-53-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03291, current rewards: -103.22372, mean: -0.04892
[32m[0906 18-53-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03291, current rewards: -97.79388, mean: -0.04527
[32m[0906 18-53-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03301, current rewards: -137.06165, mean: -0.06202
[32m[0906 18-53-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03314, current rewards: -182.09542, mean: -0.08057
[32m[0906 18-53-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03327, current rewards: -231.87526, mean: -0.10038
[32m[0906 18-53-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03340, current rewards: -276.38089, mean: -0.11711
[32m[0906 18-53-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03354, current rewards: -321.96932, mean: -0.13360
[32m[0906 18-53-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03355, current rewards: -366.50620, mean: -0.14899
[32m[0906 18-53-31 @Agent.py:117][0m Average action selection time: 0.0335
[32m[0906 18-53-31 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-53-31 @MBExp.py:227][0m Rewards obtained: [-401.9307882354878], Lows: [323], Highs: [25], Total time: 8536.554315999998
[32m[0906 18-56-56 @MBExp.py:144][0m ####################################################################
[32m[0906 18-56-56 @MBExp.py:145][0m Starting training iteration 101.
[32m[0906 18-56-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03245, current rewards: -10.43746, mean: -1.04375
[32m[0906 18-56-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03314, current rewards: -4.60154, mean: -0.07669
[32m[0906 18-56-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03319, current rewards: 1.11845, mean: 0.01017
[32m[0906 18-57-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03331, current rewards: 6.84150, mean: 0.04276
[32m[0906 18-57-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03338, current rewards: 12.54852, mean: 0.05975
[32m[0906 18-57-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03340, current rewards: 18.26194, mean: 0.07024
[32m[0906 18-57-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03342, current rewards: 23.97864, mean: 0.07735
[32m[0906 18-57-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03346, current rewards: 30.60660, mean: 0.08502
[32m[0906 18-57-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03347, current rewards: 36.20338, mean: 0.08830
[32m[0906 18-57-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03348, current rewards: 41.85887, mean: 0.09100
[32m[0906 18-57-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03348, current rewards: 47.51864, mean: 0.09317
[32m[0906 18-57-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03349, current rewards: 53.17520, mean: 0.09496
[32m[0906 18-57-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03340, current rewards: 58.82962, mean: 0.09644
[32m[0906 18-57-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03333, current rewards: 64.49016, mean: 0.09771
[32m[0906 18-57-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03328, current rewards: 63.78761, mean: 0.08984
[32m[0906 18-57-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03322, current rewards: 69.53191, mean: 0.09149
[32m[0906 18-57-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03317, current rewards: 75.22834, mean: 0.09287
[32m[0906 18-57-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03314, current rewards: 80.92242, mean: 0.09410
[32m[0906 18-57-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03312, current rewards: 86.61758, mean: 0.09518
[32m[0906 18-57-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03309, current rewards: 92.31086, mean: 0.09616
[32m[0906 18-57-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03307, current rewards: 98.01101, mean: 0.09704
[32m[0906 18-57-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03306, current rewards: 103.70660, mean: 0.09784
[32m[0906 18-57-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03303, current rewards: 104.12225, mean: 0.09380
[32m[0906 18-57-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03302, current rewards: 109.98203, mean: 0.09481
[32m[0906 18-57-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03299, current rewards: 116.15722, mean: 0.09600
[32m[0906 18-57-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03298, current rewards: 122.01896, mean: 0.09684
[32m[0906 18-57-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03298, current rewards: 127.88466, mean: 0.09762
[32m[0906 18-57-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03297, current rewards: 133.74862, mean: 0.09834
[32m[0906 18-57-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03296, current rewards: 139.62017, mean: 0.09902
[32m[0906 18-57-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03295, current rewards: 145.48504, mean: 0.09965
[32m[0906 18-57-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03295, current rewards: 149.70180, mean: 0.09914
[32m[0906 18-57-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03294, current rewards: 155.59798, mean: 0.09974
[32m[0906 18-57-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03293, current rewards: 161.42021, mean: 0.10026
[32m[0906 18-57-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03292, current rewards: 167.37610, mean: 0.10083
[32m[0906 18-57-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03292, current rewards: 173.33306, mean: 0.10136
[32m[0906 18-57-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03290, current rewards: 179.28346, mean: 0.10187
[32m[0906 18-57-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03289, current rewards: 185.23794, mean: 0.10234
[32m[0906 18-57-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03288, current rewards: 191.10214, mean: 0.10274
[32m[0906 18-57-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03288, current rewards: 196.89315, mean: 0.10309
[32m[0906 18-58-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03287, current rewards: 202.68439, mean: 0.10341
[32m[0906 18-58-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03287, current rewards: 208.47541, mean: 0.10372
[32m[0906 18-58-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03286, current rewards: 214.21221, mean: 0.10399
[32m[0906 18-58-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03286, current rewards: 220.00070, mean: 0.10427
[32m[0906 18-58-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03285, current rewards: 225.79266, mean: 0.10453
[32m[0906 18-58-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03286, current rewards: 231.58706, mean: 0.10479
[32m[0906 18-58-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03288, current rewards: 237.37665, mean: 0.10503
[32m[0906 18-58-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03289, current rewards: 243.16652, mean: 0.10527
[32m[0906 18-58-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03290, current rewards: 248.95241, mean: 0.10549
[32m[0906 18-58-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03292, current rewards: 251.78079, mean: 0.10447
[32m[0906 18-58-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03293, current rewards: 257.54679, mean: 0.10469
[32m[0906 18-58-19 @Agent.py:117][0m Average action selection time: 0.0329
[32m[0906 18-58-19 @Agent.py:118][0m Rollout length: 2501
[32m[0906 18-58-19 @MBExp.py:227][0m Rewards obtained: [262.1106208547867], Lows: [12], Highs: [3], Total time: 8619.655981999998
[32m[0906 19-01-45 @MBExp.py:144][0m ####################################################################
[32m[0906 19-01-45 @MBExp.py:145][0m Starting training iteration 102.
[32m[0906 19-01-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03291, current rewards: -0.96688, mean: -0.09669
[32m[0906 19-01-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03342, current rewards: 4.59725, mean: 0.07662
[32m[0906 19-01-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03344, current rewards: 10.12642, mean: 0.09206
[32m[0906 19-01-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03352, current rewards: 15.64849, mean: 0.09780
[32m[0906 19-01-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03354, current rewards: 21.17598, mean: 0.10084
[32m[0906 19-01-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03356, current rewards: 26.70162, mean: 0.10270
[32m[0906 19-01-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03358, current rewards: 32.22506, mean: 0.10395
[32m[0906 19-01-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03361, current rewards: 37.74233, mean: 0.10484
[32m[0906 19-01-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03358, current rewards: 43.26777, mean: 0.10553
[32m[0906 19-02-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03359, current rewards: 48.79680, mean: 0.10608
[32m[0906 19-02-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03360, current rewards: 49.00455, mean: 0.09609
[32m[0906 19-02-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03359, current rewards: 54.47998, mean: 0.09729
[32m[0906 19-02-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03346, current rewards: 59.96232, mean: 0.09830
[32m[0906 19-02-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03340, current rewards: 65.43466, mean: 0.09914
[32m[0906 19-02-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03335, current rewards: 70.90707, mean: 0.09987
[32m[0906 19-02-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03329, current rewards: 76.40905, mean: 0.10054
[32m[0906 19-02-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03325, current rewards: 81.88026, mean: 0.10109
[32m[0906 19-02-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03323, current rewards: 87.36170, mean: 0.10158
[32m[0906 19-02-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03320, current rewards: 92.83658, mean: 0.10202
[32m[0906 19-02-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03317, current rewards: 98.31728, mean: 0.10241
[32m[0906 19-02-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03316, current rewards: 101.77350, mean: 0.10077
[32m[0906 19-02-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03313, current rewards: 107.29003, mean: 0.10122
[32m[0906 19-02-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03312, current rewards: 112.80730, mean: 0.10163
[32m[0906 19-02-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03308, current rewards: 118.45122, mean: 0.10211
[32m[0906 19-02-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03306, current rewards: 123.96588, mean: 0.10245
[32m[0906 19-02-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03305, current rewards: 129.48054, mean: 0.10276
[32m[0906 19-02-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03303, current rewards: 134.99541, mean: 0.10305
[32m[0906 19-02-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03302, current rewards: 140.50894, mean: 0.10332
[32m[0906 19-02-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03300, current rewards: 146.02569, mean: 0.10356
[32m[0906 19-02-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03298, current rewards: 151.54210, mean: 0.10380
[32m[0906 19-02-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03298, current rewards: 155.62353, mean: 0.10306
[32m[0906 19-02-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03296, current rewards: 161.19359, mean: 0.10333
[32m[0906 19-02-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03295, current rewards: 166.72964, mean: 0.10356
[32m[0906 19-02-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03294, current rewards: 172.33147, mean: 0.10381
[32m[0906 19-02-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03294, current rewards: 177.93523, mean: 0.10406
[32m[0906 19-02-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03294, current rewards: 183.54002, mean: 0.10428
[32m[0906 19-02-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03293, current rewards: 189.14371, mean: 0.10450
[32m[0906 19-02-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03291, current rewards: 194.74943, mean: 0.10470
[32m[0906 19-02-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03291, current rewards: 200.34929, mean: 0.10489
[32m[0906 19-02-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03290, current rewards: 205.95139, mean: 0.10508
[32m[0906 19-02-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03289, current rewards: 211.55419, mean: 0.10525
[32m[0906 19-02-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03289, current rewards: 217.15786, mean: 0.10542
[32m[0906 19-02-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03288, current rewards: 220.59495, mean: 0.10455
[32m[0906 19-02-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03287, current rewards: 226.08941, mean: 0.10467
[32m[0906 19-02-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03288, current rewards: 231.58626, mean: 0.10479
[32m[0906 19-03-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03290, current rewards: 237.08766, mean: 0.10491
[32m[0906 19-03-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03291, current rewards: 242.58506, mean: 0.10502
[32m[0906 19-03-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03292, current rewards: 248.08478, mean: 0.10512
[32m[0906 19-03-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03293, current rewards: 253.53538, mean: 0.10520
[32m[0906 19-03-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03295, current rewards: 259.02887, mean: 0.10530
[32m[0906 19-03-08 @Agent.py:117][0m Average action selection time: 0.0330
[32m[0906 19-03-08 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-03-08 @MBExp.py:227][0m Rewards obtained: [263.42404132664745], Lows: [4], Highs: [5], Total time: 8702.806315999998
[32m[0906 19-06-36 @MBExp.py:144][0m ####################################################################
[32m[0906 19-06-36 @MBExp.py:145][0m Starting training iteration 103.
[32m[0906 19-06-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03239, current rewards: -2.02336, mean: -0.20234
[32m[0906 19-06-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03325, current rewards: 4.79185, mean: 0.07986
[32m[0906 19-06-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03338, current rewards: 11.55925, mean: 0.10508
[32m[0906 19-06-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03346, current rewards: 18.31662, mean: 0.11448
[32m[0906 19-06-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03348, current rewards: 25.06054, mean: 0.11934
[32m[0906 19-06-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03358, current rewards: 31.80526, mean: 0.12233
[32m[0906 19-06-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03359, current rewards: 38.54870, mean: 0.12435
[32m[0906 19-06-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03360, current rewards: 45.30175, mean: 0.12584
[32m[0906 19-06-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03360, current rewards: 52.04679, mean: 0.12694
[32m[0906 19-06-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03357, current rewards: 55.79035, mean: 0.12128
[32m[0906 19-06-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03359, current rewards: 61.61669, mean: 0.12082
[32m[0906 19-06-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03351, current rewards: 67.43891, mean: 0.12043
[32m[0906 19-06-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03345, current rewards: 73.23500, mean: 0.12006
[32m[0906 19-06-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03338, current rewards: 77.54750, mean: 0.11750
[32m[0906 19-07-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03332, current rewards: 82.78380, mean: 0.11660
[32m[0906 19-07-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03327, current rewards: 88.12232, mean: 0.11595
[32m[0906 19-07-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03322, current rewards: 93.48954, mean: 0.11542
[32m[0906 19-07-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03318, current rewards: 98.85641, mean: 0.11495
[32m[0906 19-07-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03311, current rewards: 104.22042, mean: 0.11453
[32m[0906 19-07-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03308, current rewards: 109.59140, mean: 0.11416
[32m[0906 19-07-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03305, current rewards: 114.95981, mean: 0.11382
[32m[0906 19-07-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03304, current rewards: 120.32868, mean: 0.11352
[32m[0906 19-07-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03302, current rewards: 125.70049, mean: 0.11324
[32m[0906 19-07-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03299, current rewards: 131.35617, mean: 0.11324
[32m[0906 19-07-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03296, current rewards: 132.78735, mean: 0.10974
[32m[0906 19-07-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03294, current rewards: 138.23077, mean: 0.10971
[32m[0906 19-07-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03293, current rewards: 143.67603, mean: 0.10968
[32m[0906 19-07-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03292, current rewards: 149.10229, mean: 0.10963
[32m[0906 19-07-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03291, current rewards: 154.60698, mean: 0.10965
[32m[0906 19-07-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03290, current rewards: 160.10128, mean: 0.10966
[32m[0906 19-07-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03290, current rewards: 165.53940, mean: 0.10963
[32m[0906 19-07-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03290, current rewards: 169.26620, mean: 0.10850
[32m[0906 19-07-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03288, current rewards: 174.90143, mean: 0.10863
[32m[0906 19-07-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03288, current rewards: 180.53710, mean: 0.10876
[32m[0906 19-07-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03287, current rewards: 186.17275, mean: 0.10887
[32m[0906 19-07-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03286, current rewards: 191.80907, mean: 0.10898
[32m[0906 19-07-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03286, current rewards: 197.44450, mean: 0.10909
[32m[0906 19-07-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03284, current rewards: 203.07933, mean: 0.10918
[32m[0906 19-07-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03284, current rewards: 208.71523, mean: 0.10927
[32m[0906 19-07-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03284, current rewards: 214.27870, mean: 0.10933
[32m[0906 19-07-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03283, current rewards: 219.45791, mean: 0.10918
[32m[0906 19-07-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03282, current rewards: 219.86858, mean: 0.10673
[32m[0906 19-07-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03281, current rewards: 227.68437, mean: 0.10791
[32m[0906 19-07-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03281, current rewards: 234.98279, mean: 0.10879
[32m[0906 19-07-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03282, current rewards: 242.16166, mean: 0.10958
[32m[0906 19-07-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03284, current rewards: 249.60253, mean: 0.11044
[32m[0906 19-07-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03286, current rewards: 257.15246, mean: 0.11132
[32m[0906 19-07-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03288, current rewards: 264.57632, mean: 0.11211
[32m[0906 19-07-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03289, current rewards: 272.41986, mean: 0.11304
[32m[0906 19-07-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03290, current rewards: 279.96660, mean: 0.11381
[32m[0906 19-07-59 @Agent.py:117][0m Average action selection time: 0.0329
[32m[0906 19-07-59 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-07-59 @MBExp.py:227][0m Rewards obtained: [270.6517483936579], Lows: [14], Highs: [4], Total time: 8785.920939999998
[32m[0906 19-11-29 @MBExp.py:144][0m ####################################################################
[32m[0906 19-11-29 @MBExp.py:145][0m Starting training iteration 104.
[32m[0906 19-11-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03345, current rewards: 0.69984, mean: 0.06998
[32m[0906 19-11-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03359, current rewards: 0.81263, mean: 0.01354
[32m[0906 19-11-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03362, current rewards: 4.99556, mean: 0.04541
[32m[0906 19-11-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03362, current rewards: 8.62889, mean: 0.05393
[32m[0906 19-11-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03359, current rewards: 12.26222, mean: 0.05839
[32m[0906 19-11-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03356, current rewards: 15.89555, mean: 0.06114
[32m[0906 19-11-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03354, current rewards: 20.06501, mean: 0.06473
[32m[0906 19-11-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03355, current rewards: -9.84871, mean: -0.02736
[32m[0906 19-11-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03357, current rewards: -59.84871, mean: -0.14597
[32m[0906 19-11-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03357, current rewards: -109.84871, mean: -0.23880
[32m[0906 19-11-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03353, current rewards: -159.84871, mean: -0.31343
[32m[0906 19-11-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03343, current rewards: -209.84871, mean: -0.37473
[32m[0906 19-11-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03336, current rewards: -256.63580, mean: -0.42071
[32m[0906 19-11-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03331, current rewards: -243.54543, mean: -0.36901
[32m[0906 19-11-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03324, current rewards: -230.24565, mean: -0.32429
[32m[0906 19-11-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03318, current rewards: -216.30596, mean: -0.28461
[32m[0906 19-11-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03314, current rewards: -210.87557, mean: -0.26034
[32m[0906 19-11-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03312, current rewards: -205.50846, mean: -0.23896
[32m[0906 19-11-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03309, current rewards: -200.13190, mean: -0.21993
[32m[0906 19-12-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03307, current rewards: -194.76212, mean: -0.20288
[32m[0906 19-12-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03306, current rewards: -189.40084, mean: -0.18753
[32m[0906 19-12-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03305, current rewards: -184.02623, mean: -0.17361
[32m[0906 19-12-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03304, current rewards: -178.67689, mean: -0.16097
[32m[0906 19-12-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03302, current rewards: -173.49632, mean: -0.14957
[32m[0906 19-12-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03299, current rewards: -168.26175, mean: -0.13906
[32m[0906 19-12-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03297, current rewards: -163.03088, mean: -0.12939
[32m[0906 19-12-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03295, current rewards: -157.78021, mean: -0.12044
[32m[0906 19-12-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03293, current rewards: -155.44896, mean: -0.11430
[32m[0906 19-12-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03292, current rewards: -150.26177, mean: -0.10657
[32m[0906 19-12-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03291, current rewards: -145.07319, mean: -0.09937
[32m[0906 19-12-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03291, current rewards: -139.89132, mean: -0.09264
[32m[0906 19-12-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03290, current rewards: -134.52625, mean: -0.08623
[32m[0906 19-12-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03289, current rewards: -129.35118, mean: -0.08034
[32m[0906 19-12-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03288, current rewards: -124.16440, mean: -0.07480
[32m[0906 19-12-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03288, current rewards: -118.98342, mean: -0.06958
[32m[0906 19-12-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03287, current rewards: -113.80252, mean: -0.06466
[32m[0906 19-12-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03287, current rewards: -108.59721, mean: -0.06000
[32m[0906 19-12-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03286, current rewards: -103.41016, mean: -0.05560
[32m[0906 19-12-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03286, current rewards: -98.21093, mean: -0.05142
[32m[0906 19-12-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03287, current rewards: -131.82245, mean: -0.06726
[32m[0906 19-12-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03287, current rewards: -157.67723, mean: -0.07845
[32m[0906 19-12-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03287, current rewards: -183.19609, mean: -0.08893
[32m[0906 19-12-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03286, current rewards: -213.12311, mean: -0.10101
[32m[0906 19-12-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03286, current rewards: -238.88920, mean: -0.11060
[32m[0906 19-12-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03286, current rewards: -264.35234, mean: -0.11962
[32m[0906 19-12-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03288, current rewards: -294.38752, mean: -0.13026
[32m[0906 19-12-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03290, current rewards: -320.32916, mean: -0.13867
[32m[0906 19-12-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03291, current rewards: -317.05292, mean: -0.13434
[32m[0906 19-12-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03292, current rewards: -303.10096, mean: -0.12577
[32m[0906 19-12-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03294, current rewards: -289.56305, mean: -0.11771
[32m[0906 19-12-52 @Agent.py:117][0m Average action selection time: 0.0329
[32m[0906 19-12-52 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-12-52 @MBExp.py:227][0m Rewards obtained: [-278.40432818656177], Lows: [145], Highs: [281], Total time: 8869.046669999998
[32m[0906 19-16-25 @MBExp.py:144][0m ####################################################################
[32m[0906 19-16-25 @MBExp.py:145][0m Starting training iteration 105.
[32m[0906 19-16-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03340, current rewards: 0.00523, mean: 0.00052
[32m[0906 19-16-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03336, current rewards: 5.83008, mean: 0.09717
[32m[0906 19-16-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03341, current rewards: 11.45792, mean: 0.10416
[32m[0906 19-16-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03346, current rewards: 17.08553, mean: 0.10678
[32m[0906 19-16-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03341, current rewards: 22.71123, mean: 0.10815
[32m[0906 19-16-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03344, current rewards: 26.87473, mean: 0.10336
[32m[0906 19-16-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03346, current rewards: 31.91486, mean: 0.10295
[32m[0906 19-16-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03347, current rewards: 37.07695, mean: 0.10299
[32m[0906 19-16-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03350, current rewards: 42.23654, mean: 0.10302
[32m[0906 19-16-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03352, current rewards: 46.42337, mean: 0.10092
[32m[0906 19-16-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03343, current rewards: 51.86260, mean: 0.10169
[32m[0906 19-16-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03336, current rewards: 57.29958, mean: 0.10232
[32m[0906 19-16-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03330, current rewards: 62.73678, mean: 0.10285
[32m[0906 19-16-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03327, current rewards: 68.16920, mean: 0.10329
[32m[0906 19-16-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03323, current rewards: 73.56544, mean: 0.10361
[32m[0906 19-16-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03318, current rewards: 78.99913, mean: 0.10395
[32m[0906 19-16-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03313, current rewards: 84.42545, mean: 0.10423
[32m[0906 19-16-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03311, current rewards: 89.85907, mean: 0.10449
[32m[0906 19-16-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03309, current rewards: 93.19301, mean: 0.10241
[32m[0906 19-16-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03306, current rewards: 98.71514, mean: 0.10283
[32m[0906 19-16-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03305, current rewards: 104.24279, mean: 0.10321
[32m[0906 19-17-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03302, current rewards: 109.76847, mean: 0.10356
[32m[0906 19-17-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03301, current rewards: 115.20787, mean: 0.10379
[32m[0906 19-17-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03299, current rewards: 120.74950, mean: 0.10409
[32m[0906 19-17-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03297, current rewards: 126.28548, mean: 0.10437
[32m[0906 19-17-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03295, current rewards: 131.82081, mean: 0.10462
[32m[0906 19-17-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03293, current rewards: 137.36164, mean: 0.10486
[32m[0906 19-17-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03291, current rewards: 142.90619, mean: 0.10508
[32m[0906 19-17-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03289, current rewards: 148.44480, mean: 0.10528
[32m[0906 19-17-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03287, current rewards: 153.98689, mean: 0.10547
[32m[0906 19-17-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03286, current rewards: 159.66883, mean: 0.10574
[32m[0906 19-17-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03285, current rewards: 161.97852, mean: 0.10383
[32m[0906 19-17-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03283, current rewards: 169.43871, mean: 0.10524
[32m[0906 19-17-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03283, current rewards: 176.89890, mean: 0.10657
[32m[0906 19-17-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03281, current rewards: 184.35909, mean: 0.10781
[32m[0906 19-17-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03281, current rewards: 191.81928, mean: 0.10899
[32m[0906 19-17-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03279, current rewards: 199.27947, mean: 0.11010
[32m[0906 19-17-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03279, current rewards: 198.69524, mean: 0.10683
[32m[0906 19-17-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03278, current rewards: 148.69524, mean: 0.07785
[32m[0906 19-17-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03279, current rewards: 98.69524, mean: 0.05035
[32m[0906 19-17-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03278, current rewards: 48.69524, mean: 0.02423
[32m[0906 19-17-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03278, current rewards: -1.30476, mean: -0.00063
[32m[0906 19-17-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03278, current rewards: -51.30476, mean: -0.02432
[32m[0906 19-17-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03276, current rewards: -101.30476, mean: -0.04690
[32m[0906 19-17-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03278, current rewards: -151.30476, mean: -0.06846
[32m[0906 19-17-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03279, current rewards: -201.30476, mean: -0.08907
[32m[0906 19-17-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03281, current rewards: -251.30476, mean: -0.10879
[32m[0906 19-17-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03283, current rewards: -301.30476, mean: -0.12767
[32m[0906 19-17-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03284, current rewards: -351.30476, mean: -0.14577
[32m[0906 19-17-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03286, current rewards: -401.30476, mean: -0.16313
[32m[0906 19-17-47 @Agent.py:117][0m Average action selection time: 0.0329
[32m[0906 19-17-47 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-17-48 @MBExp.py:227][0m Rewards obtained: [-441.30476420804143], Lows: [4], Highs: [649], Total time: 8951.999237999999
[32m[0906 19-21-21 @MBExp.py:144][0m ####################################################################
[32m[0906 19-21-21 @MBExp.py:145][0m Starting training iteration 106.
[32m[0906 19-21-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03960, current rewards: -4.36225, mean: -0.43622
[32m[0906 19-21-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03697, current rewards: -13.01096, mean: -0.21685
[32m[0906 19-21-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03637, current rewards: -4.77403, mean: -0.04340
[32m[0906 19-21-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03608, current rewards: 3.54075, mean: 0.02213
[32m[0906 19-21-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03574, current rewards: 12.07577, mean: 0.05750
[32m[0906 19-21-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03573, current rewards: 19.31431, mean: 0.07429
[32m[0906 19-21-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03562, current rewards: 27.93550, mean: 0.09011
[32m[0906 19-21-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03551, current rewards: 36.36572, mean: 0.10102
[32m[0906 19-21-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03529, current rewards: 37.34295, mean: 0.09108
[32m[0906 19-21-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03501, current rewards: 43.45567, mean: 0.09447
[32m[0906 19-21-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03480, current rewards: 49.45810, mean: 0.09698
[32m[0906 19-21-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03458, current rewards: 53.35209, mean: 0.09527
[32m[0906 19-21-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03486, current rewards: 28.85601, mean: 0.04730
[32m[0906 19-21-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03538, current rewards: 36.18130, mean: 0.05482
[32m[0906 19-21-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03546, current rewards: 18.29742, mean: 0.02577
[32m[0906 19-21-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03544, current rewards: -27.39544, mean: -0.03605
[32m[0906 19-21-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03526, current rewards: -77.39544, mean: -0.09555
[32m[0906 19-21-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03508, current rewards: -127.39544, mean: -0.14813
[32m[0906 19-21-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03496, current rewards: -177.39544, mean: -0.19494
[32m[0906 19-21-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03485, current rewards: -227.39544, mean: -0.23687
[32m[0906 19-21-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03474, current rewards: -277.39544, mean: -0.27465
[32m[0906 19-21-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03464, current rewards: -327.39544, mean: -0.30886
[32m[0906 19-22-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03456, current rewards: -366.10368, mean: -0.32982
[32m[0906 19-22-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03447, current rewards: -359.64486, mean: -0.31004
[32m[0906 19-22-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03440, current rewards: -353.18603, mean: -0.29189
[32m[0906 19-22-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03432, current rewards: -346.72721, mean: -0.27518
[32m[0906 19-22-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03427, current rewards: -391.08133, mean: -0.29854
[32m[0906 19-22-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03421, current rewards: -441.08133, mean: -0.32432
[32m[0906 19-22-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03415, current rewards: -491.08133, mean: -0.34828
[32m[0906 19-22-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03410, current rewards: -541.08133, mean: -0.37060
[32m[0906 19-22-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03404, current rewards: -591.08133, mean: -0.39144
[32m[0906 19-22-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03398, current rewards: -641.08133, mean: -0.41095
[32m[0906 19-22-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03394, current rewards: -691.08133, mean: -0.42924
[32m[0906 19-22-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03392, current rewards: -741.08133, mean: -0.44643
[32m[0906 19-22-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03387, current rewards: -791.08133, mean: -0.46262
[32m[0906 19-22-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03383, current rewards: -841.08133, mean: -0.47789
[32m[0906 19-22-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03380, current rewards: -891.08133, mean: -0.49231
[32m[0906 19-22-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03376, current rewards: -941.08133, mean: -0.50596
[32m[0906 19-22-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03374, current rewards: -991.08133, mean: -0.51889
[32m[0906 19-22-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03371, current rewards: -1041.08133, mean: -0.53116
[32m[0906 19-22-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03368, current rewards: -1091.08133, mean: -0.54283
[32m[0906 19-22-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03365, current rewards: -1141.08133, mean: -0.55392
[32m[0906 19-22-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03363, current rewards: -1191.08133, mean: -0.56449
[32m[0906 19-22-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03362, current rewards: -1241.08133, mean: -0.57457
[32m[0906 19-22-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03361, current rewards: -1291.08133, mean: -0.58420
[32m[0906 19-22-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03361, current rewards: -1341.08133, mean: -0.59340
[32m[0906 19-22-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03361, current rewards: -1391.08133, mean: -0.60220
[32m[0906 19-22-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03360, current rewards: -1441.08133, mean: -0.61063
[32m[0906 19-22-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03360, current rewards: -1491.08133, mean: -0.61871
[32m[0906 19-22-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03359, current rewards: -1541.08133, mean: -0.62646
[32m[0906 19-22-46 @Agent.py:117][0m Average action selection time: 0.0336
[32m[0906 19-22-46 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-22-46 @MBExp.py:227][0m Rewards obtained: [-1581.0813267345688], Lows: [35], Highs: [1631], Total time: 9036.742287
[32m[0906 19-26-22 @MBExp.py:144][0m ####################################################################
[32m[0906 19-26-22 @MBExp.py:145][0m Starting training iteration 107.
[32m[0906 19-26-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03242, current rewards: -3.11724, mean: -0.31172
[32m[0906 19-26-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03322, current rewards: 2.70790, mean: 0.04513
[32m[0906 19-26-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03338, current rewards: 8.53123, mean: 0.07756
[32m[0906 19-26-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03341, current rewards: 14.34664, mean: 0.08967
[32m[0906 19-26-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03339, current rewards: 20.16335, mean: 0.09602
[32m[0906 19-26-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03341, current rewards: 26.10946, mean: 0.10042
[32m[0906 19-26-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03346, current rewards: 31.73589, mean: 0.10237
[32m[0906 19-26-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03346, current rewards: 37.25220, mean: 0.10348
[32m[0906 19-26-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03348, current rewards: 42.76562, mean: 0.10431
[32m[0906 19-26-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03350, current rewards: 48.27439, mean: 0.10494
[32m[0906 19-26-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03349, current rewards: 53.78530, mean: 0.10546
[32m[0906 19-26-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03340, current rewards: 59.29783, mean: 0.10589
[32m[0906 19-26-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03334, current rewards: 64.81200, mean: 0.10625
[32m[0906 19-26-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03329, current rewards: 68.26780, mean: 0.10344
[32m[0906 19-26-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03325, current rewards: 73.92556, mean: 0.10412
[32m[0906 19-26-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03321, current rewards: 79.58542, mean: 0.10472
[32m[0906 19-26-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03316, current rewards: 85.24002, mean: 0.10523
[32m[0906 19-26-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03315, current rewards: 90.90092, mean: 0.10570
[32m[0906 19-26-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03310, current rewards: 96.55773, mean: 0.10611
[32m[0906 19-26-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03309, current rewards: 102.21619, mean: 0.10648
[32m[0906 19-26-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03307, current rewards: 107.87091, mean: 0.10680
[32m[0906 19-26-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03302, current rewards: 113.62263, mean: 0.10719
[32m[0906 19-26-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03302, current rewards: 117.17269, mean: 0.10556
[32m[0906 19-27-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03300, current rewards: 122.71833, mean: 0.10579
[32m[0906 19-27-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03299, current rewards: 128.26190, mean: 0.10600
[32m[0906 19-27-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03297, current rewards: 133.80905, mean: 0.10620
[32m[0906 19-27-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03295, current rewards: 139.35157, mean: 0.10638
[32m[0906 19-27-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03294, current rewards: 144.89790, mean: 0.10654
[32m[0906 19-27-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03294, current rewards: 148.66766, mean: 0.10544
[32m[0906 19-27-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03293, current rewards: 154.17953, mean: 0.10560
[32m[0906 19-27-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03292, current rewards: 159.56921, mean: 0.10567
[32m[0906 19-27-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03290, current rewards: 165.12502, mean: 0.10585
[32m[0906 19-27-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03289, current rewards: 170.68103, mean: 0.10601
[32m[0906 19-27-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03289, current rewards: 176.23502, mean: 0.10617
[32m[0906 19-27-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03288, current rewards: 181.79072, mean: 0.10631
[32m[0906 19-27-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03287, current rewards: 187.34357, mean: 0.10645
[32m[0906 19-27-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03287, current rewards: 192.90319, mean: 0.10658
[32m[0906 19-27-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03284, current rewards: 196.54729, mean: 0.10567
[32m[0906 19-27-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03284, current rewards: 202.06150, mean: 0.10579
[32m[0906 19-27-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03282, current rewards: 207.61798, mean: 0.10593
[32m[0906 19-27-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03282, current rewards: 213.17604, mean: 0.10606
[32m[0906 19-27-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03282, current rewards: 218.73484, mean: 0.10618
[32m[0906 19-27-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03281, current rewards: 224.29040, mean: 0.10630
[32m[0906 19-27-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03282, current rewards: 229.84707, mean: 0.10641
[32m[0906 19-27-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03284, current rewards: 235.40627, mean: 0.10652
[32m[0906 19-27-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03285, current rewards: 240.96547, mean: 0.10662
[32m[0906 19-27-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03286, current rewards: 246.59899, mean: 0.10675
[32m[0906 19-27-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03287, current rewards: 252.15853, mean: 0.10685
[32m[0906 19-27-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03288, current rewards: 257.70993, mean: 0.10693
[32m[0906 19-27-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03290, current rewards: 262.05581, mean: 0.10653
[32m[0906 19-27-45 @Agent.py:117][0m Average action selection time: 0.0329
[32m[0906 19-27-45 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-27-45 @MBExp.py:227][0m Rewards obtained: [266.5010106868247], Lows: [5], Highs: [3], Total time: 9119.766134
[32m[0906 19-31-23 @MBExp.py:144][0m ####################################################################
[32m[0906 19-31-23 @MBExp.py:145][0m Starting training iteration 108.
[32m[0906 19-31-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03251, current rewards: 0.97310, mean: 0.09731
[32m[0906 19-31-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03335, current rewards: 6.45550, mean: 0.10759
[32m[0906 19-31-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03342, current rewards: 11.93862, mean: 0.10853
[32m[0906 19-31-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03349, current rewards: 17.42291, mean: 0.10889
[32m[0906 19-31-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03354, current rewards: 22.90681, mean: 0.10908
[32m[0906 19-31-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03350, current rewards: 28.39083, mean: 0.10920
[32m[0906 19-31-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03350, current rewards: 33.87303, mean: 0.10927
[32m[0906 19-31-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03348, current rewards: 39.35452, mean: 0.10932
[32m[0906 19-31-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03348, current rewards: 44.83965, mean: 0.10937
[32m[0906 19-31-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03347, current rewards: 49.16444, mean: 0.10688
[32m[0906 19-31-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03339, current rewards: 54.70608, mean: 0.10727
[32m[0906 19-31-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03334, current rewards: 60.24312, mean: 0.10758
[32m[0906 19-31-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03328, current rewards: 65.90608, mean: 0.10804
[32m[0906 19-31-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03320, current rewards: 71.46092, mean: 0.10827
[32m[0906 19-31-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03317, current rewards: 77.01206, mean: 0.10847
[32m[0906 19-31-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03313, current rewards: 82.56487, mean: 0.10864
[32m[0906 19-31-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03306, current rewards: 88.12044, mean: 0.10879
[32m[0906 19-31-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03304, current rewards: 93.67121, mean: 0.10892
[32m[0906 19-31-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03301, current rewards: 99.22545, mean: 0.10904
[32m[0906 19-31-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03299, current rewards: 99.46728, mean: 0.10361
[32m[0906 19-31-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03297, current rewards: 104.83295, mean: 0.10380
[32m[0906 19-31-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03295, current rewards: 110.22517, mean: 0.10399
[32m[0906 19-31-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03294, current rewards: 115.62362, mean: 0.10417
[32m[0906 19-32-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03292, current rewards: 121.01742, mean: 0.10433
[32m[0906 19-32-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03292, current rewards: 126.41756, mean: 0.10448
[32m[0906 19-32-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03291, current rewards: 131.82009, mean: 0.10462
[32m[0906 19-32-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03291, current rewards: 137.21762, mean: 0.10475
[32m[0906 19-32-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03290, current rewards: 142.61937, mean: 0.10487
[32m[0906 19-32-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03289, current rewards: 147.97993, mean: 0.10495
[32m[0906 19-32-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03290, current rewards: 151.33302, mean: 0.10365
[32m[0906 19-32-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03289, current rewards: 157.01270, mean: 0.10398
[32m[0906 19-32-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03289, current rewards: 162.69065, mean: 0.10429
[32m[0906 19-32-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03289, current rewards: 168.36220, mean: 0.10457
[32m[0906 19-32-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03288, current rewards: 174.04041, mean: 0.10484
[32m[0906 19-32-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03288, current rewards: 176.46562, mean: 0.10320
[32m[0906 19-32-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03288, current rewards: 182.05595, mean: 0.10344
[32m[0906 19-32-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03288, current rewards: 187.64899, mean: 0.10367
[32m[0906 19-32-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03287, current rewards: 193.24081, mean: 0.10389
[32m[0906 19-32-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03286, current rewards: 198.83725, mean: 0.10410
[32m[0906 19-32-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03284, current rewards: 204.43092, mean: 0.10430
[32m[0906 19-32-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03284, current rewards: 210.02829, mean: 0.10449
[32m[0906 19-32-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03285, current rewards: 215.62470, mean: 0.10467
[32m[0906 19-32-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03284, current rewards: 221.22949, mean: 0.10485
[32m[0906 19-32-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03285, current rewards: 226.75521, mean: 0.10498
[32m[0906 19-32-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03287, current rewards: 232.28369, mean: 0.10511
[32m[0906 19-32-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03289, current rewards: 238.02757, mean: 0.10532
[32m[0906 19-32-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03290, current rewards: 243.58383, mean: 0.10545
[32m[0906 19-32-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03291, current rewards: 249.14401, mean: 0.10557
[32m[0906 19-32-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03292, current rewards: 254.70148, mean: 0.10569
[32m[0906 19-32-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03294, current rewards: 260.26006, mean: 0.10580
[32m[0906 19-32-45 @Agent.py:117][0m Average action selection time: 0.0330
[32m[0906 19-32-45 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-32-46 @MBExp.py:227][0m Rewards obtained: [264.7114986971432], Lows: [4], Highs: [3], Total time: 9202.907438
[32m[0906 19-36-25 @MBExp.py:144][0m ####################################################################
[32m[0906 19-36-25 @MBExp.py:145][0m Starting training iteration 109.
[32m[0906 19-36-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03272, current rewards: -0.03878, mean: -0.00388
[32m[0906 19-36-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03335, current rewards: 5.52430, mean: 0.09207
[32m[0906 19-36-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03337, current rewards: 11.08873, mean: 0.10081
[32m[0906 19-36-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03341, current rewards: 16.64581, mean: 0.10404
[32m[0906 19-36-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03345, current rewards: 22.21147, mean: 0.10577
[32m[0906 19-36-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03347, current rewards: 27.77790, mean: 0.10684
[32m[0906 19-36-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03349, current rewards: 33.33833, mean: 0.10754
[32m[0906 19-36-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03350, current rewards: 38.90488, mean: 0.10807
[32m[0906 19-36-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03352, current rewards: 44.47116, mean: 0.10847
[32m[0906 19-36-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03350, current rewards: 50.03993, mean: 0.10878
[32m[0906 19-36-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03343, current rewards: 54.03973, mean: 0.10596
[32m[0906 19-36-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03335, current rewards: 59.88256, mean: 0.10693
[32m[0906 19-36-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03329, current rewards: 66.19798, mean: 0.10852
[32m[0906 19-36-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03322, current rewards: 72.51341, mean: 0.10987
[32m[0906 19-36-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03318, current rewards: 63.06052, mean: 0.08882
[32m[0906 19-36-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03315, current rewards: 13.06052, mean: 0.01718
[32m[0906 19-36-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03309, current rewards: -36.93948, mean: -0.04560
[32m[0906 19-36-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03305, current rewards: -86.93948, mean: -0.10109
[32m[0906 19-36-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03302, current rewards: -136.93948, mean: -0.15048
[32m[0906 19-36-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03300, current rewards: -186.93948, mean: -0.19473
[32m[0906 19-36-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03297, current rewards: -236.93948, mean: -0.23459
[32m[0906 19-37-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03297, current rewards: -286.93948, mean: -0.27070
[32m[0906 19-37-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03294, current rewards: -336.93948, mean: -0.30355
[32m[0906 19-37-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03294, current rewards: -386.93948, mean: -0.33357
[32m[0906 19-37-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03293, current rewards: -436.93948, mean: -0.36111
[32m[0906 19-37-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03293, current rewards: -486.93948, mean: -0.38646
[32m[0906 19-37-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03291, current rewards: -536.93948, mean: -0.40988
[32m[0906 19-37-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03288, current rewards: -586.93948, mean: -0.43157
[32m[0906 19-37-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03288, current rewards: -636.93948, mean: -0.45173
[32m[0906 19-37-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03287, current rewards: -686.93948, mean: -0.47051
[32m[0906 19-37-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03286, current rewards: -736.93948, mean: -0.48804
[32m[0906 19-37-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03285, current rewards: -786.93948, mean: -0.50445
[32m[0906 19-37-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03283, current rewards: -836.93948, mean: -0.51984
[32m[0906 19-37-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03283, current rewards: -886.93948, mean: -0.53430
[32m[0906 19-37-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03284, current rewards: -936.93948, mean: -0.54792
[32m[0906 19-37-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03283, current rewards: -986.93948, mean: -0.56076
[32m[0906 19-37-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03282, current rewards: -1036.93948, mean: -0.57289
[32m[0906 19-37-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03281, current rewards: -1086.93948, mean: -0.58438
[32m[0906 19-37-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03281, current rewards: -1136.93948, mean: -0.59526
[32m[0906 19-37-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03280, current rewards: -1186.93948, mean: -0.60558
[32m[0906 19-37-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03278, current rewards: -1236.93948, mean: -0.61539
[32m[0906 19-37-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03278, current rewards: -1286.93948, mean: -0.62473
[32m[0906 19-37-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03278, current rewards: -1336.93948, mean: -0.63362
[32m[0906 19-37-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03278, current rewards: -1386.93948, mean: -0.64210
[32m[0906 19-37-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03280, current rewards: -1436.93948, mean: -0.65020
[32m[0906 19-37-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03282, current rewards: -1486.93948, mean: -0.65794
[32m[0906 19-37-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03284, current rewards: -1536.93948, mean: -0.66534
[32m[0906 19-37-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03285, current rewards: -1586.93948, mean: -0.67243
[32m[0906 19-37-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03286, current rewards: -1636.93948, mean: -0.67923
[32m[0906 19-37-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03287, current rewards: -1686.93948, mean: -0.68575
[32m[0906 19-37-48 @Agent.py:117][0m Average action selection time: 0.0329
[32m[0906 19-37-48 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-37-48 @MBExp.py:227][0m Rewards obtained: [-1726.9394847412948], Lows: [1], Highs: [1805], Total time: 9285.872987
[32m[0906 19-41-30 @MBExp.py:144][0m ####################################################################
[32m[0906 19-41-30 @MBExp.py:145][0m Starting training iteration 110.
[32m[0906 19-41-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03552, current rewards: -6.91987, mean: -0.69199
[32m[0906 19-41-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03376, current rewards: -1.36194, mean: -0.02270
[32m[0906 19-41-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03365, current rewards: 4.17249, mean: 0.03793
[32m[0906 19-41-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03364, current rewards: 9.93003, mean: 0.06206
[32m[0906 19-41-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03359, current rewards: 15.47698, mean: 0.07370
[32m[0906 19-41-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03355, current rewards: 21.02418, mean: 0.08086
[32m[0906 19-41-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03357, current rewards: 26.57107, mean: 0.08571
[32m[0906 19-41-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03358, current rewards: 32.11700, mean: 0.08921
[32m[0906 19-41-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03358, current rewards: 37.66544, mean: 0.09187
[32m[0906 19-41-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03358, current rewards: 35.85478, mean: 0.07795
[32m[0906 19-41-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03358, current rewards: 41.31753, mean: 0.08101
[32m[0906 19-41-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03358, current rewards: 46.72057, mean: 0.08343
[32m[0906 19-41-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03358, current rewards: 51.86432, mean: 0.08502
[32m[0906 19-41-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03357, current rewards: 57.24734, mean: 0.08674
[32m[0906 19-41-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03354, current rewards: 62.62809, mean: 0.08821
[32m[0906 19-41-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03346, current rewards: 68.00440, mean: 0.08948
[32m[0906 19-41-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03338, current rewards: 73.38656, mean: 0.09060
[32m[0906 19-41-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03334, current rewards: 78.77023, mean: 0.09159
[32m[0906 19-42-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03329, current rewards: 84.15653, mean: 0.09248
[32m[0906 19-42-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03323, current rewards: 89.53639, mean: 0.09327
[32m[0906 19-42-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03320, current rewards: 95.26933, mean: 0.09433
[32m[0906 19-42-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03317, current rewards: 100.82788, mean: 0.09512
[32m[0906 19-42-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03314, current rewards: 104.74450, mean: 0.09436
[32m[0906 19-42-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03311, current rewards: 110.13269, mean: 0.09494
[32m[0906 19-42-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03309, current rewards: 115.51600, mean: 0.09547
[32m[0906 19-42-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03307, current rewards: 120.89700, mean: 0.09595
[32m[0906 19-42-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03304, current rewards: 126.27917, mean: 0.09640
[32m[0906 19-42-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03301, current rewards: 131.66389, mean: 0.09681
[32m[0906 19-42-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03300, current rewards: 137.04509, mean: 0.09720
[32m[0906 19-42-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03299, current rewards: 142.22498, mean: 0.09741
[32m[0906 19-42-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03298, current rewards: 147.48413, mean: 0.09767
[32m[0906 19-42-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03297, current rewards: 152.74465, mean: 0.09791
[32m[0906 19-42-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03295, current rewards: 156.13264, mean: 0.09698
[32m[0906 19-42-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03294, current rewards: 161.64227, mean: 0.09737
[32m[0906 19-42-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03294, current rewards: 167.14882, mean: 0.09775
[32m[0906 19-42-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03292, current rewards: 172.65318, mean: 0.09810
[32m[0906 19-42-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03292, current rewards: 178.15930, mean: 0.09843
[32m[0906 19-42-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03291, current rewards: 183.85058, mean: 0.09884
[32m[0906 19-42-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03291, current rewards: 189.34619, mean: 0.09913
[32m[0906 19-42-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03290, current rewards: 194.84543, mean: 0.09941
[32m[0906 19-42-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03289, current rewards: 200.34668, mean: 0.09967
[32m[0906 19-42-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03288, current rewards: 202.96321, mean: 0.09853
[32m[0906 19-42-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03292, current rewards: 208.54191, mean: 0.09884
[32m[0906 19-42-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03295, current rewards: 213.94657, mean: 0.09905
[32m[0906 19-42-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03303, current rewards: 217.36958, mean: 0.09836
[32m[0906 19-42-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03308, current rewards: 217.62550, mean: 0.09629
[32m[0906 19-42-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03309, current rewards: 223.03768, mean: 0.09655
[32m[0906 19-42-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03312, current rewards: 228.43666, mean: 0.09680
[32m[0906 19-42-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03314, current rewards: 233.84171, mean: 0.09703
[32m[0906 19-42-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03317, current rewards: 239.26349, mean: 0.09726
[32m[0906 19-42-53 @Agent.py:117][0m Average action selection time: 0.0332
[32m[0906 19-42-53 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-42-54 @MBExp.py:227][0m Rewards obtained: [235.93277511325], Lows: [16], Highs: [5], Total time: 9369.592479
[32m[0906 19-46-38 @MBExp.py:144][0m ####################################################################
[32m[0906 19-46-38 @MBExp.py:145][0m Starting training iteration 111.
[32m[0906 19-46-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03211, current rewards: -0.83613, mean: -0.08361
[32m[0906 19-46-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03333, current rewards: 4.79684, mean: 0.07995
[32m[0906 19-46-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03337, current rewards: 10.42239, mean: 0.09475
[32m[0906 19-46-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03344, current rewards: 16.03204, mean: 0.10020
[32m[0906 19-46-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03353, current rewards: 21.66412, mean: 0.10316
[32m[0906 19-46-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03353, current rewards: 27.31271, mean: 0.10505
[32m[0906 19-46-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03357, current rewards: 32.95318, mean: 0.10630
[32m[0906 19-46-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03360, current rewards: 34.73157, mean: 0.09648
[32m[0906 19-46-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03360, current rewards: 40.27415, mean: 0.09823
[32m[0906 19-46-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03358, current rewards: 45.81659, mean: 0.09960
[32m[0906 19-46-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03358, current rewards: 51.35861, mean: 0.10070
[32m[0906 19-46-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03358, current rewards: 56.90091, mean: 0.10161
[32m[0906 19-46-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03357, current rewards: 61.04051, mean: 0.10007
[32m[0906 19-47-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03356, current rewards: 66.55378, mean: 0.10084
[32m[0906 19-47-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03350, current rewards: 72.06632, mean: 0.10150
[32m[0906 19-47-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03343, current rewards: 77.57581, mean: 0.10207
[32m[0906 19-47-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03336, current rewards: 83.09323, mean: 0.10258
[32m[0906 19-47-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03331, current rewards: 88.60539, mean: 0.10303
[32m[0906 19-47-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03326, current rewards: 94.12228, mean: 0.10343
[32m[0906 19-47-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03322, current rewards: 99.63746, mean: 0.10379
[32m[0906 19-47-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03319, current rewards: 105.33606, mean: 0.10429
[32m[0906 19-47-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03317, current rewards: 110.85396, mean: 0.10458
[32m[0906 19-47-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03316, current rewards: 116.36936, mean: 0.10484
[32m[0906 19-47-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03312, current rewards: 121.87216, mean: 0.10506
[32m[0906 19-47-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03309, current rewards: 127.53785, mean: 0.10540
[32m[0906 19-47-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03307, current rewards: 133.20781, mean: 0.10572
[32m[0906 19-47-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03305, current rewards: 138.87773, mean: 0.10601
[32m[0906 19-47-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03303, current rewards: 144.54696, mean: 0.10628
[32m[0906 19-47-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03302, current rewards: 150.13218, mean: 0.10648
[32m[0906 19-47-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03301, current rewards: 155.79246, mean: 0.10671
[32m[0906 19-47-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03299, current rewards: 161.45214, mean: 0.10692
[32m[0906 19-47-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03297, current rewards: 167.11648, mean: 0.10713
[32m[0906 19-47-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03296, current rewards: 172.77345, mean: 0.10731
[32m[0906 19-47-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03295, current rewards: 178.43513, mean: 0.10749
[32m[0906 19-47-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03295, current rewards: 184.09409, mean: 0.10766
[32m[0906 19-47-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03293, current rewards: 189.74944, mean: 0.10781
[32m[0906 19-47-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03294, current rewards: 193.15091, mean: 0.10671
[32m[0906 19-47-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03292, current rewards: 198.66445, mean: 0.10681
[32m[0906 19-47-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03291, current rewards: 204.19954, mean: 0.10691
[32m[0906 19-47-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03291, current rewards: 209.73742, mean: 0.10701
[32m[0906 19-47-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03289, current rewards: 215.27392, mean: 0.10710
[32m[0906 19-47-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03288, current rewards: 220.81138, mean: 0.10719
[32m[0906 19-47-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03287, current rewards: 226.34547, mean: 0.10727
[32m[0906 19-47-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03287, current rewards: 231.87879, mean: 0.10735
[32m[0906 19-47-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03289, current rewards: 237.41351, mean: 0.10743
[32m[0906 19-47-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03290, current rewards: 243.12780, mean: 0.10758
[32m[0906 19-47-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03292, current rewards: 246.72327, mean: 0.10681
[32m[0906 19-47-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03293, current rewards: 252.25301, mean: 0.10689
[32m[0906 19-47-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03295, current rewards: 257.78564, mean: 0.10696
[32m[0906 19-48-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03296, current rewards: 263.31261, mean: 0.10704
[32m[0906 19-48-01 @Agent.py:117][0m Average action selection time: 0.0330
[32m[0906 19-48-01 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-48-01 @MBExp.py:227][0m Rewards obtained: [267.73714773649607], Lows: [4], Highs: [3], Total time: 9452.792629000001
[32m[0906 19-51-48 @MBExp.py:144][0m ####################################################################
[32m[0906 19-51-48 @MBExp.py:145][0m Starting training iteration 112.
[32m[0906 19-51-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03428, current rewards: -9.72819, mean: -0.97282
[32m[0906 19-51-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03357, current rewards: -8.11002, mean: -0.13517
[32m[0906 19-51-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03362, current rewards: -2.80645, mean: -0.02551
[32m[0906 19-51-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03357, current rewards: 2.59049, mean: 0.01619
[32m[0906 19-51-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03356, current rewards: 7.87980, mean: 0.03752
[32m[0906 19-51-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03357, current rewards: 13.17498, mean: 0.05067
[32m[0906 19-51-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03358, current rewards: 19.21190, mean: 0.06197
[32m[0906 19-52-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03361, current rewards: 24.93728, mean: 0.06927
[32m[0906 19-52-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03359, current rewards: 30.66356, mean: 0.07479
[32m[0906 19-52-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03359, current rewards: 36.38616, mean: 0.07910
[32m[0906 19-52-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03359, current rewards: 42.10484, mean: 0.08256
[32m[0906 19-52-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03360, current rewards: 47.73852, mean: 0.08525
[32m[0906 19-52-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03358, current rewards: 53.34853, mean: 0.08746
[32m[0906 19-52-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03356, current rewards: 56.04314, mean: 0.08491
[32m[0906 19-52-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03348, current rewards: 59.70724, mean: 0.08409
[32m[0906 19-52-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03342, current rewards: 65.35700, mean: 0.08600
[32m[0906 19-52-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03337, current rewards: 70.99558, mean: 0.08765
[32m[0906 19-52-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03329, current rewards: 76.64048, mean: 0.08912
[32m[0906 19-52-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03324, current rewards: 82.27536, mean: 0.09041
[32m[0906 19-52-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03322, current rewards: 87.91753, mean: 0.09158
[32m[0906 19-52-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03319, current rewards: 93.80716, mean: 0.09288
[32m[0906 19-52-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03315, current rewards: 99.43903, mean: 0.09381
[32m[0906 19-52-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03315, current rewards: 102.05297, mean: 0.09194
[32m[0906 19-52-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03310, current rewards: 107.62836, mean: 0.09278
[32m[0906 19-52-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03309, current rewards: 113.20257, mean: 0.09356
[32m[0906 19-52-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03307, current rewards: 118.77964, mean: 0.09427
[32m[0906 19-52-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03305, current rewards: 124.35600, mean: 0.09493
[32m[0906 19-52-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03304, current rewards: 129.93262, mean: 0.09554
[32m[0906 19-52-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03303, current rewards: 135.51347, mean: 0.09611
[32m[0906 19-52-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03301, current rewards: 140.85651, mean: 0.09648
[32m[0906 19-52-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03300, current rewards: 146.41311, mean: 0.09696
[32m[0906 19-52-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03298, current rewards: 151.96452, mean: 0.09741
[32m[0906 19-52-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03298, current rewards: 152.30745, mean: 0.09460
[32m[0906 19-52-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03296, current rewards: 157.66723, mean: 0.09498
[32m[0906 19-52-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03296, current rewards: 163.02626, mean: 0.09534
[32m[0906 19-52-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03296, current rewards: 168.38574, mean: 0.09567
[32m[0906 19-52-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03294, current rewards: 173.74899, mean: 0.09599
[32m[0906 19-52-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03293, current rewards: 179.41709, mean: 0.09646
[32m[0906 19-52-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03293, current rewards: 185.11962, mean: 0.09692
[32m[0906 19-52-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03292, current rewards: 190.81530, mean: 0.09735
[32m[0906 19-52-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03290, current rewards: 196.51414, mean: 0.09777
[32m[0906 19-52-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03289, current rewards: 202.21351, mean: 0.09816
[32m[0906 19-52-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03289, current rewards: 203.74163, mean: 0.09656
[32m[0906 19-53-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03288, current rewards: 209.35863, mean: 0.09693
[32m[0906 19-53-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03287, current rewards: 214.97576, mean: 0.09727
[32m[0906 19-53-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03286, current rewards: 220.59259, mean: 0.09761
[32m[0906 19-53-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03286, current rewards: 226.04091, mean: 0.09785
[32m[0906 19-53-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03285, current rewards: 231.68117, mean: 0.09817
[32m[0906 19-53-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03286, current rewards: 237.32323, mean: 0.09847
[32m[0906 19-53-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03285, current rewards: 242.96962, mean: 0.09877
[32m[0906 19-53-11 @Agent.py:117][0m Average action selection time: 0.0328
[32m[0906 19-53-11 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-53-11 @MBExp.py:227][0m Rewards obtained: [247.47691135274326], Lows: [12], Highs: [7], Total time: 9535.668463000002
[32m[0906 19-57-01 @MBExp.py:144][0m ####################################################################
[32m[0906 19-57-01 @MBExp.py:145][0m Starting training iteration 113.
[32m[0906 19-57-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03412, current rewards: -6.15055, mean: -0.61505
[32m[0906 19-57-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03369, current rewards: -0.39960, mean: -0.00666
[32m[0906 19-57-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03369, current rewards: 5.34369, mean: 0.04858
[32m[0906 19-57-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03359, current rewards: 11.08980, mean: 0.06931
[32m[0906 19-57-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03354, current rewards: 16.71604, mean: 0.07960
[32m[0906 19-57-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03351, current rewards: 22.45672, mean: 0.08637
[32m[0906 19-57-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03353, current rewards: 28.20404, mean: 0.09098
[32m[0906 19-57-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03352, current rewards: 33.95181, mean: 0.09431
[32m[0906 19-57-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03355, current rewards: 39.69936, mean: 0.09683
[32m[0906 19-57-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03353, current rewards: 45.44529, mean: 0.09879
[32m[0906 19-57-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03354, current rewards: 51.19216, mean: 0.10038
[32m[0906 19-57-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03354, current rewards: 56.93420, mean: 0.10167
[32m[0906 19-57-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03352, current rewards: 62.76145, mean: 0.10289
[32m[0906 19-57-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03342, current rewards: 68.52275, mean: 0.10382
[32m[0906 19-57-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03337, current rewards: 74.26303, mean: 0.10460
[32m[0906 19-57-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03334, current rewards: 77.77319, mean: 0.10233
[32m[0906 19-57-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03329, current rewards: 83.36402, mean: 0.10292
[32m[0906 19-57-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03323, current rewards: 88.96239, mean: 0.10344
[32m[0906 19-57-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03318, current rewards: 94.56050, mean: 0.10391
[32m[0906 19-57-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03316, current rewards: 100.15954, mean: 0.10433
[32m[0906 19-57-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03313, current rewards: 105.75731, mean: 0.10471
[32m[0906 19-57-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03310, current rewards: 111.55351, mean: 0.10524
[32m[0906 19-57-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03307, current rewards: 117.14123, mean: 0.10553
[32m[0906 19-57-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03304, current rewards: 122.74034, mean: 0.10581
[32m[0906 19-57-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03302, current rewards: 128.33606, mean: 0.10606
[32m[0906 19-57-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03299, current rewards: 133.94004, mean: 0.10630
[32m[0906 19-57-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03298, current rewards: 139.53711, mean: 0.10652
[32m[0906 19-57-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03296, current rewards: 140.20139, mean: 0.10309
[32m[0906 19-57-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03294, current rewards: 147.47560, mean: 0.10459
[32m[0906 19-57-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03293, current rewards: 154.74981, mean: 0.10599
[32m[0906 19-57-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03292, current rewards: 162.02403, mean: 0.10730
[32m[0906 19-57-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03291, current rewards: 169.29824, mean: 0.10852
[32m[0906 19-57-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03290, current rewards: 171.99052, mean: 0.10683
[32m[0906 19-57-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03289, current rewards: 121.99052, mean: 0.07349
[32m[0906 19-57-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03288, current rewards: 71.99052, mean: 0.04210
[32m[0906 19-57-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03287, current rewards: 21.99052, mean: 0.01249
[32m[0906 19-58-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03287, current rewards: -28.00948, mean: -0.01547
[32m[0906 19-58-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03285, current rewards: -78.00948, mean: -0.04194
[32m[0906 19-58-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03285, current rewards: -128.00948, mean: -0.06702
[32m[0906 19-58-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03285, current rewards: -178.00948, mean: -0.09082
[32m[0906 19-58-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03283, current rewards: -228.00948, mean: -0.11344
[32m[0906 19-58-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03282, current rewards: -278.00948, mean: -0.13496
[32m[0906 19-58-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03282, current rewards: -328.00948, mean: -0.15545
[32m[0906 19-58-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03281, current rewards: -378.00948, mean: -0.17500
[32m[0906 19-58-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03280, current rewards: -428.00948, mean: -0.19367
[32m[0906 19-58-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03279, current rewards: -478.00948, mean: -0.21151
[32m[0906 19-58-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03279, current rewards: -528.00948, mean: -0.22858
[32m[0906 19-58-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03279, current rewards: -578.00948, mean: -0.24492
[32m[0906 19-58-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03279, current rewards: -628.00948, mean: -0.26058
[32m[0906 19-58-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03278, current rewards: -678.00948, mean: -0.27561
[32m[0906 19-58-23 @Agent.py:117][0m Average action selection time: 0.0328
[32m[0906 19-58-23 @Agent.py:118][0m Rollout length: 2501
[32m[0906 19-58-23 @MBExp.py:227][0m Rewards obtained: [-718.009483632354], Lows: [7], Highs: [896], Total time: 9618.383445000001
[32m[0906 20-02-15 @MBExp.py:144][0m ####################################################################
[32m[0906 20-02-15 @MBExp.py:145][0m Starting training iteration 114.
[32m[0906 20-02-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03326, current rewards: -2.06598, mean: -0.20660
[32m[0906 20-02-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03354, current rewards: 3.50447, mean: 0.05841
[32m[0906 20-02-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03353, current rewards: 9.07172, mean: 0.08247
[32m[0906 20-02-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03346, current rewards: 14.53949, mean: 0.09087
[32m[0906 20-02-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03351, current rewards: 20.08140, mean: 0.09563
[32m[0906 20-02-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03353, current rewards: 25.62839, mean: 0.09857
[32m[0906 20-02-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03353, current rewards: 31.17107, mean: 0.10055
[32m[0906 20-02-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03356, current rewards: 36.72209, mean: 0.10201
[32m[0906 20-02-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03356, current rewards: 42.26275, mean: 0.10308
[32m[0906 20-02-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03356, current rewards: 47.80493, mean: 0.10392
[32m[0906 20-02-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03358, current rewards: 53.35325, mean: 0.10461
[32m[0906 20-02-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03359, current rewards: 58.92480, mean: 0.10522
[32m[0906 20-02-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03359, current rewards: 60.44351, mean: 0.09909
[32m[0906 20-02-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03345, current rewards: 65.97420, mean: 0.09996
[32m[0906 20-02-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03337, current rewards: 71.50460, mean: 0.10071
[32m[0906 20-02-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03332, current rewards: 77.03479, mean: 0.10136
[32m[0906 20-02-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03328, current rewards: 82.56819, mean: 0.10194
[32m[0906 20-02-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03324, current rewards: 88.09898, mean: 0.10244
[32m[0906 20-02-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03320, current rewards: 93.62748, mean: 0.10289
[32m[0906 20-02-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03318, current rewards: 99.16693, mean: 0.10330
[32m[0906 20-02-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03316, current rewards: 104.69403, mean: 0.10366
[32m[0906 20-02-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03312, current rewards: 110.22160, mean: 0.10398
[32m[0906 20-02-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03311, current rewards: 114.64504, mean: 0.10328
[32m[0906 20-02-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03308, current rewards: 120.18930, mean: 0.10361
[32m[0906 20-02-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03305, current rewards: 125.73927, mean: 0.10392
[32m[0906 20-02-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03303, current rewards: 131.28675, mean: 0.10420
[32m[0906 20-02-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03301, current rewards: 136.82948, mean: 0.10445
[32m[0906 20-03-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03299, current rewards: 142.34313, mean: 0.10466
[32m[0906 20-03-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03298, current rewards: 147.87249, mean: 0.10487
[32m[0906 20-03-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03297, current rewards: 147.99622, mean: 0.10137
[32m[0906 20-03-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03296, current rewards: 153.33718, mean: 0.10155
[32m[0906 20-03-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03295, current rewards: 158.67178, mean: 0.10171
[32m[0906 20-03-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03294, current rewards: 164.01679, mean: 0.10187
[32m[0906 20-03-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03293, current rewards: 169.36075, mean: 0.10202
[32m[0906 20-03-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03293, current rewards: 170.99769, mean: 0.10000
[32m[0906 20-03-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03292, current rewards: 176.62011, mean: 0.10035
[32m[0906 20-03-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03292, current rewards: 182.19532, mean: 0.10066
[32m[0906 20-03-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03291, current rewards: 187.77369, mean: 0.10095
[32m[0906 20-03-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03290, current rewards: 193.34958, mean: 0.10123
[32m[0906 20-03-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03290, current rewards: 198.92732, mean: 0.10149
[32m[0906 20-03-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03289, current rewards: 204.50468, mean: 0.10174
[32m[0906 20-03-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03287, current rewards: 206.79640, mean: 0.10039
[32m[0906 20-03-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03287, current rewards: 212.32224, mean: 0.10063
[32m[0906 20-03-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03286, current rewards: 217.89322, mean: 0.10088
[32m[0906 20-03-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03286, current rewards: 223.43592, mean: 0.10110
[32m[0906 20-03-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03285, current rewards: 228.97808, mean: 0.10132
[32m[0906 20-03-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03284, current rewards: 234.52177, mean: 0.10152
[32m[0906 20-03-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03285, current rewards: 240.06601, mean: 0.10172
[32m[0906 20-03-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03285, current rewards: 245.60485, mean: 0.10191
[32m[0906 20-03-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03284, current rewards: 251.14759, mean: 0.10209
[32m[0906 20-03-37 @Agent.py:117][0m Average action selection time: 0.0328
[32m[0906 20-03-37 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-03-38 @MBExp.py:227][0m Rewards obtained: [253.50071697462357], Lows: [8], Highs: [6], Total time: 9701.251806000002
[32m[0906 20-07-31 @MBExp.py:144][0m ####################################################################
[32m[0906 20-07-31 @MBExp.py:145][0m Starting training iteration 115.
[32m[0906 20-07-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03246, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-07-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03339, current rewards: -60.00000, mean: -1.00000
[32m[0906 20-07-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03355, current rewards: -110.00000, mean: -1.00000
[32m[0906 20-07-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03356, current rewards: -160.00000, mean: -1.00000
[32m[0906 20-07-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03351, current rewards: -207.88276, mean: -0.98992
[32m[0906 20-07-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03353, current rewards: -254.72879, mean: -0.97973
[32m[0906 20-07-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03354, current rewards: -304.72879, mean: -0.98300
[32m[0906 20-07-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03355, current rewards: -354.72879, mean: -0.98536
[32m[0906 20-07-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03354, current rewards: -404.72879, mean: -0.98714
[32m[0906 20-07-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03354, current rewards: -454.72879, mean: -0.98854
[32m[0906 20-07-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03353, current rewards: -504.72879, mean: -0.98966
[32m[0906 20-07-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03352, current rewards: -554.72879, mean: -0.99059
[32m[0906 20-07-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03346, current rewards: -604.72879, mean: -0.99136
[32m[0906 20-07-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03341, current rewards: -648.38678, mean: -0.98240
[32m[0906 20-07-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03337, current rewards: -694.15213, mean: -0.97768
[32m[0906 20-07-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03333, current rewards: -742.04623, mean: -0.97638
[32m[0906 20-07-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03328, current rewards: -788.88254, mean: -0.97393
[32m[0906 20-08-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03325, current rewards: -829.14284, mean: -0.96412
[32m[0906 20-08-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03323, current rewards: -873.83467, mean: -0.96026
[32m[0906 20-08-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03319, current rewards: -917.42883, mean: -0.95566
[32m[0906 20-08-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03316, current rewards: -962.11070, mean: -0.95258
[32m[0906 20-08-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03314, current rewards: -1007.70341, mean: -0.95066
[32m[0906 20-08-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03312, current rewards: -1063.08653, mean: -0.95774
[32m[0906 20-08-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03310, current rewards: -1108.45447, mean: -0.95556
[32m[0906 20-08-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03310, current rewards: -1156.35756, mean: -0.95567
[32m[0906 20-08-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03307, current rewards: -1199.76886, mean: -0.95220
[32m[0906 20-08-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03307, current rewards: -1254.26511, mean: -0.95745
[32m[0906 20-08-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03305, current rewards: -1311.80943, mean: -0.96457
[32m[0906 20-08-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03303, current rewards: -1359.60187, mean: -0.96426
[32m[0906 20-08-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03301, current rewards: -1354.25077, mean: -0.92757
[32m[0906 20-08-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03299, current rewards: -1348.87579, mean: -0.89330
[32m[0906 20-08-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03297, current rewards: -1343.52646, mean: -0.86123
[32m[0906 20-08-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03296, current rewards: -1338.14895, mean: -0.83115
[32m[0906 20-08-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03296, current rewards: -1335.00042, mean: -0.80422
[32m[0906 20-08-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03295, current rewards: -1385.00042, mean: -0.80994
[32m[0906 20-08-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03294, current rewards: -1435.00042, mean: -0.81534
[32m[0906 20-08-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03294, current rewards: -1452.72758, mean: -0.80261
[32m[0906 20-08-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03292, current rewards: -1447.14231, mean: -0.77803
[32m[0906 20-08-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03292, current rewards: -1441.55175, mean: -0.75474
[32m[0906 20-08-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03291, current rewards: -1435.96068, mean: -0.73263
[32m[0906 20-08-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03290, current rewards: -1430.37574, mean: -0.71163
[32m[0906 20-08-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03288, current rewards: -1424.78894, mean: -0.69165
[32m[0906 20-08-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03288, current rewards: -1419.19825, mean: -0.67261
[32m[0906 20-08-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03288, current rewards: -1454.45270, mean: -0.67336
[32m[0906 20-08-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03287, current rewards: -1514.34855, mean: -0.68523
[32m[0906 20-08-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03287, current rewards: -1564.67155, mean: -0.69233
[32m[0906 20-08-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03287, current rewards: -1626.44482, mean: -0.70409
[32m[0906 20-08-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03287, current rewards: -1702.15471, mean: -0.72125
[32m[0906 20-08-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03287, current rewards: -1719.37362, mean: -0.71343
[32m[0906 20-08-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03287, current rewards: -1712.72814, mean: -0.69623
[32m[0906 20-08-54 @Agent.py:117][0m Average action selection time: 0.0329
[32m[0906 20-08-54 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-08-54 @MBExp.py:227][0m Rewards obtained: [-1707.4317776995686], Lows: [153], Highs: [1496], Total time: 9784.163233000003
[32m[0906 20-12-49 @MBExp.py:144][0m ####################################################################
[32m[0906 20-12-49 @MBExp.py:145][0m Starting training iteration 116.
[32m[0906 20-12-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03244, current rewards: -2.21646, mean: -0.22165
[32m[0906 20-12-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03349, current rewards: 3.26105, mean: 0.05435
[32m[0906 20-12-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03346, current rewards: 8.78489, mean: 0.07986
[32m[0906 20-12-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03352, current rewards: 14.37573, mean: 0.08985
[32m[0906 20-12-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03350, current rewards: 19.96254, mean: 0.09506
[32m[0906 20-12-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03352, current rewards: 25.54981, mean: 0.09827
[32m[0906 20-12-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03351, current rewards: 31.13673, mean: 0.10044
[32m[0906 20-13-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03351, current rewards: 36.72557, mean: 0.10202
[32m[0906 20-13-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03349, current rewards: 42.31273, mean: 0.10320
[32m[0906 20-13-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03351, current rewards: 47.90379, mean: 0.10414
[32m[0906 20-13-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03351, current rewards: 53.49378, mean: 0.10489
[32m[0906 20-13-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03344, current rewards: 47.58476, mean: 0.08497
[32m[0906 20-13-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03337, current rewards: 52.21290, mean: 0.08559
[32m[0906 20-13-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03328, current rewards: 56.83966, mean: 0.08612
[32m[0906 20-13-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03324, current rewards: 61.47134, mean: 0.08658
[32m[0906 20-13-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03318, current rewards: 66.10092, mean: 0.08697
[32m[0906 20-13-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03314, current rewards: 66.79553, mean: 0.08246
[32m[0906 20-13-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03312, current rewards: 72.59891, mean: 0.08442
[32m[0906 20-13-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03308, current rewards: 78.43340, mean: 0.08619
[32m[0906 20-13-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03307, current rewards: 84.35723, mean: 0.08787
[32m[0906 20-13-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03304, current rewards: 90.27784, mean: 0.08938
[32m[0906 20-13-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03302, current rewards: 96.19693, mean: 0.09075
[32m[0906 20-13-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03301, current rewards: 102.11894, mean: 0.09200
[32m[0906 20-13-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03299, current rewards: 108.04577, mean: 0.09314
[32m[0906 20-13-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03300, current rewards: 107.19791, mean: 0.08859
[32m[0906 20-13-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03297, current rewards: 112.66002, mean: 0.08941
[32m[0906 20-13-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03296, current rewards: 118.22854, mean: 0.09025
[32m[0906 20-13-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03295, current rewards: 123.71949, mean: 0.09097
[32m[0906 20-13-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03294, current rewards: 129.20812, mean: 0.09164
[32m[0906 20-13-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03294, current rewards: 134.70233, mean: 0.09226
[32m[0906 20-13-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03292, current rewards: 140.19386, mean: 0.09284
[32m[0906 20-13-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03291, current rewards: 145.68437, mean: 0.09339
[32m[0906 20-13-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03290, current rewards: 151.17142, mean: 0.09390
[32m[0906 20-13-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03290, current rewards: 156.65865, mean: 0.09437
[32m[0906 20-13-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03289, current rewards: 162.21282, mean: 0.09486
[32m[0906 20-13-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03288, current rewards: 167.71756, mean: 0.09529
[32m[0906 20-13-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03288, current rewards: 173.21793, mean: 0.09570
[32m[0906 20-13-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03288, current rewards: 178.71476, mean: 0.09608
[32m[0906 20-13-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03287, current rewards: 184.21580, mean: 0.09645
[32m[0906 20-13-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03286, current rewards: 189.71635, mean: 0.09679
[32m[0906 20-13-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03285, current rewards: 195.16345, mean: 0.09710
[32m[0906 20-13-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03285, current rewards: 200.56982, mean: 0.09736
[32m[0906 20-13-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03285, current rewards: 205.97625, mean: 0.09762
[32m[0906 20-14-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03284, current rewards: 211.38662, mean: 0.09786
[32m[0906 20-14-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03283, current rewards: 216.79650, mean: 0.09810
[32m[0906 20-14-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03282, current rewards: 222.20188, mean: 0.09832
[32m[0906 20-14-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03282, current rewards: 227.61024, mean: 0.09853
[32m[0906 20-14-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03282, current rewards: 233.01396, mean: 0.09873
[32m[0906 20-14-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03282, current rewards: 238.42231, mean: 0.09893
[32m[0906 20-14-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03281, current rewards: 243.83007, mean: 0.09912
[32m[0906 20-14-11 @Agent.py:117][0m Average action selection time: 0.0328
[32m[0906 20-14-11 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-14-11 @MBExp.py:227][0m Rewards obtained: [248.18777346536623], Lows: [8], Highs: [7], Total time: 9866.948564000002
[32m[0906 20-18-08 @MBExp.py:144][0m ####################################################################
[32m[0906 20-18-08 @MBExp.py:145][0m Starting training iteration 117.
[32m[0906 20-18-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03322, current rewards: -10.80602, mean: -1.08060
[32m[0906 20-18-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03392, current rewards: -18.27089, mean: -0.30451
[32m[0906 20-18-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03379, current rewards: -12.71887, mean: -0.11563
[32m[0906 20-18-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03376, current rewards: -7.16860, mean: -0.04480
[32m[0906 20-18-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03369, current rewards: -1.61932, mean: -0.00771
[32m[0906 20-18-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03364, current rewards: 3.93268, mean: 0.01513
[32m[0906 20-18-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03365, current rewards: 9.77009, mean: 0.03152
[32m[0906 20-18-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03362, current rewards: -83.74572, mean: -0.23263
[32m[0906 20-18-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03362, current rewards: -183.74572, mean: -0.44816
[32m[0906 20-18-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03361, current rewards: -283.74572, mean: -0.61684
[32m[0906 20-18-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03355, current rewards: -383.74572, mean: -0.75244
[32m[0906 20-18-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03355, current rewards: -483.74572, mean: -0.86383
[32m[0906 20-18-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03347, current rewards: -583.74572, mean: -0.95696
[32m[0906 20-18-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03341, current rewards: -683.74572, mean: -1.03598
[32m[0906 20-18-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03334, current rewards: -783.74572, mean: -1.10387
[32m[0906 20-18-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03326, current rewards: -883.74572, mean: -1.16282
[32m[0906 20-18-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03322, current rewards: -926.33146, mean: -1.14362
[32m[0906 20-18-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03318, current rewards: -920.63404, mean: -1.07050
[32m[0906 20-18-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03313, current rewards: -915.07931, mean: -1.00558
[32m[0906 20-18-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03309, current rewards: -909.52442, mean: -0.94742
[32m[0906 20-18-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03307, current rewards: -913.96830, mean: -0.90492
[32m[0906 20-18-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03305, current rewards: -905.17964, mean: -0.85394
[32m[0906 20-18-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03304, current rewards: -896.39097, mean: -0.80756
[32m[0906 20-18-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03302, current rewards: -887.60231, mean: -0.76517
[32m[0906 20-18-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03300, current rewards: -878.81365, mean: -0.72629
[32m[0906 20-18-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03299, current rewards: -881.64609, mean: -0.69972
[32m[0906 20-18-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03298, current rewards: -931.64609, mean: -0.71118
[32m[0906 20-18-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03298, current rewards: -981.64609, mean: -0.72180
[32m[0906 20-18-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03297, current rewards: -1031.64609, mean: -0.73166
[32m[0906 20-18-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03296, current rewards: -1081.64609, mean: -0.74085
[32m[0906 20-18-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03295, current rewards: -1131.64609, mean: -0.74943
[32m[0906 20-19-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03294, current rewards: -1181.64609, mean: -0.75747
[32m[0906 20-19-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03293, current rewards: -1231.64609, mean: -0.76500
[32m[0906 20-19-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03292, current rewards: -1281.64609, mean: -0.77208
[32m[0906 20-19-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03291, current rewards: -1331.64609, mean: -0.77874
[32m[0906 20-19-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03291, current rewards: -1381.64609, mean: -0.78503
[32m[0906 20-19-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03290, current rewards: -1431.64609, mean: -0.79096
[32m[0906 20-19-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03289, current rewards: -1481.64609, mean: -0.79658
[32m[0906 20-19-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03288, current rewards: -1531.64609, mean: -0.80191
[32m[0906 20-19-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03286, current rewards: -1581.64609, mean: -0.80696
[32m[0906 20-19-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03286, current rewards: -1631.64609, mean: -0.81176
[32m[0906 20-19-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03284, current rewards: -1681.64609, mean: -0.81633
[32m[0906 20-19-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03284, current rewards: -1731.64609, mean: -0.82069
[32m[0906 20-19-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03283, current rewards: -1781.64609, mean: -0.82484
[32m[0906 20-19-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03282, current rewards: -1831.64609, mean: -0.82880
[32m[0906 20-19-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03281, current rewards: -1881.64609, mean: -0.83259
[32m[0906 20-19-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03281, current rewards: -1931.64609, mean: -0.83621
[32m[0906 20-19-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03281, current rewards: -1981.64609, mean: -0.83968
[32m[0906 20-19-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03280, current rewards: -2031.64609, mean: -0.84301
[32m[0906 20-19-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03280, current rewards: -2081.64609, mean: -0.84620
[32m[0906 20-19-31 @Agent.py:117][0m Average action selection time: 0.0328
[32m[0906 20-19-31 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-19-31 @MBExp.py:227][0m Rewards obtained: [-2121.6460885100073], Lows: [488], Highs: [1251], Total time: 9949.689275000002
[32m[0906 20-23-30 @MBExp.py:144][0m ####################################################################
[32m[0906 20-23-30 @MBExp.py:145][0m Starting training iteration 118.
[32m[0906 20-23-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03430, current rewards: -0.93016, mean: -0.09302
[32m[0906 20-23-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03373, current rewards: 4.69769, mean: 0.07829
[32m[0906 20-23-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03352, current rewards: 10.32134, mean: 0.09383
[32m[0906 20-23-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03353, current rewards: 15.94468, mean: 0.09965
[32m[0906 20-23-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03355, current rewards: 21.57097, mean: 0.10272
[32m[0906 20-23-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03354, current rewards: 27.19847, mean: 0.10461
[32m[0906 20-23-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03351, current rewards: 32.82346, mean: 0.10588
[32m[0906 20-23-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03349, current rewards: 38.44895, mean: 0.10680
[32m[0906 20-23-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03348, current rewards: 44.10816, mean: 0.10758
[32m[0906 20-23-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03342, current rewards: 49.80678, mean: 0.10828
[32m[0906 20-23-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03342, current rewards: 55.46045, mean: 0.10875
[32m[0906 20-23-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03346, current rewards: 58.83269, mean: 0.10506
[32m[0906 20-23-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03339, current rewards: 64.43696, mean: 0.10563
[32m[0906 20-23-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03332, current rewards: 70.04330, mean: 0.10613
[32m[0906 20-23-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03325, current rewards: 75.64932, mean: 0.10655
[32m[0906 20-23-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03320, current rewards: 81.25098, mean: 0.10691
[32m[0906 20-23-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03315, current rewards: 86.85976, mean: 0.10723
[32m[0906 20-23-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03312, current rewards: 92.56559, mean: 0.10763
[32m[0906 20-24-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03311, current rewards: 92.80268, mean: 0.10198
[32m[0906 20-24-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03307, current rewards: 98.52716, mean: 0.10263
[32m[0906 20-24-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03306, current rewards: 104.25920, mean: 0.10323
[32m[0906 20-24-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03304, current rewards: 109.99486, mean: 0.10377
[32m[0906 20-24-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03303, current rewards: 115.72339, mean: 0.10426
[32m[0906 20-24-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03302, current rewards: 117.34997, mean: 0.10116
[32m[0906 20-24-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03299, current rewards: 123.11465, mean: 0.10175
[32m[0906 20-24-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03296, current rewards: 128.64024, mean: 0.10210
[32m[0906 20-24-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03294, current rewards: 134.35479, mean: 0.10256
[32m[0906 20-24-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03292, current rewards: 140.06623, mean: 0.10299
[32m[0906 20-24-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03291, current rewards: 145.78190, mean: 0.10339
[32m[0906 20-24-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03290, current rewards: 151.49872, mean: 0.10377
[32m[0906 20-24-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03288, current rewards: 157.21058, mean: 0.10411
[32m[0906 20-24-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03289, current rewards: 162.92233, mean: 0.10444
[32m[0906 20-24-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03288, current rewards: 168.63847, mean: 0.10474
[32m[0906 20-24-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03287, current rewards: 174.45586, mean: 0.10509
[32m[0906 20-24-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03285, current rewards: 180.26730, mean: 0.10542
[32m[0906 20-24-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03285, current rewards: 186.00883, mean: 0.10569
[32m[0906 20-24-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03284, current rewards: 191.75124, mean: 0.10594
[32m[0906 20-24-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03284, current rewards: 197.49742, mean: 0.10618
[32m[0906 20-24-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03292, current rewards: 195.91497, mean: 0.10257
[32m[0906 20-24-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03297, current rewards: 201.59618, mean: 0.10286
[32m[0906 20-24-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03305, current rewards: 207.27615, mean: 0.10312
[32m[0906 20-24-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03309, current rewards: 212.96772, mean: 0.10338
[32m[0906 20-24-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03316, current rewards: 218.62306, mean: 0.10361
[32m[0906 20-24-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03325, current rewards: 205.82638, mean: 0.09529
[32m[0906 20-24-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03343, current rewards: 173.07711, mean: 0.07832
[32m[0906 20-24-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03359, current rewards: 132.61945, mean: 0.05868
[32m[0906 20-24-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03375, current rewards: 101.25787, mean: 0.04383
[32m[0906 20-24-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03388, current rewards: 60.65275, mean: 0.02570
[32m[0906 20-24-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03403, current rewards: 32.76294, mean: 0.01359
[32m[0906 20-24-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03414, current rewards: -3.60779, mean: -0.00147
[32m[0906 20-24-56 @Agent.py:117][0m Average action selection time: 0.0342
[32m[0906 20-24-56 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-24-56 @MBExp.py:227][0m Rewards obtained: [-0.8952863785657461], Lows: [113], Highs: [41], Total time: 10035.868329000003
[32m[0906 20-28-58 @MBExp.py:144][0m ####################################################################
[32m[0906 20-28-58 @MBExp.py:145][0m Starting training iteration 119.
[32m[0906 20-28-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03227, current rewards: -5.32337, mean: -0.53234
[32m[0906 20-29-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03332, current rewards: 0.42421, mean: 0.00707
[32m[0906 20-29-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03349, current rewards: 6.07492, mean: 0.05523
[32m[0906 20-29-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03349, current rewards: 11.73141, mean: 0.07332
[32m[0906 20-29-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03346, current rewards: 17.38833, mean: 0.08280
[32m[0906 20-29-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03347, current rewards: 23.03680, mean: 0.08860
[32m[0906 20-29-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03345, current rewards: 28.68939, mean: 0.09255
[32m[0906 20-29-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03341, current rewards: 34.34366, mean: 0.09540
[32m[0906 20-29-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03341, current rewards: 40.10586, mean: 0.09782
[32m[0906 20-29-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03340, current rewards: 45.69400, mean: 0.09933
[32m[0906 20-29-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03326, current rewards: 51.28650, mean: 0.10056
[32m[0906 20-29-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03320, current rewards: 51.62011, mean: 0.09218
[32m[0906 20-29-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03311, current rewards: 58.89433, mean: 0.09655
[32m[0906 20-29-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03308, current rewards: 66.16854, mean: 0.10026
[32m[0906 20-29-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03303, current rewards: 73.44275, mean: 0.10344
[32m[0906 20-29-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03301, current rewards: 80.71697, mean: 0.10621
[32m[0906 20-29-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03299, current rewards: 87.99118, mean: 0.10863
[32m[0906 20-29-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03296, current rewards: 95.26539, mean: 0.11077
[32m[0906 20-29-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03294, current rewards: 102.53961, mean: 0.11268
[32m[0906 20-29-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03293, current rewards: 82.32220, mean: 0.08575
[32m[0906 20-29-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03292, current rewards: 32.32220, mean: 0.03200
[32m[0906 20-29-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03291, current rewards: -17.67780, mean: -0.01668
[32m[0906 20-29-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03287, current rewards: -67.67780, mean: -0.06097
[32m[0906 20-29-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03286, current rewards: -117.67780, mean: -0.10145
[32m[0906 20-29-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03285, current rewards: -160.34171, mean: -0.13251
[32m[0906 20-29-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03284, current rewards: -157.94103, mean: -0.12535
[32m[0906 20-29-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03283, current rewards: -166.02049, mean: -0.12673
[32m[0906 20-29-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03283, current rewards: -216.02049, mean: -0.15884
[32m[0906 20-29-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03283, current rewards: -266.02049, mean: -0.18867
[32m[0906 20-29-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03281, current rewards: -296.05426, mean: -0.20278
[32m[0906 20-29-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03281, current rewards: -290.62007, mean: -0.19246
[32m[0906 20-29-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03280, current rewards: -285.12405, mean: -0.18277
[32m[0906 20-29-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03280, current rewards: -279.67324, mean: -0.17371
[32m[0906 20-29-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03279, current rewards: -274.24303, mean: -0.16521
[32m[0906 20-29-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03277, current rewards: -268.72875, mean: -0.15715
[32m[0906 20-29-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03278, current rewards: -263.21431, mean: -0.14955
[32m[0906 20-29-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03276, current rewards: -257.69733, mean: -0.14237
[32m[0906 20-29-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03276, current rewards: -252.17980, mean: -0.13558
[32m[0906 20-30-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03275, current rewards: -246.66477, mean: -0.12914
[32m[0906 20-30-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03274, current rewards: -241.15566, mean: -0.12304
[32m[0906 20-30-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03274, current rewards: -235.63829, mean: -0.11723
[32m[0906 20-30-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03273, current rewards: -232.27754, mean: -0.11276
[32m[0906 20-30-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03274, current rewards: -226.61597, mean: -0.10740
[32m[0906 20-30-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03273, current rewards: -220.95579, mean: -0.10229
[32m[0906 20-30-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03273, current rewards: -215.29249, mean: -0.09742
[32m[0906 20-30-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03273, current rewards: -209.63197, mean: -0.09276
[32m[0906 20-30-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03272, current rewards: -203.97017, mean: -0.08830
[32m[0906 20-30-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03272, current rewards: -198.30816, mean: -0.08403
[32m[0906 20-30-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03271, current rewards: -192.64824, mean: -0.07994
[32m[0906 20-30-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03271, current rewards: -189.00469, mean: -0.07683
[32m[0906 20-30-20 @Agent.py:117][0m Average action selection time: 0.0327
[32m[0906 20-30-20 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-30-20 @MBExp.py:227][0m Rewards obtained: [-184.52275993338893], Lows: [7], Highs: [411], Total time: 10118.409256000003
[32m[0906 20-34-23 @MBExp.py:144][0m ####################################################################
[32m[0906 20-34-23 @MBExp.py:145][0m Starting training iteration 120.
[32m[0906 20-34-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.03255, current rewards: -11.33607, mean: -1.13361
[32m[0906 20-34-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.03339, current rewards: -5.79427, mean: -0.09657
[32m[0906 20-34-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.03352, current rewards: -0.28370, mean: -0.00258
[32m[0906 20-34-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.03347, current rewards: 5.23027, mean: 0.03269
[32m[0906 20-34-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.03349, current rewards: 10.73609, mean: 0.05112
[32m[0906 20-34-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.03350, current rewards: 16.24113, mean: 0.06247
[32m[0906 20-34-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.03349, current rewards: 21.75563, mean: 0.07018
[32m[0906 20-34-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.03347, current rewards: 25.45405, mean: 0.07071
[32m[0906 20-34-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.03346, current rewards: 30.97951, mean: 0.07556
[32m[0906 20-34-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.03332, current rewards: 36.50755, mean: 0.07936
[32m[0906 20-34-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.03326, current rewards: 42.03670, mean: 0.08242
[32m[0906 20-34-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.03318, current rewards: 47.56227, mean: 0.08493
[32m[0906 20-34-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.03312, current rewards: 53.08435, mean: 0.08702
[32m[0906 20-34-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.03307, current rewards: 58.61005, mean: 0.08880
[32m[0906 20-34-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.03303, current rewards: 64.13600, mean: 0.09033
[32m[0906 20-34-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.03301, current rewards: 69.58258, mean: 0.09156
[32m[0906 20-34-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.03299, current rewards: 75.08640, mean: 0.09270
[32m[0906 20-34-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.03296, current rewards: 80.59692, mean: 0.09372
[32m[0906 20-34-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.03294, current rewards: 86.11113, mean: 0.09463
[32m[0906 20-34-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.03292, current rewards: 91.61932, mean: 0.09544
[32m[0906 20-34-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.03291, current rewards: 95.12697, mean: 0.09419
[32m[0906 20-34-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.03288, current rewards: 100.65933, mean: 0.09496
[32m[0906 20-35-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.03287, current rewards: 106.19061, mean: 0.09567
[32m[0906 20-35-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.03287, current rewards: 111.74432, mean: 0.09633
[32m[0906 20-35-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.03286, current rewards: 117.42653, mean: 0.09705
[32m[0906 20-35-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.03286, current rewards: 122.97244, mean: 0.09760
[32m[0906 20-35-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.03285, current rewards: 128.51951, mean: 0.09811
[32m[0906 20-35-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.03283, current rewards: 134.06854, mean: 0.09858
[32m[0906 20-35-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.03282, current rewards: 139.60954, mean: 0.09901
[32m[0906 20-35-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.03281, current rewards: 145.15336, mean: 0.09942
[32m[0906 20-35-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.03281, current rewards: 150.70066, mean: 0.09980
[32m[0906 20-35-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.03281, current rewards: 154.13686, mean: 0.09881
[32m[0906 20-35-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.03280, current rewards: 155.97325, mean: 0.09688
[32m[0906 20-35-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.03280, current rewards: 161.59493, mean: 0.09735
[32m[0906 20-35-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.03279, current rewards: 167.21626, mean: 0.09779
[32m[0906 20-35-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.03279, current rewards: 172.83639, mean: 0.09820
[32m[0906 20-35-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.03277, current rewards: 178.45744, mean: 0.09860
[32m[0906 20-35-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.03277, current rewards: 184.07819, mean: 0.09897
[32m[0906 20-35-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.03276, current rewards: 189.69918, mean: 0.09932
[32m[0906 20-35-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.03274, current rewards: 195.32118, mean: 0.09965
[32m[0906 20-35-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.03274, current rewards: 200.80854, mean: 0.09990
[32m[0906 20-35-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.03273, current rewards: 206.38791, mean: 0.10019
[32m[0906 20-35-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.03273, current rewards: 210.78163, mean: 0.09990
[32m[0906 20-35-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.03273, current rewards: 216.32773, mean: 0.10015
[32m[0906 20-35-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.03273, current rewards: 221.87534, mean: 0.10040
[32m[0906 20-35-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.03273, current rewards: 227.42739, mean: 0.10063
[32m[0906 20-35-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.03273, current rewards: 232.97471, mean: 0.10085
[32m[0906 20-35-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.03272, current rewards: 231.16250, mean: 0.09795
[32m[0906 20-35-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.03272, current rewards: 236.71199, mean: 0.09822
[32m[0906 20-35-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.03272, current rewards: 242.28974, mean: 0.09849
[32m[0906 20-35-46 @Agent.py:117][0m Average action selection time: 0.0327
[32m[0906 20-35-46 @Agent.py:118][0m Rollout length: 2501
[32m[0906 20-35-46 @MBExp.py:227][0m Rewards obtained: [246.75053804985177], Lows: [13], Highs: [4], Total time: 10200.967995000003
