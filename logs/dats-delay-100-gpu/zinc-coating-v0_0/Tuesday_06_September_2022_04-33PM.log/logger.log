[32m[0906 16-33-17 @logger.py:99][0m Log file set to /home/rweinreich/dev/own/final/algos/dats/logs/dats-delay-100/zinc-coating-v0_0/Tuesday_06_September_2022_04-33PM.log
[32m[0906 16-33-17 @MBExp.py:88][0m Starting the experiments
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00001, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00001, current rewards: -60.00000, mean: -1.00000
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00001, current rewards: -107.51517, mean: -0.97741
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00001, current rewards: -156.87674, mean: -0.98048
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00001, current rewards: -215.15234, mean: -1.02453
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00001, current rewards: -261.36482, mean: -1.00525
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00001, current rewards: -310.08031, mean: -1.00026
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00001, current rewards: -370.78066, mean: -1.02995
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00001, current rewards: -421.39689, mean: -1.02780
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00001, current rewards: -466.31114, mean: -1.01372
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00001, current rewards: -523.16910, mean: -1.02582
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00001, current rewards: -577.68351, mean: -1.03158
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00001, current rewards: -630.32556, mean: -1.03332
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00001, current rewards: -681.61781, mean: -1.03275
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00001, current rewards: -737.06631, mean: -1.03812
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00001, current rewards: -794.92108, mean: -1.04595
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00001, current rewards: -851.82446, mean: -1.05164
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00001, current rewards: -902.47082, mean: -1.04938
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00001, current rewards: -955.74873, mean: -1.05027
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00001, current rewards: -1024.16750, mean: -1.06684
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00001, current rewards: -1081.74764, mean: -1.07104
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00001, current rewards: -1140.58096, mean: -1.07602
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00001, current rewards: -1203.43265, mean: -1.08417
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00001, current rewards: -1269.22321, mean: -1.09416
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00001, current rewards: -1336.31332, mean: -1.10439
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00001, current rewards: -1399.75254, mean: -1.11091
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00001, current rewards: -1464.79329, mean: -1.11816
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00001, current rewards: -1533.35010, mean: -1.12746
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00001, current rewards: -1598.31958, mean: -1.13356
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00001, current rewards: -1666.01687, mean: -1.14111
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00001, current rewards: -1723.00357, mean: -1.14106
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00001, current rewards: -1777.64921, mean: -1.13952
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00001, current rewards: -1837.58730, mean: -1.14136
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00001, current rewards: -1884.48339, mean: -1.13523
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00001, current rewards: -1936.31178, mean: -1.13235
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00001, current rewards: -1987.35537, mean: -1.12918
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00001, current rewards: -2042.55429, mean: -1.12848
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00001, current rewards: -2092.74819, mean: -1.12513
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00001, current rewards: -2142.02108, mean: -1.12148
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00001, current rewards: -2215.18318, mean: -1.13020
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00001, current rewards: -2293.65734, mean: -1.14112
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00001, current rewards: -2379.76448, mean: -1.15523
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00001, current rewards: -2446.14804, mean: -1.15931
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00001, current rewards: -2507.34535, mean: -1.16081
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00001, current rewards: -2575.19083, mean: -1.16524
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00001, current rewards: -2630.32137, mean: -1.16386
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00001, current rewards: -2701.50416, mean: -1.16948
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00001, current rewards: -2761.87036, mean: -1.17028
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00001, current rewards: -2845.04430, mean: -1.18052
[32m[0906 16-33-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00001, current rewards: -2912.13523, mean: -1.18379
[32m[0906 16-33-17 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 16-33-17 @Agent.py:118][0m Rollout length: 2600
[32m[0906 16-33-18 @MBExp.py:144][0m ####################################################################
[32m[0906 16-33-18 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 16-33-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49016, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-33-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.44645, current rewards: -60.00000, mean: -1.00000
[32m[0906 16-33-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37787, current rewards: -100.20654, mean: -0.91097
[32m[0906 16-34-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35314, current rewards: -130.86310, mean: -0.81789
[32m[0906 16-34-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34024, current rewards: -180.86310, mean: -0.86125
[32m[0906 16-34-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.33178, current rewards: -230.86310, mean: -0.88793
[32m[0906 16-34-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32558, current rewards: -280.86310, mean: -0.90601
[32m[0906 16-35-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32142, current rewards: -330.86310, mean: -0.91906
[32m[0906 16-35-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31787, current rewards: -380.86310, mean: -0.92893
[32m[0906 16-35-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31514, current rewards: -430.86310, mean: -0.93666
[32m[0906 16-35-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31289, current rewards: -480.86310, mean: -0.94287
[32m[0906 16-36-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31127, current rewards: -530.86310, mean: -0.94797
[32m[0906 16-36-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31035, current rewards: -539.20423, mean: -0.88394
[32m[0906 16-36-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30905, current rewards: -531.34469, mean: -0.80507
[32m[0906 16-36-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30815, current rewards: -523.48515, mean: -0.73730
[32m[0906 16-37-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30728, current rewards: -515.62562, mean: -0.67845
[32m[0906 16-37-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30667, current rewards: -507.76608, mean: -0.62687
[32m[0906 16-37-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30624, current rewards: -523.68291, mean: -0.60893
[32m[0906 16-37-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30613, current rewards: -573.68291, mean: -0.63042
[32m[0906 16-38-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30591, current rewards: -623.68291, mean: -0.64967
[32m[0906 16-38-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30576, current rewards: -673.68291, mean: -0.66701
[32m[0906 16-38-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30521, current rewards: -723.68291, mean: -0.68272
[32m[0906 16-38-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30475, current rewards: -773.68291, mean: -0.69701
[32m[0906 16-39-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30430, current rewards: -823.68291, mean: -0.71007
[32m[0906 16-39-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30386, current rewards: -873.68291, mean: -0.72205
[32m[0906 16-39-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30344, current rewards: -923.68291, mean: -0.73308
[32m[0906 16-39-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30306, current rewards: -973.68291, mean: -0.74327
[32m[0906 16-40-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30270, current rewards: -1023.68291, mean: -0.75271
[32m[0906 16-40-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30237, current rewards: -1073.68291, mean: -0.76148
[32m[0906 16-40-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30207, current rewards: -1123.68291, mean: -0.76965
[32m[0906 16-40-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30179, current rewards: -1173.68291, mean: -0.77727
[32m[0906 16-41-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30154, current rewards: -1223.68291, mean: -0.78441
[32m[0906 16-41-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30130, current rewards: -1273.68291, mean: -0.79111
[32m[0906 16-41-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30107, current rewards: -1323.68291, mean: -0.79740
[32m[0906 16-41-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30086, current rewards: -1373.68291, mean: -0.80332
[32m[0906 16-42-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30068, current rewards: -1423.68291, mean: -0.80891
[32m[0906 16-42-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30050, current rewards: -1473.68291, mean: -0.81419
[32m[0906 16-42-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30033, current rewards: -1523.68291, mean: -0.81918
[32m[0906 16-42-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30017, current rewards: -1573.68291, mean: -0.82392
[32m[0906 16-43-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30002, current rewards: -1623.68291, mean: -0.82841
[32m[0906 16-43-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29987, current rewards: -1673.68291, mean: -0.83268
[32m[0906 16-43-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29973, current rewards: -1723.68291, mean: -0.83674
[32m[0906 16-43-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29961, current rewards: -1773.68291, mean: -0.84061
[32m[0906 16-44-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29958, current rewards: -1823.68291, mean: -0.84430
[32m[0906 16-44-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29947, current rewards: -1873.68291, mean: -0.84782
[32m[0906 16-44-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29900, current rewards: -1923.68291, mean: -0.85119
[32m[0906 16-44-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29855, current rewards: -1973.68291, mean: -0.85441
[32m[0906 16-45-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29812, current rewards: -2023.68291, mean: -0.85749
[32m[0906 16-45-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29771, current rewards: -2073.68291, mean: -0.86045
[32m[0906 16-45-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29731, current rewards: -2123.68291, mean: -0.86329
[32m[0906 16-45-41 @Agent.py:117][0m Average action selection time: 0.2970
[32m[0906 16-45-41 @Agent.py:118][0m Rollout length: 2600
[32m[0906 16-45-41 @MBExp.py:227][0m Rewards obtained: [-2163.6829075676446], Lows: [0], Highs: [2206], Total time: 742.849768
[32m[0906 16-45-42 @MBExp.py:144][0m ####################################################################
[32m[0906 16-45-42 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 16-45-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.27713, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-45-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.27790, current rewards: -60.00000, mean: -1.00000
[32m[0906 16-46-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.27827, current rewards: -120.00000, mean: -1.09091
[32m[0906 16-46-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.27824, current rewards: -220.00000, mean: -1.37500
[32m[0906 16-46-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.27822, current rewards: -320.00000, mean: -1.52381
[32m[0906 16-46-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.27822, current rewards: -420.00000, mean: -1.61538
[32m[0906 16-47-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.27825, current rewards: -520.00000, mean: -1.67742
[32m[0906 16-47-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.27825, current rewards: -620.00000, mean: -1.72222
[32m[0906 16-47-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.27829, current rewards: -720.00000, mean: -1.75610
[32m[0906 16-47-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.27831, current rewards: -820.00000, mean: -1.78261
[32m[0906 16-48-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.27834, current rewards: -920.00000, mean: -1.80392
[32m[0906 16-48-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.27834, current rewards: -1020.00000, mean: -1.82143
[32m[0906 16-48-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.27836, current rewards: -1120.00000, mean: -1.83607
[32m[0906 16-48-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.27835, current rewards: -1220.00000, mean: -1.84848
[32m[0906 16-49-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.27837, current rewards: -1320.00000, mean: -1.85915
[32m[0906 16-49-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.27837, current rewards: -1420.00000, mean: -1.86842
[32m[0906 16-49-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.27835, current rewards: -1520.00000, mean: -1.87654
[32m[0906 16-49-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.27834, current rewards: -1620.00000, mean: -1.88372
[32m[0906 16-49-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.27835, current rewards: -1720.00000, mean: -1.89011
[32m[0906 16-50-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.27835, current rewards: -1820.00000, mean: -1.89583
[32m[0906 16-50-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.27835, current rewards: -1920.00000, mean: -1.90099
[32m[0906 16-50-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.27835, current rewards: -2020.00000, mean: -1.90566
[32m[0906 16-50-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.27834, current rewards: -2120.00000, mean: -1.90991
[32m[0906 16-51-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.27835, current rewards: -2220.00000, mean: -1.91379
[32m[0906 16-51-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.27835, current rewards: -2320.00000, mean: -1.91736
[32m[0906 16-51-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.27836, current rewards: -2420.00000, mean: -1.92063
[32m[0906 16-51-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.27835, current rewards: -2520.00000, mean: -1.92366
[32m[0906 16-52-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.27837, current rewards: -2620.00000, mean: -1.92647
[32m[0906 16-52-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.27837, current rewards: -2720.00000, mean: -1.92908
[32m[0906 16-52-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.27837, current rewards: -2820.00000, mean: -1.93151
[32m[0906 16-52-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.27837, current rewards: -2920.00000, mean: -1.93377
[32m[0906 16-52-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.27837, current rewards: -3020.00000, mean: -1.93590
[32m[0906 16-53-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.27837, current rewards: -3120.00000, mean: -1.93789
[32m[0906 16-53-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.27836, current rewards: -3220.00000, mean: -1.93976
[32m[0906 16-53-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.27835, current rewards: -3320.00000, mean: -1.94152
[32m[0906 16-53-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.27835, current rewards: -3420.00000, mean: -1.94318
[32m[0906 16-54-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.27836, current rewards: -3520.00000, mean: -1.94475
[32m[0906 16-54-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.27835, current rewards: -3620.00000, mean: -1.94624
[32m[0906 16-54-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.27835, current rewards: -3720.00000, mean: -1.94764
[32m[0906 16-54-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.27835, current rewards: -3820.00000, mean: -1.94898
[32m[0906 16-55-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.27836, current rewards: -3920.00000, mean: -1.95025
[32m[0906 16-55-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.27836, current rewards: -4020.00000, mean: -1.95146
[32m[0906 16-55-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.27836, current rewards: -4120.00000, mean: -1.95261
[32m[0906 16-55-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.27835, current rewards: -4220.00000, mean: -1.95370
[32m[0906 16-55-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.27835, current rewards: -4320.00000, mean: -1.95475
[32m[0906 16-56-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.27834, current rewards: -4420.00000, mean: -1.95575
[32m[0906 16-56-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.27834, current rewards: -4520.00000, mean: -1.95671
[32m[0906 16-56-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.27833, current rewards: -4620.00000, mean: -1.95763
[32m[0906 16-56-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.27832, current rewards: -4720.00000, mean: -1.95851
[32m[0906 16-57-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.27832, current rewards: -4820.00000, mean: -1.95935
[32m[0906 16-57-18 @Agent.py:117][0m Average action selection time: 0.2783
[32m[0906 16-57-18 @Agent.py:118][0m Rollout length: 2600
[32m[0906 16-57-18 @MBExp.py:227][0m Rewards obtained: [-4900], Lows: [2400], Highs: [100], Total time: 1438.908713
[32m[0906 16-57-20 @MBExp.py:144][0m ####################################################################
[32m[0906 16-57-20 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 16-57-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29512, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-57-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.28042, current rewards: -60.00000, mean: -1.00000
[32m[0906 16-57-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.27944, current rewards: -100.18314, mean: -0.91076
[32m[0906 16-58-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.27906, current rewards: -147.52613, mean: -0.92204
[32m[0906 16-58-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.27885, current rewards: -247.52613, mean: -1.17870
[32m[0906 16-58-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.27875, current rewards: -347.52613, mean: -1.33664
[32m[0906 16-58-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.27867, current rewards: -447.52613, mean: -1.44363
[32m[0906 16-59-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.27862, current rewards: -547.52613, mean: -1.52091
[32m[0906 16-59-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.27855, current rewards: -647.52613, mean: -1.57933
[32m[0906 16-59-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.27851, current rewards: -747.52613, mean: -1.62506
[32m[0906 16-59-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.27848, current rewards: -847.52613, mean: -1.66182
[32m[0906 16-59-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.27846, current rewards: -900.37486, mean: -1.60781
[32m[0906 17-00-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.27845, current rewards: -893.56816, mean: -1.46487
[32m[0906 17-00-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.27843, current rewards: -933.92161, mean: -1.41503
[32m[0906 17-00-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.27841, current rewards: -1033.92161, mean: -1.45623
[32m[0906 17-00-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.27838, current rewards: -1133.92161, mean: -1.49200
[32m[0906 17-01-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.27838, current rewards: -1233.92161, mean: -1.52336
[32m[0906 17-01-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.27836, current rewards: -1333.92161, mean: -1.55107
[32m[0906 17-01-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.27834, current rewards: -1433.92161, mean: -1.57574
[32m[0906 17-01-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.27833, current rewards: -1533.92161, mean: -1.59784
[32m[0906 17-02-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.27833, current rewards: -1633.92161, mean: -1.61774
[32m[0906 17-02-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.27832, current rewards: -1733.92161, mean: -1.63578
[32m[0906 17-02-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.27831, current rewards: -1833.92161, mean: -1.65218
[32m[0906 17-02-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.27830, current rewards: -1933.92161, mean: -1.66717
[32m[0906 17-02-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.27829, current rewards: -1930.69323, mean: -1.59561
[32m[0906 17-03-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.27831, current rewards: -1925.47151, mean: -1.52815
[32m[0906 17-03-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.27830, current rewards: -1922.27580, mean: -1.46739
[32m[0906 17-03-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.27831, current rewards: -1919.19174, mean: -1.41117
[32m[0906 17-03-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.27831, current rewards: -1915.64436, mean: -1.35861
[32m[0906 17-04-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.27832, current rewards: -1912.17862, mean: -1.30971
[32m[0906 17-04-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.27832, current rewards: -1908.76365, mean: -1.26408
[32m[0906 17-04-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.27832, current rewards: -1905.32586, mean: -1.22136
[32m[0906 17-04-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.27832, current rewards: -1901.88971, mean: -1.18130
[32m[0906 17-05-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.27833, current rewards: -1954.30947, mean: -1.17729
[32m[0906 17-05-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.27833, current rewards: -2054.30947, mean: -1.20135
[32m[0906 17-05-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.27833, current rewards: -2097.68453, mean: -1.19187
[32m[0906 17-05-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.27834, current rewards: -2092.91889, mean: -1.15631
[32m[0906 17-05-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.27834, current rewards: -2087.68550, mean: -1.12241
[32m[0906 17-06-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.27834, current rewards: -2082.09129, mean: -1.09010
[32m[0906 17-06-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.27834, current rewards: -2076.39778, mean: -1.05939
[32m[0906 17-06-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.27834, current rewards: -2070.64938, mean: -1.03017
[32m[0906 17-06-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.27833, current rewards: -2151.61600, mean: -1.04447
[32m[0906 17-07-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.27833, current rewards: -2251.61600, mean: -1.06712
[32m[0906 17-07-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.27833, current rewards: -2351.61600, mean: -1.08871
[32m[0906 17-07-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.27833, current rewards: -2451.61600, mean: -1.10933
[32m[0906 17-07-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.27833, current rewards: -2551.61600, mean: -1.12903
[32m[0906 17-08-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.27833, current rewards: -2651.61600, mean: -1.14789
[32m[0906 17-08-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.27833, current rewards: -2751.61600, mean: -1.16594
[32m[0906 17-08-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.27834, current rewards: -2836.61600, mean: -1.17702
[32m[0906 17-08-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.27834, current rewards: -2841.21097, mean: -1.15496
[32m[0906 17-08-56 @Agent.py:117][0m Average action selection time: 0.2783
[32m[0906 17-08-56 @Agent.py:118][0m Rollout length: 2600
[32m[0906 17-08-56 @MBExp.py:227][0m Rewards obtained: [-2838.854098062728], Lows: [1403], Highs: [123], Total time: 2135.01603
[32m[0906 17-08-59 @MBExp.py:144][0m ####################################################################
[32m[0906 17-08-59 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 17-09-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.27738, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-09-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.27740, current rewards: -60.00000, mean: -1.00000
[32m[0906 17-09-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.27777, current rewards: -110.00000, mean: -1.00000
[32m[0906 17-09-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.27796, current rewards: -160.00000, mean: -1.00000
[32m[0906 17-09-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.27808, current rewards: -210.00000, mean: -1.00000
[32m[0906 17-10-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.27817, current rewards: -260.00000, mean: -1.00000
[32m[0906 17-10-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.27823, current rewards: -310.00000, mean: -1.00000
[32m[0906 17-10-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.27828, current rewards: -360.00000, mean: -1.00000
[32m[0906 17-10-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.27830, current rewards: -382.64636, mean: -0.93328
[32m[0906 17-11-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.27835, current rewards: -380.03253, mean: -0.82616
[32m[0906 17-11-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.27835, current rewards: -415.30100, mean: -0.81432
[32m[0906 17-11-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.27836, current rewards: -465.30100, mean: -0.83089
[32m[0906 17-11-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.27838, current rewards: -515.30100, mean: -0.84476
[32m[0906 17-12-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.27838, current rewards: -565.30100, mean: -0.85652
[32m[0906 17-12-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.27836, current rewards: -615.30100, mean: -0.86662
[32m[0906 17-12-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.27836, current rewards: -665.30100, mean: -0.87540
[32m[0906 17-12-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.27838, current rewards: -715.30100, mean: -0.88309
[32m[0906 17-12-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.27838, current rewards: -765.30100, mean: -0.88988
[32m[0906 17-13-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.27839, current rewards: -815.30100, mean: -0.89594
[32m[0906 17-13-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.27839, current rewards: -865.30100, mean: -0.90136
[32m[0906 17-13-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.27839, current rewards: -915.30100, mean: -0.90624
[32m[0906 17-13-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.27839, current rewards: -965.30100, mean: -0.91066
[32m[0906 17-14-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.27839, current rewards: -1015.30100, mean: -0.91469
[32m[0906 17-14-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.27838, current rewards: -1065.30100, mean: -0.91836
[32m[0906 17-14-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.27836, current rewards: -1115.30100, mean: -0.92174
[32m[0906 17-14-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.27835, current rewards: -1165.30100, mean: -0.92484
[32m[0906 17-15-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.27835, current rewards: -1215.30100, mean: -0.92771
[32m[0906 17-15-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.27835, current rewards: -1265.30100, mean: -0.93037
[32m[0906 17-15-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.27836, current rewards: -1315.30100, mean: -0.93284
[32m[0906 17-15-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.27836, current rewards: -1365.30100, mean: -0.93514
[32m[0906 17-16-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.27837, current rewards: -1415.30100, mean: -0.93729
[32m[0906 17-16-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.27836, current rewards: -1465.30100, mean: -0.93930
[32m[0906 17-16-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.27836, current rewards: -1515.30100, mean: -0.94118
[32m[0906 17-16-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.27836, current rewards: -1537.80023, mean: -0.92639
[32m[0906 17-16-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.27835, current rewards: -1534.91415, mean: -0.89761
[32m[0906 17-17-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.27836, current rewards: -1532.02807, mean: -0.87047
[32m[0906 17-17-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.27835, current rewards: -1529.14198, mean: -0.84483
[32m[0906 17-17-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.27834, current rewards: -1526.25590, mean: -0.82057
[32m[0906 17-17-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.27834, current rewards: -1523.36981, mean: -0.79758
[32m[0906 17-18-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.27834, current rewards: -1520.48373, mean: -0.77576
[32m[0906 17-18-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.27833, current rewards: -1517.59765, mean: -0.75502
[32m[0906 17-18-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.27833, current rewards: -1513.61397, mean: -0.73476
[32m[0906 17-18-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.27832, current rewards: -1509.15522, mean: -0.71524
[32m[0906 17-19-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.27832, current rewards: -1517.76658, mean: -0.70267
[32m[0906 17-19-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.27832, current rewards: -1567.76658, mean: -0.70940
[32m[0906 17-19-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.27831, current rewards: -1617.76658, mean: -0.71583
[32m[0906 17-19-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.27831, current rewards: -1667.76658, mean: -0.72198
[32m[0906 17-19-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.27830, current rewards: -1717.76658, mean: -0.72787
[32m[0906 17-20-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.27830, current rewards: -1767.76658, mean: -0.73351
[32m[0906 17-20-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.27830, current rewards: -1817.76658, mean: -0.73893
[32m[0906 17-20-35 @Agent.py:117][0m Average action selection time: 0.2783
[32m[0906 17-20-35 @Agent.py:118][0m Rollout length: 2600
[32m[0906 17-20-35 @MBExp.py:227][0m Rewards obtained: [-1857.7665768398822], Lows: [0], Highs: [1896], Total time: 2831.0519289999997
[32m[0906 17-20-39 @MBExp.py:144][0m ####################################################################
[32m[0906 17-20-39 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 17-20-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.27676, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-20-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.27679, current rewards: -60.00000, mean: -1.00000
[32m[0906 17-21-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.27749, current rewards: -109.90655, mean: -0.99915
[32m[0906 17-21-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.27767, current rewards: -209.90655, mean: -1.31192
[32m[0906 17-21-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.27780, current rewards: -304.90655, mean: -1.45194
[32m[0906 17-21-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.27789, current rewards: -354.90655, mean: -1.36503
[32m[0906 17-22-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.27798, current rewards: -407.85855, mean: -1.31567
[32m[0906 17-22-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.27807, current rewards: -507.85855, mean: -1.41072
[32m[0906 17-22-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.27812, current rewards: -602.62448, mean: -1.46982
[32m[0906 17-22-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.27815, current rewards: -652.62448, mean: -1.41875
[32m[0906 17-23-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.27822, current rewards: -689.66878, mean: -1.35229
[32m[0906 17-23-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.27824, current rewards: -789.66878, mean: -1.41012
[32m[0906 17-23-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.27825, current rewards: -883.61647, mean: -1.44855
[32m[0906 17-23-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.27828, current rewards: -933.61647, mean: -1.41457
[32m[0906 17-23-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.27830, current rewards: -983.61647, mean: -1.38538
[32m[0906 17-24-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.27831, current rewards: -1033.61647, mean: -1.36002
[32m[0906 17-24-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.27833, current rewards: -1083.61647, mean: -1.33780
[32m[0906 17-24-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.27833, current rewards: -1133.61647, mean: -1.31816
[32m[0906 17-24-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.27834, current rewards: -1183.61647, mean: -1.30068
[32m[0906 17-25-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.27835, current rewards: -1233.61647, mean: -1.28502
[32m[0906 17-25-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.27836, current rewards: -1283.61647, mean: -1.27091
[32m[0906 17-25-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.27836, current rewards: -1333.61647, mean: -1.25813
[32m[0906 17-25-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.27837, current rewards: -1383.61647, mean: -1.24650
[32m[0906 17-26-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.27838, current rewards: -1433.61647, mean: -1.23588
[32m[0906 17-26-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.27839, current rewards: -1483.61647, mean: -1.22613
[32m[0906 17-26-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.27838, current rewards: -1533.61647, mean: -1.21716
[32m[0906 17-26-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.27839, current rewards: -1583.61647, mean: -1.20887
[32m[0906 17-26-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.27838, current rewards: -1633.61647, mean: -1.20119
[32m[0906 17-27-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.27839, current rewards: -1683.61647, mean: -1.19405
[32m[0906 17-27-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.27839, current rewards: -1733.61647, mean: -1.18741
[32m[0906 17-27-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.27838, current rewards: -1783.61647, mean: -1.18120
[32m[0906 17-27-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.27838, current rewards: -1833.61647, mean: -1.17540
[32m[0906 17-28-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.27838, current rewards: -1831.54289, mean: -1.13760
[32m[0906 17-28-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.27838, current rewards: -1823.68335, mean: -1.09860
[32m[0906 17-28-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.27837, current rewards: -1815.82381, mean: -1.06189
[32m[0906 17-28-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.27838, current rewards: -1807.96427, mean: -1.02725
[32m[0906 17-29-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.27838, current rewards: -1800.10473, mean: -0.99453
[32m[0906 17-29-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.27838, current rewards: -1792.24519, mean: -0.96357
[32m[0906 17-29-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.27838, current rewards: -1784.38565, mean: -0.93423
[32m[0906 17-29-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.27838, current rewards: -1779.99768, mean: -0.90816
[32m[0906 17-29-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.27838, current rewards: -1829.99768, mean: -0.91045
[32m[0906 17-30-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.27839, current rewards: -1879.99768, mean: -0.91262
[32m[0906 17-30-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.27839, current rewards: -1929.99768, mean: -0.91469
[32m[0906 17-30-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.27839, current rewards: -1979.99768, mean: -0.91667
[32m[0906 17-30-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.27839, current rewards: -2029.99768, mean: -0.91855
[32m[0906 17-31-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.27839, current rewards: -2079.99768, mean: -0.92035
[32m[0906 17-31-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.27839, current rewards: -2129.99768, mean: -0.92208
[32m[0906 17-31-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.27839, current rewards: -2179.99768, mean: -0.92373
[32m[0906 17-31-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.27839, current rewards: -2229.99768, mean: -0.92531
[32m[0906 17-32-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.27839, current rewards: -2279.99768, mean: -0.92683
[32m[0906 17-32-15 @Agent.py:117][0m Average action selection time: 0.2784
[32m[0906 17-32-15 @Agent.py:118][0m Rollout length: 2600
[32m[0906 17-32-15 @MBExp.py:227][0m Rewards obtained: [-2319.997684884589], Lows: [302], Highs: [1783], Total time: 3527.285383
[32m[0906 17-32-19 @MBExp.py:144][0m ####################################################################
[32m[0906 17-32-19 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 17-32-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.27624, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-32-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.27644, current rewards: -60.00000, mean: -1.00000
[32m[0906 17-32-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.27709, current rewards: -120.00000, mean: -1.09091
[32m[0906 17-33-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.27738, current rewards: -220.00000, mean: -1.37500
[32m[0906 17-33-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.27749, current rewards: -320.00000, mean: -1.52381
[32m[0906 17-33-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.27755, current rewards: -420.00000, mean: -1.61538
[32m[0906 17-33-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.27767, current rewards: -520.00000, mean: -1.67742
[32m[0906 17-33-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.27775, current rewards: -620.00000, mean: -1.72222
[32m[0906 17-34-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.27785, current rewards: -720.00000, mean: -1.75610
[32m[0906 17-34-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.27793, current rewards: -820.00000, mean: -1.78261
[32m[0906 17-34-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.27797, current rewards: -920.00000, mean: -1.80392
[32m[0906 17-34-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.27802, current rewards: -1020.00000, mean: -1.82143
[32m[0906 17-35-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.27806, current rewards: -1120.00000, mean: -1.83607
[32m[0906 17-35-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.27809, current rewards: -1220.00000, mean: -1.84848
[32m[0906 17-35-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.27811, current rewards: -1320.00000, mean: -1.85915
[32m[0906 17-35-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.27812, current rewards: -1420.00000, mean: -1.86842
[32m[0906 17-36-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.27815, current rewards: -1520.00000, mean: -1.87654
[32m[0906 17-36-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.27818, current rewards: -1620.00000, mean: -1.88372
[32m[0906 17-36-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.27819, current rewards: -1720.00000, mean: -1.89011
[32m[0906 17-36-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.27820, current rewards: -1820.00000, mean: -1.89583
[32m[0906 17-37-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.27822, current rewards: -1920.00000, mean: -1.90099
[32m[0906 17-37-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.27823, current rewards: -2020.00000, mean: -1.90566
[32m[0906 17-37-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.27824, current rewards: -2120.00000, mean: -1.90991
[32m[0906 17-37-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.27825, current rewards: -2220.00000, mean: -1.91379
[32m[0906 17-37-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.27825, current rewards: -2320.00000, mean: -1.91736
[32m[0906 17-38-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.27826, current rewards: -2420.00000, mean: -1.92063
[32m[0906 17-38-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.27826, current rewards: -2520.00000, mean: -1.92366
[32m[0906 17-38-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.27826, current rewards: -2620.00000, mean: -1.92647
[32m[0906 17-38-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.27826, current rewards: -2720.00000, mean: -1.92908
[32m[0906 17-39-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.27827, current rewards: -2820.00000, mean: -1.93151
[32m[0906 17-39-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.27827, current rewards: -2920.00000, mean: -1.93377
[32m[0906 17-39-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.27827, current rewards: -3020.00000, mean: -1.93590
[32m[0906 17-39-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.27826, current rewards: -3120.00000, mean: -1.93789
[32m[0906 17-40-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.27827, current rewards: -3220.00000, mean: -1.93976
[32m[0906 17-40-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.27827, current rewards: -3320.00000, mean: -1.94152
[32m[0906 17-40-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.27827, current rewards: -3420.00000, mean: -1.94318
[32m[0906 17-40-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.27827, current rewards: -3520.00000, mean: -1.94475
[32m[0906 17-40-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.27828, current rewards: -3620.00000, mean: -1.94624
[32m[0906 17-41-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.27829, current rewards: -3720.00000, mean: -1.94764
[32m[0906 17-41-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.27829, current rewards: -3820.00000, mean: -1.94898
[32m[0906 17-41-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.27830, current rewards: -3920.00000, mean: -1.95025
[32m[0906 17-41-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.27830, current rewards: -4020.00000, mean: -1.95146
[32m[0906 17-42-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.27831, current rewards: -4120.00000, mean: -1.95261
[32m[0906 17-42-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.27831, current rewards: -4220.00000, mean: -1.95370
[32m[0906 17-42-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.27830, current rewards: -4320.00000, mean: -1.95475
[32m[0906 17-42-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.27830, current rewards: -4420.00000, mean: -1.95575
[32m[0906 17-43-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.27831, current rewards: -4520.00000, mean: -1.95671
[32m[0906 17-43-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.27831, current rewards: -4620.00000, mean: -1.95763
[32m[0906 17-43-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.27832, current rewards: -4720.00000, mean: -1.95851
[32m[0906 17-43-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.27832, current rewards: -4820.00000, mean: -1.95935
[32m[0906 17-43-55 @Agent.py:117][0m Average action selection time: 0.2783
[32m[0906 17-43-55 @Agent.py:118][0m Rollout length: 2600
[32m[0906 17-43-55 @MBExp.py:227][0m Rewards obtained: [-4900], Lows: [2400], Highs: [100], Total time: 4223.346995
[32m[0906 17-44-00 @MBExp.py:144][0m ####################################################################
[32m[0906 17-44-00 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 17-44-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.27632, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-44-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.27645, current rewards: -60.00000, mean: -1.00000
[32m[0906 17-44-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.27711, current rewards: -115.80609, mean: -1.05278
[32m[0906 17-44-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.27744, current rewards: -215.80609, mean: -1.34879
[32m[0906 17-44-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.27758, current rewards: -315.80609, mean: -1.50384
[32m[0906 17-45-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.27772, current rewards: -415.80609, mean: -1.59925
[32m[0906 17-45-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.27784, current rewards: -515.80609, mean: -1.66389
[32m[0906 17-45-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.27790, current rewards: -615.80609, mean: -1.71057
[32m[0906 17-45-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.27794, current rewards: -715.80609, mean: -1.74587
[32m[0906 17-46-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.27800, current rewards: -775.85022, mean: -1.68663
[32m[0906 17-46-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.27801, current rewards: -875.85022, mean: -1.71735
[32m[0906 17-46-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.27804, current rewards: -930.31894, mean: -1.66128
[32m[0906 17-46-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.27807, current rewards: -1030.31894, mean: -1.68905
[32m[0906 17-47-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.27809, current rewards: -1107.21428, mean: -1.67760
[32m[0906 17-47-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.27811, current rewards: -1102.25702, mean: -1.55247
[32m[0906 17-47-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.27811, current rewards: -1107.43111, mean: -1.45715
[32m[0906 17-47-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.27812, current rewards: -1207.43111, mean: -1.49066
[32m[0906 17-48-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.27814, current rewards: -1307.43111, mean: -1.52027
[32m[0906 17-48-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.27813, current rewards: -1407.43111, mean: -1.54663
[32m[0906 17-48-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.27814, current rewards: -1445.69192, mean: -1.50593
[32m[0906 17-48-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.27815, current rewards: -1483.60134, mean: -1.46891
[32m[0906 17-48-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.27816, current rewards: -1533.60134, mean: -1.44679
[32m[0906 17-49-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.27816, current rewards: -1619.49277, mean: -1.45900
[32m[0906 17-49-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.27815, current rewards: -1719.49277, mean: -1.48232
[32m[0906 17-49-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.27816, current rewards: -1819.49277, mean: -1.50371
[32m[0906 17-49-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.27816, current rewards: -1919.49277, mean: -1.52341
[32m[0906 17-50-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.27817, current rewards: -2019.49277, mean: -1.54160
[32m[0906 17-50-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.27816, current rewards: -2119.49277, mean: -1.55845
[32m[0906 17-50-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.27817, current rewards: -2219.49277, mean: -1.57411
[32m[0906 17-50-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.27817, current rewards: -2319.49277, mean: -1.58869
[32m[0906 17-51-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.27818, current rewards: -2419.49277, mean: -1.60231
[32m[0906 17-51-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.27818, current rewards: -2519.49277, mean: -1.61506
[32m[0906 17-51-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.27818, current rewards: -2619.49277, mean: -1.62701
[32m[0906 17-51-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.27819, current rewards: -2719.49277, mean: -1.63825
[32m[0906 17-51-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.27820, current rewards: -2819.49277, mean: -1.64883
[32m[0906 17-52-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.27821, current rewards: -2914.17450, mean: -1.65578
[32m[0906 17-52-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.27822, current rewards: -3014.17450, mean: -1.66529
[32m[0906 17-52-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.27822, current rewards: -3114.17450, mean: -1.67429
[32m[0906 17-52-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.27823, current rewards: -3214.17450, mean: -1.68281
[32m[0906 17-53-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.27824, current rewards: -3314.17450, mean: -1.69091
[32m[0906 17-53-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.27825, current rewards: -3414.17450, mean: -1.69859
[32m[0906 17-53-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.27826, current rewards: -3514.17450, mean: -1.70591
[32m[0906 17-53-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.27827, current rewards: -3614.17450, mean: -1.71288
[32m[0906 17-54-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.27827, current rewards: -3714.17450, mean: -1.71953
[32m[0906 17-54-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.27837, current rewards: -3814.17450, mean: -1.72587
[32m[0906 17-54-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.27880, current rewards: -3914.17450, mean: -1.73194
[32m[0906 17-54-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.27922, current rewards: -4014.17450, mean: -1.73774
[32m[0906 17-55-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.27957, current rewards: -4114.17450, mean: -1.74329
[32m[0906 17-55-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.27992, current rewards: -4214.17450, mean: -1.74862
[32m[0906 17-55-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.28027, current rewards: -4314.17450, mean: -1.75373
[32m[0906 17-55-42 @Agent.py:117][0m Average action selection time: 0.2806
[32m[0906 17-55-42 @Agent.py:118][0m Rollout length: 2600
[32m[0906 17-55-42 @MBExp.py:227][0m Rewards obtained: [-4394.174496108405], Lows: [2115], Highs: [203], Total time: 4925.083843
[32m[0906 17-55-48 @MBExp.py:144][0m ####################################################################
[32m[0906 17-55-48 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 17-55-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29267, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-56-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29258, current rewards: -60.00000, mean: -1.00000
[32m[0906 17-56-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29514, current rewards: -106.85365, mean: -0.97140
[32m[0906 17-56-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29544, current rewards: -103.32919, mean: -0.64581
[32m[0906 17-56-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29566, current rewards: -101.35971, mean: -0.48267
[32m[0906 17-57-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29584, current rewards: -151.35971, mean: -0.58215
[32m[0906 17-57-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29562, current rewards: -200.31061, mean: -0.64616
[32m[0906 17-57-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29555, current rewards: -198.93787, mean: -0.55261
[32m[0906 17-57-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29584, current rewards: -196.47753, mean: -0.47921
[32m[0906 17-58-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29598, current rewards: -245.40861, mean: -0.53350
[32m[0906 17-58-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29592, current rewards: -295.40861, mean: -0.57923
[32m[0906 17-58-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29596, current rewards: -294.74488, mean: -0.52633
[32m[0906 17-58-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29605, current rewards: -292.10416, mean: -0.47886
[32m[0906 17-59-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29671, current rewards: -338.92817, mean: -0.51353
[32m[0906 17-59-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29689, current rewards: -388.92817, mean: -0.54779
[32m[0906 17-59-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29704, current rewards: -473.53701, mean: -0.62308
[32m[0906 17-59-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29736, current rewards: -573.53701, mean: -0.70807
[32m[0906 18-00-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29746, current rewards: -673.53701, mean: -0.78318
[32m[0906 18-00-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29753, current rewards: -773.53701, mean: -0.85004
[32m[0906 18-00-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29758, current rewards: -873.53701, mean: -0.90993
[32m[0906 18-00-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29776, current rewards: -973.53701, mean: -0.96390
[32m[0906 18-01-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29808, current rewards: -1073.53701, mean: -1.01277
[32m[0906 18-01-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29837, current rewards: -1161.21608, mean: -1.04614
[32m[0906 18-01-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29850, current rewards: -1158.24144, mean: -0.99848
[32m[0906 18-01-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29866, current rewards: -1191.03060, mean: -0.98432
[32m[0906 18-02-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29875, current rewards: -1175.80823, mean: -0.93318
[32m[0906 18-02-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29868, current rewards: -1211.53397, mean: -0.92484
[32m[0906 18-02-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29872, current rewards: -1223.43401, mean: -0.89958
[32m[0906 18-02-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29875, current rewards: -1270.50670, mean: -0.90107
[32m[0906 18-03-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29882, current rewards: -1370.50670, mean: -0.93870
[32m[0906 18-03-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29872, current rewards: -1470.50670, mean: -0.97385
[32m[0906 18-03-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29876, current rewards: -1570.50670, mean: -1.00674
[32m[0906 18-03-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29880, current rewards: -1670.50670, mean: -1.03758
[32m[0906 18-04-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29886, current rewards: -1770.50670, mean: -1.06657
[32m[0906 18-04-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29892, current rewards: -1870.50670, mean: -1.09386
[32m[0906 18-04-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29886, current rewards: -1970.50670, mean: -1.11961
[32m[0906 18-04-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29880, current rewards: -2070.50670, mean: -1.14393
[32m[0906 18-05-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29874, current rewards: -2170.50670, mean: -1.16694
[32m[0906 18-05-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29867, current rewards: -2270.50670, mean: -1.18875
[32m[0906 18-05-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29864, current rewards: -2305.46666, mean: -1.17626
[32m[0906 18-05-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29863, current rewards: -2374.14368, mean: -1.18117
[32m[0906 18-06-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29861, current rewards: -2405.50335, mean: -1.16772
[32m[0906 18-06-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29869, current rewards: -2471.22194, mean: -1.17120
[32m[0906 18-06-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29875, current rewards: -2501.49129, mean: -1.15810
[32m[0906 18-06-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29866, current rewards: -2568.54197, mean: -1.16224
[32m[0906 18-07-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29863, current rewards: -2600.56791, mean: -1.15069
[32m[0906 18-07-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29858, current rewards: -2664.60451, mean: -1.15351
[32m[0906 18-07-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29853, current rewards: -2764.60451, mean: -1.17144
[32m[0906 18-07-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29848, current rewards: -2864.60451, mean: -1.18863
[32m[0906 18-08-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29839, current rewards: -2964.60451, mean: -1.20512
[32m[0906 18-08-14 @Agent.py:117][0m Average action selection time: 0.2983
[32m[0906 18-08-14 @Agent.py:118][0m Rollout length: 2600
[32m[0906 18-08-14 @MBExp.py:227][0m Rewards obtained: [-3044.604509696382], Lows: [1393], Highs: [432], Total time: 5671.250111
[32m[0906 18-08-21 @MBExp.py:144][0m ####################################################################
[32m[0906 18-08-21 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 18-08-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30339, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-08-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30303, current rewards: -60.00000, mean: -1.00000
[32m[0906 18-08-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30353, current rewards: -120.00000, mean: -1.09091
[32m[0906 18-09-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30402, current rewards: -220.00000, mean: -1.37500
[32m[0906 18-09-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30434, current rewards: -320.00000, mean: -1.52381
[32m[0906 18-09-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30447, current rewards: -420.00000, mean: -1.61538
[32m[0906 18-09-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30429, current rewards: -520.00000, mean: -1.67742
[32m[0906 18-10-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30315, current rewards: -620.00000, mean: -1.72222
[32m[0906 18-10-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30213, current rewards: -720.00000, mean: -1.75610
[32m[0906 18-10-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30160, current rewards: -820.00000, mean: -1.78261
[32m[0906 18-10-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30173, current rewards: -920.00000, mean: -1.80392
[32m[0906 18-11-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30207, current rewards: -1020.00000, mean: -1.82143
[32m[0906 18-11-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30228, current rewards: -1120.00000, mean: -1.83607
[32m[0906 18-11-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30263, current rewards: -1220.00000, mean: -1.84848
[32m[0906 18-11-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30282, current rewards: -1320.00000, mean: -1.85915
[32m[0906 18-12-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30258, current rewards: -1420.00000, mean: -1.86842
[32m[0906 18-12-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30271, current rewards: -1520.00000, mean: -1.87654
[32m[0906 18-12-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30258, current rewards: -1620.00000, mean: -1.88372
[32m[0906 18-12-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30269, current rewards: -1720.00000, mean: -1.89011
[32m[0906 18-13-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30279, current rewards: -1820.00000, mean: -1.89583
[32m[0906 18-13-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30289, current rewards: -1920.00000, mean: -1.90099
[32m[0906 18-13-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30298, current rewards: -2020.00000, mean: -1.90566
[32m[0906 18-13-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30302, current rewards: -2120.00000, mean: -1.90991
[32m[0906 18-14-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30312, current rewards: -2220.00000, mean: -1.91379
[32m[0906 18-14-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30317, current rewards: -2320.00000, mean: -1.91736
[32m[0906 18-14-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30303, current rewards: -2420.00000, mean: -1.92063
[32m[0906 18-14-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30295, current rewards: -2520.00000, mean: -1.92366
[32m[0906 18-15-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30308, current rewards: -2620.00000, mean: -1.92647
[32m[0906 18-15-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30324, current rewards: -2720.00000, mean: -1.92908
[32m[0906 18-15-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30335, current rewards: -2820.00000, mean: -1.93151
[32m[0906 18-15-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30332, current rewards: -2920.00000, mean: -1.93377
[32m[0906 18-16-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30316, current rewards: -3020.00000, mean: -1.93590
[32m[0906 18-16-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30318, current rewards: -3120.00000, mean: -1.93789
[32m[0906 18-16-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30324, current rewards: -3220.00000, mean: -1.93976
[32m[0906 18-16-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30330, current rewards: -3320.00000, mean: -1.94152
[32m[0906 18-17-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30335, current rewards: -3420.00000, mean: -1.94318
[32m[0906 18-17-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30345, current rewards: -3520.00000, mean: -1.94475
[32m[0906 18-17-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30354, current rewards: -3620.00000, mean: -1.94624
[32m[0906 18-18-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30360, current rewards: -3720.00000, mean: -1.94764
[32m[0906 18-18-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30345, current rewards: -3820.00000, mean: -1.94898
[32m[0906 18-18-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30344, current rewards: -3920.00000, mean: -1.95025
[32m[0906 18-18-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30345, current rewards: -4020.00000, mean: -1.95146
[32m[0906 18-19-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30340, current rewards: -4120.00000, mean: -1.95261
[32m[0906 18-19-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30336, current rewards: -4220.00000, mean: -1.95370
[32m[0906 18-19-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30341, current rewards: -4320.00000, mean: -1.95475
[32m[0906 18-19-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30331, current rewards: -4420.00000, mean: -1.95575
[32m[0906 18-20-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30335, current rewards: -4520.00000, mean: -1.95671
[32m[0906 18-20-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30339, current rewards: -4620.00000, mean: -1.95763
[32m[0906 18-20-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30344, current rewards: -4720.00000, mean: -1.95851
[32m[0906 18-20-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30347, current rewards: -4820.00000, mean: -1.95935
[32m[0906 18-21-00 @Agent.py:117][0m Average action selection time: 0.3035
[32m[0906 18-21-00 @Agent.py:118][0m Rollout length: 2600
[32m[0906 18-21-00 @MBExp.py:227][0m Rewards obtained: [-4900], Lows: [2400], Highs: [100], Total time: 6430.43045
[32m[0906 18-21-07 @MBExp.py:144][0m ####################################################################
[32m[0906 18-21-07 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 18-21-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31035, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-21-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30873, current rewards: -60.00000, mean: -1.00000
[32m[0906 18-21-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30850, current rewards: -110.00000, mean: -1.00000
[32m[0906 18-21-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30866, current rewards: -160.00000, mean: -1.00000
[32m[0906 18-22-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30882, current rewards: -160.70894, mean: -0.76528
[32m[0906 18-22-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30910, current rewards: -156.90969, mean: -0.60350
[32m[0906 18-22-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30924, current rewards: -152.77270, mean: -0.49282
[32m[0906 18-22-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30916, current rewards: -148.08227, mean: -0.41134
[32m[0906 18-23-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30910, current rewards: -142.72694, mean: -0.34811
[32m[0906 18-23-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30924, current rewards: -136.23154, mean: -0.29616
[32m[0906 18-23-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30931, current rewards: -128.24626, mean: -0.25146
[32m[0906 18-24-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30977, current rewards: -124.01678, mean: -0.22146
[32m[0906 18-24-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31037, current rewards: -174.01678, mean: -0.28527
[32m[0906 18-24-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31094, current rewards: -224.01678, mean: -0.33942
[32m[0906 18-24-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31089, current rewards: -274.01678, mean: -0.38594
[32m[0906 18-25-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31062, current rewards: -324.01678, mean: -0.42634
[32m[0906 18-25-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31038, current rewards: -374.01678, mean: -0.46175
[32m[0906 18-25-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31003, current rewards: -424.01678, mean: -0.49304
[32m[0906 18-25-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30975, current rewards: -474.01678, mean: -0.52090
[32m[0906 18-26-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30994, current rewards: -524.01678, mean: -0.54585
[32m[0906 18-26-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31016, current rewards: -574.01678, mean: -0.56833
[32m[0906 18-26-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31009, current rewards: -624.01678, mean: -0.58870
[32m[0906 18-26-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30965, current rewards: -674.01678, mean: -0.60722
[32m[0906 18-27-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30959, current rewards: -724.01678, mean: -0.62415
[32m[0906 18-27-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30957, current rewards: -774.01678, mean: -0.63968
[32m[0906 18-27-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30958, current rewards: -824.01678, mean: -0.65398
[32m[0906 18-27-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30954, current rewards: -874.01678, mean: -0.66719
[32m[0906 18-28-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30974, current rewards: -924.01678, mean: -0.67942
[32m[0906 18-28-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30967, current rewards: -974.01678, mean: -0.69079
[32m[0906 18-28-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30972, current rewards: -1024.01678, mean: -0.70138
[32m[0906 18-28-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30968, current rewards: -1074.01678, mean: -0.71127
[32m[0906 18-29-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30985, current rewards: -1124.01678, mean: -0.72052
[32m[0906 18-29-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30995, current rewards: -1165.51989, mean: -0.72393
[32m[0906 18-29-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31007, current rewards: -1202.72535, mean: -0.72453
[32m[0906 18-29-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31012, current rewards: -1228.17051, mean: -0.71823
[32m[0906 18-30-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31021, current rewards: -1292.68465, mean: -0.73448
[32m[0906 18-30-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31020, current rewards: -1368.53228, mean: -0.75610
[32m[0906 18-30-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31031, current rewards: -1431.15873, mean: -0.76944
[32m[0906 18-31-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31060, current rewards: -1486.94835, mean: -0.77851
[32m[0906 18-31-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31079, current rewards: -1544.11205, mean: -0.78781
[32m[0906 18-31-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31085, current rewards: -1541.69474, mean: -0.76701
[32m[0906 18-31-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31104, current rewards: -1591.69474, mean: -0.77267
[32m[0906 18-32-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31111, current rewards: -1640.61931, mean: -0.77754
[32m[0906 18-32-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31111, current rewards: -1690.61931, mean: -0.78269
[32m[0906 18-32-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31125, current rewards: -1728.99801, mean: -0.78235
[32m[0906 18-32-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31130, current rewards: -1726.16447, mean: -0.76379
[32m[0906 18-33-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31139, current rewards: -1757.29226, mean: -0.76073
[32m[0906 18-33-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31148, current rewards: -1807.29226, mean: -0.76580
[32m[0906 18-33-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31153, current rewards: -1843.54911, mean: -0.76496
[32m[0906 18-33-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31152, current rewards: -1893.54911, mean: -0.76974
[32m[0906 18-34-06 @Agent.py:117][0m Average action selection time: 0.3115
[32m[0906 18-34-06 @Agent.py:118][0m Rollout length: 2600
[32m[0906 18-34-06 @MBExp.py:227][0m Rewards obtained: [-1933.549105760025], Lows: [149], Highs: [1723], Total time: 7209.718764
[32m[0906 18-34-15 @MBExp.py:144][0m ####################################################################
[32m[0906 18-34-15 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 18-34-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31051, current rewards: 0.78723, mean: 0.07872
[32m[0906 18-34-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30377, current rewards: 5.24598, mean: 0.08743
[32m[0906 18-34-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30315, current rewards: -6.92817, mean: -0.06298
[32m[0906 18-35-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30265, current rewards: -106.92817, mean: -0.66830
[32m[0906 18-35-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30237, current rewards: -206.92817, mean: -0.98537
[32m[0906 18-35-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30315, current rewards: -235.74584, mean: -0.90671
[32m[0906 18-35-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30312, current rewards: -230.50115, mean: -0.74355
[32m[0906 18-36-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30293, current rewards: -225.25646, mean: -0.62571
[32m[0906 18-36-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30279, current rewards: -220.01177, mean: -0.53661
[32m[0906 18-36-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30254, current rewards: -254.54326, mean: -0.55335
[32m[0906 18-36-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30232, current rewards: -304.54326, mean: -0.59714
[32m[0906 18-37-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30242, current rewards: -354.54326, mean: -0.63311
[32m[0906 18-37-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30278, current rewards: -404.54326, mean: -0.66319
[32m[0906 18-37-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30325, current rewards: -454.54326, mean: -0.68870
[32m[0906 18-37-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30356, current rewards: -504.54326, mean: -0.71062
[32m[0906 18-38-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30404, current rewards: -554.54326, mean: -0.72966
[32m[0906 18-38-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30385, current rewards: -609.48854, mean: -0.75245
[32m[0906 18-38-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30371, current rewards: -630.21368, mean: -0.73281
[32m[0906 18-38-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30381, current rewards: -725.01454, mean: -0.79672
[32m[0906 18-39-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30395, current rewards: -757.21724, mean: -0.78877
[32m[0906 18-39-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30413, current rewards: -787.14392, mean: -0.77935
[32m[0906 18-39-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30436, current rewards: -775.47445, mean: -0.73158
[32m[0906 18-39-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30430, current rewards: -779.98305, mean: -0.70269
[32m[0906 18-40-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30415, current rewards: -802.75632, mean: -0.69203
[32m[0906 18-40-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30399, current rewards: -852.75632, mean: -0.70476
[32m[0906 18-40-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30398, current rewards: -901.69185, mean: -0.71563
[32m[0906 18-40-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30385, current rewards: -921.21122, mean: -0.70321
[32m[0906 18-41-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30372, current rewards: -971.21122, mean: -0.71413
[32m[0906 18-41-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30362, current rewards: -1012.79279, mean: -0.71829
[32m[0906 18-41-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30380, current rewards: -1062.79279, mean: -0.72794
[32m[0906 18-41-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30401, current rewards: -1111.74205, mean: -0.73625
[32m[0906 18-42-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30406, current rewards: -1161.74205, mean: -0.74471
[32m[0906 18-42-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30416, current rewards: -1211.74205, mean: -0.75263
[32m[0906 18-42-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30428, current rewards: -1261.74205, mean: -0.76009
[32m[0906 18-42-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30425, current rewards: -1311.74205, mean: -0.76710
[32m[0906 18-43-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30424, current rewards: -1361.74205, mean: -0.77372
[32m[0906 18-43-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30438, current rewards: -1411.74205, mean: -0.77997
[32m[0906 18-43-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30454, current rewards: -1461.74205, mean: -0.78588
[32m[0906 18-43-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30468, current rewards: -1511.74205, mean: -0.79149
[32m[0906 18-44-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30465, current rewards: -1561.74205, mean: -0.79681
[32m[0906 18-44-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30458, current rewards: -1611.74205, mean: -0.80186
[32m[0906 18-44-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30468, current rewards: -1645.80386, mean: -0.79893
[32m[0906 18-44-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30476, current rewards: -1642.73525, mean: -0.77855
[32m[0906 18-45-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30476, current rewards: -1654.52364, mean: -0.76598
[32m[0906 18-45-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30485, current rewards: -1704.52364, mean: -0.77128
[32m[0906 18-45-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30481, current rewards: -1740.71294, mean: -0.77023
[32m[0906 18-45-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30474, current rewards: -1737.59487, mean: -0.75221
[32m[0906 18-46-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30470, current rewards: -1734.47679, mean: -0.73495
[32m[0906 18-46-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30464, current rewards: -1731.35872, mean: -0.71841
[32m[0906 18-46-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30456, current rewards: -1728.24065, mean: -0.70254
[32m[0906 18-46-56 @Agent.py:117][0m Average action selection time: 0.3045
[32m[0906 18-46-56 @Agent.py:118][0m Rollout length: 2600
[32m[0906 18-46-56 @MBExp.py:227][0m Rewards obtained: [-1725.7461881914753], Lows: [247], Highs: [1352], Total time: 7971.402851
[32m[0906 18-47-05 @MBExp.py:144][0m ####################################################################
[32m[0906 18-47-05 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 18-47-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29899, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-47-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29876, current rewards: -60.00000, mean: -1.00000
[32m[0906 18-47-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29936, current rewards: -110.00000, mean: -1.00000
[32m[0906 18-47-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30015, current rewards: -160.00000, mean: -1.00000
[32m[0906 18-48-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30026, current rewards: -161.43772, mean: -0.76875
[32m[0906 18-48-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30025, current rewards: -164.41624, mean: -0.63237
[32m[0906 18-48-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30031, current rewards: -214.41624, mean: -0.69167
[32m[0906 18-48-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30032, current rewards: -264.41624, mean: -0.73449
[32m[0906 18-49-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30035, current rewards: -314.41624, mean: -0.76687
[32m[0906 18-49-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30049, current rewards: -364.41624, mean: -0.79221
[32m[0906 18-49-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30062, current rewards: -414.41624, mean: -0.81258
[32m[0906 18-49-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30059, current rewards: -464.41624, mean: -0.82931
[32m[0906 18-50-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30066, current rewards: -514.41624, mean: -0.84331
[32m[0906 18-50-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30067, current rewards: -564.41624, mean: -0.85518
[32m[0906 18-50-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30068, current rewards: -614.41624, mean: -0.86537
[32m[0906 18-50-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30083, current rewards: -664.41624, mean: -0.87423
[32m[0906 18-51-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30103, current rewards: -714.41624, mean: -0.88200
[32m[0906 18-51-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30117, current rewards: -764.41624, mean: -0.88886
[32m[0906 18-51-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30132, current rewards: -814.41624, mean: -0.89496
[32m[0906 18-51-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30137, current rewards: -864.41624, mean: -0.90043
[32m[0906 18-52-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30136, current rewards: -914.41624, mean: -0.90536
[32m[0906 18-52-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30134, current rewards: -964.41624, mean: -0.90983
[32m[0906 18-52-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30133, current rewards: -1001.64768, mean: -0.90239
[32m[0906 18-52-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30127, current rewards: -998.44535, mean: -0.86073
[32m[0906 18-53-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30124, current rewards: -995.24303, mean: -0.82251
[32m[0906 18-53-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30121, current rewards: -992.04070, mean: -0.78733
[32m[0906 18-53-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30118, current rewards: -988.83837, mean: -0.75484
[32m[0906 18-53-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30129, current rewards: -985.63604, mean: -0.72473
[32m[0906 18-54-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30125, current rewards: -1023.93153, mean: -0.72619
[32m[0906 18-54-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30114, current rewards: -1073.93153, mean: -0.73557
[32m[0906 18-54-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30108, current rewards: -1123.93153, mean: -0.74433
[32m[0906 18-54-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30103, current rewards: -1173.93153, mean: -0.75252
[32m[0906 18-55-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30099, current rewards: -1223.93153, mean: -0.76021
[32m[0906 18-55-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30094, current rewards: -1273.93153, mean: -0.76743
[32m[0906 18-55-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30090, current rewards: -1323.93153, mean: -0.77423
[32m[0906 18-55-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30087, current rewards: -1373.93153, mean: -0.78064
[32m[0906 18-56-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30084, current rewards: -1423.93153, mean: -0.78670
[32m[0906 18-56-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30082, current rewards: -1473.93153, mean: -0.79244
[32m[0906 18-56-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30079, current rewards: -1523.93153, mean: -0.79787
[32m[0906 18-56-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30076, current rewards: -1573.93153, mean: -0.80303
[32m[0906 18-57-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30080, current rewards: -1623.93153, mean: -0.80793
[32m[0906 18-57-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30112, current rewards: -1673.93153, mean: -0.81259
[32m[0906 18-57-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30128, current rewards: -1723.93153, mean: -0.81703
[32m[0906 18-57-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30141, current rewards: -1773.93153, mean: -0.82126
[32m[0906 18-58-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30146, current rewards: -1823.93153, mean: -0.82531
[32m[0906 18-58-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30146, current rewards: -1873.93153, mean: -0.82917
[32m[0906 18-58-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30158, current rewards: -1923.93153, mean: -0.83287
[32m[0906 18-58-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30172, current rewards: -1973.93153, mean: -0.83641
[32m[0906 18-59-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30175, current rewards: -2023.93153, mean: -0.83981
[32m[0906 18-59-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30185, current rewards: -2073.93153, mean: -0.84306
[32m[0906 18-59-40 @Agent.py:117][0m Average action selection time: 0.3019
[32m[0906 18-59-40 @Agent.py:118][0m Rollout length: 2600
[32m[0906 18-59-40 @MBExp.py:227][0m Rewards obtained: [-2113.9315328343087], Lows: [0], Highs: [2137], Total time: 8726.543547
[32m[0906 18-59-50 @MBExp.py:144][0m ####################################################################
[32m[0906 18-59-50 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 18-59-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29522, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-00-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30431, current rewards: -60.00000, mean: -1.00000
[32m[0906 19-00-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30463, current rewards: -110.00000, mean: -1.00000
[32m[0906 19-00-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30441, current rewards: -160.00000, mean: -1.00000
[32m[0906 19-00-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30426, current rewards: -210.00000, mean: -1.00000
[32m[0906 19-01-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30411, current rewards: -260.00000, mean: -1.00000
[32m[0906 19-01-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30398, current rewards: -310.00000, mean: -1.00000
[32m[0906 19-01-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30367, current rewards: -342.18377, mean: -0.95051
[32m[0906 19-01-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30352, current rewards: -339.78310, mean: -0.82874
[32m[0906 19-02-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30339, current rewards: -337.38242, mean: -0.73344
[32m[0906 19-02-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30327, current rewards: -334.98174, mean: -0.65683
[32m[0906 19-02-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30311, current rewards: -332.58107, mean: -0.59389
[32m[0906 19-02-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30292, current rewards: -361.62080, mean: -0.59282
[32m[0906 19-03-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30302, current rewards: -411.62080, mean: -0.62367
[32m[0906 19-03-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30285, current rewards: -461.62080, mean: -0.65017
[32m[0906 19-03-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30277, current rewards: -511.62080, mean: -0.67319
[32m[0906 19-03-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30271, current rewards: -561.62080, mean: -0.69336
[32m[0906 19-04-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30267, current rewards: -611.62080, mean: -0.71119
[32m[0906 19-04-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30266, current rewards: -661.62080, mean: -0.72706
[32m[0906 19-04-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30257, current rewards: -711.62080, mean: -0.74127
[32m[0906 19-04-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30248, current rewards: -761.62080, mean: -0.75408
[32m[0906 19-05-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30267, current rewards: -811.62080, mean: -0.76568
[32m[0906 19-05-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30257, current rewards: -861.62080, mean: -0.77623
[32m[0906 19-05-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30251, current rewards: -911.62080, mean: -0.78588
[32m[0906 19-05-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30245, current rewards: -961.62080, mean: -0.79473
[32m[0906 19-06-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30239, current rewards: -1011.62080, mean: -0.80287
[32m[0906 19-06-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30229, current rewards: -1061.62080, mean: -0.81040
[32m[0906 19-06-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30218, current rewards: -1111.62080, mean: -0.81737
[32m[0906 19-06-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30214, current rewards: -1161.62080, mean: -0.82384
[32m[0906 19-07-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30212, current rewards: -1160.78519, mean: -0.79506
[32m[0906 19-07-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30209, current rewards: -1205.48535, mean: -0.79833
[32m[0906 19-07-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30203, current rewards: -1255.48535, mean: -0.80480
[32m[0906 19-07-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30193, current rewards: -1305.48535, mean: -0.81086
[32m[0906 19-08-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30188, current rewards: -1355.48535, mean: -0.81656
[32m[0906 19-08-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30184, current rewards: -1405.48535, mean: -0.82192
[32m[0906 19-08-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30181, current rewards: -1455.48535, mean: -0.82698
[32m[0906 19-08-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30179, current rewards: -1505.48535, mean: -0.83176
[32m[0906 19-09-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30179, current rewards: -1555.48535, mean: -0.83628
[32m[0906 19-09-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30174, current rewards: -1605.48535, mean: -0.84057
[32m[0906 19-09-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30170, current rewards: -1655.48535, mean: -0.84464
[32m[0906 19-09-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30168, current rewards: -1705.48535, mean: -0.84850
[32m[0906 19-10-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30165, current rewards: -1755.48535, mean: -0.85218
[32m[0906 19-10-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30163, current rewards: -1805.48535, mean: -0.85568
[32m[0906 19-10-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30163, current rewards: -1855.48535, mean: -0.85902
[32m[0906 19-10-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30162, current rewards: -1905.48535, mean: -0.86221
[32m[0906 19-11-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30164, current rewards: -1955.48535, mean: -0.86526
[32m[0906 19-11-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30163, current rewards: -2005.48535, mean: -0.86818
[32m[0906 19-11-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30160, current rewards: -2055.48535, mean: -0.87097
[32m[0906 19-11-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30156, current rewards: -2105.48535, mean: -0.87365
[32m[0906 19-12-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30158, current rewards: -2155.48535, mean: -0.87621
[32m[0906 19-12-24 @Agent.py:117][0m Average action selection time: 0.3016
[32m[0906 19-12-24 @Agent.py:118][0m Rollout length: 2600
[32m[0906 19-12-24 @MBExp.py:227][0m Rewards obtained: [-2195.485352412942], Lows: [0], Highs: [2210], Total time: 9480.93613
[32m[0906 19-12-35 @MBExp.py:144][0m ####################################################################
[32m[0906 19-12-35 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 19-12-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29849, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-12-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29979, current rewards: -60.00000, mean: -1.00000
[32m[0906 19-13-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30008, current rewards: -110.00000, mean: -1.00000
[32m[0906 19-13-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30047, current rewards: -160.00000, mean: -1.00000
[32m[0906 19-13-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30056, current rewards: -215.85078, mean: -1.02786
[32m[0906 19-13-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30064, current rewards: -281.34194, mean: -1.08208
[32m[0906 19-14-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30072, current rewards: -278.54198, mean: -0.89852
[32m[0906 19-14-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30092, current rewards: -274.57931, mean: -0.76272
[32m[0906 19-14-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30104, current rewards: -299.30493, mean: -0.73001
[32m[0906 19-14-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30099, current rewards: -318.21538, mean: -0.69177
[32m[0906 19-15-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30097, current rewards: -343.23891, mean: -0.67302
[32m[0906 19-15-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30104, current rewards: -389.66534, mean: -0.69583
[32m[0906 19-15-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30107, current rewards: -388.45387, mean: -0.63681
[32m[0906 19-15-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30098, current rewards: -383.20409, mean: -0.58061
[32m[0906 19-16-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30099, current rewards: -386.07771, mean: -0.54377
[32m[0906 19-16-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30103, current rewards: -383.69857, mean: -0.50487
[32m[0906 19-16-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30115, current rewards: -430.04653, mean: -0.53092
[32m[0906 19-16-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30130, current rewards: -423.50339, mean: -0.49245
[32m[0906 19-17-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30141, current rewards: -475.75102, mean: -0.52280
[32m[0906 19-17-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30151, current rewards: -466.64726, mean: -0.48609
[32m[0906 19-17-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30152, current rewards: -505.34673, mean: -0.50034
[32m[0906 19-17-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30143, current rewards: -500.00197, mean: -0.47170
[32m[0906 19-18-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30142, current rewards: -542.77539, mean: -0.48899
[32m[0906 19-18-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30141, current rewards: -630.01663, mean: -0.54312
[32m[0906 19-18-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30146, current rewards: -695.95076, mean: -0.57517
[32m[0906 19-18-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30151, current rewards: -783.37565, mean: -0.62173
[32m[0906 19-19-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30152, current rewards: -862.40754, mean: -0.65833
[32m[0906 19-19-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30150, current rewards: -859.25370, mean: -0.63180
[32m[0906 19-19-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30147, current rewards: -855.56390, mean: -0.60678
[32m[0906 19-19-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30143, current rewards: -850.15559, mean: -0.58230
[32m[0906 19-20-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30140, current rewards: -845.93296, mean: -0.56022
[32m[0906 19-20-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30138, current rewards: -842.04267, mean: -0.53977
[32m[0906 19-20-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30141, current rewards: -837.86070, mean: -0.52041
[32m[0906 19-20-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30143, current rewards: -833.68710, mean: -0.50222
[32m[0906 19-21-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30145, current rewards: -856.63381, mean: -0.50096
[32m[0906 19-21-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30151, current rewards: -956.63381, mean: -0.54354
[32m[0906 19-21-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30158, current rewards: -1056.63381, mean: -0.58378
[32m[0906 19-21-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30163, current rewards: -1156.63381, mean: -0.62185
[32m[0906 19-22-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30167, current rewards: -1236.07996, mean: -0.64716
[32m[0906 19-22-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30169, current rewards: -1333.82202, mean: -0.68052
[32m[0906 19-22-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30168, current rewards: -1420.33051, mean: -0.70663
[32m[0906 19-22-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30166, current rewards: -1516.15555, mean: -0.73600
[32m[0906 19-23-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30162, current rewards: -1613.25262, mean: -0.76457
[32m[0906 19-23-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30157, current rewards: -1713.25262, mean: -0.79317
[32m[0906 19-23-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30154, current rewards: -1813.25262, mean: -0.82048
[32m[0906 19-23-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30151, current rewards: -1881.78787, mean: -0.83265
[32m[0906 19-24-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30149, current rewards: -1931.24826, mean: -0.83604
[32m[0906 19-24-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30149, current rewards: -2031.24826, mean: -0.86070
[32m[0906 19-24-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30149, current rewards: -2076.79877, mean: -0.86174
[32m[0906 19-24-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30148, current rewards: -2160.58726, mean: -0.87829
[32m[0906 19-25-09 @Agent.py:117][0m Average action selection time: 0.3015
[32m[0906 19-25-09 @Agent.py:118][0m Rollout length: 2600
[32m[0906 19-25-09 @MBExp.py:227][0m Rewards obtained: [-2187.6635161378376], Lows: [1024], Highs: [291], Total time: 10235.070823
[32m[0906 19-25-19 @MBExp.py:144][0m ####################################################################
[32m[0906 19-25-19 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 19-25-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29832, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-25-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29872, current rewards: -60.00000, mean: -1.00000
[32m[0906 19-25-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29878, current rewards: -108.94478, mean: -0.99041
[32m[0906 19-26-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29941, current rewards: -158.94478, mean: -0.99340
[32m[0906 19-26-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29965, current rewards: -208.94478, mean: -0.99498
[32m[0906 19-26-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29995, current rewards: -258.94478, mean: -0.99594
[32m[0906 19-26-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30040, current rewards: -308.94478, mean: -0.99660
[32m[0906 19-27-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30074, current rewards: -358.94478, mean: -0.99707
[32m[0906 19-27-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30086, current rewards: -408.94478, mean: -0.99743
[32m[0906 19-27-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30106, current rewards: -458.94478, mean: -0.99771
[32m[0906 19-27-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30113, current rewards: -508.94478, mean: -0.99793
[32m[0906 19-28-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30110, current rewards: -558.94478, mean: -0.99812
[32m[0906 19-28-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30093, current rewards: -608.94478, mean: -0.99827
[32m[0906 19-28-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30099, current rewards: -658.94478, mean: -0.99840
[32m[0906 19-28-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30099, current rewards: -708.94478, mean: -0.99851
[32m[0906 19-29-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30103, current rewards: -758.94478, mean: -0.99861
[32m[0906 19-29-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30102, current rewards: -808.94478, mean: -0.99870
[32m[0906 19-29-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30100, current rewards: -858.94478, mean: -0.99877
[32m[0906 19-29-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30098, current rewards: -908.94478, mean: -0.99884
[32m[0906 19-30-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30100, current rewards: -958.94478, mean: -0.99890
[32m[0906 19-30-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30098, current rewards: -1008.94478, mean: -0.99896
[32m[0906 19-30-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30097, current rewards: -1058.94478, mean: -0.99900
[32m[0906 19-30-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30099, current rewards: -1086.13387, mean: -0.97850
[32m[0906 19-31-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30098, current rewards: -1081.82219, mean: -0.93261
[32m[0906 19-31-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30095, current rewards: -1077.51051, mean: -0.89050
[32m[0906 19-31-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30090, current rewards: -1073.19883, mean: -0.85175
[32m[0906 19-31-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30088, current rewards: -1068.88714, mean: -0.81594
[32m[0906 19-32-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30090, current rewards: -1115.62844, mean: -0.82032
[32m[0906 19-32-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30091, current rewards: -1165.62844, mean: -0.82669
[32m[0906 19-32-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30092, current rewards: -1215.62844, mean: -0.83262
[32m[0906 19-32-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30091, current rewards: -1265.62844, mean: -0.83816
[32m[0906 19-33-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30092, current rewards: -1315.62844, mean: -0.84335
[32m[0906 19-33-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30092, current rewards: -1365.62844, mean: -0.84822
[32m[0906 19-33-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30090, current rewards: -1415.62844, mean: -0.85279
[32m[0906 19-33-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30088, current rewards: -1465.62844, mean: -0.85709
[32m[0906 19-34-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30087, current rewards: -1515.62844, mean: -0.86115
[32m[0906 19-34-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30086, current rewards: -1565.62844, mean: -0.86499
[32m[0906 19-34-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30087, current rewards: -1615.62844, mean: -0.86862
[32m[0906 19-34-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30086, current rewards: -1665.62844, mean: -0.87206
[32m[0906 19-35-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30085, current rewards: -1715.62844, mean: -0.87532
[32m[0906 19-35-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30083, current rewards: -1765.62844, mean: -0.87842
[32m[0906 19-35-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30080, current rewards: -1815.62844, mean: -0.88137
[32m[0906 19-35-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30075, current rewards: -1865.62844, mean: -0.88418
[32m[0906 19-36-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30075, current rewards: -1915.62844, mean: -0.88687
[32m[0906 19-36-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30076, current rewards: -1965.62844, mean: -0.88942
[32m[0906 19-36-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30073, current rewards: -2015.62844, mean: -0.89187
[32m[0906 19-36-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30071, current rewards: -2065.62844, mean: -0.89421
[32m[0906 19-37-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30068, current rewards: -2115.62844, mean: -0.89645
[32m[0906 19-37-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30065, current rewards: -2165.62844, mean: -0.89860
[32m[0906 19-37-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30067, current rewards: -2215.62844, mean: -0.90066
[32m[0906 19-37-51 @Agent.py:117][0m Average action selection time: 0.3007
[32m[0906 19-37-51 @Agent.py:118][0m Rollout length: 2600
[32m[0906 19-37-51 @MBExp.py:227][0m Rewards obtained: [-2255.628443415454], Lows: [0], Highs: [2275], Total time: 10987.379008
[32m[0906 19-38-03 @MBExp.py:144][0m ####################################################################
[32m[0906 19-38-03 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 19-38-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30304, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-38-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30267, current rewards: -60.00000, mean: -1.00000
[32m[0906 19-38-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30327, current rewards: -110.00000, mean: -1.00000
[32m[0906 19-38-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30390, current rewards: -160.00000, mean: -1.00000
[32m[0906 19-39-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30480, current rewards: -210.00000, mean: -1.00000
[32m[0906 19-39-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30521, current rewards: -227.30592, mean: -0.87425
[32m[0906 19-39-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30559, current rewards: -223.64264, mean: -0.72143
[32m[0906 19-39-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30577, current rewards: -252.11802, mean: -0.70033
[32m[0906 19-40-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30574, current rewards: -277.95568, mean: -0.67794
[32m[0906 19-40-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30574, current rewards: -274.61819, mean: -0.59700
[32m[0906 19-40-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30576, current rewards: -294.54848, mean: -0.57755
[32m[0906 19-40-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30577, current rewards: -369.54848, mean: -0.65991
[32m[0906 19-41-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30574, current rewards: -469.54848, mean: -0.76975
[32m[0906 19-41-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30575, current rewards: -517.55534, mean: -0.78417
[32m[0906 19-41-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30584, current rewards: -514.12486, mean: -0.72412
[32m[0906 19-41-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30592, current rewards: -510.69441, mean: -0.67197
[32m[0906 19-42-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30599, current rewards: -507.26398, mean: -0.62625
[32m[0906 19-42-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30607, current rewards: -503.83355, mean: -0.58585
[32m[0906 19-42-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30617, current rewards: -498.01017, mean: -0.54726
[32m[0906 19-42-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30619, current rewards: -494.05864, mean: -0.51464
[32m[0906 19-43-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30627, current rewards: -491.63463, mean: -0.48677
[32m[0906 19-43-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30631, current rewards: -489.21062, mean: -0.46152
[32m[0906 19-43-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30632, current rewards: -486.78661, mean: -0.43855
[32m[0906 19-43-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30631, current rewards: -484.36260, mean: -0.41755
[32m[0906 19-44-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30627, current rewards: -481.93859, mean: -0.39830
[32m[0906 19-44-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30628, current rewards: -482.66002, mean: -0.38306
[32m[0906 19-44-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30630, current rewards: -532.66002, mean: -0.40661
[32m[0906 19-44-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30630, current rewards: -582.66002, mean: -0.42843
[32m[0906 19-45-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30623, current rewards: -632.66002, mean: -0.44870
[32m[0906 19-45-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30617, current rewards: -682.66002, mean: -0.46758
[32m[0906 19-45-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30608, current rewards: -732.66002, mean: -0.48521
[32m[0906 19-46-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30600, current rewards: -782.66002, mean: -0.50171
[32m[0906 19-46-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30593, current rewards: -832.66002, mean: -0.51718
[32m[0906 19-46-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30588, current rewards: -882.66002, mean: -0.53172
[32m[0906 19-46-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30583, current rewards: -932.66002, mean: -0.54542
[32m[0906 19-47-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30581, current rewards: -982.66002, mean: -0.55833
[32m[0906 19-47-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30580, current rewards: -1032.66002, mean: -0.57053
[32m[0906 19-47-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30578, current rewards: -1082.66002, mean: -0.58208
[32m[0906 19-47-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30580, current rewards: -1132.66002, mean: -0.59302
[32m[0906 19-48-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30582, current rewards: -1182.66002, mean: -0.60340
[32m[0906 19-48-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30584, current rewards: -1232.66002, mean: -0.61326
[32m[0906 19-48-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30582, current rewards: -1282.66002, mean: -0.62265
[32m[0906 19-48-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30583, current rewards: -1332.66002, mean: -0.63159
[32m[0906 19-49-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30583, current rewards: -1382.66002, mean: -0.64012
[32m[0906 19-49-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30581, current rewards: -1432.66002, mean: -0.64826
[32m[0906 19-49-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30581, current rewards: -1482.66002, mean: -0.65604
[32m[0906 19-49-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30579, current rewards: -1532.66002, mean: -0.66349
[32m[0906 19-50-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30579, current rewards: -1582.66002, mean: -0.67062
[32m[0906 19-50-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30578, current rewards: -1620.01878, mean: -0.67221
[32m[0906 19-50-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30576, current rewards: -1612.55859, mean: -0.65551
[32m[0906 19-50-47 @Agent.py:117][0m Average action selection time: 0.3058
[32m[0906 19-50-47 @Agent.py:118][0m Rollout length: 2600
[32m[0906 19-50-48 @MBExp.py:227][0m Rewards obtained: [-1606.5904351737643], Lows: [100], Highs: [1475], Total time: 11752.242395
[32m[0906 19-51-01 @MBExp.py:144][0m ####################################################################
[32m[0906 19-51-01 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 19-51-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30581, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-51-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30422, current rewards: -60.00000, mean: -1.00000
[32m[0906 19-51-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30425, current rewards: -110.00000, mean: -1.00000
[32m[0906 19-51-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30489, current rewards: -160.00000, mean: -1.00000
[32m[0906 19-52-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30533, current rewards: -210.00000, mean: -1.00000
[32m[0906 19-52-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30545, current rewards: -260.00000, mean: -1.00000
[32m[0906 19-52-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30563, current rewards: -310.00000, mean: -1.00000
[32m[0906 19-52-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30585, current rewards: -360.00000, mean: -1.00000
[32m[0906 19-53-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30588, current rewards: -410.00000, mean: -1.00000
[32m[0906 19-53-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30570, current rewards: -460.00000, mean: -1.00000
[32m[0906 19-53-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30555, current rewards: -510.00000, mean: -1.00000
[32m[0906 19-53-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30525, current rewards: -560.00000, mean: -1.00000
[32m[0906 19-54-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30500, current rewards: -610.00000, mean: -1.00000
[32m[0906 19-54-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30470, current rewards: -671.50282, mean: -1.01743
[32m[0906 19-54-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30446, current rewards: -771.50282, mean: -1.08662
[32m[0906 19-54-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30429, current rewards: -871.50282, mean: -1.14671
[32m[0906 19-55-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30410, current rewards: -971.50282, mean: -1.19939
[32m[0906 19-55-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30397, current rewards: -1071.50282, mean: -1.24593
[32m[0906 19-55-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30389, current rewards: -1171.50282, mean: -1.28737
[32m[0906 19-55-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30382, current rewards: -1224.40873, mean: -1.27543
[32m[0906 19-56-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30377, current rewards: -1217.83178, mean: -1.20577
[32m[0906 19-56-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30367, current rewards: -1209.56324, mean: -1.14110
[32m[0906 19-56-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30360, current rewards: -1198.03678, mean: -1.07931
[32m[0906 19-56-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30353, current rewards: -1181.98598, mean: -1.01895
[32m[0906 19-57-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30347, current rewards: -1206.43716, mean: -0.99706
[32m[0906 19-57-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30341, current rewards: -1230.60894, mean: -0.97667
[32m[0906 19-57-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30334, current rewards: -1238.22844, mean: -0.94521
[32m[0906 19-57-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30329, current rewards: -1228.00119, mean: -0.90294
[32m[0906 19-58-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30324, current rewards: -1239.52233, mean: -0.87909
[32m[0906 19-58-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30320, current rewards: -1232.52921, mean: -0.84420
[32m[0906 19-58-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30315, current rewards: -1262.07147, mean: -0.83581
[32m[0906 19-58-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30311, current rewards: -1253.52245, mean: -0.80354
[32m[0906 19-59-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30307, current rewards: -1322.79259, mean: -0.82161
[32m[0906 19-59-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30303, current rewards: -1422.79259, mean: -0.85710
[32m[0906 19-59-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30298, current rewards: -1503.79259, mean: -0.87941
[32m[0906 19-59-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30293, current rewards: -1542.66027, mean: -0.87651
[32m[0906 20-00-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30289, current rewards: -1584.75345, mean: -0.87555
[32m[0906 20-00-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30286, current rewards: -1634.75345, mean: -0.87890
[32m[0906 20-00-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30285, current rewards: -1728.42751, mean: -0.90494
[32m[0906 20-00-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30281, current rewards: -1751.83808, mean: -0.89379
[32m[0906 20-01-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30279, current rewards: -1771.24373, mean: -0.88122
[32m[0906 20-01-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30276, current rewards: -1766.04852, mean: -0.85731
[32m[0906 20-01-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30272, current rewards: -1775.04960, mean: -0.84126
[32m[0906 20-01-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30270, current rewards: -1770.78215, mean: -0.81981
[32m[0906 20-02-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30269, current rewards: -1768.10110, mean: -0.80005
[32m[0906 20-02-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30266, current rewards: -1770.09458, mean: -0.78323
[32m[0906 20-02-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30265, current rewards: -1767.35278, mean: -0.76509
[32m[0906 20-02-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30263, current rewards: -1773.19433, mean: -0.75135
[32m[0906 20-03-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30262, current rewards: -1768.09378, mean: -0.73365
[32m[0906 20-03-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30261, current rewards: -1804.30949, mean: -0.73346
[32m[0906 20-03-38 @Agent.py:117][0m Average action selection time: 0.3026
[32m[0906 20-03-38 @Agent.py:118][0m Rollout length: 2600
[32m[0906 20-03-38 @MBExp.py:227][0m Rewards obtained: [-1844.3094853269893], Lows: [615], Highs: [810], Total time: 12509.091563999998
[32m[0906 20-03-51 @MBExp.py:144][0m ####################################################################
[32m[0906 20-03-51 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 20-03-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29872, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-04-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29971, current rewards: -60.00000, mean: -1.00000
[32m[0906 20-04-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30020, current rewards: -120.00000, mean: -1.09091
[32m[0906 20-04-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30042, current rewards: -211.69942, mean: -1.32312
[32m[0906 20-04-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30071, current rewards: -213.37196, mean: -1.01606
[32m[0906 20-05-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30096, current rewards: -313.37196, mean: -1.20528
[32m[0906 20-05-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30111, current rewards: -413.37196, mean: -1.33346
[32m[0906 20-05-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30120, current rewards: -486.36963, mean: -1.35103
[32m[0906 20-05-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30122, current rewards: -483.20909, mean: -1.17856
[32m[0906 20-06-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30120, current rewards: -479.44779, mean: -1.04228
[32m[0906 20-06-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30120, current rewards: -476.40322, mean: -0.93412
[32m[0906 20-06-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30123, current rewards: -473.13307, mean: -0.84488
[32m[0906 20-06-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30124, current rewards: -469.86169, mean: -0.77027
[32m[0906 20-07-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30130, current rewards: -466.51017, mean: -0.70683
[32m[0906 20-07-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30136, current rewards: -463.09905, mean: -0.65225
[32m[0906 20-07-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30140, current rewards: -459.65162, mean: -0.60480
[32m[0906 20-07-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30144, current rewards: -460.44545, mean: -0.56845
[32m[0906 20-08-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30150, current rewards: -510.44545, mean: -0.59354
[32m[0906 20-08-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30154, current rewards: -557.21404, mean: -0.61232
[32m[0906 20-08-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30154, current rewards: -607.21404, mean: -0.63251
[32m[0906 20-08-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30156, current rewards: -657.21404, mean: -0.65071
[32m[0906 20-09-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30196, current rewards: -695.64547, mean: -0.65627
[32m[0906 20-09-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30294, current rewards: -736.19777, mean: -0.66324
[32m[0906 20-09-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30383, current rewards: -744.07676, mean: -0.64145
[32m[0906 20-09-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30465, current rewards: -769.84726, mean: -0.63624
[32m[0906 20-10-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30540, current rewards: -811.44675, mean: -0.64401
[32m[0906 20-10-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30611, current rewards: -860.39432, mean: -0.65679
[32m[0906 20-10-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30676, current rewards: -910.39432, mean: -0.66941
[32m[0906 20-11-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30736, current rewards: -960.39432, mean: -0.68113
[32m[0906 20-11-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30792, current rewards: -1010.39432, mean: -0.69205
[32m[0906 20-11-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30844, current rewards: -1060.39432, mean: -0.70225
[32m[0906 20-11-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30891, current rewards: -1110.39432, mean: -0.71179
[32m[0906 20-12-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30936, current rewards: -1160.39432, mean: -0.72074
[32m[0906 20-12-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30978, current rewards: -1210.39432, mean: -0.72915
[32m[0906 20-12-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31018, current rewards: -1260.39432, mean: -0.73707
[32m[0906 20-12-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31056, current rewards: -1282.18891, mean: -0.72852
[32m[0906 20-13-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31092, current rewards: -1272.22602, mean: -0.70289
[32m[0906 20-13-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31126, current rewards: -1303.68898, mean: -0.70091
[32m[0906 20-13-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31159, current rewards: -1306.05719, mean: -0.68380
[32m[0906 20-14-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31189, current rewards: -1309.32486, mean: -0.66802
[32m[0906 20-14-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31217, current rewards: -1320.14397, mean: -0.65679
[32m[0906 20-14-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31247, current rewards: -1337.82675, mean: -0.64943
[32m[0906 20-14-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31272, current rewards: -1350.98080, mean: -0.64028
[32m[0906 20-15-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31298, current rewards: -1372.42235, mean: -0.63538
[32m[0906 20-15-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31321, current rewards: -1382.98624, mean: -0.62579
[32m[0906 20-15-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31343, current rewards: -1403.10273, mean: -0.62084
[32m[0906 20-15-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31364, current rewards: -1427.16331, mean: -0.61782
[32m[0906 20-16-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31384, current rewards: -1427.02388, mean: -0.60467
[32m[0906 20-16-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31404, current rewards: -1451.03723, mean: -0.60209
[32m[0906 20-16-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31425, current rewards: -1551.03723, mean: -0.63050
[32m[0906 20-16-57 @Agent.py:117][0m Average action selection time: 0.3144
[32m[0906 20-16-57 @Agent.py:118][0m Rollout length: 2600
[32m[0906 20-16-57 @MBExp.py:227][0m Rewards obtained: [-1631.0372300634695], Lows: [309], Highs: [1122], Total time: 13295.423791
[32m[0906 20-17-12 @MBExp.py:144][0m ####################################################################
[32m[0906 20-17-12 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 20-17-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34256, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-17-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32507, current rewards: -60.00000, mean: -1.00000
[32m[0906 20-17-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32387, current rewards: -100.79196, mean: -0.91629
[32m[0906 20-18-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32333, current rewards: -95.36021, mean: -0.59600
[32m[0906 20-18-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32330, current rewards: -90.55625, mean: -0.43122
[32m[0906 20-18-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32326, current rewards: -85.65330, mean: -0.32944
[32m[0906 20-18-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32326, current rewards: -81.93082, mean: -0.26429
[32m[0906 20-19-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32325, current rewards: -79.00587, mean: -0.21946
[32m[0906 20-19-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32338, current rewards: -75.12012, mean: -0.18322
[32m[0906 20-19-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32343, current rewards: -99.55088, mean: -0.21641
[32m[0906 20-19-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32348, current rewards: -149.55088, mean: -0.29324
[32m[0906 20-20-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32349, current rewards: -199.55088, mean: -0.35634
[32m[0906 20-20-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32348, current rewards: -249.55088, mean: -0.40910
[32m[0906 20-20-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32348, current rewards: -299.55088, mean: -0.45386
[32m[0906 20-21-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32349, current rewards: -349.55088, mean: -0.49233
[32m[0906 20-21-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32350, current rewards: -399.55088, mean: -0.52572
[32m[0906 20-21-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32350, current rewards: -449.55088, mean: -0.55500
[32m[0906 20-21-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32350, current rewards: -499.55088, mean: -0.58087
[32m[0906 20-22-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32351, current rewards: -549.55088, mean: -0.60390
[32m[0906 20-22-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32350, current rewards: -599.55088, mean: -0.62453
[32m[0906 20-22-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32351, current rewards: -649.55088, mean: -0.64312
[32m[0906 20-22-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32352, current rewards: -699.55088, mean: -0.65995
[32m[0906 20-23-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32353, current rewards: -749.55088, mean: -0.67527
[32m[0906 20-23-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32353, current rewards: -799.55088, mean: -0.68927
[32m[0906 20-23-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32351, current rewards: -849.55088, mean: -0.70211
[32m[0906 20-23-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32351, current rewards: -899.55088, mean: -0.71393
[32m[0906 20-24-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32349, current rewards: -949.55088, mean: -0.72485
[32m[0906 20-24-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32349, current rewards: -999.55088, mean: -0.73496
[32m[0906 20-24-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32349, current rewards: -1049.55088, mean: -0.74436
[32m[0906 20-25-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32348, current rewards: -1099.55088, mean: -0.75312
[32m[0906 20-25-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32346, current rewards: -1149.55088, mean: -0.76129
[32m[0906 20-25-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32347, current rewards: -1199.55088, mean: -0.76894
[32m[0906 20-25-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32347, current rewards: -1249.55088, mean: -0.77612
[32m[0906 20-26-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32348, current rewards: -1299.55088, mean: -0.78286
[32m[0906 20-26-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32348, current rewards: -1349.55088, mean: -0.78921
[32m[0906 20-26-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32347, current rewards: -1399.55088, mean: -0.79520
[32m[0906 20-26-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32346, current rewards: -1449.55088, mean: -0.80086
[32m[0906 20-27-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32345, current rewards: -1499.55088, mean: -0.80621
[32m[0906 20-27-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32344, current rewards: -1549.55088, mean: -0.81128
[32m[0906 20-27-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32345, current rewards: -1599.55088, mean: -0.81610
[32m[0906 20-28-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32346, current rewards: -1649.55088, mean: -0.82067
[32m[0906 20-28-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32346, current rewards: -1699.55088, mean: -0.82502
[32m[0906 20-28-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32347, current rewards: -1749.55088, mean: -0.82917
[32m[0906 20-28-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32346, current rewards: -1799.55088, mean: -0.83313
[32m[0906 20-29-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32346, current rewards: -1849.55088, mean: -0.83690
[32m[0906 20-29-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32346, current rewards: -1899.55088, mean: -0.84051
[32m[0906 20-29-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32346, current rewards: -1949.55088, mean: -0.84396
[32m[0906 20-29-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32346, current rewards: -1999.55088, mean: -0.84727
[32m[0906 20-30-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32347, current rewards: -2049.55088, mean: -0.85044
[32m[0906 20-30-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32346, current rewards: -2099.55088, mean: -0.85348
[32m[0906 20-30-41 @Agent.py:117][0m Average action selection time: 0.3235
[32m[0906 20-30-41 @Agent.py:118][0m Rollout length: 2600
[32m[0906 20-30-41 @MBExp.py:227][0m Rewards obtained: [-2139.5508761150936], Lows: [1], Highs: [2166], Total time: 14104.402979999999
[32m[0906 20-30-56 @MBExp.py:144][0m ####################################################################
[32m[0906 20-30-56 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 20-30-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32032, current rewards: -3.70628, mean: -0.37063
[32m[0906 20-31-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32073, current rewards: -1.25857, mean: -0.02098
[32m[0906 20-31-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32144, current rewards: 1.19175, mean: 0.01083
[32m[0906 20-31-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32197, current rewards: 3.95636, mean: 0.02473
[32m[0906 20-32-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32208, current rewards: 6.70322, mean: 0.03192
[32m[0906 20-32-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32233, current rewards: 9.53090, mean: 0.03666
[32m[0906 20-32-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32252, current rewards: 12.44078, mean: 0.04013
[32m[0906 20-32-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32261, current rewards: 14.90656, mean: 0.04141
[32m[0906 20-33-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32269, current rewards: 17.35059, mean: 0.04232
[32m[0906 20-33-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32284, current rewards: -30.55132, mean: -0.06642
[32m[0906 20-33-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32287, current rewards: -80.55132, mean: -0.15794
[32m[0906 20-33-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32299, current rewards: -130.55132, mean: -0.23313
[32m[0906 20-34-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32302, current rewards: -180.55132, mean: -0.29599
[32m[0906 20-34-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32308, current rewards: -230.55132, mean: -0.34932
[32m[0906 20-34-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32312, current rewards: -280.55132, mean: -0.39514
[32m[0906 20-35-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32314, current rewards: -330.55132, mean: -0.43494
[32m[0906 20-35-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32314, current rewards: -380.55132, mean: -0.46982
[32m[0906 20-35-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32316, current rewards: -430.55132, mean: -0.50064
[32m[0906 20-35-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32316, current rewards: -470.71533, mean: -0.51727
[32m[0906 20-36-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32316, current rewards: -466.66642, mean: -0.48611
[32m[0906 20-36-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32318, current rewards: -462.71594, mean: -0.45813
[32m[0906 20-36-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32318, current rewards: -459.23661, mean: -0.43324
[32m[0906 20-36-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32320, current rewards: -455.75728, mean: -0.41059
[32m[0906 20-37-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32319, current rewards: -452.37253, mean: -0.38998
[32m[0906 20-37-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32318, current rewards: -449.03651, mean: -0.37110
[32m[0906 20-37-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32318, current rewards: -445.70048, mean: -0.35373
[32m[0906 20-37-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32318, current rewards: -442.36446, mean: -0.33768
[32m[0906 20-38-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32318, current rewards: -483.83070, mean: -0.35576
[32m[0906 20-38-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32320, current rewards: -533.83070, mean: -0.37860
[32m[0906 20-38-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32321, current rewards: -583.83070, mean: -0.39988
[32m[0906 20-39-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32320, current rewards: -633.83070, mean: -0.41976
[32m[0906 20-39-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32321, current rewards: -683.83070, mean: -0.43835
[32m[0906 20-39-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32321, current rewards: -733.83070, mean: -0.45580
[32m[0906 20-39-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32319, current rewards: -783.83070, mean: -0.47219
[32m[0906 20-40-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32320, current rewards: -833.83070, mean: -0.48762
[32m[0906 20-40-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32320, current rewards: -883.83070, mean: -0.50218
[32m[0906 20-40-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32320, current rewards: -933.83070, mean: -0.51593
[32m[0906 20-40-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32320, current rewards: -983.83070, mean: -0.52894
[32m[0906 20-41-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32321, current rewards: -1033.83070, mean: -0.54127
[32m[0906 20-41-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32321, current rewards: -1083.83070, mean: -0.55297
[32m[0906 20-41-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32322, current rewards: -1133.83070, mean: -0.56409
[32m[0906 20-42-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32323, current rewards: -1183.83070, mean: -0.57468
[32m[0906 20-42-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32322, current rewards: -1233.83070, mean: -0.58475
[32m[0906 20-42-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32324, current rewards: -1283.83070, mean: -0.59437
[32m[0906 20-42-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32325, current rewards: -1325.16304, mean: -0.59962
[32m[0906 20-43-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32324, current rewards: -1320.99021, mean: -0.58451
[32m[0906 20-43-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32324, current rewards: -1316.81737, mean: -0.57005
[32m[0906 20-43-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32324, current rewards: -1312.46193, mean: -0.55613
[32m[0906 20-43-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32324, current rewards: -1307.31628, mean: -0.54245
[32m[0906 20-44-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32324, current rewards: -1302.17063, mean: -0.52934
[32m[0906 20-44-24 @Agent.py:117][0m Average action selection time: 0.3232
[32m[0906 20-44-24 @Agent.py:118][0m Rollout length: 2600
[32m[0906 20-44-24 @MBExp.py:227][0m Rewards obtained: [-1298.0541123170465], Lows: [0], Highs: [1377], Total time: 14912.843394
[32m[0906 20-44-41 @MBExp.py:144][0m ####################################################################
[32m[0906 20-44-41 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 20-44-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32029, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-45-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32137, current rewards: -60.00000, mean: -1.00000
[32m[0906 20-45-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32176, current rewards: -120.00000, mean: -1.09091
[32m[0906 20-45-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32185, current rewards: -220.00000, mean: -1.37500
[32m[0906 20-45-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32211, current rewards: -320.00000, mean: -1.52381
[32m[0906 20-46-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32320, current rewards: -420.00000, mean: -1.61538
[32m[0906 20-46-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32316, current rewards: -517.79074, mean: -1.67029
[32m[0906 20-46-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32323, current rewards: -512.54422, mean: -1.42373
[32m[0906 20-46-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32321, current rewards: -612.54422, mean: -1.49401
[32m[0906 20-47-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32323, current rewards: -712.54422, mean: -1.54901
[32m[0906 20-47-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32327, current rewards: -812.54422, mean: -1.59322
[32m[0906 20-47-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32322, current rewards: -912.54422, mean: -1.62954
[32m[0906 20-47-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32324, current rewards: -1012.54422, mean: -1.65991
[32m[0906 20-48-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32329, current rewards: -1112.54422, mean: -1.68567
[32m[0906 20-48-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32326, current rewards: -1212.54422, mean: -1.70781
[32m[0906 20-48-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32329, current rewards: -1312.54422, mean: -1.72703
[32m[0906 20-49-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32330, current rewards: -1412.54422, mean: -1.74388
[32m[0906 20-49-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32329, current rewards: -1512.54422, mean: -1.75877
[32m[0906 20-49-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32328, current rewards: -1612.54422, mean: -1.77203
[32m[0906 20-49-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32329, current rewards: -1712.54422, mean: -1.78390
[32m[0906 20-50-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32331, current rewards: -1812.54422, mean: -1.79460
[32m[0906 20-50-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32334, current rewards: -1912.54422, mean: -1.80429
[32m[0906 20-50-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32336, current rewards: -2012.54422, mean: -1.81310
[32m[0906 20-50-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32338, current rewards: -2112.54422, mean: -1.82116
[32m[0906 20-51-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32339, current rewards: -2212.54422, mean: -1.82855
[32m[0906 20-51-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32338, current rewards: -2312.54422, mean: -1.83535
[32m[0906 20-51-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32338, current rewards: -2412.54422, mean: -1.84164
[32m[0906 20-52-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32337, current rewards: -2512.54422, mean: -1.84746
[32m[0906 20-52-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32336, current rewards: -2612.54422, mean: -1.85287
[32m[0906 20-52-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32335, current rewards: -2712.54422, mean: -1.85791
[32m[0906 20-52-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32336, current rewards: -2812.54422, mean: -1.86261
[32m[0906 20-53-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32335, current rewards: -2912.54422, mean: -1.86702
[32m[0906 20-53-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32336, current rewards: -3012.54422, mean: -1.87115
[32m[0906 20-53-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32337, current rewards: -3112.54422, mean: -1.87503
[32m[0906 20-53-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32338, current rewards: -3212.54422, mean: -1.87868
[32m[0906 20-54-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32338, current rewards: -3312.54422, mean: -1.88213
[32m[0906 20-54-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32337, current rewards: -3412.54422, mean: -1.88538
[32m[0906 20-54-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32339, current rewards: -3512.54422, mean: -1.88846
[32m[0906 20-54-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32340, current rewards: -3612.54422, mean: -1.89138
[32m[0906 20-55-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32340, current rewards: -3712.54422, mean: -1.89416
[32m[0906 20-55-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32341, current rewards: -3812.54422, mean: -1.89679
[32m[0906 20-55-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32341, current rewards: -3912.54422, mean: -1.89929
[32m[0906 20-56-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32341, current rewards: -4012.54422, mean: -1.90168
[32m[0906 20-56-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32341, current rewards: -4112.54422, mean: -1.90396
[32m[0906 20-56-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32341, current rewards: -4212.54422, mean: -1.90613
[32m[0906 20-56-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32341, current rewards: -4312.54422, mean: -1.90821
[32m[0906 20-57-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32341, current rewards: -4412.54422, mean: -1.91019
[32m[0906 20-57-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32342, current rewards: -4512.54422, mean: -1.91210
[32m[0906 20-57-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32343, current rewards: -4612.54422, mean: -1.91392
[32m[0906 20-57-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32343, current rewards: -4712.54422, mean: -1.91567
[32m[0906 20-58-10 @Agent.py:117][0m Average action selection time: 0.3234
[32m[0906 20-58-10 @Agent.py:118][0m Rollout length: 2600
[32m[0906 20-58-10 @MBExp.py:227][0m Rewards obtained: [-4792.544224072907], Lows: [2350], Highs: [100], Total time: 15721.755501
[32m[0906 20-58-27 @MBExp.py:144][0m ####################################################################
[32m[0906 20-58-27 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 20-58-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34004, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-58-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32399, current rewards: -60.00000, mean: -1.00000
[32m[0906 20-59-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32328, current rewards: -119.00000, mean: -1.08182
[32m[0906 20-59-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32289, current rewards: -144.19776, mean: -0.90124
[32m[0906 20-59-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32282, current rewards: -176.25087, mean: -0.83929
[32m[0906 20-59-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32294, current rewards: -226.25087, mean: -0.87020
[32m[0906 21-00-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32300, current rewards: -276.25087, mean: -0.89113
[32m[0906 21-00-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32307, current rewards: -326.25087, mean: -0.90625
[32m[0906 21-00-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32314, current rewards: -376.25087, mean: -0.91769
[32m[0906 21-00-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32323, current rewards: -426.25087, mean: -0.92663
[32m[0906 21-01-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32329, current rewards: -476.25087, mean: -0.93383
[32m[0906 21-01-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32338, current rewards: -526.25087, mean: -0.93973
[32m[0906 21-01-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32338, current rewards: -576.25087, mean: -0.94467
[32m[0906 21-02-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32339, current rewards: -626.25087, mean: -0.94886
[32m[0906 21-02-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32338, current rewards: -676.25087, mean: -0.95247
[32m[0906 21-02-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32339, current rewards: -726.25087, mean: -0.95559
[32m[0906 21-02-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32341, current rewards: -776.25087, mean: -0.95833
[32m[0906 21-03-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32342, current rewards: -826.25087, mean: -0.96076
[32m[0906 21-03-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32341, current rewards: -876.25087, mean: -0.96291
[32m[0906 21-03-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32342, current rewards: -926.25087, mean: -0.96484
[32m[0906 21-03-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32345, current rewards: -976.25087, mean: -0.96659
[32m[0906 21-04-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32344, current rewards: -1026.25087, mean: -0.96816
[32m[0906 21-04-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32343, current rewards: -1076.25087, mean: -0.96960
[32m[0906 21-04-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32342, current rewards: -1126.25087, mean: -0.97091
[32m[0906 21-04-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32341, current rewards: -1176.25087, mean: -0.97211
[32m[0906 21-05-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32341, current rewards: -1226.25087, mean: -0.97321
[32m[0906 21-05-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32341, current rewards: -1276.25087, mean: -0.97424
[32m[0906 21-05-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32343, current rewards: -1326.25087, mean: -0.97518
[32m[0906 21-06-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32342, current rewards: -1376.25087, mean: -0.97606
[32m[0906 21-06-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32341, current rewards: -1422.03556, mean: -0.97400
[32m[0906 21-06-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32339, current rewards: -1417.21791, mean: -0.93855
[32m[0906 21-06-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32341, current rewards: -1473.30578, mean: -0.94443
[32m[0906 21-07-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32340, current rewards: -1573.30578, mean: -0.97721
[32m[0906 21-07-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32340, current rewards: -1641.09922, mean: -0.98861
[32m[0906 21-07-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32340, current rewards: -1643.41315, mean: -0.96106
[32m[0906 21-07-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32340, current rewards: -1671.74432, mean: -0.94985
[32m[0906 21-08-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32340, current rewards: -1721.74432, mean: -0.95124
[32m[0906 21-08-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32341, current rewards: -1771.74432, mean: -0.95255
[32m[0906 21-08-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32340, current rewards: -1821.74432, mean: -0.95379
[32m[0906 21-09-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32340, current rewards: -1871.74432, mean: -0.95497
[32m[0906 21-09-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32339, current rewards: -1921.74432, mean: -0.95609
[32m[0906 21-09-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32341, current rewards: -1971.74432, mean: -0.95716
[32m[0906 21-09-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32342, current rewards: -2021.74432, mean: -0.95817
[32m[0906 21-10-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32341, current rewards: -2116.74432, mean: -0.97997
[32m[0906 21-10-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32340, current rewards: -2216.74432, mean: -1.00305
[32m[0906 21-10-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32339, current rewards: -2253.18367, mean: -0.99698
[32m[0906 21-10-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32340, current rewards: -2303.18367, mean: -0.99705
[32m[0906 21-11-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32340, current rewards: -2323.00028, mean: -0.98432
[32m[0906 21-11-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32339, current rewards: -2343.69000, mean: -0.97249
[32m[0906 21-11-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32339, current rewards: -2368.47280, mean: -0.96279
[32m[0906 21-11-56 @Agent.py:117][0m Average action selection time: 0.3234
[32m[0906 21-11-56 @Agent.py:118][0m Rollout length: 2600
[32m[0906 21-11-56 @MBExp.py:227][0m Rewards obtained: [-2363.435140552909], Lows: [225], Highs: [1955], Total time: 16530.543983
[32m[0906 21-12-14 @MBExp.py:144][0m ####################################################################
[32m[0906 21-12-14 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 21-12-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32081, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-12-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32120, current rewards: -60.00000, mean: -1.00000
[32m[0906 21-12-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32159, current rewards: -98.80273, mean: -0.89821
[32m[0906 21-13-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32177, current rewards: -97.84314, mean: -0.61152
[32m[0906 21-13-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32185, current rewards: -112.03449, mean: -0.53350
[32m[0906 21-13-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32215, current rewards: -102.67190, mean: -0.39489
[32m[0906 21-13-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32235, current rewards: -97.51016, mean: -0.31455
[32m[0906 21-14-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32249, current rewards: -91.47761, mean: -0.25410
[32m[0906 21-14-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32261, current rewards: -113.06168, mean: -0.27576
[32m[0906 21-14-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32271, current rewards: -213.06168, mean: -0.46318
[32m[0906 21-14-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32278, current rewards: -313.06168, mean: -0.61385
[32m[0906 21-15-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32283, current rewards: -413.06168, mean: -0.73761
[32m[0906 21-15-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32293, current rewards: -513.06168, mean: -0.84108
[32m[0906 21-15-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32298, current rewards: -535.69719, mean: -0.81166
[32m[0906 21-16-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32301, current rewards: -585.69719, mean: -0.82493
[32m[0906 21-16-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32307, current rewards: -634.21438, mean: -0.83449
[32m[0906 21-16-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32306, current rewards: -627.17358, mean: -0.77429
[32m[0906 21-16-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32309, current rewards: -643.60180, mean: -0.74837
[32m[0906 21-17-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32314, current rewards: -743.60180, mean: -0.81714
[32m[0906 21-17-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32317, current rewards: -783.19917, mean: -0.81583
[32m[0906 21-17-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32317, current rewards: -778.32465, mean: -0.77062
[32m[0906 21-17-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32318, current rewards: -825.09329, mean: -0.77839
[32m[0906 21-18-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32317, current rewards: -925.09329, mean: -0.83342
[32m[0906 21-18-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32317, current rewards: -942.25905, mean: -0.81229
[32m[0906 21-18-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32318, current rewards: -963.52371, mean: -0.79630
[32m[0906 21-19-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32318, current rewards: -1057.36683, mean: -0.83918
[32m[0906 21-19-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32317, current rewards: -1157.36683, mean: -0.88349
[32m[0906 21-19-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32319, current rewards: -1204.78224, mean: -0.88587
[32m[0906 21-19-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32320, current rewards: -1257.49217, mean: -0.89184
[32m[0906 21-20-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32320, current rewards: -1282.39404, mean: -0.87835
[32m[0906 21-20-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32320, current rewards: -1333.11552, mean: -0.88286
[32m[0906 21-20-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32320, current rewards: -1413.48280, mean: -0.90608
[32m[0906 21-20-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32321, current rewards: -1513.48280, mean: -0.94005
[32m[0906 21-21-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32320, current rewards: -1581.98003, mean: -0.95300
[32m[0906 21-21-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32322, current rewards: -1578.16912, mean: -0.92291
[32m[0906 21-21-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32323, current rewards: -1589.57546, mean: -0.90317
[32m[0906 21-21-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32325, current rewards: -1622.54008, mean: -0.89643
[32m[0906 21-22-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32326, current rewards: -1663.18136, mean: -0.89418
[32m[0906 21-22-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32328, current rewards: -1708.14314, mean: -0.89432
[32m[0906 21-22-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32328, current rewards: -1781.91089, mean: -0.90914
[32m[0906 21-23-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32328, current rewards: -1881.91089, mean: -0.93627
[32m[0906 21-23-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32329, current rewards: -1981.91089, mean: -0.96209
[32m[0906 21-23-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32328, current rewards: -2081.91089, mean: -0.98669
[32m[0906 21-23-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32328, current rewards: -2181.91089, mean: -1.01014
[32m[0906 21-24-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32329, current rewards: -2281.91089, mean: -1.03254
[32m[0906 21-24-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32329, current rewards: -2381.91089, mean: -1.05394
[32m[0906 21-24-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32330, current rewards: -2481.91089, mean: -1.07442
[32m[0906 21-24-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32330, current rewards: -2581.91089, mean: -1.09403
[32m[0906 21-25-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32330, current rewards: -2681.91089, mean: -1.11283
[32m[0906 21-25-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32330, current rewards: -2781.91089, mean: -1.13086
[32m[0906 21-25-43 @Agent.py:117][0m Average action selection time: 0.3233
[32m[0906 21-25-43 @Agent.py:118][0m Rollout length: 2600
[32m[0906 21-25-43 @MBExp.py:227][0m Rewards obtained: [-2861.910886833495], Lows: [1315], Highs: [362], Total time: 17339.107707
[32m[0906 21-26-02 @MBExp.py:144][0m ####################################################################
[32m[0906 21-26-02 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 21-26-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31988, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-26-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32102, current rewards: -60.00000, mean: -1.00000
[32m[0906 21-26-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32127, current rewards: -120.00000, mean: -1.09091
[32m[0906 21-26-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32155, current rewards: -220.00000, mean: -1.37500
[32m[0906 21-27-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32176, current rewards: -320.00000, mean: -1.52381
[32m[0906 21-27-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32196, current rewards: -420.00000, mean: -1.61538
[32m[0906 21-27-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32230, current rewards: -520.00000, mean: -1.67742
[32m[0906 21-27-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32255, current rewards: -620.00000, mean: -1.72222
[32m[0906 21-28-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32279, current rewards: -720.00000, mean: -1.75610
[32m[0906 21-28-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32286, current rewards: -820.00000, mean: -1.78261
[32m[0906 21-28-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32300, current rewards: -920.00000, mean: -1.80392
[32m[0906 21-29-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32302, current rewards: -1020.00000, mean: -1.82143
[32m[0906 21-29-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32307, current rewards: -1120.00000, mean: -1.83607
[32m[0906 21-29-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32307, current rewards: -1220.00000, mean: -1.84848
[32m[0906 21-29-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32308, current rewards: -1320.00000, mean: -1.85915
[32m[0906 21-30-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32311, current rewards: -1420.00000, mean: -1.86842
[32m[0906 21-30-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32314, current rewards: -1520.00000, mean: -1.87654
[32m[0906 21-30-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32317, current rewards: -1620.00000, mean: -1.88372
[32m[0906 21-30-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32317, current rewards: -1720.00000, mean: -1.89011
[32m[0906 21-31-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32317, current rewards: -1820.00000, mean: -1.89583
[32m[0906 21-31-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32319, current rewards: -1920.00000, mean: -1.90099
[32m[0906 21-31-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32320, current rewards: -2020.00000, mean: -1.90566
[32m[0906 21-32-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32320, current rewards: -2120.00000, mean: -1.90991
[32m[0906 21-32-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32320, current rewards: -2220.00000, mean: -1.91379
[32m[0906 21-32-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32322, current rewards: -2320.00000, mean: -1.91736
[32m[0906 21-32-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32322, current rewards: -2420.00000, mean: -1.92063
[32m[0906 21-33-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32321, current rewards: -2520.00000, mean: -1.92366
[32m[0906 21-33-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32321, current rewards: -2620.00000, mean: -1.92647
[32m[0906 21-33-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32321, current rewards: -2720.00000, mean: -1.92908
[32m[0906 21-33-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32321, current rewards: -2820.00000, mean: -1.93151
[32m[0906 21-34-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32321, current rewards: -2920.00000, mean: -1.93377
[32m[0906 21-34-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32320, current rewards: -3020.00000, mean: -1.93590
[32m[0906 21-34-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32320, current rewards: -3120.00000, mean: -1.93789
[32m[0906 21-34-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32320, current rewards: -3220.00000, mean: -1.93976
[32m[0906 21-35-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32320, current rewards: -3320.00000, mean: -1.94152
[32m[0906 21-35-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32321, current rewards: -3420.00000, mean: -1.94318
[32m[0906 21-35-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32322, current rewards: -3520.00000, mean: -1.94475
[32m[0906 21-36-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32322, current rewards: -3620.00000, mean: -1.94624
[32m[0906 21-36-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32322, current rewards: -3720.00000, mean: -1.94764
[32m[0906 21-36-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32321, current rewards: -3820.00000, mean: -1.94898
[32m[0906 21-36-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32323, current rewards: -3920.00000, mean: -1.95025
[32m[0906 21-37-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32323, current rewards: -4020.00000, mean: -1.95146
[32m[0906 21-37-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32324, current rewards: -4120.00000, mean: -1.95261
[32m[0906 21-37-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32324, current rewards: -4220.00000, mean: -1.95370
[32m[0906 21-37-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32324, current rewards: -4320.00000, mean: -1.95475
[32m[0906 21-38-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32323, current rewards: -4420.00000, mean: -1.95575
[32m[0906 21-38-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32323, current rewards: -4520.00000, mean: -1.95671
[32m[0906 21-38-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32323, current rewards: -4620.00000, mean: -1.95763
[32m[0906 21-39-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32322, current rewards: -4720.00000, mean: -1.95851
[32m[0906 21-39-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32322, current rewards: -4820.00000, mean: -1.95935
[32m[0906 21-39-30 @Agent.py:117][0m Average action selection time: 0.3232
[32m[0906 21-39-30 @Agent.py:118][0m Rollout length: 2600
[32m[0906 21-39-30 @MBExp.py:227][0m Rewards obtained: [-4900], Lows: [2400], Highs: [100], Total time: 18147.503622
[32m[0906 21-39-50 @MBExp.py:144][0m ####################################################################
[32m[0906 21-39-50 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 21-39-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31816, current rewards: -3.71192, mean: -0.37119
[32m[0906 21-40-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32053, current rewards: -1.31124, mean: -0.02185
[32m[0906 21-40-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32108, current rewards: -19.39070, mean: -0.17628
[32m[0906 21-40-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32130, current rewards: -119.39070, mean: -0.74619
[32m[0906 21-40-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32161, current rewards: -219.39070, mean: -1.04472
[32m[0906 21-41-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32193, current rewards: -319.39070, mean: -1.22843
[32m[0906 21-41-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32219, current rewards: -419.39070, mean: -1.35287
[32m[0906 21-41-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32231, current rewards: -519.39070, mean: -1.44275
[32m[0906 21-42-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32249, current rewards: -619.39070, mean: -1.51071
[32m[0906 21-42-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32261, current rewards: -719.39070, mean: -1.56389
[32m[0906 21-42-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32269, current rewards: -819.39070, mean: -1.60665
[32m[0906 21-42-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32279, current rewards: -919.39070, mean: -1.64177
[32m[0906 21-43-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32283, current rewards: -1019.39070, mean: -1.67113
[32m[0906 21-43-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32289, current rewards: -1119.39070, mean: -1.69605
[32m[0906 21-43-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32291, current rewards: -1219.39070, mean: -1.71745
[32m[0906 21-43-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32294, current rewards: -1319.39070, mean: -1.73604
[32m[0906 21-44-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32297, current rewards: -1419.39070, mean: -1.75233
[32m[0906 21-44-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32302, current rewards: -1519.39070, mean: -1.76673
[32m[0906 21-44-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32306, current rewards: -1619.39070, mean: -1.77955
[32m[0906 21-45-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32306, current rewards: -1719.39070, mean: -1.79103
[32m[0906 21-45-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32309, current rewards: -1819.39070, mean: -1.80138
[32m[0906 21-45-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32308, current rewards: -1919.39070, mean: -1.81075
[32m[0906 21-45-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32308, current rewards: -2019.39070, mean: -1.81927
[32m[0906 21-46-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32310, current rewards: -2108.30034, mean: -1.81750
[32m[0906 21-46-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32311, current rewards: -2158.30034, mean: -1.78372
[32m[0906 21-46-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32315, current rewards: -2219.73697, mean: -1.76170
[32m[0906 21-46-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32315, current rewards: -2260.26890, mean: -1.72540
[32m[0906 21-47-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32316, current rewards: -2310.26890, mean: -1.69873
[32m[0906 21-47-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32314, current rewards: -2360.26890, mean: -1.67395
[32m[0906 21-47-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32315, current rewards: -2410.26890, mean: -1.65087
[32m[0906 21-47-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32314, current rewards: -2460.26890, mean: -1.62932
[32m[0906 21-48-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32316, current rewards: -2510.26890, mean: -1.60915
[32m[0906 21-48-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32317, current rewards: -2560.26890, mean: -1.59023
[32m[0906 21-48-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32317, current rewards: -2648.11664, mean: -1.59525
[32m[0906 21-49-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32317, current rewards: -2748.11664, mean: -1.60709
[32m[0906 21-49-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32317, current rewards: -2843.24244, mean: -1.61548
[32m[0906 21-49-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32317, current rewards: -2943.24244, mean: -1.62610
[32m[0906 21-49-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32316, current rewards: -3043.24244, mean: -1.63615
[32m[0906 21-50-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32316, current rewards: -3143.24244, mean: -1.64568
[32m[0906 21-50-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32316, current rewards: -3243.24244, mean: -1.65472
[32m[0906 21-50-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32317, current rewards: -3343.24244, mean: -1.66330
[32m[0906 21-50-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32317, current rewards: -3443.24244, mean: -1.67148
[32m[0906 21-51-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32319, current rewards: -3543.24244, mean: -1.67926
[32m[0906 21-51-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32322, current rewards: -3643.24244, mean: -1.68669
[32m[0906 21-51-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32321, current rewards: -3743.24244, mean: -1.69377
[32m[0906 21-52-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32321, current rewards: -3843.24244, mean: -1.70055
[32m[0906 21-52-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32322, current rewards: -3928.66964, mean: -1.70072
[32m[0906 21-52-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32320, current rewards: -3923.16143, mean: -1.66236
[32m[0906 21-52-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32321, current rewards: -3922.75009, mean: -1.62770
[32m[0906 21-53-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32322, current rewards: -3972.75009, mean: -1.61494
[32m[0906 21-53-18 @Agent.py:117][0m Average action selection time: 0.3232
[32m[0906 21-53-18 @Agent.py:118][0m Rollout length: 2600
[32m[0906 21-53-18 @MBExp.py:227][0m Rewards obtained: [-4047.7500908163197], Lows: [1781], Highs: [505], Total time: 18955.890433
[32m[0906 21-53-38 @MBExp.py:144][0m ####################################################################
[32m[0906 21-53-38 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 21-53-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32080, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-53-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32097, current rewards: -60.00000, mean: -1.00000
[32m[0906 21-54-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32136, current rewards: -99.38230, mean: -0.90348
[32m[0906 21-54-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32163, current rewards: -96.20952, mean: -0.60131
[32m[0906 21-54-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32181, current rewards: -93.64638, mean: -0.44594
[32m[0906 21-55-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32207, current rewards: -88.78440, mean: -0.34148
[32m[0906 21-55-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32225, current rewards: -86.43216, mean: -0.27881
[32m[0906 21-55-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32240, current rewards: -83.32579, mean: -0.23146
[32m[0906 21-55-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32261, current rewards: -82.39355, mean: -0.20096
[32m[0906 21-56-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32272, current rewards: -130.29784, mean: -0.28326
[32m[0906 21-56-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32277, current rewards: -179.21492, mean: -0.35140
[32m[0906 21-56-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32286, current rewards: -225.96543, mean: -0.40351
[32m[0906 21-56-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32289, current rewards: -275.96543, mean: -0.45240
[32m[0906 21-57-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32292, current rewards: -325.96543, mean: -0.49389
[32m[0906 21-57-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32299, current rewards: -375.96543, mean: -0.52953
[32m[0906 21-57-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32303, current rewards: -425.96543, mean: -0.56048
[32m[0906 21-58-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32306, current rewards: -475.96543, mean: -0.58761
[32m[0906 21-58-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32309, current rewards: -525.96543, mean: -0.61159
[32m[0906 21-58-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32312, current rewards: -575.96543, mean: -0.63293
[32m[0906 21-58-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32314, current rewards: -625.96543, mean: -0.65205
[32m[0906 21-59-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32318, current rewards: -675.96543, mean: -0.66927
[32m[0906 21-59-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32320, current rewards: -725.96543, mean: -0.68487
[32m[0906 21-59-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32321, current rewards: -819.96543, mean: -0.73871
[32m[0906 21-59-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32324, current rewards: -919.96543, mean: -0.79307
[32m[0906 22-00-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32325, current rewards: -1019.96543, mean: -0.84295
[32m[0906 22-00-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32326, current rewards: -1119.96543, mean: -0.88886
[32m[0906 22-00-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32327, current rewards: -1219.96543, mean: -0.93127
[32m[0906 22-00-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32327, current rewards: -1236.20676, mean: -0.90898
[32m[0906 22-01-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32328, current rewards: -1261.18286, mean: -0.89446
[32m[0906 22-01-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32329, current rewards: -1311.18286, mean: -0.89807
[32m[0906 22-01-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32330, current rewards: -1361.18286, mean: -0.90145
[32m[0906 22-02-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32330, current rewards: -1411.18286, mean: -0.90460
[32m[0906 22-02-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32332, current rewards: -1461.18286, mean: -0.90757
[32m[0906 22-02-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32333, current rewards: -1511.18286, mean: -0.91035
[32m[0906 22-02-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32334, current rewards: -1561.18286, mean: -0.91297
[32m[0906 22-03-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32335, current rewards: -1611.18286, mean: -0.91544
[32m[0906 22-03-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32335, current rewards: -1661.18286, mean: -0.91778
[32m[0906 22-03-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32336, current rewards: -1711.18286, mean: -0.91999
[32m[0906 22-03-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32337, current rewards: -1761.18286, mean: -0.92209
[32m[0906 22-04-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32337, current rewards: -1811.18286, mean: -0.92407
[32m[0906 22-04-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32337, current rewards: -1861.18286, mean: -0.92596
[32m[0906 22-04-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32338, current rewards: -1911.18286, mean: -0.92776
[32m[0906 22-05-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32336, current rewards: -1961.18286, mean: -0.92947
[32m[0906 22-05-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32336, current rewards: -2011.18286, mean: -0.93110
[32m[0906 22-05-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32336, current rewards: -2061.18286, mean: -0.93266
[32m[0906 22-05-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32337, current rewards: -2111.18286, mean: -0.93415
[32m[0906 22-06-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32337, current rewards: -2161.18286, mean: -0.93558
[32m[0906 22-06-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32339, current rewards: -2211.18286, mean: -0.93694
[32m[0906 22-06-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32338, current rewards: -2261.18286, mean: -0.93825
[32m[0906 22-06-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32338, current rewards: -2311.18286, mean: -0.93951
[32m[0906 22-07-07 @Agent.py:117][0m Average action selection time: 0.3234
[32m[0906 22-07-07 @Agent.py:118][0m Rollout length: 2600
[32m[0906 22-07-07 @MBExp.py:227][0m Rewards obtained: [-2351.1828582168846], Lows: [257], Highs: [1871], Total time: 19764.692913
[32m[0906 22-07-28 @MBExp.py:144][0m ####################################################################
[32m[0906 22-07-28 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 22-07-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32077, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-07-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32085, current rewards: -60.00000, mean: -1.00000
[32m[0906 22-08-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32131, current rewards: -120.00000, mean: -1.09091
[32m[0906 22-08-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32153, current rewards: -220.00000, mean: -1.37500
[32m[0906 22-08-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32175, current rewards: -320.00000, mean: -1.52381
[32m[0906 22-08-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32191, current rewards: -420.00000, mean: -1.61538
[32m[0906 22-09-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32216, current rewards: -520.00000, mean: -1.67742
[32m[0906 22-09-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32236, current rewards: -620.00000, mean: -1.72222
[32m[0906 22-09-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32248, current rewards: -720.00000, mean: -1.75610
[32m[0906 22-09-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32262, current rewards: -820.00000, mean: -1.78261
[32m[0906 22-10-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32264, current rewards: -920.00000, mean: -1.80392
[32m[0906 22-10-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32268, current rewards: -1020.00000, mean: -1.82143
[32m[0906 22-10-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32277, current rewards: -1120.00000, mean: -1.83607
[32m[0906 22-11-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32281, current rewards: -1220.00000, mean: -1.84848
[32m[0906 22-11-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32283, current rewards: -1320.00000, mean: -1.85915
[32m[0906 22-11-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32288, current rewards: -1420.00000, mean: -1.86842
[32m[0906 22-11-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32291, current rewards: -1520.00000, mean: -1.87654
[32m[0906 22-12-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32294, current rewards: -1620.00000, mean: -1.88372
[32m[0906 22-12-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32298, current rewards: -1720.00000, mean: -1.89011
[32m[0906 22-12-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32300, current rewards: -1820.00000, mean: -1.89583
[32m[0906 22-12-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32301, current rewards: -1920.00000, mean: -1.90099
[32m[0906 22-13-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32302, current rewards: -2020.00000, mean: -1.90566
[32m[0906 22-13-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32305, current rewards: -2120.00000, mean: -1.90991
[32m[0906 22-13-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32309, current rewards: -2220.00000, mean: -1.91379
[32m[0906 22-13-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32312, current rewards: -2320.00000, mean: -1.91736
[32m[0906 22-14-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32313, current rewards: -2420.00000, mean: -1.92063
[32m[0906 22-14-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32314, current rewards: -2520.00000, mean: -1.92366
[32m[0906 22-14-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32313, current rewards: -2620.00000, mean: -1.92647
[32m[0906 22-15-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32315, current rewards: -2720.00000, mean: -1.92908
[32m[0906 22-15-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32316, current rewards: -2820.00000, mean: -1.93151
[32m[0906 22-15-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32318, current rewards: -2920.00000, mean: -1.93377
[32m[0906 22-15-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32318, current rewards: -3020.00000, mean: -1.93590
[32m[0906 22-16-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32318, current rewards: -3120.00000, mean: -1.93789
[32m[0906 22-16-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32319, current rewards: -3220.00000, mean: -1.93976
[32m[0906 22-16-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32319, current rewards: -3320.00000, mean: -1.94152
[32m[0906 22-16-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32320, current rewards: -3420.00000, mean: -1.94318
[32m[0906 22-17-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32319, current rewards: -3520.00000, mean: -1.94475
[32m[0906 22-17-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32319, current rewards: -3620.00000, mean: -1.94624
[32m[0906 22-17-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32319, current rewards: -3720.00000, mean: -1.94764
[32m[0906 22-18-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32320, current rewards: -3820.00000, mean: -1.94898
[32m[0906 22-18-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32320, current rewards: -3920.00000, mean: -1.95025
[32m[0906 22-18-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32321, current rewards: -4020.00000, mean: -1.95146
[32m[0906 22-18-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32322, current rewards: -4120.00000, mean: -1.95261
[32m[0906 22-19-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32322, current rewards: -4220.00000, mean: -1.95370
[32m[0906 22-19-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32323, current rewards: -4320.00000, mean: -1.95475
[32m[0906 22-19-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32324, current rewards: -4420.00000, mean: -1.95575
[32m[0906 22-19-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32325, current rewards: -4520.00000, mean: -1.95671
[32m[0906 22-20-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32325, current rewards: -4620.00000, mean: -1.95763
[32m[0906 22-20-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32325, current rewards: -4720.00000, mean: -1.95851
[32m[0906 22-20-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32326, current rewards: -4820.00000, mean: -1.95935
[32m[0906 22-20-57 @Agent.py:117][0m Average action selection time: 0.3233
[32m[0906 22-20-57 @Agent.py:118][0m Rollout length: 2600
[32m[0906 22-20-57 @MBExp.py:227][0m Rewards obtained: [-4900], Lows: [2400], Highs: [100], Total time: 20573.169627
[32m[0906 22-21-19 @MBExp.py:144][0m ####################################################################
[32m[0906 22-21-19 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 22-21-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32041, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-21-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32082, current rewards: -60.00000, mean: -1.00000
[32m[0906 22-21-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32145, current rewards: -104.66319, mean: -0.95148
[32m[0906 22-22-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32160, current rewards: -132.19210, mean: -0.82620
[32m[0906 22-22-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32172, current rewards: -169.60294, mean: -0.80763
[32m[0906 22-22-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32176, current rewards: -206.65837, mean: -0.79484
[32m[0906 22-22-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32198, current rewards: -256.65837, mean: -0.82793
[32m[0906 22-23-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32216, current rewards: -290.48036, mean: -0.80689
[32m[0906 22-23-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32237, current rewards: -340.48036, mean: -0.83044
[32m[0906 22-23-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32246, current rewards: -390.48036, mean: -0.84887
[32m[0906 22-24-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32258, current rewards: -440.48036, mean: -0.86369
[32m[0906 22-24-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32264, current rewards: -477.88009, mean: -0.85336
[32m[0906 22-24-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32270, current rewards: -527.88009, mean: -0.86538
[32m[0906 22-24-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32280, current rewards: -571.95435, mean: -0.86660
[32m[0906 22-25-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32283, current rewards: -617.14387, mean: -0.86922
[32m[0906 22-25-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32297, current rewards: -681.99594, mean: -0.89736
[32m[0906 22-25-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32304, current rewards: -763.11019, mean: -0.94211
[32m[0906 22-25-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32316, current rewards: -863.11019, mean: -1.00362
[32m[0906 22-26-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32318, current rewards: -961.03774, mean: -1.05609
[32m[0906 22-26-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32320, current rewards: -1061.03774, mean: -1.10525
[32m[0906 22-26-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32321, current rewards: -1161.03774, mean: -1.14954
[32m[0906 22-27-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32323, current rewards: -1261.03774, mean: -1.18966
[32m[0906 22-27-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32321, current rewards: -1361.03774, mean: -1.22616
[32m[0906 22-27-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32323, current rewards: -1445.85027, mean: -1.24642
[32m[0906 22-27-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32325, current rewards: -1505.57248, mean: -1.24427
[32m[0906 22-28-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32327, current rewards: -1534.38762, mean: -1.21777
[32m[0906 22-28-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32328, current rewards: -1584.38762, mean: -1.20946
[32m[0906 22-28-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32329, current rewards: -1634.38762, mean: -1.20176
[32m[0906 22-28-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32330, current rewards: -1684.38762, mean: -1.19460
[32m[0906 22-29-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32329, current rewards: -1734.38762, mean: -1.18794
[32m[0906 22-29-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32356, current rewards: -1784.38762, mean: -1.18171
[32m[0906 22-29-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32373, current rewards: -1834.38762, mean: -1.17589
[32m[0906 22-30-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32372, current rewards: -1884.38762, mean: -1.17043
[32m[0906 22-30-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32371, current rewards: -1934.38762, mean: -1.16529
[32m[0906 22-30-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32372, current rewards: -1984.38762, mean: -1.16046
[32m[0906 22-30-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32377, current rewards: -2034.38762, mean: -1.15590
[32m[0906 22-31-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32385, current rewards: -2084.38762, mean: -1.15160
[32m[0906 22-31-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32389, current rewards: -2134.38762, mean: -1.14752
[32m[0906 22-31-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32392, current rewards: -2184.38762, mean: -1.14366
[32m[0906 22-31-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32375, current rewards: -2234.38762, mean: -1.13999
[32m[0906 22-32-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32369, current rewards: -2284.38762, mean: -1.13651
[32m[0906 22-32-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32356, current rewards: -2309.83772, mean: -1.12128
[32m[0906 22-32-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32349, current rewards: -2304.04249, mean: -1.09196
[32m[0906 22-32-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32334, current rewards: -2298.24726, mean: -1.06400
[32m[0906 22-33-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32334, current rewards: -2292.10292, mean: -1.03715
[32m[0906 22-33-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32331, current rewards: -2285.49469, mean: -1.01128
[32m[0906 22-33-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32334, current rewards: -2278.88646, mean: -0.98653
[32m[0906 22-34-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32336, current rewards: -2272.27822, mean: -0.96283
[32m[0906 22-34-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32354, current rewards: -2290.57761, mean: -0.95045
[32m[0906 22-34-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32348, current rewards: -2340.57761, mean: -0.95145
[32m[0906 22-34-48 @Agent.py:117][0m Average action selection time: 0.3235
[32m[0906 22-34-48 @Agent.py:118][0m Rollout length: 2600
[32m[0906 22-34-48 @MBExp.py:227][0m Rewards obtained: [-2380.577612443782], Lows: [499], Highs: [1463], Total time: 21382.134922999998
[32m[0906 22-35-10 @MBExp.py:144][0m ####################################################################
[32m[0906 22-35-10 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 22-35-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33635, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-35-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32763, current rewards: -60.00000, mean: -1.00000
[32m[0906 22-35-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32940, current rewards: -98.54732, mean: -0.89588
[32m[0906 22-36-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32956, current rewards: -92.39771, mean: -0.57749
[32m[0906 22-36-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32829, current rewards: -87.27440, mean: -0.41559
[32m[0906 22-36-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32849, current rewards: -78.51075, mean: -0.30196
[32m[0906 22-36-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32950, current rewards: -64.16410, mean: -0.20698
[32m[0906 22-37-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32873, current rewards: -117.84516, mean: -0.32735
[32m[0906 22-37-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32777, current rewards: -95.25405, mean: -0.23233
[32m[0906 22-37-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32681, current rewards: -192.27510, mean: -0.41799
[32m[0906 22-37-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32670, current rewards: -219.41345, mean: -0.43022
[32m[0906 22-38-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32700, current rewards: -263.05546, mean: -0.46974
[32m[0906 22-38-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32658, current rewards: -275.22052, mean: -0.45118
[32m[0906 22-38-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32625, current rewards: -306.92305, mean: -0.46503
[32m[0906 22-39-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32584, current rewards: -321.35818, mean: -0.45262
[32m[0906 22-39-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32533, current rewards: -328.65785, mean: -0.43244
[32m[0906 22-39-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32494, current rewards: -329.40974, mean: -0.40668
[32m[0906 22-39-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32458, current rewards: -408.66164, mean: -0.47519
[32m[0906 22-40-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32424, current rewards: -497.72778, mean: -0.54695
[32m[0906 22-40-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32398, current rewards: -518.69883, mean: -0.54031
[32m[0906 22-40-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32373, current rewards: -618.69883, mean: -0.61257
[32m[0906 22-40-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32349, current rewards: -718.69883, mean: -0.67802
[32m[0906 22-41-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32335, current rewards: -739.79039, mean: -0.66648
[32m[0906 22-41-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32318, current rewards: -735.80449, mean: -0.63431
[32m[0906 22-41-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32293, current rewards: -732.78987, mean: -0.60561
[32m[0906 22-41-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32271, current rewards: -730.93755, mean: -0.58011
[32m[0906 22-42-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32254, current rewards: -801.20304, mean: -0.61161
[32m[0906 22-42-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32237, current rewards: -893.00100, mean: -0.65662
[32m[0906 22-42-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32220, current rewards: -937.58474, mean: -0.66495
[32m[0906 22-43-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32207, current rewards: -987.58474, mean: -0.67643
[32m[0906 22-43-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32197, current rewards: -1037.58474, mean: -0.68714
[32m[0906 22-43-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32185, current rewards: -1087.58474, mean: -0.69717
[32m[0906 22-43-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32178, current rewards: -1112.84642, mean: -0.69121
[32m[0906 22-44-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32169, current rewards: -1136.04328, mean: -0.68436
[32m[0906 22-44-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32162, current rewards: -1186.04328, mean: -0.69359
[32m[0906 22-44-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32156, current rewards: -1210.09233, mean: -0.68755
[32m[0906 22-44-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32146, current rewards: -1217.42736, mean: -0.67261
[32m[0906 22-45-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32143, current rewards: -1236.34377, mean: -0.66470
[32m[0906 22-45-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32139, current rewards: -1230.68422, mean: -0.64434
[32m[0906 22-45-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32138, current rewards: -1243.05878, mean: -0.63421
[32m[0906 22-45-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32136, current rewards: -1315.89439, mean: -0.65467
[32m[0906 22-46-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32150, current rewards: -1325.05784, mean: -0.64323
[32m[0906 22-46-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32153, current rewards: -1361.27402, mean: -0.64515
[32m[0906 22-46-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32146, current rewards: -1433.67976, mean: -0.66374
[32m[0906 22-47-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32142, current rewards: -1426.90179, mean: -0.64566
[32m[0906 22-47-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32146, current rewards: -1474.25601, mean: -0.65233
[32m[0906 22-47-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32140, current rewards: -1491.16312, mean: -0.64553
[32m[0906 22-47-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32145, current rewards: -1559.49372, mean: -0.66080
[32m[0906 22-48-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32171, current rewards: -1559.01980, mean: -0.64690
[32m[0906 22-48-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32183, current rewards: -1601.61209, mean: -0.65106
[32m[0906 22-48-35 @Agent.py:117][0m Average action selection time: 0.3218
[32m[0906 22-48-35 @Agent.py:118][0m Rollout length: 2600
[32m[0906 22-48-35 @MBExp.py:227][0m Rewards obtained: [-1641.6120941217728], Lows: [584], Highs: [699], Total time: 22187.066634
[32m[0906 22-48-58 @MBExp.py:144][0m ####################################################################
[32m[0906 22-48-58 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 22-49-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.36832, current rewards: 0.81491, mean: 0.08149
[32m[0906 22-49-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33101, current rewards: 8.67858, mean: 0.14464
[32m[0906 22-49-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32773, current rewards: 8.31071, mean: 0.07555
[32m[0906 22-49-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32555, current rewards: 15.21420, mean: 0.09509
[32m[0906 22-50-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32422, current rewards: 22.14086, mean: 0.10543
[32m[0906 22-50-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32413, current rewards: 29.06752, mean: 0.11180
[32m[0906 22-50-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32479, current rewards: 35.99418, mean: 0.11611
[32m[0906 22-50-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32591, current rewards: 42.92084, mean: 0.11922
[32m[0906 22-51-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32621, current rewards: 21.38416, mean: 0.05216
[32m[0906 22-51-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32575, current rewards: -28.61584, mean: -0.06221
[32m[0906 22-51-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32541, current rewards: -78.61584, mean: -0.15415
[32m[0906 22-52-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32497, current rewards: -128.61584, mean: -0.22967
[32m[0906 22-52-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32554, current rewards: -178.61584, mean: -0.29281
[32m[0906 22-52-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32628, current rewards: -228.61584, mean: -0.34639
[32m[0906 22-52-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32649, current rewards: -278.61584, mean: -0.39242
[32m[0906 22-53-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32608, current rewards: -328.61584, mean: -0.43239
[32m[0906 22-53-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32564, current rewards: -378.61584, mean: -0.46743
[32m[0906 22-53-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32523, current rewards: -428.61584, mean: -0.49839
[32m[0906 22-53-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32491, current rewards: -478.61584, mean: -0.52595
[32m[0906 22-54-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32460, current rewards: -528.61584, mean: -0.55064
[32m[0906 22-54-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32431, current rewards: -578.61584, mean: -0.57289
[32m[0906 22-54-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32413, current rewards: -628.61584, mean: -0.59303
[32m[0906 22-54-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32405, current rewards: -678.61584, mean: -0.61137
[32m[0906 22-55-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32385, current rewards: -728.61584, mean: -0.62812
[32m[0906 22-55-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32368, current rewards: -778.61584, mean: -0.64348
[32m[0906 22-55-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32352, current rewards: -828.61584, mean: -0.65763
[32m[0906 22-56-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32341, current rewards: -878.61584, mean: -0.67070
[32m[0906 22-56-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32353, current rewards: -928.61584, mean: -0.68281
[32m[0906 22-56-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32349, current rewards: -978.61584, mean: -0.69405
[32m[0906 22-56-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32336, current rewards: -1028.61584, mean: -0.70453
[32m[0906 22-57-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32321, current rewards: -1078.61584, mean: -0.71432
[32m[0906 22-57-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32320, current rewards: -1128.61584, mean: -0.72347
[32m[0906 22-57-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32327, current rewards: -1178.61584, mean: -0.73206
[32m[0906 22-57-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32324, current rewards: -1228.61584, mean: -0.74013
[32m[0906 22-58-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32312, current rewards: -1278.61584, mean: -0.74773
[32m[0906 22-58-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32301, current rewards: -1328.61584, mean: -0.75490
[32m[0906 22-58-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32287, current rewards: -1378.61584, mean: -0.76167
[32m[0906 22-58-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32274, current rewards: -1428.61584, mean: -0.76807
[32m[0906 22-59-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32261, current rewards: -1478.61584, mean: -0.77414
[32m[0906 22-59-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32249, current rewards: -1528.61584, mean: -0.77991
[32m[0906 22-59-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32237, current rewards: -1578.61584, mean: -0.78538
[32m[0906 23-00-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32227, current rewards: -1628.61584, mean: -0.79059
[32m[0906 23-00-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32229, current rewards: -1678.61584, mean: -0.79555
[32m[0906 23-00-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32224, current rewards: -1728.61584, mean: -0.80029
[32m[0906 23-00-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32213, current rewards: -1778.61584, mean: -0.80480
[32m[0906 23-01-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32205, current rewards: -1828.61584, mean: -0.80912
[32m[0906 23-01-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32218, current rewards: -1878.61584, mean: -0.81325
[32m[0906 23-01-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32213, current rewards: -1928.61584, mean: -0.81721
[32m[0906 23-01-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32208, current rewards: -1978.61584, mean: -0.82100
[32m[0906 23-02-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32209, current rewards: -2028.61584, mean: -0.82464
[32m[0906 23-02-24 @Agent.py:117][0m Average action selection time: 0.3220
[32m[0906 23-02-24 @Agent.py:118][0m Rollout length: 2600
[32m[0906 23-02-24 @MBExp.py:227][0m Rewards obtained: [-2068.615835567933], Lows: [5], Highs: [2115], Total time: 22992.597359
[32m[0906 23-02-46 @MBExp.py:144][0m ####################################################################
[32m[0906 23-02-46 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 23-02-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32181, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-03-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31801, current rewards: -60.00000, mean: -1.00000
[32m[0906 23-03-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31803, current rewards: -110.00000, mean: -1.00000
[32m[0906 23-03-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31813, current rewards: -160.00000, mean: -1.00000
[32m[0906 23-03-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31814, current rewards: -210.00000, mean: -1.00000
[32m[0906 23-04-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31847, current rewards: -258.95169, mean: -0.99597
[32m[0906 23-04-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31865, current rewards: -256.00110, mean: -0.82581
[32m[0906 23-04-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31868, current rewards: -250.64260, mean: -0.69623
[32m[0906 23-04-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31900, current rewards: -250.04508, mean: -0.60987
[32m[0906 23-05-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31961, current rewards: -246.84167, mean: -0.53661
[32m[0906 23-05-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31969, current rewards: -262.15544, mean: -0.51403
[32m[0906 23-05-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31974, current rewards: -306.88653, mean: -0.54801
[32m[0906 23-06-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31971, current rewards: -320.36652, mean: -0.52519
[32m[0906 23-06-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31968, current rewards: -325.63298, mean: -0.49338
[32m[0906 23-06-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31963, current rewards: -425.63298, mean: -0.59948
[32m[0906 23-06-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31962, current rewards: -519.34856, mean: -0.68335
[32m[0906 23-07-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31994, current rewards: -516.35813, mean: -0.63748
[32m[0906 23-07-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31987, current rewards: -511.62043, mean: -0.59491
[32m[0906 23-07-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31993, current rewards: -574.61819, mean: -0.63145
[32m[0906 23-07-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31982, current rewards: -613.46909, mean: -0.63903
[32m[0906 23-08-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31928, current rewards: -623.34358, mean: -0.61717
[32m[0906 23-08-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31819, current rewards: -671.24548, mean: -0.63325
[32m[0906 23-08-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31729, current rewards: -707.47278, mean: -0.63736
[32m[0906 23-08-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31637, current rewards: -716.48681, mean: -0.61766
[32m[0906 23-09-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31550, current rewards: -724.68197, mean: -0.59891
[32m[0906 23-09-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31473, current rewards: -763.99958, mean: -0.60635
[32m[0906 23-09-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31401, current rewards: -813.99958, mean: -0.62137
[32m[0906 23-09-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31336, current rewards: -835.54271, mean: -0.61437
[32m[0906 23-10-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31271, current rewards: -885.54271, mean: -0.62804
[32m[0906 23-10-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31221, current rewards: -913.34915, mean: -0.62558
[32m[0906 23-10-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31166, current rewards: -934.06342, mean: -0.61859
[32m[0906 23-10-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31115, current rewards: -968.93760, mean: -0.62111
[32m[0906 23-11-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31066, current rewards: -1025.90139, mean: -0.63721
[32m[0906 23-11-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31021, current rewards: -1054.34388, mean: -0.63515
[32m[0906 23-11-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30979, current rewards: -1119.51067, mean: -0.65468
[32m[0906 23-11-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30938, current rewards: -1212.26153, mean: -0.68878
[32m[0906 23-12-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30900, current rewards: -1264.28773, mean: -0.69850
[32m[0906 23-12-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30864, current rewards: -1266.43284, mean: -0.68088
[32m[0906 23-12-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30829, current rewards: -1284.53480, mean: -0.67253
[32m[0906 23-12-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30796, current rewards: -1375.94337, mean: -0.70201
[32m[0906 23-13-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30766, current rewards: -1434.69699, mean: -0.71378
[32m[0906 23-13-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30738, current rewards: -1482.53689, mean: -0.71968
[32m[0906 23-13-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30711, current rewards: -1532.53689, mean: -0.72632
[32m[0906 23-13-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30684, current rewards: -1526.18174, mean: -0.70657
[32m[0906 23-14-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30659, current rewards: -1588.28219, mean: -0.71868
[32m[0906 23-14-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30635, current rewards: -1683.15898, mean: -0.74476
[32m[0906 23-14-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30610, current rewards: -1746.51012, mean: -0.75606
[32m[0906 23-14-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30588, current rewards: -1744.63136, mean: -0.73925
[32m[0906 23-15-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30566, current rewards: -1784.63467, mean: -0.74051
[32m[0906 23-15-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30544, current rewards: -1872.25337, mean: -0.76108
[32m[0906 23-15-30 @Agent.py:117][0m Average action selection time: 0.3053
[32m[0906 23-15-30 @Agent.py:118][0m Rollout length: 2600
[32m[0906 23-15-30 @MBExp.py:227][0m Rewards obtained: [-1903.229529784935], Lows: [585], Highs: [872], Total time: 23756.168625
[32m[0906 23-15-53 @MBExp.py:144][0m ####################################################################
[32m[0906 23-15-53 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 23-15-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31222, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-16-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29776, current rewards: -60.00000, mean: -1.00000
[32m[0906 23-16-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29593, current rewards: -117.93957, mean: -1.07218
[32m[0906 23-16-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29526, current rewards: -217.93957, mean: -1.36212
[32m[0906 23-16-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29495, current rewards: -228.18272, mean: -1.08658
[32m[0906 23-17-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29481, current rewards: -256.14425, mean: -0.98517
[32m[0906 23-17-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29482, current rewards: -292.07119, mean: -0.94217
[32m[0906 23-17-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29485, current rewards: -332.23916, mean: -0.92289
[32m[0906 23-17-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29491, current rewards: -382.23916, mean: -0.93229
[32m[0906 23-18-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29499, current rewards: -389.42175, mean: -0.84657
[32m[0906 23-18-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29501, current rewards: -378.50998, mean: -0.74218
[32m[0906 23-18-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29503, current rewards: -376.45068, mean: -0.67223
[32m[0906 23-18-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29509, current rewards: -362.98056, mean: -0.59505
[32m[0906 23-19-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29512, current rewards: -379.75986, mean: -0.57539
[32m[0906 23-19-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29514, current rewards: -429.75986, mean: -0.60530
[32m[0906 23-19-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29517, current rewards: -474.50068, mean: -0.62434
[32m[0906 23-19-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29516, current rewards: -471.30263, mean: -0.58186
[32m[0906 23-20-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29517, current rewards: -467.28171, mean: -0.54335
[32m[0906 23-20-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29517, current rewards: -513.04729, mean: -0.56379
[32m[0906 23-20-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29519, current rewards: -563.04729, mean: -0.58651
[32m[0906 23-20-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29519, current rewards: -556.35710, mean: -0.55085
[32m[0906 23-21-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29518, current rewards: -566.09116, mean: -0.53405
[32m[0906 23-21-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29518, current rewards: -564.88393, mean: -0.50890
[32m[0906 23-21-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29517, current rewards: -555.74154, mean: -0.47909
[32m[0906 23-21-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29517, current rewards: -559.53393, mean: -0.46242
[32m[0906 23-22-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29518, current rewards: -585.56012, mean: -0.46473
[32m[0906 23-22-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29517, current rewards: -668.45902, mean: -0.51027
[32m[0906 23-22-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29517, current rewards: -705.69895, mean: -0.51890
[32m[0906 23-22-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29517, current rewards: -799.32892, mean: -0.56690
[32m[0906 23-23-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29517, current rewards: -896.86347, mean: -0.61429
[32m[0906 23-23-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29517, current rewards: -898.45504, mean: -0.59500
[32m[0906 23-23-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29517, current rewards: -894.49139, mean: -0.57339
[32m[0906 23-23-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29515, current rewards: -940.15829, mean: -0.58395
[32m[0906 23-24-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29515, current rewards: -990.15829, mean: -0.59648
[32m[0906 23-24-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29516, current rewards: -1040.15829, mean: -0.60828
[32m[0906 23-24-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29515, current rewards: -1090.15829, mean: -0.61941
[32m[0906 23-24-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29514, current rewards: -1140.15829, mean: -0.62992
[32m[0906 23-25-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29513, current rewards: -1190.15829, mean: -0.63987
[32m[0906 23-25-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29513, current rewards: -1240.15829, mean: -0.64930
[32m[0906 23-25-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29512, current rewards: -1290.15829, mean: -0.65824
[32m[0906 23-25-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29511, current rewards: -1340.15829, mean: -0.66675
[32m[0906 23-26-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29510, current rewards: -1390.15829, mean: -0.67483
[32m[0906 23-26-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29509, current rewards: -1440.15829, mean: -0.68254
[32m[0906 23-26-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29509, current rewards: -1490.15829, mean: -0.68989
[32m[0906 23-26-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29509, current rewards: -1540.15829, mean: -0.69690
[32m[0906 23-27-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29508, current rewards: -1590.15829, mean: -0.70361
[32m[0906 23-27-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29507, current rewards: -1640.15829, mean: -0.71003
[32m[0906 23-27-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29507, current rewards: -1690.15829, mean: -0.71617
[32m[0906 23-27-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29506, current rewards: -1689.91270, mean: -0.70121
[32m[0906 23-27-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29506, current rewards: -1685.61238, mean: -0.68521
[32m[0906 23-28-11 @Agent.py:117][0m Average action selection time: 0.2951
[32m[0906 23-28-11 @Agent.py:118][0m Rollout length: 2600
[32m[0906 23-28-11 @MBExp.py:227][0m Rewards obtained: [-1683.6972187373087], Lows: [263], Highs: [1303], Total time: 24494.110005
[32m[0906 23-28-35 @MBExp.py:144][0m ####################################################################
[32m[0906 23-28-35 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 23-28-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29237, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-28-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29288, current rewards: -60.00000, mean: -1.00000
[32m[0906 23-29-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29328, current rewards: -99.18013, mean: -0.90164
[32m[0906 23-29-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29343, current rewards: -88.89304, mean: -0.55558
[32m[0906 23-29-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29358, current rewards: -188.89304, mean: -0.89949
[32m[0906 23-29-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29375, current rewards: -268.56070, mean: -1.03293
[32m[0906 23-30-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29384, current rewards: -260.19951, mean: -0.83935
[32m[0906 23-30-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29396, current rewards: -344.59195, mean: -0.95720
[32m[0906 23-30-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29409, current rewards: -433.59685, mean: -1.05755
[32m[0906 23-30-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29418, current rewards: -519.18409, mean: -1.12866
[32m[0906 23-31-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29426, current rewards: -545.75408, mean: -1.07011
[32m[0906 23-31-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29432, current rewards: -539.59162, mean: -0.96356
[32m[0906 23-31-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29439, current rewards: -602.72401, mean: -0.98807
[32m[0906 23-31-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29444, current rewards: -640.09526, mean: -0.96984
[32m[0906 23-32-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29447, current rewards: -687.22233, mean: -0.96792
[32m[0906 23-32-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29450, current rewards: -726.07352, mean: -0.95536
[32m[0906 23-32-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29452, current rewards: -793.33864, mean: -0.97943
[32m[0906 23-32-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29455, current rewards: -883.59910, mean: -1.02744
[32m[0906 23-33-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29456, current rewards: -983.59910, mean: -1.08088
[32m[0906 23-33-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29457, current rewards: -1083.59910, mean: -1.12875
[32m[0906 23-33-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29460, current rewards: -1183.59910, mean: -1.17188
[32m[0906 23-33-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29461, current rewards: -1283.59910, mean: -1.21094
[32m[0906 23-34-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29462, current rewards: -1383.59910, mean: -1.24649
[32m[0906 23-34-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29463, current rewards: -1483.59910, mean: -1.27896
[32m[0906 23-34-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29464, current rewards: -1583.59910, mean: -1.30876
[32m[0906 23-34-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29464, current rewards: -1683.59910, mean: -1.33619
[32m[0906 23-35-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29465, current rewards: -1783.59910, mean: -1.36153
[32m[0906 23-35-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29466, current rewards: -1883.59910, mean: -1.38500
[32m[0906 23-35-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29467, current rewards: -1983.59910, mean: -1.40681
[32m[0906 23-35-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29468, current rewards: -2083.59910, mean: -1.42712
[32m[0906 23-36-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29470, current rewards: -2183.59910, mean: -1.44609
[32m[0906 23-36-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29471, current rewards: -2283.59910, mean: -1.46385
[32m[0906 23-36-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29471, current rewards: -2383.59910, mean: -1.48050
[32m[0906 23-36-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29471, current rewards: -2483.59910, mean: -1.49614
[32m[0906 23-36-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29471, current rewards: -2583.59910, mean: -1.51088
[32m[0906 23-37-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29471, current rewards: -2683.59910, mean: -1.52477
[32m[0906 23-37-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29471, current rewards: -2783.59910, mean: -1.53790
[32m[0906 23-37-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29471, current rewards: -2883.59910, mean: -1.55032
[32m[0906 23-37-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29471, current rewards: -2983.59910, mean: -1.56209
[32m[0906 23-38-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29471, current rewards: -3083.59910, mean: -1.57326
[32m[0906 23-38-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29472, current rewards: -3183.59910, mean: -1.58388
[32m[0906 23-38-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29471, current rewards: -3283.59910, mean: -1.59398
[32m[0906 23-38-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29472, current rewards: -3383.59910, mean: -1.60360
[32m[0906 23-39-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29473, current rewards: -3483.59910, mean: -1.61278
[32m[0906 23-39-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29474, current rewards: -3583.59910, mean: -1.62154
[32m[0906 23-39-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29475, current rewards: -3683.59910, mean: -1.62991
[32m[0906 23-39-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29475, current rewards: -3783.59910, mean: -1.63792
[32m[0906 23-40-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29475, current rewards: -3883.59910, mean: -1.64559
[32m[0906 23-40-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29476, current rewards: -3983.59910, mean: -1.65295
[32m[0906 23-40-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29476, current rewards: -4083.59910, mean: -1.66000
[32m[0906 23-40-52 @Agent.py:117][0m Average action selection time: 0.2948
[32m[0906 23-40-52 @Agent.py:118][0m Rollout length: 2600
[32m[0906 23-40-52 @MBExp.py:227][0m Rewards obtained: [-4163.599097342025], Lows: [2002], Highs: [217], Total time: 25231.319495
[32m[0906 23-41-17 @MBExp.py:144][0m ####################################################################
[32m[0906 23-41-17 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 23-41-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31231, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-41-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29636, current rewards: -60.00000, mean: -1.00000
[32m[0906 23-41-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29507, current rewards: -108.95152, mean: -0.99047
[32m[0906 23-42-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29472, current rewards: -113.33965, mean: -0.70837
[32m[0906 23-42-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29449, current rewards: -135.06306, mean: -0.64316
[32m[0906 23-42-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29441, current rewards: -127.32075, mean: -0.48970
[32m[0906 23-42-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29502, current rewards: -199.74796, mean: -0.64435
[32m[0906 23-43-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29497, current rewards: -217.87249, mean: -0.60520
[32m[0906 23-43-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29498, current rewards: -273.93099, mean: -0.66812
[32m[0906 23-43-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29501, current rewards: -307.36030, mean: -0.66817
[32m[0906 23-43-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29502, current rewards: -366.45026, mean: -0.71853
[32m[0906 23-44-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29501, current rewards: -371.67293, mean: -0.66370
[32m[0906 23-44-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29503, current rewards: -423.30329, mean: -0.69394
[32m[0906 23-44-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29503, current rewards: -453.59652, mean: -0.68727
[32m[0906 23-44-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29503, current rewards: -516.54772, mean: -0.72753
[32m[0906 23-45-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29503, current rewards: -572.81015, mean: -0.75370
[32m[0906 23-45-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29504, current rewards: -637.99958, mean: -0.78765
[32m[0906 23-45-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29506, current rewards: -682.21064, mean: -0.79327
[32m[0906 23-45-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29506, current rewards: -758.98591, mean: -0.83405
[32m[0906 23-46-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29508, current rewards: -806.77008, mean: -0.84039
[32m[0906 23-46-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29510, current rewards: -858.41339, mean: -0.84991
[32m[0906 23-46-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29511, current rewards: -954.41339, mean: -0.90039
[32m[0906 23-46-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29513, current rewards: -989.05940, mean: -0.89104
[32m[0906 23-47-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29513, current rewards: -1040.38662, mean: -0.89689
[32m[0906 23-47-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29515, current rewards: -1074.90601, mean: -0.88835
[32m[0906 23-47-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29516, current rewards: -1123.81662, mean: -0.89192
[32m[0906 23-47-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29517, current rewards: -1165.33524, mean: -0.88957
[32m[0906 23-47-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29517, current rewards: -1215.33524, mean: -0.89363
[32m[0906 23-48-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29518, current rewards: -1256.97849, mean: -0.89147
[32m[0906 23-48-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29517, current rewards: -1304.88280, mean: -0.89376
[32m[0906 23-48-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29517, current rewards: -1353.83192, mean: -0.89658
[32m[0906 23-48-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29518, current rewards: -1415.15133, mean: -0.90715
[32m[0906 23-49-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29519, current rewards: -1455.57959, mean: -0.90409
[32m[0906 23-49-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29519, current rewards: -1505.57959, mean: -0.90698
[32m[0906 23-49-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29519, current rewards: -1560.20153, mean: -0.91240
[32m[0906 23-49-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29519, current rewards: -1604.42238, mean: -0.91160
[32m[0906 23-50-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29519, current rewards: -1637.77013, mean: -0.90485
[32m[0906 23-50-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29519, current rewards: -1737.77013, mean: -0.93429
[32m[0906 23-50-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29519, current rewards: -1818.10267, mean: -0.95189
[32m[0906 23-50-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29518, current rewards: -1827.87521, mean: -0.93259
[32m[0906 23-51-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29517, current rewards: -1835.21150, mean: -0.91304
[32m[0906 23-51-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29517, current rewards: -1838.30299, mean: -0.89238
[32m[0906 23-51-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29517, current rewards: -1866.38157, mean: -0.88454
[32m[0906 23-51-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29517, current rewards: -1919.31855, mean: -0.88857
[32m[0906 23-52-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29516, current rewards: -1950.39904, mean: -0.88253
[32m[0906 23-52-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29517, current rewards: -1953.51450, mean: -0.86439
[32m[0906 23-52-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29517, current rewards: -1973.93267, mean: -0.85452
[32m[0906 23-52-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29516, current rewards: -2073.93267, mean: -0.87879
[32m[0906 23-53-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29523, current rewards: -2108.44068, mean: -0.87487
[32m[0906 23-53-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29522, current rewards: -2208.44068, mean: -0.89774
[32m[0906 23-53-36 @Agent.py:117][0m Average action selection time: 0.2952
[32m[0906 23-53-36 @Agent.py:118][0m Rollout length: 2600
[32m[0906 23-53-36 @MBExp.py:227][0m Rewards obtained: [-2254.193757064626], Lows: [777], Highs: [855], Total time: 25969.664918
[32m[0906 23-54-01 @MBExp.py:144][0m ####################################################################
[32m[0906 23-54-01 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 23-54-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31257, current rewards: 0.84193, mean: 0.08419
[32m[0906 23-54-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30576, current rewards: 6.40508, mean: 0.10675
[32m[0906 23-54-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30022, current rewards: -9.14440, mean: -0.08313
[32m[0906 23-54-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29832, current rewards: -87.96795, mean: -0.54980
[32m[0906 23-55-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29730, current rewards: -112.34024, mean: -0.53495
[32m[0906 23-55-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29672, current rewards: -106.77709, mean: -0.41068
[32m[0906 23-55-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29636, current rewards: -155.66582, mean: -0.50215
[32m[0906 23-55-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29616, current rewards: -205.66582, mean: -0.57129
[32m[0906 23-56-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29608, current rewards: -255.66582, mean: -0.62358
[32m[0906 23-56-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29604, current rewards: -305.66582, mean: -0.66449
[32m[0906 23-56-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29596, current rewards: -355.66582, mean: -0.69738
[32m[0906 23-56-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29590, current rewards: -405.66582, mean: -0.72440
[32m[0906 23-57-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29586, current rewards: -455.66582, mean: -0.74699
[32m[0906 23-57-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29581, current rewards: -505.66582, mean: -0.76616
[32m[0906 23-57-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29576, current rewards: -555.66582, mean: -0.78263
[32m[0906 23-57-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29574, current rewards: -605.66582, mean: -0.79693
[32m[0906 23-58-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29573, current rewards: -655.66582, mean: -0.80946
[32m[0906 23-58-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29567, current rewards: -675.20126, mean: -0.78512
[32m[0906 23-58-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29565, current rewards: -672.59242, mean: -0.73911
[32m[0906 23-58-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29564, current rewards: -718.39717, mean: -0.74833
[32m[0906 23-59-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29561, current rewards: -766.29834, mean: -0.75871
[32m[0906 23-59-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29559, current rewards: -816.29834, mean: -0.77009
[32m[0906 23-59-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29556, current rewards: -866.29834, mean: -0.78045
[32m[0906 23-59-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29553, current rewards: -923.95802, mean: -0.79652
[32m[0906 23-59-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29550, current rewards: -1023.95802, mean: -0.84625
[32m[0907 00-00-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29548, current rewards: -1080.44860, mean: -0.85750
[32m[0907 00-00-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29547, current rewards: -1067.28303, mean: -0.81472
[32m[0907 00-00-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29547, current rewards: -1107.53312, mean: -0.81436
[32m[0907 00-00-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29546, current rewards: -1089.37800, mean: -0.77261
[32m[0907 00-01-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29546, current rewards: -1134.05283, mean: -0.77675
[32m[0907 00-01-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29545, current rewards: -1184.05283, mean: -0.78414
[32m[0907 00-01-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29545, current rewards: -1234.05283, mean: -0.79106
[32m[0907 00-01-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29545, current rewards: -1284.05283, mean: -0.79755
[32m[0907 00-02-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29545, current rewards: -1334.05283, mean: -0.80365
[32m[0907 00-02-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29545, current rewards: -1384.05283, mean: -0.80939
[32m[0907 00-02-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29545, current rewards: -1434.05283, mean: -0.81480
[32m[0907 00-02-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29544, current rewards: -1484.05283, mean: -0.81992
[32m[0907 00-03-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29543, current rewards: -1534.05283, mean: -0.82476
[32m[0907 00-03-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29543, current rewards: -1584.05283, mean: -0.82935
[32m[0907 00-03-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29542, current rewards: -1634.05283, mean: -0.83370
[32m[0907 00-03-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29541, current rewards: -1684.05283, mean: -0.83784
[32m[0907 00-04-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29541, current rewards: -1734.05283, mean: -0.84177
[32m[0907 00-04-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29540, current rewards: -1784.05283, mean: -0.84552
[32m[0907 00-04-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29540, current rewards: -1834.05283, mean: -0.84910
[32m[0907 00-04-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29540, current rewards: -1884.05283, mean: -0.85251
[32m[0907 00-05-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29540, current rewards: -1934.05283, mean: -0.85578
[32m[0907 00-05-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29539, current rewards: -1984.05283, mean: -0.85890
[32m[0907 00-05-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29538, current rewards: -2034.05283, mean: -0.86189
[32m[0907 00-05-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29538, current rewards: -2084.05283, mean: -0.86475
[32m[0907 00-06-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29537, current rewards: -2134.05283, mean: -0.86750
[32m[0907 00-06-20 @Agent.py:117][0m Average action selection time: 0.2954
[32m[0907 00-06-20 @Agent.py:118][0m Rollout length: 2600
[32m[0907 00-06-20 @MBExp.py:227][0m Rewards obtained: [-2174.0528256765256], Lows: [191], Highs: [1882], Total time: 26708.415332999997
[32m[0907 00-06-46 @MBExp.py:144][0m ####################################################################
[32m[0907 00-06-46 @MBExp.py:145][0m Starting training iteration 36.
[32m[0907 00-06-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31302, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-07-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29617, current rewards: -60.00000, mean: -1.00000
[32m[0907 00-07-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29484, current rewards: -102.81115, mean: -0.93465
[32m[0907 00-07-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29453, current rewards: -102.53624, mean: -0.64085
[32m[0907 00-07-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29442, current rewards: -160.74393, mean: -0.76545
[32m[0907 00-08-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29444, current rewards: -260.74393, mean: -1.00286
[32m[0907 00-08-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29453, current rewards: -360.74393, mean: -1.16369
[32m[0907 00-08-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29461, current rewards: -460.74393, mean: -1.27984
[32m[0907 00-08-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29470, current rewards: -560.74393, mean: -1.36767
[32m[0907 00-09-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29475, current rewards: -621.08357, mean: -1.35018
[32m[0907 00-09-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29478, current rewards: -670.09285, mean: -1.31391
[32m[0907 00-09-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29478, current rewards: -770.09285, mean: -1.37517
[32m[0907 00-09-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29480, current rewards: -812.41129, mean: -1.33182
[32m[0907 00-10-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29484, current rewards: -882.83408, mean: -1.33763
[32m[0907 00-10-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29486, current rewards: -952.78763, mean: -1.34195
[32m[0907 00-10-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29488, current rewards: -989.78911, mean: -1.30235
[32m[0907 00-10-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29489, current rewards: -1076.69771, mean: -1.32926
[32m[0907 00-11-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29492, current rewards: -1089.58947, mean: -1.26696
[32m[0907 00-11-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29496, current rewards: -1129.88415, mean: -1.24163
[32m[0907 00-11-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29499, current rewards: -1147.56637, mean: -1.19538
[32m[0907 00-11-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29502, current rewards: -1234.72671, mean: -1.22250
[32m[0907 00-11-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29504, current rewards: -1267.72697, mean: -1.19597
[32m[0907 00-12-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29504, current rewards: -1348.22219, mean: -1.21461
[32m[0907 00-12-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29505, current rewards: -1407.56964, mean: -1.21342
[32m[0907 00-12-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29507, current rewards: -1505.51769, mean: -1.24423
[32m[0907 00-12-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29506, current rewards: -1597.17333, mean: -1.26760
[32m[0907 00-13-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29507, current rewards: -1697.17333, mean: -1.29555
[32m[0907 00-13-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29507, current rewards: -1768.41394, mean: -1.30030
[32m[0907 00-13-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29508, current rewards: -1741.19158, mean: -1.23489
[32m[0907 00-13-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29509, current rewards: -1728.19837, mean: -1.18370
[32m[0907 00-14-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29510, current rewards: -1774.70288, mean: -1.17530
[32m[0907 00-14-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29510, current rewards: -1856.07641, mean: -1.18979
[32m[0907 00-14-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29510, current rewards: -1860.43375, mean: -1.15555
[32m[0907 00-14-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29510, current rewards: -1840.93204, mean: -1.10900
[32m[0907 00-15-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29510, current rewards: -1841.84639, mean: -1.07710
[32m[0907 00-15-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29509, current rewards: -1894.73427, mean: -1.07655
[32m[0907 00-15-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29514, current rewards: -1944.73427, mean: -1.07444
[32m[0907 00-15-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29514, current rewards: -1951.02674, mean: -1.04894
[32m[0907 00-16-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29514, current rewards: -2021.27842, mean: -1.05826
[32m[0907 00-16-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29514, current rewards: -2046.25932, mean: -1.04401
[32m[0907 00-16-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29519, current rewards: -2143.97744, mean: -1.06666
[32m[0907 00-16-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29519, current rewards: -2222.77457, mean: -1.07902
[32m[0907 00-17-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29520, current rewards: -2272.39598, mean: -1.07696
[32m[0907 00-17-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29521, current rewards: -2266.58754, mean: -1.04935
[32m[0907 00-17-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29525, current rewards: -2266.65357, mean: -1.02564
[32m[0907 00-17-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29525, current rewards: -2276.00094, mean: -1.00708
[32m[0907 00-18-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29525, current rewards: -2336.06478, mean: -1.01128
[32m[0907 00-18-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29524, current rewards: -2436.06478, mean: -1.03223
[32m[0907 00-18-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29524, current rewards: -2536.06478, mean: -1.05231
[32m[0907 00-18-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29523, current rewards: -2636.06478, mean: -1.07157
[32m[0907 00-19-04 @Agent.py:117][0m Average action selection time: 0.2952
[32m[0907 00-19-04 @Agent.py:118][0m Rollout length: 2600
[32m[0907 00-19-04 @MBExp.py:227][0m Rewards obtained: [-2716.064779226882], Lows: [1258], Highs: [400], Total time: 27446.806644999997
[32m[0907 00-19-32 @MBExp.py:144][0m ####################################################################
[32m[0907 00-19-32 @MBExp.py:145][0m Starting training iteration 37.
[32m[0907 00-19-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29287, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-19-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29270, current rewards: -60.00000, mean: -1.00000
[32m[0907 00-20-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29281, current rewards: -103.40084, mean: -0.94001
[32m[0907 00-20-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29566, current rewards: -203.40084, mean: -1.27126
[32m[0907 00-20-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29617, current rewards: -271.07664, mean: -1.29084
[32m[0907 00-20-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29571, current rewards: -299.80835, mean: -1.15311
[32m[0907 00-21-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29768, current rewards: -389.75591, mean: -1.25728
[32m[0907 00-21-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30080, current rewards: -408.96206, mean: -1.13601
[32m[0907 00-21-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30124, current rewards: -416.02167, mean: -1.01469
[32m[0907 00-21-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30076, current rewards: -440.49213, mean: -0.95759
[32m[0907 00-22-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30017, current rewards: -504.99361, mean: -0.99018
[32m[0907 00-22-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30458, current rewards: -550.81229, mean: -0.98359
[32m[0907 00-22-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30443, current rewards: -637.30386, mean: -1.04476
[32m[0907 00-22-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30371, current rewards: -720.24003, mean: -1.09127
[32m[0907 00-23-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30876, current rewards: -733.80043, mean: -1.03352
[32m[0907 00-23-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30900, current rewards: -757.99268, mean: -0.99736
[32m[0907 00-23-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30995, current rewards: -782.61254, mean: -0.96619
[32m[0907 00-23-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31035, current rewards: -798.65753, mean: -0.92867
[32m[0907 00-24-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30995, current rewards: -818.44501, mean: -0.89939
[32m[0907 00-24-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30988, current rewards: -816.03742, mean: -0.85004
[32m[0907 00-24-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31186, current rewards: -810.39249, mean: -0.80237
[32m[0907 00-25-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31106, current rewards: -837.54903, mean: -0.79014
[32m[0907 00-25-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31060, current rewards: -850.40022, mean: -0.76613
[32m[0907 00-25-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31076, current rewards: -851.50976, mean: -0.73406
[32m[0907 00-25-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31011, current rewards: -894.62584, mean: -0.73936
[32m[0907 00-26-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30950, current rewards: -983.24835, mean: -0.78036
[32m[0907 00-26-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30969, current rewards: -1009.25932, mean: -0.77043
[32m[0907 00-26-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31039, current rewards: -1058.20257, mean: -0.77809
[32m[0907 00-26-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31042, current rewards: -1116.03574, mean: -0.79151
[32m[0907 00-27-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30988, current rewards: -1191.30135, mean: -0.81596
[32m[0907 00-27-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30940, current rewards: -1291.30135, mean: -0.85517
[32m[0907 00-27-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30895, current rewards: -1391.30135, mean: -0.89186
[32m[0907 00-27-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30852, current rewards: -1491.30135, mean: -0.92627
[32m[0907 00-28-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30907, current rewards: -1588.70070, mean: -0.95705
[32m[0907 00-28-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30894, current rewards: -1688.70070, mean: -0.98754
[32m[0907 00-28-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30854, current rewards: -1772.36154, mean: -1.00702
[32m[0907 00-28-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30832, current rewards: -1805.80230, mean: -0.99768
[32m[0907 00-29-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30801, current rewards: -1802.41841, mean: -0.96904
[32m[0907 00-29-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30771, current rewards: -1849.22741, mean: -0.96818
[32m[0907 00-29-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30739, current rewards: -1940.77951, mean: -0.99019
[32m[0907 00-29-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30708, current rewards: -1979.81855, mean: -0.98498
[32m[0907 00-30-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30678, current rewards: -2079.81855, mean: -1.00962
[32m[0907 00-30-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30650, current rewards: -2158.48134, mean: -1.02298
[32m[0907 00-30-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30624, current rewards: -2236.48993, mean: -1.03541
[32m[0907 00-30-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30604, current rewards: -2336.48993, mean: -1.05724
[32m[0907 00-31-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30579, current rewards: -2394.25385, mean: -1.05940
[32m[0907 00-31-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30581, current rewards: -2494.25385, mean: -1.07976
[32m[0907 00-31-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30558, current rewards: -2574.99397, mean: -1.09110
[32m[0907 00-31-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30536, current rewards: -2639.18576, mean: -1.09510
[32m[0907 00-32-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30515, current rewards: -2739.18576, mean: -1.11349
[32m[0907 00-32-15 @Agent.py:117][0m Average action selection time: 0.3050
[32m[0907 00-32-15 @Agent.py:118][0m Rollout length: 2600
[32m[0907 00-32-15 @MBExp.py:227][0m Rewards obtained: [-2802.319708216852], Lows: [1194], Highs: [530], Total time: 28209.586563999997
[32m[0907 00-32-42 @MBExp.py:144][0m ####################################################################
[32m[0907 00-32-42 @MBExp.py:145][0m Starting training iteration 38.
[32m[0907 00-32-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29249, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-32-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29279, current rewards: -60.00000, mean: -1.00000
[32m[0907 00-33-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29298, current rewards: -120.00000, mean: -1.09091
[32m[0907 00-33-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29330, current rewards: -220.00000, mean: -1.37500
[32m[0907 00-33-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29346, current rewards: -320.00000, mean: -1.52381
[32m[0907 00-33-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29353, current rewards: -420.00000, mean: -1.61538
[32m[0907 00-34-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29360, current rewards: -520.00000, mean: -1.67742
[32m[0907 00-34-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29379, current rewards: -620.00000, mean: -1.72222
[32m[0907 00-34-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29391, current rewards: -720.00000, mean: -1.75610
[32m[0907 00-34-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29401, current rewards: -820.00000, mean: -1.78261
[32m[0907 00-35-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29413, current rewards: -920.00000, mean: -1.80392
[32m[0907 00-35-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29420, current rewards: -1020.00000, mean: -1.82143
[32m[0907 00-35-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29427, current rewards: -1120.00000, mean: -1.83607
[32m[0907 00-35-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29431, current rewards: -1220.00000, mean: -1.84848
[32m[0907 00-36-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29436, current rewards: -1320.00000, mean: -1.85915
[32m[0907 00-36-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29439, current rewards: -1420.00000, mean: -1.86842
[32m[0907 00-36-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29442, current rewards: -1520.00000, mean: -1.87654
[32m[0907 00-36-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29445, current rewards: -1620.00000, mean: -1.88372
[32m[0907 00-37-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29446, current rewards: -1720.00000, mean: -1.89011
[32m[0907 00-37-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29448, current rewards: -1820.00000, mean: -1.89583
[32m[0907 00-37-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29451, current rewards: -1920.00000, mean: -1.90099
[32m[0907 00-37-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29454, current rewards: -2020.00000, mean: -1.90566
[32m[0907 00-38-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29458, current rewards: -2120.00000, mean: -1.90991
[32m[0907 00-38-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29459, current rewards: -2220.00000, mean: -1.91379
[32m[0907 00-38-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29460, current rewards: -2320.00000, mean: -1.91736
[32m[0907 00-38-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29461, current rewards: -2420.00000, mean: -1.92063
[32m[0907 00-39-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29463, current rewards: -2520.00000, mean: -1.92366
[32m[0907 00-39-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29464, current rewards: -2620.00000, mean: -1.92647
[32m[0907 00-39-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29463, current rewards: -2720.00000, mean: -1.92908
[32m[0907 00-39-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29464, current rewards: -2820.00000, mean: -1.93151
[32m[0907 00-40-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29464, current rewards: -2920.00000, mean: -1.93377
[32m[0907 00-40-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29464, current rewards: -3020.00000, mean: -1.93590
[32m[0907 00-40-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29465, current rewards: -3120.00000, mean: -1.93789
[32m[0907 00-40-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29465, current rewards: -3220.00000, mean: -1.93976
[32m[0907 00-41-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29465, current rewards: -3320.00000, mean: -1.94152
[32m[0907 00-41-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29467, current rewards: -3420.00000, mean: -1.94318
[32m[0907 00-41-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29467, current rewards: -3520.00000, mean: -1.94475
[32m[0907 00-41-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29468, current rewards: -3620.00000, mean: -1.94624
[32m[0907 00-42-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29468, current rewards: -3720.00000, mean: -1.94764
[32m[0907 00-42-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29468, current rewards: -3820.00000, mean: -1.94898
[32m[0907 00-42-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29469, current rewards: -3920.00000, mean: -1.95025
[32m[0907 00-42-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29470, current rewards: -4020.00000, mean: -1.95146
[32m[0907 00-43-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29471, current rewards: -4120.00000, mean: -1.95261
[32m[0907 00-43-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29472, current rewards: -4220.00000, mean: -1.95370
[32m[0907 00-43-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29472, current rewards: -4320.00000, mean: -1.95475
[32m[0907 00-43-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29472, current rewards: -4420.00000, mean: -1.95575
[32m[0907 00-44-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29473, current rewards: -4520.00000, mean: -1.95671
[32m[0907 00-44-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29473, current rewards: -4620.00000, mean: -1.95763
[32m[0907 00-44-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29474, current rewards: -4720.00000, mean: -1.95851
[32m[0907 00-44-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29474, current rewards: -4820.00000, mean: -1.95935
[32m[0907 00-44-59 @Agent.py:117][0m Average action selection time: 0.2947
[32m[0907 00-44-59 @Agent.py:118][0m Rollout length: 2600
[32m[0907 00-44-59 @MBExp.py:227][0m Rewards obtained: [-4900], Lows: [2400], Highs: [100], Total time: 28946.743109999996
[32m[0907 00-45-28 @MBExp.py:144][0m ####################################################################
[32m[0907 00-45-28 @MBExp.py:145][0m Starting training iteration 39.
[32m[0907 00-45-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31201, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-45-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29561, current rewards: -60.00000, mean: -1.00000
[32m[0907 00-46-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29445, current rewards: -119.00000, mean: -1.08182
[32m[0907 00-46-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29434, current rewards: -193.76343, mean: -1.21102
[32m[0907 00-46-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29419, current rewards: -227.71281, mean: -1.08435
[32m[0907 00-46-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29415, current rewards: -277.71281, mean: -1.06813
[32m[0907 00-46-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29413, current rewards: -293.37214, mean: -0.94636
[32m[0907 00-47-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29423, current rewards: -313.56766, mean: -0.87102
[32m[0907 00-47-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29433, current rewards: -342.07221, mean: -0.83432
[32m[0907 00-47-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29440, current rewards: -392.07221, mean: -0.85233
[32m[0907 00-47-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29447, current rewards: -425.10259, mean: -0.83353
[32m[0907 00-48-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29449, current rewards: -453.64114, mean: -0.81007
[32m[0907 00-48-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29455, current rewards: -503.64114, mean: -0.82564
[32m[0907 00-48-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29458, current rewards: -529.70017, mean: -0.80258
[32m[0907 00-48-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29459, current rewards: -538.88415, mean: -0.75899
[32m[0907 00-49-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29463, current rewards: -575.04078, mean: -0.75663
[32m[0907 00-49-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29464, current rewards: -620.38928, mean: -0.76591
[32m[0907 00-49-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29465, current rewards: -671.58992, mean: -0.78092
[32m[0907 00-49-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29466, current rewards: -676.62290, mean: -0.74354
[32m[0907 00-50-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29469, current rewards: -697.78479, mean: -0.72686
[32m[0907 00-50-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29469, current rewards: -697.13508, mean: -0.69023
[32m[0907 00-50-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29470, current rewards: -736.63357, mean: -0.69494
[32m[0907 00-50-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29472, current rewards: -777.13570, mean: -0.70012
[32m[0907 00-51-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29473, current rewards: -766.62993, mean: -0.66089
[32m[0907 00-51-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29475, current rewards: -782.50551, mean: -0.64670
[32m[0907 00-51-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29476, current rewards: -778.47997, mean: -0.61784
[32m[0907 00-51-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29478, current rewards: -773.39089, mean: -0.59037
[32m[0907 00-52-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29480, current rewards: -823.39089, mean: -0.60543
[32m[0907 00-52-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29482, current rewards: -873.39089, mean: -0.61943
[32m[0907 00-52-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29484, current rewards: -960.53542, mean: -0.65790
[32m[0907 00-52-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29485, current rewards: -1060.53542, mean: -0.70234
[32m[0907 00-53-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29486, current rewards: -1075.66422, mean: -0.68953
[32m[0907 00-53-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29488, current rewards: -1125.66422, mean: -0.69917
[32m[0907 00-53-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29488, current rewards: -1171.20398, mean: -0.70554
[32m[0907 00-53-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29490, current rewards: -1224.30201, mean: -0.71597
[32m[0907 00-54-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29490, current rewards: -1317.85075, mean: -0.74878
[32m[0907 00-54-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29489, current rewards: -1321.37324, mean: -0.73004
[32m[0907 00-54-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29490, current rewards: -1316.79926, mean: -0.70796
[32m[0907 00-54-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29490, current rewards: -1328.22568, mean: -0.69541
[32m[0907 00-55-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29490, current rewards: -1325.66857, mean: -0.67636
[32m[0907 00-55-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29491, current rewards: -1323.11145, mean: -0.65826
[32m[0907 00-55-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29491, current rewards: -1320.55433, mean: -0.64105
[32m[0907 00-55-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29491, current rewards: -1345.32692, mean: -0.63760
[32m[0907 00-56-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29491, current rewards: -1395.32692, mean: -0.64598
[32m[0907 00-56-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29492, current rewards: -1445.32692, mean: -0.65399
[32m[0907 00-56-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29492, current rewards: -1495.32692, mean: -0.66165
[32m[0907 00-56-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29492, current rewards: -1545.32692, mean: -0.66897
[32m[0907 00-57-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29493, current rewards: -1595.32692, mean: -0.67599
[32m[0907 00-57-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29493, current rewards: -1645.32692, mean: -0.68271
[32m[0907 00-57-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29492, current rewards: -1695.32692, mean: -0.68916
[32m[0907 00-57-45 @Agent.py:117][0m Average action selection time: 0.2949
[32m[0907 00-57-45 @Agent.py:118][0m Rollout length: 2600
[32m[0907 00-57-45 @MBExp.py:227][0m Rewards obtained: [-1735.3269168937918], Lows: [345], Highs: [1164], Total time: 29684.354319999995
[32m[0907 00-58-14 @MBExp.py:144][0m ####################################################################
[32m[0907 00-58-14 @MBExp.py:145][0m Starting training iteration 40.
[32m[0907 00-58-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29277, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-58-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29273, current rewards: -60.00000, mean: -1.00000
[32m[0907 00-58-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29284, current rewards: -120.00000, mean: -1.09091
[32m[0907 00-59-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29618, current rewards: -122.36626, mean: -0.76479
[32m[0907 00-59-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29570, current rewards: -142.63454, mean: -0.67921
[32m[0907 00-59-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29537, current rewards: -197.32564, mean: -0.75894
[32m[0907 00-59-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29545, current rewards: -194.21638, mean: -0.62650
[32m[0907 01-00-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29538, current rewards: -219.49019, mean: -0.60969
[32m[0907 01-00-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29535, current rewards: -245.27041, mean: -0.59822
[32m[0907 01-00-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29531, current rewards: -254.39963, mean: -0.55304
[32m[0907 01-00-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29529, current rewards: -324.19602, mean: -0.63568
[32m[0907 01-01-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29526, current rewards: -341.48606, mean: -0.60980
[32m[0907 01-01-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29524, current rewards: -334.40258, mean: -0.54820
[32m[0907 01-01-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29523, current rewards: -330.22975, mean: -0.50035
[32m[0907 01-01-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29521, current rewards: -363.50212, mean: -0.51197
[32m[0907 01-01-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29521, current rewards: -439.28223, mean: -0.57800
[32m[0907 01-02-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29521, current rewards: -434.51113, mean: -0.53643
[32m[0907 01-02-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29521, current rewards: -430.33830, mean: -0.50039
[32m[0907 01-02-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29519, current rewards: -457.58570, mean: -0.50284
[32m[0907 01-02-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29518, current rewards: -507.58570, mean: -0.52874
[32m[0907 01-03-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29518, current rewards: -557.58570, mean: -0.55207
[32m[0907 01-03-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29519, current rewards: -607.58570, mean: -0.57319
[32m[0907 01-03-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29517, current rewards: -657.58570, mean: -0.59242
[32m[0907 01-03-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29518, current rewards: -707.58570, mean: -0.60999
[32m[0907 01-04-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29518, current rewards: -757.58570, mean: -0.62610
[32m[0907 01-04-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29516, current rewards: -807.58570, mean: -0.64094
[32m[0907 01-04-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29514, current rewards: -857.58570, mean: -0.65465
[32m[0907 01-04-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29513, current rewards: -907.58570, mean: -0.66734
[32m[0907 01-05-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29511, current rewards: -957.58570, mean: -0.67914
[32m[0907 01-05-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29511, current rewards: -1007.58570, mean: -0.69013
[32m[0907 01-05-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29510, current rewards: -1057.58570, mean: -0.70039
[32m[0907 01-05-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29509, current rewards: -1107.58570, mean: -0.70999
[32m[0907 01-06-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29508, current rewards: -1157.58570, mean: -0.71900
[32m[0907 01-06-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29507, current rewards: -1207.58570, mean: -0.72746
[32m[0907 01-06-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29506, current rewards: -1257.58570, mean: -0.73543
[32m[0907 01-06-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29504, current rewards: -1307.58570, mean: -0.74295
[32m[0907 01-07-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29504, current rewards: -1357.58570, mean: -0.75005
[32m[0907 01-07-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29504, current rewards: -1407.58570, mean: -0.75677
[32m[0907 01-07-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29502, current rewards: -1457.58570, mean: -0.76313
[32m[0907 01-07-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29501, current rewards: -1507.58570, mean: -0.76918
[32m[0907 01-08-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29501, current rewards: -1557.58570, mean: -0.77492
[32m[0907 01-08-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29500, current rewards: -1607.58570, mean: -0.78038
[32m[0907 01-08-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29499, current rewards: -1657.58570, mean: -0.78559
[32m[0907 01-08-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29498, current rewards: -1707.58570, mean: -0.79055
[32m[0907 01-09-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29498, current rewards: -1757.58570, mean: -0.79529
[32m[0907 01-09-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29497, current rewards: -1807.58570, mean: -0.79982
[32m[0907 01-09-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29497, current rewards: -1857.58570, mean: -0.80415
[32m[0907 01-09-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29496, current rewards: -1907.58570, mean: -0.80830
[32m[0907 01-10-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29496, current rewards: -1957.58570, mean: -0.81228
[32m[0907 01-10-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29495, current rewards: -2007.58570, mean: -0.81609
[32m[0907 01-10-32 @Agent.py:117][0m Average action selection time: 0.2950
[32m[0907 01-10-32 @Agent.py:118][0m Rollout length: 2600
[32m[0907 01-10-32 @MBExp.py:227][0m Rewards obtained: [-2047.5857049267547], Lows: [167], Highs: [1785], Total time: 30422.048254999994
[32m[0907 01-11-02 @MBExp.py:144][0m ####################################################################
[32m[0907 01-11-02 @MBExp.py:145][0m Starting training iteration 41.
[32m[0907 01-11-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29276, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-11-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29285, current rewards: -60.00000, mean: -1.00000
[32m[0907 01-11-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29289, current rewards: -100.16115, mean: -0.91056
[32m[0907 01-11-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29319, current rewards: -120.41291, mean: -0.75258
[32m[0907 01-12-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29338, current rewards: -209.88958, mean: -0.99947
[32m[0907 01-12-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29353, current rewards: -252.51715, mean: -0.97122
[32m[0907 01-12-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29365, current rewards: -273.84209, mean: -0.88336
[32m[0907 01-12-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29549, current rewards: -317.09500, mean: -0.88082
[32m[0907 01-13-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29563, current rewards: -329.03331, mean: -0.80252
[32m[0907 01-13-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29772, current rewards: -366.18604, mean: -0.79606
[32m[0907 01-13-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29745, current rewards: -417.36501, mean: -0.81836
[32m[0907 01-13-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29722, current rewards: -427.58897, mean: -0.76355
[32m[0907 01-14-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29737, current rewards: -461.57969, mean: -0.75669
[32m[0907 01-14-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29841, current rewards: -497.62132, mean: -0.75397
[32m[0907 01-14-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29887, current rewards: -547.62132, mean: -0.77130
[32m[0907 01-14-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29954, current rewards: -596.57695, mean: -0.78497
[32m[0907 01-15-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30109, current rewards: -644.44848, mean: -0.79562
[32m[0907 01-15-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30200, current rewards: -683.10063, mean: -0.79430
[32m[0907 01-15-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30270, current rewards: -730.97291, mean: -0.80327
[32m[0907 01-15-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30240, current rewards: -775.76247, mean: -0.80809
[32m[0907 01-16-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30280, current rewards: -825.51300, mean: -0.81734
[32m[0907 01-16-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30280, current rewards: -873.32184, mean: -0.82389
[32m[0907 01-16-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30264, current rewards: -915.78091, mean: -0.82503
[32m[0907 01-16-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30231, current rewards: -987.70415, mean: -0.85147
[32m[0907 01-17-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30266, current rewards: -1036.70491, mean: -0.85678
[32m[0907 01-17-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30258, current rewards: -1056.34957, mean: -0.83837
[32m[0907 01-17-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30349, current rewards: -1096.39566, mean: -0.83694
[32m[0907 01-17-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30318, current rewards: -1152.62441, mean: -0.84752
[32m[0907 01-18-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30345, current rewards: -1176.68659, mean: -0.83453
[32m[0907 01-18-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30316, current rewards: -1241.96245, mean: -0.85066
[32m[0907 01-18-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30289, current rewards: -1339.71191, mean: -0.88723
[32m[0907 01-18-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30263, current rewards: -1429.22101, mean: -0.91617
[32m[0907 01-19-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30238, current rewards: -1522.81702, mean: -0.94585
[32m[0907 01-19-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30216, current rewards: -1521.25680, mean: -0.91642
[32m[0907 01-19-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30195, current rewards: -1538.52523, mean: -0.89972
[32m[0907 01-19-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30175, current rewards: -1602.96831, mean: -0.91078
[32m[0907 01-20-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30156, current rewards: -1658.07829, mean: -0.91607
[32m[0907 01-20-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30138, current rewards: -1758.07829, mean: -0.94520
[32m[0907 01-20-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30121, current rewards: -1776.73241, mean: -0.93023
[32m[0907 01-20-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30109, current rewards: -1781.05517, mean: -0.90870
[32m[0907 01-21-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30094, current rewards: -1824.55684, mean: -0.90774
[32m[0907 01-21-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30079, current rewards: -1867.15268, mean: -0.90638
[32m[0907 01-21-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30065, current rewards: -1917.15268, mean: -0.90860
[32m[0907 01-21-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30051, current rewards: -1967.15268, mean: -0.91072
[32m[0907 01-22-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30038, current rewards: -2017.15268, mean: -0.91274
[32m[0907 01-22-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30025, current rewards: -2067.15268, mean: -0.91467
[32m[0907 01-22-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30013, current rewards: -2117.15268, mean: -0.91652
[32m[0907 01-22-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30002, current rewards: -2167.15268, mean: -0.91829
[32m[0907 01-23-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29991, current rewards: -2217.15268, mean: -0.91998
[32m[0907 01-23-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29980, current rewards: -2267.15268, mean: -0.92161
[32m[0907 01-23-31 @Agent.py:117][0m Average action selection time: 0.2997
[32m[0907 01-23-31 @Agent.py:118][0m Rollout length: 2600
[32m[0907 01-23-31 @MBExp.py:227][0m Rewards obtained: [-2307.152683562135], Lows: [494], Highs: [1423], Total time: 31171.649239999995
[32m[0907 01-24-03 @MBExp.py:144][0m ####################################################################
[32m[0907 01-24-03 @MBExp.py:145][0m Starting training iteration 42.
[32m[0907 01-24-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29236, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-24-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29245, current rewards: -60.00000, mean: -1.00000
[32m[0907 01-24-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30587, current rewards: -99.14353, mean: -0.90130
[32m[0907 01-24-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30328, current rewards: -101.74697, mean: -0.63592
[32m[0907 01-25-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31410, current rewards: -160.63780, mean: -0.76494
[32m[0907 01-25-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31027, current rewards: -161.95548, mean: -0.62291
[32m[0907 01-25-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30895, current rewards: -201.27475, mean: -0.64927
[32m[0907 01-25-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30780, current rewards: -251.27475, mean: -0.69799
[32m[0907 01-26-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31292, current rewards: -295.92386, mean: -0.72177
[32m[0907 01-26-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31096, current rewards: -340.65443, mean: -0.74055
[32m[0907 01-26-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30942, current rewards: -394.32084, mean: -0.77318
[32m[0907 01-26-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30816, current rewards: -444.32084, mean: -0.79343
[32m[0907 01-27-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30709, current rewards: -476.35423, mean: -0.78091
[32m[0907 01-27-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30619, current rewards: -504.94065, mean: -0.76506
[32m[0907 01-27-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30539, current rewards: -541.60486, mean: -0.76282
[32m[0907 01-27-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30471, current rewards: -556.68225, mean: -0.73248
[32m[0907 01-28-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30424, current rewards: -573.60641, mean: -0.70816
[32m[0907 01-28-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30373, current rewards: -562.96362, mean: -0.65461
[32m[0907 01-28-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30369, current rewards: -605.19002, mean: -0.66504
[32m[0907 01-28-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30323, current rewards: -591.46644, mean: -0.61611
[32m[0907 01-29-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30304, current rewards: -586.93198, mean: -0.58112
[32m[0907 01-29-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30265, current rewards: -620.44022, mean: -0.58532
[32m[0907 01-29-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30335, current rewards: -671.65442, mean: -0.60509
[32m[0907 01-29-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30299, current rewards: -719.20774, mean: -0.62001
[32m[0907 01-30-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30264, current rewards: -801.80567, mean: -0.66265
[32m[0907 01-30-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30233, current rewards: -901.80567, mean: -0.71572
[32m[0907 01-30-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30203, current rewards: -963.69755, mean: -0.73565
[32m[0907 01-30-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30177, current rewards: -956.11387, mean: -0.70302
[32m[0907 01-31-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30152, current rewards: -951.52353, mean: -0.67484
[32m[0907 01-31-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30149, current rewards: -945.29501, mean: -0.64746
[32m[0907 01-31-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30179, current rewards: -978.60718, mean: -0.64808
[32m[0907 01-31-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30156, current rewards: -1039.50482, mean: -0.66635
[32m[0907 01-32-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30135, current rewards: -1042.61580, mean: -0.64759
[32m[0907 01-32-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30116, current rewards: -1039.53848, mean: -0.62623
[32m[0907 01-32-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30097, current rewards: -1058.27613, mean: -0.61887
[32m[0907 01-32-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30080, current rewards: -1081.57044, mean: -0.61453
[32m[0907 01-33-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30064, current rewards: -1131.57044, mean: -0.62518
[32m[0907 01-33-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30049, current rewards: -1170.89468, mean: -0.62951
[32m[0907 01-33-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30033, current rewards: -1168.31963, mean: -0.61169
[32m[0907 01-33-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30019, current rewards: -1184.29555, mean: -0.60423
[32m[0907 01-34-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30005, current rewards: -1180.67375, mean: -0.58740
[32m[0907 01-34-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29992, current rewards: -1204.60179, mean: -0.58476
[32m[0907 01-34-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29980, current rewards: -1200.36085, mean: -0.56889
[32m[0907 01-34-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29968, current rewards: -1211.91334, mean: -0.56107
[32m[0907 01-35-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29957, current rewards: -1241.04722, mean: -0.56156
[32m[0907 01-35-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29995, current rewards: -1233.70172, mean: -0.54589
[32m[0907 01-35-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29983, current rewards: -1280.95277, mean: -0.55453
[32m[0907 01-35-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29973, current rewards: -1342.07160, mean: -0.56867
[32m[0907 01-36-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29963, current rewards: -1392.07160, mean: -0.57762
[32m[0907 01-36-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29953, current rewards: -1437.55604, mean: -0.58437
[32m[0907 01-36-32 @Agent.py:117][0m Average action selection time: 0.2995
[32m[0907 01-36-32 @Agent.py:118][0m Rollout length: 2600
[32m[0907 01-36-32 @MBExp.py:227][0m Rewards obtained: [-1434.6642214174167], Lows: [472], Highs: [715], Total time: 31920.584180999995
[32m[0907 01-37-04 @MBExp.py:144][0m ####################################################################
[32m[0907 01-37-04 @MBExp.py:145][0m Starting training iteration 43.
[32m[0907 01-37-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29218, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-37-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29260, current rewards: -60.00000, mean: -1.00000
[32m[0907 01-37-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29261, current rewards: -117.93108, mean: -1.07210
[32m[0907 01-37-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29295, current rewards: -217.93108, mean: -1.36207
[32m[0907 01-38-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29312, current rewards: -289.32400, mean: -1.37773
[32m[0907 01-38-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29334, current rewards: -389.32400, mean: -1.49740
[32m[0907 01-38-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29347, current rewards: -479.73206, mean: -1.54752
[32m[0907 01-38-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29361, current rewards: -579.73206, mean: -1.61037
[32m[0907 01-39-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29378, current rewards: -669.26654, mean: -1.63236
[32m[0907 01-39-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29392, current rewards: -769.26654, mean: -1.67232
[32m[0907 01-39-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29399, current rewards: -869.26654, mean: -1.70444
[32m[0907 01-39-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29407, current rewards: -969.26654, mean: -1.73083
[32m[0907 01-40-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29413, current rewards: -1069.26654, mean: -1.75290
[32m[0907 01-40-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29416, current rewards: -1169.26654, mean: -1.77162
[32m[0907 01-40-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29420, current rewards: -1269.26654, mean: -1.78770
[32m[0907 01-40-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29426, current rewards: -1369.26654, mean: -1.80167
[32m[0907 01-41-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29430, current rewards: -1469.26654, mean: -1.81391
[32m[0907 01-41-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29434, current rewards: -1569.26654, mean: -1.82473
[32m[0907 01-41-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29438, current rewards: -1669.26654, mean: -1.83436
[32m[0907 01-41-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29441, current rewards: -1769.26654, mean: -1.84299
[32m[0907 01-42-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29444, current rewards: -1869.26654, mean: -1.85076
[32m[0907 01-42-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29448, current rewards: -1969.26654, mean: -1.85780
[32m[0907 01-42-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29451, current rewards: -2069.26654, mean: -1.86420
[32m[0907 01-42-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29452, current rewards: -2169.26654, mean: -1.87006
[32m[0907 01-43-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29454, current rewards: -2269.26654, mean: -1.87543
[32m[0907 01-43-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29456, current rewards: -2369.26654, mean: -1.88037
[32m[0907 01-43-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29457, current rewards: -2469.26654, mean: -1.88494
[32m[0907 01-43-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29458, current rewards: -2569.26654, mean: -1.88917
[32m[0907 01-44-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29460, current rewards: -2669.26654, mean: -1.89310
[32m[0907 01-44-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29461, current rewards: -2769.26654, mean: -1.89676
[32m[0907 01-44-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29462, current rewards: -2869.26654, mean: -1.90018
[32m[0907 01-44-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29463, current rewards: -2969.26654, mean: -1.90338
[32m[0907 01-44-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29462, current rewards: -3069.26654, mean: -1.90638
[32m[0907 01-45-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29462, current rewards: -3169.26654, mean: -1.90920
[32m[0907 01-45-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29462, current rewards: -3269.26654, mean: -1.91185
[32m[0907 01-45-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29461, current rewards: -3369.26654, mean: -1.91436
[32m[0907 01-45-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29462, current rewards: -3469.26654, mean: -1.91672
[32m[0907 01-46-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29462, current rewards: -3569.26654, mean: -1.91896
[32m[0907 01-46-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29463, current rewards: -3669.26654, mean: -1.92108
[32m[0907 01-46-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29463, current rewards: -3769.26654, mean: -1.92310
[32m[0907 01-46-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29464, current rewards: -3869.26654, mean: -1.92501
[32m[0907 01-47-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29464, current rewards: -3969.26654, mean: -1.92683
[32m[0907 01-47-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29463, current rewards: -4069.26654, mean: -1.92856
[32m[0907 01-47-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29464, current rewards: -4169.26654, mean: -1.93022
[32m[0907 01-47-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29465, current rewards: -4269.26654, mean: -1.93179
[32m[0907 01-48-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29465, current rewards: -4369.26654, mean: -1.93330
[32m[0907 01-48-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29465, current rewards: -4469.26654, mean: -1.93475
[32m[0907 01-48-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29465, current rewards: -4569.26654, mean: -1.93613
[32m[0907 01-48-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29464, current rewards: -4669.26654, mean: -1.93745
[32m[0907 01-49-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29464, current rewards: -4769.26654, mean: -1.93873
[32m[0907 01-49-21 @Agent.py:117][0m Average action selection time: 0.2946
[32m[0907 01-49-21 @Agent.py:118][0m Rollout length: 2600
[32m[0907 01-49-21 @MBExp.py:227][0m Rewards obtained: [-4849.2665397646715], Lows: [2378], Highs: [100], Total time: 32657.506991999995
[32m[0907 01-49-52 @MBExp.py:144][0m ####################################################################
[32m[0907 01-49-52 @MBExp.py:145][0m Starting training iteration 44.
[32m[0907 01-49-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29268, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-50-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29283, current rewards: -60.00000, mean: -1.00000
[32m[0907 01-50-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29291, current rewards: -100.39533, mean: -0.91268
[32m[0907 01-50-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29321, current rewards: -127.51981, mean: -0.79700
[32m[0907 01-50-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29343, current rewards: -135.99516, mean: -0.64760
[32m[0907 01-51-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29358, current rewards: -164.74957, mean: -0.63365
[32m[0907 01-51-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29370, current rewards: -155.89064, mean: -0.50287
[32m[0907 01-51-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29385, current rewards: -188.14227, mean: -0.52262
[32m[0907 01-51-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29400, current rewards: -238.14227, mean: -0.58083
[32m[0907 01-52-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29415, current rewards: -275.35316, mean: -0.59859
[32m[0907 01-52-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29426, current rewards: -316.93192, mean: -0.62144
[32m[0907 01-52-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29435, current rewards: -350.98929, mean: -0.62677
[32m[0907 01-52-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29456, current rewards: -384.17738, mean: -0.62980
[32m[0907 01-53-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29462, current rewards: -484.17738, mean: -0.73360
[32m[0907 01-53-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29478, current rewards: -565.24595, mean: -0.79612
[32m[0907 01-53-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29478, current rewards: -620.50611, mean: -0.81646
[32m[0907 01-53-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29479, current rewards: -682.95238, mean: -0.84315
[32m[0907 01-54-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29481, current rewards: -740.45532, mean: -0.86099
[32m[0907 01-54-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29483, current rewards: -786.09711, mean: -0.86384
[32m[0907 01-54-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29484, current rewards: -876.77603, mean: -0.91331
[32m[0907 01-54-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29485, current rewards: -932.91537, mean: -0.92368
[32m[0907 01-55-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29485, current rewards: -983.46519, mean: -0.92780
[32m[0907 01-55-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29484, current rewards: -1008.20775, mean: -0.90830
[32m[0907 01-55-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29484, current rewards: -1061.07798, mean: -0.91472
[32m[0907 01-55-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29484, current rewards: -1064.94800, mean: -0.88012
[32m[0907 01-56-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29483, current rewards: -1086.53906, mean: -0.86233
[32m[0907 01-56-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29484, current rewards: -1186.53906, mean: -0.90576
[32m[0907 01-56-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29485, current rewards: -1262.98898, mean: -0.92867
[32m[0907 01-56-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29484, current rewards: -1280.87388, mean: -0.90842
[32m[0907 01-57-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29484, current rewards: -1362.86046, mean: -0.93347
[32m[0907 01-57-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29485, current rewards: -1432.78848, mean: -0.94887
[32m[0907 01-57-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29486, current rewards: -1446.72711, mean: -0.92739
[32m[0907 01-57-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29486, current rewards: -1546.72711, mean: -0.96070
[32m[0907 01-58-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29486, current rewards: -1623.94661, mean: -0.97828
[32m[0907 01-58-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29486, current rewards: -1626.41444, mean: -0.95112
[32m[0907 01-58-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29485, current rewards: -1631.24615, mean: -0.92684
[32m[0907 01-58-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29485, current rewards: -1731.24615, mean: -0.95649
[32m[0907 01-59-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29484, current rewards: -1754.97492, mean: -0.94353
[32m[0907 01-59-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29484, current rewards: -1758.20618, mean: -0.92053
[32m[0907 01-59-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29484, current rewards: -1808.20618, mean: -0.92255
[32m[0907 01-59-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29484, current rewards: -1858.20618, mean: -0.92448
[32m[0907 01-59-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29483, current rewards: -1908.20618, mean: -0.92631
[32m[0907 02-00-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29483, current rewards: -1958.20618, mean: -0.92806
[32m[0907 02-00-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29484, current rewards: -2008.20618, mean: -0.92973
[32m[0907 02-00-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29483, current rewards: -2058.20618, mean: -0.93132
[32m[0907 02-00-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29483, current rewards: -2108.20618, mean: -0.93283
[32m[0907 02-01-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29482, current rewards: -2158.20618, mean: -0.93429
[32m[0907 02-01-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29482, current rewards: -2208.20618, mean: -0.93568
[32m[0907 02-01-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29481, current rewards: -2258.20618, mean: -0.93702
[32m[0907 02-01-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29481, current rewards: -2308.20618, mean: -0.93830
[32m[0907 02-02-09 @Agent.py:117][0m Average action selection time: 0.2948
[32m[0907 02-02-09 @Agent.py:118][0m Rollout length: 2600
[32m[0907 02-02-09 @MBExp.py:227][0m Rewards obtained: [-2348.206176433215], Lows: [805], Highs: [880], Total time: 33394.836172999996
[32m[0907 02-02-40 @MBExp.py:144][0m ####################################################################
[32m[0907 02-02-40 @MBExp.py:145][0m Starting training iteration 45.
[32m[0907 02-02-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29262, current rewards: 0.83374, mean: 0.08337
[32m[0907 02-02-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29244, current rewards: 4.91265, mean: 0.08188
[32m[0907 02-03-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29266, current rewards: 9.37974, mean: 0.08527
[32m[0907 02-03-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29305, current rewards: 13.83849, mean: 0.08649
[32m[0907 02-03-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29319, current rewards: 18.29724, mean: 0.08713
[32m[0907 02-03-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29334, current rewards: 22.75598, mean: 0.08752
[32m[0907 02-04-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29343, current rewards: 27.21473, mean: 0.08779
[32m[0907 02-04-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29353, current rewards: 26.22760, mean: 0.07285
[32m[0907 02-04-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29370, current rewards: -23.77240, mean: -0.05798
[32m[0907 02-04-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29383, current rewards: -73.77240, mean: -0.16037
[32m[0907 02-05-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29395, current rewards: -123.77240, mean: -0.24269
[32m[0907 02-05-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29402, current rewards: -200.53887, mean: -0.35811
[32m[0907 02-05-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29411, current rewards: -300.53887, mean: -0.49269
[32m[0907 02-05-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29417, current rewards: -328.41489, mean: -0.49760
[32m[0907 02-06-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29420, current rewards: -363.76096, mean: -0.51234
[32m[0907 02-06-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29425, current rewards: -463.76096, mean: -0.61021
[32m[0907 02-06-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29428, current rewards: -524.27309, mean: -0.64725
[32m[0907 02-06-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29430, current rewards: -532.33981, mean: -0.61900
[32m[0907 02-07-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29434, current rewards: -620.32727, mean: -0.68168
[32m[0907 02-07-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29437, current rewards: -707.92228, mean: -0.73742
[32m[0907 02-07-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29438, current rewards: -714.65076, mean: -0.70758
[32m[0907 02-07-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29440, current rewards: -753.78770, mean: -0.71112
[32m[0907 02-08-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29442, current rewards: -841.92469, mean: -0.75849
[32m[0907 02-08-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29443, current rewards: -878.09359, mean: -0.75698
[32m[0907 02-08-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29443, current rewards: -887.62069, mean: -0.73357
[32m[0907 02-08-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29443, current rewards: -987.62069, mean: -0.78383
[32m[0907 02-09-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29443, current rewards: -1087.62069, mean: -0.83024
[32m[0907 02-09-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29443, current rewards: -1187.62069, mean: -0.87325
[32m[0907 02-09-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29443, current rewards: -1287.62069, mean: -0.91321
[32m[0907 02-09-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29443, current rewards: -1387.62069, mean: -0.95043
[32m[0907 02-10-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29443, current rewards: -1487.62069, mean: -0.98518
[32m[0907 02-10-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29444, current rewards: -1587.62069, mean: -1.01771
[32m[0907 02-10-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29445, current rewards: -1687.62069, mean: -1.04821
[32m[0907 02-10-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29446, current rewards: -1787.62069, mean: -1.07688
[32m[0907 02-11-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29447, current rewards: -1887.62069, mean: -1.10387
[32m[0907 02-11-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29448, current rewards: -1987.62069, mean: -1.12933
[32m[0907 02-11-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29448, current rewards: -2087.62069, mean: -1.15338
[32m[0907 02-11-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29448, current rewards: -2187.62069, mean: -1.17614
[32m[0907 02-12-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29448, current rewards: -2287.62069, mean: -1.19771
[32m[0907 02-12-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29448, current rewards: -2387.62069, mean: -1.21817
[32m[0907 02-12-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29448, current rewards: -2487.62069, mean: -1.23762
[32m[0907 02-12-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29448, current rewards: -2587.62069, mean: -1.25613
[32m[0907 02-13-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29448, current rewards: -2687.62069, mean: -1.27375
[32m[0907 02-13-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29447, current rewards: -2787.62069, mean: -1.29057
[32m[0907 02-13-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29446, current rewards: -2887.62069, mean: -1.30662
[32m[0907 02-13-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29446, current rewards: -2987.62069, mean: -1.32196
[32m[0907 02-14-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29446, current rewards: -3087.62069, mean: -1.33663
[32m[0907 02-14-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29446, current rewards: -3187.62069, mean: -1.35069
[32m[0907 02-14-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29446, current rewards: -3287.62069, mean: -1.36416
[32m[0907 02-14-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29446, current rewards: -3387.62069, mean: -1.37708
[32m[0907 02-14-56 @Agent.py:117][0m Average action selection time: 0.2945
[32m[0907 02-14-56 @Agent.py:118][0m Rollout length: 2600
[32m[0907 02-14-56 @MBExp.py:227][0m Rewards obtained: [-3467.6206911600743], Lows: [1682], Highs: [168], Total time: 34131.28428199999
[32m[0907 02-15-30 @MBExp.py:144][0m ####################################################################
[32m[0907 02-15-30 @MBExp.py:145][0m Starting training iteration 46.
[32m[0907 02-15-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29256, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-15-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29221, current rewards: -60.00000, mean: -1.00000
[32m[0907 02-16-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29260, current rewards: -99.94362, mean: -0.90858
[32m[0907 02-16-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29286, current rewards: -92.87051, mean: -0.58044
[32m[0907 02-16-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29307, current rewards: -83.81695, mean: -0.39913
[32m[0907 02-16-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29323, current rewards: -77.92284, mean: -0.29970
[32m[0907 02-17-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29332, current rewards: -78.72494, mean: -0.25395
[32m[0907 02-17-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29346, current rewards: -74.97174, mean: -0.20825
[32m[0907 02-17-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29356, current rewards: -76.49029, mean: -0.18656
[32m[0907 02-17-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29364, current rewards: -72.86949, mean: -0.15841
[32m[0907 02-18-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29371, current rewards: -156.23529, mean: -0.30634
[32m[0907 02-18-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29380, current rewards: -256.23529, mean: -0.45756
[32m[0907 02-18-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29388, current rewards: -356.23529, mean: -0.58399
[32m[0907 02-18-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29393, current rewards: -405.50542, mean: -0.61440
[32m[0907 02-18-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29400, current rewards: -437.68873, mean: -0.61646
[32m[0907 02-19-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29407, current rewards: -487.68873, mean: -0.64170
[32m[0907 02-19-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29409, current rewards: -537.68873, mean: -0.66381
[32m[0907 02-19-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29458, current rewards: -592.55441, mean: -0.68902
[32m[0907 02-19-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29458, current rewards: -692.55441, mean: -0.76105
[32m[0907 02-20-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29459, current rewards: -768.57225, mean: -0.80060
[32m[0907 02-20-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29478, current rewards: -775.64755, mean: -0.76797
[32m[0907 02-20-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29477, current rewards: -815.10962, mean: -0.76897
[32m[0907 02-20-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29476, current rewards: -814.30145, mean: -0.73360
[32m[0907 02-21-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29477, current rewards: -840.54173, mean: -0.72460
[32m[0907 02-21-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29478, current rewards: -861.61639, mean: -0.71208
[32m[0907 02-21-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29478, current rewards: -907.02910, mean: -0.71986
[32m[0907 02-21-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29575, current rewards: -923.20095, mean: -0.70473
[32m[0907 02-22-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29579, current rewards: -957.87924, mean: -0.70432
[32m[0907 02-22-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29713, current rewards: -1003.28721, mean: -0.71155
[32m[0907 02-22-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29731, current rewards: -1084.47136, mean: -0.74279
[32m[0907 02-23-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29884, current rewards: -1149.97935, mean: -0.76158
[32m[0907 02-23-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29870, current rewards: -1216.92752, mean: -0.78008
[32m[0907 02-23-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29857, current rewards: -1290.89175, mean: -0.80180
[32m[0907 02-23-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29870, current rewards: -1340.89175, mean: -0.80777
[32m[0907 02-24-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29875, current rewards: -1390.89175, mean: -0.81339
[32m[0907 02-24-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29869, current rewards: -1453.65634, mean: -0.82594
[32m[0907 02-24-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29858, current rewards: -1532.45490, mean: -0.84666
[32m[0907 02-24-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29847, current rewards: -1528.59767, mean: -0.82183
[32m[0907 02-25-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29836, current rewards: -1576.50076, mean: -0.82539
[32m[0907 02-25-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29826, current rewards: -1626.50076, mean: -0.82985
[32m[0907 02-25-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29817, current rewards: -1676.50076, mean: -0.83408
[32m[0907 02-25-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29808, current rewards: -1726.50076, mean: -0.83811
[32m[0907 02-25-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29800, current rewards: -1776.50076, mean: -0.84194
[32m[0907 02-26-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29793, current rewards: -1826.50076, mean: -0.84560
[32m[0907 02-26-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29785, current rewards: -1876.50076, mean: -0.84910
[32m[0907 02-26-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29777, current rewards: -1926.50076, mean: -0.85243
[32m[0907 02-26-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29770, current rewards: -1976.50076, mean: -0.85563
[32m[0907 02-27-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29763, current rewards: -2026.50076, mean: -0.85869
[32m[0907 02-27-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29757, current rewards: -2076.50076, mean: -0.86162
[32m[0907 02-27-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29751, current rewards: -2126.50076, mean: -0.86443
[32m[0907 02-27-54 @Agent.py:117][0m Average action selection time: 0.2975
[32m[0907 02-27-54 @Agent.py:118][0m Rollout length: 2600
[32m[0907 02-27-54 @MBExp.py:227][0m Rewards obtained: [-2166.5007634900044], Lows: [566], Highs: [1150], Total time: 34875.262322999995
[32m[0907 02-28-29 @MBExp.py:144][0m ####################################################################
[32m[0907 02-28-29 @MBExp.py:145][0m Starting training iteration 47.
[32m[0907 02-28-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29311, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-28-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30417, current rewards: -60.00000, mean: -1.00000
[32m[0907 02-29-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30625, current rewards: -103.23598, mean: -0.93851
[32m[0907 02-29-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30791, current rewards: -132.08747, mean: -0.82555
[32m[0907 02-29-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30688, current rewards: -195.97116, mean: -0.93320
[32m[0907 02-29-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30628, current rewards: -236.97609, mean: -0.91145
[32m[0907 02-30-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30817, current rewards: -263.33292, mean: -0.84946
[32m[0907 02-30-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30810, current rewards: -304.15695, mean: -0.84488
[32m[0907 02-30-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30835, current rewards: -342.59795, mean: -0.83560
[32m[0907 02-30-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30684, current rewards: -427.58545, mean: -0.92953
[32m[0907 02-31-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30561, current rewards: -527.58545, mean: -1.03448
[32m[0907 02-31-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30463, current rewards: -627.58545, mean: -1.12069
[32m[0907 02-31-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30379, current rewards: -727.58545, mean: -1.19276
[32m[0907 02-31-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30307, current rewards: -827.58545, mean: -1.25392
[32m[0907 02-32-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30247, current rewards: -849.34316, mean: -1.19626
[32m[0907 02-32-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30194, current rewards: -857.09171, mean: -1.12775
[32m[0907 02-32-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30149, current rewards: -907.09171, mean: -1.11987
[32m[0907 02-32-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30107, current rewards: -957.09171, mean: -1.11290
[32m[0907 02-33-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30070, current rewards: -1007.09171, mean: -1.10669
[32m[0907 02-33-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30037, current rewards: -1057.09171, mean: -1.10114
[32m[0907 02-33-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30007, current rewards: -1107.09171, mean: -1.09613
[32m[0907 02-33-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29983, current rewards: -1157.09171, mean: -1.09160
[32m[0907 02-34-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29959, current rewards: -1207.09171, mean: -1.08747
[32m[0907 02-34-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29935, current rewards: -1257.09171, mean: -1.08370
[32m[0907 02-34-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29915, current rewards: -1307.09171, mean: -1.08024
[32m[0907 02-34-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29897, current rewards: -1357.09171, mean: -1.07706
[32m[0907 02-35-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29879, current rewards: -1407.09171, mean: -1.07412
[32m[0907 02-35-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29865, current rewards: -1457.09171, mean: -1.07139
[32m[0907 02-35-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29850, current rewards: -1507.09171, mean: -1.06886
[32m[0907 02-35-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29836, current rewards: -1557.09171, mean: -1.06650
[32m[0907 02-35-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29823, current rewards: -1607.09171, mean: -1.06430
[32m[0907 02-36-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29811, current rewards: -1657.09171, mean: -1.06224
[32m[0907 02-36-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29799, current rewards: -1707.09171, mean: -1.06031
[32m[0907 02-36-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29788, current rewards: -1757.09171, mean: -1.05849
[32m[0907 02-36-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29779, current rewards: -1807.09171, mean: -1.05678
[32m[0907 02-37-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29769, current rewards: -1857.09171, mean: -1.05517
[32m[0907 02-37-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29760, current rewards: -1907.09171, mean: -1.05364
[32m[0907 02-37-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29751, current rewards: -1957.09171, mean: -1.05220
[32m[0907 02-37-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29744, current rewards: -2007.09171, mean: -1.05083
[32m[0907 02-38-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29735, current rewards: -2057.09171, mean: -1.04954
[32m[0907 02-38-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29728, current rewards: -2107.09171, mean: -1.04830
[32m[0907 02-38-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29721, current rewards: -2157.09171, mean: -1.04713
[32m[0907 02-38-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29714, current rewards: -2207.09171, mean: -1.04602
[32m[0907 02-39-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29707, current rewards: -2257.09171, mean: -1.04495
[32m[0907 02-39-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29702, current rewards: -2278.54344, mean: -1.03102
[32m[0907 02-39-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29695, current rewards: -2271.44689, mean: -1.00506
[32m[0907 02-39-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29690, current rewards: -2264.35034, mean: -0.98024
[32m[0907 02-40-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29684, current rewards: -2257.25379, mean: -0.95646
[32m[0907 02-40-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29678, current rewards: -2250.15724, mean: -0.93368
[32m[0907 02-40-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29674, current rewards: -2276.17669, mean: -0.92528
[32m[0907 02-40-51 @Agent.py:117][0m Average action selection time: 0.2967
[32m[0907 02-40-51 @Agent.py:118][0m Rollout length: 2600
[32m[0907 02-40-51 @MBExp.py:227][0m Rewards obtained: [-2316.1766860269236], Lows: [338], Highs: [1713], Total time: 35617.315911
[32m[0907 02-41-25 @MBExp.py:144][0m ####################################################################
[32m[0907 02-41-25 @MBExp.py:145][0m Starting training iteration 48.
[32m[0907 02-41-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29308, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-41-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29283, current rewards: -60.00000, mean: -1.00000
[32m[0907 02-41-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29275, current rewards: -113.14662, mean: -1.02861
[32m[0907 02-42-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29415, current rewards: -117.59147, mean: -0.73495
[32m[0907 02-42-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29410, current rewards: -201.69352, mean: -0.96045
[32m[0907 02-42-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29400, current rewards: -277.64127, mean: -1.06785
[32m[0907 02-42-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29398, current rewards: -327.42033, mean: -1.05619
[32m[0907 02-43-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29394, current rewards: -402.33344, mean: -1.11759
[32m[0907 02-43-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29397, current rewards: -426.52530, mean: -1.04031
[32m[0907 02-43-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29401, current rewards: -452.94798, mean: -0.98467
[32m[0907 02-43-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29403, current rewards: -552.94798, mean: -1.08421
[32m[0907 02-44-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29404, current rewards: -652.94798, mean: -1.16598
[32m[0907 02-44-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29405, current rewards: -752.94798, mean: -1.23434
[32m[0907 02-44-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29406, current rewards: -852.94798, mean: -1.29235
[32m[0907 02-44-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29406, current rewards: -952.94798, mean: -1.34218
[32m[0907 02-45-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29404, current rewards: -1052.94798, mean: -1.38546
[32m[0907 02-45-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29404, current rewards: -1152.94798, mean: -1.42339
[32m[0907 02-45-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29402, current rewards: -1252.94798, mean: -1.45692
[32m[0907 02-45-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29401, current rewards: -1352.94798, mean: -1.48676
[32m[0907 02-46-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29402, current rewards: -1452.94798, mean: -1.51349
[32m[0907 02-46-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29402, current rewards: -1552.94798, mean: -1.53757
[32m[0907 02-46-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29402, current rewards: -1652.94798, mean: -1.55938
[32m[0907 02-46-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29401, current rewards: -1752.94798, mean: -1.57923
[32m[0907 02-47-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29401, current rewards: -1852.94798, mean: -1.59737
[32m[0907 02-47-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29402, current rewards: -1952.94798, mean: -1.61401
[32m[0907 02-47-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29402, current rewards: -2052.94798, mean: -1.62932
[32m[0907 02-47-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29402, current rewards: -2152.94798, mean: -1.64347
[32m[0907 02-48-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29401, current rewards: -2252.94798, mean: -1.65658
[32m[0907 02-48-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29402, current rewards: -2352.94798, mean: -1.66876
[32m[0907 02-48-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29403, current rewards: -2452.94798, mean: -1.68010
[32m[0907 02-48-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29403, current rewards: -2552.94798, mean: -1.69069
[32m[0907 02-49-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29403, current rewards: -2652.94798, mean: -1.70061
[32m[0907 02-49-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29403, current rewards: -2752.94798, mean: -1.70991
[32m[0907 02-49-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29403, current rewards: -2852.94798, mean: -1.71864
[32m[0907 02-49-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29403, current rewards: -2952.94798, mean: -1.72687
[32m[0907 02-50-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29404, current rewards: -3052.94798, mean: -1.73463
[32m[0907 02-50-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29405, current rewards: -3152.94798, mean: -1.74196
[32m[0907 02-50-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29405, current rewards: -3252.94798, mean: -1.74890
[32m[0907 02-50-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29405, current rewards: -3352.94798, mean: -1.75547
[32m[0907 02-51-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29406, current rewards: -3452.94798, mean: -1.76171
[32m[0907 02-51-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29406, current rewards: -3552.94798, mean: -1.76764
[32m[0907 02-51-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29407, current rewards: -3652.94798, mean: -1.77328
[32m[0907 02-51-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29407, current rewards: -3752.94798, mean: -1.77865
[32m[0907 02-52-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29407, current rewards: -3852.94798, mean: -1.78377
[32m[0907 02-52-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29407, current rewards: -3952.94798, mean: -1.78866
[32m[0907 02-52-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29408, current rewards: -4052.94798, mean: -1.79334
[32m[0907 02-52-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29409, current rewards: -4152.94798, mean: -1.79781
[32m[0907 02-52-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29409, current rewards: -4252.94798, mean: -1.80210
[32m[0907 02-53-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29409, current rewards: -4352.94798, mean: -1.80620
[32m[0907 02-53-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29410, current rewards: -4452.94798, mean: -1.81014
[32m[0907 02-53-40 @Agent.py:117][0m Average action selection time: 0.2941
[32m[0907 02-53-40 @Agent.py:118][0m Rollout length: 2600
[32m[0907 02-53-40 @MBExp.py:227][0m Rewards obtained: [-4532.94798021866], Lows: [2205], Highs: [152], Total time: 36352.884306
[32m[0907 02-54-16 @MBExp.py:144][0m ####################################################################
[32m[0907 02-54-16 @MBExp.py:145][0m Starting training iteration 49.
[32m[0907 02-54-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.38976, current rewards: 0.67602, mean: 0.06760
[32m[0907 02-54-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32810, current rewards: 4.01204, mean: 0.06687
[32m[0907 02-54-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31204, current rewards: -8.55664, mean: -0.07779
[32m[0907 02-55-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30745, current rewards: -40.34280, mean: -0.25214
[32m[0907 02-55-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30648, current rewards: -37.00673, mean: -0.17622
[32m[0907 02-55-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30406, current rewards: -56.24853, mean: -0.21634
[32m[0907 02-55-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30242, current rewards: -156.24853, mean: -0.50403
[32m[0907 02-56-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30119, current rewards: -256.24853, mean: -0.71180
[32m[0907 02-56-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30033, current rewards: -356.24853, mean: -0.86890
[32m[0907 02-56-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29963, current rewards: -456.24853, mean: -0.99184
[32m[0907 02-56-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29906, current rewards: -556.24853, mean: -1.09068
[32m[0907 02-57-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29861, current rewards: -656.24853, mean: -1.17187
[32m[0907 02-57-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29825, current rewards: -756.24853, mean: -1.23975
[32m[0907 02-57-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29794, current rewards: -856.24853, mean: -1.29735
[32m[0907 02-57-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29768, current rewards: -956.24853, mean: -1.34683
[32m[0907 02-58-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29747, current rewards: -1056.24853, mean: -1.38980
[32m[0907 02-58-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29727, current rewards: -1156.24853, mean: -1.42747
[32m[0907 02-58-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29708, current rewards: -1256.24853, mean: -1.46075
[32m[0907 02-58-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29691, current rewards: -1356.24853, mean: -1.49038
[32m[0907 02-59-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29674, current rewards: -1456.24853, mean: -1.51693
[32m[0907 02-59-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29661, current rewards: -1556.24853, mean: -1.54084
[32m[0907 02-59-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29649, current rewards: -1656.24853, mean: -1.56250
[32m[0907 02-59-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29639, current rewards: -1756.24853, mean: -1.58221
[32m[0907 02-59-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29629, current rewards: -1856.24853, mean: -1.60021
[32m[0907 03-00-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29620, current rewards: -1956.24853, mean: -1.61673
[32m[0907 03-00-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29612, current rewards: -2056.24853, mean: -1.63194
[32m[0907 03-00-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29603, current rewards: -2156.24853, mean: -1.64599
[32m[0907 03-00-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29597, current rewards: -2256.24853, mean: -1.65901
[32m[0907 03-01-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29591, current rewards: -2356.24853, mean: -1.67110
[32m[0907 03-01-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29584, current rewards: -2456.24853, mean: -1.68236
[32m[0907 03-01-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29579, current rewards: -2556.24853, mean: -1.69288
[32m[0907 03-01-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29574, current rewards: -2656.24853, mean: -1.70272
[32m[0907 03-02-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29569, current rewards: -2756.24853, mean: -1.71196
[32m[0907 03-02-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29564, current rewards: -2856.24853, mean: -1.72063
[32m[0907 03-02-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29559, current rewards: -2956.24853, mean: -1.72880
[32m[0907 03-02-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29555, current rewards: -3056.24853, mean: -1.73650
[32m[0907 03-03-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29551, current rewards: -3156.24853, mean: -1.74378
[32m[0907 03-03-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29547, current rewards: -3256.24853, mean: -1.75067
[32m[0907 03-03-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29543, current rewards: -3356.24853, mean: -1.75720
[32m[0907 03-03-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29539, current rewards: -3456.24853, mean: -1.76339
[32m[0907 03-04-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29536, current rewards: -3556.24853, mean: -1.76928
[32m[0907 03-04-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29533, current rewards: -3656.24853, mean: -1.77488
[32m[0907 03-04-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29529, current rewards: -3756.24853, mean: -1.78021
[32m[0907 03-04-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29525, current rewards: -3856.24853, mean: -1.78530
[32m[0907 03-05-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29522, current rewards: -3956.24853, mean: -1.79016
[32m[0907 03-05-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29519, current rewards: -4056.24853, mean: -1.79480
[32m[0907 03-05-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29517, current rewards: -4156.24853, mean: -1.79924
[32m[0907 03-05-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29515, current rewards: -4256.24853, mean: -1.80350
[32m[0907 03-06-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29512, current rewards: -4356.24853, mean: -1.80757
[32m[0907 03-06-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29510, current rewards: -4456.24853, mean: -1.81148
[32m[0907 03-06-33 @Agent.py:117][0m Average action selection time: 0.2951
[32m[0907 03-06-33 @Agent.py:118][0m Rollout length: 2600
[32m[0907 03-06-34 @MBExp.py:227][0m Rewards obtained: [-4536.248534176784], Lows: [2277], Highs: [0], Total time: 37090.889503
[32m[0907 03-07-10 @MBExp.py:144][0m ####################################################################
[32m[0907 03-07-10 @MBExp.py:145][0m Starting training iteration 50.
[32m[0907 03-07-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30185, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-07-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29378, current rewards: -60.00000, mean: -1.00000
[32m[0907 03-07-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29322, current rewards: -99.53355, mean: -0.90485
[32m[0907 03-07-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29313, current rewards: -146.16679, mean: -0.91354
[32m[0907 03-08-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29324, current rewards: -170.62371, mean: -0.81249
[32m[0907 03-08-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29329, current rewards: -178.58548, mean: -0.68687
[32m[0907 03-08-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29332, current rewards: -189.20036, mean: -0.61032
[32m[0907 03-08-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29341, current rewards: -194.87289, mean: -0.54131
[32m[0907 03-09-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29348, current rewards: -216.30887, mean: -0.52758
[32m[0907 03-09-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29354, current rewards: -245.07245, mean: -0.53277
[32m[0907 03-09-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29361, current rewards: -296.67277, mean: -0.58171
[32m[0907 03-09-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29367, current rewards: -293.62863, mean: -0.52434
[32m[0907 03-10-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29371, current rewards: -283.74397, mean: -0.46515
[32m[0907 03-10-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29375, current rewards: -349.85958, mean: -0.53009
[32m[0907 03-10-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29378, current rewards: -414.27765, mean: -0.58349
[32m[0907 03-10-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29379, current rewards: -419.20243, mean: -0.55158
[32m[0907 03-11-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29380, current rewards: -450.14935, mean: -0.55574
[32m[0907 03-11-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29384, current rewards: -534.84449, mean: -0.62191
[32m[0907 03-11-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29384, current rewards: -584.49197, mean: -0.64230
[32m[0907 03-11-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29387, current rewards: -590.66691, mean: -0.61528
[32m[0907 03-12-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29388, current rewards: -609.18720, mean: -0.60316
[32m[0907 03-12-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29388, current rewards: -605.58427, mean: -0.57131
[32m[0907 03-12-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29389, current rewards: -602.81104, mean: -0.54307
[32m[0907 03-12-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29388, current rewards: -646.12839, mean: -0.55701
[32m[0907 03-13-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29388, current rewards: -696.88128, mean: -0.57593
[32m[0907 03-13-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29388, current rewards: -746.88128, mean: -0.59276
[32m[0907 03-13-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29388, current rewards: -760.94054, mean: -0.58087
[32m[0907 03-13-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29390, current rewards: -772.30716, mean: -0.56787
[32m[0907 03-14-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29390, current rewards: -798.37471, mean: -0.56622
[32m[0907 03-14-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29392, current rewards: -848.37471, mean: -0.58108
[32m[0907 03-14-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29394, current rewards: -861.14012, mean: -0.57029
[32m[0907 03-14-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29393, current rewards: -858.38407, mean: -0.55025
[32m[0907 03-15-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29394, current rewards: -856.98932, mean: -0.53229
[32m[0907 03-15-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29395, current rewards: -929.45607, mean: -0.55991
[32m[0907 03-15-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29395, current rewards: -1029.45607, mean: -0.60202
[32m[0907 03-15-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29396, current rewards: -1088.21627, mean: -0.61830
[32m[0907 03-16-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29397, current rewards: -1103.24066, mean: -0.60953
[32m[0907 03-16-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29398, current rewards: -1113.04691, mean: -0.59841
[32m[0907 03-16-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29399, current rewards: -1208.47680, mean: -0.63271
[32m[0907 03-16-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29400, current rewards: -1208.69801, mean: -0.61668
[32m[0907 03-17-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29400, current rewards: -1220.42832, mean: -0.60718
[32m[0907 03-17-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29401, current rewards: -1262.69360, mean: -0.61296
[32m[0907 03-17-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29402, current rewards: -1265.82755, mean: -0.59992
[32m[0907 03-17-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29402, current rewards: -1321.46713, mean: -0.61179
[32m[0907 03-18-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29402, current rewards: -1347.53008, mean: -0.60974
[32m[0907 03-18-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29402, current rewards: -1374.73608, mean: -0.60829
[32m[0907 03-18-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29402, current rewards: -1394.13744, mean: -0.60352
[32m[0907 03-18-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29402, current rewards: -1435.27660, mean: -0.60817
[32m[0907 03-18-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29402, current rewards: -1469.02232, mean: -0.60955
[32m[0907 03-19-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29401, current rewards: -1527.18734, mean: -0.62081
[32m[0907 03-19-25 @Agent.py:117][0m Average action selection time: 0.2940
[32m[0907 03-19-25 @Agent.py:118][0m Rollout length: 2600
[32m[0907 03-19-25 @MBExp.py:227][0m Rewards obtained: [-1571.0115114981065], Lows: [657], Highs: [449], Total time: 37826.231486
[32m[0907 03-20-03 @MBExp.py:144][0m ####################################################################
[32m[0907 03-20-03 @MBExp.py:145][0m Starting training iteration 51.
[32m[0907 03-20-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31254, current rewards: -2.65584, mean: -0.26558
[32m[0907 03-20-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30534, current rewards: -0.18576, mean: -0.00310
[32m[0907 03-20-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30042, current rewards: -16.14897, mean: -0.14681
[32m[0907 03-20-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29815, current rewards: -50.77099, mean: -0.31732
[32m[0907 03-21-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29707, current rewards: -150.77099, mean: -0.71796
[32m[0907 03-21-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29908, current rewards: -183.41248, mean: -0.70543
[32m[0907 03-21-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29886, current rewards: -179.83302, mean: -0.58011
[32m[0907 03-21-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29873, current rewards: -236.45872, mean: -0.65683
[32m[0907 03-22-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29866, current rewards: -314.59104, mean: -0.76730
[32m[0907 03-22-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29818, current rewards: -367.20697, mean: -0.79828
[32m[0907 03-22-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29777, current rewards: -416.15893, mean: -0.81600
[32m[0907 03-22-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29744, current rewards: -466.15893, mean: -0.83243
[32m[0907 03-23-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29717, current rewards: -562.15893, mean: -0.92157
[32m[0907 03-23-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29693, current rewards: -662.15893, mean: -1.00327
[32m[0907 03-23-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29673, current rewards: -762.15893, mean: -1.07346
[32m[0907 03-23-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29656, current rewards: -862.15893, mean: -1.13442
[32m[0907 03-24-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29638, current rewards: -962.15893, mean: -1.18785
[32m[0907 03-24-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29624, current rewards: -1062.15893, mean: -1.23507
[32m[0907 03-24-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29612, current rewards: -1162.15893, mean: -1.27710
[32m[0907 03-24-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29600, current rewards: -1262.15893, mean: -1.31475
[32m[0907 03-25-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29590, current rewards: -1362.15893, mean: -1.34867
[32m[0907 03-25-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29581, current rewards: -1462.15893, mean: -1.37940
[32m[0907 03-25-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29574, current rewards: -1562.15893, mean: -1.40735
[32m[0907 03-25-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29565, current rewards: -1662.15893, mean: -1.43290
[32m[0907 03-26-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29558, current rewards: -1762.15893, mean: -1.45633
[32m[0907 03-26-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29552, current rewards: -1862.15893, mean: -1.47790
[32m[0907 03-26-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29544, current rewards: -1962.15893, mean: -1.49783
[32m[0907 03-26-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29539, current rewards: -2062.15893, mean: -1.51629
[32m[0907 03-27-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29533, current rewards: -2162.15893, mean: -1.53345
[32m[0907 03-27-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29527, current rewards: -2262.15893, mean: -1.54942
[32m[0907 03-27-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29522, current rewards: -2362.15893, mean: -1.56434
[32m[0907 03-27-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29517, current rewards: -2462.15893, mean: -1.57831
[32m[0907 03-27-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29513, current rewards: -2562.15893, mean: -1.59140
[32m[0907 03-28-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29509, current rewards: -2662.15893, mean: -1.60371
[32m[0907 03-28-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29506, current rewards: -2762.15893, mean: -1.61530
[32m[0907 03-28-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29502, current rewards: -2862.15893, mean: -1.62623
[32m[0907 03-28-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29499, current rewards: -2962.15893, mean: -1.63655
[32m[0907 03-29-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29497, current rewards: -3062.15893, mean: -1.64632
[32m[0907 03-29-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29494, current rewards: -3162.15893, mean: -1.65558
[32m[0907 03-29-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29491, current rewards: -3262.15893, mean: -1.66437
[32m[0907 03-29-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29488, current rewards: -3362.15893, mean: -1.67272
[32m[0907 03-30-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29486, current rewards: -3462.15893, mean: -1.68066
[32m[0907 03-30-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29483, current rewards: -3562.15893, mean: -1.68823
[32m[0907 03-30-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29480, current rewards: -3662.15893, mean: -1.69544
[32m[0907 03-30-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29477, current rewards: -3762.15893, mean: -1.70233
[32m[0907 03-31-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29475, current rewards: -3862.15893, mean: -1.70892
[32m[0907 03-31-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29473, current rewards: -3962.15893, mean: -1.71522
[32m[0907 03-31-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29471, current rewards: -4062.15893, mean: -1.72125
[32m[0907 03-31-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29468, current rewards: -4162.15893, mean: -1.72704
[32m[0907 03-32-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29467, current rewards: -4262.15893, mean: -1.73258
[32m[0907 03-32-20 @Agent.py:117][0m Average action selection time: 0.2947
[32m[0907 03-32-20 @Agent.py:118][0m Rollout length: 2600
[32m[0907 03-32-20 @MBExp.py:227][0m Rewards obtained: [-4342.158934968503], Lows: [2102], Highs: [161], Total time: 38563.21215
[32m[0907 03-32-59 @MBExp.py:144][0m ####################################################################
[32m[0907 03-32-59 @MBExp.py:145][0m Starting training iteration 52.
[32m[0907 03-33-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.37009, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-33-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32017, current rewards: -60.00000, mean: -1.00000
[32m[0907 03-33-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30770, current rewards: -110.35140, mean: -1.00319
[32m[0907 03-33-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30559, current rewards: -162.61140, mean: -1.01632
[32m[0907 03-34-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30284, current rewards: -165.20399, mean: -0.78669
[32m[0907 03-34-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30112, current rewards: -256.39958, mean: -0.98615
[32m[0907 03-34-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29995, current rewards: -356.39958, mean: -1.14968
[32m[0907 03-34-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29909, current rewards: -452.23656, mean: -1.25621
[32m[0907 03-35-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30153, current rewards: -477.94893, mean: -1.16573
[32m[0907 03-35-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30075, current rewards: -518.48168, mean: -1.12713
[32m[0907 03-35-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30352, current rewards: -564.23128, mean: -1.10634
[32m[0907 03-35-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30264, current rewards: -614.86215, mean: -1.09797
[32m[0907 03-36-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30305, current rewards: -710.59137, mean: -1.16490
[32m[0907 03-36-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30502, current rewards: -721.05934, mean: -1.09251
[32m[0907 03-36-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30547, current rewards: -731.76981, mean: -1.03066
[32m[0907 03-36-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30728, current rewards: -770.16713, mean: -1.01338
[32m[0907 03-37-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30828, current rewards: -861.68166, mean: -1.06380
[32m[0907 03-37-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30825, current rewards: -910.56624, mean: -1.05880
[32m[0907 03-37-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30779, current rewards: -945.34914, mean: -1.03885
[32m[0907 03-37-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30972, current rewards: -1031.39698, mean: -1.07437
[32m[0907 03-38-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30982, current rewards: -1103.33119, mean: -1.09241
[32m[0907 03-38-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30955, current rewards: -1151.31489, mean: -1.08615
[32m[0907 03-38-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30921, current rewards: -1217.55758, mean: -1.09690
[32m[0907 03-38-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30857, current rewards: -1298.08121, mean: -1.11904
[32m[0907 03-39-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30853, current rewards: -1364.41733, mean: -1.12762
[32m[0907 03-39-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30797, current rewards: -1412.30422, mean: -1.12088
[32m[0907 03-39-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30744, current rewards: -1468.82548, mean: -1.12124
[32m[0907 03-39-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30695, current rewards: -1568.82548, mean: -1.15355
[32m[0907 03-40-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30648, current rewards: -1668.82548, mean: -1.18356
[32m[0907 03-40-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30605, current rewards: -1768.82548, mean: -1.21152
[32m[0907 03-40-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30564, current rewards: -1868.82548, mean: -1.23763
[32m[0907 03-40-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30526, current rewards: -1968.82548, mean: -1.26207
[32m[0907 03-41-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30490, current rewards: -2068.82548, mean: -1.28498
[32m[0907 03-41-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30458, current rewards: -2168.82548, mean: -1.30652
[32m[0907 03-41-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30427, current rewards: -2268.82548, mean: -1.32680
[32m[0907 03-41-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30398, current rewards: -2368.82548, mean: -1.34592
[32m[0907 03-42-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30370, current rewards: -2468.82548, mean: -1.36399
[32m[0907 03-42-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30344, current rewards: -2568.82548, mean: -1.38109
[32m[0907 03-42-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30319, current rewards: -2668.82548, mean: -1.39729
[32m[0907 03-42-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30295, current rewards: -2768.82548, mean: -1.41267
[32m[0907 03-43-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30272, current rewards: -2868.82548, mean: -1.42728
[32m[0907 03-43-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30251, current rewards: -2968.82548, mean: -1.44118
[32m[0907 03-43-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30230, current rewards: -3068.82548, mean: -1.45442
[32m[0907 03-43-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30209, current rewards: -3168.82548, mean: -1.46705
[32m[0907 03-44-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30191, current rewards: -3268.82548, mean: -1.47911
[32m[0907 03-44-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30173, current rewards: -3368.82548, mean: -1.49063
[32m[0907 03-44-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30156, current rewards: -3468.82548, mean: -1.50166
[32m[0907 03-44-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30140, current rewards: -3568.82548, mean: -1.51221
[32m[0907 03-45-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30124, current rewards: -3668.82548, mean: -1.52233
[32m[0907 03-45-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30108, current rewards: -3768.82548, mean: -1.53204
[32m[0907 03-45-31 @Agent.py:117][0m Average action selection time: 0.3010
[32m[0907 03-45-31 @Agent.py:118][0m Rollout length: 2600
[32m[0907 03-45-31 @MBExp.py:227][0m Rewards obtained: [-3848.82547823362], Lows: [1800], Highs: [305], Total time: 39315.999446
[32m[0907 03-46-10 @MBExp.py:144][0m ####################################################################
[32m[0907 03-46-10 @MBExp.py:145][0m Starting training iteration 53.
[32m[0907 03-46-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29269, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-46-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29218, current rewards: -60.00000, mean: -1.00000
[32m[0907 03-46-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29760, current rewards: -99.92607, mean: -0.90842
[32m[0907 03-46-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30158, current rewards: -141.42729, mean: -0.88392
[32m[0907 03-47-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30098, current rewards: -148.57555, mean: -0.70750
[32m[0907 03-47-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30138, current rewards: -199.95798, mean: -0.76907
[32m[0907 03-47-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30259, current rewards: -249.80000, mean: -0.80581
[32m[0907 03-47-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30194, current rewards: -317.31467, mean: -0.88143
[32m[0907 03-48-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30097, current rewards: -373.32017, mean: -0.91054
[32m[0907 03-48-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30065, current rewards: -414.06259, mean: -0.90014
[32m[0907 03-48-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30001, current rewards: -467.93156, mean: -0.91751
[32m[0907 03-48-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29946, current rewards: -565.55168, mean: -1.00991
[32m[0907 03-49-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29903, current rewards: -587.06030, mean: -0.96239
[32m[0907 03-49-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29895, current rewards: -600.11955, mean: -0.90927
[32m[0907 03-49-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29860, current rewards: -639.75817, mean: -0.90107
[32m[0907 03-49-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29842, current rewards: -655.22279, mean: -0.86214
[32m[0907 03-50-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29814, current rewards: -650.34931, mean: -0.80290
[32m[0907 03-50-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29826, current rewards: -659.72395, mean: -0.76712
[32m[0907 03-50-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29823, current rewards: -681.27087, mean: -0.74865
[32m[0907 03-50-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29863, current rewards: -728.86253, mean: -0.75923
[32m[0907 03-51-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29859, current rewards: -787.62479, mean: -0.77983
[32m[0907 03-51-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29854, current rewards: -807.67845, mean: -0.76196
[32m[0907 03-51-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29834, current rewards: -847.99146, mean: -0.76396
[32m[0907 03-51-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29814, current rewards: -900.40943, mean: -0.77622
[32m[0907 03-52-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29796, current rewards: -899.58318, mean: -0.74346
[32m[0907 03-52-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29780, current rewards: -958.83064, mean: -0.76098
[32m[0907 03-52-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29764, current rewards: -988.36547, mean: -0.75448
[32m[0907 03-52-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29748, current rewards: -1031.46779, mean: -0.75843
[32m[0907 03-53-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29735, current rewards: -1075.19988, mean: -0.76255
[32m[0907 03-53-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29725, current rewards: -1175.19988, mean: -0.80493
[32m[0907 03-53-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29714, current rewards: -1178.99784, mean: -0.78079
[32m[0907 03-53-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29704, current rewards: -1238.65329, mean: -0.79401
[32m[0907 03-54-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29695, current rewards: -1338.65329, mean: -0.83146
[32m[0907 03-54-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29685, current rewards: -1438.65329, mean: -0.86666
[32m[0907 03-54-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29676, current rewards: -1472.70960, mean: -0.86123
[32m[0907 03-54-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29667, current rewards: -1522.70960, mean: -0.86518
[32m[0907 03-55-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29660, current rewards: -1572.70960, mean: -0.86890
[32m[0907 03-55-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29653, current rewards: -1622.70960, mean: -0.87242
[32m[0907 03-55-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29661, current rewards: -1670.61341, mean: -0.87467
[32m[0907 03-55-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29655, current rewards: -1720.61341, mean: -0.87786
[32m[0907 03-56-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29663, current rewards: -1770.61341, mean: -0.88090
[32m[0907 03-56-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29657, current rewards: -1820.61341, mean: -0.88379
[32m[0907 03-56-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29660, current rewards: -1871.24887, mean: -0.88685
[32m[0907 03-56-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29653, current rewards: -1892.46103, mean: -0.87614
[32m[0907 03-57-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29647, current rewards: -1942.46103, mean: -0.87894
[32m[0907 03-57-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29655, current rewards: -1982.83189, mean: -0.87736
[32m[0907 03-57-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29649, current rewards: -2009.29644, mean: -0.86983
[32m[0907 03-57-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29660, current rewards: -2056.79573, mean: -0.87152
[32m[0907 03-58-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29682, current rewards: -2096.43403, mean: -0.86989
[32m[0907 03-58-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29676, current rewards: -2159.55751, mean: -0.87787
[32m[0907 03-58-32 @Agent.py:117][0m Average action selection time: 0.2967
[32m[0907 03-58-32 @Agent.py:118][0m Rollout length: 2600
[32m[0907 03-58-32 @MBExp.py:227][0m Rewards obtained: [-2172.452881091969], Lows: [624], Highs: [1056], Total time: 40058.104683000005
[32m[0907 03-59-12 @MBExp.py:144][0m ####################################################################
[32m[0907 03-59-12 @MBExp.py:145][0m Starting training iteration 54.
[32m[0907 03-59-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29217, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-59-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29545, current rewards: -60.00000, mean: -1.00000
[32m[0907 03-59-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30016, current rewards: -120.00000, mean: -1.09091
[32m[0907 04-00-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30197, current rewards: -208.68734, mean: -1.30430
[32m[0907 04-00-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30904, current rewards: -308.68734, mean: -1.46994
[32m[0907 04-00-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30849, current rewards: -401.49685, mean: -1.54422
[32m[0907 04-00-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30727, current rewards: -491.01844, mean: -1.58393
[32m[0907 04-01-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30536, current rewards: -584.56485, mean: -1.62379
[32m[0907 04-01-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30631, current rewards: -684.56485, mean: -1.66967
[32m[0907 04-01-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30555, current rewards: -782.43080, mean: -1.70094
[32m[0907 04-01-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30668, current rewards: -882.43080, mean: -1.73026
[32m[0907 04-02-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30624, current rewards: -970.21802, mean: -1.73253
[32m[0907 04-02-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30745, current rewards: -1059.76541, mean: -1.73732
[32m[0907 04-02-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30803, current rewards: -1146.87497, mean: -1.73769
[32m[0907 04-02-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30758, current rewards: -1216.78450, mean: -1.71378
[32m[0907 04-03-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30705, current rewards: -1274.94760, mean: -1.67756
[32m[0907 04-03-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30792, current rewards: -1331.51903, mean: -1.64385
[32m[0907 04-03-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30869, current rewards: -1426.69135, mean: -1.65894
[32m[0907 04-03-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30872, current rewards: -1506.41946, mean: -1.65541
[32m[0907 04-04-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30886, current rewards: -1604.33449, mean: -1.67118
[32m[0907 04-04-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30889, current rewards: -1702.15892, mean: -1.68531
[32m[0907 04-04-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30817, current rewards: -1747.17843, mean: -1.64828
[32m[0907 04-04-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30752, current rewards: -1806.39646, mean: -1.62738
[32m[0907 04-05-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30692, current rewards: -1803.43994, mean: -1.55469
[32m[0907 04-05-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30636, current rewards: -1853.43994, mean: -1.53177
[32m[0907 04-05-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30585, current rewards: -1903.43994, mean: -1.51067
[32m[0907 04-05-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30539, current rewards: -1953.43994, mean: -1.49118
[32m[0907 04-06-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30495, current rewards: -2003.43994, mean: -1.47312
[32m[0907 04-06-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30455, current rewards: -2053.43994, mean: -1.45634
[32m[0907 04-06-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30418, current rewards: -2103.43994, mean: -1.44071
[32m[0907 04-06-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30382, current rewards: -2153.43994, mean: -1.42612
[32m[0907 04-07-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30348, current rewards: -2203.43994, mean: -1.41246
[32m[0907 04-07-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30317, current rewards: -2215.51324, mean: -1.37610
[32m[0907 04-07-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30288, current rewards: -2241.33207, mean: -1.35020
[32m[0907 04-07-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30261, current rewards: -2291.33207, mean: -1.33996
[32m[0907 04-08-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30236, current rewards: -2341.33207, mean: -1.33030
[32m[0907 04-08-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30213, current rewards: -2391.33207, mean: -1.32118
[32m[0907 04-08-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30190, current rewards: -2441.33207, mean: -1.31254
[32m[0907 04-08-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30169, current rewards: -2491.33207, mean: -1.30436
[32m[0907 04-09-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30148, current rewards: -2541.33207, mean: -1.29660
[32m[0907 04-09-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30129, current rewards: -2591.33207, mean: -1.28922
[32m[0907 04-09-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30110, current rewards: -2641.33207, mean: -1.28220
[32m[0907 04-09-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30093, current rewards: -2691.33207, mean: -1.27551
[32m[0907 04-10-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30076, current rewards: -2741.33207, mean: -1.26914
[32m[0907 04-10-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30060, current rewards: -2791.33207, mean: -1.26305
[32m[0907 04-10-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30045, current rewards: -2841.33207, mean: -1.25723
[32m[0907 04-10-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30030, current rewards: -2891.33207, mean: -1.25166
[32m[0907 04-11-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30016, current rewards: -2941.33207, mean: -1.24633
[32m[0907 04-11-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30003, current rewards: -2991.33207, mean: -1.24122
[32m[0907 04-11-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29990, current rewards: -3041.33207, mean: -1.23631
[32m[0907 04-11-42 @Agent.py:117][0m Average action selection time: 0.2998
[32m[0907 04-11-42 @Agent.py:118][0m Rollout length: 2600
[32m[0907 04-11-42 @MBExp.py:227][0m Rewards obtained: [-3081.3320718261175], Lows: [858], Highs: [1401], Total time: 40807.88415600001
[32m[0907 04-12-21 @MBExp.py:144][0m ####################################################################
[32m[0907 04-12-21 @MBExp.py:145][0m Starting training iteration 55.
[32m[0907 04-12-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30252, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-12-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29410, current rewards: -60.00000, mean: -1.00000
[32m[0907 04-12-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29348, current rewards: -117.84846, mean: -1.07135
[32m[0907 04-13-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29504, current rewards: -193.17814, mean: -1.20736
[32m[0907 04-13-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29447, current rewards: -278.50045, mean: -1.32619
[32m[0907 04-13-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29417, current rewards: -361.88977, mean: -1.39188
[32m[0907 04-13-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29522, current rewards: -461.88977, mean: -1.48997
[32m[0907 04-14-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30145, current rewards: -533.34448, mean: -1.48151
[32m[0907 04-14-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30505, current rewards: -590.91371, mean: -1.44125
[32m[0907 04-14-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30489, current rewards: -631.04074, mean: -1.37183
[32m[0907 04-14-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30724, current rewards: -715.67524, mean: -1.40328
[32m[0907 04-15-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30744, current rewards: -801.75966, mean: -1.43171
[32m[0907 04-15-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30725, current rewards: -898.75966, mean: -1.47338
[32m[0907 04-15-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30753, current rewards: -980.46732, mean: -1.48556
[32m[0907 04-16-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30873, current rewards: -994.87731, mean: -1.40124
[32m[0907 04-16-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30876, current rewards: -1073.10576, mean: -1.41198
[32m[0907 04-16-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30781, current rewards: -1159.27852, mean: -1.43121
[32m[0907 04-16-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30697, current rewards: -1230.08380, mean: -1.43033
[32m[0907 04-17-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30623, current rewards: -1315.99375, mean: -1.44615
[32m[0907 04-17-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30558, current rewards: -1415.99375, mean: -1.47499
[32m[0907 04-17-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30537, current rewards: -1462.03203, mean: -1.44756
[32m[0907 04-17-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30500, current rewards: -1472.20126, mean: -1.38887
[32m[0907 04-18-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30518, current rewards: -1538.28133, mean: -1.38584
[32m[0907 04-18-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30468, current rewards: -1602.16318, mean: -1.38118
[32m[0907 04-18-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30422, current rewards: -1690.58036, mean: -1.39717
[32m[0907 04-18-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30411, current rewards: -1790.58036, mean: -1.42110
[32m[0907 04-19-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30408, current rewards: -1841.99980, mean: -1.40611
[32m[0907 04-19-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30369, current rewards: -1858.33814, mean: -1.36643
[32m[0907 04-19-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30334, current rewards: -1936.11755, mean: -1.37313
[32m[0907 04-19-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30300, current rewards: -2036.11755, mean: -1.39460
[32m[0907 04-19-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30268, current rewards: -2136.11755, mean: -1.41465
[32m[0907 04-20-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30238, current rewards: -2236.11755, mean: -1.43341
[32m[0907 04-20-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30211, current rewards: -2336.11755, mean: -1.45100
[32m[0907 04-20-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30185, current rewards: -2436.11755, mean: -1.46754
[32m[0907 04-20-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30161, current rewards: -2536.11755, mean: -1.48311
[32m[0907 04-21-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30139, current rewards: -2636.11755, mean: -1.49779
[32m[0907 04-21-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30119, current rewards: -2736.11755, mean: -1.51167
[32m[0907 04-21-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30099, current rewards: -2836.11755, mean: -1.52479
[32m[0907 04-21-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30079, current rewards: -2936.11755, mean: -1.53723
[32m[0907 04-22-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30061, current rewards: -3036.11755, mean: -1.54904
[32m[0907 04-22-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30044, current rewards: -3136.11755, mean: -1.56026
[32m[0907 04-22-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30026, current rewards: -3236.11755, mean: -1.57093
[32m[0907 04-22-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30010, current rewards: -3336.11755, mean: -1.58110
[32m[0907 04-23-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29995, current rewards: -3436.11755, mean: -1.59080
[32m[0907 04-23-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29981, current rewards: -3536.11755, mean: -1.60005
[32m[0907 04-23-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29967, current rewards: -3636.11755, mean: -1.60890
[32m[0907 04-23-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29954, current rewards: -3736.11755, mean: -1.61737
[32m[0907 04-24-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29941, current rewards: -3836.11755, mean: -1.62547
[32m[0907 04-24-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29929, current rewards: -3936.11755, mean: -1.63324
[32m[0907 04-24-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29917, current rewards: -4036.11755, mean: -1.64070
[32m[0907 04-24-49 @Agent.py:117][0m Average action selection time: 0.2991
[32m[0907 04-24-49 @Agent.py:118][0m Rollout length: 2600
[32m[0907 04-24-49 @MBExp.py:227][0m Rewards obtained: [-4116.117552234085], Lows: [1930], Highs: [294], Total time: 41555.873123000005
[32m[0907 04-25-30 @MBExp.py:144][0m ####################################################################
[32m[0907 04-25-30 @MBExp.py:145][0m Starting training iteration 56.
[32m[0907 04-25-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31220, current rewards: -8.95116, mean: -0.89512
[32m[0907 04-25-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29558, current rewards: -2.25048, mean: -0.03751
[32m[0907 04-26-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29413, current rewards: 4.38311, mean: 0.03985
[32m[0907 04-26-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29379, current rewards: 13.18600, mean: 0.08241
[32m[0907 04-26-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29351, current rewards: 21.97476, mean: 0.10464
[32m[0907 04-26-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29334, current rewards: 30.76342, mean: 0.11832
[32m[0907 04-27-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29329, current rewards: 39.55209, mean: 0.12759
[32m[0907 04-27-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29327, current rewards: 47.31406, mean: 0.13143
[32m[0907 04-27-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29335, current rewards: 52.09468, mean: 0.12706
[32m[0907 04-27-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29383, current rewards: 10.85957, mean: 0.02361
[32m[0907 04-28-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29802, current rewards: -39.14043, mean: -0.07675
[32m[0907 04-28-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30198, current rewards: -83.56604, mean: -0.14923
[32m[0907 04-28-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30130, current rewards: -146.47316, mean: -0.24012
[32m[0907 04-28-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30158, current rewards: -212.61897, mean: -0.32215
[32m[0907 04-29-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30101, current rewards: -312.61897, mean: -0.44031
[32m[0907 04-29-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30055, current rewards: -381.21320, mean: -0.50160
[32m[0907 04-29-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30012, current rewards: -431.21320, mean: -0.53236
[32m[0907 04-29-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29974, current rewards: -481.21320, mean: -0.55955
[32m[0907 04-30-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29940, current rewards: -531.21320, mean: -0.58375
[32m[0907 04-30-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29910, current rewards: -581.21320, mean: -0.60543
[32m[0907 04-30-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29883, current rewards: -631.21320, mean: -0.62496
[32m[0907 04-30-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29859, current rewards: -681.21320, mean: -0.64265
[32m[0907 04-31-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29836, current rewards: -731.21320, mean: -0.65875
[32m[0907 04-31-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29816, current rewards: -781.21320, mean: -0.67346
[32m[0907 04-31-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29798, current rewards: -831.21320, mean: -0.68695
[32m[0907 04-31-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29783, current rewards: -881.21320, mean: -0.69938
[32m[0907 04-32-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29767, current rewards: -931.21320, mean: -0.71085
[32m[0907 04-32-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29755, current rewards: -981.21320, mean: -0.72148
[32m[0907 04-32-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29742, current rewards: -1031.21320, mean: -0.73136
[32m[0907 04-32-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29729, current rewards: -1081.21320, mean: -0.74056
[32m[0907 04-32-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29718, current rewards: -1131.21320, mean: -0.74915
[32m[0907 04-33-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29708, current rewards: -1181.21320, mean: -0.75719
[32m[0907 04-33-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29697, current rewards: -1231.21320, mean: -0.76473
[32m[0907 04-33-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29688, current rewards: -1281.21320, mean: -0.77182
[32m[0907 04-33-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29678, current rewards: -1331.21320, mean: -0.77849
[32m[0907 04-34-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29669, current rewards: -1381.21320, mean: -0.78478
[32m[0907 04-34-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29661, current rewards: -1431.21320, mean: -0.79073
[32m[0907 04-34-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29653, current rewards: -1481.21320, mean: -0.79635
[32m[0907 04-34-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29645, current rewards: -1531.21320, mean: -0.80168
[32m[0907 04-35-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29638, current rewards: -1581.21320, mean: -0.80674
[32m[0907 04-35-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29632, current rewards: -1631.21320, mean: -0.81155
[32m[0907 04-35-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29625, current rewards: -1681.21320, mean: -0.81612
[32m[0907 04-35-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29619, current rewards: -1731.21320, mean: -0.82048
[32m[0907 04-36-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29613, current rewards: -1781.21320, mean: -0.82464
[32m[0907 04-36-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29607, current rewards: -1831.21320, mean: -0.82860
[32m[0907 04-36-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29601, current rewards: -1881.21320, mean: -0.83240
[32m[0907 04-36-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29596, current rewards: -1931.21320, mean: -0.83602
[32m[0907 04-37-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29590, current rewards: -1981.21320, mean: -0.83950
[32m[0907 04-37-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29585, current rewards: -2031.21320, mean: -0.84283
[32m[0907 04-37-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29580, current rewards: -2081.21320, mean: -0.84602
[32m[0907 04-37-50 @Agent.py:117][0m Average action selection time: 0.2958
[32m[0907 04-37-50 @Agent.py:118][0m Rollout length: 2600
[32m[0907 04-37-50 @MBExp.py:227][0m Rewards obtained: [-2121.2131962182975], Lows: [119], Highs: [1950], Total time: 42295.582607000004
[32m[0907 04-38-31 @MBExp.py:144][0m ####################################################################
[32m[0907 04-38-31 @MBExp.py:145][0m Starting training iteration 57.
[32m[0907 04-38-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29265, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-38-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29719, current rewards: -60.00000, mean: -1.00000
[32m[0907 04-39-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29501, current rewards: -110.05423, mean: -1.00049
[32m[0907 04-39-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29430, current rewards: -161.73030, mean: -1.01081
[32m[0907 04-39-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29387, current rewards: -211.73030, mean: -1.00824
[32m[0907 04-39-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29365, current rewards: -261.73030, mean: -1.00665
[32m[0907 04-40-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29351, current rewards: -311.73030, mean: -1.00558
[32m[0907 04-40-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29344, current rewards: -361.73030, mean: -1.00481
[32m[0907 04-40-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29346, current rewards: -411.73030, mean: -1.00422
[32m[0907 04-40-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29346, current rewards: -461.73030, mean: -1.00376
[32m[0907 04-41-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29348, current rewards: -511.73030, mean: -1.00339
[32m[0907 04-41-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29348, current rewards: -561.73030, mean: -1.00309
[32m[0907 04-41-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29354, current rewards: -611.73030, mean: -1.00284
[32m[0907 04-41-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29357, current rewards: -661.73030, mean: -1.00262
[32m[0907 04-42-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29360, current rewards: -711.73030, mean: -1.00244
[32m[0907 04-42-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29363, current rewards: -761.73030, mean: -1.00228
[32m[0907 04-42-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29364, current rewards: -811.73030, mean: -1.00214
[32m[0907 04-42-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29365, current rewards: -861.73030, mean: -1.00201
[32m[0907 04-42-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29365, current rewards: -911.73030, mean: -1.00190
[32m[0907 04-43-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29365, current rewards: -961.73030, mean: -1.00180
[32m[0907 04-43-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29366, current rewards: -974.53674, mean: -0.96489
[32m[0907 04-43-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29364, current rewards: -969.84033, mean: -0.91494
[32m[0907 04-43-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29366, current rewards: -965.14392, mean: -0.86950
[32m[0907 04-44-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29368, current rewards: -960.81260, mean: -0.82829
[32m[0907 04-44-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29370, current rewards: -1008.71433, mean: -0.83365
[32m[0907 04-44-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29371, current rewards: -1058.71433, mean: -0.84025
[32m[0907 04-44-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29372, current rewards: -1108.71433, mean: -0.84635
[32m[0907 04-45-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29372, current rewards: -1158.71433, mean: -0.85200
[32m[0907 04-45-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29374, current rewards: -1208.71433, mean: -0.85724
[32m[0907 04-45-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29374, current rewards: -1258.71433, mean: -0.86213
[32m[0907 04-45-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29374, current rewards: -1308.71433, mean: -0.86670
[32m[0907 04-46-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29374, current rewards: -1358.71433, mean: -0.87097
[32m[0907 04-46-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29373, current rewards: -1375.39812, mean: -0.85428
[32m[0907 04-46-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29373, current rewards: -1397.19266, mean: -0.84168
[32m[0907 04-46-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29373, current rewards: -1447.19266, mean: -0.84631
[32m[0907 04-47-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29373, current rewards: -1497.19266, mean: -0.85068
[32m[0907 04-47-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29373, current rewards: -1547.19266, mean: -0.85480
[32m[0907 04-47-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29373, current rewards: -1597.19266, mean: -0.85871
[32m[0907 04-47-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29373, current rewards: -1647.19266, mean: -0.86240
[32m[0907 04-48-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29374, current rewards: -1697.19266, mean: -0.86591
[32m[0907 04-48-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29374, current rewards: -1747.19266, mean: -0.86925
[32m[0907 04-48-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29373, current rewards: -1797.19266, mean: -0.87242
[32m[0907 04-48-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29373, current rewards: -1847.19266, mean: -0.87545
[32m[0907 04-49-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29373, current rewards: -1897.19266, mean: -0.87833
[32m[0907 04-49-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29373, current rewards: -1947.19266, mean: -0.88108
[32m[0907 04-49-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29373, current rewards: -1997.19266, mean: -0.88371
[32m[0907 04-49-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29372, current rewards: -2047.19266, mean: -0.88623
[32m[0907 04-50-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29372, current rewards: -2097.19266, mean: -0.88864
[32m[0907 04-50-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29372, current rewards: -2147.19266, mean: -0.89095
[32m[0907 04-50-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29372, current rewards: -2197.19266, mean: -0.89317
[32m[0907 04-50-46 @Agent.py:117][0m Average action selection time: 0.2937
[32m[0907 04-50-46 @Agent.py:118][0m Rollout length: 2600
[32m[0907 04-50-46 @MBExp.py:227][0m Rewards obtained: [-2237.192660264688], Lows: [13], Highs: [2236], Total time: 43030.223408000005
[32m[0907 04-51-29 @MBExp.py:144][0m ####################################################################
[32m[0907 04-51-29 @MBExp.py:145][0m Starting training iteration 58.
[32m[0907 04-51-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29242, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-51-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29226, current rewards: -60.00000, mean: -1.00000
[32m[0907 04-52-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29236, current rewards: -117.91692, mean: -1.07197
[32m[0907 04-52-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29244, current rewards: -138.84911, mean: -0.86781
[32m[0907 04-52-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29252, current rewards: -138.86507, mean: -0.66126
[32m[0907 04-52-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29260, current rewards: -134.45928, mean: -0.51715
[32m[0907 04-52-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29271, current rewards: -147.19486, mean: -0.47482
[32m[0907 04-53-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29280, current rewards: -149.39908, mean: -0.41500
[32m[0907 04-53-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29294, current rewards: -186.97779, mean: -0.45604
[32m[0907 04-53-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29302, current rewards: -286.97779, mean: -0.62386
[32m[0907 04-53-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29310, current rewards: -380.48516, mean: -0.74605
[32m[0907 04-54-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29320, current rewards: -372.62510, mean: -0.66540
[32m[0907 04-54-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29325, current rewards: -364.76552, mean: -0.59798
[32m[0907 04-54-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29328, current rewards: -356.90598, mean: -0.54077
[32m[0907 04-54-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29331, current rewards: -349.04644, mean: -0.49161
[32m[0907 04-55-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29333, current rewards: -341.65015, mean: -0.44954
[32m[0907 04-55-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29336, current rewards: -349.52036, mean: -0.43151
[32m[0907 04-55-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29337, current rewards: -399.52036, mean: -0.46456
[32m[0907 04-55-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29338, current rewards: -449.52036, mean: -0.49398
[32m[0907 04-56-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29340, current rewards: -499.52036, mean: -0.52033
[32m[0907 04-56-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29343, current rewards: -549.52036, mean: -0.54408
[32m[0907 04-56-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29346, current rewards: -599.52036, mean: -0.56559
[32m[0907 04-56-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29346, current rewards: -649.52036, mean: -0.58515
[32m[0907 04-57-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29347, current rewards: -699.52036, mean: -0.60303
[32m[0907 04-57-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29348, current rewards: -749.52036, mean: -0.61944
[32m[0907 04-57-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29346, current rewards: -799.52036, mean: -0.63454
[32m[0907 04-57-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29347, current rewards: -849.52036, mean: -0.64849
[32m[0907 04-58-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29348, current rewards: -899.52036, mean: -0.66141
[32m[0907 04-58-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29347, current rewards: -949.52036, mean: -0.67342
[32m[0907 04-58-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29347, current rewards: -999.52036, mean: -0.68460
[32m[0907 04-58-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29347, current rewards: -1049.52036, mean: -0.69505
[32m[0907 04-59-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29347, current rewards: -1099.52036, mean: -0.70482
[32m[0907 04-59-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29348, current rewards: -1149.52036, mean: -0.71399
[32m[0907 04-59-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29348, current rewards: -1199.52036, mean: -0.72260
[32m[0907 04-59-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29349, current rewards: -1249.52036, mean: -0.73071
[32m[0907 05-00-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29348, current rewards: -1299.52036, mean: -0.73836
[32m[0907 05-00-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29348, current rewards: -1349.52036, mean: -0.74559
[32m[0907 05-00-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29349, current rewards: -1399.52036, mean: -0.75243
[32m[0907 05-00-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29348, current rewards: -1449.52036, mean: -0.75891
[32m[0907 05-01-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29348, current rewards: -1499.52036, mean: -0.76506
[32m[0907 05-01-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29348, current rewards: -1549.52036, mean: -0.77091
[32m[0907 05-01-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29347, current rewards: -1599.52036, mean: -0.77647
[32m[0907 05-01-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29348, current rewards: -1649.52036, mean: -0.78176
[32m[0907 05-02-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29348, current rewards: -1699.52036, mean: -0.78681
[32m[0907 05-02-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29348, current rewards: -1749.52036, mean: -0.79164
[32m[0907 05-02-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29349, current rewards: -1799.52036, mean: -0.79625
[32m[0907 05-02-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29349, current rewards: -1849.52036, mean: -0.80066
[32m[0907 05-03-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29349, current rewards: -1899.52036, mean: -0.80488
[32m[0907 05-03-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29348, current rewards: -1949.52036, mean: -0.80893
[32m[0907 05-03-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29348, current rewards: -1999.52036, mean: -0.81281
[32m[0907 05-03-43 @Agent.py:117][0m Average action selection time: 0.2935
[32m[0907 05-03-43 @Agent.py:118][0m Rollout length: 2600
[32m[0907 05-03-43 @MBExp.py:227][0m Rewards obtained: [-2039.5203606498214], Lows: [144], Highs: [1824], Total time: 43764.244017000005
[32m[0907 05-04-25 @MBExp.py:144][0m ####################################################################
[32m[0907 05-04-25 @MBExp.py:145][0m Starting training iteration 59.
[32m[0907 05-04-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29220, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-04-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29204, current rewards: -60.00000, mean: -1.00000
[32m[0907 05-04-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29206, current rewards: -115.55243, mean: -1.05048
[32m[0907 05-05-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29222, current rewards: -164.79437, mean: -1.02996
[32m[0907 05-05-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29229, current rewards: -214.79437, mean: -1.02283
[32m[0907 05-05-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29232, current rewards: -264.79437, mean: -1.01844
[32m[0907 05-05-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29238, current rewards: -314.79437, mean: -1.01547
[32m[0907 05-06-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29241, current rewards: -364.79437, mean: -1.01332
[32m[0907 05-06-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29250, current rewards: -414.79437, mean: -1.01169
[32m[0907 05-06-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29261, current rewards: -464.79437, mean: -1.01042
[32m[0907 05-06-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29268, current rewards: -514.79437, mean: -1.00940
[32m[0907 05-07-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29275, current rewards: -564.79437, mean: -1.00856
[32m[0907 05-07-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29280, current rewards: -614.79437, mean: -1.00786
[32m[0907 05-07-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29287, current rewards: -664.79437, mean: -1.00726
[32m[0907 05-07-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29293, current rewards: -714.79437, mean: -1.00675
[32m[0907 05-08-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29299, current rewards: -764.79437, mean: -1.00631
[32m[0907 05-08-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29304, current rewards: -814.79437, mean: -1.00592
[32m[0907 05-08-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29307, current rewards: -864.79437, mean: -1.00557
[32m[0907 05-08-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29310, current rewards: -914.79437, mean: -1.00527
[32m[0907 05-09-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29313, current rewards: -964.79437, mean: -1.00499
[32m[0907 05-09-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29314, current rewards: -1014.79437, mean: -1.00475
[32m[0907 05-09-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29317, current rewards: -1064.79437, mean: -1.00452
[32m[0907 05-09-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29318, current rewards: -1114.79437, mean: -1.00432
[32m[0907 05-10-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29320, current rewards: -1164.79437, mean: -1.00413
[32m[0907 05-10-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29322, current rewards: -1214.79437, mean: -1.00396
[32m[0907 05-10-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29323, current rewards: -1241.08166, mean: -0.98499
[32m[0907 05-10-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29325, current rewards: -1234.62284, mean: -0.94246
[32m[0907 05-11-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29326, current rewards: -1228.16402, mean: -0.90306
[32m[0907 05-11-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29328, current rewards: -1223.96355, mean: -0.86806
[32m[0907 05-11-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29329, current rewards: -1273.96355, mean: -0.87258
[32m[0907 05-11-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29330, current rewards: -1323.96355, mean: -0.87680
[32m[0907 05-12-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29331, current rewards: -1373.96355, mean: -0.88075
[32m[0907 05-12-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29333, current rewards: -1423.96355, mean: -0.88445
[32m[0907 05-12-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29333, current rewards: -1473.96355, mean: -0.88793
[32m[0907 05-12-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29334, current rewards: -1523.96355, mean: -0.89121
[32m[0907 05-13-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29334, current rewards: -1573.96355, mean: -0.89430
[32m[0907 05-13-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29334, current rewards: -1623.96355, mean: -0.89722
[32m[0907 05-13-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29334, current rewards: -1673.96355, mean: -0.89998
[32m[0907 05-13-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29334, current rewards: -1723.96355, mean: -0.90260
[32m[0907 05-14-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29335, current rewards: -1773.96355, mean: -0.90508
[32m[0907 05-14-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29335, current rewards: -1823.96355, mean: -0.90744
[32m[0907 05-14-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29337, current rewards: -1873.96355, mean: -0.90969
[32m[0907 05-14-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29337, current rewards: -1923.96355, mean: -0.91183
[32m[0907 05-14-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29338, current rewards: -1973.96355, mean: -0.91387
[32m[0907 05-15-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29338, current rewards: -2023.96355, mean: -0.91582
[32m[0907 05-15-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29338, current rewards: -2073.96355, mean: -0.91768
[32m[0907 05-15-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29338, current rewards: -2123.96355, mean: -0.91946
[32m[0907 05-15-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29338, current rewards: -2173.96355, mean: -0.92117
[32m[0907 05-16-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29339, current rewards: -2223.96355, mean: -0.92281
[32m[0907 05-16-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29339, current rewards: -2273.96355, mean: -0.92438
[32m[0907 05-16-39 @Agent.py:117][0m Average action selection time: 0.2934
[32m[0907 05-16-39 @Agent.py:118][0m Rollout length: 2600
[32m[0907 05-16-39 @MBExp.py:227][0m Rewards obtained: [-2313.9635458341772], Lows: [17], Highs: [2304], Total time: 44498.03911800001
[32m[0907 05-17-22 @MBExp.py:144][0m ####################################################################
[32m[0907 05-17-22 @MBExp.py:145][0m Starting training iteration 60.
[32m[0907 05-17-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29246, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-17-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29234, current rewards: -60.00000, mean: -1.00000
[32m[0907 05-17-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31540, current rewards: -97.87759, mean: -0.88980
[32m[0907 05-18-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31186, current rewards: -192.34337, mean: -1.20215
[32m[0907 05-18-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30727, current rewards: -261.97445, mean: -1.24750
[32m[0907 05-18-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30477, current rewards: -344.09842, mean: -1.32346
[32m[0907 05-18-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30280, current rewards: -444.09842, mean: -1.43258
[32m[0907 05-19-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30305, current rewards: -539.51414, mean: -1.49865
[32m[0907 05-19-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30188, current rewards: -637.07217, mean: -1.55383
[32m[0907 05-19-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30100, current rewards: -727.10288, mean: -1.58066
[32m[0907 05-19-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30027, current rewards: -827.10288, mean: -1.62177
[32m[0907 05-20-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29966, current rewards: -927.10288, mean: -1.65554
[32m[0907 05-20-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29919, current rewards: -1027.10288, mean: -1.68378
[32m[0907 05-20-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29907, current rewards: -1127.10288, mean: -1.70773
[32m[0907 05-20-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29866, current rewards: -1227.10288, mean: -1.72831
[32m[0907 05-21-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29831, current rewards: -1277.47894, mean: -1.68089
[32m[0907 05-21-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29802, current rewards: -1273.74163, mean: -1.57252
[32m[0907 05-21-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29775, current rewards: -1305.84233, mean: -1.51842
[32m[0907 05-21-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29751, current rewards: -1355.84233, mean: -1.48994
[32m[0907 05-22-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29729, current rewards: -1405.84233, mean: -1.46442
[32m[0907 05-22-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29712, current rewards: -1455.84233, mean: -1.44143
[32m[0907 05-22-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29695, current rewards: -1505.84233, mean: -1.42061
[32m[0907 05-22-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29681, current rewards: -1555.84233, mean: -1.40166
[32m[0907 05-23-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29667, current rewards: -1605.84233, mean: -1.38435
[32m[0907 05-23-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29653, current rewards: -1655.84233, mean: -1.36846
[32m[0907 05-23-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29641, current rewards: -1705.84233, mean: -1.35384
[32m[0907 05-23-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29630, current rewards: -1755.84233, mean: -1.34034
[32m[0907 05-24-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29620, current rewards: -1805.84233, mean: -1.32783
[32m[0907 05-24-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29611, current rewards: -1855.84233, mean: -1.31620
[32m[0907 05-24-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29603, current rewards: -1905.84233, mean: -1.30537
[32m[0907 05-24-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29595, current rewards: -1955.84233, mean: -1.29526
[32m[0907 05-25-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29587, current rewards: -1967.98475, mean: -1.26153
[32m[0907 05-25-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29579, current rewards: -1965.39753, mean: -1.22074
[32m[0907 05-25-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29572, current rewards: -2013.29404, mean: -1.21283
[32m[0907 05-25-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29565, current rewards: -2063.29404, mean: -1.20660
[32m[0907 05-26-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29559, current rewards: -2113.29404, mean: -1.20074
[32m[0907 05-26-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29553, current rewards: -2163.29404, mean: -1.19519
[32m[0907 05-26-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29547, current rewards: -2213.29404, mean: -1.18994
[32m[0907 05-26-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29542, current rewards: -2263.29404, mean: -1.18497
[32m[0907 05-27-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29537, current rewards: -2313.29404, mean: -1.18025
[32m[0907 05-27-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29531, current rewards: -2363.29404, mean: -1.17577
[32m[0907 05-27-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29527, current rewards: -2413.29404, mean: -1.17150
[32m[0907 05-27-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29523, current rewards: -2463.29404, mean: -1.16744
[32m[0907 05-28-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29518, current rewards: -2513.29404, mean: -1.16356
[32m[0907 05-28-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29514, current rewards: -2563.29404, mean: -1.15986
[32m[0907 05-28-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29509, current rewards: -2613.29404, mean: -1.15632
[32m[0907 05-28-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29504, current rewards: -2663.29404, mean: -1.15294
[32m[0907 05-28-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29502, current rewards: -2713.29404, mean: -1.14970
[32m[0907 05-29-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29499, current rewards: -2763.29404, mean: -1.14660
[32m[0907 05-29-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29497, current rewards: -2813.29404, mean: -1.14362
[32m[0907 05-29-40 @Agent.py:117][0m Average action selection time: 0.2950
[32m[0907 05-29-40 @Agent.py:118][0m Rollout length: 2600
[32m[0907 05-29-40 @MBExp.py:227][0m Rewards obtained: [-2853.294038518587], Lows: [595], Highs: [1687], Total time: 45235.743054000006
[32m[0907 05-30-22 @MBExp.py:144][0m ####################################################################
[32m[0907 05-30-22 @MBExp.py:145][0m Starting training iteration 61.
[32m[0907 05-30-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31173, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-30-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30839, current rewards: -60.00000, mean: -1.00000
[32m[0907 05-30-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30106, current rewards: -113.60138, mean: -1.03274
[32m[0907 05-31-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29837, current rewards: -213.60138, mean: -1.33501
[32m[0907 05-31-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29701, current rewards: -313.60138, mean: -1.49334
[32m[0907 05-31-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29619, current rewards: -413.60138, mean: -1.59077
[32m[0907 05-31-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29563, current rewards: -513.60138, mean: -1.65678
[32m[0907 05-32-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29530, current rewards: -613.60138, mean: -1.70445
[32m[0907 05-32-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29514, current rewards: -713.60138, mean: -1.74049
[32m[0907 05-32-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29499, current rewards: -813.60138, mean: -1.76870
[32m[0907 05-32-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29488, current rewards: -913.60138, mean: -1.79138
[32m[0907 05-33-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29478, current rewards: -1013.60138, mean: -1.81000
[32m[0907 05-33-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29469, current rewards: -1113.60138, mean: -1.82558
[32m[0907 05-33-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29459, current rewards: -1213.60138, mean: -1.83879
[32m[0907 05-33-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29451, current rewards: -1313.60138, mean: -1.85014
[32m[0907 05-34-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29447, current rewards: -1413.60138, mean: -1.86000
[32m[0907 05-34-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29442, current rewards: -1513.60138, mean: -1.86864
[32m[0907 05-34-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29438, current rewards: -1613.60138, mean: -1.87628
[32m[0907 05-34-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29433, current rewards: -1713.60138, mean: -1.88308
[32m[0907 05-35-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29430, current rewards: -1813.60138, mean: -1.88917
[32m[0907 05-35-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29427, current rewards: -1913.60138, mean: -1.89465
[32m[0907 05-35-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29423, current rewards: -2013.60138, mean: -1.89962
[32m[0907 05-35-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29419, current rewards: -2113.60138, mean: -1.90415
[32m[0907 05-36-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29416, current rewards: -2213.60138, mean: -1.90828
[32m[0907 05-36-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29413, current rewards: -2313.60138, mean: -1.91207
[32m[0907 05-36-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29409, current rewards: -2413.60138, mean: -1.91556
[32m[0907 05-36-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29407, current rewards: -2513.60138, mean: -1.91878
[32m[0907 05-37-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29405, current rewards: -2613.60138, mean: -1.92177
[32m[0907 05-37-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29401, current rewards: -2713.60138, mean: -1.92454
[32m[0907 05-37-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29399, current rewards: -2813.60138, mean: -1.92712
[32m[0907 05-37-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29397, current rewards: -2913.60138, mean: -1.92954
[32m[0907 05-38-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29395, current rewards: -3013.60138, mean: -1.93180
[32m[0907 05-38-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29393, current rewards: -3113.60138, mean: -1.93391
[32m[0907 05-38-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29391, current rewards: -3213.60138, mean: -1.93590
[32m[0907 05-38-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29390, current rewards: -3313.60138, mean: -1.93778
[32m[0907 05-38-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29389, current rewards: -3413.60138, mean: -1.93955
[32m[0907 05-39-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29388, current rewards: -3513.60138, mean: -1.94122
[32m[0907 05-39-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29386, current rewards: -3613.60138, mean: -1.94280
[32m[0907 05-39-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29385, current rewards: -3713.60138, mean: -1.94429
[32m[0907 05-39-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29384, current rewards: -3813.60138, mean: -1.94571
[32m[0907 05-40-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29384, current rewards: -3913.60138, mean: -1.94707
[32m[0907 05-40-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29384, current rewards: -4013.60138, mean: -1.94835
[32m[0907 05-40-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29383, current rewards: -4113.60138, mean: -1.94957
[32m[0907 05-40-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29382, current rewards: -4213.60138, mean: -1.95074
[32m[0907 05-41-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29380, current rewards: -4313.60138, mean: -1.95186
[32m[0907 05-41-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29380, current rewards: -4413.60138, mean: -1.95292
[32m[0907 05-41-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29380, current rewards: -4513.60138, mean: -1.95394
[32m[0907 05-41-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29379, current rewards: -4613.60138, mean: -1.95492
[32m[0907 05-42-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29377, current rewards: -4713.60138, mean: -1.95585
[32m[0907 05-42-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29376, current rewards: -4813.60138, mean: -1.95675
[32m[0907 05-42-36 @Agent.py:117][0m Average action selection time: 0.2938
[32m[0907 05-42-36 @Agent.py:118][0m Rollout length: 2600
[32m[0907 05-42-36 @MBExp.py:227][0m Rewards obtained: [-4893.601380866627], Lows: [2396], Highs: [102], Total time: 45970.462914
[32m[0907 05-43-20 @MBExp.py:144][0m ####################################################################
[32m[0907 05-43-20 @MBExp.py:145][0m Starting training iteration 62.
[32m[0907 05-43-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29192, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-43-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29176, current rewards: -60.00000, mean: -1.00000
[32m[0907 05-43-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29204, current rewards: -117.79991, mean: -1.07091
[32m[0907 05-44-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29222, current rewards: -217.79991, mean: -1.36125
[32m[0907 05-44-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29236, current rewards: -300.09656, mean: -1.42903
[32m[0907 05-44-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29242, current rewards: -333.99336, mean: -1.28459
[32m[0907 05-44-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29252, current rewards: -433.99336, mean: -1.39998
[32m[0907 05-45-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29259, current rewards: -533.99336, mean: -1.48331
[32m[0907 05-45-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29272, current rewards: -559.25300, mean: -1.36403
[32m[0907 05-45-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29286, current rewards: -553.30295, mean: -1.20283
[32m[0907 05-45-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29295, current rewards: -569.51107, mean: -1.11669
[32m[0907 05-46-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29302, current rewards: -563.49779, mean: -1.00625
[32m[0907 05-46-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29309, current rewards: -620.48816, mean: -1.01719
[32m[0907 05-46-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29315, current rewards: -696.50484, mean: -1.05531
[32m[0907 05-46-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29318, current rewards: -703.64350, mean: -0.99105
[32m[0907 05-47-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29320, current rewards: -699.11406, mean: -0.91989
[32m[0907 05-47-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29324, current rewards: -690.41135, mean: -0.85236
[32m[0907 05-47-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29327, current rewards: -683.10980, mean: -0.79431
[32m[0907 05-47-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29330, current rewards: -675.03345, mean: -0.74179
[32m[0907 05-48-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29332, current rewards: -666.10982, mean: -0.69386
[32m[0907 05-48-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29332, current rewards: -678.10070, mean: -0.67139
[32m[0907 05-48-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29333, current rewards: -728.10070, mean: -0.68689
[32m[0907 05-48-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29334, current rewards: -758.18177, mean: -0.68305
[32m[0907 05-49-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29337, current rewards: -796.90170, mean: -0.68698
[32m[0907 05-49-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29339, current rewards: -812.48918, mean: -0.67148
[32m[0907 05-49-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29341, current rewards: -842.45337, mean: -0.66861
[32m[0907 05-49-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29343, current rewards: -852.82738, mean: -0.65101
[32m[0907 05-49-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29344, current rewards: -843.11243, mean: -0.61994
[32m[0907 05-50-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29347, current rewards: -836.93371, mean: -0.59357
[32m[0907 05-50-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29349, current rewards: -853.06965, mean: -0.58429
[32m[0907 05-50-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29349, current rewards: -853.99331, mean: -0.56556
[32m[0907 05-51-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29575, current rewards: -920.86304, mean: -0.59030
[32m[0907 05-51-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29569, current rewards: -1020.86304, mean: -0.63408
[32m[0907 05-51-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29562, current rewards: -1077.64427, mean: -0.64918
[32m[0907 05-51-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29556, current rewards: -1079.71828, mean: -0.63141
[32m[0907 05-52-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29551, current rewards: -1153.66754, mean: -0.65549
[32m[0907 05-52-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29545, current rewards: -1156.98437, mean: -0.63922
[32m[0907 05-52-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29540, current rewards: -1181.77821, mean: -0.63536
[32m[0907 05-52-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29536, current rewards: -1194.18511, mean: -0.62523
[32m[0907 05-52-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29532, current rewards: -1294.18511, mean: -0.66030
[32m[0907 05-53-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29529, current rewards: -1306.01031, mean: -0.64976
[32m[0907 05-53-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29525, current rewards: -1326.91792, mean: -0.64413
[32m[0907 05-53-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29521, current rewards: -1376.91792, mean: -0.65257
[32m[0907 05-53-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29518, current rewards: -1401.33122, mean: -0.64876
[32m[0907 05-54-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29514, current rewards: -1501.33122, mean: -0.67934
[32m[0907 05-54-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29511, current rewards: -1601.33122, mean: -0.70855
[32m[0907 05-54-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29507, current rewards: -1701.33122, mean: -0.73651
[32m[0907 05-54-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29504, current rewards: -1801.33122, mean: -0.76328
[32m[0907 05-55-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29501, current rewards: -1901.33122, mean: -0.78893
[32m[0907 05-55-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29499, current rewards: -2001.33122, mean: -0.81355
[32m[0907 05-55-38 @Agent.py:117][0m Average action selection time: 0.2950
[32m[0907 05-55-38 @Agent.py:118][0m Rollout length: 2600
[32m[0907 05-55-38 @MBExp.py:227][0m Rewards obtained: [-2081.331219157274], Lows: [930], Highs: [423], Total time: 46708.223751000005
[32m[0907 05-56-21 @MBExp.py:144][0m ####################################################################
[32m[0907 05-56-21 @MBExp.py:145][0m Starting training iteration 63.
[32m[0907 05-56-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31243, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-56-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29567, current rewards: -60.00000, mean: -1.00000
[32m[0907 05-56-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29594, current rewards: -119.00000, mean: -1.08182
[32m[0907 05-57-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29489, current rewards: -219.00000, mean: -1.36875
[32m[0907 05-57-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29903, current rewards: -314.89244, mean: -1.49949
[32m[0907 05-57-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29780, current rewards: -312.04540, mean: -1.20017
[32m[0907 05-57-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29702, current rewards: -347.15786, mean: -1.11986
[32m[0907 05-58-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29653, current rewards: -447.15786, mean: -1.24211
[32m[0907 05-58-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30072, current rewards: -547.15786, mean: -1.33453
[32m[0907 05-58-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30334, current rewards: -632.73810, mean: -1.37552
[32m[0907 05-58-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30239, current rewards: -722.17503, mean: -1.41603
[32m[0907 05-59-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30213, current rewards: -781.87396, mean: -1.39620
[32m[0907 05-59-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30143, current rewards: -831.87396, mean: -1.36373
[32m[0907 05-59-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30085, current rewards: -903.89407, mean: -1.36954
[32m[0907 05-59-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30047, current rewards: -1003.89407, mean: -1.41394
[32m[0907 06-00-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30080, current rewards: -1059.47179, mean: -1.39404
[32m[0907 06-00-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30035, current rewards: -1129.13647, mean: -1.39400
[32m[0907 06-00-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29996, current rewards: -1198.34355, mean: -1.39342
[32m[0907 06-00-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29961, current rewards: -1248.34355, mean: -1.37181
[32m[0907 06-01-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29930, current rewards: -1298.34355, mean: -1.35244
[32m[0907 06-01-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29902, current rewards: -1338.34996, mean: -1.32510
[32m[0907 06-01-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29874, current rewards: -1438.34996, mean: -1.35693
[32m[0907 06-01-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29851, current rewards: -1538.34996, mean: -1.38590
[32m[0907 06-02-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29830, current rewards: -1638.34996, mean: -1.41237
[32m[0907 06-02-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29812, current rewards: -1738.34996, mean: -1.43665
[32m[0907 06-02-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29794, current rewards: -1838.34996, mean: -1.45901
[32m[0907 06-02-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29778, current rewards: -1938.34996, mean: -1.47966
[32m[0907 06-03-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29761, current rewards: -2038.34996, mean: -1.49879
[32m[0907 06-03-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29747, current rewards: -2138.34996, mean: -1.51656
[32m[0907 06-03-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29732, current rewards: -2238.34996, mean: -1.53312
[32m[0907 06-03-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29718, current rewards: -2338.34996, mean: -1.54858
[32m[0907 06-04-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29705, current rewards: -2438.34996, mean: -1.56304
[32m[0907 06-04-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29695, current rewards: -2538.34996, mean: -1.57661
[32m[0907 06-04-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29685, current rewards: -2638.34996, mean: -1.58937
[32m[0907 06-04-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29677, current rewards: -2738.34996, mean: -1.60137
[32m[0907 06-05-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29669, current rewards: -2838.34996, mean: -1.61270
[32m[0907 06-05-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29660, current rewards: -2938.34996, mean: -1.62340
[32m[0907 06-05-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29652, current rewards: -3038.34996, mean: -1.63352
[32m[0907 06-05-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29644, current rewards: -3138.34996, mean: -1.64312
[32m[0907 06-06-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29637, current rewards: -3238.34996, mean: -1.65222
[32m[0907 06-06-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29629, current rewards: -3338.34996, mean: -1.66087
[32m[0907 06-06-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29622, current rewards: -3438.34996, mean: -1.66910
[32m[0907 06-06-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29615, current rewards: -3538.34996, mean: -1.67694
[32m[0907 06-07-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29608, current rewards: -3638.34996, mean: -1.68442
[32m[0907 06-07-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29601, current rewards: -3738.34996, mean: -1.69156
[32m[0907 06-07-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29594, current rewards: -3838.34996, mean: -1.69838
[32m[0907 06-07-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29587, current rewards: -3938.34996, mean: -1.70491
[32m[0907 06-07-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29582, current rewards: -4038.34996, mean: -1.71117
[32m[0907 06-08-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29578, current rewards: -4138.34996, mean: -1.71716
[32m[0907 06-08-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29574, current rewards: -4238.34996, mean: -1.72291
[32m[0907 06-08-40 @Agent.py:117][0m Average action selection time: 0.2957
[32m[0907 06-08-40 @Agent.py:118][0m Rollout length: 2600
[32m[0907 06-08-40 @MBExp.py:227][0m Rewards obtained: [-4318.3499621158135], Lows: [1984], Highs: [369], Total time: 47447.82662400001
[32m[0907 06-09-27 @MBExp.py:144][0m ####################################################################
[32m[0907 06-09-27 @MBExp.py:145][0m Starting training iteration 64.
[32m[0907 06-09-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29238, current rewards: 0.76517, mean: 0.07652
[32m[0907 06-09-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29241, current rewards: 3.29254, mean: 0.05488
[32m[0907 06-09-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29242, current rewards: 5.79446, mean: 0.05268
[32m[0907 06-10-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29239, current rewards: 8.29408, mean: 0.05184
[32m[0907 06-10-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29244, current rewards: 11.22401, mean: 0.05345
[32m[0907 06-10-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29246, current rewards: -81.84786, mean: -0.31480
[32m[0907 06-10-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29250, current rewards: -158.80286, mean: -0.51227
[32m[0907 06-11-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29256, current rewards: -208.80286, mean: -0.58001
[32m[0907 06-11-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29271, current rewards: -262.69589, mean: -0.64072
[32m[0907 06-11-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29280, current rewards: -362.69589, mean: -0.78847
[32m[0907 06-11-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29286, current rewards: -462.69589, mean: -0.90725
[32m[0907 06-12-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29292, current rewards: -516.16131, mean: -0.92172
[32m[0907 06-12-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29297, current rewards: -616.16131, mean: -1.01010
[32m[0907 06-12-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29304, current rewards: -697.03717, mean: -1.05612
[32m[0907 06-12-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29307, current rewards: -772.99648, mean: -1.08873
[32m[0907 06-13-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29399, current rewards: -872.99648, mean: -1.14868
[32m[0907 06-13-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29408, current rewards: -939.03171, mean: -1.15930
[32m[0907 06-13-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29405, current rewards: -996.44662, mean: -1.15866
[32m[0907 06-13-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29402, current rewards: -1092.31095, mean: -1.20034
[32m[0907 06-14-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29399, current rewards: -1192.31095, mean: -1.24199
[32m[0907 06-14-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29397, current rewards: -1250.39496, mean: -1.23801
[32m[0907 06-14-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29396, current rewards: -1300.39496, mean: -1.22679
[32m[0907 06-14-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29395, current rewards: -1369.31722, mean: -1.23362
[32m[0907 06-15-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29393, current rewards: -1469.31722, mean: -1.26665
[32m[0907 06-15-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29391, current rewards: -1546.09509, mean: -1.27776
[32m[0907 06-15-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29389, current rewards: -1592.87386, mean: -1.26419
[32m[0907 06-15-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29387, current rewards: -1642.87386, mean: -1.25410
[32m[0907 06-16-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29411, current rewards: -1716.91487, mean: -1.26244
[32m[0907 06-16-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29406, current rewards: -1816.91487, mean: -1.28859
[32m[0907 06-16-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29402, current rewards: -1902.22097, mean: -1.30289
[32m[0907 06-16-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29400, current rewards: -2002.22097, mean: -1.32597
[32m[0907 06-17-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29399, current rewards: -2081.70455, mean: -1.33443
[32m[0907 06-17-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29398, current rewards: -2131.70455, mean: -1.32404
[32m[0907 06-17-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29397, current rewards: -2181.70455, mean: -1.31428
[32m[0907 06-17-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29396, current rewards: -2231.70455, mean: -1.30509
[32m[0907 06-18-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29395, current rewards: -2281.27397, mean: -1.29618
[32m[0907 06-18-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29395, current rewards: -2378.97085, mean: -1.31435
[32m[0907 06-18-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29393, current rewards: -2478.97085, mean: -1.33278
[32m[0907 06-18-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29392, current rewards: -2578.97085, mean: -1.35025
[32m[0907 06-19-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29392, current rewards: -2678.97085, mean: -1.36682
[32m[0907 06-19-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29391, current rewards: -2778.97085, mean: -1.38257
[32m[0907 06-19-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29390, current rewards: -2878.97085, mean: -1.39756
[32m[0907 06-19-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29389, current rewards: -2978.97085, mean: -1.41183
[32m[0907 06-20-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29389, current rewards: -3078.97085, mean: -1.42545
[32m[0907 06-20-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29388, current rewards: -3178.97085, mean: -1.43845
[32m[0907 06-20-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29388, current rewards: -3278.97085, mean: -1.45087
[32m[0907 06-20-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29388, current rewards: -3378.97085, mean: -1.46276
[32m[0907 06-21-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29388, current rewards: -3478.97085, mean: -1.47414
[32m[0907 06-21-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29388, current rewards: -3578.97085, mean: -1.48505
[32m[0907 06-21-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29387, current rewards: -3678.97085, mean: -1.49552
[32m[0907 06-21-42 @Agent.py:117][0m Average action selection time: 0.2939
[32m[0907 06-21-42 @Agent.py:118][0m Rollout length: 2600
[32m[0907 06-21-42 @MBExp.py:227][0m Rewards obtained: [-3758.9708481668213], Lows: [1618], Highs: [552], Total time: 48182.807015000006
[32m[0907 06-22-28 @MBExp.py:144][0m ####################################################################
[32m[0907 06-22-28 @MBExp.py:145][0m Starting training iteration 65.
[32m[0907 06-22-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29219, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-22-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29194, current rewards: -60.00000, mean: -1.00000
[32m[0907 06-23-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29221, current rewards: -120.00000, mean: -1.09091
[32m[0907 06-23-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29905, current rewards: -220.00000, mean: -1.37500
[32m[0907 06-23-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29751, current rewards: -317.77166, mean: -1.51320
[32m[0907 06-23-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29662, current rewards: -387.77862, mean: -1.49146
[32m[0907 06-24-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30325, current rewards: -487.77862, mean: -1.57348
[32m[0907 06-24-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31597, current rewards: -548.77205, mean: -1.52437
[32m[0907 06-24-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31712, current rewards: -597.04328, mean: -1.45620
[32m[0907 06-24-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31455, current rewards: -611.23529, mean: -1.32877
[32m[0907 06-25-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31328, current rewards: -687.99915, mean: -1.34902
[32m[0907 06-25-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31148, current rewards: -746.52406, mean: -1.33308
[32m[0907 06-25-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31016, current rewards: -828.60493, mean: -1.35837
[32m[0907 06-25-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30964, current rewards: -897.44505, mean: -1.35977
[32m[0907 06-26-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31113, current rewards: -964.69937, mean: -1.35873
[32m[0907 06-26-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31330, current rewards: -1012.01673, mean: -1.33160
[32m[0907 06-26-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31209, current rewards: -1053.56905, mean: -1.30070
[32m[0907 06-26-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31100, current rewards: -1118.61160, mean: -1.30071
[32m[0907 06-27-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31002, current rewards: -1218.61160, mean: -1.33913
[32m[0907 06-27-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30916, current rewards: -1318.61160, mean: -1.37355
[32m[0907 06-27-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30838, current rewards: -1418.61160, mean: -1.40457
[32m[0907 06-27-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30767, current rewards: -1518.61160, mean: -1.43265
[32m[0907 06-28-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30702, current rewards: -1618.61160, mean: -1.45821
[32m[0907 06-28-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30644, current rewards: -1718.61160, mean: -1.48156
[32m[0907 06-28-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30590, current rewards: -1818.61160, mean: -1.50298
[32m[0907 06-28-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30541, current rewards: -1918.61160, mean: -1.52271
[32m[0907 06-29-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30496, current rewards: -2018.61160, mean: -1.54092
[32m[0907 06-29-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30456, current rewards: -2118.61160, mean: -1.55780
[32m[0907 06-29-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30418, current rewards: -2218.61160, mean: -1.57348
[32m[0907 06-29-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30382, current rewards: -2318.61160, mean: -1.58809
[32m[0907 06-30-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30349, current rewards: -2418.61160, mean: -1.60173
[32m[0907 06-30-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30317, current rewards: -2518.61160, mean: -1.61449
[32m[0907 06-30-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30288, current rewards: -2618.61160, mean: -1.62647
[32m[0907 06-30-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30259, current rewards: -2718.61160, mean: -1.63772
[32m[0907 06-31-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30233, current rewards: -2818.61160, mean: -1.64831
[32m[0907 06-31-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30209, current rewards: -2918.61160, mean: -1.65830
[32m[0907 06-31-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30187, current rewards: -3018.61160, mean: -1.66774
[32m[0907 06-31-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30165, current rewards: -3118.61160, mean: -1.67667
[32m[0907 06-32-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30143, current rewards: -3218.61160, mean: -1.68514
[32m[0907 06-32-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30123, current rewards: -3318.61160, mean: -1.69317
[32m[0907 06-32-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30102, current rewards: -3418.61160, mean: -1.70080
[32m[0907 06-32-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30083, current rewards: -3518.61160, mean: -1.70806
[32m[0907 06-33-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30064, current rewards: -3618.61160, mean: -1.71498
[32m[0907 06-33-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30047, current rewards: -3718.61160, mean: -1.72158
[32m[0907 06-33-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30033, current rewards: -3818.61160, mean: -1.72788
[32m[0907 06-33-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30018, current rewards: -3918.61160, mean: -1.73390
[32m[0907 06-34-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30004, current rewards: -4018.61160, mean: -1.73966
[32m[0907 06-34-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29990, current rewards: -4118.61160, mean: -1.74517
[32m[0907 06-34-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29977, current rewards: -4218.61160, mean: -1.75046
[32m[0907 06-34-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29964, current rewards: -4318.61160, mean: -1.75553
[32m[0907 06-34-58 @Agent.py:117][0m Average action selection time: 0.2995
[32m[0907 06-34-58 @Agent.py:118][0m Rollout length: 2600
[32m[0907 06-34-58 @MBExp.py:227][0m Rewards obtained: [-4398.611601578292], Lows: [2114], Highs: [206], Total time: 48931.99428400001
[32m[0907 06-35-45 @MBExp.py:144][0m ####################################################################
[32m[0907 06-35-45 @MBExp.py:145][0m Starting training iteration 66.
[32m[0907 06-35-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.46694, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-36-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.35686, current rewards: -60.00000, mean: -1.00000
[32m[0907 06-36-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32747, current rewards: -100.52934, mean: -0.91390
[32m[0907 06-36-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32746, current rewards: -147.23688, mean: -0.92023
[32m[0907 06-36-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.33397, current rewards: -197.23688, mean: -0.93922
[32m[0907 06-37-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32602, current rewards: -277.23688, mean: -1.06630
[32m[0907 06-37-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32063, current rewards: -320.29717, mean: -1.03322
[32m[0907 06-37-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31677, current rewards: -370.29717, mean: -1.02860
[32m[0907 06-37-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31384, current rewards: -432.50354, mean: -1.05489
[32m[0907 06-38-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31159, current rewards: -432.01243, mean: -0.93916
[32m[0907 06-38-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30985, current rewards: -434.47098, mean: -0.85190
[32m[0907 06-38-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30839, current rewards: -426.16917, mean: -0.76102
[32m[0907 06-38-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30956, current rewards: -400.93293, mean: -0.65727
[32m[0907 06-39-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30832, current rewards: -454.86682, mean: -0.68919
[32m[0907 06-39-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30723, current rewards: -459.99704, mean: -0.64788
[32m[0907 06-39-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30626, current rewards: -457.03196, mean: -0.60136
[32m[0907 06-39-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30542, current rewards: -454.07179, mean: -0.56058
[32m[0907 06-40-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30470, current rewards: -451.11163, mean: -0.52455
[32m[0907 06-40-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30428, current rewards: -464.03951, mean: -0.50993
[32m[0907 06-40-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30372, current rewards: -516.98508, mean: -0.53853
[32m[0907 06-40-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30322, current rewards: -565.54438, mean: -0.55994
[32m[0907 06-41-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30277, current rewards: -615.54438, mean: -0.58070
[32m[0907 06-41-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30237, current rewards: -665.54438, mean: -0.59959
[32m[0907 06-41-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30200, current rewards: -715.54438, mean: -0.61685
[32m[0907 06-41-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30166, current rewards: -765.54438, mean: -0.63268
[32m[0907 06-42-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30135, current rewards: -815.54438, mean: -0.64726
[32m[0907 06-42-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30106, current rewards: -865.54438, mean: -0.66072
[32m[0907 06-42-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30079, current rewards: -915.54438, mean: -0.67319
[32m[0907 06-42-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30054, current rewards: -965.54438, mean: -0.68478
[32m[0907 06-43-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30030, current rewards: -1015.54438, mean: -0.69558
[32m[0907 06-43-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30007, current rewards: -1065.54438, mean: -0.70566
[32m[0907 06-43-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29986, current rewards: -1115.54438, mean: -0.71509
[32m[0907 06-43-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29966, current rewards: -1165.54438, mean: -0.72394
[32m[0907 06-44-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29947, current rewards: -1215.54438, mean: -0.73226
[32m[0907 06-44-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29928, current rewards: -1265.54438, mean: -0.74008
[32m[0907 06-44-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29911, current rewards: -1315.54438, mean: -0.74747
[32m[0907 06-44-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29897, current rewards: -1365.54438, mean: -0.75444
[32m[0907 06-45-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29882, current rewards: -1415.54438, mean: -0.76105
[32m[0907 06-45-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29869, current rewards: -1465.54438, mean: -0.76730
[32m[0907 06-45-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29857, current rewards: -1515.54438, mean: -0.77324
[32m[0907 06-45-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29845, current rewards: -1565.54438, mean: -0.77888
[32m[0907 06-46-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29832, current rewards: -1615.54438, mean: -0.78424
[32m[0907 06-46-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29821, current rewards: -1665.54438, mean: -0.78936
[32m[0907 06-46-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29810, current rewards: -1715.54438, mean: -0.79423
[32m[0907 06-46-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29800, current rewards: -1765.54438, mean: -0.79889
[32m[0907 06-46-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29788, current rewards: -1815.54438, mean: -0.80334
[32m[0907 06-47-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29777, current rewards: -1865.54438, mean: -0.80759
[32m[0907 06-47-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29766, current rewards: -1915.54438, mean: -0.81167
[32m[0907 06-47-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29756, current rewards: -1965.54438, mean: -0.81558
[32m[0907 06-47-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29747, current rewards: -2015.54438, mean: -0.81933
[32m[0907 06-48-09 @Agent.py:117][0m Average action selection time: 0.2974
[32m[0907 06-48-09 @Agent.py:118][0m Rollout length: 2600
[32m[0907 06-48-09 @MBExp.py:227][0m Rewards obtained: [-2055.5443800226712], Lows: [118], Highs: [1893], Total time: 49675.84276000001
[32m[0907 06-48-58 @MBExp.py:144][0m ####################################################################
[32m[0907 06-48-58 @MBExp.py:145][0m Starting training iteration 67.
[32m[0907 06-49-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30164, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-49-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29362, current rewards: -60.00000, mean: -1.00000
[32m[0907 06-49-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29303, current rewards: -115.84647, mean: -1.05315
[32m[0907 06-49-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30373, current rewards: -215.84647, mean: -1.34904
[32m[0907 06-50-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30103, current rewards: -315.84647, mean: -1.50403
[32m[0907 06-50-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30501, current rewards: -351.06610, mean: -1.35025
[32m[0907 06-50-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30302, current rewards: -400.89855, mean: -1.29322
[32m[0907 06-50-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30164, current rewards: -476.52634, mean: -1.32368
[32m[0907 06-51-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31678, current rewards: -514.69672, mean: -1.25536
[32m[0907 06-51-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32048, current rewards: -596.63573, mean: -1.29703
[32m[0907 06-51-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31775, current rewards: -696.63573, mean: -1.36595
[32m[0907 06-51-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31741, current rewards: -737.09534, mean: -1.31624
[32m[0907 06-52-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31537, current rewards: -805.63371, mean: -1.32071
[32m[0907 06-52-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31663, current rewards: -884.40812, mean: -1.34001
[32m[0907 06-52-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31707, current rewards: -984.40812, mean: -1.38649
[32m[0907 06-52-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31552, current rewards: -1082.23970, mean: -1.42400
[32m[0907 06-53-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31536, current rewards: -1140.92559, mean: -1.40855
[32m[0907 06-53-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31407, current rewards: -1190.92559, mean: -1.38480
[32m[0907 06-53-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31299, current rewards: -1290.92559, mean: -1.41860
[32m[0907 06-53-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31193, current rewards: -1390.92559, mean: -1.44888
[32m[0907 06-54-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31099, current rewards: -1446.69770, mean: -1.43237
[32m[0907 06-54-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31017, current rewards: -1546.69770, mean: -1.45915
[32m[0907 06-54-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30944, current rewards: -1646.69770, mean: -1.48351
[32m[0907 06-54-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30919, current rewards: -1721.63890, mean: -1.48417
[32m[0907 06-55-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31015, current rewards: -1782.00541, mean: -1.47273
[32m[0907 06-55-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30950, current rewards: -1865.34854, mean: -1.48044
[32m[0907 06-55-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30957, current rewards: -1887.54947, mean: -1.44088
[32m[0907 06-55-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30957, current rewards: -1937.57904, mean: -1.42469
[32m[0907 06-56-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31369, current rewards: -2017.43982, mean: -1.43081
[32m[0907 06-56-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31313, current rewards: -2108.87067, mean: -1.44443
[32m[0907 06-56-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31246, current rewards: -2096.74641, mean: -1.38857
[32m[0907 06-57-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31185, current rewards: -2154.05976, mean: -1.38081
[32m[0907 06-57-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31141, current rewards: -2248.90341, mean: -1.39683
[32m[0907 06-57-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31087, current rewards: -2288.77133, mean: -1.37878
[32m[0907 06-57-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31038, current rewards: -2285.16617, mean: -1.33635
[32m[0907 06-58-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30991, current rewards: -2304.34924, mean: -1.30929
[32m[0907 06-58-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30946, current rewards: -2369.90086, mean: -1.30934
[32m[0907 06-58-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30904, current rewards: -2406.73599, mean: -1.29394
[32m[0907 06-58-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30864, current rewards: -2495.27335, mean: -1.30643
[32m[0907 06-59-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31201, current rewards: -2535.51405, mean: -1.29363
[32m[0907 06-59-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31280, current rewards: -2592.44220, mean: -1.28977
[32m[0907 06-59-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31231, current rewards: -2642.44220, mean: -1.28274
[32m[0907 06-59-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31184, current rewards: -2727.31559, mean: -1.29257
[32m[0907 07-00-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31141, current rewards: -2827.31559, mean: -1.30894
[32m[0907 07-00-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31100, current rewards: -2895.06895, mean: -1.30999
[32m[0907 07-00-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31061, current rewards: -2945.06895, mean: -1.30313
[32m[0907 07-00-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31025, current rewards: -3011.06895, mean: -1.30349
[32m[0907 07-01-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31019, current rewards: -3111.06895, mean: -1.31825
[32m[0907 07-01-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30984, current rewards: -3201.95484, mean: -1.32861
[32m[0907 07-01-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30955, current rewards: -3244.31651, mean: -1.31883
[32m[0907 07-01-51 @Agent.py:117][0m Average action selection time: 0.3093
[32m[0907 07-01-51 @Agent.py:118][0m Rollout length: 2600
[32m[0907 07-01-51 @MBExp.py:227][0m Rewards obtained: [-3284.3165148450494], Lows: [1304], Highs: [761], Total time: 50449.38209800001
[32m[0907 07-02-42 @MBExp.py:144][0m ####################################################################
[32m[0907 07-02-42 @MBExp.py:145][0m Starting training iteration 68.
[32m[0907 07-02-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31165, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-03-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29497, current rewards: -60.00000, mean: -1.00000
[32m[0907 07-03-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29363, current rewards: -117.92325, mean: -1.07203
[32m[0907 07-03-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29328, current rewards: -217.92325, mean: -1.36202
[32m[0907 07-03-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29308, current rewards: -313.21444, mean: -1.49150
[32m[0907 07-03-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29297, current rewards: -352.32054, mean: -1.35508
[32m[0907 07-04-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29292, current rewards: -419.10572, mean: -1.35195
[32m[0907 07-04-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29295, current rewards: -519.10572, mean: -1.44196
[32m[0907 07-04-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29303, current rewards: -619.10572, mean: -1.51001
[32m[0907 07-04-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29309, current rewards: -659.64070, mean: -1.43400
[32m[0907 07-05-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29311, current rewards: -713.59308, mean: -1.39920
[32m[0907 07-05-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29312, current rewards: -813.59308, mean: -1.45284
[32m[0907 07-05-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29312, current rewards: -913.59308, mean: -1.49769
[32m[0907 07-05-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29312, current rewards: -956.47093, mean: -1.44920
[32m[0907 07-06-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29311, current rewards: -1031.56745, mean: -1.45291
[32m[0907 07-06-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29318, current rewards: -1131.56745, mean: -1.48890
[32m[0907 07-06-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29830, current rewards: -1231.56745, mean: -1.52045
[32m[0907 07-06-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29826, current rewards: -1331.56745, mean: -1.54833
[32m[0907 07-07-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29801, current rewards: -1400.94562, mean: -1.53950
[32m[0907 07-07-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29775, current rewards: -1440.58250, mean: -1.50061
[32m[0907 07-07-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29750, current rewards: -1490.53425, mean: -1.47578
[32m[0907 07-07-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29727, current rewards: -1488.67525, mean: -1.40441
[32m[0907 07-08-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29708, current rewards: -1487.66393, mean: -1.34024
[32m[0907 07-08-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29689, current rewards: -1484.70328, mean: -1.27992
[32m[0907 07-08-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29672, current rewards: -1481.74264, mean: -1.22458
[32m[0907 07-08-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29657, current rewards: -1478.78183, mean: -1.17364
[32m[0907 07-09-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29643, current rewards: -1475.82134, mean: -1.12658
[32m[0907 07-09-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29630, current rewards: -1472.86101, mean: -1.08299
[32m[0907 07-09-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29619, current rewards: -1510.15052, mean: -1.07103
[32m[0907 07-09-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29609, current rewards: -1560.15052, mean: -1.06860
[32m[0907 07-10-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29602, current rewards: -1610.15052, mean: -1.06632
[32m[0907 07-10-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29595, current rewards: -1660.15052, mean: -1.06420
[32m[0907 07-10-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29588, current rewards: -1710.15052, mean: -1.06221
[32m[0907 07-10-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29582, current rewards: -1760.15052, mean: -1.06033
[32m[0907 07-11-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29576, current rewards: -1810.15052, mean: -1.05857
[32m[0907 07-11-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29570, current rewards: -1860.15052, mean: -1.05690
[32m[0907 07-11-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29563, current rewards: -1910.15052, mean: -1.05533
[32m[0907 07-11-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29557, current rewards: -1960.15052, mean: -1.05384
[32m[0907 07-12-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29549, current rewards: -2010.15052, mean: -1.05243
[32m[0907 07-12-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29541, current rewards: -2060.15052, mean: -1.05110
[32m[0907 07-12-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29535, current rewards: -2110.15052, mean: -1.04983
[32m[0907 07-12-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29529, current rewards: -2160.15052, mean: -1.04862
[32m[0907 07-13-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29524, current rewards: -2210.15052, mean: -1.04746
[32m[0907 07-13-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29518, current rewards: -2260.15052, mean: -1.04637
[32m[0907 07-13-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29513, current rewards: -2310.15052, mean: -1.04532
[32m[0907 07-13-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29510, current rewards: -2360.15052, mean: -1.04431
[32m[0907 07-14-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29506, current rewards: -2410.15052, mean: -1.04336
[32m[0907 07-14-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29503, current rewards: -2460.15052, mean: -1.04244
[32m[0907 07-14-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29501, current rewards: -2510.15052, mean: -1.04156
[32m[0907 07-14-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29498, current rewards: -2560.15052, mean: -1.04071
[32m[0907 07-15-00 @Agent.py:117][0m Average action selection time: 0.2950
[32m[0907 07-15-00 @Agent.py:118][0m Rollout length: 2600
[32m[0907 07-15-00 @MBExp.py:227][0m Rewards obtained: [-2600.15052357085], Lows: [583], Highs: [1469], Total time: 51187.10173100001
[32m[0907 07-15-49 @MBExp.py:144][0m ####################################################################
[32m[0907 07-15-49 @MBExp.py:145][0m Starting training iteration 69.
[32m[0907 07-15-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29224, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-16-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29575, current rewards: -60.00000, mean: -1.00000
[32m[0907 07-16-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29771, current rewards: -116.63389, mean: -1.06031
[32m[0907 07-16-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29614, current rewards: -141.41560, mean: -0.88385
[32m[0907 07-16-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29532, current rewards: -185.37603, mean: -0.88274
[32m[0907 07-17-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29477, current rewards: -235.37603, mean: -0.90529
[32m[0907 07-17-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29448, current rewards: -285.37603, mean: -0.92057
[32m[0907 07-17-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29428, current rewards: -335.37603, mean: -0.93160
[32m[0907 07-17-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29415, current rewards: -385.37603, mean: -0.93994
[32m[0907 07-18-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29408, current rewards: -435.37603, mean: -0.94647
[32m[0907 07-18-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29824, current rewards: -485.37603, mean: -0.95172
[32m[0907 07-18-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29885, current rewards: -534.32300, mean: -0.95415
[32m[0907 07-18-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29874, current rewards: -623.60426, mean: -1.02230
[32m[0907 07-19-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29834, current rewards: -723.60426, mean: -1.09637
[32m[0907 07-19-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29893, current rewards: -771.06538, mean: -1.08601
[32m[0907 07-19-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29852, current rewards: -825.99191, mean: -1.08683
[32m[0907 07-19-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29829, current rewards: -914.99191, mean: -1.12962
[32m[0907 07-20-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29797, current rewards: -1014.99191, mean: -1.18022
[32m[0907 07-20-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29786, current rewards: -1013.59411, mean: -1.11384
[32m[0907 07-20-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29765, current rewards: -1021.09938, mean: -1.06365
[32m[0907 07-20-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29756, current rewards: -1017.59435, mean: -1.00752
[32m[0907 07-21-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29740, current rewards: -1109.31987, mean: -1.04653
[32m[0907 07-21-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29725, current rewards: -1209.31987, mean: -1.08948
[32m[0907 07-21-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29736, current rewards: -1307.05677, mean: -1.12677
[32m[0907 07-21-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29770, current rewards: -1352.93685, mean: -1.11813
[32m[0907 07-22-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29787, current rewards: -1380.11622, mean: -1.09533
[32m[0907 07-22-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29770, current rewards: -1480.11622, mean: -1.12986
[32m[0907 07-22-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29752, current rewards: -1556.83510, mean: -1.14473
[32m[0907 07-22-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29736, current rewards: -1551.27192, mean: -1.10019
[32m[0907 07-23-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29721, current rewards: -1547.39506, mean: -1.05986
[32m[0907 07-23-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29708, current rewards: -1544.27699, mean: -1.02270
[32m[0907 07-23-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29699, current rewards: -1541.15891, mean: -0.98792
[32m[0907 07-23-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29689, current rewards: -1538.04084, mean: -0.95530
[32m[0907 07-24-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29680, current rewards: -1534.92277, mean: -0.92465
[32m[0907 07-24-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29671, current rewards: -1531.80469, mean: -0.89579
[32m[0907 07-24-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29662, current rewards: -1528.68662, mean: -0.86857
[32m[0907 07-24-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29654, current rewards: -1525.56855, mean: -0.84286
[32m[0907 07-25-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29646, current rewards: -1555.38368, mean: -0.83623
[32m[0907 07-25-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29639, current rewards: -1605.38368, mean: -0.84052
[32m[0907 07-25-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29631, current rewards: -1655.38368, mean: -0.84458
[32m[0907 07-25-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29624, current rewards: -1705.38368, mean: -0.84845
[32m[0907 07-26-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29616, current rewards: -1755.38368, mean: -0.85213
[32m[0907 07-26-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29608, current rewards: -1805.38368, mean: -0.85563
[32m[0907 07-26-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29601, current rewards: -1855.38368, mean: -0.85897
[32m[0907 07-26-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29595, current rewards: -1905.38368, mean: -0.86216
[32m[0907 07-26-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29590, current rewards: -1955.38368, mean: -0.86521
[32m[0907 07-27-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29585, current rewards: -2005.38368, mean: -0.86813
[32m[0907 07-27-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29581, current rewards: -2055.38368, mean: -0.87093
[32m[0907 07-27-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29576, current rewards: -2105.38368, mean: -0.87360
[32m[0907 07-27-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29572, current rewards: -2155.38368, mean: -0.87617
[32m[0907 07-28-09 @Agent.py:117][0m Average action selection time: 0.2957
[32m[0907 07-28-09 @Agent.py:118][0m Rollout length: 2600
[32m[0907 07-28-09 @MBExp.py:227][0m Rewards obtained: [-2195.3836782614194], Lows: [488], Highs: [1290], Total time: 51926.64364800001
[32m[0907 07-29-00 @MBExp.py:144][0m ####################################################################
[32m[0907 07-29-00 @MBExp.py:145][0m Starting training iteration 70.
[32m[0907 07-29-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29223, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-29-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29222, current rewards: -60.00000, mean: -1.00000
[32m[0907 07-29-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.29226, current rewards: -101.56941, mean: -0.92336
[32m[0907 07-29-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29231, current rewards: -98.19601, mean: -0.61373
[32m[0907 07-30-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.29238, current rewards: -142.94258, mean: -0.68068
[32m[0907 07-30-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.29761, current rewards: -166.61373, mean: -0.64082
[32m[0907 07-30-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.29870, current rewards: -228.77078, mean: -0.73797
[32m[0907 07-30-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.29793, current rewards: -287.49052, mean: -0.79858
[32m[0907 07-31-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.29739, current rewards: -339.74960, mean: -0.82866
[32m[0907 07-31-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.29697, current rewards: -407.82454, mean: -0.88658
[32m[0907 07-31-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.29667, current rewards: -502.63541, mean: -0.98556
[32m[0907 07-31-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.29636, current rewards: -602.63541, mean: -1.07613
[32m[0907 07-32-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.29612, current rewards: -702.63541, mean: -1.15186
[32m[0907 07-32-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.29588, current rewards: -802.63541, mean: -1.21611
[32m[0907 07-32-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.29572, current rewards: -902.63541, mean: -1.27132
[32m[0907 07-32-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.29556, current rewards: -1002.63541, mean: -1.31926
[32m[0907 07-33-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.29542, current rewards: -1102.63541, mean: -1.36128
[32m[0907 07-33-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.29536, current rewards: -1202.63541, mean: -1.39841
[32m[0907 07-33-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.29527, current rewards: -1302.63541, mean: -1.43147
[32m[0907 07-33-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.29518, current rewards: -1402.63541, mean: -1.46108
[32m[0907 07-33-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.29511, current rewards: -1502.63541, mean: -1.48776
[32m[0907 07-34-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.29503, current rewards: -1602.63541, mean: -1.51192
[32m[0907 07-34-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.29496, current rewards: -1702.63541, mean: -1.53391
[32m[0907 07-34-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.29490, current rewards: -1802.63541, mean: -1.55400
[32m[0907 07-34-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.29483, current rewards: -1902.63541, mean: -1.57243
[32m[0907 07-35-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.29475, current rewards: -2002.63541, mean: -1.58939
[32m[0907 07-35-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.29469, current rewards: -2102.63541, mean: -1.60507
[32m[0907 07-35-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.29462, current rewards: -2202.63541, mean: -1.61958
[32m[0907 07-35-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.29454, current rewards: -2302.63541, mean: -1.63307
[32m[0907 07-36-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.29451, current rewards: -2402.63541, mean: -1.64564
[32m[0907 07-36-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.29449, current rewards: -2502.63541, mean: -1.65737
[32m[0907 07-36-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.29446, current rewards: -2602.63541, mean: -1.66836
[32m[0907 07-36-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.29443, current rewards: -2702.63541, mean: -1.67866
[32m[0907 07-37-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.29440, current rewards: -2802.63541, mean: -1.68833
[32m[0907 07-37-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.29437, current rewards: -2902.63541, mean: -1.69745
[32m[0907 07-37-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.29435, current rewards: -3002.63541, mean: -1.70604
[32m[0907 07-37-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.29435, current rewards: -3102.63541, mean: -1.71416
[32m[0907 07-38-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.29450, current rewards: -3202.63541, mean: -1.72185
[32m[0907 07-38-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.29466, current rewards: -3302.63541, mean: -1.72913
[32m[0907 07-38-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.29463, current rewards: -3402.63541, mean: -1.73604
[32m[0907 07-38-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.29461, current rewards: -3502.63541, mean: -1.74260
[32m[0907 07-39-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.29461, current rewards: -3602.63541, mean: -1.74885
[32m[0907 07-39-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.29458, current rewards: -3702.63541, mean: -1.75480
[32m[0907 07-39-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.29455, current rewards: -3802.63541, mean: -1.76048
[32m[0907 07-39-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.29453, current rewards: -3902.63541, mean: -1.76590
[32m[0907 07-40-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.29450, current rewards: -4002.63541, mean: -1.77108
[32m[0907 07-40-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.29449, current rewards: -4102.63541, mean: -1.77603
[32m[0907 07-40-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.29450, current rewards: -4202.63541, mean: -1.78078
[32m[0907 07-40-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.29463, current rewards: -4302.63541, mean: -1.78533
[32m[0907 07-41-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.29479, current rewards: -4402.63541, mean: -1.78969
[32m[0907 07-41-18 @Agent.py:117][0m Average action selection time: 0.2950
[32m[0907 07-41-18 @Agent.py:118][0m Rollout length: 2600
[32m[0907 07-41-18 @MBExp.py:227][0m Rewards obtained: [-4482.635407098908], Lows: [2118], Highs: [256], Total time: 52664.36260600001
[32m[0907 07-42-07 @MBExp.py:144][0m ####################################################################
[32m[0907 07-42-07 @MBExp.py:145][0m Starting training iteration 71.
[32m[0907 07-42-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.44057, current rewards: 0.81165, mean: 0.08117
[32m[0907 07-42-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33839, current rewards: 4.66910, mean: 0.07782
[32m[0907 07-42-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32169, current rewards: -12.24494, mean: -0.11132
[32m[0907 07-42-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31247, current rewards: -112.24494, mean: -0.70153
[32m[0907 07-43-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30762, current rewards: -212.24494, mean: -1.01069
[32m[0907 07-43-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30762, current rewards: -296.86916, mean: -1.14180
[32m[0907 07-43-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30519, current rewards: -347.25901, mean: -1.12019
[32m[0907 07-43-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30398, current rewards: -447.25901, mean: -1.24239
[32m[0907 07-44-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30261, current rewards: -547.25901, mean: -1.33478
[32m[0907 07-44-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30231, current rewards: -647.25901, mean: -1.40708
[32m[0907 07-44-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30376, current rewards: -726.36303, mean: -1.42424
[32m[0907 07-44-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30418, current rewards: -775.28310, mean: -1.38443
[32m[0907 07-45-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30438, current rewards: -821.67201, mean: -1.34700
[32m[0907 07-45-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30470, current rewards: -921.67201, mean: -1.39647
[32m[0907 07-45-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30478, current rewards: -1021.67201, mean: -1.43897
[32m[0907 07-45-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30470, current rewards: -1121.67201, mean: -1.47588
[32m[0907 07-46-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30498, current rewards: -1221.67201, mean: -1.50824
[32m[0907 07-46-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30514, current rewards: -1321.67201, mean: -1.53683
[32m[0907 07-46-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30536, current rewards: -1421.67201, mean: -1.56228
[32m[0907 07-47-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30550, current rewards: -1521.67201, mean: -1.58508
[32m[0907 07-47-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30601, current rewards: -1621.67201, mean: -1.60562
[32m[0907 07-47-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30651, current rewards: -1684.30326, mean: -1.58897
[32m[0907 07-47-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30699, current rewards: -1784.30326, mean: -1.60748
[32m[0907 07-48-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30729, current rewards: -1884.30326, mean: -1.62440
[32m[0907 07-48-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30818, current rewards: -1959.66045, mean: -1.61955
[32m[0907 07-48-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30855, current rewards: -2009.66045, mean: -1.59497
[32m[0907 07-48-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30889, current rewards: -2056.87775, mean: -1.57014
[32m[0907 07-49-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30918, current rewards: -2156.87775, mean: -1.58594
[32m[0907 07-49-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30943, current rewards: -2256.87775, mean: -1.60062
[32m[0907 07-49-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30954, current rewards: -2356.87775, mean: -1.61430
[32m[0907 07-49-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30913, current rewards: -2456.87775, mean: -1.62707
[32m[0907 07-50-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30865, current rewards: -2556.87775, mean: -1.63902
[32m[0907 07-50-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30828, current rewards: -2656.87775, mean: -1.65023
[32m[0907 07-50-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30795, current rewards: -2756.87775, mean: -1.66077
[32m[0907 07-50-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30826, current rewards: -2856.87775, mean: -1.67069
[32m[0907 07-51-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30847, current rewards: -2956.87775, mean: -1.68004
[32m[0907 07-51-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30867, current rewards: -3056.87775, mean: -1.68888
[32m[0907 07-51-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30908, current rewards: -3156.87775, mean: -1.69725
[32m[0907 07-51-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30933, current rewards: -3256.87775, mean: -1.70517
[32m[0907 07-52-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30952, current rewards: -3356.87775, mean: -1.71269
[32m[0907 07-52-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30998, current rewards: -3456.87775, mean: -1.71984
[32m[0907 07-52-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31058, current rewards: -3556.87775, mean: -1.72664
[32m[0907 07-53-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31117, current rewards: -3656.87775, mean: -1.73312
[32m[0907 07-53-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31119, current rewards: -3756.87775, mean: -1.73930
[32m[0907 07-53-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31106, current rewards: -3856.87775, mean: -1.74519
[32m[0907 07-53-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31145, current rewards: -3956.87775, mean: -1.75083
[32m[0907 07-54-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31193, current rewards: -4056.87775, mean: -1.75622
[32m[0907 07-54-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31236, current rewards: -4156.87775, mean: -1.76139
[32m[0907 07-54-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31222, current rewards: -4256.87775, mean: -1.76634
[32m[0907 07-54-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31242, current rewards: -4356.87775, mean: -1.77109
[32m[0907 07-55-09 @Agent.py:117][0m Average action selection time: 0.3128
[32m[0907 07-55-09 @Agent.py:118][0m Rollout length: 2600
[32m[0907 07-55-09 @MBExp.py:227][0m Rewards obtained: [-4436.877747407445], Lows: [2130], Highs: [197], Total time: 53446.74353400001
[32m[0907 07-55-58 @MBExp.py:144][0m ####################################################################
[32m[0907 07-55-58 @MBExp.py:145][0m Starting training iteration 72.
[32m[0907 07-56-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33721, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-56-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37335, current rewards: -9.69535, mean: -0.16159
[32m[0907 07-56-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.40957, current rewards: -23.37540, mean: -0.21250
[32m[0907 07-57-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.38575, current rewards: -123.37540, mean: -0.77110
[32m[0907 07-57-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37357, current rewards: -206.03884, mean: -0.98114
[32m[0907 07-57-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36624, current rewards: -202.10077, mean: -0.77731
[32m[0907 07-57-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36117, current rewards: -199.67710, mean: -0.64412
[32m[0907 07-58-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35760, current rewards: -219.78196, mean: -0.61051
[32m[0907 07-58-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35227, current rewards: -263.55232, mean: -0.64281
[32m[0907 07-58-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34784, current rewards: -284.39009, mean: -0.61824
[32m[0907 07-58-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34420, current rewards: -322.42439, mean: -0.63220
[32m[0907 07-59-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34103, current rewards: -372.42439, mean: -0.66504
[32m[0907 07-59-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33855, current rewards: -445.17814, mean: -0.72980
[32m[0907 07-59-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33651, current rewards: -545.17814, mean: -0.82603
[32m[0907 07-59-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33494, current rewards: -645.17814, mean: -0.90870
[32m[0907 08-00-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33345, current rewards: -745.17814, mean: -0.98050
[32m[0907 08-00-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33204, current rewards: -845.17814, mean: -1.04343
[32m[0907 08-00-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33119, current rewards: -945.17814, mean: -1.09904
[32m[0907 08-00-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33088, current rewards: -1045.17814, mean: -1.14855
[32m[0907 08-01-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33007, current rewards: -1145.17814, mean: -1.19289
[32m[0907 08-01-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33027, current rewards: -1245.17814, mean: -1.23285
[32m[0907 08-01-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33044, current rewards: -1345.17814, mean: -1.26904
[32m[0907 08-02-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33016, current rewards: -1445.17814, mean: -1.30196
[32m[0907 08-02-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32952, current rewards: -1545.17814, mean: -1.33205
[32m[0907 08-02-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32874, current rewards: -1645.17814, mean: -1.35965
[32m[0907 08-02-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32786, current rewards: -1745.17814, mean: -1.38506
[32m[0907 08-03-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32712, current rewards: -1845.17814, mean: -1.40853
[32m[0907 08-03-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32642, current rewards: -1945.17814, mean: -1.43028
[32m[0907 08-03-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32604, current rewards: -2045.17814, mean: -1.45048
[32m[0907 08-03-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32549, current rewards: -2145.17814, mean: -1.46930
[32m[0907 08-04-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32491, current rewards: -2245.17814, mean: -1.48687
[32m[0907 08-04-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32445, current rewards: -2345.17814, mean: -1.50332
[32m[0907 08-04-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32401, current rewards: -2445.17814, mean: -1.51874
[32m[0907 08-04-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32362, current rewards: -2545.17814, mean: -1.53324
[32m[0907 08-05-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32330, current rewards: -2645.17814, mean: -1.54689
[32m[0907 08-05-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32291, current rewards: -2745.17814, mean: -1.55976
[32m[0907 08-05-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32245, current rewards: -2845.17814, mean: -1.57192
[32m[0907 08-05-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32216, current rewards: -2945.17814, mean: -1.58343
[32m[0907 08-06-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32187, current rewards: -3045.17814, mean: -1.59433
[32m[0907 08-06-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32149, current rewards: -3145.17814, mean: -1.60468
[32m[0907 08-06-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32114, current rewards: -3245.17814, mean: -1.61452
[32m[0907 08-06-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32085, current rewards: -3345.17814, mean: -1.62387
[32m[0907 08-07-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32056, current rewards: -3445.17814, mean: -1.63279
[32m[0907 08-07-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32026, current rewards: -3545.17814, mean: -1.64129
[32m[0907 08-07-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31998, current rewards: -3645.17814, mean: -1.64940
[32m[0907 08-08-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31992, current rewards: -3745.17814, mean: -1.65716
[32m[0907 08-08-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31985, current rewards: -3845.17814, mean: -1.66458
[32m[0907 08-08-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31980, current rewards: -3945.17814, mean: -1.67169
[32m[0907 08-08-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31974, current rewards: -4045.17814, mean: -1.67850
[32m[0907 08-09-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31970, current rewards: -4145.17814, mean: -1.68503
[32m[0907 08-09-17 @Agent.py:117][0m Average action selection time: 0.3196
[32m[0907 08-09-17 @Agent.py:118][0m Rollout length: 2600
[32m[0907 08-09-18 @MBExp.py:227][0m Rewards obtained: [-4225.178135772387], Lows: [2068], Highs: [115], Total time: 54246.30242600001
[32m[0907 08-10-07 @MBExp.py:144][0m ####################################################################
[32m[0907 08-10-07 @MBExp.py:145][0m Starting training iteration 73.
[32m[0907 08-10-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49271, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-10-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.50365, current rewards: -60.00000, mean: -1.00000
[32m[0907 08-11-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.48967, current rewards: -111.33384, mean: -1.01213
[32m[0907 08-11-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.43268, current rewards: -211.33384, mean: -1.32084
[32m[0907 08-11-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.40359, current rewards: -307.33384, mean: -1.46349
[32m[0907 08-11-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.38822, current rewards: -357.33384, mean: -1.37436
[32m[0907 08-12-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37450, current rewards: -407.33384, mean: -1.31398
[32m[0907 08-12-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36521, current rewards: -479.25864, mean: -1.33127
[32m[0907 08-12-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35778, current rewards: -529.25864, mean: -1.29087
[32m[0907 08-12-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35174, current rewards: -577.13449, mean: -1.25464
[32m[0907 08-13-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34747, current rewards: -677.13449, mean: -1.32771
[32m[0907 08-13-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34431, current rewards: -777.13449, mean: -1.38774
[32m[0907 08-13-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34169, current rewards: -877.13449, mean: -1.43793
[32m[0907 08-13-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33930, current rewards: -957.54995, mean: -1.45083
[32m[0907 08-14-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33739, current rewards: -1000.36986, mean: -1.40897
[32m[0907 08-14-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33546, current rewards: -994.57464, mean: -1.30865
[32m[0907 08-14-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33361, current rewards: -988.77941, mean: -1.22072
[32m[0907 08-14-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33227, current rewards: -982.98418, mean: -1.14300
[32m[0907 08-15-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33115, current rewards: -977.18895, mean: -1.07383
[32m[0907 08-15-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33086, current rewards: -971.02657, mean: -1.01149
[32m[0907 08-15-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33055, current rewards: -964.84888, mean: -0.95530
[32m[0907 08-15-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33021, current rewards: -958.67120, mean: -0.90441
[32m[0907 08-16-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32988, current rewards: -952.49352, mean: -0.85810
[32m[0907 08-16-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32954, current rewards: -954.18072, mean: -0.82257
[32m[0907 08-16-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32925, current rewards: -1004.18072, mean: -0.82990
[32m[0907 08-17-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32909, current rewards: -1054.18072, mean: -0.83665
[32m[0907 08-17-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32886, current rewards: -1104.18072, mean: -0.84289
[32m[0907 08-17-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32864, current rewards: -1154.18072, mean: -0.84866
[32m[0907 08-17-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32839, current rewards: -1204.18072, mean: -0.85403
[32m[0907 08-18-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32760, current rewards: -1254.18072, mean: -0.85903
[32m[0907 08-18-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32654, current rewards: -1304.18072, mean: -0.86370
[32m[0907 08-18-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32554, current rewards: -1354.18072, mean: -0.86806
[32m[0907 08-18-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32521, current rewards: -1409.18072, mean: -0.87527
[32m[0907 08-19-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32520, current rewards: -1509.18072, mean: -0.90915
[32m[0907 08-19-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32534, current rewards: -1609.18072, mean: -0.94104
[32m[0907 08-19-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32546, current rewards: -1703.19140, mean: -0.96772
[32m[0907 08-19-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32560, current rewards: -1803.19140, mean: -0.99624
[32m[0907 08-20-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32596, current rewards: -1893.70980, mean: -1.01812
[32m[0907 08-20-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32606, current rewards: -1900.73329, mean: -0.99515
[32m[0907 08-20-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32618, current rewards: -1948.74157, mean: -0.99426
[32m[0907 08-21-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32631, current rewards: -1998.74157, mean: -0.99440
[32m[0907 08-21-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32646, current rewards: -2048.74157, mean: -0.99453
[32m[0907 08-21-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32660, current rewards: -2098.74157, mean: -0.99466
[32m[0907 08-21-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32667, current rewards: -2148.74157, mean: -0.99479
[32m[0907 08-22-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32676, current rewards: -2198.74157, mean: -0.99491
[32m[0907 08-22-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32685, current rewards: -2248.74157, mean: -0.99502
[32m[0907 08-22-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32696, current rewards: -2298.74157, mean: -0.99513
[32m[0907 08-22-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32703, current rewards: -2348.74157, mean: -0.99523
[32m[0907 08-23-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32716, current rewards: -2398.74157, mean: -0.99533
[32m[0907 08-23-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32753, current rewards: -2448.74157, mean: -0.99542
[32m[0907 08-23-47 @Agent.py:117][0m Average action selection time: 0.3276
[32m[0907 08-23-47 @Agent.py:118][0m Rollout length: 2600
[32m[0907 08-23-47 @MBExp.py:227][0m Rewards obtained: [-2516.689434025909], Lows: [626], Highs: [1335], Total time: 55065.80575100001
[32m[0907 08-24-40 @MBExp.py:144][0m ####################################################################
[32m[0907 08-24-40 @MBExp.py:145][0m Starting training iteration 74.
[32m[0907 08-24-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33247, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-25-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.33146, current rewards: -60.00000, mean: -1.00000
[32m[0907 08-25-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33159, current rewards: -119.00000, mean: -1.08182
[32m[0907 08-25-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.33017, current rewards: -219.00000, mean: -1.36875
[32m[0907 08-25-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.32907, current rewards: -319.00000, mean: -1.51905
[32m[0907 08-26-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32601, current rewards: -419.00000, mean: -1.61154
[32m[0907 08-26-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32528, current rewards: -519.00000, mean: -1.67419
[32m[0907 08-26-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32511, current rewards: -619.00000, mean: -1.71944
[32m[0907 08-26-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32495, current rewards: -719.00000, mean: -1.75366
[32m[0907 08-27-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32482, current rewards: -819.00000, mean: -1.78043
[32m[0907 08-27-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32474, current rewards: -919.00000, mean: -1.80196
[32m[0907 08-27-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32486, current rewards: -1019.00000, mean: -1.81964
[32m[0907 08-27-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32474, current rewards: -1119.00000, mean: -1.83443
[32m[0907 08-28-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32491, current rewards: -1219.00000, mean: -1.84697
[32m[0907 08-28-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32497, current rewards: -1319.00000, mean: -1.85775
[32m[0907 08-28-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32487, current rewards: -1419.00000, mean: -1.86711
[32m[0907 08-29-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32475, current rewards: -1519.00000, mean: -1.87531
[32m[0907 08-29-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32485, current rewards: -1619.00000, mean: -1.88256
[32m[0907 08-29-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32489, current rewards: -1719.00000, mean: -1.88901
[32m[0907 08-29-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32491, current rewards: -1819.00000, mean: -1.89479
[32m[0907 08-30-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32509, current rewards: -1919.00000, mean: -1.90000
[32m[0907 08-30-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32526, current rewards: -2019.00000, mean: -1.90472
[32m[0907 08-30-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32541, current rewards: -2119.00000, mean: -1.90901
[32m[0907 08-30-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32555, current rewards: -2219.00000, mean: -1.91293
[32m[0907 08-31-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32570, current rewards: -2319.00000, mean: -1.91653
[32m[0907 08-31-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32581, current rewards: -2419.00000, mean: -1.91984
[32m[0907 08-31-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32592, current rewards: -2519.00000, mean: -1.92290
[32m[0907 08-32-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32592, current rewards: -2619.00000, mean: -1.92574
[32m[0907 08-32-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32590, current rewards: -2719.00000, mean: -1.92837
[32m[0907 08-32-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32585, current rewards: -2819.00000, mean: -1.93082
[32m[0907 08-32-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32583, current rewards: -2919.00000, mean: -1.93311
[32m[0907 08-33-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32579, current rewards: -3019.00000, mean: -1.93526
[32m[0907 08-33-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32571, current rewards: -3119.00000, mean: -1.93727
[32m[0907 08-33-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32562, current rewards: -3219.00000, mean: -1.93916
[32m[0907 08-33-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32553, current rewards: -3319.00000, mean: -1.94094
[32m[0907 08-34-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32545, current rewards: -3419.00000, mean: -1.94261
[32m[0907 08-34-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32542, current rewards: -3519.00000, mean: -1.94420
[32m[0907 08-34-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32539, current rewards: -3619.00000, mean: -1.94570
[32m[0907 08-35-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32537, current rewards: -3719.00000, mean: -1.94712
[32m[0907 08-35-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32532, current rewards: -3819.00000, mean: -1.94847
[32m[0907 08-35-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32530, current rewards: -3919.00000, mean: -1.94975
[32m[0907 08-35-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32527, current rewards: -4019.00000, mean: -1.95097
[32m[0907 08-36-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32522, current rewards: -4119.00000, mean: -1.95213
[32m[0907 08-36-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32520, current rewards: -4219.00000, mean: -1.95324
[32m[0907 08-36-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32516, current rewards: -4319.00000, mean: -1.95430
[32m[0907 08-36-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32489, current rewards: -4419.00000, mean: -1.95531
[32m[0907 08-37-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32477, current rewards: -4519.00000, mean: -1.95628
[32m[0907 08-37-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32462, current rewards: -4619.00000, mean: -1.95720
[32m[0907 08-37-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32420, current rewards: -4719.00000, mean: -1.95809
[32m[0907 08-37-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32387, current rewards: -4819.00000, mean: -1.95894
[32m[0907 08-38-10 @Agent.py:117][0m Average action selection time: 0.3236
[32m[0907 08-38-10 @Agent.py:118][0m Rollout length: 2600
[32m[0907 08-38-10 @MBExp.py:227][0m Rewards obtained: [-4899], Lows: [2399], Highs: [101], Total time: 55875.28497200001
[32m[0907 08-39-00 @MBExp.py:144][0m ####################################################################
[32m[0907 08-39-00 @MBExp.py:145][0m Starting training iteration 75.
[32m[0907 08-39-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.47990, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-39-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.49728, current rewards: -60.00000, mean: -1.00000
[32m[0907 08-39-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.49383, current rewards: -102.59395, mean: -0.93267
[32m[0907 08-40-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.43706, current rewards: -102.45072, mean: -0.64032
[32m[0907 08-40-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.40828, current rewards: -202.45072, mean: -0.96405
[32m[0907 08-40-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.39043, current rewards: -302.45072, mean: -1.16327
[32m[0907 08-40-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37800, current rewards: -346.77334, mean: -1.11862
[32m[0907 08-41-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36978, current rewards: -396.77334, mean: -1.10215
[32m[0907 08-41-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36331, current rewards: -446.77334, mean: -1.08969
[32m[0907 08-41-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35789, current rewards: -496.77334, mean: -1.07994
[32m[0907 08-42-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35359, current rewards: -546.77334, mean: -1.07210
[32m[0907 08-42-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34995, current rewards: -596.77334, mean: -1.06567
[32m[0907 08-42-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34716, current rewards: -646.77334, mean: -1.06028
[32m[0907 08-42-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34542, current rewards: -696.77334, mean: -1.05572
[32m[0907 08-43-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34382, current rewards: -746.77334, mean: -1.05179
[32m[0907 08-43-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34239, current rewards: -796.77334, mean: -1.04839
[32m[0907 08-43-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34112, current rewards: -846.77334, mean: -1.04540
[32m[0907 08-43-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34003, current rewards: -896.77334, mean: -1.04276
[32m[0907 08-44-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33906, current rewards: -946.77334, mean: -1.04041
[32m[0907 08-44-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33819, current rewards: -996.77334, mean: -1.03831
[32m[0907 08-44-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33742, current rewards: -1046.77334, mean: -1.03641
[32m[0907 08-44-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33674, current rewards: -1096.77334, mean: -1.03469
[32m[0907 08-45-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33632, current rewards: -1146.77334, mean: -1.03313
[32m[0907 08-45-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33581, current rewards: -1196.77334, mean: -1.03170
[32m[0907 08-45-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33528, current rewards: -1246.77334, mean: -1.03039
[32m[0907 08-46-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33490, current rewards: -1296.77334, mean: -1.02919
[32m[0907 08-46-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33454, current rewards: -1346.77334, mean: -1.02807
[32m[0907 08-46-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33422, current rewards: -1360.63970, mean: -1.00047
[32m[0907 08-46-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33388, current rewards: -1354.18087, mean: -0.96041
[32m[0907 08-47-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33365, current rewards: -1347.72205, mean: -0.92310
[32m[0907 08-47-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33339, current rewards: -1341.26323, mean: -0.88825
[32m[0907 08-47-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33309, current rewards: -1334.80440, mean: -0.85564
[32m[0907 08-47-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33277, current rewards: -1328.34558, mean: -0.82506
[32m[0907 08-48-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33247, current rewards: -1321.88676, mean: -0.79632
[32m[0907 08-48-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33218, current rewards: -1315.42793, mean: -0.76926
[32m[0907 08-48-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33192, current rewards: -1311.94237, mean: -0.74542
[32m[0907 08-49-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33170, current rewards: -1309.22882, mean: -0.72333
[32m[0907 08-49-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33125, current rewards: -1340.25194, mean: -0.72057
[32m[0907 08-49-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33080, current rewards: -1390.25194, mean: -0.72788
[32m[0907 08-49-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33047, current rewards: -1440.25194, mean: -0.73482
[32m[0907 08-50-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33009, current rewards: -1490.25194, mean: -0.74142
[32m[0907 08-50-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32985, current rewards: -1540.25194, mean: -0.74770
[32m[0907 08-50-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32961, current rewards: -1590.25194, mean: -0.75367
[32m[0907 08-50-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32933, current rewards: -1640.25194, mean: -0.75938
[32m[0907 08-51-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32905, current rewards: -1690.25194, mean: -0.76482
[32m[0907 08-51-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32879, current rewards: -1740.25194, mean: -0.77002
[32m[0907 08-51-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32849, current rewards: -1790.25194, mean: -0.77500
[32m[0907 08-51-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32820, current rewards: -1840.25194, mean: -0.77977
[32m[0907 08-52-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32794, current rewards: -1890.25194, mean: -0.78434
[32m[0907 08-52-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32774, current rewards: -1940.25194, mean: -0.78872
[32m[0907 08-52-39 @Agent.py:117][0m Average action selection time: 0.3275
[32m[0907 08-52-39 @Agent.py:118][0m Rollout length: 2600
[32m[0907 08-52-39 @MBExp.py:227][0m Rewards obtained: [-1980.2519433003752], Lows: [106], Highs: [1832], Total time: 56694.61832700001
[32m[0907 08-53-37 @MBExp.py:144][0m ####################################################################
[32m[0907 08-53-37 @MBExp.py:145][0m Starting training iteration 76.
[32m[0907 08-53-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.41833, current rewards: -2.61847, mean: -0.26185
[32m[0907 08-54-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.49328, current rewards: -31.13836, mean: -0.51897
[32m[0907 08-54-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.45376, current rewards: -38.17533, mean: -0.34705
[32m[0907 08-54-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.46864, current rewards: -116.60264, mean: -0.72877
[32m[0907 08-55-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.43290, current rewards: -122.99287, mean: -0.58568
[32m[0907 08-55-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.41028, current rewards: -207.69344, mean: -0.79882
[32m[0907 08-55-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.39504, current rewards: -199.26072, mean: -0.64278
[32m[0907 08-55-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.38699, current rewards: -191.18640, mean: -0.53107
[32m[0907 08-56-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37867, current rewards: -212.26093, mean: -0.51771
[32m[0907 08-56-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37174, current rewards: -262.26093, mean: -0.57013
[32m[0907 08-56-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.36702, current rewards: -312.26093, mean: -0.61228
[32m[0907 08-57-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36273, current rewards: -362.26093, mean: -0.64689
[32m[0907 08-57-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35905, current rewards: -412.26093, mean: -0.67584
[32m[0907 08-57-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35637, current rewards: -462.26093, mean: -0.70040
[32m[0907 08-57-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35375, current rewards: -512.26093, mean: -0.72149
[32m[0907 08-58-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35123, current rewards: -562.26093, mean: -0.73982
[32m[0907 08-58-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34910, current rewards: -612.26093, mean: -0.75588
[32m[0907 08-58-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34761, current rewards: -662.26093, mean: -0.77007
[32m[0907 08-58-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34606, current rewards: -712.26093, mean: -0.78270
[32m[0907 08-59-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34448, current rewards: -762.26093, mean: -0.79402
[32m[0907 08-59-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34304, current rewards: -812.26093, mean: -0.80422
[32m[0907 08-59-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34184, current rewards: -862.26093, mean: -0.81345
[32m[0907 08-59-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34077, current rewards: -912.26093, mean: -0.82186
[32m[0907 09-00-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33977, current rewards: -962.26093, mean: -0.82954
[32m[0907 09-00-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33885, current rewards: -1012.26093, mean: -0.83658
[32m[0907 09-00-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33799, current rewards: -1062.26093, mean: -0.84306
[32m[0907 09-00-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33712, current rewards: -1112.26093, mean: -0.84905
[32m[0907 09-01-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33634, current rewards: -1162.26093, mean: -0.85460
[32m[0907 09-01-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33554, current rewards: -1212.26093, mean: -0.85976
[32m[0907 09-01-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33487, current rewards: -1262.26093, mean: -0.86456
[32m[0907 09-02-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33425, current rewards: -1312.26093, mean: -0.86905
[32m[0907 09-02-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33388, current rewards: -1362.26093, mean: -0.87324
[32m[0907 09-02-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33354, current rewards: -1412.26093, mean: -0.87718
[32m[0907 09-02-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33310, current rewards: -1462.26093, mean: -0.88088
[32m[0907 09-03-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33265, current rewards: -1512.26093, mean: -0.88436
[32m[0907 09-03-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33216, current rewards: -1562.26093, mean: -0.88765
[32m[0907 09-03-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33172, current rewards: -1612.26093, mean: -0.89075
[32m[0907 09-03-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33140, current rewards: -1662.26093, mean: -0.89369
[32m[0907 09-04-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33096, current rewards: -1712.26093, mean: -0.89647
[32m[0907 09-04-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33061, current rewards: -1762.26093, mean: -0.89911
[32m[0907 09-04-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33032, current rewards: -1812.26093, mean: -0.90162
[32m[0907 09-04-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33003, current rewards: -1862.26093, mean: -0.90401
[32m[0907 09-05-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32964, current rewards: -1912.26093, mean: -0.90628
[32m[0907 09-05-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32937, current rewards: -1962.26093, mean: -0.90845
[32m[0907 09-05-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32915, current rewards: -2012.26093, mean: -0.91053
[32m[0907 09-06-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32882, current rewards: -2062.26093, mean: -0.91250
[32m[0907 09-06-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32873, current rewards: -2112.26093, mean: -0.91440
[32m[0907 09-06-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32857, current rewards: -2162.26093, mean: -0.91621
[32m[0907 09-06-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32848, current rewards: -2212.26093, mean: -0.91795
[32m[0907 09-07-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32841, current rewards: -2262.26093, mean: -0.91962
[32m[0907 09-07-18 @Agent.py:117][0m Average action selection time: 0.3283
[32m[0907 09-07-18 @Agent.py:118][0m Rollout length: 2600
[32m[0907 09-07-18 @MBExp.py:227][0m Rewards obtained: [-2302.260933099021], Lows: [102], Highs: [2148], Total time: 57515.97682600001
[32m[0907 09-08-15 @MBExp.py:144][0m ####################################################################
[32m[0907 09-08-15 @MBExp.py:145][0m Starting training iteration 77.
[32m[0907 09-08-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.38683, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-08-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.47475, current rewards: -60.00000, mean: -1.00000
[32m[0907 09-09-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.41491, current rewards: -116.89557, mean: -1.06269
[32m[0907 09-09-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.38540, current rewards: -216.89557, mean: -1.35560
[32m[0907 09-09-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37025, current rewards: -298.84309, mean: -1.42306
[32m[0907 09-09-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36042, current rewards: -352.24118, mean: -1.35477
[32m[0907 09-10-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35349, current rewards: -447.80053, mean: -1.44452
[32m[0907 09-10-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34815, current rewards: -516.68437, mean: -1.43523
[32m[0907 09-10-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34471, current rewards: -616.68437, mean: -1.50411
[32m[0907 09-10-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34250, current rewards: -716.68437, mean: -1.55801
[32m[0907 09-11-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33996, current rewards: -816.68437, mean: -1.60134
[32m[0907 09-11-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33870, current rewards: -916.68437, mean: -1.63694
[32m[0907 09-11-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33752, current rewards: -1016.68437, mean: -1.66670
[32m[0907 09-11-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33646, current rewards: -1116.68437, mean: -1.69195
[32m[0907 09-12-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33549, current rewards: -1216.68437, mean: -1.71364
[32m[0907 09-12-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33435, current rewards: -1316.68437, mean: -1.73248
[32m[0907 09-12-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33330, current rewards: -1416.68437, mean: -1.74899
[32m[0907 09-13-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33247, current rewards: -1516.68437, mean: -1.76359
[32m[0907 09-13-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33191, current rewards: -1616.68437, mean: -1.77658
[32m[0907 09-13-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33159, current rewards: -1716.68437, mean: -1.78821
[32m[0907 09-13-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33085, current rewards: -1816.68437, mean: -1.79870
[32m[0907 09-14-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33035, current rewards: -1916.68437, mean: -1.80819
[32m[0907 09-14-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33007, current rewards: -2016.68437, mean: -1.81683
[32m[0907 09-14-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32947, current rewards: -2116.68437, mean: -1.82473
[32m[0907 09-14-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32894, current rewards: -2216.68437, mean: -1.83197
[32m[0907 09-15-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32870, current rewards: -2316.68437, mean: -1.83864
[32m[0907 09-15-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32869, current rewards: -2416.68437, mean: -1.84480
[32m[0907 09-15-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32873, current rewards: -2516.68437, mean: -1.85050
[32m[0907 09-15-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32832, current rewards: -2616.68437, mean: -1.85580
[32m[0907 09-16-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32797, current rewards: -2716.68437, mean: -1.86074
[32m[0907 09-16-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32780, current rewards: -2816.68437, mean: -1.86535
[32m[0907 09-16-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32765, current rewards: -2916.68437, mean: -1.86967
[32m[0907 09-17-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32763, current rewards: -3016.68437, mean: -1.87372
[32m[0907 09-17-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32767, current rewards: -3116.68437, mean: -1.87752
[32m[0907 09-17-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32760, current rewards: -3216.68437, mean: -1.88110
[32m[0907 09-17-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32727, current rewards: -3316.68437, mean: -1.88448
[32m[0907 09-18-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32720, current rewards: -3416.68437, mean: -1.88767
[32m[0907 09-18-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32717, current rewards: -3516.68437, mean: -1.89069
[32m[0907 09-18-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32721, current rewards: -3616.68437, mean: -1.89355
[32m[0907 09-18-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32705, current rewards: -3716.68437, mean: -1.89627
[32m[0907 09-19-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32705, current rewards: -3816.68437, mean: -1.89885
[32m[0907 09-19-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32696, current rewards: -3916.68437, mean: -1.90130
[32m[0907 09-19-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32675, current rewards: -4016.68437, mean: -1.90364
[32m[0907 09-20-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32649, current rewards: -4116.68437, mean: -1.90587
[32m[0907 09-20-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32627, current rewards: -4216.68437, mean: -1.90800
[32m[0907 09-20-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32605, current rewards: -4316.68437, mean: -1.91004
[32m[0907 09-20-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32583, current rewards: -4416.68437, mean: -1.91198
[32m[0907 09-21-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32560, current rewards: -4516.68437, mean: -1.91385
[32m[0907 09-21-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32540, current rewards: -4616.68437, mean: -1.91564
[32m[0907 09-21-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32509, current rewards: -4716.68437, mean: -1.91735
[32m[0907 09-21-47 @Agent.py:117][0m Average action selection time: 0.3248
[32m[0907 09-21-47 @Agent.py:118][0m Rollout length: 2600
[32m[0907 09-21-47 @MBExp.py:227][0m Rewards obtained: [-4796.6843667717], Lows: [2347], Highs: [112], Total time: 58328.459767000015
[32m[0907 09-22-41 @MBExp.py:144][0m ####################################################################
[32m[0907 09-22-41 @MBExp.py:145][0m Starting training iteration 78.
[32m[0907 09-22-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.41315, current rewards: -3.67922, mean: -0.36792
[32m[0907 09-23-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32593, current rewards: 0.01903, mean: 0.00032
[32m[0907 09-23-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31849, current rewards: -44.03081, mean: -0.40028
[32m[0907 09-23-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31641, current rewards: -144.03081, mean: -0.90019
[32m[0907 09-23-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31391, current rewards: -244.03081, mean: -1.16205
[32m[0907 09-24-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31848, current rewards: -344.03081, mean: -1.32320
[32m[0907 09-24-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.32071, current rewards: -436.69119, mean: -1.40868
[32m[0907 09-24-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.32703, current rewards: -513.09073, mean: -1.42525
[32m[0907 09-24-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32546, current rewards: -611.03286, mean: -1.49032
[32m[0907 09-25-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32306, current rewards: -662.40749, mean: -1.44002
[32m[0907 09-25-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32120, current rewards: -745.40749, mean: -1.46158
[32m[0907 09-25-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32028, current rewards: -845.40749, mean: -1.50966
[32m[0907 09-25-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31904, current rewards: -936.40766, mean: -1.53509
[32m[0907 09-26-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31819, current rewards: -991.33616, mean: -1.50202
[32m[0907 09-26-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31794, current rewards: -1091.33616, mean: -1.53709
[32m[0907 09-26-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31701, current rewards: -1189.10091, mean: -1.56461
[32m[0907 09-26-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31653, current rewards: -1253.92205, mean: -1.54805
[32m[0907 09-27-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31743, current rewards: -1353.92205, mean: -1.57433
[32m[0907 09-27-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31659, current rewards: -1447.64364, mean: -1.59082
[32m[0907 09-27-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31587, current rewards: -1484.95645, mean: -1.54683
[32m[0907 09-28-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31567, current rewards: -1567.25056, mean: -1.55173
[32m[0907 09-28-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31530, current rewards: -1667.25056, mean: -1.57288
[32m[0907 09-28-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31471, current rewards: -1735.42035, mean: -1.56344
[32m[0907 09-28-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31487, current rewards: -1818.61149, mean: -1.56777
[32m[0907 09-29-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31493, current rewards: -1918.61149, mean: -1.58563
[32m[0907 09-29-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31451, current rewards: -1995.24400, mean: -1.58353
[32m[0907 09-29-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31414, current rewards: -2024.75099, mean: -1.54561
[32m[0907 09-29-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31484, current rewards: -2124.75099, mean: -1.56232
[32m[0907 09-30-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31447, current rewards: -2224.75099, mean: -1.57784
[32m[0907 09-30-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31414, current rewards: -2262.91143, mean: -1.54994
[32m[0907 09-30-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31462, current rewards: -2334.62331, mean: -1.54611
[32m[0907 09-30-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31430, current rewards: -2434.62331, mean: -1.56066
[32m[0907 09-31-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31401, current rewards: -2512.07555, mean: -1.56030
[32m[0907 09-31-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31374, current rewards: -2562.07555, mean: -1.54342
[32m[0907 09-31-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31348, current rewards: -2604.08456, mean: -1.52286
[32m[0907 09-31-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31349, current rewards: -2704.08456, mean: -1.53641
[32m[0907 09-32-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31324, current rewards: -2793.44561, mean: -1.54334
[32m[0907 09-32-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31301, current rewards: -2877.73335, mean: -1.54717
[32m[0907 09-32-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31289, current rewards: -2977.73335, mean: -1.55902
[32m[0907 09-32-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31271, current rewards: -3069.61740, mean: -1.56613
[32m[0907 09-33-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31258, current rewards: -3167.33008, mean: -1.57579
[32m[0907 09-33-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31237, current rewards: -3267.33008, mean: -1.58608
[32m[0907 09-33-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31218, current rewards: -3365.28126, mean: -1.59492
[32m[0907 09-33-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31231, current rewards: -3465.28126, mean: -1.60430
[32m[0907 09-34-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31223, current rewards: -3565.28126, mean: -1.61325
[32m[0907 09-34-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31219, current rewards: -3665.28126, mean: -1.62181
[32m[0907 09-34-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31235, current rewards: -3762.70070, mean: -1.62887
[32m[0907 09-35-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31279, current rewards: -3860.24740, mean: -1.63570
[32m[0907 09-35-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31286, current rewards: -3955.85549, mean: -1.64143
[32m[0907 09-35-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31374, current rewards: -4050.65882, mean: -1.64661
[32m[0907 09-35-46 @Agent.py:117][0m Average action selection time: 0.3138
[32m[0907 09-35-46 @Agent.py:118][0m Rollout length: 2600
[32m[0907 09-35-46 @MBExp.py:227][0m Rewards obtained: [-4127.4435397131865], Lows: [1976], Highs: [222], Total time: 59113.307819000016
[32m[0907 09-36-40 @MBExp.py:144][0m ####################################################################
[32m[0907 09-36-40 @MBExp.py:145][0m Starting training iteration 79.
[32m[0907 09-36-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.52974, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-37-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.42359, current rewards: -60.00000, mean: -1.00000
[32m[0907 09-37-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37394, current rewards: -100.88199, mean: -0.91711
[32m[0907 09-37-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36101, current rewards: -193.79125, mean: -1.21120
[32m[0907 09-37-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34829, current rewards: -293.79125, mean: -1.39901
[32m[0907 09-38-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34022, current rewards: -367.10881, mean: -1.41196
[32m[0907 09-38-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33482, current rewards: -417.10881, mean: -1.34551
[32m[0907 09-38-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33149, current rewards: -467.10881, mean: -1.29752
[32m[0907 09-38-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32884, current rewards: -517.10881, mean: -1.26124
[32m[0907 09-39-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32674, current rewards: -567.10881, mean: -1.23285
[32m[0907 09-39-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32546, current rewards: -617.10881, mean: -1.21002
[32m[0907 09-39-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32465, current rewards: -667.10881, mean: -1.19127
[32m[0907 09-39-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32361, current rewards: -717.10881, mean: -1.17559
[32m[0907 09-40-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32233, current rewards: -767.10881, mean: -1.16229
[32m[0907 09-40-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32127, current rewards: -817.10881, mean: -1.15086
[32m[0907 09-40-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32033, current rewards: -867.10881, mean: -1.14093
[32m[0907 09-40-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31952, current rewards: -917.10881, mean: -1.13223
[32m[0907 09-41-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31882, current rewards: -967.10881, mean: -1.12455
[32m[0907 09-41-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31835, current rewards: -1017.10881, mean: -1.11770
[32m[0907 09-41-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31770, current rewards: -1067.10881, mean: -1.11157
[32m[0907 09-42-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31696, current rewards: -1117.10881, mean: -1.10605
[32m[0907 09-42-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31656, current rewards: -1167.10881, mean: -1.10105
[32m[0907 09-42-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31645, current rewards: -1217.10881, mean: -1.09649
[32m[0907 09-42-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31646, current rewards: -1267.10881, mean: -1.09234
[32m[0907 09-43-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31657, current rewards: -1317.10881, mean: -1.08852
[32m[0907 09-43-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31665, current rewards: -1367.10881, mean: -1.08501
[32m[0907 09-43-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31698, current rewards: -1417.10881, mean: -1.08176
[32m[0907 09-43-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31670, current rewards: -1467.10881, mean: -1.07876
[32m[0907 09-44-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31631, current rewards: -1517.10881, mean: -1.07596
[32m[0907 09-44-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31598, current rewards: -1567.10881, mean: -1.07336
[32m[0907 09-44-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31599, current rewards: -1607.66420, mean: -1.06468
[32m[0907 09-44-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31564, current rewards: -1605.19412, mean: -1.02897
[32m[0907 09-45-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31535, current rewards: -1602.72405, mean: -0.99548
[32m[0907 09-45-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31509, current rewards: -1600.25397, mean: -0.96401
[32m[0907 09-45-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31477, current rewards: -1597.73431, mean: -0.93435
[32m[0907 09-45-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31447, current rewards: -1594.98762, mean: -0.90624
[32m[0907 09-46-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31418, current rewards: -1594.35079, mean: -0.88086
[32m[0907 09-46-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31398, current rewards: -1644.35079, mean: -0.88406
[32m[0907 09-46-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31396, current rewards: -1694.35079, mean: -0.88709
[32m[0907 09-46-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31388, current rewards: -1744.35079, mean: -0.88997
[32m[0907 09-47-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31375, current rewards: -1794.35079, mean: -0.89271
[32m[0907 09-47-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31368, current rewards: -1844.35079, mean: -0.89532
[32m[0907 09-47-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31359, current rewards: -1894.35079, mean: -0.89780
[32m[0907 09-47-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31352, current rewards: -1944.35079, mean: -0.90016
[32m[0907 09-48-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31335, current rewards: -1994.35079, mean: -0.90242
[32m[0907 09-48-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31322, current rewards: -2044.35079, mean: -0.90458
[32m[0907 09-48-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31309, current rewards: -2094.35079, mean: -0.90665
[32m[0907 09-48-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31307, current rewards: -2129.66544, mean: -0.90240
[32m[0907 09-49-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31294, current rewards: -2127.21773, mean: -0.88266
[32m[0907 09-49-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31293, current rewards: -2124.77003, mean: -0.86373
[32m[0907 09-49-43 @Agent.py:117][0m Average action selection time: 0.3130
[32m[0907 09-49-43 @Agent.py:118][0m Rollout length: 2600
[32m[0907 09-49-43 @MBExp.py:227][0m Rewards obtained: [-2122.811869077314], Lows: [127], Highs: [1895], Total time: 59896.184430000016
[32m[0907 09-50-38 @MBExp.py:144][0m ####################################################################
[32m[0907 09-50-38 @MBExp.py:145][0m Starting training iteration 80.
[32m[0907 09-50-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31314, current rewards: -10.00000, mean: -1.00000
[32m[0907 09-51-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.40438, current rewards: -60.00000, mean: -1.00000
[32m[0907 09-51-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.39418, current rewards: -105.26674, mean: -0.95697
[32m[0907 09-51-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.39213, current rewards: -140.34545, mean: -0.87716
[32m[0907 09-52-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.39835, current rewards: -176.54385, mean: -0.84068
[32m[0907 09-52-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.38228, current rewards: -210.20799, mean: -0.80849
[32m[0907 09-52-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.39003, current rewards: -241.24727, mean: -0.77822
[32m[0907 09-53-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.39458, current rewards: -274.60028, mean: -0.76278
[32m[0907 09-53-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.39964, current rewards: -332.44144, mean: -0.81083
[32m[0907 09-53-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.38948, current rewards: -384.44144, mean: -0.83574
[32m[0907 09-53-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.38123, current rewards: -426.55860, mean: -0.83639
[32m[0907 09-54-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37480, current rewards: -475.50962, mean: -0.84912
[32m[0907 09-54-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36922, current rewards: -521.19689, mean: -0.85442
[32m[0907 09-54-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36483, current rewards: -571.19689, mean: -0.86545
[32m[0907 09-54-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36090, current rewards: -621.19689, mean: -0.87493
[32m[0907 09-55-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35805, current rewards: -663.98182, mean: -0.87366
[32m[0907 09-55-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35479, current rewards: -763.98182, mean: -0.94319
[32m[0907 09-55-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35210, current rewards: -793.55324, mean: -0.92274
[32m[0907 09-55-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34979, current rewards: -788.50336, mean: -0.86649
[32m[0907 09-56-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34762, current rewards: -810.97841, mean: -0.84477
[32m[0907 09-56-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34566, current rewards: -860.97841, mean: -0.85245
[32m[0907 09-56-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34404, current rewards: -910.97841, mean: -0.85941
[32m[0907 09-56-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34258, current rewards: -958.85369, mean: -0.86383
[32m[0907 09-57-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34100, current rewards: -1008.85369, mean: -0.86970
[32m[0907 09-57-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33956, current rewards: -1058.85369, mean: -0.87509
[32m[0907 09-57-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33819, current rewards: -1108.85369, mean: -0.88004
[32m[0907 09-57-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33697, current rewards: -1158.85369, mean: -0.88462
[32m[0907 09-58-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33584, current rewards: -1208.85369, mean: -0.88886
[32m[0907 09-58-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33476, current rewards: -1258.85369, mean: -0.89280
[32m[0907 09-58-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33377, current rewards: -1308.85369, mean: -0.89648
[32m[0907 09-59-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33285, current rewards: -1358.85369, mean: -0.89990
[32m[0907 09-59-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33195, current rewards: -1408.85369, mean: -0.90311
[32m[0907 09-59-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33114, current rewards: -1458.85369, mean: -0.90612
[32m[0907 09-59-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33038, current rewards: -1508.85369, mean: -0.90895
[32m[0907 10-00-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32968, current rewards: -1558.85369, mean: -0.91161
[32m[0907 10-00-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32932, current rewards: -1608.85369, mean: -0.91412
[32m[0907 10-00-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32911, current rewards: -1652.48515, mean: -0.91298
[32m[0907 10-00-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32846, current rewards: -1649.28090, mean: -0.88671
[32m[0907 10-01-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32797, current rewards: -1692.49230, mean: -0.88612
[32m[0907 10-01-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32741, current rewards: -1742.49230, mean: -0.88903
[32m[0907 10-01-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33021, current rewards: -1792.49230, mean: -0.89179
[32m[0907 10-02-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33100, current rewards: -1841.42396, mean: -0.89390
[32m[0907 10-02-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33117, current rewards: -1874.03914, mean: -0.88817
[32m[0907 10-02-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33170, current rewards: -1935.03914, mean: -0.89585
[32m[0907 10-02-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33120, current rewards: -1960.75040, mean: -0.88722
[32m[0907 10-03-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33114, current rewards: -2000.13033, mean: -0.88501
[32m[0907 10-03-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33060, current rewards: -2049.08267, mean: -0.88705
[32m[0907 10-03-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33008, current rewards: -2097.30899, mean: -0.88869
[32m[0907 10-03-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32959, current rewards: -2147.30899, mean: -0.89100
[32m[0907 10-04-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32910, current rewards: -2197.30899, mean: -0.89322
[32m[0907 10-04-20 @Agent.py:117][0m Average action selection time: 0.3287
[32m[0907 10-04-20 @Agent.py:118][0m Rollout length: 2600
[32m[0907 10-04-20 @MBExp.py:227][0m Rewards obtained: [-2237.308990958517], Lows: [196], Highs: [1893], Total time: 60718.51930700002
[32m[0907 10-05-17 @MBExp.py:144][0m ####################################################################
[32m[0907 10-05-17 @MBExp.py:145][0m Starting training iteration 81.
[32m[0907 10-05-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30743, current rewards: 0.74527, mean: 0.07453
[32m[0907 10-05-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30920, current rewards: 4.48781, mean: 0.07480
[32m[0907 10-05-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30692, current rewards: 4.08599, mean: 0.03715
[32m[0907 10-06-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30737, current rewards: 7.82860, mean: 0.04893
[32m[0907 10-06-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30691, current rewards: 11.58159, mean: 0.05515
[32m[0907 10-06-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30708, current rewards: -70.34711, mean: -0.27057
[32m[0907 10-06-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30707, current rewards: -170.34711, mean: -0.54951
[32m[0907 10-07-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30749, current rewards: -220.19535, mean: -0.61165
[32m[0907 10-07-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30724, current rewards: -251.02056, mean: -0.61225
[32m[0907 10-07-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30734, current rewards: -301.02056, mean: -0.65439
[32m[0907 10-07-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30737, current rewards: -377.82718, mean: -0.74084
[32m[0907 10-08-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30700, current rewards: -477.82718, mean: -0.85326
[32m[0907 10-08-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30667, current rewards: -577.82718, mean: -0.94726
[32m[0907 10-08-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30636, current rewards: -677.82718, mean: -1.02701
[32m[0907 10-08-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30612, current rewards: -777.82718, mean: -1.09553
[32m[0907 10-09-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30589, current rewards: -877.82718, mean: -1.15504
[32m[0907 10-09-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30585, current rewards: -977.82718, mean: -1.20719
[32m[0907 10-09-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30569, current rewards: -1077.82718, mean: -1.25329
[32m[0907 10-09-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30575, current rewards: -1177.82718, mean: -1.29432
[32m[0907 10-10-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30585, current rewards: -1277.82718, mean: -1.33107
[32m[0907 10-10-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30584, current rewards: -1377.82718, mean: -1.36419
[32m[0907 10-10-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30593, current rewards: -1477.82718, mean: -1.39418
[32m[0907 10-10-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30604, current rewards: -1577.82718, mean: -1.42147
[32m[0907 10-11-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30604, current rewards: -1677.82718, mean: -1.44640
[32m[0907 10-11-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30608, current rewards: -1777.82718, mean: -1.46928
[32m[0907 10-11-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30615, current rewards: -1877.82718, mean: -1.49034
[32m[0907 10-11-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30614, current rewards: -1977.82718, mean: -1.50979
[32m[0907 10-12-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30628, current rewards: -2077.82718, mean: -1.52781
[32m[0907 10-12-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30645, current rewards: -2177.82718, mean: -1.54456
[32m[0907 10-12-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30676, current rewards: -2277.82718, mean: -1.56016
[32m[0907 10-13-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30686, current rewards: -2377.82718, mean: -1.57472
[32m[0907 10-13-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30691, current rewards: -2477.82718, mean: -1.58835
[32m[0907 10-13-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30694, current rewards: -2577.82718, mean: -1.60113
[32m[0907 10-13-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30699, current rewards: -2677.82718, mean: -1.61315
[32m[0907 10-14-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30711, current rewards: -2777.82718, mean: -1.62446
[32m[0907 10-14-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30730, current rewards: -2877.82718, mean: -1.63513
[32m[0907 10-14-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30737, current rewards: -2977.82718, mean: -1.64521
[32m[0907 10-14-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30735, current rewards: -3077.82718, mean: -1.65475
[32m[0907 10-15-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30744, current rewards: -3177.82718, mean: -1.66378
[32m[0907 10-15-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30742, current rewards: -3277.82718, mean: -1.67236
[32m[0907 10-15-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30740, current rewards: -3377.82718, mean: -1.68051
[32m[0907 10-15-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30738, current rewards: -3477.82718, mean: -1.68827
[32m[0907 10-16-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30743, current rewards: -3577.82718, mean: -1.69565
[32m[0907 10-16-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30762, current rewards: -3677.82718, mean: -1.70270
[32m[0907 10-16-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30775, current rewards: -3777.82718, mean: -1.70942
[32m[0907 10-16-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30779, current rewards: -3877.82718, mean: -1.71585
[32m[0907 10-17-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30777, current rewards: -3977.82718, mean: -1.72200
[32m[0907 10-17-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30781, current rewards: -4077.82718, mean: -1.72789
[32m[0907 10-17-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30790, current rewards: -4177.82718, mean: -1.73354
[32m[0907 10-17-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30799, current rewards: -4277.82718, mean: -1.73895
[32m[0907 10-18-07 @Agent.py:117][0m Average action selection time: 0.3081
[32m[0907 10-18-07 @Agent.py:118][0m Rollout length: 2600
[32m[0907 10-18-07 @MBExp.py:227][0m Rewards obtained: [-4357.827181569608], Lows: [2148], Highs: [84], Total time: 61489.235884000016
[32m[0907 10-19-05 @MBExp.py:144][0m ####################################################################
[32m[0907 10-19-05 @MBExp.py:145][0m Starting training iteration 82.
[32m[0907 10-19-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30969, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-19-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30910, current rewards: -60.00000, mean: -1.00000
[32m[0907 10-19-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31140, current rewards: -120.00000, mean: -1.09091
[32m[0907 10-19-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31250, current rewards: -220.00000, mean: -1.37500
[32m[0907 10-20-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31317, current rewards: -320.00000, mean: -1.52381
[32m[0907 10-20-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.32618, current rewards: -393.56092, mean: -1.51370
[32m[0907 10-20-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35670, current rewards: -443.56092, mean: -1.43084
[32m[0907 10-21-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36840, current rewards: -476.00667, mean: -1.32224
[32m[0907 10-21-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36251, current rewards: -468.28549, mean: -1.14216
[32m[0907 10-21-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35879, current rewards: -489.32866, mean: -1.06376
[32m[0907 10-22-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35400, current rewards: -554.57682, mean: -1.08741
[32m[0907 10-22-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34976, current rewards: -601.06184, mean: -1.07332
[32m[0907 10-22-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34623, current rewards: -671.01113, mean: -1.10002
[32m[0907 10-22-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34336, current rewards: -771.01113, mean: -1.16820
[32m[0907 10-23-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34141, current rewards: -871.01113, mean: -1.22678
[32m[0907 10-23-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33937, current rewards: -918.76919, mean: -1.20891
[32m[0907 10-23-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33769, current rewards: -979.78443, mean: -1.20961
[32m[0907 10-23-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33590, current rewards: -1061.09435, mean: -1.23383
[32m[0907 10-24-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33432, current rewards: -1161.09435, mean: -1.27593
[32m[0907 10-24-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33308, current rewards: -1234.81078, mean: -1.28626
[32m[0907 10-24-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33188, current rewards: -1284.81078, mean: -1.27209
[32m[0907 10-24-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33103, current rewards: -1305.39534, mean: -1.23151
[32m[0907 10-25-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32983, current rewards: -1302.86777, mean: -1.17375
[32m[0907 10-25-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32885, current rewards: -1304.54412, mean: -1.12461
[32m[0907 10-25-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32806, current rewards: -1310.43017, mean: -1.08300
[32m[0907 10-25-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32727, current rewards: -1325.61669, mean: -1.05208
[32m[0907 10-26-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32678, current rewards: -1375.61669, mean: -1.05009
[32m[0907 10-26-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32619, current rewards: -1425.61669, mean: -1.04825
[32m[0907 10-26-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32582, current rewards: -1499.71673, mean: -1.06363
[32m[0907 10-27-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32525, current rewards: -1577.90743, mean: -1.08076
[32m[0907 10-27-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32471, current rewards: -1642.64025, mean: -1.08784
[32m[0907 10-27-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32426, current rewards: -1692.64025, mean: -1.08503
[32m[0907 10-27-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32380, current rewards: -1742.64025, mean: -1.08239
[32m[0907 10-28-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32432, current rewards: -1792.64025, mean: -1.07990
[32m[0907 10-28-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32997, current rewards: -1842.64025, mean: -1.07757
[32m[0907 10-28-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33007, current rewards: -1892.64025, mean: -1.07536
[32m[0907 10-29-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33012, current rewards: -1927.08894, mean: -1.06469
[32m[0907 10-29-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32982, current rewards: -1970.54933, mean: -1.05944
[32m[0907 10-29-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32953, current rewards: -2023.31659, mean: -1.05933
[32m[0907 10-29-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32934, current rewards: -2065.79044, mean: -1.05397
[32m[0907 10-30-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32887, current rewards: -2140.15240, mean: -1.06475
[32m[0907 10-30-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32860, current rewards: -2185.73414, mean: -1.06104
[32m[0907 10-30-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32857, current rewards: -2277.60189, mean: -1.07943
[32m[0907 10-30-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32826, current rewards: -2356.62560, mean: -1.09103
[32m[0907 10-31-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32789, current rewards: -2377.93376, mean: -1.07599
[32m[0907 10-31-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32758, current rewards: -2457.35440, mean: -1.08732
[32m[0907 10-31-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32727, current rewards: -2557.35440, mean: -1.10708
[32m[0907 10-31-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32689, current rewards: -2619.19008, mean: -1.10983
[32m[0907 10-32-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32671, current rewards: -2627.79158, mean: -1.09037
[32m[0907 10-32-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32655, current rewards: -2677.79158, mean: -1.08853
[32m[0907 10-32-41 @Agent.py:117][0m Average action selection time: 0.3263
[32m[0907 10-32-41 @Agent.py:118][0m Rollout length: 2600
[32m[0907 10-32-41 @MBExp.py:227][0m Rewards obtained: [-2713.3596717779496], Lows: [894], Highs: [1005], Total time: 62305.341517000015
[32m[0907 10-33-38 @MBExp.py:144][0m ####################################################################
[32m[0907 10-33-38 @MBExp.py:145][0m Starting training iteration 83.
[32m[0907 10-33-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49110, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-34-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.42249, current rewards: -60.00000, mean: -1.00000
[32m[0907 10-34-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.37627, current rewards: -110.00000, mean: -1.00000
[32m[0907 10-34-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.41312, current rewards: -160.00000, mean: -1.00000
[32m[0907 10-35-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.42910, current rewards: -203.48396, mean: -0.96897
[32m[0907 10-35-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.40662, current rewards: -264.03411, mean: -1.01552
[32m[0907 10-35-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.39044, current rewards: -364.03411, mean: -1.17430
[32m[0907 10-35-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37870, current rewards: -417.60634, mean: -1.16002
[32m[0907 10-36-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36986, current rewards: -467.60634, mean: -1.14050
[32m[0907 10-36-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36292, current rewards: -516.53629, mean: -1.12290
[32m[0907 10-36-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35956, current rewards: -611.39948, mean: -1.19882
[32m[0907 10-36-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35476, current rewards: -711.39948, mean: -1.27036
[32m[0907 10-37-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35082, current rewards: -773.34395, mean: -1.26778
[32m[0907 10-37-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34745, current rewards: -823.34395, mean: -1.24749
[32m[0907 10-37-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34457, current rewards: -877.13949, mean: -1.23541
[32m[0907 10-38-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34373, current rewards: -977.13949, mean: -1.28571
[32m[0907 10-38-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34143, current rewards: -1077.13949, mean: -1.32980
[32m[0907 10-38-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33941, current rewards: -1129.03883, mean: -1.31284
[32m[0907 10-38-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33763, current rewards: -1179.03883, mean: -1.29565
[32m[0907 10-39-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33609, current rewards: -1253.03883, mean: -1.30525
[32m[0907 10-39-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33464, current rewards: -1353.03883, mean: -1.33964
[32m[0907 10-39-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33469, current rewards: -1424.65923, mean: -1.34402
[32m[0907 10-39-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33342, current rewards: -1437.16621, mean: -1.29474
[32m[0907 10-40-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33230, current rewards: -1484.29701, mean: -1.27957
[32m[0907 10-40-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33277, current rewards: -1538.36875, mean: -1.27138
[32m[0907 10-40-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33172, current rewards: -1633.26225, mean: -1.29624
[32m[0907 10-40-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33085, current rewards: -1691.66601, mean: -1.29135
[32m[0907 10-41-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32998, current rewards: -1791.66601, mean: -1.31740
[32m[0907 10-41-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32939, current rewards: -1891.66601, mean: -1.34161
[32m[0907 10-41-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32862, current rewards: -1991.66601, mean: -1.36415
[32m[0907 10-41-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32791, current rewards: -2010.60845, mean: -1.33153
[32m[0907 10-42-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32724, current rewards: -2006.72184, mean: -1.28636
[32m[0907 10-42-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32661, current rewards: -1998.64201, mean: -1.24139
[32m[0907 10-42-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32601, current rewards: -1990.34189, mean: -1.19900
[32m[0907 10-42-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32545, current rewards: -2032.17988, mean: -1.18841
[32m[0907 10-43-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32493, current rewards: -2082.17988, mean: -1.18306
[32m[0907 10-43-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32442, current rewards: -2132.17988, mean: -1.17800
[32m[0907 10-43-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32403, current rewards: -2182.17988, mean: -1.17321
[32m[0907 10-43-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32365, current rewards: -2232.17988, mean: -1.16868
[32m[0907 10-44-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32322, current rewards: -2282.17988, mean: -1.16438
[32m[0907 10-44-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32295, current rewards: -2332.17988, mean: -1.16029
[32m[0907 10-44-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32282, current rewards: -2382.17988, mean: -1.15640
[32m[0907 10-45-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32264, current rewards: -2432.17988, mean: -1.15269
[32m[0907 10-45-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32271, current rewards: -2482.17988, mean: -1.14916
[32m[0907 10-45-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32267, current rewards: -2532.17988, mean: -1.14578
[32m[0907 10-45-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32238, current rewards: -2582.17988, mean: -1.14256
[32m[0907 10-46-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32204, current rewards: -2632.17988, mean: -1.13947
[32m[0907 10-46-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32172, current rewards: -2682.17988, mean: -1.13652
[32m[0907 10-46-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32138, current rewards: -2732.17988, mean: -1.13368
[32m[0907 10-46-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32104, current rewards: -2782.17988, mean: -1.13097
[32m[0907 10-47-01 @Agent.py:117][0m Average action selection time: 0.3208
[32m[0907 10-47-01 @Agent.py:118][0m Rollout length: 2600
[32m[0907 10-47-01 @MBExp.py:227][0m Rewards obtained: [-2822.17987822174], Lows: [715], Highs: [1435], Total time: 63107.79213300002
[32m[0907 10-47-57 @MBExp.py:144][0m ####################################################################
[32m[0907 10-47-57 @MBExp.py:145][0m Starting training iteration 84.
[32m[0907 10-48-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32547, current rewards: -10.00000, mean: -1.00000
[32m[0907 10-48-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30799, current rewards: -60.00000, mean: -1.00000
[32m[0907 10-48-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30868, current rewards: -99.12085, mean: -0.90110
[32m[0907 10-48-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32879, current rewards: -199.12085, mean: -1.24451
[32m[0907 10-49-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37277, current rewards: -299.12085, mean: -1.42438
[32m[0907 10-49-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37387, current rewards: -354.09800, mean: -1.36192
[32m[0907 10-49-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36360, current rewards: -419.44153, mean: -1.35304
[32m[0907 10-50-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35623, current rewards: -439.21156, mean: -1.22003
[32m[0907 10-50-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35041, current rewards: -489.21156, mean: -1.19320
[32m[0907 10-50-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34575, current rewards: -539.21156, mean: -1.17220
[32m[0907 10-50-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34208, current rewards: -589.21156, mean: -1.15532
[32m[0907 10-51-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33935, current rewards: -639.21156, mean: -1.14145
[32m[0907 10-51-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33705, current rewards: -689.21156, mean: -1.12986
[32m[0907 10-51-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33476, current rewards: -739.21156, mean: -1.12002
[32m[0907 10-51-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33287, current rewards: -789.21156, mean: -1.11157
[32m[0907 10-52-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33127, current rewards: -839.21156, mean: -1.10423
[32m[0907 10-52-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33005, current rewards: -889.21156, mean: -1.09779
[32m[0907 10-52-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32890, current rewards: -939.21156, mean: -1.09211
[32m[0907 10-52-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32783, current rewards: -989.21156, mean: -1.08705
[32m[0907 10-53-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32687, current rewards: -1039.21156, mean: -1.08251
[32m[0907 10-53-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32619, current rewards: -1089.21156, mean: -1.07843
[32m[0907 10-53-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32534, current rewards: -1139.21156, mean: -1.07473
[32m[0907 10-53-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32463, current rewards: -1189.21156, mean: -1.07136
[32m[0907 10-54-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32398, current rewards: -1239.21156, mean: -1.06829
[32m[0907 10-54-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32344, current rewards: -1289.21156, mean: -1.06546
[32m[0907 10-54-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32292, current rewards: -1339.21156, mean: -1.06287
[32m[0907 10-55-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32257, current rewards: -1389.21156, mean: -1.06047
[32m[0907 10-55-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32216, current rewards: -1439.21156, mean: -1.05824
[32m[0907 10-55-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32168, current rewards: -1489.21156, mean: -1.05618
[32m[0907 10-55-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32125, current rewards: -1539.21156, mean: -1.05425
[32m[0907 10-56-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32078, current rewards: -1589.21156, mean: -1.05246
[32m[0907 10-56-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32039, current rewards: -1639.21156, mean: -1.05078
[32m[0907 10-56-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32000, current rewards: -1689.21156, mean: -1.04920
[32m[0907 10-56-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31960, current rewards: -1739.21156, mean: -1.04772
[32m[0907 10-57-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31930, current rewards: -1789.21156, mean: -1.04632
[32m[0907 10-57-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31923, current rewards: -1839.21156, mean: -1.04501
[32m[0907 10-57-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31903, current rewards: -1843.03291, mean: -1.01825
[32m[0907 10-57-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31878, current rewards: -1836.71748, mean: -0.98748
[32m[0907 10-58-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31847, current rewards: -1830.40206, mean: -0.95833
[32m[0907 10-58-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31824, current rewards: -1824.23000, mean: -0.93073
[32m[0907 10-58-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31802, current rewards: -1872.00747, mean: -0.93135
[32m[0907 10-58-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31777, current rewards: -1922.00747, mean: -0.93301
[32m[0907 10-59-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31756, current rewards: -1972.00747, mean: -0.93460
[32m[0907 10-59-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31738, current rewards: -2022.00747, mean: -0.93611
[32m[0907 10-59-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31716, current rewards: -2072.00747, mean: -0.93756
[32m[0907 10-59-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31693, current rewards: -2122.00747, mean: -0.93894
[32m[0907 11-00-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31689, current rewards: -2172.00747, mean: -0.94026
[32m[0907 11-00-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31682, current rewards: -2222.00747, mean: -0.94153
[32m[0907 11-00-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31668, current rewards: -2272.00747, mean: -0.94274
[32m[0907 11-00-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31650, current rewards: -2322.00747, mean: -0.94391
[32m[0907 11-01-08 @Agent.py:117][0m Average action selection time: 0.3163
[32m[0907 11-01-08 @Agent.py:118][0m Rollout length: 2600
[32m[0907 11-01-08 @MBExp.py:227][0m Rewards obtained: [-2362.0074701296226], Lows: [160], Highs: [2079], Total time: 63899.137576000016
[32m[0907 11-02-06 @MBExp.py:144][0m ####################################################################
[32m[0907 11-02-06 @MBExp.py:145][0m Starting training iteration 85.
[32m[0907 11-02-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49627, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-02-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.47124, current rewards: -60.00000, mean: -1.00000
[32m[0907 11-02-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.42253, current rewards: -99.20023, mean: -0.90182
[32m[0907 11-03-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.38648, current rewards: -162.47882, mean: -1.01549
[32m[0907 11-03-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36880, current rewards: -262.47882, mean: -1.24990
[32m[0907 11-03-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35755, current rewards: -362.47882, mean: -1.39415
[32m[0907 11-03-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34896, current rewards: -462.47882, mean: -1.49187
[32m[0907 11-04-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34255, current rewards: -562.47882, mean: -1.56244
[32m[0907 11-04-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33779, current rewards: -662.47882, mean: -1.61580
[32m[0907 11-04-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33409, current rewards: -762.47882, mean: -1.65756
[32m[0907 11-04-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33108, current rewards: -862.47882, mean: -1.69113
[32m[0907 11-05-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32868, current rewards: -962.47882, mean: -1.71871
[32m[0907 11-05-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32669, current rewards: -1062.47882, mean: -1.74177
[32m[0907 11-05-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32498, current rewards: -1162.47882, mean: -1.76133
[32m[0907 11-05-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32354, current rewards: -1262.47882, mean: -1.77814
[32m[0907 11-06-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32226, current rewards: -1362.47882, mean: -1.79274
[32m[0907 11-06-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32117, current rewards: -1462.47882, mean: -1.80553
[32m[0907 11-06-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32020, current rewards: -1562.47882, mean: -1.81684
[32m[0907 11-06-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31932, current rewards: -1662.47882, mean: -1.82690
[32m[0907 11-07-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31853, current rewards: -1762.47882, mean: -1.83592
[32m[0907 11-07-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31783, current rewards: -1862.47882, mean: -1.84404
[32m[0907 11-07-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31719, current rewards: -1962.47882, mean: -1.85140
[32m[0907 11-07-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31661, current rewards: -2062.47882, mean: -1.85809
[32m[0907 11-08-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31606, current rewards: -2162.47882, mean: -1.86421
[32m[0907 11-08-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31557, current rewards: -2262.47882, mean: -1.86982
[32m[0907 11-08-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31509, current rewards: -2362.47882, mean: -1.87498
[32m[0907 11-08-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31468, current rewards: -2462.47882, mean: -1.87975
[32m[0907 11-09-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31429, current rewards: -2562.47882, mean: -1.88418
[32m[0907 11-09-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31393, current rewards: -2662.47882, mean: -1.88828
[32m[0907 11-09-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31359, current rewards: -2762.47882, mean: -1.89211
[32m[0907 11-10-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31328, current rewards: -2862.47882, mean: -1.89568
[32m[0907 11-10-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31302, current rewards: -2962.47882, mean: -1.89902
[32m[0907 11-10-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31274, current rewards: -3062.47882, mean: -1.90216
[32m[0907 11-10-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31248, current rewards: -3162.47882, mean: -1.90511
[32m[0907 11-11-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31223, current rewards: -3262.47882, mean: -1.90788
[32m[0907 11-11-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31201, current rewards: -3362.47882, mean: -1.91050
[32m[0907 11-11-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31178, current rewards: -3462.47882, mean: -1.91297
[32m[0907 11-11-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31159, current rewards: -3562.47882, mean: -1.91531
[32m[0907 11-12-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31140, current rewards: -3662.47882, mean: -1.91753
[32m[0907 11-12-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31127, current rewards: -3762.47882, mean: -1.91963
[32m[0907 11-12-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31121, current rewards: -3862.47882, mean: -1.92163
[32m[0907 11-12-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31103, current rewards: -3962.47882, mean: -1.92353
[32m[0907 11-13-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31087, current rewards: -4062.47882, mean: -1.92535
[32m[0907 11-13-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31071, current rewards: -4162.47882, mean: -1.92707
[32m[0907 11-13-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31055, current rewards: -4262.47882, mean: -1.92872
[32m[0907 11-13-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31042, current rewards: -4362.47882, mean: -1.93030
[32m[0907 11-14-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31028, current rewards: -4462.47882, mean: -1.93181
[32m[0907 11-14-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31013, current rewards: -4562.47882, mean: -1.93325
[32m[0907 11-14-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31015, current rewards: -4662.47882, mean: -1.93464
[32m[0907 11-14-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30985, current rewards: -4762.47882, mean: -1.93597
[32m[0907 11-15-02 @Agent.py:117][0m Average action selection time: 0.3100
[32m[0907 11-15-02 @Agent.py:118][0m Rollout length: 2600
[32m[0907 11-15-02 @MBExp.py:227][0m Rewards obtained: [-4842.478823143104], Lows: [2375], Highs: [100], Total time: 64674.58245800002
[32m[0907 11-15-57 @MBExp.py:144][0m ####################################################################
[32m[0907 11-15-57 @MBExp.py:145][0m Starting training iteration 86.
[32m[0907 11-16-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.47886, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-16-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.37050, current rewards: -60.00000, mean: -1.00000
[32m[0907 11-16-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.33633, current rewards: -113.42435, mean: -1.03113
[32m[0907 11-16-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.32337, current rewards: -213.42435, mean: -1.33390
[32m[0907 11-17-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31701, current rewards: -313.42435, mean: -1.49250
[32m[0907 11-17-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31279, current rewards: -413.42435, mean: -1.59009
[32m[0907 11-17-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30999, current rewards: -513.42435, mean: -1.65621
[32m[0907 11-17-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30806, current rewards: -613.42435, mean: -1.70396
[32m[0907 11-18-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30658, current rewards: -713.42435, mean: -1.74006
[32m[0907 11-18-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30866, current rewards: -813.42435, mean: -1.76831
[32m[0907 11-18-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30748, current rewards: -913.42435, mean: -1.79103
[32m[0907 11-18-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30642, current rewards: -1013.42435, mean: -1.80969
[32m[0907 11-19-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30564, current rewards: -1113.42435, mean: -1.82529
[32m[0907 11-19-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30511, current rewards: -1213.42435, mean: -1.83852
[32m[0907 11-19-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30463, current rewards: -1313.42435, mean: -1.84989
[32m[0907 11-19-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30441, current rewards: -1413.42435, mean: -1.85977
[32m[0907 11-20-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30425, current rewards: -1513.42435, mean: -1.86843
[32m[0907 11-20-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30495, current rewards: -1613.42435, mean: -1.87607
[32m[0907 11-20-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30745, current rewards: -1695.30047, mean: -1.86297
[32m[0907 11-20-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30746, current rewards: -1795.30047, mean: -1.87010
[32m[0907 11-21-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31216, current rewards: -1849.99742, mean: -1.83168
[32m[0907 11-21-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31558, current rewards: -1899.99742, mean: -1.79245
[32m[0907 11-21-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31506, current rewards: -1976.94883, mean: -1.78103
[32m[0907 11-22-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31881, current rewards: -2076.94883, mean: -1.79047
[32m[0907 11-22-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32338, current rewards: -2176.94883, mean: -1.79913
[32m[0907 11-22-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32323, current rewards: -2207.82700, mean: -1.75224
[32m[0907 11-23-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32458, current rewards: -2241.97611, mean: -1.71143
[32m[0907 11-23-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32409, current rewards: -2291.97611, mean: -1.68528
[32m[0907 11-23-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32356, current rewards: -2374.91767, mean: -1.68434
[32m[0907 11-23-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32320, current rewards: -2474.91767, mean: -1.69515
[32m[0907 11-24-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32275, current rewards: -2549.66636, mean: -1.68852
[32m[0907 11-24-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32225, current rewards: -2599.66636, mean: -1.66645
[32m[0907 11-24-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32195, current rewards: -2648.41288, mean: -1.64498
[32m[0907 11-24-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32173, current rewards: -2748.41288, mean: -1.65567
[32m[0907 11-25-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32139, current rewards: -2848.41288, mean: -1.66574
[32m[0907 11-25-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32101, current rewards: -2948.41288, mean: -1.67523
[32m[0907 11-25-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32069, current rewards: -3048.41288, mean: -1.68421
[32m[0907 11-25-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32046, current rewards: -3148.41288, mean: -1.69270
[32m[0907 11-26-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32038, current rewards: -3248.41288, mean: -1.70074
[32m[0907 11-26-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32001, current rewards: -3348.41288, mean: -1.70837
[32m[0907 11-26-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31966, current rewards: -3448.41288, mean: -1.71563
[32m[0907 11-26-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31938, current rewards: -3548.41288, mean: -1.72253
[32m[0907 11-27-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31907, current rewards: -3648.41288, mean: -1.72911
[32m[0907 11-27-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31878, current rewards: -3748.41288, mean: -1.73538
[32m[0907 11-27-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31849, current rewards: -3848.41288, mean: -1.74136
[32m[0907 11-27-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31823, current rewards: -3948.41288, mean: -1.74709
[32m[0907 11-28-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31797, current rewards: -4048.41288, mean: -1.75256
[32m[0907 11-28-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31772, current rewards: -4148.41288, mean: -1.75780
[32m[0907 11-28-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31749, current rewards: -4248.41288, mean: -1.76283
[32m[0907 11-28-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31734, current rewards: -4348.41288, mean: -1.76765
[32m[0907 11-29-11 @Agent.py:117][0m Average action selection time: 0.3173
[32m[0907 11-29-11 @Agent.py:118][0m Rollout length: 2600
[32m[0907 11-29-11 @MBExp.py:227][0m Rewards obtained: [-4428.41288457188], Lows: [2021], Highs: [403], Total time: 65468.27744200002
[32m[0907 11-30-11 @MBExp.py:144][0m ####################################################################
[32m[0907 11-30-11 @MBExp.py:145][0m Starting training iteration 87.
[32m[0907 11-30-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31102, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-30-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31557, current rewards: -60.00000, mean: -1.00000
[32m[0907 11-30-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31355, current rewards: -101.35374, mean: -0.92140
[32m[0907 11-31-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31253, current rewards: -117.11427, mean: -0.73196
[32m[0907 11-31-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31314, current rewards: -164.52567, mean: -0.78346
[32m[0907 11-31-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31222, current rewards: -214.52567, mean: -0.82510
[32m[0907 11-31-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31119, current rewards: -264.52567, mean: -0.85331
[32m[0907 11-32-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31048, current rewards: -314.52567, mean: -0.87368
[32m[0907 11-32-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31018, current rewards: -364.52567, mean: -0.88909
[32m[0907 11-32-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31014, current rewards: -414.52567, mean: -0.90114
[32m[0907 11-32-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31027, current rewards: -464.52567, mean: -0.91083
[32m[0907 11-33-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31036, current rewards: -514.52567, mean: -0.91880
[32m[0907 11-33-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30987, current rewards: -564.52567, mean: -0.92545
[32m[0907 11-33-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30948, current rewards: -614.52567, mean: -0.93110
[32m[0907 11-33-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30912, current rewards: -664.52567, mean: -0.93595
[32m[0907 11-34-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30883, current rewards: -714.52567, mean: -0.94017
[32m[0907 11-34-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30858, current rewards: -764.52567, mean: -0.94386
[32m[0907 11-34-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30833, current rewards: -814.52567, mean: -0.94712
[32m[0907 11-34-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30814, current rewards: -864.52567, mean: -0.95003
[32m[0907 11-35-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30798, current rewards: -914.52567, mean: -0.95263
[32m[0907 11-35-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30781, current rewards: -964.52567, mean: -0.95498
[32m[0907 11-35-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30800, current rewards: -1014.52567, mean: -0.95710
[32m[0907 11-35-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30818, current rewards: -1064.52567, mean: -0.95903
[32m[0907 11-36-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30837, current rewards: -1114.52567, mean: -0.96080
[32m[0907 11-36-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30845, current rewards: -1164.52567, mean: -0.96242
[32m[0907 11-36-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30877, current rewards: -1214.52567, mean: -0.96391
[32m[0907 11-36-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30884, current rewards: -1264.52567, mean: -0.96529
[32m[0907 11-37-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30914, current rewards: -1314.52567, mean: -0.96656
[32m[0907 11-37-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30903, current rewards: -1364.52567, mean: -0.96775
[32m[0907 11-37-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30892, current rewards: -1414.52567, mean: -0.96885
[32m[0907 11-37-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30893, current rewards: -1464.52567, mean: -0.96988
[32m[0907 11-38-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30895, current rewards: -1514.52567, mean: -0.97085
[32m[0907 11-38-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30883, current rewards: -1564.52567, mean: -0.97176
[32m[0907 11-38-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30896, current rewards: -1614.52567, mean: -0.97261
[32m[0907 11-38-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30893, current rewards: -1664.52567, mean: -0.97341
[32m[0907 11-39-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30886, current rewards: -1714.52567, mean: -0.97416
[32m[0907 11-39-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30888, current rewards: -1764.52567, mean: -0.97488
[32m[0907 11-39-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30902, current rewards: -1814.52567, mean: -0.97555
[32m[0907 11-40-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30895, current rewards: -1864.52567, mean: -0.97619
[32m[0907 11-40-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30897, current rewards: -1914.52567, mean: -0.97680
[32m[0907 11-40-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30908, current rewards: -1964.52567, mean: -0.97738
[32m[0907 11-40-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30905, current rewards: -2014.52567, mean: -0.97793
[32m[0907 11-41-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30892, current rewards: -2064.52567, mean: -0.97845
[32m[0907 11-41-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30890, current rewards: -2114.52567, mean: -0.97895
[32m[0907 11-41-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30890, current rewards: -2164.52567, mean: -0.97942
[32m[0907 11-41-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30883, current rewards: -2214.52567, mean: -0.97988
[32m[0907 11-42-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30874, current rewards: -2264.52567, mean: -0.98031
[32m[0907 11-42-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30869, current rewards: -2300.77457, mean: -0.97490
[32m[0907 11-42-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30858, current rewards: -2297.65650, mean: -0.95338
[32m[0907 11-42-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30848, current rewards: -2294.53842, mean: -0.93274
[32m[0907 11-43-02 @Agent.py:117][0m Average action selection time: 0.3084
[32m[0907 11-43-02 @Agent.py:118][0m Rollout length: 2600
[32m[0907 11-43-02 @MBExp.py:227][0m Rewards obtained: [-2292.0439664385326], Lows: [4], Highs: [2299], Total time: 66239.78833300002
[32m[0907 11-44-01 @MBExp.py:144][0m ####################################################################
[32m[0907 11-44-01 @MBExp.py:145][0m Starting training iteration 88.
[32m[0907 11-44-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.44519, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-44-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.32932, current rewards: -60.00000, mean: -1.00000
[32m[0907 11-44-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.32079, current rewards: -108.87691, mean: -0.98979
[32m[0907 11-44-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31575, current rewards: -158.87691, mean: -0.99298
[32m[0907 11-45-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31543, current rewards: -205.70806, mean: -0.97956
[32m[0907 11-45-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31388, current rewards: -303.56062, mean: -1.16754
[32m[0907 11-45-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31259, current rewards: -403.56062, mean: -1.30181
[32m[0907 11-45-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31219, current rewards: -503.56062, mean: -1.39878
[32m[0907 11-46-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31282, current rewards: -603.56062, mean: -1.47210
[32m[0907 11-46-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31237, current rewards: -703.56062, mean: -1.52948
[32m[0907 11-46-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31238, current rewards: -803.56062, mean: -1.57561
[32m[0907 11-46-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.31243, current rewards: -903.56062, mean: -1.61350
[32m[0907 11-47-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31233, current rewards: -1003.56062, mean: -1.64518
[32m[0907 11-47-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31187, current rewards: -1103.56062, mean: -1.67206
[32m[0907 11-47-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31164, current rewards: -1203.56062, mean: -1.69516
[32m[0907 11-47-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31160, current rewards: -1303.56062, mean: -1.71521
[32m[0907 11-48-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31130, current rewards: -1403.56062, mean: -1.73279
[32m[0907 11-48-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31101, current rewards: -1503.56062, mean: -1.74833
[32m[0907 11-48-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31073, current rewards: -1603.56062, mean: -1.76215
[32m[0907 11-48-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31049, current rewards: -1703.56062, mean: -1.77454
[32m[0907 11-49-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31028, current rewards: -1803.56062, mean: -1.78570
[32m[0907 11-49-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31006, current rewards: -1903.56062, mean: -1.79581
[32m[0907 11-49-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30978, current rewards: -2003.56062, mean: -1.80501
[32m[0907 11-50-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30926, current rewards: -2103.56062, mean: -1.81341
[32m[0907 11-50-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30880, current rewards: -2203.56062, mean: -1.82112
[32m[0907 11-50-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30871, current rewards: -2303.56062, mean: -1.82822
[32m[0907 11-50-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30864, current rewards: -2403.56062, mean: -1.83478
[32m[0907 11-51-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30858, current rewards: -2503.56062, mean: -1.84085
[32m[0907 11-51-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30850, current rewards: -2603.56062, mean: -1.84650
[32m[0907 11-51-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30843, current rewards: -2703.56062, mean: -1.85175
[32m[0907 11-51-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30836, current rewards: -2803.56062, mean: -1.85666
[32m[0907 11-52-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30839, current rewards: -2903.56062, mean: -1.86126
[32m[0907 11-52-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30833, current rewards: -3003.56062, mean: -1.86557
[32m[0907 11-52-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30828, current rewards: -3103.56062, mean: -1.86961
[32m[0907 11-52-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30832, current rewards: -3203.56062, mean: -1.87343
[32m[0907 11-53-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30821, current rewards: -3303.56062, mean: -1.87702
[32m[0907 11-53-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30809, current rewards: -3403.56062, mean: -1.88042
[32m[0907 11-53-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30798, current rewards: -3503.56062, mean: -1.88363
[32m[0907 11-53-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30787, current rewards: -3603.56062, mean: -1.88668
[32m[0907 11-54-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30807, current rewards: -3703.56062, mean: -1.88957
[32m[0907 11-54-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30806, current rewards: -3803.56062, mean: -1.89232
[32m[0907 11-54-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30808, current rewards: -3903.56062, mean: -1.89493
[32m[0907 11-54-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30813, current rewards: -4003.56062, mean: -1.89742
[32m[0907 11-55-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30820, current rewards: -4103.56062, mean: -1.89980
[32m[0907 11-55-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30802, current rewards: -4203.56062, mean: -1.90206
[32m[0907 11-55-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30796, current rewards: -4303.56062, mean: -1.90423
[32m[0907 11-55-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30785, current rewards: -4403.56062, mean: -1.90630
[32m[0907 11-56-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30775, current rewards: -4503.56062, mean: -1.90829
[32m[0907 11-56-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30775, current rewards: -4603.56062, mean: -1.91019
[32m[0907 11-56-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30767, current rewards: -4703.56062, mean: -1.91202
[32m[0907 11-56-51 @Agent.py:117][0m Average action selection time: 0.3077
[32m[0907 11-56-51 @Agent.py:118][0m Rollout length: 2600
[32m[0907 11-56-51 @MBExp.py:227][0m Rewards obtained: [-4783.560622177696], Lows: [2289], Highs: [206], Total time: 67009.55794700002
[32m[0907 11-57-52 @MBExp.py:144][0m ####################################################################
[32m[0907 11-57-52 @MBExp.py:145][0m Starting training iteration 89.
[32m[0907 11-57-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.38146, current rewards: -10.00000, mean: -1.00000
[32m[0907 11-58-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31571, current rewards: -60.00000, mean: -1.00000
[32m[0907 11-58-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.31162, current rewards: -107.85892, mean: -0.98054
[32m[0907 11-58-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.31055, current rewards: -157.85892, mean: -0.98662
[32m[0907 11-58-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.31245, current rewards: -208.77481, mean: -0.99417
[32m[0907 11-59-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.31199, current rewards: -308.77481, mean: -1.18760
[32m[0907 11-59-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.31233, current rewards: -408.77481, mean: -1.31863
[32m[0907 11-59-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31247, current rewards: -508.77481, mean: -1.41326
[32m[0907 12-00-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.31146, current rewards: -608.77481, mean: -1.48482
[32m[0907 12-00-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.31102, current rewards: -708.77481, mean: -1.54081
[32m[0907 12-00-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.31033, current rewards: -808.77481, mean: -1.58583
[32m[0907 12-00-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30976, current rewards: -908.77481, mean: -1.62281
[32m[0907 12-01-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30924, current rewards: -1008.77481, mean: -1.65373
[32m[0907 12-01-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30884, current rewards: -1108.77481, mean: -1.67996
[32m[0907 12-01-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30852, current rewards: -1208.77481, mean: -1.70250
[32m[0907 12-01-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30825, current rewards: -1308.77481, mean: -1.72207
[32m[0907 12-02-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30812, current rewards: -1408.77481, mean: -1.73923
[32m[0907 12-02-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30792, current rewards: -1508.77481, mean: -1.75439
[32m[0907 12-02-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30791, current rewards: -1608.77481, mean: -1.76788
[32m[0907 12-02-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30814, current rewards: -1708.77481, mean: -1.77997
[32m[0907 12-03-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30832, current rewards: -1808.77481, mean: -1.79087
[32m[0907 12-03-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30865, current rewards: -1908.77481, mean: -1.80073
[32m[0907 12-03-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30925, current rewards: -2008.77481, mean: -1.80971
[32m[0907 12-03-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30969, current rewards: -2108.77481, mean: -1.81791
[32m[0907 12-04-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31002, current rewards: -2208.77481, mean: -1.82543
[32m[0907 12-04-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31016, current rewards: -2308.77481, mean: -1.83236
[32m[0907 12-04-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31018, current rewards: -2408.77481, mean: -1.83876
[32m[0907 12-04-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31048, current rewards: -2508.77481, mean: -1.84469
[32m[0907 12-05-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31079, current rewards: -2608.77481, mean: -1.85019
[32m[0907 12-05-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31139, current rewards: -2708.77481, mean: -1.85533
[32m[0907 12-05-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31180, current rewards: -2808.77481, mean: -1.86012
[32m[0907 12-05-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31161, current rewards: -2908.77481, mean: -1.86460
[32m[0907 12-06-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31186, current rewards: -3008.77481, mean: -1.86880
[32m[0907 12-06-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31207, current rewards: -3108.77481, mean: -1.87276
[32m[0907 12-06-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31231, current rewards: -3208.77481, mean: -1.87648
[32m[0907 12-07-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31234, current rewards: -3308.77481, mean: -1.87999
[32m[0907 12-07-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31260, current rewards: -3408.77481, mean: -1.88330
[32m[0907 12-07-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31265, current rewards: -3508.77481, mean: -1.88644
[32m[0907 12-07-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31277, current rewards: -3608.77481, mean: -1.88941
[32m[0907 12-08-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31268, current rewards: -3708.77481, mean: -1.89223
[32m[0907 12-08-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31256, current rewards: -3808.77481, mean: -1.89491
[32m[0907 12-08-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31238, current rewards: -3908.77481, mean: -1.89746
[32m[0907 12-08-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31221, current rewards: -4008.77481, mean: -1.89989
[32m[0907 12-09-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31203, current rewards: -4108.77481, mean: -1.90221
[32m[0907 12-09-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31183, current rewards: -4208.77481, mean: -1.90442
[32m[0907 12-09-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31180, current rewards: -4308.77481, mean: -1.90654
[32m[0907 12-09-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31160, current rewards: -4408.77481, mean: -1.90856
[32m[0907 12-10-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31143, current rewards: -4508.77481, mean: -1.91050
[32m[0907 12-10-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31126, current rewards: -4608.77481, mean: -1.91235
[32m[0907 12-10-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31111, current rewards: -4708.77481, mean: -1.91414
[32m[0907 12-10-50 @Agent.py:117][0m Average action selection time: 0.3110
[32m[0907 12-10-50 @Agent.py:118][0m Rollout length: 2600
[32m[0907 12-10-50 @MBExp.py:227][0m Rewards obtained: [-4788.774812360905], Lows: [2292], Highs: [205], Total time: 67787.54323200003
[32m[0907 12-11-50 @MBExp.py:144][0m ####################################################################
[32m[0907 12-11-50 @MBExp.py:145][0m Starting training iteration 90.
[32m[0907 12-11-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.50210, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-12-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.50147, current rewards: -60.00000, mean: -1.00000
[32m[0907 12-12-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.48577, current rewards: -110.00000, mean: -1.00000
[32m[0907 12-12-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.42835, current rewards: -160.00000, mean: -1.00000
[32m[0907 12-13-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.40896, current rewards: -216.84472, mean: -1.03259
[32m[0907 12-13-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.38859, current rewards: -316.84472, mean: -1.21863
[32m[0907 12-13-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37607, current rewards: -416.84472, mean: -1.34466
[32m[0907 12-14-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36597, current rewards: -516.84472, mean: -1.43568
[32m[0907 12-14-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35883, current rewards: -612.67366, mean: -1.49433
[32m[0907 12-14-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35280, current rewards: -712.67366, mean: -1.54929
[32m[0907 12-14-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34831, current rewards: -812.67366, mean: -1.59348
[32m[0907 12-15-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34469, current rewards: -912.67366, mean: -1.62977
[32m[0907 12-15-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34134, current rewards: -1012.67366, mean: -1.66012
[32m[0907 12-15-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33897, current rewards: -1112.67366, mean: -1.68587
[32m[0907 12-15-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33648, current rewards: -1212.67366, mean: -1.70799
[32m[0907 12-16-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33465, current rewards: -1312.67366, mean: -1.72720
[32m[0907 12-16-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33277, current rewards: -1410.23337, mean: -1.74103
[32m[0907 12-16-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33112, current rewards: -1508.23337, mean: -1.75376
[32m[0907 12-16-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32961, current rewards: -1608.23337, mean: -1.76729
[32m[0907 12-17-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32830, current rewards: -1708.23337, mean: -1.77941
[32m[0907 12-17-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32709, current rewards: -1806.03837, mean: -1.78816
[32m[0907 12-17-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32600, current rewards: -1890.60912, mean: -1.78359
[32m[0907 12-17-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32501, current rewards: -1990.60912, mean: -1.79334
[32m[0907 12-18-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32444, current rewards: -2090.60912, mean: -1.80225
[32m[0907 12-18-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32381, current rewards: -2190.60912, mean: -1.81042
[32m[0907 12-18-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33017, current rewards: -2290.60912, mean: -1.81794
[32m[0907 12-19-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33716, current rewards: -2382.42844, mean: -1.81865
[32m[0907 12-19-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33713, current rewards: -2482.42844, mean: -1.82532
[32m[0907 12-19-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33592, current rewards: -2582.42844, mean: -1.83151
[32m[0907 12-19-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33499, current rewards: -2664.28855, mean: -1.82486
[32m[0907 12-20-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33396, current rewards: -2764.28855, mean: -1.83065
[32m[0907 12-20-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33289, current rewards: -2864.28855, mean: -1.83608
[32m[0907 12-20-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33234, current rewards: -2964.28855, mean: -1.84117
[32m[0907 12-21-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33207, current rewards: -3064.28855, mean: -1.84596
[32m[0907 12-21-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33550, current rewards: -3156.68711, mean: -1.84602
[32m[0907 12-21-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33705, current rewards: -3247.32631, mean: -1.84507
[32m[0907 12-21-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33628, current rewards: -3297.32631, mean: -1.82173
[32m[0907 12-22-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33532, current rewards: -3347.32631, mean: -1.79964
[32m[0907 12-22-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33447, current rewards: -3426.95261, mean: -1.79422
[32m[0907 12-22-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33368, current rewards: -3526.95261, mean: -1.79947
[32m[0907 12-23-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33296, current rewards: -3626.95261, mean: -1.80445
[32m[0907 12-23-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33246, current rewards: -3726.95261, mean: -1.80920
[32m[0907 12-23-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33173, current rewards: -3826.95261, mean: -1.81372
[32m[0907 12-23-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33157, current rewards: -3926.95261, mean: -1.81803
[32m[0907 12-24-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33104, current rewards: -4026.95261, mean: -1.82215
[32m[0907 12-24-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33082, current rewards: -4126.95261, mean: -1.82609
[32m[0907 12-24-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33129, current rewards: -4226.95261, mean: -1.82985
[32m[0907 12-24-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33111, current rewards: -4326.95261, mean: -1.83345
[32m[0907 12-25-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33171, current rewards: -4426.95261, mean: -1.83691
[32m[0907 12-25-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33464, current rewards: -4509.07724, mean: -1.83296
[32m[0907 12-25-54 @Agent.py:117][0m Average action selection time: 0.3374
[32m[0907 12-25-54 @Agent.py:118][0m Rollout length: 2600
[32m[0907 12-25-54 @MBExp.py:227][0m Rewards obtained: [-4583.025113005657], Lows: [2128], Highs: [335], Total time: 68631.41140900002
[32m[0907 12-26-54 @MBExp.py:144][0m ####################################################################
[32m[0907 12-26-54 @MBExp.py:145][0m Starting training iteration 91.
[32m[0907 12-26-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49842, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-27-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.47829, current rewards: -60.00000, mean: -1.00000
[32m[0907 12-27-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.42069, current rewards: -120.00000, mean: -1.09091
[32m[0907 12-27-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.39299, current rewards: -208.37230, mean: -1.30233
[32m[0907 12-28-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37477, current rewards: -258.70621, mean: -1.23193
[32m[0907 12-28-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36430, current rewards: -334.91116, mean: -1.28812
[32m[0907 12-28-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35652, current rewards: -432.60724, mean: -1.39551
[32m[0907 12-29-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35174, current rewards: -518.97818, mean: -1.44161
[32m[0907 12-29-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35226, current rewards: -609.22876, mean: -1.48592
[32m[0907 12-29-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34825, current rewards: -702.63132, mean: -1.52746
[32m[0907 12-29-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34461, current rewards: -787.20956, mean: -1.54355
[32m[0907 12-30-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34173, current rewards: -885.10330, mean: -1.58054
[32m[0907 12-30-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34179, current rewards: -983.01216, mean: -1.61150
[32m[0907 12-30-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34097, current rewards: -1083.01216, mean: -1.64093
[32m[0907 12-30-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33995, current rewards: -1183.01216, mean: -1.66621
[32m[0907 12-31-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33892, current rewards: -1283.01216, mean: -1.68817
[32m[0907 12-31-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33707, current rewards: -1383.01216, mean: -1.70742
[32m[0907 12-31-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33816, current rewards: -1483.01216, mean: -1.72443
[32m[0907 12-32-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34395, current rewards: -1583.01216, mean: -1.73957
[32m[0907 12-32-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34643, current rewards: -1614.10197, mean: -1.68136
[32m[0907 12-32-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34469, current rewards: -1631.28487, mean: -1.61513
[32m[0907 12-32-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34285, current rewards: -1679.18612, mean: -1.58414
[32m[0907 12-33-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34127, current rewards: -1729.18612, mean: -1.55783
[32m[0907 12-33-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33982, current rewards: -1779.18612, mean: -1.53378
[32m[0907 12-33-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33847, current rewards: -1829.18612, mean: -1.51172
[32m[0907 12-34-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33883, current rewards: -1879.18612, mean: -1.49142
[32m[0907 12-34-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33855, current rewards: -1929.18612, mean: -1.47266
[32m[0907 12-34-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33846, current rewards: -2018.45119, mean: -1.48416
[32m[0907 12-34-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33731, current rewards: -2118.45119, mean: -1.50245
[32m[0907 12-35-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33689, current rewards: -2218.45119, mean: -1.51949
[32m[0907 12-35-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33754, current rewards: -2316.08586, mean: -1.53383
[32m[0907 12-35-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34206, current rewards: -2340.73038, mean: -1.50047
[32m[0907 12-36-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34156, current rewards: -2408.49439, mean: -1.49596
[32m[0907 12-36-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34046, current rewards: -2506.40863, mean: -1.50988
[32m[0907 12-36-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34039, current rewards: -2606.40863, mean: -1.52422
[32m[0907 12-36-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34043, current rewards: -2706.40863, mean: -1.53773
[32m[0907 12-37-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33974, current rewards: -2755.37282, mean: -1.52231
[32m[0907 12-37-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33926, current rewards: -2850.71747, mean: -1.53264
[32m[0907 12-37-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33842, current rewards: -2943.79083, mean: -1.54125
[32m[0907 12-37-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33764, current rewards: -3004.76965, mean: -1.53305
[32m[0907 12-38-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33752, current rewards: -3002.21152, mean: -1.49364
[32m[0907 12-38-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34068, current rewards: -3008.21200, mean: -1.46030
[32m[0907 12-38-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34307, current rewards: -3069.89125, mean: -1.45492
[32m[0907 12-39-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34263, current rewards: -3149.05907, mean: -1.45790
[32m[0907 12-39-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34189, current rewards: -3231.91096, mean: -1.46240
[32m[0907 12-39-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34163, current rewards: -3275.78509, mean: -1.44946
[32m[0907 12-40-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34085, current rewards: -3323.58080, mean: -1.43878
[32m[0907 12-40-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34059, current rewards: -3409.12598, mean: -1.44454
[32m[0907 12-40-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33979, current rewards: -3509.12598, mean: -1.45607
[32m[0907 12-40-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33972, current rewards: -3584.77445, mean: -1.45723
[32m[0907 12-41-03 @Agent.py:117][0m Average action selection time: 0.3392
[32m[0907 12-41-03 @Agent.py:118][0m Rollout length: 2600
[32m[0907 12-41-03 @MBExp.py:227][0m Rewards obtained: [-3664.774452939581], Lows: [1558], Highs: [591], Total time: 69479.94693600002
[32m[0907 12-42-01 @MBExp.py:144][0m ####################################################################
[32m[0907 12-42-01 @MBExp.py:145][0m Starting training iteration 92.
[32m[0907 12-42-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49798, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-42-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.49632, current rewards: -60.00000, mean: -1.00000
[32m[0907 12-42-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.40708, current rewards: -110.00000, mean: -1.00000
[32m[0907 12-43-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.37395, current rewards: -159.78511, mean: -0.99866
[32m[0907 12-43-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35568, current rewards: -259.78511, mean: -1.23707
[32m[0907 12-43-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34633, current rewards: -359.78511, mean: -1.38379
[32m[0907 12-43-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33976, current rewards: -459.78511, mean: -1.48318
[32m[0907 12-44-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33508, current rewards: -552.96524, mean: -1.53601
[32m[0907 12-44-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33104, current rewards: -652.96524, mean: -1.59260
[32m[0907 12-44-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32711, current rewards: -752.96524, mean: -1.63688
[32m[0907 12-44-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32470, current rewards: -852.96524, mean: -1.67248
[32m[0907 12-45-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32275, current rewards: -952.96524, mean: -1.70172
[32m[0907 12-45-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32090, current rewards: -1052.96524, mean: -1.72617
[32m[0907 12-45-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31915, current rewards: -1152.96524, mean: -1.74692
[32m[0907 12-45-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31724, current rewards: -1252.96524, mean: -1.76474
[32m[0907 12-46-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31610, current rewards: -1352.96524, mean: -1.78022
[32m[0907 12-46-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31485, current rewards: -1452.96524, mean: -1.79378
[32m[0907 12-46-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31354, current rewards: -1552.96524, mean: -1.80577
[32m[0907 12-46-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31242, current rewards: -1652.96524, mean: -1.81645
[32m[0907 12-47-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31141, current rewards: -1752.96524, mean: -1.82601
[32m[0907 12-47-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31045, current rewards: -1852.96524, mean: -1.83462
[32m[0907 12-47-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30960, current rewards: -1952.96524, mean: -1.84242
[32m[0907 12-47-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30885, current rewards: -2052.96524, mean: -1.84952
[32m[0907 12-47-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30819, current rewards: -2152.96524, mean: -1.85600
[32m[0907 12-48-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30763, current rewards: -2252.96524, mean: -1.86195
[32m[0907 12-48-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30704, current rewards: -2352.96524, mean: -1.86743
[32m[0907 12-48-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30656, current rewards: -2452.96524, mean: -1.87249
[32m[0907 12-48-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30609, current rewards: -2552.96524, mean: -1.87718
[32m[0907 12-49-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30560, current rewards: -2652.96524, mean: -1.88154
[32m[0907 12-49-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30556, current rewards: -2752.96524, mean: -1.88559
[32m[0907 12-49-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30560, current rewards: -2852.96524, mean: -1.88938
[32m[0907 12-49-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30568, current rewards: -2952.96524, mean: -1.89293
[32m[0907 12-50-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30550, current rewards: -3052.96524, mean: -1.89625
[32m[0907 12-50-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30530, current rewards: -3152.96524, mean: -1.89938
[32m[0907 12-50-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30510, current rewards: -3252.96524, mean: -1.90232
[32m[0907 12-50-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30494, current rewards: -3352.96524, mean: -1.90509
[32m[0907 12-51-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30494, current rewards: -3452.96524, mean: -1.90772
[32m[0907 12-51-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30509, current rewards: -3552.96524, mean: -1.91020
[32m[0907 12-51-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30513, current rewards: -3652.96524, mean: -1.91255
[32m[0907 12-51-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30516, current rewards: -3752.96524, mean: -1.91478
[32m[0907 12-52-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30519, current rewards: -3852.96524, mean: -1.91690
[32m[0907 12-52-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30522, current rewards: -3952.96524, mean: -1.91892
[32m[0907 12-52-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30512, current rewards: -4052.96524, mean: -1.92084
[32m[0907 12-53-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30494, current rewards: -4152.96524, mean: -1.92267
[32m[0907 12-53-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30477, current rewards: -4252.96524, mean: -1.92442
[32m[0907 12-53-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30465, current rewards: -4352.96524, mean: -1.92609
[32m[0907 12-53-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30448, current rewards: -4452.96524, mean: -1.92769
[32m[0907 12-54-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30442, current rewards: -4552.96524, mean: -1.92922
[32m[0907 12-54-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30435, current rewards: -4652.96524, mean: -1.93069
[32m[0907 12-54-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30436, current rewards: -4752.96524, mean: -1.93210
[32m[0907 12-54-42 @Agent.py:117][0m Average action selection time: 0.3043
[32m[0907 12-54-42 @Agent.py:118][0m Rollout length: 2600
[32m[0907 12-54-42 @MBExp.py:227][0m Rewards obtained: [-4832.965237507251], Lows: [2341], Highs: [152], Total time: 70241.22075100002
[32m[0907 12-55-41 @MBExp.py:144][0m ####################################################################
[32m[0907 12-55-41 @MBExp.py:145][0m Starting training iteration 93.
[32m[0907 12-55-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.51136, current rewards: -10.00000, mean: -1.00000
[32m[0907 12-56-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.50621, current rewards: -60.00000, mean: -1.00000
[32m[0907 12-56-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.47387, current rewards: -114.40775, mean: -1.04007
[32m[0907 12-56-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.45028, current rewards: -137.15012, mean: -0.85719
[32m[0907 12-57-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.42247, current rewards: -220.38592, mean: -1.04946
[32m[0907 12-57-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.40139, current rewards: -320.38592, mean: -1.23225
[32m[0907 12-57-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.38863, current rewards: -420.38592, mean: -1.35608
[32m[0907 12-57-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37925, current rewards: -520.38592, mean: -1.44552
[32m[0907 12-58-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.37050, current rewards: -620.38592, mean: -1.51314
[32m[0907 12-58-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36363, current rewards: -705.01039, mean: -1.53263
[32m[0907 12-58-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35964, current rewards: -805.01039, mean: -1.57845
[32m[0907 12-59-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35534, current rewards: -905.01039, mean: -1.61609
[32m[0907 12-59-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35189, current rewards: -1000.83010, mean: -1.64071
[32m[0907 12-59-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34905, current rewards: -1100.83010, mean: -1.66792
[32m[0907 12-59-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.34652, current rewards: -1200.83010, mean: -1.69131
[32m[0907 13-00-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34448, current rewards: -1300.83010, mean: -1.71162
[32m[0907 13-00-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34287, current rewards: -1400.83010, mean: -1.72942
[32m[0907 13-00-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34134, current rewards: -1487.33297, mean: -1.72946
[32m[0907 13-00-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33938, current rewards: -1564.48409, mean: -1.71921
[32m[0907 13-01-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.33882, current rewards: -1651.76645, mean: -1.72059
[32m[0907 13-01-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.33856, current rewards: -1749.43770, mean: -1.73212
[32m[0907 13-01-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.33781, current rewards: -1837.37922, mean: -1.73338
[32m[0907 13-01-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33680, current rewards: -1909.89412, mean: -1.72063
[32m[0907 13-02-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33935, current rewards: -2009.89412, mean: -1.73267
[32m[0907 13-02-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34596, current rewards: -2107.65093, mean: -1.74186
[32m[0907 13-02-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34489, current rewards: -2162.98301, mean: -1.71665
[32m[0907 13-03-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34304, current rewards: -2225.12446, mean: -1.69857
[32m[0907 13-03-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34169, current rewards: -2248.96290, mean: -1.65365
[32m[0907 13-03-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34033, current rewards: -2255.75965, mean: -1.59983
[32m[0907 13-03-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33877, current rewards: -2305.75965, mean: -1.57929
[32m[0907 13-04-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33741, current rewards: -2355.75965, mean: -1.56011
[32m[0907 13-04-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33591, current rewards: -2405.75965, mean: -1.54215
[32m[0907 13-04-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33477, current rewards: -2455.75965, mean: -1.52532
[32m[0907 13-04-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33380, current rewards: -2505.75965, mean: -1.50949
[32m[0907 13-05-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33280, current rewards: -2555.75965, mean: -1.49460
[32m[0907 13-05-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33178, current rewards: -2605.75965, mean: -1.48055
[32m[0907 13-05-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33096, current rewards: -2653.66292, mean: -1.46611
[32m[0907 13-05-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33010, current rewards: -2648.33714, mean: -1.42384
[32m[0907 13-06-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32937, current rewards: -2647.70380, mean: -1.38623
[32m[0907 13-06-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32883, current rewards: -2697.70380, mean: -1.37638
[32m[0907 13-06-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32816, current rewards: -2747.70380, mean: -1.36702
[32m[0907 13-06-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32748, current rewards: -2841.77835, mean: -1.37950
[32m[0907 13-07-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32689, current rewards: -2941.77835, mean: -1.39421
[32m[0907 13-07-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32627, current rewards: -3041.77835, mean: -1.40823
[32m[0907 13-07-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32566, current rewards: -3141.77835, mean: -1.42162
[32m[0907 13-07-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32501, current rewards: -3241.77835, mean: -1.43442
[32m[0907 13-08-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32441, current rewards: -3341.77835, mean: -1.44666
[32m[0907 13-08-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32396, current rewards: -3441.77835, mean: -1.45838
[32m[0907 13-08-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32352, current rewards: -3541.77835, mean: -1.46962
[32m[0907 13-08-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32305, current rewards: -3641.77835, mean: -1.48040
[32m[0907 13-09-08 @Agent.py:117][0m Average action selection time: 0.3227
[32m[0907 13-09-08 @Agent.py:118][0m Rollout length: 2600
[32m[0907 13-09-08 @MBExp.py:227][0m Rewards obtained: [-3721.778346537748], Lows: [1556], Highs: [661], Total time: 71048.38971500001
[32m[0907 13-10-08 @MBExp.py:144][0m ####################################################################
[32m[0907 13-10-08 @MBExp.py:145][0m Starting training iteration 94.
[32m[0907 13-10-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49239, current rewards: 1.00459, mean: 0.10046
[32m[0907 13-10-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.49390, current rewards: 3.98143, mean: 0.06636
[32m[0907 13-11-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.49110, current rewards: -13.68038, mean: -0.12437
[32m[0907 13-11-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.47856, current rewards: -113.68038, mean: -0.71050
[32m[0907 13-11-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.44762, current rewards: -201.13729, mean: -0.95780
[32m[0907 13-12-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.43721, current rewards: -273.83433, mean: -1.05321
[32m[0907 13-12-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.44278, current rewards: -373.83433, mean: -1.20592
[32m[0907 13-12-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.43754, current rewards: -447.18482, mean: -1.24218
[32m[0907 13-13-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.42184, current rewards: -530.16516, mean: -1.29309
[32m[0907 13-13-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.41921, current rewards: -630.16516, mean: -1.36992
[32m[0907 13-13-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.42342, current rewards: -730.16516, mean: -1.43170
[32m[0907 13-14-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.42070, current rewards: -821.86987, mean: -1.46762
[32m[0907 13-14-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.41578, current rewards: -921.86987, mean: -1.51126
[32m[0907 13-14-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.40707, current rewards: -997.29488, mean: -1.51105
[32m[0907 13-14-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.39952, current rewards: -1081.16500, mean: -1.52277
[32m[0907 13-15-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.39307, current rewards: -1130.01560, mean: -1.48686
[32m[0907 13-15-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.38752, current rewards: -1180.01560, mean: -1.45681
[32m[0907 13-15-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.38241, current rewards: -1252.92044, mean: -1.45688
[32m[0907 13-15-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37790, current rewards: -1352.92044, mean: -1.48673
[32m[0907 13-16-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37448, current rewards: -1452.92044, mean: -1.51346
[32m[0907 13-16-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37068, current rewards: -1552.92044, mean: -1.53754
[32m[0907 13-16-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36741, current rewards: -1652.92044, mean: -1.55936
[32m[0907 13-16-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36708, current rewards: -1752.92044, mean: -1.57921
[32m[0907 13-17-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36434, current rewards: -1847.71478, mean: -1.59286
[32m[0907 13-17-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36240, current rewards: -1914.47932, mean: -1.58221
[32m[0907 13-17-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36337, current rewards: -2014.47932, mean: -1.59879
[32m[0907 13-18-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36143, current rewards: -2100.80244, mean: -1.60367
[32m[0907 13-18-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36104, current rewards: -2182.40532, mean: -1.60471
[32m[0907 13-18-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35959, current rewards: -2282.40532, mean: -1.61873
[32m[0907 13-18-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35759, current rewards: -2357.69350, mean: -1.61486
[32m[0907 13-19-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35895, current rewards: -2457.69350, mean: -1.62761
[32m[0907 13-19-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36388, current rewards: -2553.62988, mean: -1.63694
[32m[0907 13-19-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36581, current rewards: -2600.14311, mean: -1.61500
[32m[0907 13-20-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36372, current rewards: -2644.22612, mean: -1.59291
[32m[0907 13-20-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36168, current rewards: -2694.22612, mean: -1.57557
[32m[0907 13-20-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35985, current rewards: -2744.22612, mean: -1.55922
[32m[0907 13-20-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35818, current rewards: -2794.22612, mean: -1.54377
[32m[0907 13-21-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35648, current rewards: -2844.22612, mean: -1.52915
[32m[0907 13-21-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35488, current rewards: -2894.22612, mean: -1.51530
[32m[0907 13-21-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35336, current rewards: -2944.22612, mean: -1.50216
[32m[0907 13-21-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35191, current rewards: -2994.22612, mean: -1.48966
[32m[0907 13-22-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35057, current rewards: -3044.22612, mean: -1.47778
[32m[0907 13-22-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34951, current rewards: -3094.22612, mean: -1.46646
[32m[0907 13-22-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34836, current rewards: -3144.22612, mean: -1.45566
[32m[0907 13-22-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34732, current rewards: -3194.22612, mean: -1.44535
[32m[0907 13-23-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34627, current rewards: -3244.22612, mean: -1.43550
[32m[0907 13-23-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34536, current rewards: -3294.22612, mean: -1.42607
[32m[0907 13-23-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34453, current rewards: -3344.22612, mean: -1.41704
[32m[0907 13-23-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34357, current rewards: -3394.22612, mean: -1.40839
[32m[0907 13-24-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34287, current rewards: -3444.22612, mean: -1.40009
[32m[0907 13-24-24 @Agent.py:117][0m Average action selection time: 0.3422
[32m[0907 13-24-24 @Agent.py:118][0m Rollout length: 2600
[32m[0907 13-24-24 @MBExp.py:227][0m Rewards obtained: [-3484.2261199155896], Lows: [1223], Highs: [1063], Total time: 71904.43880100001
[32m[0907 13-25-26 @MBExp.py:144][0m ####################################################################
[32m[0907 13-25-26 @MBExp.py:145][0m Starting training iteration 95.
[32m[0907 13-25-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33665, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-25-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.46602, current rewards: -60.00000, mean: -1.00000
[32m[0907 13-26-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.46647, current rewards: -107.38696, mean: -0.97625
[32m[0907 13-26-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.44783, current rewards: -111.39392, mean: -0.69621
[32m[0907 13-26-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.43157, current rewards: -114.60573, mean: -0.54574
[32m[0907 13-27-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.43991, current rewards: -187.98950, mean: -0.72304
[32m[0907 13-27-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.42095, current rewards: -285.84656, mean: -0.92209
[32m[0907 13-27-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.40929, current rewards: -377.14775, mean: -1.04763
[32m[0907 13-28-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.39924, current rewards: -455.82767, mean: -1.11177
[32m[0907 13-28-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.40392, current rewards: -555.82767, mean: -1.20832
[32m[0907 13-28-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.41484, current rewards: -635.96062, mean: -1.24698
[32m[0907 13-29-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.40718, current rewards: -718.56152, mean: -1.28315
[32m[0907 13-29-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.40056, current rewards: -769.56152, mean: -1.26158
[32m[0907 13-29-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.39813, current rewards: -869.56152, mean: -1.31752
[32m[0907 13-30-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.39255, current rewards: -969.56152, mean: -1.36558
[32m[0907 13-30-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.38918, current rewards: -1069.56152, mean: -1.40732
[32m[0907 13-30-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.38379, current rewards: -1169.56152, mean: -1.44390
[32m[0907 13-30-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37927, current rewards: -1269.56152, mean: -1.47623
[32m[0907 13-31-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37555, current rewards: -1369.56152, mean: -1.50501
[32m[0907 13-31-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37229, current rewards: -1469.56152, mean: -1.53079
[32m[0907 13-31-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36861, current rewards: -1569.56152, mean: -1.55402
[32m[0907 13-31-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36514, current rewards: -1669.56152, mean: -1.57506
[32m[0907 13-32-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36235, current rewards: -1769.56152, mean: -1.59420
[32m[0907 13-32-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35948, current rewards: -1869.56152, mean: -1.61169
[32m[0907 13-32-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35677, current rewards: -1969.56152, mean: -1.62774
[32m[0907 13-32-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35437, current rewards: -2069.56152, mean: -1.64251
[32m[0907 13-33-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35253, current rewards: -2169.56152, mean: -1.65615
[32m[0907 13-33-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35083, current rewards: -2269.56152, mean: -1.66880
[32m[0907 13-33-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34963, current rewards: -2369.56152, mean: -1.68054
[32m[0907 13-33-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34822, current rewards: -2469.56152, mean: -1.69148
[32m[0907 13-34-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34728, current rewards: -2569.56152, mean: -1.70170
[32m[0907 13-34-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34639, current rewards: -2669.56152, mean: -1.71126
[32m[0907 13-34-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34563, current rewards: -2769.56152, mean: -1.72022
[32m[0907 13-34-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34460, current rewards: -2869.56152, mean: -1.72865
[32m[0907 13-35-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34360, current rewards: -2969.56152, mean: -1.73659
[32m[0907 13-35-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34270, current rewards: -3069.56152, mean: -1.74407
[32m[0907 13-35-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34186, current rewards: -3169.56152, mean: -1.75114
[32m[0907 13-36-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34110, current rewards: -3269.56152, mean: -1.75783
[32m[0907 13-36-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34037, current rewards: -3369.56152, mean: -1.76417
[32m[0907 13-36-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33968, current rewards: -3469.56152, mean: -1.77018
[32m[0907 13-36-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33894, current rewards: -3569.56152, mean: -1.77590
[32m[0907 13-37-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33829, current rewards: -3669.56152, mean: -1.78134
[32m[0907 13-37-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33768, current rewards: -3769.56152, mean: -1.78652
[32m[0907 13-37-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33700, current rewards: -3869.56152, mean: -1.79146
[32m[0907 13-37-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33645, current rewards: -3969.56152, mean: -1.79618
[32m[0907 13-38-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33590, current rewards: -4069.56152, mean: -1.80069
[32m[0907 13-38-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33523, current rewards: -4169.56152, mean: -1.80500
[32m[0907 13-38-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33459, current rewards: -4269.56152, mean: -1.80914
[32m[0907 13-38-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33397, current rewards: -4369.56152, mean: -1.81310
[32m[0907 13-39-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33339, current rewards: -4469.56152, mean: -1.81689
[32m[0907 13-39-19 @Agent.py:117][0m Average action selection time: 0.3329
[32m[0907 13-39-19 @Agent.py:118][0m Rollout length: 2600
[32m[0907 13-39-19 @MBExp.py:227][0m Rewards obtained: [-4549.561523492328], Lows: [2189], Highs: [183], Total time: 72737.227624
[32m[0907 13-40-18 @MBExp.py:144][0m ####################################################################
[32m[0907 13-40-18 @MBExp.py:145][0m Starting training iteration 96.
[32m[0907 13-40-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.50276, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-40-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.50327, current rewards: -60.00000, mean: -1.00000
[32m[0907 13-41-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.44628, current rewards: -110.00000, mean: -1.00000
[32m[0907 13-41-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.45250, current rewards: -160.00000, mean: -1.00000
[32m[0907 13-41-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.41727, current rewards: -210.00000, mean: -1.00000
[32m[0907 13-42-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.39807, current rewards: -260.00000, mean: -1.00000
[32m[0907 13-42-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.38254, current rewards: -310.00000, mean: -1.00000
[32m[0907 13-42-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37056, current rewards: -388.00000, mean: -1.07778
[32m[0907 13-42-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36216, current rewards: -488.00000, mean: -1.19024
[32m[0907 13-43-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35564, current rewards: -588.00000, mean: -1.27826
[32m[0907 13-43-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35036, current rewards: -688.00000, mean: -1.34902
[32m[0907 13-43-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34594, current rewards: -788.00000, mean: -1.40714
[32m[0907 13-43-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34215, current rewards: -888.00000, mean: -1.45574
[32m[0907 13-44-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33928, current rewards: -988.00000, mean: -1.49697
[32m[0907 13-44-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33694, current rewards: -1088.00000, mean: -1.53239
[32m[0907 13-44-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33473, current rewards: -1188.00000, mean: -1.56316
[32m[0907 13-44-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33268, current rewards: -1288.00000, mean: -1.59012
[32m[0907 13-45-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33094, current rewards: -1388.00000, mean: -1.61395
[32m[0907 13-45-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32912, current rewards: -1488.00000, mean: -1.63516
[32m[0907 13-45-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32798, current rewards: -1588.00000, mean: -1.65417
[32m[0907 13-45-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32690, current rewards: -1688.00000, mean: -1.67129
[32m[0907 13-46-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32579, current rewards: -1788.00000, mean: -1.68679
[32m[0907 13-46-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32531, current rewards: -1888.00000, mean: -1.70090
[32m[0907 13-46-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32485, current rewards: -1988.00000, mean: -1.71379
[32m[0907 13-46-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32408, current rewards: -2088.00000, mean: -1.72562
[32m[0907 13-47-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32301, current rewards: -2188.00000, mean: -1.73651
[32m[0907 13-47-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32211, current rewards: -2250.62867, mean: -1.71804
[32m[0907 13-47-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32522, current rewards: -2338.52379, mean: -1.71950
[32m[0907 13-47-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32433, current rewards: -2438.52379, mean: -1.72945
[32m[0907 13-48-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32351, current rewards: -2538.52379, mean: -1.73871
[32m[0907 13-48-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32283, current rewards: -2638.52379, mean: -1.74737
[32m[0907 13-48-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32223, current rewards: -2738.52379, mean: -1.75546
[32m[0907 13-48-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32170, current rewards: -2838.52379, mean: -1.76306
[32m[0907 13-49-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32087, current rewards: -2938.52379, mean: -1.77020
[32m[0907 13-49-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32007, current rewards: -3038.52379, mean: -1.77691
[32m[0907 13-49-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31933, current rewards: -3138.52379, mean: -1.78325
[32m[0907 13-49-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31864, current rewards: -3238.52379, mean: -1.78924
[32m[0907 13-50-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31805, current rewards: -3338.52379, mean: -1.79491
[32m[0907 13-50-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31749, current rewards: -3438.52379, mean: -1.80027
[32m[0907 13-50-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31705, current rewards: -3538.52379, mean: -1.80537
[32m[0907 13-50-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31664, current rewards: -3638.52379, mean: -1.81021
[32m[0907 13-51-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31612, current rewards: -3738.52379, mean: -1.81482
[32m[0907 13-51-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31565, current rewards: -3838.52379, mean: -1.81921
[32m[0907 13-51-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31514, current rewards: -3938.52379, mean: -1.82339
[32m[0907 13-51-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31464, current rewards: -4038.52379, mean: -1.82739
[32m[0907 13-52-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31414, current rewards: -4138.52379, mean: -1.83121
[32m[0907 13-52-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31364, current rewards: -4238.52379, mean: -1.83486
[32m[0907 13-52-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31327, current rewards: -4338.52379, mean: -1.83836
[32m[0907 13-52-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31292, current rewards: -4438.52379, mean: -1.84171
[32m[0907 13-53-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31255, current rewards: -4538.52379, mean: -1.84493
[32m[0907 13-53-19 @Agent.py:117][0m Average action selection time: 0.3123
[32m[0907 13-53-19 @Agent.py:118][0m Rollout length: 2600
[32m[0907 13-53-19 @MBExp.py:227][0m Rewards obtained: [-4618.52378974111], Lows: [2121], Highs: [377], Total time: 73518.37428
[32m[0907 13-54-21 @MBExp.py:144][0m ####################################################################
[32m[0907 13-54-21 @MBExp.py:145][0m Starting training iteration 97.
[32m[0907 13-54-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49085, current rewards: -10.00000, mean: -1.00000
[32m[0907 13-54-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.49867, current rewards: -60.00000, mean: -1.00000
[32m[0907 13-55-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.49959, current rewards: -117.46712, mean: -1.06788
[32m[0907 13-55-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.46806, current rewards: -110.02020, mean: -0.68763
[32m[0907 13-55-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.42783, current rewards: -156.66207, mean: -0.74601
[32m[0907 13-56-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.40434, current rewards: -206.66207, mean: -0.79485
[32m[0907 13-56-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.38680, current rewards: -256.66207, mean: -0.82794
[32m[0907 13-56-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37404, current rewards: -324.78441, mean: -0.90218
[32m[0907 13-56-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36704, current rewards: -424.78441, mean: -1.03606
[32m[0907 13-57-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36069, current rewards: -496.77409, mean: -1.07994
[32m[0907 13-57-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35446, current rewards: -572.35041, mean: -1.12226
[32m[0907 13-57-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34909, current rewards: -622.35041, mean: -1.11134
[32m[0907 13-57-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34534, current rewards: -681.21684, mean: -1.11675
[32m[0907 13-58-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.34182, current rewards: -781.21684, mean: -1.18366
[32m[0907 13-58-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33898, current rewards: -881.21684, mean: -1.24115
[32m[0907 13-58-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33623, current rewards: -981.21684, mean: -1.29107
[32m[0907 13-58-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33409, current rewards: -1081.21684, mean: -1.33484
[32m[0907 13-59-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33196, current rewards: -1181.21684, mean: -1.37351
[32m[0907 13-59-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.33047, current rewards: -1281.21684, mean: -1.40793
[32m[0907 13-59-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32905, current rewards: -1381.21684, mean: -1.43877
[32m[0907 13-59-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32748, current rewards: -1481.21684, mean: -1.46655
[32m[0907 14-00-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32608, current rewards: -1581.21684, mean: -1.49171
[32m[0907 14-00-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32483, current rewards: -1681.21684, mean: -1.51461
[32m[0907 14-00-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32376, current rewards: -1781.21684, mean: -1.53553
[32m[0907 14-00-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32288, current rewards: -1881.21684, mean: -1.55472
[32m[0907 14-01-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32178, current rewards: -1981.21684, mean: -1.57239
[32m[0907 14-01-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32073, current rewards: -2081.21684, mean: -1.58872
[32m[0907 14-01-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31975, current rewards: -2181.21684, mean: -1.60384
[32m[0907 14-01-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31884, current rewards: -2281.21684, mean: -1.61788
[32m[0907 14-02-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31800, current rewards: -2381.21684, mean: -1.63097
[32m[0907 14-02-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31720, current rewards: -2481.21684, mean: -1.64319
[32m[0907 14-02-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31646, current rewards: -2581.21684, mean: -1.65463
[32m[0907 14-02-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31576, current rewards: -2681.21684, mean: -1.66535
[32m[0907 14-03-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31511, current rewards: -2781.21684, mean: -1.67543
[32m[0907 14-03-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31448, current rewards: -2881.21684, mean: -1.68492
[32m[0907 14-03-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31390, current rewards: -2981.21684, mean: -1.69387
[32m[0907 14-03-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31335, current rewards: -3081.21684, mean: -1.70233
[32m[0907 14-04-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31283, current rewards: -3181.21684, mean: -1.71033
[32m[0907 14-04-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31234, current rewards: -3281.21684, mean: -1.71791
[32m[0907 14-04-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31186, current rewards: -3381.21684, mean: -1.72511
[32m[0907 14-04-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31142, current rewards: -3481.21684, mean: -1.73195
[32m[0907 14-05-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31100, current rewards: -3581.21684, mean: -1.73845
[32m[0907 14-05-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31068, current rewards: -3681.21684, mean: -1.74465
[32m[0907 14-05-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31057, current rewards: -3781.21684, mean: -1.75056
[32m[0907 14-05-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31040, current rewards: -3881.21684, mean: -1.75621
[32m[0907 14-06-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30990, current rewards: -3981.21684, mean: -1.76160
[32m[0907 14-06-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30942, current rewards: -4081.21684, mean: -1.76676
[32m[0907 14-06-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30897, current rewards: -4181.21684, mean: -1.77170
[32m[0907 14-06-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30853, current rewards: -4281.21684, mean: -1.77644
[32m[0907 14-06-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30811, current rewards: -4381.21684, mean: -1.78098
[32m[0907 14-07-11 @Agent.py:117][0m Average action selection time: 0.3078
[32m[0907 14-07-11 @Agent.py:118][0m Rollout length: 2600
[32m[0907 14-07-11 @MBExp.py:227][0m Rewards obtained: [-4461.216838979835], Lows: [2081], Highs: [318], Total time: 74288.28336500001
[32m[0907 14-08-12 @MBExp.py:144][0m ####################################################################
[32m[0907 14-08-12 @MBExp.py:145][0m Starting training iteration 98.
[32m[0907 14-08-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.51879, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-08-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.52878, current rewards: -60.00000, mean: -1.00000
[32m[0907 14-09-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.50983, current rewards: -110.00000, mean: -1.00000
[32m[0907 14-09-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.44971, current rewards: -129.11850, mean: -0.80699
[32m[0907 14-09-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.41983, current rewards: -172.39297, mean: -0.82092
[32m[0907 14-09-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.41195, current rewards: -272.39297, mean: -1.04767
[32m[0907 14-10-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.39682, current rewards: -360.18293, mean: -1.16188
[32m[0907 14-10-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.38607, current rewards: -410.18293, mean: -1.13940
[32m[0907 14-10-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.38405, current rewards: -460.18293, mean: -1.12240
[32m[0907 14-11-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.37678, current rewards: -510.18293, mean: -1.10909
[32m[0907 14-11-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37130, current rewards: -538.15446, mean: -1.05520
[32m[0907 14-11-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.36973, current rewards: -588.15446, mean: -1.05028
[32m[0907 14-11-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36757, current rewards: -642.15446, mean: -1.05271
[32m[0907 14-12-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36372, current rewards: -688.38293, mean: -1.04300
[32m[0907 14-12-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.36380, current rewards: -754.07158, mean: -1.06207
[32m[0907 14-12-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36132, current rewards: -804.07158, mean: -1.05799
[32m[0907 14-13-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35861, current rewards: -843.38855, mean: -1.04122
[32m[0907 14-13-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35630, current rewards: -884.05675, mean: -1.02797
[32m[0907 14-13-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35725, current rewards: -934.05675, mean: -1.02644
[32m[0907 14-14-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36585, current rewards: -963.63322, mean: -1.00378
[32m[0907 14-14-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36874, current rewards: -1007.09059, mean: -0.99712
[32m[0907 14-14-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36649, current rewards: -1057.09059, mean: -0.99726
[32m[0907 14-14-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36429, current rewards: -1112.00114, mean: -1.00180
[32m[0907 14-15-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36248, current rewards: -1166.29294, mean: -1.00542
[32m[0907 14-15-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36532, current rewards: -1190.81440, mean: -0.98414
[32m[0907 14-15-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36761, current rewards: -1249.63783, mean: -0.99178
[32m[0907 14-16-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36527, current rewards: -1349.63783, mean: -1.03026
[32m[0907 14-16-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36300, current rewards: -1449.63783, mean: -1.06591
[32m[0907 14-16-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36090, current rewards: -1503.88626, mean: -1.06659
[32m[0907 14-16-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35899, current rewards: -1501.43490, mean: -1.02838
[32m[0907 14-17-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35717, current rewards: -1499.04717, mean: -0.99275
[32m[0907 14-17-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35549, current rewards: -1496.65951, mean: -0.95940
[32m[0907 14-17-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35434, current rewards: -1494.27186, mean: -0.92812
[32m[0907 14-17-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35328, current rewards: -1490.90182, mean: -0.89813
[32m[0907 14-18-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35227, current rewards: -1487.28100, mean: -0.86975
[32m[0907 14-18-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35126, current rewards: -1483.80167, mean: -0.84307
[32m[0907 14-18-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35032, current rewards: -1480.32234, mean: -0.81786
[32m[0907 14-19-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34949, current rewards: -1486.46928, mean: -0.79918
[32m[0907 14-19-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34867, current rewards: -1536.46928, mean: -0.80443
[32m[0907 14-19-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34787, current rewards: -1586.46928, mean: -0.80942
[32m[0907 14-19-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34711, current rewards: -1636.46928, mean: -0.81416
[32m[0907 14-20-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34641, current rewards: -1686.46928, mean: -0.81867
[32m[0907 14-20-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34572, current rewards: -1736.46928, mean: -0.82297
[32m[0907 14-20-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34505, current rewards: -1786.46928, mean: -0.82707
[32m[0907 14-20-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34443, current rewards: -1836.46928, mean: -0.83098
[32m[0907 14-21-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34386, current rewards: -1886.46928, mean: -0.83472
[32m[0907 14-21-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34331, current rewards: -1936.46928, mean: -0.83830
[32m[0907 14-21-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34286, current rewards: -1986.46928, mean: -0.84172
[32m[0907 14-21-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34260, current rewards: -2036.46928, mean: -0.84501
[32m[0907 14-22-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34212, current rewards: -2086.46928, mean: -0.84816
[32m[0907 14-22-27 @Agent.py:117][0m Average action selection time: 0.3417
[32m[0907 14-22-27 @Agent.py:118][0m Rollout length: 2600
[32m[0907 14-22-27 @MBExp.py:227][0m Rewards obtained: [-2126.4692819239826], Lows: [353], Highs: [1479], Total time: 75143.11507700001
[32m[0907 14-23-31 @MBExp.py:144][0m ####################################################################
[32m[0907 14-23-31 @MBExp.py:145][0m Starting training iteration 99.
[32m[0907 14-23-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33304, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-23-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31978, current rewards: -60.00000, mean: -1.00000
[32m[0907 14-24-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.36823, current rewards: -108.94296, mean: -0.99039
[32m[0907 14-24-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.35961, current rewards: -158.94296, mean: -0.99339
[32m[0907 14-24-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.35473, current rewards: -242.87673, mean: -1.15656
[32m[0907 14-25-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34886, current rewards: -321.11211, mean: -1.23505
[32m[0907 14-25-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36852, current rewards: -372.52589, mean: -1.20170
[32m[0907 14-25-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.37373, current rewards: -368.34251, mean: -1.02317
[32m[0907 14-26-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36702, current rewards: -446.61904, mean: -1.08931
[32m[0907 14-26-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.36205, current rewards: -546.61904, mean: -1.18830
[32m[0907 14-26-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35985, current rewards: -557.79924, mean: -1.09372
[32m[0907 14-26-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.35604, current rewards: -607.79924, mean: -1.08536
[32m[0907 14-27-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.35296, current rewards: -661.30620, mean: -1.08411
[32m[0907 14-27-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.35506, current rewards: -761.30620, mean: -1.15349
[32m[0907 14-27-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35265, current rewards: -861.30620, mean: -1.21311
[32m[0907 14-27-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.34975, current rewards: -899.90022, mean: -1.18408
[32m[0907 14-28-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.34840, current rewards: -993.34352, mean: -1.22635
[32m[0907 14-28-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34646, current rewards: -1093.34352, mean: -1.27133
[32m[0907 14-28-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34477, current rewards: -1155.34352, mean: -1.26961
[32m[0907 14-29-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34325, current rewards: -1208.08357, mean: -1.25842
[32m[0907 14-29-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34427, current rewards: -1308.08357, mean: -1.29513
[32m[0907 14-29-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34566, current rewards: -1408.08357, mean: -1.32838
[32m[0907 14-29-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34425, current rewards: -1487.64133, mean: -1.34022
[32m[0907 14-30-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34283, current rewards: -1525.38158, mean: -1.31498
[32m[0907 14-30-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34819, current rewards: -1575.38158, mean: -1.30197
[32m[0907 14-30-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35294, current rewards: -1623.80712, mean: -1.28874
[32m[0907 14-31-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35310, current rewards: -1703.51986, mean: -1.30040
[32m[0907 14-31-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35148, current rewards: -1780.86306, mean: -1.30946
[32m[0907 14-31-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35009, current rewards: -1826.82910, mean: -1.29562
[32m[0907 14-32-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34931, current rewards: -1876.82910, mean: -1.28550
[32m[0907 14-32-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34872, current rewards: -1926.82910, mean: -1.27605
[32m[0907 14-32-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34993, current rewards: -1973.58835, mean: -1.26512
[32m[0907 14-32-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34995, current rewards: -2025.65056, mean: -1.25817
[32m[0907 14-33-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34993, current rewards: -2086.18064, mean: -1.25674
[32m[0907 14-33-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35146, current rewards: -2186.18064, mean: -1.27847
[32m[0907 14-33-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35077, current rewards: -2248.00385, mean: -1.27727
[32m[0907 14-34-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35208, current rewards: -2293.94522, mean: -1.26737
[32m[0907 14-34-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35219, current rewards: -2393.94522, mean: -1.28707
[32m[0907 14-34-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35133, current rewards: -2447.93145, mean: -1.28164
[32m[0907 14-34-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35028, current rewards: -2494.71878, mean: -1.27282
[32m[0907 14-35-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34938, current rewards: -2588.24826, mean: -1.28769
[32m[0907 14-35-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34849, current rewards: -2684.16141, mean: -1.30299
[32m[0907 14-35-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34763, current rewards: -2734.16141, mean: -1.29581
[32m[0907 14-36-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34677, current rewards: -2784.16141, mean: -1.28896
[32m[0907 14-36-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34843, current rewards: -2877.60467, mean: -1.30208
[32m[0907 14-36-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34770, current rewards: -2977.60467, mean: -1.31752
[32m[0907 14-36-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34687, current rewards: -3032.42475, mean: -1.31274
[32m[0907 14-37-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34627, current rewards: -3082.42475, mean: -1.30611
[32m[0907 14-37-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34605, current rewards: -3132.42475, mean: -1.29976
[32m[0907 14-37-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34712, current rewards: -3184.35973, mean: -1.29446
[32m[0907 14-38-05 @Agent.py:117][0m Average action selection time: 0.3491
[32m[0907 14-38-05 @Agent.py:118][0m Rollout length: 2600
[32m[0907 14-38-05 @MBExp.py:227][0m Rewards obtained: [-3236.120525971944], Lows: [1170], Highs: [951], Total time: 76016.41306500002
[32m[0907 14-39-10 @MBExp.py:144][0m ####################################################################
[32m[0907 14-39-10 @MBExp.py:145][0m Starting training iteration 100.
[32m[0907 14-39-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.51400, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-39-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.51225, current rewards: -60.00000, mean: -1.00000
[32m[0907 14-40-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.51763, current rewards: -98.93535, mean: -0.89941
[32m[0907 14-40-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.51482, current rewards: -112.83979, mean: -0.70525
[32m[0907 14-40-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.51364, current rewards: -139.36940, mean: -0.66366
[32m[0907 14-41-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.49367, current rewards: -171.13614, mean: -0.65822
[32m[0907 14-41-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.47276, current rewards: -247.86839, mean: -0.79958
[32m[0907 14-42-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.47940, current rewards: -347.86839, mean: -0.96630
[32m[0907 14-42-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.48443, current rewards: -447.86839, mean: -1.09236
[32m[0907 14-42-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.48844, current rewards: -480.65565, mean: -1.04490
[32m[0907 14-43-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.49219, current rewards: -580.65565, mean: -1.13854
[32m[0907 14-43-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.49497, current rewards: -680.65565, mean: -1.21546
[32m[0907 14-44-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.49796, current rewards: -777.91011, mean: -1.27526
[32m[0907 14-44-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.50051, current rewards: -874.91891, mean: -1.32563
[32m[0907 14-45-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.50073, current rewards: -914.45791, mean: -1.28797
[32m[0907 14-45-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.49762, current rewards: -958.89074, mean: -1.26170
[32m[0907 14-45-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.48643, current rewards: -1008.89074, mean: -1.24554
[32m[0907 14-45-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.47609, current rewards: -1058.89074, mean: -1.23127
[32m[0907 14-46-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.46698, current rewards: -1108.89074, mean: -1.21856
[32m[0907 14-46-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.45910, current rewards: -1158.89074, mean: -1.20718
[32m[0907 14-46-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.45228, current rewards: -1208.89074, mean: -1.19692
[32m[0907 14-47-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.44615, current rewards: -1258.89074, mean: -1.18763
[32m[0907 14-47-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.44040, current rewards: -1308.89074, mean: -1.17918
[32m[0907 14-47-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.43506, current rewards: -1358.89074, mean: -1.17146
[32m[0907 14-47-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.43031, current rewards: -1408.89074, mean: -1.16437
[32m[0907 14-48-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.42607, current rewards: -1458.89074, mean: -1.15785
[32m[0907 14-48-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.42213, current rewards: -1508.89074, mean: -1.15182
[32m[0907 14-48-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.41850, current rewards: -1558.89074, mean: -1.14624
[32m[0907 14-48-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.41502, current rewards: -1608.89074, mean: -1.14106
[32m[0907 14-49-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.41185, current rewards: -1658.89074, mean: -1.13623
[32m[0907 14-49-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.40889, current rewards: -1708.89074, mean: -1.13172
[32m[0907 14-49-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.40616, current rewards: -1758.89074, mean: -1.12749
[32m[0907 14-50-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.40363, current rewards: -1808.89074, mean: -1.12353
[32m[0907 14-50-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.40115, current rewards: -1858.89074, mean: -1.11981
[32m[0907 14-50-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.39900, current rewards: -1908.89074, mean: -1.11631
[32m[0907 14-50-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.39705, current rewards: -1958.89074, mean: -1.11301
[32m[0907 14-51-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.39523, current rewards: -2008.89074, mean: -1.10988
[32m[0907 14-51-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.39343, current rewards: -2058.89074, mean: -1.10693
[32m[0907 14-51-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.39188, current rewards: -2099.37768, mean: -1.09915
[32m[0907 14-51-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.39016, current rewards: -2096.52740, mean: -1.06966
[32m[0907 14-52-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.38850, current rewards: -2135.98614, mean: -1.06268
[32m[0907 14-52-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.38691, current rewards: -2185.98614, mean: -1.06116
[32m[0907 14-52-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.38541, current rewards: -2235.98614, mean: -1.05971
[32m[0907 14-52-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.38402, current rewards: -2285.98614, mean: -1.05833
[32m[0907 14-53-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.38273, current rewards: -2335.98614, mean: -1.05701
[32m[0907 14-53-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.38150, current rewards: -2385.98614, mean: -1.05575
[32m[0907 14-53-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.38034, current rewards: -2435.98614, mean: -1.05454
[32m[0907 14-54-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.37919, current rewards: -2485.98614, mean: -1.05338
[32m[0907 14-54-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.37806, current rewards: -2508.88418, mean: -1.04103
[32m[0907 14-54-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.37695, current rewards: -2500.58406, mean: -1.01650
[32m[0907 14-54-50 @Agent.py:117][0m Average action selection time: 0.3761
[32m[0907 14-54-50 @Agent.py:118][0m Rollout length: 2600
[32m[0907 14-54-50 @MBExp.py:227][0m Rewards obtained: [-2493.9439660029643], Lows: [375], Highs: [1782], Total time: 76957.23176600001
[32m[0907 14-55-58 @MBExp.py:144][0m ####################################################################
[32m[0907 14-55-58 @MBExp.py:145][0m Starting training iteration 101.
[32m[0907 14-56-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.50384, current rewards: -10.00000, mean: -1.00000
[32m[0907 14-56-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.54197, current rewards: -60.00000, mean: -1.00000
[32m[0907 14-56-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.51122, current rewards: -108.93760, mean: -0.99034
[32m[0907 14-57-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.45521, current rewards: -138.32848, mean: -0.86455
[32m[0907 14-57-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.44751, current rewards: -175.93687, mean: -0.83779
[32m[0907 14-57-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.45676, current rewards: -275.93687, mean: -1.06130
[32m[0907 14-58-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.45261, current rewards: -371.66880, mean: -1.19893
[32m[0907 14-58-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.44353, current rewards: -431.37551, mean: -1.19827
[32m[0907 14-58-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.42962, current rewards: -480.31369, mean: -1.17150
[32m[0907 14-59-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.41845, current rewards: -530.31369, mean: -1.15286
[32m[0907 14-59-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.40971, current rewards: -580.31369, mean: -1.13787
[32m[0907 14-59-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.40302, current rewards: -630.31369, mean: -1.12556
[32m[0907 15-00-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.39695, current rewards: -680.31369, mean: -1.11527
[32m[0907 15-00-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.39162, current rewards: -730.31369, mean: -1.10654
[32m[0907 15-00-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.38708, current rewards: -780.31369, mean: -1.09903
[32m[0907 15-00-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.38311, current rewards: -830.31369, mean: -1.09252
[32m[0907 15-01-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.38001, current rewards: -880.31369, mean: -1.08681
[32m[0907 15-01-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37723, current rewards: -930.31369, mean: -1.08176
[32m[0907 15-01-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37476, current rewards: -980.31369, mean: -1.07727
[32m[0907 15-01-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37237, current rewards: -1030.31369, mean: -1.07324
[32m[0907 15-02-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37000, current rewards: -1080.31369, mean: -1.06962
[32m[0907 15-02-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36794, current rewards: -1130.31369, mean: -1.06633
[32m[0907 15-02-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36603, current rewards: -1180.31369, mean: -1.06335
[32m[0907 15-03-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36436, current rewards: -1230.31369, mean: -1.06062
[32m[0907 15-03-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36290, current rewards: -1280.31369, mean: -1.05811
[32m[0907 15-03-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36139, current rewards: -1330.31369, mean: -1.05580
[32m[0907 15-03-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36011, current rewards: -1380.31369, mean: -1.05367
[32m[0907 15-04-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35895, current rewards: -1430.31369, mean: -1.05170
[32m[0907 15-04-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35782, current rewards: -1480.31369, mean: -1.04987
[32m[0907 15-04-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35676, current rewards: -1530.31369, mean: -1.04816
[32m[0907 15-04-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.35579, current rewards: -1580.31369, mean: -1.04657
[32m[0907 15-05-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.35494, current rewards: -1606.58350, mean: -1.02986
[32m[0907 15-05-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.35400, current rewards: -1600.12467, mean: -0.99387
[32m[0907 15-05-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35317, current rewards: -1593.66585, mean: -0.96004
[32m[0907 15-06-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35245, current rewards: -1587.20703, mean: -0.92819
[32m[0907 15-06-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35160, current rewards: -1580.74820, mean: -0.89815
[32m[0907 15-06-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35088, current rewards: -1574.28938, mean: -0.86977
[32m[0907 15-06-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35025, current rewards: -1620.90185, mean: -0.87145
[32m[0907 15-07-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34954, current rewards: -1670.90185, mean: -0.87482
[32m[0907 15-07-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34895, current rewards: -1720.90185, mean: -0.87801
[32m[0907 15-07-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34848, current rewards: -1770.90185, mean: -0.88105
[32m[0907 15-07-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34802, current rewards: -1820.90185, mean: -0.88393
[32m[0907 15-08-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34747, current rewards: -1870.90185, mean: -0.88668
[32m[0907 15-08-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34695, current rewards: -1920.90185, mean: -0.88931
[32m[0907 15-08-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34598, current rewards: -1970.90185, mean: -0.89181
[32m[0907 15-08-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34506, current rewards: -2020.90185, mean: -0.89420
[32m[0907 15-09-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34412, current rewards: -2070.90185, mean: -0.89649
[32m[0907 15-09-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34350, current rewards: -2120.90185, mean: -0.89869
[32m[0907 15-09-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34258, current rewards: -2170.90185, mean: -0.90079
[32m[0907 15-09-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34178, current rewards: -2220.90185, mean: -0.90281
[32m[0907 15-10-11 @Agent.py:117][0m Average action selection time: 0.3411
[32m[0907 15-10-11 @Agent.py:118][0m Rollout length: 2600
[32m[0907 15-10-11 @MBExp.py:227][0m Rewards obtained: [-2260.9018490234494], Lows: [129], Highs: [2045], Total time: 77810.47249900001
[32m[0907 15-11-17 @MBExp.py:144][0m ####################################################################
[32m[0907 15-11-17 @MBExp.py:145][0m Starting training iteration 102.
[32m[0907 15-11-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49779, current rewards: -10.00000, mean: -1.00000
[32m[0907 15-11-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.49501, current rewards: -60.00000, mean: -1.00000
[32m[0907 15-12-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.49841, current rewards: -110.00000, mean: -1.00000
[32m[0907 15-12-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.49920, current rewards: -160.00000, mean: -1.00000
[32m[0907 15-13-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.50054, current rewards: -210.00000, mean: -1.00000
[32m[0907 15-13-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.50321, current rewards: -260.00000, mean: -1.00000
[32m[0907 15-13-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.50363, current rewards: -307.89988, mean: -0.99323
[32m[0907 15-14-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.50261, current rewards: -353.61492, mean: -0.98226
[32m[0907 15-14-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.49916, current rewards: -403.61492, mean: -0.98443
[32m[0907 15-15-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.49899, current rewards: -453.61492, mean: -0.98612
[32m[0907 15-15-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.49906, current rewards: -503.61492, mean: -0.98748
[32m[0907 15-15-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.49904, current rewards: -553.61492, mean: -0.98860
[32m[0907 15-16-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.48378, current rewards: -603.61492, mean: -0.98953
[32m[0907 15-16-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.46967, current rewards: -653.61492, mean: -0.99033
[32m[0907 15-16-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.45754, current rewards: -703.61492, mean: -0.99101
[32m[0907 15-16-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.44753, current rewards: -753.61492, mean: -0.99160
[32m[0907 15-17-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.43860, current rewards: -803.61492, mean: -0.99212
[32m[0907 15-17-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.43057, current rewards: -853.61492, mean: -0.99258
[32m[0907 15-17-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.42499, current rewards: -903.61492, mean: -0.99298
[32m[0907 15-18-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.41916, current rewards: -953.61492, mean: -0.99335
[32m[0907 15-18-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.41394, current rewards: -1003.61492, mean: -0.99368
[32m[0907 15-18-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.40920, current rewards: -1053.61492, mean: -0.99398
[32m[0907 15-18-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.40551, current rewards: -1103.61492, mean: -0.99425
[32m[0907 15-19-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.40195, current rewards: -1153.61492, mean: -0.99450
[32m[0907 15-19-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.39864, current rewards: -1203.61492, mean: -0.99472
[32m[0907 15-19-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.39538, current rewards: -1253.61492, mean: -0.99493
[32m[0907 15-19-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.39233, current rewards: -1303.61492, mean: -0.99513
[32m[0907 15-20-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.38947, current rewards: -1353.61492, mean: -0.99531
[32m[0907 15-20-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.38695, current rewards: -1403.61492, mean: -0.99547
[32m[0907 15-20-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.38460, current rewards: -1453.61492, mean: -0.99563
[32m[0907 15-20-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.38224, current rewards: -1503.61492, mean: -0.99577
[32m[0907 15-21-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.38105, current rewards: -1553.61492, mean: -0.99591
[32m[0907 15-21-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.37897, current rewards: -1603.61492, mean: -0.99603
[32m[0907 15-21-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.37702, current rewards: -1689.48602, mean: -1.01776
[32m[0907 15-21-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.37514, current rewards: -1789.48602, mean: -1.04648
[32m[0907 15-22-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.37335, current rewards: -1879.38062, mean: -1.06783
[32m[0907 15-22-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.37332, current rewards: -1979.38062, mean: -1.09358
[32m[0907 15-22-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.37739, current rewards: -2079.38062, mean: -1.11795
[32m[0907 15-23-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.38136, current rewards: -2138.33805, mean: -1.11955
[32m[0907 15-23-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.38506, current rewards: -2135.23046, mean: -1.08940
[32m[0907 15-24-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.38592, current rewards: -2235.23046, mean: -1.11205
[32m[0907 15-24-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.38448, current rewards: -2335.23046, mean: -1.13361
[32m[0907 15-24-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.38285, current rewards: -2435.23046, mean: -1.15414
[32m[0907 15-25-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.38264, current rewards: -2533.07010, mean: -1.17272
[32m[0907 15-25-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.38623, current rewards: -2633.07010, mean: -1.19143
[32m[0907 15-25-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.38969, current rewards: -2718.45402, mean: -1.20286
[32m[0907 15-26-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.39046, current rewards: -2818.45402, mean: -1.22011
[32m[0907 15-26-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.38926, current rewards: -2868.47517, mean: -1.21546
[32m[0907 15-26-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.38867, current rewards: -2895.69373, mean: -1.20153
[32m[0907 15-27-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.39114, current rewards: -2945.69373, mean: -1.19744
[32m[0907 15-27-41 @Agent.py:117][0m Average action selection time: 0.3932
[32m[0907 15-27-41 @Agent.py:118][0m Rollout length: 2600
[32m[0907 15-27-41 @MBExp.py:227][0m Rewards obtained: [-2985.6937313988333], Lows: [622], Highs: [1756], Total time: 78793.983917
[32m[0907 15-28-51 @MBExp.py:144][0m ####################################################################
[32m[0907 15-28-51 @MBExp.py:145][0m Starting training iteration 103.
[32m[0907 15-28-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.33775, current rewards: -10.00000, mean: -1.00000
[32m[0907 15-29-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.31202, current rewards: -60.00000, mean: -1.00000
[32m[0907 15-29-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30848, current rewards: -119.00000, mean: -1.08182
[32m[0907 15-29-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30808, current rewards: -219.00000, mean: -1.36875
[32m[0907 15-29-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30711, current rewards: -316.70036, mean: -1.50810
[32m[0907 15-30-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30690, current rewards: -416.70036, mean: -1.60269
[32m[0907 15-30-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30703, current rewards: -516.70036, mean: -1.66678
[32m[0907 15-30-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30658, current rewards: -609.80667, mean: -1.69391
[32m[0907 15-31-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32033, current rewards: -709.80667, mean: -1.73124
[32m[0907 15-31-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33008, current rewards: -792.64789, mean: -1.72315
[32m[0907 15-31-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32734, current rewards: -892.64789, mean: -1.75029
[32m[0907 15-31-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32508, current rewards: -929.25855, mean: -1.65939
[32m[0907 15-32-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32323, current rewards: -979.25855, mean: -1.60534
[32m[0907 15-32-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32164, current rewards: -1029.25855, mean: -1.55948
[32m[0907 15-32-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32709, current rewards: -1118.19190, mean: -1.57492
[32m[0907 15-33-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33006, current rewards: -1218.19190, mean: -1.60288
[32m[0907 15-33-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32873, current rewards: -1318.19190, mean: -1.62740
[32m[0907 15-33-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32785, current rewards: -1356.98999, mean: -1.57790
[32m[0907 15-33-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32659, current rewards: -1402.38480, mean: -1.54108
[32m[0907 15-34-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32528, current rewards: -1502.38480, mean: -1.56498
[32m[0907 15-34-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32416, current rewards: -1602.38480, mean: -1.58652
[32m[0907 15-34-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32334, current rewards: -1702.38480, mean: -1.60602
[32m[0907 15-34-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32251, current rewards: -1802.38480, mean: -1.62377
[32m[0907 15-35-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32199, current rewards: -1902.38480, mean: -1.63999
[32m[0907 15-35-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32142, current rewards: -2002.38480, mean: -1.65486
[32m[0907 15-35-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32108, current rewards: -2069.89725, mean: -1.64278
[32m[0907 15-35-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32193, current rewards: -2169.89725, mean: -1.65641
[32m[0907 15-36-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32121, current rewards: -2236.33889, mean: -1.64437
[32m[0907 15-36-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32090, current rewards: -2317.24578, mean: -1.64344
[32m[0907 15-36-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32042, current rewards: -2417.24578, mean: -1.65565
[32m[0907 15-36-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32056, current rewards: -2509.17931, mean: -1.66171
[32m[0907 15-37-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32172, current rewards: -2609.17931, mean: -1.67255
[32m[0907 15-37-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32124, current rewards: -2644.52863, mean: -1.64256
[32m[0907 15-37-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32070, current rewards: -2707.52863, mean: -1.63104
[32m[0907 15-37-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32033, current rewards: -2785.44648, mean: -1.62892
[32m[0907 15-38-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31983, current rewards: -2885.44648, mean: -1.63946
[32m[0907 15-38-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31948, current rewards: -2973.37067, mean: -1.64275
[32m[0907 15-38-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31997, current rewards: -3073.37067, mean: -1.65235
[32m[0907 15-39-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32353, current rewards: -3105.43941, mean: -1.62588
[32m[0907 15-39-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32698, current rewards: -3138.85784, mean: -1.60146
[32m[0907 15-39-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32665, current rewards: -3226.18303, mean: -1.60507
[32m[0907 15-40-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32993, current rewards: -3310.74908, mean: -1.60716
[32m[0907 15-40-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33046, current rewards: -3410.74908, mean: -1.61647
[32m[0907 15-40-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33143, current rewards: -3464.97348, mean: -1.60415
[32m[0907 15-41-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33087, current rewards: -3564.97348, mean: -1.61311
[32m[0907 15-41-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33067, current rewards: -3662.83748, mean: -1.62072
[32m[0907 15-41-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33036, current rewards: -3718.77018, mean: -1.60986
[32m[0907 15-41-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32981, current rewards: -3797.71787, mean: -1.60920
[32m[0907 15-42-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32964, current rewards: -3893.32529, mean: -1.61549
[32m[0907 15-42-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33149, current rewards: -3993.32529, mean: -1.62330
[32m[0907 15-42-44 @Agent.py:117][0m Average action selection time: 0.3329
[32m[0907 15-42-44 @Agent.py:118][0m Rollout length: 2600
[32m[0907 15-42-44 @MBExp.py:227][0m Rewards obtained: [-4057.911727427964], Lows: [1862], Highs: [373], Total time: 79626.795362
[32m[0907 15-43-51 @MBExp.py:144][0m ####################################################################
[32m[0907 15-43-51 @MBExp.py:145][0m Starting training iteration 104.
[32m[0907 15-43-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.50454, current rewards: -5.79872, mean: -0.57987
[32m[0907 15-44-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.52499, current rewards: -0.85648, mean: -0.01427
[32m[0907 15-44-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.51405, current rewards: -16.49389, mean: -0.14994
[32m[0907 15-45-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.48738, current rewards: -116.49389, mean: -0.72809
[32m[0907 15-45-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.48585, current rewards: -149.83606, mean: -0.71351
[32m[0907 15-45-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.48178, current rewards: -200.39951, mean: -0.77077
[32m[0907 15-46-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.45505, current rewards: -248.27879, mean: -0.80090
[32m[0907 15-46-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.43394, current rewards: -298.27879, mean: -0.82855
[32m[0907 15-46-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.41879, current rewards: -341.71899, mean: -0.83346
[32m[0907 15-46-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.40615, current rewards: -391.71899, mean: -0.85156
[32m[0907 15-47-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.39685, current rewards: -441.71899, mean: -0.86612
[32m[0907 15-47-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.38865, current rewards: -491.71899, mean: -0.87807
[32m[0907 15-47-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.38190, current rewards: -541.71899, mean: -0.88806
[32m[0907 15-47-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.37587, current rewards: -591.71899, mean: -0.89654
[32m[0907 15-48-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.37086, current rewards: -641.71899, mean: -0.90383
[32m[0907 15-48-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.36666, current rewards: -691.71899, mean: -0.91016
[32m[0907 15-48-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.36301, current rewards: -741.71899, mean: -0.91570
[32m[0907 15-49-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.35961, current rewards: -791.71899, mean: -0.92060
[32m[0907 15-49-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.35657, current rewards: -841.71899, mean: -0.92497
[32m[0907 15-49-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.35393, current rewards: -891.71899, mean: -0.92887
[32m[0907 15-49-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.35163, current rewards: -941.71899, mean: -0.93240
[32m[0907 15-50-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34947, current rewards: -991.71899, mean: -0.93558
[32m[0907 15-50-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.34739, current rewards: -1041.71899, mean: -0.93849
[32m[0907 15-50-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.34547, current rewards: -1091.71899, mean: -0.94114
[32m[0907 15-50-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.34365, current rewards: -1141.71899, mean: -0.94357
[32m[0907 15-51-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34202, current rewards: -1191.71899, mean: -0.94581
[32m[0907 15-51-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34051, current rewards: -1241.71899, mean: -0.94788
[32m[0907 15-51-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33923, current rewards: -1291.71899, mean: -0.94979
[32m[0907 15-51-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33806, current rewards: -1341.71899, mean: -0.95157
[32m[0907 15-52-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33701, current rewards: -1391.71899, mean: -0.95323
[32m[0907 15-52-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.33599, current rewards: -1441.71899, mean: -0.95478
[32m[0907 15-52-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.33490, current rewards: -1491.71899, mean: -0.95623
[32m[0907 15-52-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33387, current rewards: -1541.71899, mean: -0.95759
[32m[0907 15-53-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33295, current rewards: -1591.71899, mean: -0.95887
[32m[0907 15-53-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33220, current rewards: -1641.71899, mean: -0.96007
[32m[0907 15-53-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33138, current rewards: -1691.71899, mean: -0.96120
[32m[0907 15-53-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33079, current rewards: -1741.71899, mean: -0.96228
[32m[0907 15-54-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33013, current rewards: -1791.71899, mean: -0.96329
[32m[0907 15-54-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32944, current rewards: -1841.71899, mean: -0.96425
[32m[0907 15-54-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32875, current rewards: -1891.71899, mean: -0.96516
[32m[0907 15-54-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32810, current rewards: -1941.71899, mean: -0.96603
[32m[0907 15-55-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32756, current rewards: -1991.71899, mean: -0.96685
[32m[0907 15-55-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32722, current rewards: -2041.71899, mean: -0.96764
[32m[0907 15-55-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32674, current rewards: -2091.71899, mean: -0.96839
[32m[0907 15-55-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32641, current rewards: -2141.71899, mean: -0.96910
[32m[0907 15-56-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32596, current rewards: -2191.71899, mean: -0.96979
[32m[0907 15-56-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32564, current rewards: -2241.71899, mean: -0.97044
[32m[0907 15-56-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32543, current rewards: -2291.71899, mean: -0.97107
[32m[0907 15-56-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32499, current rewards: -2341.71899, mean: -0.97167
[32m[0907 15-57-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32453, current rewards: -2391.71899, mean: -0.97224
[32m[0907 15-57-22 @Agent.py:117][0m Average action selection time: 0.3242
[32m[0907 15-57-22 @Agent.py:118][0m Rollout length: 2600
[32m[0907 15-57-22 @MBExp.py:227][0m Rewards obtained: [-2431.7189870174434], Lows: [109], Highs: [2240], Total time: 80437.74957500001
[32m[0907 15-58-28 @MBExp.py:144][0m ####################################################################
[32m[0907 15-58-28 @MBExp.py:145][0m Starting training iteration 105.
[32m[0907 15-58-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.50842, current rewards: -10.00000, mean: -1.00000
[32m[0907 15-58-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.50147, current rewards: -60.00000, mean: -1.00000
[32m[0907 15-59-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.43818, current rewards: -106.73247, mean: -0.97030
[32m[0907 15-59-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.39507, current rewards: -141.76663, mean: -0.88604
[32m[0907 15-59-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.37345, current rewards: -241.76663, mean: -1.15127
[32m[0907 16-00-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.36013, current rewards: -341.76663, mean: -1.31449
[32m[0907 16-00-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.35069, current rewards: -441.76663, mean: -1.42505
[32m[0907 16-00-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34409, current rewards: -541.76663, mean: -1.50491
[32m[0907 16-00-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33942, current rewards: -641.76663, mean: -1.56528
[32m[0907 16-01-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.33542, current rewards: -741.76663, mean: -1.61254
[32m[0907 16-01-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33224, current rewards: -841.76663, mean: -1.65052
[32m[0907 16-01-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33041, current rewards: -941.76663, mean: -1.68173
[32m[0907 16-01-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.32862, current rewards: -1041.76663, mean: -1.70781
[32m[0907 16-02-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.32715, current rewards: -1141.76663, mean: -1.72995
[32m[0907 16-02-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32602, current rewards: -1241.76663, mean: -1.74897
[32m[0907 16-02-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32529, current rewards: -1341.76663, mean: -1.76548
[32m[0907 16-02-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32487, current rewards: -1441.76663, mean: -1.77996
[32m[0907 16-03-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32420, current rewards: -1541.76663, mean: -1.79275
[32m[0907 16-03-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32369, current rewards: -1641.76663, mean: -1.80414
[32m[0907 16-03-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32335, current rewards: -1741.76663, mean: -1.81434
[32m[0907 16-03-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32306, current rewards: -1841.76663, mean: -1.82353
[32m[0907 16-04-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32267, current rewards: -1941.76663, mean: -1.83186
[32m[0907 16-04-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32231, current rewards: -2041.76663, mean: -1.83943
[32m[0907 16-04-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32193, current rewards: -2141.76663, mean: -1.84635
[32m[0907 16-04-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32150, current rewards: -2241.76663, mean: -1.85270
[32m[0907 16-05-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32116, current rewards: -2341.76663, mean: -1.85854
[32m[0907 16-05-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32098, current rewards: -2441.76663, mean: -1.86394
[32m[0907 16-05-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32088, current rewards: -2541.76663, mean: -1.86895
[32m[0907 16-06-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32067, current rewards: -2641.76663, mean: -1.87359
[32m[0907 16-06-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32064, current rewards: -2741.76663, mean: -1.87792
[32m[0907 16-06-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32048, current rewards: -2841.76663, mean: -1.88196
[32m[0907 16-06-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32045, current rewards: -2941.76663, mean: -1.88575
[32m[0907 16-07-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32051, current rewards: -3041.76663, mean: -1.88930
[32m[0907 16-07-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32037, current rewards: -3141.76663, mean: -1.89263
[32m[0907 16-07-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32035, current rewards: -3241.76663, mean: -1.89577
[32m[0907 16-07-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32016, current rewards: -3341.76663, mean: -1.89873
[32m[0907 16-08-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32005, current rewards: -3441.76663, mean: -1.90153
[32m[0907 16-08-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31985, current rewards: -3541.76663, mean: -1.90418
[32m[0907 16-08-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31963, current rewards: -3641.76663, mean: -1.90668
[32m[0907 16-08-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31933, current rewards: -3741.76663, mean: -1.90906
[32m[0907 16-09-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31902, current rewards: -3841.76663, mean: -1.91133
[32m[0907 16-09-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31872, current rewards: -3941.76663, mean: -1.91348
[32m[0907 16-09-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31844, current rewards: -4041.76663, mean: -1.91553
[32m[0907 16-09-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31819, current rewards: -4141.76663, mean: -1.91748
[32m[0907 16-10-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31800, current rewards: -4241.76663, mean: -1.91935
[32m[0907 16-10-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31784, current rewards: -4341.76663, mean: -1.92114
[32m[0907 16-10-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31761, current rewards: -4441.76663, mean: -1.92284
[32m[0907 16-10-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31743, current rewards: -4541.76663, mean: -1.92448
[32m[0907 16-11-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31722, current rewards: -4641.76663, mean: -1.92604
[32m[0907 16-11-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31701, current rewards: -4741.76663, mean: -1.92755
[32m[0907 16-11-40 @Agent.py:117][0m Average action selection time: 0.3169
[32m[0907 16-11-40 @Agent.py:118][0m Rollout length: 2600
[32m[0907 16-11-40 @MBExp.py:227][0m Rewards obtained: [-4821.766633520401], Lows: [2361], Highs: [107], Total time: 81230.487577
[32m[0907 16-12-49 @MBExp.py:144][0m ####################################################################
[32m[0907 16-12-49 @MBExp.py:145][0m Starting training iteration 106.
[32m[0907 16-12-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.51515, current rewards: 0.61793, mean: 0.06179
[32m[0907 16-13-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.51456, current rewards: 5.75831, mean: 0.09597
[32m[0907 16-13-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.51633, current rewards: -10.04594, mean: -0.09133
[32m[0907 16-14-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.51847, current rewards: -59.05312, mean: -0.36908
[32m[0907 16-14-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.50567, current rewards: -156.22094, mean: -0.74391
[32m[0907 16-14-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.47954, current rewards: -256.22094, mean: -0.98547
[32m[0907 16-15-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.45294, current rewards: -356.22094, mean: -1.14910
[32m[0907 16-15-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.43503, current rewards: -435.22094, mean: -1.20895
[32m[0907 16-15-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.42908, current rewards: -485.22094, mean: -1.18347
[32m[0907 16-16-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.43807, current rewards: -519.10046, mean: -1.12848
[32m[0907 16-16-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.44405, current rewards: -586.28985, mean: -1.14959
[32m[0907 16-16-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.44219, current rewards: -671.82968, mean: -1.19970
[32m[0907 16-17-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.43137, current rewards: -721.45405, mean: -1.18271
[32m[0907 16-17-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.42191, current rewards: -771.45405, mean: -1.16887
[32m[0907 16-17-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.41386, current rewards: -821.45405, mean: -1.15698
[32m[0907 16-17-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.40692, current rewards: -871.45405, mean: -1.14665
[32m[0907 16-18-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.40081, current rewards: -921.45405, mean: -1.13760
[32m[0907 16-18-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.39536, current rewards: -971.45405, mean: -1.12960
[32m[0907 16-18-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.39051, current rewards: -1021.45405, mean: -1.12248
[32m[0907 16-19-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.38622, current rewards: -1071.45405, mean: -1.11610
[32m[0907 16-19-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.38253, current rewards: -1121.45405, mean: -1.11035
[32m[0907 16-19-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.37929, current rewards: -1171.45405, mean: -1.10515
[32m[0907 16-19-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37654, current rewards: -1221.45405, mean: -1.10041
[32m[0907 16-20-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37373, current rewards: -1271.45405, mean: -1.09608
[32m[0907 16-20-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37114, current rewards: -1302.76296, mean: -1.07666
[32m[0907 16-20-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37394, current rewards: -1390.64729, mean: -1.10369
[32m[0907 16-21-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37693, current rewards: -1490.64729, mean: -1.13790
[32m[0907 16-21-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37455, current rewards: -1555.49637, mean: -1.14375
[32m[0907 16-21-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.37251, current rewards: -1605.49637, mean: -1.13865
[32m[0907 16-21-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.37093, current rewards: -1655.49637, mean: -1.13390
[32m[0907 16-22-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.37232, current rewards: -1705.49637, mean: -1.12947
[32m[0907 16-22-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.37037, current rewards: -1755.49637, mean: -1.12532
[32m[0907 16-22-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36851, current rewards: -1805.49637, mean: -1.12143
[32m[0907 16-22-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36683, current rewards: -1855.49637, mean: -1.11777
[32m[0907 16-23-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36542, current rewards: -1905.49637, mean: -1.11433
[32m[0907 16-23-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36394, current rewards: -1955.49637, mean: -1.11108
[32m[0907 16-23-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36271, current rewards: -2005.49637, mean: -1.10801
[32m[0907 16-24-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.36137, current rewards: -2055.49637, mean: -1.10511
[32m[0907 16-24-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.36120, current rewards: -2105.49637, mean: -1.10235
[32m[0907 16-24-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.36190, current rewards: -2155.49637, mean: -1.09974
[32m[0907 16-25-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.36566, current rewards: -2204.70060, mean: -1.09687
[32m[0907 16-25-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.36808, current rewards: -2299.56538, mean: -1.11629
[32m[0907 16-25-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.36678, current rewards: -2324.85772, mean: -1.10183
[32m[0907 16-26-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.36930, current rewards: -2374.85772, mean: -1.09947
[32m[0907 16-26-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.37269, current rewards: -2411.80114, mean: -1.09131
[32m[0907 16-26-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.37382, current rewards: -2470.33139, mean: -1.09307
[32m[0907 16-27-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.37248, current rewards: -2520.33139, mean: -1.09105
[32m[0907 16-27-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.37527, current rewards: -2570.33139, mean: -1.08912
[32m[0907 16-27-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.37699, current rewards: -2618.19076, mean: -1.08639
[32m[0907 16-28-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.37615, current rewards: -2660.90714, mean: -1.08167
[32m[0907 16-28-28 @Agent.py:117][0m Average action selection time: 0.3752
[32m[0907 16-28-28 @Agent.py:118][0m Rollout length: 2600
[32m[0907 16-28-28 @MBExp.py:227][0m Rewards obtained: [-2700.9071382822635], Lows: [498], Highs: [1749], Total time: 82169.034767
[32m[0907 16-29-41 @MBExp.py:144][0m ####################################################################
[32m[0907 16-29-41 @MBExp.py:145][0m Starting training iteration 107.
[32m[0907 16-29-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.51422, current rewards: -10.00000, mean: -1.00000
[32m[0907 16-30-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.51574, current rewards: -60.00000, mean: -1.00000
[32m[0907 16-30-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.51393, current rewards: -110.00000, mean: -1.00000
[32m[0907 16-31-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.51467, current rewards: -160.00000, mean: -1.00000
[32m[0907 16-31-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.51147, current rewards: -210.00000, mean: -1.00000
[32m[0907 16-31-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.51246, current rewards: -260.00000, mean: -1.00000
[32m[0907 16-32-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.51324, current rewards: -310.00000, mean: -1.00000
[32m[0907 16-32-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.50767, current rewards: -365.40790, mean: -1.01502
[32m[0907 16-32-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.48380, current rewards: -465.40790, mean: -1.13514
[32m[0907 16-33-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.47447, current rewards: -542.67992, mean: -1.17974
[32m[0907 16-33-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.46412, current rewards: -539.27793, mean: -1.05741
[32m[0907 16-33-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.45138, current rewards: -535.43454, mean: -0.95613
[32m[0907 16-34-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.44116, current rewards: -531.72934, mean: -0.87169
[32m[0907 16-34-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.43193, current rewards: -528.28861, mean: -0.80044
[32m[0907 16-34-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.42307, current rewards: -524.08054, mean: -0.73814
[32m[0907 16-34-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.41552, current rewards: -520.34914, mean: -0.68467
[32m[0907 16-35-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.40899, current rewards: -517.03495, mean: -0.63831
[32m[0907 16-35-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.40357, current rewards: -564.90333, mean: -0.65686
[32m[0907 16-35-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.39895, current rewards: -614.90333, mean: -0.67572
[32m[0907 16-36-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.39518, current rewards: -664.90333, mean: -0.69261
[32m[0907 16-36-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.39182, current rewards: -714.90333, mean: -0.70783
[32m[0907 16-36-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.38881, current rewards: -764.90333, mean: -0.72161
[32m[0907 16-36-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.38604, current rewards: -776.10956, mean: -0.69920
[32m[0907 16-37-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.38321, current rewards: -773.68555, mean: -0.66697
[32m[0907 16-37-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.38057, current rewards: -771.26154, mean: -0.63741
[32m[0907 16-37-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37838, current rewards: -768.83753, mean: -0.61019
[32m[0907 16-37-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37633, current rewards: -773.75288, mean: -0.59065
[32m[0907 16-38-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37446, current rewards: -823.75288, mean: -0.60570
[32m[0907 16-38-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.37252, current rewards: -873.75288, mean: -0.61968
[32m[0907 16-38-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.37072, current rewards: -923.75288, mean: -0.63271
[32m[0907 16-38-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36896, current rewards: -973.75288, mean: -0.64487
[32m[0907 16-39-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36723, current rewards: -1023.75288, mean: -0.65625
[32m[0907 16-39-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36554, current rewards: -1073.75288, mean: -0.66693
[32m[0907 16-39-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.36413, current rewards: -1123.75288, mean: -0.67696
[32m[0907 16-40-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.36290, current rewards: -1173.75288, mean: -0.68641
[32m[0907 16-40-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.36157, current rewards: -1223.75288, mean: -0.69531
[32m[0907 16-40-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.36038, current rewards: -1273.75288, mean: -0.70373
[32m[0907 16-40-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35911, current rewards: -1323.75288, mean: -0.71170
[32m[0907 16-41-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35798, current rewards: -1373.75288, mean: -0.71924
[32m[0907 16-41-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35685, current rewards: -1423.75288, mean: -0.72640
[32m[0907 16-41-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35570, current rewards: -1473.75288, mean: -0.73321
[32m[0907 16-41-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35454, current rewards: -1523.75288, mean: -0.73969
[32m[0907 16-42-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35359, current rewards: -1573.75288, mean: -0.74585
[32m[0907 16-42-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35256, current rewards: -1623.75288, mean: -0.75174
[32m[0907 16-42-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.35161, current rewards: -1673.75288, mean: -0.75735
[32m[0907 16-42-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.35070, current rewards: -1723.75288, mean: -0.76272
[32m[0907 16-43-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34979, current rewards: -1773.75288, mean: -0.76786
[32m[0907 16-43-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34889, current rewards: -1823.75288, mean: -0.77278
[32m[0907 16-43-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34803, current rewards: -1873.75288, mean: -0.77749
[32m[0907 16-43-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34704, current rewards: -1923.75288, mean: -0.78201
[32m[0907 16-44-07 @Agent.py:117][0m Average action selection time: 0.3462
[32m[0907 16-44-07 @Agent.py:118][0m Rollout length: 2600
[32m[0907 16-44-07 @MBExp.py:227][0m Rewards obtained: [-1963.7528801988556], Lows: [118], Highs: [1770], Total time: 83035.149965
[32m[0907 16-45-20 @MBExp.py:144][0m ####################################################################
[32m[0907 16-45-20 @MBExp.py:145][0m Starting training iteration 108.
[32m[0907 16-45-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49300, current rewards: -10.00000, mean: -1.00000
[32m[0907 16-45-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.50304, current rewards: -60.00000, mean: -1.00000
[32m[0907 16-46-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.50634, current rewards: -99.14431, mean: -0.90131
[32m[0907 16-46-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.50923, current rewards: -155.52627, mean: -0.97204
[32m[0907 16-47-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.51300, current rewards: -206.32338, mean: -0.98249
[32m[0907 16-47-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.51631, current rewards: -306.32338, mean: -1.17817
[32m[0907 16-48-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.51826, current rewards: -406.32338, mean: -1.31072
[32m[0907 16-48-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.51863, current rewards: -447.13962, mean: -1.24205
[32m[0907 16-48-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.50940, current rewards: -497.13962, mean: -1.21254
[32m[0907 16-49-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.49976, current rewards: -547.13962, mean: -1.18943
[32m[0907 16-49-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.48069, current rewards: -597.13962, mean: -1.17086
[32m[0907 16-49-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.46449, current rewards: -647.13962, mean: -1.15561
[32m[0907 16-49-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.45116, current rewards: -697.13962, mean: -1.14285
[32m[0907 16-50-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.44074, current rewards: -747.13962, mean: -1.13203
[32m[0907 16-50-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.43241, current rewards: -797.13962, mean: -1.12273
[32m[0907 16-50-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.42532, current rewards: -847.13962, mean: -1.11466
[32m[0907 16-50-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.41793, current rewards: -897.13962, mean: -1.10758
[32m[0907 16-51-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.41107, current rewards: -947.13962, mean: -1.10133
[32m[0907 16-51-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.40505, current rewards: -997.13962, mean: -1.09576
[32m[0907 16-51-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.39979, current rewards: -1047.13962, mean: -1.09077
[32m[0907 16-52-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.39563, current rewards: -1097.13962, mean: -1.08628
[32m[0907 16-52-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.39127, current rewards: -1147.13962, mean: -1.08221
[32m[0907 16-52-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.38710, current rewards: -1197.13962, mean: -1.07850
[32m[0907 16-52-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.38364, current rewards: -1247.13962, mean: -1.07512
[32m[0907 16-53-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.38046, current rewards: -1297.13962, mean: -1.07202
[32m[0907 16-53-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.37758, current rewards: -1347.13962, mean: -1.06916
[32m[0907 16-53-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.37457, current rewards: -1397.13962, mean: -1.06652
[32m[0907 16-53-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.37174, current rewards: -1447.13962, mean: -1.06407
[32m[0907 16-54-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36913, current rewards: -1497.13962, mean: -1.06180
[32m[0907 16-54-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.36699, current rewards: -1547.13962, mean: -1.05968
[32m[0907 16-54-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.36475, current rewards: -1597.13962, mean: -1.05771
[32m[0907 16-54-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.36263, current rewards: -1647.13962, mean: -1.05586
[32m[0907 16-55-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.36086, current rewards: -1677.86903, mean: -1.04215
[32m[0907 16-55-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.35896, current rewards: -1674.33961, mean: -1.00864
[32m[0907 16-55-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.35715, current rewards: -1670.81019, mean: -0.97708
[32m[0907 16-55-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.35566, current rewards: -1667.28077, mean: -0.94732
[32m[0907 16-56-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.35406, current rewards: -1663.75135, mean: -0.91920
[32m[0907 16-56-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.35274, current rewards: -1660.22193, mean: -0.89259
[32m[0907 16-56-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.35192, current rewards: -1656.69251, mean: -0.86738
[32m[0907 16-56-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.35078, current rewards: -1699.19839, mean: -0.86694
[32m[0907 16-57-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.34962, current rewards: -1749.19839, mean: -0.87025
[32m[0907 16-57-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.34848, current rewards: -1799.19839, mean: -0.87340
[32m[0907 16-57-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.34737, current rewards: -1849.19839, mean: -0.87640
[32m[0907 16-57-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.34666, current rewards: -1899.19839, mean: -0.87926
[32m[0907 16-58-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.34582, current rewards: -1949.19839, mean: -0.88199
[32m[0907 16-58-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.34496, current rewards: -1999.19839, mean: -0.88460
[32m[0907 16-58-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.34421, current rewards: -2049.19839, mean: -0.88710
[32m[0907 16-58-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.34334, current rewards: -2099.19839, mean: -0.88949
[32m[0907 16-59-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.34254, current rewards: -2149.19839, mean: -0.89178
[32m[0907 16-59-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.34169, current rewards: -2174.57485, mean: -0.88397
[32m[0907 16-59-33 @Agent.py:117][0m Average action selection time: 0.3410
[32m[0907 16-59-33 @Agent.py:118][0m Rollout length: 2600
[32m[0907 16-59-33 @MBExp.py:227][0m Rewards obtained: [-2171.7513163408457], Lows: [160], Highs: [1889], Total time: 83888.133379
[32m[0907 17-00-47 @MBExp.py:144][0m ####################################################################
[32m[0907 17-00-47 @MBExp.py:145][0m Starting training iteration 109.
[32m[0907 17-00-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49195, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-01-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.50932, current rewards: -60.00000, mean: -1.00000
[32m[0907 17-01-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.50897, current rewards: -112.96488, mean: -1.02695
[32m[0907 17-02-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.50398, current rewards: -117.11142, mean: -0.73195
[32m[0907 17-02-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.50138, current rewards: -164.10565, mean: -0.78146
[32m[0907 17-02-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.48927, current rewards: -196.12079, mean: -0.75431
[32m[0907 17-03-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.45829, current rewards: -229.95024, mean: -0.74177
[32m[0907 17-03-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.43545, current rewards: -272.51331, mean: -0.75698
[32m[0907 17-03-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.42060, current rewards: -372.51331, mean: -0.90857
[32m[0907 17-04-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.42812, current rewards: -472.51331, mean: -1.02720
[32m[0907 17-04-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.42783, current rewards: -561.27289, mean: -1.10054
[32m[0907 17-04-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.41666, current rewards: -618.54537, mean: -1.10455
[32m[0907 17-04-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.41085, current rewards: -718.54537, mean: -1.17794
[32m[0907 17-05-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.40282, current rewards: -818.54537, mean: -1.24022
[32m[0907 17-05-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.39588, current rewards: -863.74428, mean: -1.21654
[32m[0907 17-05-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.38994, current rewards: -913.74428, mean: -1.20230
[32m[0907 17-05-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.38463, current rewards: -963.74428, mean: -1.18981
[32m[0907 17-06-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.38081, current rewards: -1013.74428, mean: -1.17877
[32m[0907 17-06-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37664, current rewards: -1063.74428, mean: -1.16895
[32m[0907 17-06-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37296, current rewards: -1122.54647, mean: -1.16932
[32m[0907 17-07-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36960, current rewards: -1222.54647, mean: -1.21044
[32m[0907 17-07-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36657, current rewards: -1322.54647, mean: -1.24769
[32m[0907 17-07-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36379, current rewards: -1422.54647, mean: -1.28157
[32m[0907 17-07-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36127, current rewards: -1522.54647, mean: -1.31254
[32m[0907 17-08-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35892, current rewards: -1622.54647, mean: -1.34095
[32m[0907 17-08-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35681, current rewards: -1722.54647, mean: -1.36710
[32m[0907 17-08-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35486, current rewards: -1822.54647, mean: -1.39126
[32m[0907 17-08-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35301, current rewards: -1922.54647, mean: -1.41364
[32m[0907 17-09-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35134, current rewards: -2022.54647, mean: -1.43443
[32m[0907 17-09-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34976, current rewards: -2122.54647, mean: -1.45380
[32m[0907 17-09-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34826, current rewards: -2222.54647, mean: -1.47189
[32m[0907 17-09-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34687, current rewards: -2322.54647, mean: -1.48881
[32m[0907 17-10-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34553, current rewards: -2422.54647, mean: -1.50469
[32m[0907 17-10-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34430, current rewards: -2522.54647, mean: -1.51961
[32m[0907 17-10-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34314, current rewards: -2622.54647, mean: -1.53365
[32m[0907 17-10-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34203, current rewards: -2722.54647, mean: -1.54690
[32m[0907 17-11-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34099, current rewards: -2822.54647, mean: -1.55942
[32m[0907 17-11-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34001, current rewards: -2922.54647, mean: -1.57126
[32m[0907 17-11-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33908, current rewards: -3022.54647, mean: -1.58249
[32m[0907 17-11-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33818, current rewards: -3122.54647, mean: -1.59314
[32m[0907 17-12-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33734, current rewards: -3222.54647, mean: -1.60326
[32m[0907 17-12-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33653, current rewards: -3322.54647, mean: -1.61289
[32m[0907 17-12-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33577, current rewards: -3422.54647, mean: -1.62206
[32m[0907 17-12-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33504, current rewards: -3522.54647, mean: -1.63081
[32m[0907 17-13-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33434, current rewards: -3622.54647, mean: -1.63916
[32m[0907 17-13-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33367, current rewards: -3722.54647, mean: -1.64714
[32m[0907 17-13-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33304, current rewards: -3822.54647, mean: -1.65478
[32m[0907 17-13-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33244, current rewards: -3922.54647, mean: -1.66210
[32m[0907 17-14-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33186, current rewards: -4022.54647, mean: -1.66911
[32m[0907 17-14-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33132, current rewards: -4122.54647, mean: -1.67583
[32m[0907 17-14-34 @Agent.py:117][0m Average action selection time: 0.3309
[32m[0907 17-14-34 @Agent.py:118][0m Rollout length: 2600
[32m[0907 17-14-34 @MBExp.py:227][0m Rewards obtained: [-4202.546468676156], Lows: [1886], Highs: [453], Total time: 84715.91680800001
[32m[0907 17-15-49 @MBExp.py:144][0m ####################################################################
[32m[0907 17-15-49 @MBExp.py:145][0m Starting training iteration 110.
[32m[0907 17-15-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.49966, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-16-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.50215, current rewards: -60.00000, mean: -1.00000
[32m[0907 17-16-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.47633, current rewards: -101.12663, mean: -0.91933
[32m[0907 17-16-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.42215, current rewards: -151.54679, mean: -0.94717
[32m[0907 17-17-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.40409, current rewards: -251.54679, mean: -1.19784
[32m[0907 17-17-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.39175, current rewards: -348.81438, mean: -1.34159
[32m[0907 17-17-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37753, current rewards: -418.95577, mean: -1.35147
[32m[0907 17-18-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36785, current rewards: -510.43630, mean: -1.41788
[32m[0907 17-18-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36194, current rewards: -610.43630, mean: -1.48887
[32m[0907 17-18-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35585, current rewards: -708.36270, mean: -1.53992
[32m[0907 17-18-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.35709, current rewards: -808.36270, mean: -1.58502
[32m[0907 17-19-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.37022, current rewards: -908.36270, mean: -1.62208
[32m[0907 17-19-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.36626, current rewards: -976.70276, mean: -1.60115
[32m[0907 17-19-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.36148, current rewards: -1026.70276, mean: -1.55561
[32m[0907 17-20-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.35840, current rewards: -1109.81244, mean: -1.56312
[32m[0907 17-20-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.35480, current rewards: -1209.81244, mean: -1.59186
[32m[0907 17-20-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.35168, current rewards: -1299.40152, mean: -1.60420
[32m[0907 17-20-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.34883, current rewards: -1345.08095, mean: -1.56405
[32m[0907 17-21-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.34639, current rewards: -1395.08095, mean: -1.53306
[32m[0907 17-21-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.34419, current rewards: -1436.64699, mean: -1.49651
[32m[0907 17-21-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.34220, current rewards: -1430.64825, mean: -1.41648
[32m[0907 17-21-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.34038, current rewards: -1424.04002, mean: -1.34343
[32m[0907 17-22-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.33875, current rewards: -1417.43178, mean: -1.27697
[32m[0907 17-22-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.33727, current rewards: -1451.58147, mean: -1.25136
[32m[0907 17-22-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.33590, current rewards: -1501.58147, mean: -1.24098
[32m[0907 17-22-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.33463, current rewards: -1551.58147, mean: -1.23141
[32m[0907 17-23-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.33347, current rewards: -1601.58147, mean: -1.22258
[32m[0907 17-23-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.33237, current rewards: -1651.58147, mean: -1.21440
[32m[0907 17-23-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.33140, current rewards: -1701.58147, mean: -1.20680
[32m[0907 17-23-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.33045, current rewards: -1751.58147, mean: -1.19971
[32m[0907 17-24-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32957, current rewards: -1801.58147, mean: -1.19310
[32m[0907 17-24-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32874, current rewards: -1851.58147, mean: -1.18691
[32m[0907 17-24-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32798, current rewards: -1901.58147, mean: -1.18111
[32m[0907 17-24-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32725, current rewards: -1951.58147, mean: -1.17565
[32m[0907 17-25-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32659, current rewards: -2001.58147, mean: -1.17052
[32m[0907 17-25-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.32595, current rewards: -2051.58147, mean: -1.16567
[32m[0907 17-25-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.32534, current rewards: -2101.58147, mean: -1.16109
[32m[0907 17-25-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.32475, current rewards: -2151.58147, mean: -1.15676
[32m[0907 17-26-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.32422, current rewards: -2201.58147, mean: -1.15266
[32m[0907 17-26-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.32368, current rewards: -2251.58147, mean: -1.14877
[32m[0907 17-26-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.32319, current rewards: -2301.58147, mean: -1.14507
[32m[0907 17-26-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.32273, current rewards: -2351.58147, mean: -1.14154
[32m[0907 17-27-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.32228, current rewards: -2401.58147, mean: -1.13819
[32m[0907 17-27-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.32184, current rewards: -2451.58147, mean: -1.13499
[32m[0907 17-27-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32144, current rewards: -2501.58147, mean: -1.13194
[32m[0907 17-27-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32104, current rewards: -2551.58147, mean: -1.12902
[32m[0907 17-28-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32069, current rewards: -2601.58147, mean: -1.12623
[32m[0907 17-28-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32034, current rewards: -2651.58147, mean: -1.12355
[32m[0907 17-28-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32002, current rewards: -2701.58147, mean: -1.12099
[32m[0907 17-28-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31969, current rewards: -2751.58147, mean: -1.11853
[32m[0907 17-29-08 @Agent.py:117][0m Average action selection time: 0.3195
[32m[0907 17-29-08 @Agent.py:118][0m Rollout length: 2600
[32m[0907 17-29-08 @MBExp.py:227][0m Rewards obtained: [-2791.581474154689], Lows: [548], Highs: [1727], Total time: 85515.066122
[32m[0907 17-30-24 @MBExp.py:144][0m ####################################################################
[32m[0907 17-30-24 @MBExp.py:145][0m Starting training iteration 111.
[32m[0907 17-30-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.50161, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-30-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.50219, current rewards: -60.00000, mean: -1.00000
[32m[0907 17-31-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.49771, current rewards: -105.63104, mean: -0.96028
[32m[0907 17-31-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.49712, current rewards: -167.35241, mean: -1.04595
[32m[0907 17-32-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.49911, current rewards: -267.35241, mean: -1.27311
[32m[0907 17-32-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.50043, current rewards: -367.35241, mean: -1.41289
[32m[0907 17-32-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.49049, current rewards: -393.08086, mean: -1.26800
[32m[0907 17-33-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.46458, current rewards: -443.08086, mean: -1.23078
[32m[0907 17-33-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.44496, current rewards: -493.08086, mean: -1.20264
[32m[0907 17-33-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.42954, current rewards: -543.08086, mean: -1.18061
[32m[0907 17-33-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.41710, current rewards: -593.08086, mean: -1.16290
[32m[0907 17-34-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.40697, current rewards: -643.08086, mean: -1.14836
[32m[0907 17-34-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.39844, current rewards: -693.08086, mean: -1.13620
[32m[0907 17-34-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.39129, current rewards: -743.08086, mean: -1.12588
[32m[0907 17-34-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.38508, current rewards: -793.08086, mean: -1.11702
[32m[0907 17-35-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.37976, current rewards: -843.08086, mean: -1.10932
[32m[0907 17-35-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.37504, current rewards: -893.08086, mean: -1.10257
[32m[0907 17-35-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.37093, current rewards: -943.08086, mean: -1.09661
[32m[0907 17-35-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.36725, current rewards: -993.08086, mean: -1.09130
[32m[0907 17-36-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.36399, current rewards: -1043.08086, mean: -1.08654
[32m[0907 17-36-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.36099, current rewards: -1093.08086, mean: -1.08226
[32m[0907 17-36-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.35831, current rewards: -1143.08086, mean: -1.07838
[32m[0907 17-36-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.35582, current rewards: -1193.08086, mean: -1.07485
[32m[0907 17-37-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.35357, current rewards: -1243.08086, mean: -1.07162
[32m[0907 17-37-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.35150, current rewards: -1293.08086, mean: -1.06866
[32m[0907 17-37-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.34960, current rewards: -1343.08086, mean: -1.06594
[32m[0907 17-38-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.34786, current rewards: -1393.08086, mean: -1.06342
[32m[0907 17-38-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.34623, current rewards: -1443.08086, mean: -1.06109
[32m[0907 17-38-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.34470, current rewards: -1493.08086, mean: -1.05892
[32m[0907 17-38-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.34332, current rewards: -1543.08086, mean: -1.05690
[32m[0907 17-39-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34202, current rewards: -1593.08086, mean: -1.05502
[32m[0907 17-39-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34076, current rewards: -1643.08086, mean: -1.05326
[32m[0907 17-39-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.33960, current rewards: -1693.08086, mean: -1.05160
[32m[0907 17-39-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.33854, current rewards: -1743.08086, mean: -1.05005
[32m[0907 17-40-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.33751, current rewards: -1793.08086, mean: -1.04859
[32m[0907 17-40-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33655, current rewards: -1843.08086, mean: -1.04721
[32m[0907 17-40-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33562, current rewards: -1893.08086, mean: -1.04590
[32m[0907 17-40-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.33474, current rewards: -1943.08086, mean: -1.04467
[32m[0907 17-41-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33393, current rewards: -1993.08086, mean: -1.04350
[32m[0907 17-41-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33316, current rewards: -2043.08086, mean: -1.04239
[32m[0907 17-41-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33244, current rewards: -2093.08086, mean: -1.04133
[32m[0907 17-41-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33174, current rewards: -2143.08086, mean: -1.04033
[32m[0907 17-42-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33108, current rewards: -2193.08086, mean: -1.03937
[32m[0907 17-42-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33046, current rewards: -2203.51164, mean: -1.02014
[32m[0907 17-42-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.32987, current rewards: -2198.55438, mean: -0.99482
[32m[0907 17-42-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.32929, current rewards: -2193.59714, mean: -0.97062
[32m[0907 17-43-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.32871, current rewards: -2188.63991, mean: -0.94746
[32m[0907 17-43-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.32819, current rewards: -2183.68265, mean: -0.92529
[32m[0907 17-43-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.32770, current rewards: -2178.72535, mean: -0.90404
[32m[0907 17-43-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.32721, current rewards: -2173.76799, mean: -0.88365
[32m[0907 17-44-02 @Agent.py:117][0m Average action selection time: 0.3269
[32m[0907 17-44-02 @Agent.py:118][0m Rollout length: 2600
[32m[0907 17-44-02 @MBExp.py:227][0m Rewards obtained: [-2169.8021178092063], Lows: [138], Highs: [1938], Total time: 86332.68174100001
[32m[0907 17-45-17 @MBExp.py:144][0m ####################################################################
[32m[0907 17-45-17 @MBExp.py:145][0m Starting training iteration 112.
[32m[0907 17-45-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.32126, current rewards: -10.00000, mean: -1.00000
[32m[0907 17-45-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30562, current rewards: -60.00000, mean: -1.00000
[32m[0907 17-45-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30420, current rewards: -119.00000, mean: -1.08182
[32m[0907 17-46-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30401, current rewards: -219.00000, mean: -1.36875
[32m[0907 17-46-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30389, current rewards: -319.00000, mean: -1.51905
[32m[0907 17-46-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30388, current rewards: -419.00000, mean: -1.61154
[32m[0907 17-46-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30384, current rewards: -519.00000, mean: -1.67419
[32m[0907 17-47-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.31619, current rewards: -619.00000, mean: -1.71944
[32m[0907 17-47-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.33914, current rewards: -719.00000, mean: -1.75366
[32m[0907 17-48-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35644, current rewards: -785.46387, mean: -1.70753
[32m[0907 17-48-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.37112, current rewards: -885.46387, mean: -1.73620
[32m[0907 17-48-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.38320, current rewards: -985.46387, mean: -1.75976
[32m[0907 17-49-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.39188, current rewards: -1085.46387, mean: -1.77945
[32m[0907 17-49-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.39548, current rewards: -1185.46387, mean: -1.79616
[32m[0907 17-49-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.38983, current rewards: -1285.46387, mean: -1.81051
[32m[0907 17-50-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.39231, current rewards: -1385.46387, mean: -1.82298
[32m[0907 17-50-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.39159, current rewards: -1485.46387, mean: -1.83391
[32m[0907 17-50-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.38649, current rewards: -1585.46387, mean: -1.84356
[32m[0907 17-51-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.39116, current rewards: -1685.46387, mean: -1.85216
[32m[0907 17-51-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.38778, current rewards: -1785.46387, mean: -1.85986
[32m[0907 17-51-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.38400, current rewards: -1885.46387, mean: -1.86680
[32m[0907 17-52-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.38022, current rewards: -1985.46387, mean: -1.87308
[32m[0907 17-52-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.37679, current rewards: -2085.46387, mean: -1.87880
[32m[0907 17-52-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.37363, current rewards: -2185.46387, mean: -1.88402
[32m[0907 17-52-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.37077, current rewards: -2285.46387, mean: -1.88881
[32m[0907 17-53-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.36811, current rewards: -2385.46387, mean: -1.89323
[32m[0907 17-53-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.36564, current rewards: -2485.46387, mean: -1.89730
[32m[0907 17-53-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.36351, current rewards: -2585.46387, mean: -1.90108
[32m[0907 17-53-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.36633, current rewards: -2685.46387, mean: -1.90458
[32m[0907 17-54-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.37096, current rewards: -2785.46387, mean: -1.90785
[32m[0907 17-54-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.37545, current rewards: -2885.46387, mean: -1.91090
[32m[0907 17-55-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.37962, current rewards: -2954.93425, mean: -1.89419
[32m[0907 17-55-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.38354, current rewards: -3014.72655, mean: -1.87250
[32m[0907 17-56-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.38715, current rewards: -3062.70263, mean: -1.84500
[32m[0907 17-56-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.39060, current rewards: -3162.70263, mean: -1.84953
[32m[0907 17-56-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.39389, current rewards: -3262.70263, mean: -1.85381
[32m[0907 17-57-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.39287, current rewards: -3362.70263, mean: -1.85785
[32m[0907 17-57-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.39053, current rewards: -3462.70263, mean: -1.86167
[32m[0907 17-57-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.38826, current rewards: -3562.70263, mean: -1.86529
[32m[0907 17-57-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.38609, current rewards: -3662.70263, mean: -1.86873
[32m[0907 17-58-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.38402, current rewards: -3762.70263, mean: -1.87199
[32m[0907 17-58-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.38206, current rewards: -3862.70263, mean: -1.87510
[32m[0907 17-58-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.38022, current rewards: -3962.70263, mean: -1.87806
[32m[0907 17-58-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.37844, current rewards: -4062.70263, mean: -1.88088
[32m[0907 17-59-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.37676, current rewards: -4162.70263, mean: -1.88358
[32m[0907 17-59-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.37515, current rewards: -4262.70263, mean: -1.88615
[32m[0907 17-59-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.37360, current rewards: -4362.70263, mean: -1.88862
[32m[0907 17-59-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.37213, current rewards: -4462.70263, mean: -1.89098
[32m[0907 18-00-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.37071, current rewards: -4562.70263, mean: -1.89324
[32m[0907 18-00-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36933, current rewards: -4662.70263, mean: -1.89541
[32m[0907 18-00-38 @Agent.py:117][0m Average action selection time: 0.3683
[32m[0907 18-00-38 @Agent.py:118][0m Rollout length: 2600
[32m[0907 18-00-38 @MBExp.py:227][0m Rewards obtained: [-4742.702628114233], Lows: [2324], Highs: [110], Total time: 87253.89044700001
[32m[0907 18-01-53 @MBExp.py:144][0m ####################################################################
[32m[0907 18-01-53 @MBExp.py:145][0m Starting training iteration 113.
[32m[0907 18-01-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.50278, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-02-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.45120, current rewards: -60.00000, mean: -1.00000
[32m[0907 18-02-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.38838, current rewards: -106.83801, mean: -0.97125
[32m[0907 18-02-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36445, current rewards: -148.34840, mean: -0.92718
[32m[0907 18-03-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.34979, current rewards: -198.34840, mean: -0.94452
[32m[0907 18-03-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.34085, current rewards: -276.19834, mean: -1.06230
[32m[0907 18-03-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.33496, current rewards: -376.19834, mean: -1.21354
[32m[0907 18-03-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.33068, current rewards: -476.19834, mean: -1.32277
[32m[0907 18-04-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.32741, current rewards: -576.19834, mean: -1.40536
[32m[0907 18-04-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.32487, current rewards: -676.19834, mean: -1.47000
[32m[0907 18-04-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.32286, current rewards: -776.19834, mean: -1.52196
[32m[0907 18-04-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.32117, current rewards: -876.19834, mean: -1.56464
[32m[0907 18-05-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.31976, current rewards: -976.19834, mean: -1.60033
[32m[0907 18-05-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.31849, current rewards: -1076.19834, mean: -1.63060
[32m[0907 18-05-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.31749, current rewards: -1176.19834, mean: -1.65662
[32m[0907 18-05-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.31660, current rewards: -1276.19834, mean: -1.67921
[32m[0907 18-06-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.31585, current rewards: -1376.19834, mean: -1.69901
[32m[0907 18-06-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.31515, current rewards: -1476.19834, mean: -1.71651
[32m[0907 18-06-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.31459, current rewards: -1576.19834, mean: -1.73209
[32m[0907 18-06-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.31402, current rewards: -1676.19834, mean: -1.74604
[32m[0907 18-07-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.31357, current rewards: -1776.19834, mean: -1.75861
[32m[0907 18-07-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.31313, current rewards: -1876.19834, mean: -1.77000
[32m[0907 18-07-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.31274, current rewards: -1976.19834, mean: -1.78036
[32m[0907 18-07-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31237, current rewards: -2076.19834, mean: -1.78983
[32m[0907 18-08-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31202, current rewards: -2176.19834, mean: -1.79851
[32m[0907 18-08-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31171, current rewards: -2276.19834, mean: -1.80651
[32m[0907 18-08-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31144, current rewards: -2376.19834, mean: -1.81389
[32m[0907 18-08-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31116, current rewards: -2476.19834, mean: -1.82073
[32m[0907 18-09-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31090, current rewards: -2576.19834, mean: -1.82709
[32m[0907 18-09-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31069, current rewards: -2676.19834, mean: -1.83301
[32m[0907 18-09-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31047, current rewards: -2776.19834, mean: -1.83854
[32m[0907 18-09-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31025, current rewards: -2876.19834, mean: -1.84372
[32m[0907 18-10-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31006, current rewards: -2976.19834, mean: -1.84857
[32m[0907 18-10-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30987, current rewards: -3076.19834, mean: -1.85313
[32m[0907 18-10-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30969, current rewards: -3176.19834, mean: -1.85743
[32m[0907 18-10-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30953, current rewards: -3276.19834, mean: -1.86148
[32m[0907 18-11-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30937, current rewards: -3376.19834, mean: -1.86530
[32m[0907 18-11-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30922, current rewards: -3476.19834, mean: -1.86892
[32m[0907 18-11-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30910, current rewards: -3576.19834, mean: -1.87236
[32m[0907 18-11-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30899, current rewards: -3676.19834, mean: -1.87561
[32m[0907 18-12-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30887, current rewards: -3776.19834, mean: -1.87871
[32m[0907 18-12-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30874, current rewards: -3876.19834, mean: -1.88165
[32m[0907 18-12-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30863, current rewards: -3976.19834, mean: -1.88445
[32m[0907 18-13-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30850, current rewards: -4076.19834, mean: -1.88713
[32m[0907 18-13-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30841, current rewards: -4176.19834, mean: -1.88968
[32m[0907 18-13-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30832, current rewards: -4276.19834, mean: -1.89212
[32m[0907 18-13-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30822, current rewards: -4376.19834, mean: -1.89446
[32m[0907 18-14-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30813, current rewards: -4476.19834, mean: -1.89669
[32m[0907 18-14-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30804, current rewards: -4576.19834, mean: -1.89884
[32m[0907 18-14-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30795, current rewards: -4676.19834, mean: -1.90089
[32m[0907 18-14-43 @Agent.py:117][0m Average action selection time: 0.3079
[32m[0907 18-14-43 @Agent.py:118][0m Rollout length: 2600
[32m[0907 18-14-43 @MBExp.py:227][0m Rewards obtained: [-4756.198340840385], Lows: [2271], Highs: [216], Total time: 88024.11129600002
[32m[0907 18-15-59 @MBExp.py:144][0m ####################################################################
[32m[0907 18-15-59 @MBExp.py:145][0m Starting training iteration 114.
[32m[0907 18-16-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.50496, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-16-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.50218, current rewards: -60.00000, mean: -1.00000
[32m[0907 18-16-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.50300, current rewards: -110.00000, mean: -1.00000
[32m[0907 18-17-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.44968, current rewards: -157.02896, mean: -0.98143
[32m[0907 18-17-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.41584, current rewards: -194.58970, mean: -0.92662
[32m[0907 18-17-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.39459, current rewards: -294.58970, mean: -1.13304
[32m[0907 18-17-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.37988, current rewards: -394.58970, mean: -1.27287
[32m[0907 18-18-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.36926, current rewards: -494.58970, mean: -1.37386
[32m[0907 18-18-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.36123, current rewards: -594.58970, mean: -1.45022
[32m[0907 18-18-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.35503, current rewards: -694.58970, mean: -1.50998
[32m[0907 18-18-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34989, current rewards: -794.58970, mean: -1.55802
[32m[0907 18-19-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34580, current rewards: -894.58970, mean: -1.59748
[32m[0907 18-19-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.34238, current rewards: -994.58970, mean: -1.63047
[32m[0907 18-19-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33948, current rewards: -1094.58970, mean: -1.65847
[32m[0907 18-19-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33698, current rewards: -1194.58970, mean: -1.68252
[32m[0907 18-20-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33475, current rewards: -1294.58970, mean: -1.70341
[32m[0907 18-20-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33280, current rewards: -1394.58970, mean: -1.72172
[32m[0907 18-20-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.33113, current rewards: -1494.58970, mean: -1.73789
[32m[0907 18-20-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32962, current rewards: -1594.58970, mean: -1.75230
[32m[0907 18-21-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32830, current rewards: -1694.58970, mean: -1.76520
[32m[0907 18-21-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32705, current rewards: -1794.58970, mean: -1.77682
[32m[0907 18-21-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32596, current rewards: -1894.58970, mean: -1.78735
[32m[0907 18-22-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32495, current rewards: -1994.58970, mean: -1.79693
[32m[0907 18-22-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32409, current rewards: -2094.58970, mean: -1.80568
[32m[0907 18-22-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32326, current rewards: -2194.58970, mean: -1.81371
[32m[0907 18-22-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32252, current rewards: -2294.58970, mean: -1.82110
[32m[0907 18-23-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32181, current rewards: -2394.58970, mean: -1.82793
[32m[0907 18-23-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32116, current rewards: -2494.58970, mean: -1.83426
[32m[0907 18-23-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32055, current rewards: -2594.58970, mean: -1.84013
[32m[0907 18-23-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32003, current rewards: -2694.58970, mean: -1.84561
[32m[0907 18-24-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31951, current rewards: -2794.58970, mean: -1.85072
[32m[0907 18-24-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31899, current rewards: -2894.58970, mean: -1.85551
[32m[0907 18-24-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31852, current rewards: -2994.58970, mean: -1.85999
[32m[0907 18-24-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31808, current rewards: -3094.58970, mean: -1.86421
[32m[0907 18-25-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31768, current rewards: -3194.58970, mean: -1.86818
[32m[0907 18-25-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31728, current rewards: -3294.58970, mean: -1.87193
[32m[0907 18-25-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31687, current rewards: -3394.58970, mean: -1.87546
[32m[0907 18-25-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31653, current rewards: -3494.58970, mean: -1.87881
[32m[0907 18-26-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31620, current rewards: -3594.58970, mean: -1.88198
[32m[0907 18-26-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31589, current rewards: -3694.58970, mean: -1.88499
[32m[0907 18-26-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31559, current rewards: -3794.58970, mean: -1.88786
[32m[0907 18-26-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31530, current rewards: -3894.58970, mean: -1.89058
[32m[0907 18-27-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31504, current rewards: -3994.58970, mean: -1.89317
[32m[0907 18-27-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31478, current rewards: -4094.58970, mean: -1.89564
[32m[0907 18-27-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31453, current rewards: -4194.58970, mean: -1.89800
[32m[0907 18-27-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31428, current rewards: -4294.58970, mean: -1.90026
[32m[0907 18-28-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31405, current rewards: -4394.58970, mean: -1.90242
[32m[0907 18-28-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31386, current rewards: -4494.58970, mean: -1.90449
[32m[0907 18-28-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31365, current rewards: -4594.58970, mean: -1.90647
[32m[0907 18-28-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31346, current rewards: -4694.58970, mean: -1.90837
[32m[0907 18-29-03 @Agent.py:117][0m Average action selection time: 0.3133
[32m[0907 18-29-03 @Agent.py:118][0m Rollout length: 2600
[32m[0907 18-29-03 @MBExp.py:227][0m Rewards obtained: [-4774.589699727185], Lows: [2337], Highs: [113], Total time: 88807.82362700002
[32m[0907 18-30-19 @MBExp.py:144][0m ####################################################################
[32m[0907 18-30-19 @MBExp.py:145][0m Starting training iteration 115.
[32m[0907 18-30-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.50297, current rewards: 0.90097, mean: 0.09010
[32m[0907 18-30-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.50207, current rewards: 4.48171, mean: 0.07470
[32m[0907 18-31-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.50284, current rewards: -12.65370, mean: -0.11503
[32m[0907 18-31-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.50348, current rewards: -112.65370, mean: -0.70409
[32m[0907 18-32-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.50398, current rewards: -212.65370, mean: -1.01264
[32m[0907 18-32-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.50430, current rewards: -312.65370, mean: -1.20251
[32m[0907 18-32-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.49526, current rewards: -407.21190, mean: -1.31359
[32m[0907 18-33-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.49152, current rewards: -490.27315, mean: -1.36187
[32m[0907 18-33-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.46997, current rewards: -540.27315, mean: -1.31774
[32m[0907 18-33-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.45191, current rewards: -590.27315, mean: -1.28320
[32m[0907 18-34-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.43743, current rewards: -640.27315, mean: -1.25544
[32m[0907 18-34-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.42549, current rewards: -690.27315, mean: -1.23263
[32m[0907 18-34-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.41551, current rewards: -740.27315, mean: -1.21356
[32m[0907 18-34-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.40700, current rewards: -790.27315, mean: -1.19738
[32m[0907 18-35-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.39972, current rewards: -840.27315, mean: -1.18348
[32m[0907 18-35-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.39339, current rewards: -890.27315, mean: -1.17141
[32m[0907 18-35-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.38788, current rewards: -940.27315, mean: -1.16083
[32m[0907 18-35-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.38295, current rewards: -990.27315, mean: -1.15148
[32m[0907 18-36-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.37862, current rewards: -1040.27315, mean: -1.14316
[32m[0907 18-36-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.37472, current rewards: -1090.27315, mean: -1.13570
[32m[0907 18-36-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.37118, current rewards: -1140.27315, mean: -1.12898
[32m[0907 18-36-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.36797, current rewards: -1190.27315, mean: -1.12290
[32m[0907 18-37-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.36510, current rewards: -1240.27315, mean: -1.11736
[32m[0907 18-37-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.36245, current rewards: -1290.27315, mean: -1.11230
[32m[0907 18-37-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.36004, current rewards: -1340.27315, mean: -1.10766
[32m[0907 18-37-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.35778, current rewards: -1390.27315, mean: -1.10339
[32m[0907 18-38-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.35573, current rewards: -1440.27315, mean: -1.09945
[32m[0907 18-38-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.35382, current rewards: -1490.27315, mean: -1.09579
[32m[0907 18-38-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.35206, current rewards: -1540.27315, mean: -1.09239
[32m[0907 18-38-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.35043, current rewards: -1590.27315, mean: -1.08923
[32m[0907 18-39-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.34886, current rewards: -1640.27315, mean: -1.08627
[32m[0907 18-39-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.34742, current rewards: -1690.27315, mean: -1.08351
[32m[0907 18-39-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.34609, current rewards: -1740.27315, mean: -1.08092
[32m[0907 18-39-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.34480, current rewards: -1790.27315, mean: -1.07848
[32m[0907 18-40-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.34362, current rewards: -1840.27315, mean: -1.07618
[32m[0907 18-40-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.34247, current rewards: -1890.27315, mean: -1.07402
[32m[0907 18-40-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.34138, current rewards: -1940.27315, mean: -1.07197
[32m[0907 18-40-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34037, current rewards: -1990.27315, mean: -1.07004
[32m[0907 18-41-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.33943, current rewards: -2040.27315, mean: -1.06821
[32m[0907 18-41-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.33852, current rewards: -2090.27315, mean: -1.06647
[32m[0907 18-41-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.33766, current rewards: -2140.27315, mean: -1.06481
[32m[0907 18-41-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.33685, current rewards: -2190.27315, mean: -1.06324
[32m[0907 18-42-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.33607, current rewards: -2240.27315, mean: -1.06174
[32m[0907 18-42-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.33534, current rewards: -2290.27315, mean: -1.06031
[32m[0907 18-42-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.33463, current rewards: -2340.27315, mean: -1.05895
[32m[0907 18-42-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.33393, current rewards: -2390.27315, mean: -1.05764
[32m[0907 18-43-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.33328, current rewards: -2440.27315, mean: -1.05640
[32m[0907 18-43-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.33264, current rewards: -2490.27315, mean: -1.05520
[32m[0907 18-43-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.33204, current rewards: -2540.27315, mean: -1.05406
[32m[0907 18-43-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.33145, current rewards: -2590.27315, mean: -1.05296
[32m[0907 18-44-07 @Agent.py:117][0m Average action selection time: 0.3310
[32m[0907 18-44-07 @Agent.py:118][0m Rollout length: 2600
[32m[0907 18-44-08 @MBExp.py:227][0m Rewards obtained: [-2630.273152321958], Lows: [243], Highs: [2154], Total time: 89635.86565500002
[32m[0907 18-45-25 @MBExp.py:144][0m ####################################################################
[32m[0907 18-45-25 @MBExp.py:145][0m Starting training iteration 116.
[32m[0907 18-45-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.41233, current rewards: -10.00000, mean: -1.00000
[32m[0907 18-45-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.45858, current rewards: -60.00000, mean: -1.00000
[32m[0907 18-46-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.39639, current rewards: -107.83807, mean: -0.98035
[32m[0907 18-46-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.36705, current rewards: -134.54779, mean: -0.84092
[32m[0907 18-46-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.36304, current rewards: -184.54779, mean: -0.87880
[32m[0907 18-46-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.35146, current rewards: -234.54779, mean: -0.90211
[32m[0907 18-47-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.34390, current rewards: -268.90433, mean: -0.86743
[32m[0907 18-47-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.34169, current rewards: -318.90433, mean: -0.88585
[32m[0907 18-47-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34116, current rewards: -368.90433, mean: -0.89977
[32m[0907 18-48-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34418, current rewards: -408.86065, mean: -0.88883
[32m[0907 18-48-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34641, current rewards: -458.86065, mean: -0.89973
[32m[0907 18-48-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.34258, current rewards: -541.86065, mean: -0.96761
[32m[0907 18-48-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33939, current rewards: -641.86065, mean: -1.05223
[32m[0907 18-49-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33672, current rewards: -741.86065, mean: -1.12403
[32m[0907 18-49-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33445, current rewards: -841.86065, mean: -1.18572
[32m[0907 18-49-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.33246, current rewards: -941.86065, mean: -1.23929
[32m[0907 18-49-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.33070, current rewards: -1041.86065, mean: -1.28625
[32m[0907 18-50-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32915, current rewards: -1141.86065, mean: -1.32774
[32m[0907 18-50-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32772, current rewards: -1241.86065, mean: -1.36468
[32m[0907 18-50-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32649, current rewards: -1341.86065, mean: -1.39777
[32m[0907 18-50-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32535, current rewards: -1441.86065, mean: -1.42758
[32m[0907 18-51-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32435, current rewards: -1541.86065, mean: -1.45459
[32m[0907 18-51-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32341, current rewards: -1641.86065, mean: -1.47915
[32m[0907 18-51-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32261, current rewards: -1741.86065, mean: -1.50160
[32m[0907 18-51-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.32179, current rewards: -1841.86065, mean: -1.52220
[32m[0907 18-52-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.32198, current rewards: -1937.69446, mean: -1.53785
[32m[0907 18-52-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.32454, current rewards: -2037.69446, mean: -1.55549
[32m[0907 18-52-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.32543, current rewards: -2120.20319, mean: -1.55897
[32m[0907 18-53-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.32630, current rewards: -2170.20319, mean: -1.53915
[32m[0907 18-53-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.32672, current rewards: -2213.43639, mean: -1.51605
[32m[0907 18-53-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.32594, current rewards: -2263.43639, mean: -1.49896
[32m[0907 18-53-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.32708, current rewards: -2351.33521, mean: -1.50727
[32m[0907 18-54-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.32677, current rewards: -2451.33521, mean: -1.52257
[32m[0907 18-54-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.32608, current rewards: -2513.08691, mean: -1.51391
[32m[0907 18-54-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.32673, current rewards: -2601.30012, mean: -1.52123
[32m[0907 18-55-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.33181, current rewards: -2701.30012, mean: -1.53483
[32m[0907 18-55-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.33658, current rewards: -2801.30012, mean: -1.54768
[32m[0907 18-55-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.34112, current rewards: -2807.72205, mean: -1.50953
[32m[0907 18-56-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.34541, current rewards: -2849.96051, mean: -1.49213
[32m[0907 18-56-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.34951, current rewards: -2929.08052, mean: -1.49443
[32m[0907 18-57-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.35337, current rewards: -2935.93553, mean: -1.46066
[32m[0907 18-57-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.35705, current rewards: -3035.93553, mean: -1.47376
[32m[0907 18-58-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.35950, current rewards: -3132.96641, mean: -1.48482
[32m[0907 18-58-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.35821, current rewards: -3232.96641, mean: -1.49674
[32m[0907 18-58-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.36039, current rewards: -3260.46399, mean: -1.47532
[32m[0907 18-59-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.36336, current rewards: -3310.46399, mean: -1.46481
[32m[0907 18-59-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.36568, current rewards: -3339.84103, mean: -1.44582
[32m[0907 18-59-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.36439, current rewards: -3403.83260, mean: -1.44230
[32m[0907 19-00-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.36313, current rewards: -3474.71238, mean: -1.44179
[32m[0907 19-00-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.36193, current rewards: -3524.71238, mean: -1.43281
[32m[0907 19-00-28 @Agent.py:117][0m Average action selection time: 0.3610
[32m[0907 19-00-28 @Agent.py:118][0m Rollout length: 2600
[32m[0907 19-00-28 @MBExp.py:227][0m Rewards obtained: [-3564.712376028429], Lows: [1387], Highs: [851], Total time: 90538.88606200002
[32m[0907 19-01-46 @MBExp.py:144][0m ####################################################################
[32m[0907 19-01-46 @MBExp.py:145][0m Starting training iteration 117.
[32m[0907 19-01-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.34095, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-02-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30866, current rewards: -60.00000, mean: -1.00000
[32m[0907 19-02-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30595, current rewards: -107.53407, mean: -0.97758
[32m[0907 19-02-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30501, current rewards: -157.53407, mean: -0.98459
[32m[0907 19-02-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30439, current rewards: -207.53407, mean: -0.98826
[32m[0907 19-03-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30403, current rewards: -255.33380, mean: -0.98205
[32m[0907 19-03-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30393, current rewards: -305.33380, mean: -0.98495
[32m[0907 19-03-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30396, current rewards: -355.33380, mean: -0.98704
[32m[0907 19-03-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30396, current rewards: -405.33380, mean: -0.98862
[32m[0907 19-04-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30395, current rewards: -455.33380, mean: -0.98986
[32m[0907 19-04-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30390, current rewards: -505.33380, mean: -0.99085
[32m[0907 19-04-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30514, current rewards: -555.33380, mean: -0.99167
[32m[0907 19-04-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30497, current rewards: -605.33380, mean: -0.99235
[32m[0907 19-05-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30497, current rewards: -655.25249, mean: -0.99281
[32m[0907 19-05-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30489, current rewards: -705.25249, mean: -0.99331
[32m[0907 19-05-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30480, current rewards: -755.25249, mean: -0.99375
[32m[0907 19-05-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30472, current rewards: -805.25249, mean: -0.99414
[32m[0907 19-06-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30470, current rewards: -855.25249, mean: -0.99448
[32m[0907 19-06-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30466, current rewards: -905.25249, mean: -0.99478
[32m[0907 19-06-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30464, current rewards: -955.25249, mean: -0.99505
[32m[0907 19-06-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30460, current rewards: -1005.25249, mean: -0.99530
[32m[0907 19-07-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30460, current rewards: -1055.25249, mean: -0.99552
[32m[0907 19-07-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30455, current rewards: -1105.25249, mean: -0.99572
[32m[0907 19-07-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30450, current rewards: -1155.25249, mean: -0.99591
[32m[0907 19-07-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30448, current rewards: -1205.25249, mean: -0.99608
[32m[0907 19-08-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30443, current rewards: -1255.25249, mean: -0.99623
[32m[0907 19-08-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30439, current rewards: -1305.25249, mean: -0.99638
[32m[0907 19-08-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30440, current rewards: -1355.25249, mean: -0.99651
[32m[0907 19-08-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30441, current rewards: -1405.25249, mean: -0.99663
[32m[0907 19-09-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30442, current rewards: -1455.25249, mean: -0.99675
[32m[0907 19-09-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30439, current rewards: -1505.25249, mean: -0.99686
[32m[0907 19-09-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30440, current rewards: -1555.25249, mean: -0.99696
[32m[0907 19-09-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30439, current rewards: -1605.25249, mean: -0.99705
[32m[0907 19-10-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30438, current rewards: -1655.25249, mean: -0.99714
[32m[0907 19-10-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30439, current rewards: -1705.25249, mean: -0.99722
[32m[0907 19-10-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30438, current rewards: -1755.25249, mean: -0.99730
[32m[0907 19-10-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30436, current rewards: -1805.25249, mean: -0.99738
[32m[0907 19-11-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30436, current rewards: -1855.25249, mean: -0.99745
[32m[0907 19-11-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30437, current rewards: -1905.25249, mean: -0.99751
[32m[0907 19-11-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30437, current rewards: -1955.25249, mean: -0.99758
[32m[0907 19-11-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30437, current rewards: -2005.25249, mean: -0.99764
[32m[0907 19-12-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30434, current rewards: -2083.11333, mean: -1.01122
[32m[0907 19-12-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30434, current rewards: -2183.11333, mean: -1.03465
[32m[0907 19-12-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30433, current rewards: -2283.11333, mean: -1.05700
[32m[0907 19-12-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30433, current rewards: -2383.11333, mean: -1.07833
[32m[0907 19-13-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30432, current rewards: -2483.11333, mean: -1.09872
[32m[0907 19-13-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30431, current rewards: -2583.11333, mean: -1.11823
[32m[0907 19-13-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30433, current rewards: -2683.11333, mean: -1.13691
[32m[0907 19-14-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30433, current rewards: -2783.11333, mean: -1.15482
[32m[0907 19-14-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30434, current rewards: -2883.11333, mean: -1.17200
[32m[0907 19-14-27 @Agent.py:117][0m Average action selection time: 0.3043
[32m[0907 19-14-27 @Agent.py:118][0m Rollout length: 2600
[32m[0907 19-14-27 @MBExp.py:227][0m Rewards obtained: [-2963.1133297920096], Lows: [471], Highs: [2022], Total time: 91300.24013200002
[32m[0907 19-15-47 @MBExp.py:144][0m ####################################################################
[32m[0907 19-15-47 @MBExp.py:145][0m Starting training iteration 118.
[32m[0907 19-15-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.31985, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-16-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30388, current rewards: -60.00000, mean: -1.00000
[32m[0907 19-16-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30336, current rewards: -117.94081, mean: -1.07219
[32m[0907 19-16-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.30315, current rewards: -217.94081, mean: -1.36213
[32m[0907 19-16-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.30307, current rewards: -317.94081, mean: -1.51400
[32m[0907 19-17-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.30322, current rewards: -417.94081, mean: -1.60746
[32m[0907 19-17-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.30327, current rewards: -517.94081, mean: -1.67078
[32m[0907 19-17-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.30340, current rewards: -617.94081, mean: -1.71650
[32m[0907 19-17-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.30337, current rewards: -717.94081, mean: -1.75108
[32m[0907 19-18-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.30339, current rewards: -817.94081, mean: -1.77813
[32m[0907 19-18-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.30347, current rewards: -917.94081, mean: -1.79988
[32m[0907 19-18-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.30350, current rewards: -1017.94081, mean: -1.81775
[32m[0907 19-18-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.30351, current rewards: -1117.94081, mean: -1.83269
[32m[0907 19-19-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.30359, current rewards: -1217.94081, mean: -1.84536
[32m[0907 19-19-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.30364, current rewards: -1317.94081, mean: -1.85625
[32m[0907 19-19-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.30367, current rewards: -1417.94081, mean: -1.86571
[32m[0907 19-19-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.30372, current rewards: -1517.94081, mean: -1.87400
[32m[0907 19-20-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.30370, current rewards: -1617.94081, mean: -1.88133
[32m[0907 19-20-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.30368, current rewards: -1717.94081, mean: -1.88785
[32m[0907 19-20-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.30371, current rewards: -1817.94081, mean: -1.89369
[32m[0907 19-20-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.30371, current rewards: -1917.94081, mean: -1.89895
[32m[0907 19-21-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.30374, current rewards: -2017.94081, mean: -1.90372
[32m[0907 19-21-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.30377, current rewards: -2117.94081, mean: -1.90805
[32m[0907 19-21-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.30382, current rewards: -2217.94081, mean: -1.91202
[32m[0907 19-21-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.30383, current rewards: -2317.94081, mean: -1.91565
[32m[0907 19-22-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.30385, current rewards: -2417.94081, mean: -1.91900
[32m[0907 19-22-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.30382, current rewards: -2517.94081, mean: -1.92209
[32m[0907 19-22-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.30382, current rewards: -2617.94081, mean: -1.92496
[32m[0907 19-22-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.30380, current rewards: -2717.94081, mean: -1.92762
[32m[0907 19-23-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.30380, current rewards: -2817.94081, mean: -1.93010
[32m[0907 19-23-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.30380, current rewards: -2917.94081, mean: -1.93241
[32m[0907 19-23-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.30383, current rewards: -3017.94081, mean: -1.93458
[32m[0907 19-23-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.30383, current rewards: -3117.94081, mean: -1.93661
[32m[0907 19-24-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.30384, current rewards: -3217.94081, mean: -1.93852
[32m[0907 19-24-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.30383, current rewards: -3317.94081, mean: -1.94032
[32m[0907 19-24-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.30385, current rewards: -3417.94081, mean: -1.94201
[32m[0907 19-24-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.30386, current rewards: -3517.94081, mean: -1.94361
[32m[0907 19-25-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.30387, current rewards: -3617.94081, mean: -1.94513
[32m[0907 19-25-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.30389, current rewards: -3717.94081, mean: -1.94657
[32m[0907 19-25-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.30389, current rewards: -3817.94081, mean: -1.94793
[32m[0907 19-25-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.30389, current rewards: -3917.94081, mean: -1.94922
[32m[0907 19-26-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.30392, current rewards: -4017.94081, mean: -1.95046
[32m[0907 19-26-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.30392, current rewards: -4117.94081, mean: -1.95163
[32m[0907 19-26-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.30392, current rewards: -4217.94081, mean: -1.95275
[32m[0907 19-26-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.30393, current rewards: -4317.94081, mean: -1.95382
[32m[0907 19-27-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.30393, current rewards: -4417.94081, mean: -1.95484
[32m[0907 19-27-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.30391, current rewards: -4517.94081, mean: -1.95582
[32m[0907 19-27-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.30391, current rewards: -4617.94081, mean: -1.95675
[32m[0907 19-28-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.30390, current rewards: -4717.94081, mean: -1.95765
[32m[0907 19-28-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.30389, current rewards: -4817.94081, mean: -1.95851
[32m[0907 19-28-28 @Agent.py:117][0m Average action selection time: 0.3039
[32m[0907 19-28-28 @Agent.py:118][0m Rollout length: 2600
[32m[0907 19-28-28 @MBExp.py:227][0m Rewards obtained: [-4897.940805316857], Lows: [2399], Highs: [100], Total time: 92060.45529600001
[32m[0907 19-29-47 @MBExp.py:144][0m ####################################################################
[32m[0907 19-29-47 @MBExp.py:145][0m Starting training iteration 119.
[32m[0907 19-29-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.50141, current rewards: -10.00000, mean: -1.00000
[32m[0907 19-30-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.50242, current rewards: -60.00000, mean: -1.00000
[32m[0907 19-30-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.46194, current rewards: -109.74675, mean: -0.99770
[32m[0907 19-30-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.42487, current rewards: -209.74675, mean: -1.31092
[32m[0907 19-31-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.39608, current rewards: -309.74675, mean: -1.47498
[32m[0907 19-31-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37835, current rewards: -409.74675, mean: -1.57595
[32m[0907 19-31-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36650, current rewards: -509.74675, mean: -1.64434
[32m[0907 19-31-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35780, current rewards: -609.74675, mean: -1.69374
[32m[0907 19-32-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.35108, current rewards: -709.74675, mean: -1.73109
[32m[0907 19-32-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34594, current rewards: -809.74675, mean: -1.76032
[32m[0907 19-32-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.34185, current rewards: -909.74675, mean: -1.78382
[32m[0907 19-32-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33846, current rewards: -1009.74675, mean: -1.80312
[32m[0907 19-33-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33560, current rewards: -1109.74675, mean: -1.81926
[32m[0907 19-33-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33319, current rewards: -1209.74675, mean: -1.83295
[32m[0907 19-33-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.33114, current rewards: -1309.74675, mean: -1.84471
[32m[0907 19-33-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32930, current rewards: -1409.74675, mean: -1.85493
[32m[0907 19-34-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32777, current rewards: -1509.74675, mean: -1.86388
[32m[0907 19-34-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32636, current rewards: -1609.74675, mean: -1.87180
[32m[0907 19-34-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32505, current rewards: -1709.74675, mean: -1.87884
[32m[0907 19-34-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32396, current rewards: -1809.74675, mean: -1.88515
[32m[0907 19-35-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32298, current rewards: -1909.74675, mean: -1.89084
[32m[0907 19-35-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32202, current rewards: -2009.74675, mean: -1.89599
[32m[0907 19-35-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32124, current rewards: -2109.74675, mean: -1.90067
[32m[0907 19-35-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.32048, current rewards: -2209.74675, mean: -1.90495
[32m[0907 19-36-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31979, current rewards: -2309.74675, mean: -1.90888
[32m[0907 19-36-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31917, current rewards: -2409.74675, mean: -1.91250
[32m[0907 19-36-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31857, current rewards: -2509.74675, mean: -1.91584
[32m[0907 19-37-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31801, current rewards: -2609.74675, mean: -1.91893
[32m[0907 19-37-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31751, current rewards: -2709.74675, mean: -1.92181
[32m[0907 19-37-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31705, current rewards: -2809.74675, mean: -1.92448
[32m[0907 19-37-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31663, current rewards: -2909.74675, mean: -1.92698
[32m[0907 19-38-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31622, current rewards: -3009.74675, mean: -1.92932
[32m[0907 19-38-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31586, current rewards: -3109.74675, mean: -1.93152
[32m[0907 19-38-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31552, current rewards: -3209.74675, mean: -1.93358
[32m[0907 19-38-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31517, current rewards: -3309.74675, mean: -1.93552
[32m[0907 19-39-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31487, current rewards: -3409.74675, mean: -1.93736
[32m[0907 19-39-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31455, current rewards: -3509.74675, mean: -1.93909
[32m[0907 19-39-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31427, current rewards: -3609.74675, mean: -1.94072
[32m[0907 19-39-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31400, current rewards: -3709.74675, mean: -1.94228
[32m[0907 19-40-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31375, current rewards: -3809.74675, mean: -1.94375
[32m[0907 19-40-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31350, current rewards: -3909.74675, mean: -1.94515
[32m[0907 19-40-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31328, current rewards: -4009.74675, mean: -1.94648
[32m[0907 19-40-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31304, current rewards: -4109.74675, mean: -1.94775
[32m[0907 19-41-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31283, current rewards: -4209.74675, mean: -1.94896
[32m[0907 19-41-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31263, current rewards: -4309.74675, mean: -1.95011
[32m[0907 19-41-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31245, current rewards: -4409.74675, mean: -1.95122
[32m[0907 19-41-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31227, current rewards: -4509.74675, mean: -1.95227
[32m[0907 19-42-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31209, current rewards: -4609.74675, mean: -1.95328
[32m[0907 19-42-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31192, current rewards: -4709.74675, mean: -1.95425
[32m[0907 19-42-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31175, current rewards: -4809.74675, mean: -1.95518
[32m[0907 19-42-47 @Agent.py:117][0m Average action selection time: 0.3116
[32m[0907 19-42-47 @Agent.py:118][0m Rollout length: 2600
[32m[0907 19-42-47 @MBExp.py:227][0m Rewards obtained: [-4889.746754546137], Lows: [2396], Highs: [100], Total time: 92839.97295500002
[32m[0907 19-44-07 @MBExp.py:144][0m ####################################################################
[32m[0907 19-44-07 @MBExp.py:145][0m Starting training iteration 120.
[32m[0907 19-44-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.50080, current rewards: 1.21732, mean: 0.12173
[32m[0907 19-44-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.49985, current rewards: 7.26259, mean: 0.12104
[32m[0907 19-44-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.47264, current rewards: -7.90120, mean: -0.07183
[32m[0907 19-45-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.41957, current rewards: -80.55047, mean: -0.50344
[32m[0907 19-45-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.39231, current rewards: -95.35386, mean: -0.45407
[32m[0907 19-45-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.37512, current rewards: -145.35386, mean: -0.55905
[32m[0907 19-46-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.36345, current rewards: -195.35386, mean: -0.63017
[32m[0907 19-46-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.35521, current rewards: -245.35386, mean: -0.68154
[32m[0907 19-46-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.34894, current rewards: -295.35386, mean: -0.72038
[32m[0907 19-46-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.34392, current rewards: -345.35386, mean: -0.75077
[32m[0907 19-47-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.33997, current rewards: -395.35386, mean: -0.77520
[32m[0907 19-47-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.33678, current rewards: -445.35386, mean: -0.79527
[32m[0907 19-47-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.33399, current rewards: -484.77244, mean: -0.79471
[32m[0907 19-47-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.33173, current rewards: -534.77244, mean: -0.81026
[32m[0907 19-48-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.32977, current rewards: -584.77244, mean: -0.82362
[32m[0907 19-48-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.32801, current rewards: -634.77244, mean: -0.83523
[32m[0907 19-48-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.32650, current rewards: -684.77244, mean: -0.84540
[32m[0907 19-48-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.32520, current rewards: -734.77244, mean: -0.85439
[32m[0907 19-49-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.32407, current rewards: -784.77244, mean: -0.86239
[32m[0907 19-49-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.32301, current rewards: -834.77244, mean: -0.86955
[32m[0907 19-49-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.32207, current rewards: -884.77244, mean: -0.87601
[32m[0907 19-49-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.32119, current rewards: -934.77244, mean: -0.88186
[32m[0907 19-50-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.32043, current rewards: -984.77244, mean: -0.88718
[32m[0907 19-50-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.31971, current rewards: -1034.77244, mean: -0.89205
[32m[0907 19-50-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.31905, current rewards: -1084.77244, mean: -0.89651
[32m[0907 19-50-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.31849, current rewards: -1134.77244, mean: -0.90061
[32m[0907 19-51-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.31795, current rewards: -1184.77244, mean: -0.90441
[32m[0907 19-51-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.31742, current rewards: -1234.77244, mean: -0.90792
[32m[0907 19-51-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.31698, current rewards: -1284.77244, mean: -0.91119
[32m[0907 19-51-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.31653, current rewards: -1334.77244, mean: -0.91423
[32m[0907 19-52-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.31612, current rewards: -1384.77244, mean: -0.91707
[32m[0907 19-52-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.31575, current rewards: -1434.77244, mean: -0.91973
[32m[0907 19-52-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.31540, current rewards: -1484.77244, mean: -0.92222
[32m[0907 19-52-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.31501, current rewards: -1534.77244, mean: -0.92456
[32m[0907 19-53-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.31469, current rewards: -1584.77244, mean: -0.92677
[32m[0907 19-53-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.31438, current rewards: -1634.77244, mean: -0.92885
[32m[0907 19-53-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.31408, current rewards: -1684.77244, mean: -0.93081
[32m[0907 19-53-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.31379, current rewards: -1734.77244, mean: -0.93267
[32m[0907 19-54-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.31353, current rewards: -1784.77244, mean: -0.93444
[32m[0907 19-54-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.31327, current rewards: -1834.77244, mean: -0.93611
[32m[0907 19-54-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.31305, current rewards: -1884.77244, mean: -0.93770
[32m[0907 19-54-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.31283, current rewards: -1934.77244, mean: -0.93921
[32m[0907 19-55-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.31261, current rewards: -1984.77244, mean: -0.94065
[32m[0907 19-55-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.31243, current rewards: -2034.77244, mean: -0.94202
[32m[0907 19-55-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.31223, current rewards: -2084.77244, mean: -0.94334
[32m[0907 19-55-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.31204, current rewards: -2134.77244, mean: -0.94459
[32m[0907 19-56-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.31187, current rewards: -2184.77244, mean: -0.94579
[32m[0907 19-56-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.31169, current rewards: -2234.77244, mean: -0.94694
[32m[0907 19-56-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.31153, current rewards: -2284.77244, mean: -0.94804
[32m[0907 19-56-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.31135, current rewards: -2334.77244, mean: -0.94909
[32m[0907 19-57-06 @Agent.py:117][0m Average action selection time: 0.3112
[32m[0907 19-57-06 @Agent.py:118][0m Rollout length: 2600
[32m[0907 19-57-06 @MBExp.py:227][0m Rewards obtained: [-2374.7724401249366], Lows: [48], Highs: [2297], Total time: 93618.58009900001
