[32m[0906 13-41-24 @logger.py:99][0m Log file set to /app/logs/dats-delay-10/zinc-coating-v0_4/Tuesday_06_September_2022_01-41PM.log
[32m[0906 13-41-24 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00003, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -73.12286, mean: -1.21871
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -128.98239, mean: -1.17257
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -184.94094, mean: -1.15588
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -247.28914, mean: -1.17757
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -308.37765, mean: -1.18607
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -382.27147, mean: -1.23313
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -450.48115, mean: -1.25134
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -504.36057, mean: -1.23015
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -560.19456, mean: -1.21781
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -609.98862, mean: -1.19606
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -657.15470, mean: -1.17349
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -712.69402, mean: -1.16835
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -761.41706, mean: -1.15366
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -826.91749, mean: -1.16467
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -885.74974, mean: -1.16546
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -931.91667, mean: -1.15051
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -986.95713, mean: -1.14762
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -1030.86066, mean: -1.13281
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -1075.14670, mean: -1.11994
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1128.83167, mean: -1.11766
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1177.49849, mean: -1.11085
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1226.18121, mean: -1.10467
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1272.99894, mean: -1.09741
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1327.70690, mean: -1.09728
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1379.68155, mean: -1.09499
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1426.44438, mean: -1.08889
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1475.09522, mean: -1.08463
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1533.55951, mean: -1.08763
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1588.45206, mean: -1.08798
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1636.13288, mean: -1.08353
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -1688.16425, mean: -1.08216
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -1745.84274, mean: -1.08437
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -1792.53802, mean: -1.07984
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -1842.94861, mean: -1.07775
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -1905.07830, mean: -1.08243
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -1958.31790, mean: -1.08194
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2023.32510, mean: -1.08781
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2091.20159, mean: -1.09487
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2156.45160, mean: -1.10023
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2222.25239, mean: -1.10560
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2282.22765, mean: -1.10788
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2354.07507, mean: -1.11568
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2433.39521, mean: -1.12657
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2507.85938, mean: -1.13478
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2579.88046, mean: -1.14154
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2655.01034, mean: -1.14936
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2724.97791, mean: -1.15465
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2796.45795, mean: -1.16036
[32m[0906 13-41-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2859.17842, mean: -1.16227
[32m[0906 13-41-24 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-41-24 @Agent.py:118][0m Rollout length: 2510
[32m[0906 13-41-27 @MBExp.py:144][0m ####################################################################
[32m[0906 13-41-27 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-41-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20855, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-41-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19379, current rewards: -94.09388, mean: -1.56823
[32m[0906 13-41-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19174, current rewards: -194.09388, mean: -1.76449
[32m[0906 13-41-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19158, current rewards: -294.09388, mean: -1.83809
[32m[0906 13-42-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19113, current rewards: -394.09388, mean: -1.87664
[32m[0906 13-42-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19062, current rewards: -494.09388, mean: -1.90036
[32m[0906 13-42-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19019, current rewards: -594.09388, mean: -1.91643
[32m[0906 13-42-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19007, current rewards: -694.09388, mean: -1.92804
[32m[0906 13-42-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18978, current rewards: -794.09388, mean: -1.93681
[32m[0906 13-42-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18965, current rewards: -894.09388, mean: -1.94368
[32m[0906 13-43-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18952, current rewards: -994.09388, mean: -1.94920
[32m[0906 13-43-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18940, current rewards: -1094.09388, mean: -1.95374
[32m[0906 13-43-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18924, current rewards: -1194.09388, mean: -1.95753
[32m[0906 13-43-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18921, current rewards: -1294.09388, mean: -1.96075
[32m[0906 13-43-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18925, current rewards: -1394.09388, mean: -1.96351
[32m[0906 13-43-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18924, current rewards: -1494.09388, mean: -1.96591
[32m[0906 13-44-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18921, current rewards: -1594.09388, mean: -1.96802
[32m[0906 13-44-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18918, current rewards: -1694.09388, mean: -1.96988
[32m[0906 13-44-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18914, current rewards: -1794.09388, mean: -1.97153
[32m[0906 13-44-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18907, current rewards: -1894.09388, mean: -1.97301
[32m[0906 13-44-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18905, current rewards: -1987.23552, mean: -1.96756
[32m[0906 13-44-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18903, current rewards: -2087.23552, mean: -1.96909
[32m[0906 13-44-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18901, current rewards: -2187.23552, mean: -1.97048
[32m[0906 13-45-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18898, current rewards: -2287.23552, mean: -1.97175
[32m[0906 13-45-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18889, current rewards: -2387.23552, mean: -1.97292
[32m[0906 13-45-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18887, current rewards: -2477.07009, mean: -1.96593
[32m[0906 13-45-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18881, current rewards: -2558.38615, mean: -1.95297
[32m[0906 13-45-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18881, current rewards: -2658.38615, mean: -1.95470
[32m[0906 13-45-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18879, current rewards: -2758.38615, mean: -1.95630
[32m[0906 13-46-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18876, current rewards: -2858.38615, mean: -1.95780
[32m[0906 13-46-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18871, current rewards: -2958.38615, mean: -1.95920
[32m[0906 13-46-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18865, current rewards: -3058.38615, mean: -1.96050
[32m[0906 13-46-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18865, current rewards: -3158.38615, mean: -1.96173
[32m[0906 13-46-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18863, current rewards: -3258.38615, mean: -1.96288
[32m[0906 13-46-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18861, current rewards: -3347.38615, mean: -1.95754
[32m[0906 13-46-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18858, current rewards: -3447.38615, mean: -1.95874
[32m[0906 13-47-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18853, current rewards: -3547.38615, mean: -1.95988
[32m[0906 13-47-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18849, current rewards: -3647.38615, mean: -1.96096
[32m[0906 13-47-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18844, current rewards: -3747.38615, mean: -1.96198
[32m[0906 13-47-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18841, current rewards: -3847.38615, mean: -1.96295
[32m[0906 13-47-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18838, current rewards: -3947.38615, mean: -1.96387
[32m[0906 13-47-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18835, current rewards: -4047.38615, mean: -1.96475
[32m[0906 13-48-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18831, current rewards: -4147.38615, mean: -1.96559
[32m[0906 13-48-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18831, current rewards: -4247.38615, mean: -1.96638
[32m[0906 13-48-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18828, current rewards: -4347.38615, mean: -1.96714
[32m[0906 13-48-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18824, current rewards: -4447.38615, mean: -1.96787
[32m[0906 13-48-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18824, current rewards: -4547.38615, mean: -1.96857
[32m[0906 13-48-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18822, current rewards: -4647.38615, mean: -1.96923
[32m[0906 13-49-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18818, current rewards: -4747.38615, mean: -1.96987
[32m[0906 13-49-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18815, current rewards: -4847.38615, mean: -1.97048
[32m[0906 13-49-18 @Agent.py:117][0m Average action selection time: 0.1881
[32m[0906 13-49-18 @Agent.py:118][0m Rollout length: 2510
[32m[0906 13-49-18 @MBExp.py:227][0m Rewards obtained: [-4927.3861502252785], Lows: [2454], Highs: [28], Total time: 470.960821
[32m[0906 13-49-22 @MBExp.py:144][0m ####################################################################
[32m[0906 13-49-22 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-49-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18678, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-49-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18597, current rewards: -23.29007, mean: -0.38817
[32m[0906 13-49-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18521, current rewards: -19.96193, mean: -0.18147
[32m[0906 13-49-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18494, current rewards: -16.63675, mean: -0.10398
[32m[0906 13-50-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18544, current rewards: -13.30882, mean: -0.06338
[32m[0906 13-50-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18547, current rewards: -9.98218, mean: -0.03839
[32m[0906 13-50-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18527, current rewards: -6.65105, mean: -0.02146
[32m[0906 13-50-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18522, current rewards: -3.32272, mean: -0.00923
[32m[0906 13-50-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18519, current rewards: 0.13378, mean: 0.00033
[32m[0906 13-50-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18515, current rewards: 5.85848, mean: 0.01274
[32m[0906 13-50-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18516, current rewards: 11.38971, mean: 0.02233
[32m[0906 13-51-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18516, current rewards: 16.93177, mean: 0.03024
[32m[0906 13-51-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18508, current rewards: 22.46652, mean: 0.03683
[32m[0906 13-51-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18501, current rewards: 7.95438, mean: 0.01205
[32m[0906 13-51-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18495, current rewards: 15.47374, mean: 0.02179
[32m[0906 13-51-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18499, current rewards: 22.81533, mean: 0.03002
[32m[0906 13-51-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18495, current rewards: 30.14828, mean: 0.03722
[32m[0906 13-52-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18493, current rewards: 36.43574, mean: 0.04237
[32m[0906 13-52-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18495, current rewards: 42.41943, mean: 0.04661
[32m[0906 13-52-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18494, current rewards: 48.41116, mean: 0.05043
[32m[0906 13-52-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18492, current rewards: 54.39566, mean: 0.05386
[32m[0906 13-52-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18489, current rewards: 61.04029, mean: 0.05759
[32m[0906 13-52-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18484, current rewards: 69.63048, mean: 0.06273
[32m[0906 13-52-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18484, current rewards: 78.22962, mean: 0.06744
[32m[0906 13-53-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18485, current rewards: 86.82295, mean: 0.07175
[32m[0906 13-53-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18482, current rewards: 94.93120, mean: 0.07534
[32m[0906 13-53-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18482, current rewards: 102.85195, mean: 0.07851
[32m[0906 13-53-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18483, current rewards: 110.75751, mean: 0.08144
[32m[0906 13-53-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18481, current rewards: 118.65956, mean: 0.08416
[32m[0906 13-53-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18480, current rewards: 126.58404, mean: 0.08670
[32m[0906 13-54-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18476, current rewards: 134.48733, mean: 0.08906
[32m[0906 13-54-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18475, current rewards: 142.39667, mean: 0.09128
[32m[0906 13-54-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18477, current rewards: 150.30896, mean: 0.09336
[32m[0906 13-54-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18477, current rewards: 102.12316, mean: 0.06152
[32m[0906 13-54-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18474, current rewards: 2.12316, mean: 0.00124
[32m[0906 13-54-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18474, current rewards: -97.87684, mean: -0.05561
[32m[0906 13-54-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18473, current rewards: -197.87684, mean: -0.10932
[32m[0906 13-55-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18472, current rewards: -297.87684, mean: -0.16015
[32m[0906 13-55-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18465, current rewards: -397.87684, mean: -0.20831
[32m[0906 13-55-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18467, current rewards: -497.87684, mean: -0.25402
[32m[0906 13-55-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18470, current rewards: -597.87684, mean: -0.29745
[32m[0906 13-55-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18470, current rewards: -697.87684, mean: -0.33878
[32m[0906 13-55-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18469, current rewards: -797.87684, mean: -0.37814
[32m[0906 13-56-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18472, current rewards: -897.87684, mean: -0.41568
[32m[0906 13-56-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18470, current rewards: -997.87684, mean: -0.45153
[32m[0906 13-56-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18470, current rewards: -1077.02562, mean: -0.47656
[32m[0906 13-56-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18472, current rewards: -1070.41070, mean: -0.46338
[32m[0906 13-56-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18472, current rewards: -1063.85142, mean: -0.45078
[32m[0906 13-56-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18473, current rewards: -1057.28812, mean: -0.43871
[32m[0906 13-56-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18473, current rewards: -1050.73487, mean: -0.42713
[32m[0906 13-57-04 @Agent.py:117][0m Average action selection time: 0.1847
[32m[0906 13-57-04 @Agent.py:118][0m Rollout length: 2510
[32m[0906 13-57-04 @MBExp.py:227][0m Rewards obtained: [-1045.4871489773172], Lows: [634], Highs: [11], Total time: 933.459134
[32m[0906 13-57-11 @MBExp.py:144][0m ####################################################################
[32m[0906 13-57-11 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-57-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18599, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-57-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18560, current rewards: -4.46414, mean: -0.07440
[32m[0906 13-57-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18558, current rewards: 2.34278, mean: 0.02130
[32m[0906 13-57-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18547, current rewards: 9.14744, mean: 0.05717
[32m[0906 13-57-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18564, current rewards: 15.95348, mean: 0.07597
[32m[0906 13-57-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18556, current rewards: 22.75548, mean: 0.08752
[32m[0906 13-58-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18558, current rewards: 29.56331, mean: 0.09537
[32m[0906 13-58-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18558, current rewards: 36.36800, mean: 0.10102
[32m[0906 13-58-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18561, current rewards: 42.19781, mean: 0.10292
[32m[0906 13-58-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18550, current rewards: 47.99607, mean: 0.10434
[32m[0906 13-58-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18545, current rewards: 41.22426, mean: 0.08083
[32m[0906 13-58-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18535, current rewards: 46.19761, mean: 0.08250
[32m[0906 13-59-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18538, current rewards: 51.16729, mean: 0.08388
[32m[0906 13-59-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18530, current rewards: 56.13015, mean: 0.08505
[32m[0906 13-59-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18526, current rewards: 61.09515, mean: 0.08605
[32m[0906 13-59-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18523, current rewards: 66.05932, mean: 0.08692
[32m[0906 13-59-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18516, current rewards: 71.58304, mean: 0.08837
[32m[0906 13-59-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18512, current rewards: 77.16096, mean: 0.08972
[32m[0906 14-00-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18509, current rewards: 82.73478, mean: 0.09092
[32m[0906 14-00-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18510, current rewards: 88.31538, mean: 0.09200
[32m[0906 14-00-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18508, current rewards: 70.77510, mean: 0.07007
[32m[0906 14-00-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18518, current rewards: 76.82150, mean: 0.07247
[32m[0906 14-00-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18517, current rewards: 82.86677, mean: 0.07465
[32m[0906 14-00-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18515, current rewards: 88.91203, mean: 0.07665
[32m[0906 14-00-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18513, current rewards: 73.21227, mean: 0.06051
[32m[0906 14-01-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18512, current rewards: 79.14852, mean: 0.06282
[32m[0906 14-01-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18512, current rewards: 85.07956, mean: 0.06495
[32m[0906 14-01-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18508, current rewards: 91.01004, mean: 0.06692
[32m[0906 14-01-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18506, current rewards: 96.94669, mean: 0.06876
[32m[0906 14-01-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18504, current rewards: 102.88255, mean: 0.07047
[32m[0906 14-01-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18500, current rewards: 108.81561, mean: 0.07206
[32m[0906 14-02-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18490, current rewards: 98.51805, mean: 0.06315
[32m[0906 14-02-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18494, current rewards: 107.51968, mean: 0.06678
[32m[0906 14-02-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18494, current rewards: 115.17047, mean: 0.06938
[32m[0906 14-02-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18492, current rewards: 122.83351, mean: 0.07183
[32m[0906 14-02-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18496, current rewards: 130.48404, mean: 0.07414
[32m[0906 14-02-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18498, current rewards: 126.59331, mean: 0.06994
[32m[0906 14-02-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18498, current rewards: 131.80783, mean: 0.07086
[32m[0906 14-03-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18488, current rewards: 137.06754, mean: 0.07176
[32m[0906 14-03-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18490, current rewards: 142.32331, mean: 0.07261
[32m[0906 14-03-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18492, current rewards: 146.77578, mean: 0.07302
[32m[0906 14-03-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18494, current rewards: 150.16081, mean: 0.07289
[32m[0906 14-03-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18486, current rewards: 153.54730, mean: 0.07277
[32m[0906 14-03-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18487, current rewards: 156.92939, mean: 0.07265
[32m[0906 14-04-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18488, current rewards: 160.31440, mean: 0.07254
[32m[0906 14-04-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18481, current rewards: 163.69951, mean: 0.07243
[32m[0906 14-04-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18485, current rewards: 167.08262, mean: 0.07233
[32m[0906 14-04-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18487, current rewards: 170.46809, mean: 0.07223
[32m[0906 14-04-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18490, current rewards: 173.93467, mean: 0.07217
[32m[0906 14-04-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18493, current rewards: 179.03597, mean: 0.07278
[32m[0906 14-04-54 @Agent.py:117][0m Average action selection time: 0.1849
[32m[0906 14-04-54 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-04-54 @MBExp.py:227][0m Rewards obtained: [183.00653355287045], Lows: [21], Highs: [52], Total time: 1396.4626979999998
[32m[0906 14-05-03 @MBExp.py:144][0m ####################################################################
[32m[0906 14-05-03 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 14-05-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18641, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-05-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18662, current rewards: -3.41586, mean: -0.05693
[32m[0906 14-05-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18581, current rewards: 4.25730, mean: 0.03870
[32m[0906 14-05-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18553, current rewards: 11.94421, mean: 0.07465
[32m[0906 14-05-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18537, current rewards: 19.62239, mean: 0.09344
[32m[0906 14-05-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18522, current rewards: 27.30020, mean: 0.10500
[32m[0906 14-06-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18507, current rewards: 34.98213, mean: 0.11285
[32m[0906 14-06-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18489, current rewards: 41.32022, mean: 0.11478
[32m[0906 14-06-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18490, current rewards: 47.08178, mean: 0.11483
[32m[0906 14-06-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18485, current rewards: 52.84994, mean: 0.11489
[32m[0906 14-06-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18475, current rewards: 36.91352, mean: 0.07238
[32m[0906 14-06-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18479, current rewards: 41.54530, mean: 0.07419
[32m[0906 14-06-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18479, current rewards: 46.17560, mean: 0.07570
[32m[0906 14-07-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18473, current rewards: 50.80727, mean: 0.07698
[32m[0906 14-07-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18466, current rewards: 55.43456, mean: 0.07808
[32m[0906 14-07-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18460, current rewards: 59.48881, mean: 0.07827
[32m[0906 14-07-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18461, current rewards: 63.45465, mean: 0.07834
[32m[0906 14-07-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18462, current rewards: 67.51695, mean: 0.07851
[32m[0906 14-07-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18463, current rewards: 71.57878, mean: 0.07866
[32m[0906 14-08-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18460, current rewards: 75.63797, mean: 0.07879
[32m[0906 14-08-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18456, current rewards: 79.69993, mean: 0.07891
[32m[0906 14-08-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18455, current rewards: 83.76011, mean: 0.07902
[32m[0906 14-08-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18455, current rewards: 87.82280, mean: 0.07912
[32m[0906 14-08-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18454, current rewards: 81.80295, mean: 0.07052
[32m[0906 14-08-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18454, current rewards: 91.85903, mean: 0.07592
[32m[0906 14-08-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18456, current rewards: 99.94632, mean: 0.07932
[32m[0906 14-09-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18457, current rewards: 108.03560, mean: 0.08247
[32m[0906 14-09-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18454, current rewards: 93.50838, mean: 0.06876
[32m[0906 14-09-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18455, current rewards: 99.39592, mean: 0.07049
[32m[0906 14-09-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18455, current rewards: 105.28860, mean: 0.07212
[32m[0906 14-09-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18451, current rewards: 111.18194, mean: 0.07363
[32m[0906 14-09-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18438, current rewards: 117.07372, mean: 0.07505
[32m[0906 14-10-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18441, current rewards: 122.54060, mean: 0.07611
[32m[0906 14-10-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18441, current rewards: 128.05329, mean: 0.07714
[32m[0906 14-10-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18443, current rewards: 133.57564, mean: 0.07811
[32m[0906 14-10-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18444, current rewards: 139.09081, mean: 0.07903
[32m[0906 14-10-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18446, current rewards: 133.37591, mean: 0.07369
[32m[0906 14-10-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18444, current rewards: 138.41076, mean: 0.07441
[32m[0906 14-10-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18437, current rewards: 143.45183, mean: 0.07511
[32m[0906 14-11-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18442, current rewards: 148.49268, mean: 0.07576
[32m[0906 14-11-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18445, current rewards: 153.21970, mean: 0.07623
[32m[0906 14-11-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18445, current rewards: 157.87412, mean: 0.07664
[32m[0906 14-11-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18436, current rewards: 162.53316, mean: 0.07703
[32m[0906 14-11-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18438, current rewards: 167.19085, mean: 0.07740
[32m[0906 14-11-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18441, current rewards: 161.18694, mean: 0.07294
[32m[0906 14-12-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18432, current rewards: 166.68721, mean: 0.07376
[32m[0906 14-12-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18433, current rewards: 172.16363, mean: 0.07453
[32m[0906 14-12-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18435, current rewards: 177.64074, mean: 0.07527
[32m[0906 14-12-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18436, current rewards: 182.42900, mean: 0.07570
[32m[0906 14-12-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18438, current rewards: 186.95104, mean: 0.07600
[32m[0906 14-12-44 @Agent.py:117][0m Average action selection time: 0.1844
[32m[0906 14-12-44 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-12-44 @MBExp.py:227][0m Rewards obtained: [190.5500091962363], Lows: [20], Highs: [41], Total time: 1858.089695
[32m[0906 14-12-55 @MBExp.py:144][0m ####################################################################
[32m[0906 14-12-55 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 14-12-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18673, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-13-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18733, current rewards: -7.88312, mean: -0.13139
[32m[0906 14-13-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18655, current rewards: -4.81417, mean: -0.04377
[32m[0906 14-13-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18620, current rewards: -1.74675, mean: -0.01092
[32m[0906 14-13-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18592, current rewards: 1.31929, mean: 0.00628
[32m[0906 14-13-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18570, current rewards: 4.38612, mean: 0.01687
[32m[0906 14-13-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18570, current rewards: 7.44953, mean: 0.02403
[32m[0906 14-14-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18553, current rewards: 1.99379, mean: 0.00554
[32m[0906 14-14-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18535, current rewards: 5.29796, mean: 0.01292
[32m[0906 14-14-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18533, current rewards: -12.00369, mean: -0.02609
[32m[0906 14-14-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18529, current rewards: -9.16271, mean: -0.01797
[32m[0906 14-14-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18537, current rewards: -6.72736, mean: -0.01201
[32m[0906 14-14-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18529, current rewards: -4.29149, mean: -0.00704
[32m[0906 14-14-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18529, current rewards: -1.85550, mean: -0.00281
[32m[0906 14-15-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18529, current rewards: 0.57959, mean: 0.00082
[32m[0906 14-15-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18530, current rewards: 3.13055, mean: 0.00412
[32m[0906 14-15-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18528, current rewards: 5.63632, mean: 0.00696
[32m[0906 14-15-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18517, current rewards: 8.14196, mean: 0.00947
[32m[0906 14-15-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18513, current rewards: 10.64807, mean: 0.01170
[32m[0906 14-15-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18511, current rewards: 13.15310, mean: 0.01370
[32m[0906 14-16-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18508, current rewards: 16.89438, mean: 0.01673
[32m[0906 14-16-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18507, current rewards: 8.15643, mean: 0.00769
[32m[0906 14-16-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18504, current rewards: -0.61968, mean: -0.00056
[32m[0906 14-16-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18500, current rewards: -15.65306, mean: -0.01349
[32m[0906 14-16-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18498, current rewards: -12.20125, mean: -0.01008
[32m[0906 14-16-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18497, current rewards: -8.68075, mean: -0.00689
[32m[0906 14-16-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18496, current rewards: -5.15449, mean: -0.00393
[32m[0906 14-17-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18495, current rewards: -1.63126, mean: -0.00120
[32m[0906 14-17-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18497, current rewards: -18.71462, mean: -0.01327
[32m[0906 14-17-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18495, current rewards: -12.82797, mean: -0.00879
[32m[0906 14-17-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18492, current rewards: -5.33898, mean: -0.00354
[32m[0906 14-17-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18477, current rewards: 1.86096, mean: 0.00119
[32m[0906 14-17-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18476, current rewards: 9.05318, mean: 0.00562
[32m[0906 14-18-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18477, current rewards: 16.63399, mean: 0.01002
[32m[0906 14-18-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18480, current rewards: 24.20629, mean: 0.01416
[32m[0906 14-18-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18482, current rewards: 31.79366, mean: 0.01806
[32m[0906 14-18-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18484, current rewards: 39.38368, mean: 0.02176
[32m[0906 14-18-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18480, current rewards: 46.95728, mean: 0.02525
[32m[0906 14-18-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18469, current rewards: 54.54184, mean: 0.02856
[32m[0906 14-18-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18473, current rewards: 50.49120, mean: 0.02576
[32m[0906 14-19-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18472, current rewards: 53.77186, mean: 0.02675
[32m[0906 14-19-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18475, current rewards: 56.86431, mean: 0.02760
[32m[0906 14-19-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18465, current rewards: 59.95432, mean: 0.02841
[32m[0906 14-19-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18463, current rewards: 63.04740, mean: 0.02919
[32m[0906 14-19-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18467, current rewards: 66.14027, mean: 0.02993
[32m[0906 14-19-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18459, current rewards: 69.23149, mean: 0.03063
[32m[0906 14-20-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18457, current rewards: 72.32537, mean: 0.03131
[32m[0906 14-20-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18460, current rewards: 75.41916, mean: 0.03196
[32m[0906 14-20-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18462, current rewards: 79.04289, mean: 0.03280
[32m[0906 14-20-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18461, current rewards: 82.11847, mean: 0.03338
[32m[0906 14-20-37 @Agent.py:117][0m Average action selection time: 0.1846
[32m[0906 14-20-37 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-20-37 @MBExp.py:227][0m Rewards obtained: [74.05402513454295], Lows: [20], Highs: [78], Total time: 2320.2875919999997
[32m[0906 14-20-50 @MBExp.py:144][0m ####################################################################
[32m[0906 14-20-50 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 14-20-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18589, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-21-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18614, current rewards: -21.11534, mean: -0.35192
[32m[0906 14-21-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18536, current rewards: -9.17381, mean: -0.08340
[32m[0906 14-21-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18547, current rewards: 2.75185, mean: 0.01720
[32m[0906 14-21-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18564, current rewards: 14.66861, mean: 0.06985
[32m[0906 14-21-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18547, current rewards: 26.56317, mean: 0.10217
[32m[0906 14-21-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18537, current rewards: 35.66930, mean: 0.11506
[32m[0906 14-21-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18525, current rewards: 44.81334, mean: 0.12448
[32m[0906 14-22-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18517, current rewards: 39.35063, mean: 0.09598
[32m[0906 14-22-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18516, current rewards: 45.53573, mean: 0.09899
[32m[0906 14-22-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18515, current rewards: 51.70011, mean: 0.10137
[32m[0906 14-22-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18507, current rewards: 57.86463, mean: 0.10333
[32m[0906 14-22-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18509, current rewards: 64.02907, mean: 0.10497
[32m[0906 14-22-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18505, current rewards: 70.19166, mean: 0.10635
[32m[0906 14-23-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18506, current rewards: 77.46815, mean: 0.10911
[32m[0906 14-23-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18502, current rewards: 85.94789, mean: 0.11309
[32m[0906 14-23-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18503, current rewards: 70.43960, mean: 0.08696
[32m[0906 14-23-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18506, current rewards: 80.63538, mean: 0.09376
[32m[0906 14-23-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18509, current rewards: 97.75650, mean: 0.10742
[32m[0906 14-23-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18507, current rewards: 114.92068, mean: 0.11971
[32m[0906 14-23-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18504, current rewards: 132.04627, mean: 0.13074
[32m[0906 14-24-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18503, current rewards: 149.18272, mean: 0.14074
[32m[0906 14-24-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18501, current rewards: 166.34518, mean: 0.14986
[32m[0906 14-24-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18499, current rewards: 163.52626, mean: 0.14097
[32m[0906 14-24-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18496, current rewards: 178.19281, mean: 0.14727
[32m[0906 14-24-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18497, current rewards: 192.84977, mean: 0.15306
[32m[0906 14-24-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18495, current rewards: 189.31373, mean: 0.14451
[32m[0906 14-25-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18495, current rewards: 197.84913, mean: 0.14548
[32m[0906 14-25-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18496, current rewards: 206.39132, mean: 0.14638
[32m[0906 14-25-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18496, current rewards: 214.95292, mean: 0.14723
[32m[0906 14-25-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18492, current rewards: 223.49411, mean: 0.14801
[32m[0906 14-25-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18480, current rewards: 217.11825, mean: 0.13918
[32m[0906 14-25-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18475, current rewards: 223.08445, mean: 0.13856
[32m[0906 14-25-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18479, current rewards: 229.05398, mean: 0.13798
[32m[0906 14-26-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18479, current rewards: 235.02376, mean: 0.13744
[32m[0906 14-26-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18478, current rewards: 241.00016, mean: 0.13693
[32m[0906 14-26-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18479, current rewards: 246.97334, mean: 0.13645
[32m[0906 14-26-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18471, current rewards: 252.94223, mean: 0.13599
[32m[0906 14-26-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18460, current rewards: 258.92910, mean: 0.13556
[32m[0906 14-26-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18463, current rewards: 266.16216, mean: 0.13580
[32m[0906 14-27-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18464, current rewards: 272.73807, mean: 0.13569
[32m[0906 14-27-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18467, current rewards: 279.33197, mean: 0.13560
[32m[0906 14-27-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18459, current rewards: 285.93214, mean: 0.13551
[32m[0906 14-27-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18454, current rewards: 278.03774, mean: 0.12872
[32m[0906 14-27-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18457, current rewards: 293.79438, mean: 0.13294
[32m[0906 14-27-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18452, current rewards: 309.58746, mean: 0.13699
[32m[0906 14-27-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18447, current rewards: 325.30694, mean: 0.14083
[32m[0906 14-28-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18451, current rewards: 341.04642, mean: 0.14451
[32m[0906 14-28-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18456, current rewards: 356.81608, mean: 0.14806
[32m[0906 14-28-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18458, current rewards: 372.53429, mean: 0.15144
[32m[0906 14-28-32 @Agent.py:117][0m Average action selection time: 0.1846
[32m[0906 14-28-32 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-28-32 @MBExp.py:227][0m Rewards obtained: [385.1777030469284], Lows: [45], Highs: [42], Total time: 2782.3923459999996
[32m[0906 14-28-47 @MBExp.py:144][0m ####################################################################
[32m[0906 14-28-47 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 14-28-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18585, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-28-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18541, current rewards: -7.93374, mean: -0.13223
[32m[0906 14-29-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18527, current rewards: -3.76339, mean: -0.03421
[32m[0906 14-29-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18533, current rewards: 0.36725, mean: 0.00230
[32m[0906 14-29-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18544, current rewards: 4.49649, mean: 0.02141
[32m[0906 14-29-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18548, current rewards: 8.62393, mean: 0.03317
[32m[0906 14-29-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18532, current rewards: 12.72004, mean: 0.04103
[32m[0906 14-29-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18534, current rewards: 16.83999, mean: 0.04678
[32m[0906 14-30-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18523, current rewards: 20.95291, mean: 0.05110
[32m[0906 14-30-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18518, current rewards: 25.06424, mean: 0.05449
[32m[0906 14-30-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18509, current rewards: 29.17772, mean: 0.05721
[32m[0906 14-30-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18500, current rewards: 10.76784, mean: 0.01923
[32m[0906 14-30-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18495, current rewards: 14.02716, mean: 0.02300
[32m[0906 14-30-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18491, current rewards: 17.28668, mean: 0.02619
[32m[0906 14-30-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18485, current rewards: 20.54495, mean: 0.02894
[32m[0906 14-31-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18485, current rewards: 23.80337, mean: 0.03132
[32m[0906 14-31-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18483, current rewards: 27.06275, mean: 0.03341
[32m[0906 14-31-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18484, current rewards: 30.32213, mean: 0.03526
[32m[0906 14-31-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18480, current rewards: 33.58143, mean: 0.03690
[32m[0906 14-31-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18479, current rewards: 28.57821, mean: 0.02977
[32m[0906 14-31-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18482, current rewards: 19.71229, mean: 0.01952
[32m[0906 14-32-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18484, current rewards: 23.09497, mean: 0.02179
[32m[0906 14-32-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18481, current rewards: 25.83729, mean: 0.02328
[32m[0906 14-32-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18478, current rewards: 28.42451, mean: 0.02450
[32m[0906 14-32-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18479, current rewards: 31.01174, mean: 0.02563
[32m[0906 14-32-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18476, current rewards: 33.59896, mean: 0.02667
[32m[0906 14-32-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18475, current rewards: 36.18618, mean: 0.02762
[32m[0906 14-32-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18473, current rewards: 0.91061, mean: 0.00067
[32m[0906 14-33-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18473, current rewards: -13.22829, mean: -0.00938
[32m[0906 14-33-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18471, current rewards: -9.15860, mean: -0.00627
[32m[0906 14-33-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18472, current rewards: -3.72006, mean: -0.00246
[32m[0906 14-33-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18459, current rewards: 1.19307, mean: 0.00076
[32m[0906 14-33-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18452, current rewards: 6.09657, mean: 0.00379
[32m[0906 14-33-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18457, current rewards: 10.99913, mean: 0.00663
[32m[0906 14-34-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18463, current rewards: 15.90338, mean: 0.00930
[32m[0906 14-34-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18466, current rewards: 20.80543, mean: 0.01182
[32m[0906 14-34-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18470, current rewards: 14.72864, mean: 0.00814
[32m[0906 14-34-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18459, current rewards: 18.90662, mean: 0.01016
[32m[0906 14-34-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18449, current rewards: 22.83800, mean: 0.01196
[32m[0906 14-34-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18453, current rewards: 26.82796, mean: 0.01369
[32m[0906 14-34-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18457, current rewards: 30.94466, mean: 0.01540
[32m[0906 14-35-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18461, current rewards: 35.05874, mean: 0.01702
[32m[0906 14-35-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18452, current rewards: 39.17278, mean: 0.01857
[32m[0906 14-35-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18444, current rewards: 32.65676, mean: 0.01512
[32m[0906 14-35-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18448, current rewards: 36.37110, mean: 0.01646
[32m[0906 14-35-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18444, current rewards: 40.06736, mean: 0.01773
[32m[0906 14-35-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18436, current rewards: 43.76456, mean: 0.01895
[32m[0906 14-36-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18441, current rewards: 48.29378, mean: 0.02046
[32m[0906 14-36-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18454, current rewards: 29.96637, mean: 0.01243
[32m[0906 14-36-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18463, current rewards: 34.91453, mean: 0.01419
[32m[0906 14-36-29 @Agent.py:117][0m Average action selection time: 0.1846
[32m[0906 14-36-29 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-36-29 @MBExp.py:227][0m Rewards obtained: [38.875476668694326], Lows: [32], Highs: [86], Total time: 3244.6381779999997
[32m[0906 14-36-46 @MBExp.py:144][0m ####################################################################
[32m[0906 14-36-46 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 14-36-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18536, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-36-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18546, current rewards: -109.00000, mean: -1.81667
[32m[0906 14-37-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18586, current rewards: -209.00000, mean: -1.90000
[32m[0906 14-37-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18623, current rewards: -309.00000, mean: -1.93125
[32m[0906 14-37-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18605, current rewards: -409.00000, mean: -1.94762
[32m[0906 14-37-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18571, current rewards: -509.00000, mean: -1.95769
[32m[0906 14-37-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18565, current rewards: -609.00000, mean: -1.96452
[32m[0906 14-37-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18556, current rewards: -709.00000, mean: -1.96944
[32m[0906 14-38-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18550, current rewards: -791.84876, mean: -1.93134
[32m[0906 14-38-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18551, current rewards: -786.88593, mean: -1.71062
[32m[0906 14-38-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18548, current rewards: -782.18247, mean: -1.53369
[32m[0906 14-38-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18540, current rewards: -777.48199, mean: -1.38836
[32m[0906 14-38-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18536, current rewards: -772.77930, mean: -1.26685
[32m[0906 14-38-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18534, current rewards: -768.10058, mean: -1.16379
[32m[0906 14-38-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18528, current rewards: -764.06356, mean: -1.07615
[32m[0906 14-39-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18527, current rewards: -774.22515, mean: -1.01872
[32m[0906 14-39-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18523, current rewards: -778.97961, mean: -0.96170
[32m[0906 14-39-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18517, current rewards: -775.65953, mean: -0.90193
[32m[0906 14-39-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18514, current rewards: -772.33865, mean: -0.84872
[32m[0906 14-39-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18515, current rewards: -769.01851, mean: -0.80106
[32m[0906 14-39-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18515, current rewards: -765.69828, mean: -0.75812
[32m[0906 14-40-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18514, current rewards: -762.37820, mean: -0.71922
[32m[0906 14-40-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18513, current rewards: -758.80780, mean: -0.68361
[32m[0906 14-40-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18514, current rewards: -776.33928, mean: -0.66926
[32m[0906 14-40-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18512, current rewards: -787.87902, mean: -0.65114
[32m[0906 14-40-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18514, current rewards: -790.83119, mean: -0.62764
[32m[0906 14-40-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18514, current rewards: -795.91606, mean: -0.60757
[32m[0906 14-40-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18513, current rewards: -798.86531, mean: -0.58740
[32m[0906 14-41-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18510, current rewards: -803.95747, mean: -0.57018
[32m[0906 14-41-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18508, current rewards: -809.02728, mean: -0.55413
[32m[0906 14-41-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18506, current rewards: -807.71974, mean: -0.53491
[32m[0906 14-41-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18490, current rewards: -802.12696, mean: -0.51418
[32m[0906 14-41-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18477, current rewards: -796.52809, mean: -0.49474
[32m[0906 14-41-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18481, current rewards: -790.92942, mean: -0.47646
[32m[0906 14-42-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18483, current rewards: -833.27172, mean: -0.48729
[32m[0906 14-42-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18485, current rewards: -870.41738, mean: -0.49456
[32m[0906 14-42-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18485, current rewards: -916.23151, mean: -0.50621
[32m[0906 14-42-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18474, current rewards: -951.20842, mean: -0.51140
[32m[0906 14-42-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18462, current rewards: -1004.09383, mean: -0.52570
[32m[0906 14-42-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18465, current rewards: -1090.17765, mean: -0.55621
[32m[0906 14-42-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18464, current rewards: -1168.58168, mean: -0.58138
[32m[0906 14-43-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18467, current rewards: -1251.30200, mean: -0.60743
[32m[0906 14-43-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18460, current rewards: -1320.17868, mean: -0.62568
[32m[0906 14-43-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18450, current rewards: -1396.07255, mean: -0.64633
[32m[0906 14-43-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18449, current rewards: -1387.48008, mean: -0.62782
[32m[0906 14-43-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18444, current rewards: -1381.75174, mean: -0.61139
[32m[0906 14-43-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18435, current rewards: -1376.02461, mean: -0.59568
[32m[0906 14-44-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18436, current rewards: -1370.67438, mean: -0.58079
[32m[0906 14-44-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18440, current rewards: -1375.18294, mean: -0.57062
[32m[0906 14-44-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18443, current rewards: -1397.13010, mean: -0.56794
[32m[0906 14-44-28 @Agent.py:117][0m Average action selection time: 0.1845
[32m[0906 14-44-28 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-44-28 @MBExp.py:227][0m Rewards obtained: [-1406.5699178960108], Lows: [785], Highs: [33], Total time: 3706.424608
[32m[0906 14-44-47 @MBExp.py:144][0m ####################################################################
[32m[0906 14-44-47 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 14-44-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18729, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-44-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18605, current rewards: -16.34378, mean: -0.27240
[32m[0906 14-45-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18565, current rewards: -23.67274, mean: -0.21521
[32m[0906 14-45-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18537, current rewards: -28.86508, mean: -0.18041
[32m[0906 14-45-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18541, current rewards: -36.19407, mean: -0.17235
[32m[0906 14-45-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18519, current rewards: -36.56191, mean: -0.14062
[32m[0906 14-45-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18505, current rewards: -32.58384, mean: -0.10511
[32m[0906 14-45-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18500, current rewards: -28.60667, mean: -0.07946
[32m[0906 14-46-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18507, current rewards: -24.62350, mean: -0.06006
[32m[0906 14-46-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18519, current rewards: -20.64297, mean: -0.04488
[32m[0906 14-46-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18517, current rewards: -16.65995, mean: -0.03267
[32m[0906 14-46-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18520, current rewards: -12.67867, mean: -0.02264
[32m[0906 14-46-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18527, current rewards: -29.51506, mean: -0.04839
[32m[0906 14-46-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18525, current rewards: -25.67891, mean: -0.03891
[32m[0906 14-46-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18522, current rewards: -21.67223, mean: -0.03052
[32m[0906 14-47-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18517, current rewards: -17.62451, mean: -0.02319
[32m[0906 14-47-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18510, current rewards: -13.57597, mean: -0.01676
[32m[0906 14-47-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18507, current rewards: -9.52837, mean: -0.01108
[32m[0906 14-47-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18504, current rewards: -5.48043, mean: -0.00602
[32m[0906 14-47-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18495, current rewards: -1.43032, mean: -0.00149
[32m[0906 14-47-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18492, current rewards: 2.61756, mean: 0.00259
[32m[0906 14-48-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18493, current rewards: 6.63855, mean: 0.00626
[32m[0906 14-48-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18491, current rewards: 10.65215, mean: 0.00960
[32m[0906 14-48-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18489, current rewards: -5.92819, mean: -0.00511
[32m[0906 14-48-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18486, current rewards: -1.52081, mean: -0.00126
[32m[0906 14-48-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18487, current rewards: 2.88536, mean: 0.00229
[32m[0906 14-48-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18490, current rewards: 7.28828, mean: 0.00556
[32m[0906 14-48-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18486, current rewards: 11.69443, mean: 0.00860
[32m[0906 14-49-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18484, current rewards: 16.09784, mean: 0.01142
[32m[0906 14-49-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18482, current rewards: 20.63425, mean: 0.01413
[32m[0906 14-49-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18479, current rewards: 25.78687, mean: 0.01708
[32m[0906 14-49-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18463, current rewards: 30.28070, mean: 0.01941
[32m[0906 14-49-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18449, current rewards: 34.77504, mean: 0.02160
[32m[0906 14-49-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18447, current rewards: 39.26810, mean: 0.02366
[32m[0906 14-50-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18450, current rewards: 43.76079, mean: 0.02559
[32m[0906 14-50-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18452, current rewards: 48.25362, mean: 0.02742
[32m[0906 14-50-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18449, current rewards: 37.29575, mean: 0.02061
[32m[0906 14-50-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18438, current rewards: 11.79712, mean: 0.00634
[32m[0906 14-50-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18429, current rewards: 4.84780, mean: 0.00254
[32m[0906 14-50-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18436, current rewards: 4.62511, mean: 0.00236
[32m[0906 14-50-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18438, current rewards: 3.33218, mean: 0.00166
[32m[0906 14-51-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18439, current rewards: 3.10499, mean: 0.00151
[32m[0906 14-51-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18432, current rewards: 1.81413, mean: 0.00086
[32m[0906 14-51-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18423, current rewards: 0.50843, mean: 0.00024
[32m[0906 14-51-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18417, current rewards: -18.44970, mean: -0.00835
[32m[0906 14-51-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18413, current rewards: -15.43466, mean: -0.00683
[32m[0906 14-51-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18407, current rewards: -33.74467, mean: -0.01461
[32m[0906 14-52-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18403, current rewards: -69.02652, mean: -0.02925
[32m[0906 14-52-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18407, current rewards: -105.36023, mean: -0.04372
[32m[0906 14-52-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18413, current rewards: -123.29174, mean: -0.05012
[32m[0906 14-52-28 @Agent.py:117][0m Average action selection time: 0.1841
[32m[0906 14-52-28 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-52-28 @MBExp.py:227][0m Rewards obtained: [-119.94792195137178], Lows: [30], Highs: [240], Total time: 4167.445087
[32m[0906 14-52-50 @MBExp.py:144][0m ####################################################################
[32m[0906 14-52-50 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 14-52-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18830, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-53-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18623, current rewards: -7.00022, mean: -0.11667
[32m[0906 14-53-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18613, current rewards: -2.54849, mean: -0.02317
[32m[0906 14-53-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18602, current rewards: 1.90255, mean: 0.01189
[32m[0906 14-53-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18595, current rewards: 6.49640, mean: 0.03094
[32m[0906 14-53-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18565, current rewards: 11.03658, mean: 0.04245
[32m[0906 14-53-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18547, current rewards: 15.56435, mean: 0.05021
[32m[0906 14-53-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18534, current rewards: 11.72973, mean: 0.03258
[32m[0906 14-54-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18520, current rewards: 5.08073, mean: 0.01239
[32m[0906 14-54-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18523, current rewards: 11.14930, mean: 0.02424
[32m[0906 14-54-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18524, current rewards: 17.21519, mean: 0.03376
[32m[0906 14-54-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18529, current rewards: 23.28684, mean: 0.04158
[32m[0906 14-54-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18520, current rewards: 28.81302, mean: 0.04723
[32m[0906 14-54-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18522, current rewards: 34.07063, mean: 0.05162
[32m[0906 14-55-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18526, current rewards: 38.55028, mean: 0.05430
[32m[0906 14-55-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18522, current rewards: 43.07076, mean: 0.05667
[32m[0906 14-55-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18520, current rewards: 47.59085, mean: 0.05875
[32m[0906 14-55-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18517, current rewards: 52.11187, mean: 0.06060
[32m[0906 14-55-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18517, current rewards: 56.63449, mean: 0.06224
[32m[0906 14-55-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18513, current rewards: 61.15215, mean: 0.06370
[32m[0906 14-55-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18512, current rewards: 65.67458, mean: 0.06502
[32m[0906 14-56-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18508, current rewards: 71.06803, mean: 0.06705
[32m[0906 14-56-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18505, current rewards: 75.94921, mean: 0.06842
[32m[0906 14-56-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18502, current rewards: 59.62674, mean: 0.05140
[32m[0906 14-56-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18502, current rewards: 64.94182, mean: 0.05367
[32m[0906 14-56-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18502, current rewards: 70.18907, mean: 0.05571
[32m[0906 14-56-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18498, current rewards: 75.43834, mean: 0.05759
[32m[0906 14-57-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18501, current rewards: 80.68288, mean: 0.05933
[32m[0906 14-57-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18501, current rewards: 85.92887, mean: 0.06094
[32m[0906 14-57-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18500, current rewards: 90.34179, mean: 0.06188
[32m[0906 14-57-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18499, current rewards: 94.74720, mean: 0.06275
[32m[0906 14-57-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18484, current rewards: 78.80837, mean: 0.05052
[32m[0906 14-57-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18470, current rewards: 76.01184, mean: 0.04721
[32m[0906 14-57-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18467, current rewards: 77.32363, mean: 0.04658
[32m[0906 14-58-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18471, current rewards: 80.57266, mean: 0.04712
[32m[0906 14-58-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18471, current rewards: 82.39392, mean: 0.04681
[32m[0906 14-58-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18462, current rewards: 84.90881, mean: 0.04691
[32m[0906 14-58-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18450, current rewards: 83.76330, mean: 0.04503
[32m[0906 14-58-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18440, current rewards: 89.83635, mean: 0.04703
[32m[0906 14-58-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18444, current rewards: 96.02712, mean: 0.04899
[32m[0906 14-59-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18446, current rewards: 102.17591, mean: 0.05083
[32m[0906 14-59-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18451, current rewards: 108.26497, mean: 0.05256
[32m[0906 14-59-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18447, current rewards: 114.50273, mean: 0.05427
[32m[0906 14-59-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18439, current rewards: 108.02328, mean: 0.05001
[32m[0906 14-59-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18431, current rewards: 111.91339, mean: 0.05064
[32m[0906 14-59-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18429, current rewards: 115.71510, mean: 0.05120
[32m[0906 14-59-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18420, current rewards: 119.51560, mean: 0.05174
[32m[0906 15-00-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18414, current rewards: 123.31712, mean: 0.05225
[32m[0906 15-00-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18417, current rewards: 127.11766, mean: 0.05275
[32m[0906 15-00-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18419, current rewards: 130.91792, mean: 0.05322
[32m[0906 15-00-31 @Agent.py:117][0m Average action selection time: 0.1842
[32m[0906 15-00-31 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-00-31 @MBExp.py:227][0m Rewards obtained: [133.9588786051622], Lows: [54], Highs: [23], Total time: 4628.598101
[32m[0906 15-00-54 @MBExp.py:144][0m ####################################################################
[32m[0906 15-00-54 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 15-00-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18619, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-01-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18632, current rewards: 2.16866, mean: 0.03614
[32m[0906 15-01-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18610, current rewards: 11.85413, mean: 0.10776
[32m[0906 15-01-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18587, current rewards: 21.40971, mean: 0.13381
[32m[0906 15-01-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18586, current rewards: 29.31110, mean: 0.13958
[32m[0906 15-01-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18571, current rewards: 38.45985, mean: 0.14792
[32m[0906 15-01-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18570, current rewards: 47.60178, mean: 0.15355
[32m[0906 15-02-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18552, current rewards: 56.76431, mean: 0.15768
[32m[0906 15-02-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18550, current rewards: 65.93376, mean: 0.16081
[32m[0906 15-02-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18544, current rewards: 54.41442, mean: 0.11829
[32m[0906 15-02-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18532, current rewards: 66.53205, mean: 0.13045
[32m[0906 15-02-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18529, current rewards: 78.61634, mean: 0.14039
[32m[0906 15-02-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18530, current rewards: 91.33462, mean: 0.14973
[32m[0906 15-02-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18530, current rewards: 103.32463, mean: 0.15655
[32m[0906 15-03-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18526, current rewards: 92.37932, mean: 0.13011
[32m[0906 15-03-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18526, current rewards: 103.02603, mean: 0.13556
[32m[0906 15-03-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18529, current rewards: 113.67987, mean: 0.14035
[32m[0906 15-03-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18521, current rewards: 124.32159, mean: 0.14456
[32m[0906 15-03-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18523, current rewards: 134.94014, mean: 0.14829
[32m[0906 15-03-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18521, current rewards: 145.58294, mean: 0.15165
[32m[0906 15-04-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18517, current rewards: 153.71282, mean: 0.15219
[32m[0906 15-04-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18514, current rewards: 163.70112, mean: 0.15444
[32m[0906 15-04-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18509, current rewards: 173.65846, mean: 0.15645
[32m[0906 15-04-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18505, current rewards: 183.65319, mean: 0.15832
[32m[0906 15-04-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18501, current rewards: 193.62184, mean: 0.16002
[32m[0906 15-04-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18500, current rewards: 203.04546, mean: 0.16115
[32m[0906 15-04-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18501, current rewards: 209.39528, mean: 0.15984
[32m[0906 15-05-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18501, current rewards: 215.80187, mean: 0.15868
[32m[0906 15-05-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18499, current rewards: 224.88330, mean: 0.15949
[32m[0906 15-05-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18498, current rewards: 232.70565, mean: 0.15939
[32m[0906 15-05-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18496, current rewards: 240.47440, mean: 0.15925
[32m[0906 15-05-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18481, current rewards: 248.25026, mean: 0.15913
[32m[0906 15-05-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18468, current rewards: 256.02095, mean: 0.15902
[32m[0906 15-06-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18459, current rewards: 263.79540, mean: 0.15891
[32m[0906 15-06-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18464, current rewards: 271.57030, mean: 0.15881
[32m[0906 15-06-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18466, current rewards: 279.33445, mean: 0.15871
[32m[0906 15-06-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18456, current rewards: 286.72078, mean: 0.15841
[32m[0906 15-06-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18445, current rewards: 286.47861, mean: 0.15402
[32m[0906 15-06-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18434, current rewards: 279.18600, mean: 0.14617
[32m[0906 15-06-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18438, current rewards: 289.24067, mean: 0.14757
[32m[0906 15-07-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18440, current rewards: 299.28631, mean: 0.14890
[32m[0906 15-07-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18442, current rewards: 309.34300, mean: 0.15017
[32m[0906 15-07-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18439, current rewards: 319.39450, mean: 0.15137
[32m[0906 15-07-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18433, current rewards: 329.46905, mean: 0.15253
[32m[0906 15-07-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18425, current rewards: 311.60014, mean: 0.14100
[32m[0906 15-07-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18420, current rewards: 303.97698, mean: 0.13450
[32m[0906 15-08-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18414, current rewards: 317.16804, mean: 0.13730
[32m[0906 15-08-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18408, current rewards: 330.35745, mean: 0.13998
[32m[0906 15-08-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18409, current rewards: 343.58692, mean: 0.14257
[32m[0906 15-08-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18414, current rewards: 356.81434, mean: 0.14505
[32m[0906 15-08-35 @Agent.py:117][0m Average action selection time: 0.1842
[32m[0906 15-08-35 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-08-35 @MBExp.py:227][0m Rewards obtained: [367.4025959847459], Lows: [48], Highs: [21], Total time: 5089.69993
[32m[0906 15-09-01 @MBExp.py:144][0m ####################################################################
[32m[0906 15-09-01 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 15-09-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18670, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-09-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18576, current rewards: -4.22460, mean: -0.07041
[32m[0906 15-09-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18546, current rewards: 2.53218, mean: 0.02302
[32m[0906 15-09-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18550, current rewards: 8.25701, mean: 0.05161
[32m[0906 15-09-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18592, current rewards: 15.30303, mean: 0.07287
[32m[0906 15-09-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18573, current rewards: 22.27271, mean: 0.08566
[32m[0906 15-09-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18554, current rewards: 29.25264, mean: 0.09436
[32m[0906 15-10-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18565, current rewards: 36.21350, mean: 0.10059
[32m[0906 15-10-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18561, current rewards: 43.18168, mean: 0.10532
[32m[0906 15-10-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18557, current rewards: 50.16354, mean: 0.10905
[32m[0906 15-10-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18551, current rewards: 57.13804, mean: 0.11204
[32m[0906 15-10-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18550, current rewards: 64.95063, mean: 0.11598
[32m[0906 15-10-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18544, current rewards: 52.57944, mean: 0.08620
[32m[0906 15-11-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18540, current rewards: 59.11136, mean: 0.08956
[32m[0906 15-11-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18549, current rewards: 65.63515, mean: 0.09244
[32m[0906 15-11-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18548, current rewards: 72.16479, mean: 0.09495
[32m[0906 15-11-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18547, current rewards: 78.69816, mean: 0.09716
[32m[0906 15-11-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18550, current rewards: 85.22627, mean: 0.09910
[32m[0906 15-11-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18549, current rewards: 91.75665, mean: 0.10083
[32m[0906 15-11-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18548, current rewards: 98.28601, mean: 0.10238
[32m[0906 15-12-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18548, current rewards: 104.55482, mean: 0.10352
[32m[0906 15-12-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18543, current rewards: 111.08147, mean: 0.10479
[32m[0906 15-12-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18537, current rewards: 117.61030, mean: 0.10596
[32m[0906 15-12-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18533, current rewards: 104.17368, mean: 0.08980
[32m[0906 15-12-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18532, current rewards: 110.79780, mean: 0.09157
[32m[0906 15-12-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18529, current rewards: 117.41300, mean: 0.09318
[32m[0906 15-13-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18530, current rewards: 124.03366, mean: 0.09468
[32m[0906 15-13-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18527, current rewards: 130.66634, mean: 0.09608
[32m[0906 15-13-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18526, current rewards: 139.39825, mean: 0.09886
[32m[0906 15-13-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18522, current rewards: 145.89706, mean: 0.09993
[32m[0906 15-13-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18521, current rewards: 152.39862, mean: 0.10093
[32m[0906 15-13-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18510, current rewards: 158.89402, mean: 0.10186
[32m[0906 15-13-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18497, current rewards: 165.39430, mean: 0.10273
[32m[0906 15-14-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18484, current rewards: 171.88584, mean: 0.10355
[32m[0906 15-14-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18485, current rewards: 157.77481, mean: 0.09227
[32m[0906 15-14-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18486, current rewards: 164.89219, mean: 0.09369
[32m[0906 15-14-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18471, current rewards: 171.18958, mean: 0.09458
[32m[0906 15-14-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18461, current rewards: 177.94665, mean: 0.09567
[32m[0906 15-14-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18449, current rewards: 184.70871, mean: 0.09671
[32m[0906 15-15-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18453, current rewards: 185.79293, mean: 0.09479
[32m[0906 15-15-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18455, current rewards: 185.68145, mean: 0.09238
[32m[0906 15-15-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18456, current rewards: 192.35373, mean: 0.09338
[32m[0906 15-15-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18453, current rewards: 199.00940, mean: 0.09432
[32m[0906 15-15-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18443, current rewards: 205.66397, mean: 0.09521
[32m[0906 15-15-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18434, current rewards: 211.29175, mean: 0.09561
[32m[0906 15-15-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18429, current rewards: 218.39111, mean: 0.09663
[32m[0906 15-16-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18422, current rewards: 225.56134, mean: 0.09765
[32m[0906 15-16-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18414, current rewards: 232.71431, mean: 0.09861
[32m[0906 15-16-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18412, current rewards: 239.87347, mean: 0.09953
[32m[0906 15-16-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18415, current rewards: 226.07411, mean: 0.09190
[32m[0906 15-16-42 @Agent.py:117][0m Average action selection time: 0.1842
[32m[0906 15-16-42 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-16-42 @MBExp.py:227][0m Rewards obtained: [231.88740840955666], Lows: [40], Highs: [22], Total time: 5550.801273
[32m[0906 15-17-09 @MBExp.py:144][0m ####################################################################
[32m[0906 15-17-09 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 15-17-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18519, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-17-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18578, current rewards: -5.20670, mean: -0.08678
[32m[0906 15-17-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18599, current rewards: -0.06850, mean: -0.00062
[32m[0906 15-17-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18591, current rewards: 4.64048, mean: 0.02900
[32m[0906 15-17-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18585, current rewards: 9.79355, mean: 0.04664
[32m[0906 15-17-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18569, current rewards: 14.95595, mean: 0.05752
[32m[0906 15-18-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18583, current rewards: 20.10596, mean: 0.06486
[32m[0906 15-18-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18577, current rewards: 25.25830, mean: 0.07016
[32m[0906 15-18-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18570, current rewards: 30.42160, mean: 0.07420
[32m[0906 15-18-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18569, current rewards: 35.57833, mean: 0.07734
[32m[0906 15-18-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18562, current rewards: 40.73515, mean: 0.07987
[32m[0906 15-18-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18560, current rewards: 26.41853, mean: 0.04718
[32m[0906 15-19-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18558, current rewards: 31.48592, mean: 0.05162
[32m[0906 15-19-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18553, current rewards: 36.47319, mean: 0.05526
[32m[0906 15-19-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18552, current rewards: 41.46210, mean: 0.05840
[32m[0906 15-19-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18544, current rewards: 46.44928, mean: 0.06112
[32m[0906 15-19-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18543, current rewards: 51.43737, mean: 0.06350
[32m[0906 15-19-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18538, current rewards: 56.42469, mean: 0.06561
[32m[0906 15-19-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18533, current rewards: 61.41197, mean: 0.06749
[32m[0906 15-20-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18534, current rewards: 66.33458, mean: 0.06910
[32m[0906 15-20-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18530, current rewards: 61.14050, mean: 0.06054
[32m[0906 15-20-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18529, current rewards: 71.29275, mean: 0.06726
[32m[0906 15-20-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18527, current rewards: 81.66857, mean: 0.07358
[32m[0906 15-20-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18525, current rewards: 92.00503, mean: 0.07931
[32m[0906 15-20-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18523, current rewards: 102.34907, mean: 0.08459
[32m[0906 15-21-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18523, current rewards: 112.71764, mean: 0.08946
[32m[0906 15-21-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18521, current rewards: 123.06889, mean: 0.09395
[32m[0906 15-21-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18520, current rewards: 133.41448, mean: 0.09810
[32m[0906 15-21-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18517, current rewards: 148.44450, mean: 0.10528
[32m[0906 15-21-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18517, current rewards: 158.96200, mean: 0.10888
[32m[0906 15-21-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18520, current rewards: 169.38259, mean: 0.11217
[32m[0906 15-21-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18504, current rewards: 170.95379, mean: 0.10959
[32m[0906 15-22-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18491, current rewards: 161.57958, mean: 0.10036
[32m[0906 15-22-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18480, current rewards: 166.79093, mean: 0.10048
[32m[0906 15-22-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18479, current rewards: 172.00267, mean: 0.10059
[32m[0906 15-22-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18479, current rewards: 177.21116, mean: 0.10069
[32m[0906 15-22-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18467, current rewards: 182.29675, mean: 0.10072
[32m[0906 15-22-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18456, current rewards: 187.50666, mean: 0.10081
[32m[0906 15-23-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18447, current rewards: 192.71797, mean: 0.10090
[32m[0906 15-23-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18450, current rewards: 185.62029, mean: 0.09470
[32m[0906 15-23-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18451, current rewards: 190.63453, mean: 0.09484
[32m[0906 15-23-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18453, current rewards: 195.65248, mean: 0.09498
[32m[0906 15-23-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18452, current rewards: 200.66460, mean: 0.09510
[32m[0906 15-23-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18445, current rewards: 205.68396, mean: 0.09522
[32m[0906 15-23-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18437, current rewards: 210.69793, mean: 0.09534
[32m[0906 15-24-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18427, current rewards: 215.70745, mean: 0.09545
[32m[0906 15-24-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18420, current rewards: 199.53174, mean: 0.08638
[32m[0906 15-24-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18414, current rewards: 204.43942, mean: 0.08663
[32m[0906 15-24-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18408, current rewards: 209.34684, mean: 0.08687
[32m[0906 15-24-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18413, current rewards: 214.25328, mean: 0.08709
[32m[0906 15-24-50 @Agent.py:117][0m Average action selection time: 0.1842
[32m[0906 15-24-50 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-24-50 @MBExp.py:227][0m Rewards obtained: [218.1851445246944], Lows: [31], Highs: [32], Total time: 6011.882582
[32m[0906 15-25-20 @MBExp.py:144][0m ####################################################################
[32m[0906 15-25-20 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 15-25-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18722, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-25-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18638, current rewards: -110.00000, mean: -1.83333
[32m[0906 15-25-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18585, current rewards: -210.00000, mean: -1.90909
[32m[0906 15-25-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18596, current rewards: -310.00000, mean: -1.93750
[32m[0906 15-25-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18588, current rewards: -410.00000, mean: -1.95238
[32m[0906 15-26-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18573, current rewards: -510.00000, mean: -1.96154
[32m[0906 15-26-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18562, current rewards: -610.00000, mean: -1.96774
[32m[0906 15-26-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18562, current rewards: -642.34473, mean: -1.78429
[32m[0906 15-26-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18554, current rewards: -636.37864, mean: -1.55214
[32m[0906 15-26-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18554, current rewards: -630.41045, mean: -1.37046
[32m[0906 15-26-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18552, current rewards: -621.42333, mean: -1.21848
[32m[0906 15-27-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18549, current rewards: -613.03637, mean: -1.09471
[32m[0906 15-27-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18541, current rewards: -606.55347, mean: -0.99435
[32m[0906 15-27-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18531, current rewards: -600.06907, mean: -0.90920
[32m[0906 15-27-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18528, current rewards: -593.58294, mean: -0.83603
[32m[0906 15-27-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18522, current rewards: -587.10004, mean: -0.77250
[32m[0906 15-27-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18521, current rewards: -580.61530, mean: -0.71681
[32m[0906 15-28-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18515, current rewards: -574.13178, mean: -0.66760
[32m[0906 15-28-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18513, current rewards: -608.23499, mean: -0.66839
[32m[0906 15-28-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18509, current rewards: -603.90242, mean: -0.62907
[32m[0906 15-28-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18511, current rewards: -599.52756, mean: -0.59359
[32m[0906 15-28-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18513, current rewards: -595.10171, mean: -0.56142
[32m[0906 15-28-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18510, current rewards: -590.67555, mean: -0.53214
[32m[0906 15-28-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18505, current rewards: -586.25105, mean: -0.50539
[32m[0906 15-29-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18504, current rewards: -581.82541, mean: -0.48085
[32m[0906 15-29-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18501, current rewards: -577.40189, mean: -0.45826
[32m[0906 15-29-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18499, current rewards: -572.97687, mean: -0.43739
[32m[0906 15-29-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18497, current rewards: -568.62192, mean: -0.41810
[32m[0906 15-29-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18493, current rewards: -564.18127, mean: -0.40013
[32m[0906 15-29-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18492, current rewards: -559.75364, mean: -0.38339
[32m[0906 15-30-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18488, current rewards: -555.33426, mean: -0.36777
[32m[0906 15-30-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18476, current rewards: -550.91368, mean: -0.35315
[32m[0906 15-30-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18461, current rewards: -566.08704, mean: -0.35161
[32m[0906 15-30-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18446, current rewards: -559.60293, mean: -0.33711
[32m[0906 15-30-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18444, current rewards: -553.17261, mean: -0.32349
[32m[0906 15-30-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18440, current rewards: -545.09714, mean: -0.30971
[32m[0906 15-30-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18429, current rewards: -538.30542, mean: -0.29741
[32m[0906 15-31-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18420, current rewards: -532.09596, mean: -0.28607
[32m[0906 15-31-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18411, current rewards: -525.89134, mean: -0.27534
[32m[0906 15-31-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18415, current rewards: -519.68286, mean: -0.26514
[32m[0906 15-31-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18417, current rewards: -513.47712, mean: -0.25546
[32m[0906 15-31-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18416, current rewards: -518.58649, mean: -0.25174
[32m[0906 15-31-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18414, current rewards: -566.95365, mean: -0.26870
[32m[0906 15-31-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18405, current rewards: -615.19398, mean: -0.28481
[32m[0906 15-32-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18398, current rewards: -656.66516, mean: -0.29713
[32m[0906 15-32-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18386, current rewards: -749.79182, mean: -0.33177
[32m[0906 15-32-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18378, current rewards: -800.20021, mean: -0.34641
[32m[0906 15-32-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18371, current rewards: -895.45728, mean: -0.37943
[32m[0906 15-32-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18367, current rewards: -985.76844, mean: -0.40903
[32m[0906 15-32-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18369, current rewards: -1075.86355, mean: -0.43734
[32m[0906 15-33-00 @Agent.py:117][0m Average action selection time: 0.1837
[32m[0906 15-33-00 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-33-00 @MBExp.py:227][0m Rewards obtained: [-1145.9590300883772], Lows: [681], Highs: [20], Total time: 6471.858464
[32m[0906 15-33-32 @MBExp.py:144][0m ####################################################################
[32m[0906 15-33-32 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 15-33-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18544, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-33-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18584, current rewards: 3.57987, mean: 0.05966
[32m[0906 15-33-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18568, current rewards: 15.54241, mean: 0.14129
[32m[0906 15-34-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18525, current rewards: 29.56177, mean: 0.18476
[32m[0906 15-34-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18508, current rewards: 43.04620, mean: 0.20498
[32m[0906 15-34-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18525, current rewards: 56.55860, mean: 0.21753
[32m[0906 15-34-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18521, current rewards: 70.06548, mean: 0.22602
[32m[0906 15-34-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18510, current rewards: 83.57950, mean: 0.23217
[32m[0906 15-34-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18517, current rewards: 97.10921, mean: 0.23685
[32m[0906 15-34-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18512, current rewards: 110.61211, mean: 0.24046
[32m[0906 15-35-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18515, current rewards: 123.42544, mean: 0.24201
[32m[0906 15-35-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18516, current rewards: 114.82755, mean: 0.20505
[32m[0906 15-35-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18513, current rewards: 129.60860, mean: 0.21247
[32m[0906 15-35-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18509, current rewards: 144.37554, mean: 0.21875
[32m[0906 15-35-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18510, current rewards: 159.14601, mean: 0.22415
[32m[0906 15-35-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18509, current rewards: 143.10440, mean: 0.18830
[32m[0906 15-36-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18510, current rewards: 147.50815, mean: 0.18211
[32m[0906 15-36-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18507, current rewards: 151.90721, mean: 0.17664
[32m[0906 15-36-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18504, current rewards: 156.31054, mean: 0.17177
[32m[0906 15-36-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18501, current rewards: 160.62337, mean: 0.16732
[32m[0906 15-36-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18495, current rewards: 164.98896, mean: 0.16336
[32m[0906 15-36-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18492, current rewards: 169.35860, mean: 0.15977
[32m[0906 15-36-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18492, current rewards: 173.72440, mean: 0.15651
[32m[0906 15-37-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18489, current rewards: 178.09036, mean: 0.15353
[32m[0906 15-37-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18487, current rewards: 182.45501, mean: 0.15079
[32m[0906 15-37-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18486, current rewards: 186.82307, mean: 0.14827
[32m[0906 15-37-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18485, current rewards: 191.18914, mean: 0.14595
[32m[0906 15-37-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18484, current rewards: 195.27941, mean: 0.14359
[32m[0906 15-37-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18482, current rewards: 199.62676, mean: 0.14158
[32m[0906 15-38-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18483, current rewards: 193.24101, mean: 0.13236
[32m[0906 15-38-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18481, current rewards: 197.65330, mean: 0.13090
[32m[0906 15-38-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18465, current rewards: 202.07249, mean: 0.12953
[32m[0906 15-38-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18451, current rewards: 206.49117, mean: 0.12826
[32m[0906 15-38-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18438, current rewards: 210.91319, mean: 0.12706
[32m[0906 15-38-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18429, current rewards: 215.33200, mean: 0.12593
[32m[0906 15-38-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18422, current rewards: 220.78859, mean: 0.12545
[32m[0906 15-39-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18415, current rewards: 225.14463, mean: 0.12439
[32m[0906 15-39-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18406, current rewards: 208.09634, mean: 0.11188
[32m[0906 15-39-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18398, current rewards: 214.24821, mean: 0.11217
[32m[0906 15-39-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18402, current rewards: 220.39726, mean: 0.11245
[32m[0906 15-39-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18405, current rewards: 226.54845, mean: 0.11271
[32m[0906 15-39-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18408, current rewards: 232.70059, mean: 0.11296
[32m[0906 15-40-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18406, current rewards: 238.85144, mean: 0.11320
[32m[0906 15-40-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18397, current rewards: 234.47684, mean: 0.10855
[32m[0906 15-40-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18389, current rewards: 241.57756, mean: 0.10931
[32m[0906 15-40-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18379, current rewards: 248.62225, mean: 0.11001
[32m[0906 15-40-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18366, current rewards: 255.66936, mean: 0.11068
[32m[0906 15-40-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18358, current rewards: 262.71255, mean: 0.11132
[32m[0906 15-40-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18352, current rewards: 269.75099, mean: 0.11193
[32m[0906 15-41-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18355, current rewards: 276.80261, mean: 0.11252
[32m[0906 15-41-12 @Agent.py:117][0m Average action selection time: 0.1836
[32m[0906 15-41-12 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-41-12 @MBExp.py:227][0m Rewards obtained: [282.44519206326623], Lows: [33], Highs: [30], Total time: 6931.528588
[32m[0906 15-41-45 @MBExp.py:144][0m ####################################################################
[32m[0906 15-41-45 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 15-41-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18572, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-41-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18600, current rewards: -5.45429, mean: -0.09090
[32m[0906 15-42-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18580, current rewards: 0.31272, mean: 0.00284
[32m[0906 15-42-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18561, current rewards: 5.89079, mean: 0.03682
[32m[0906 15-42-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18541, current rewards: 11.46792, mean: 0.05461
[32m[0906 15-42-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18534, current rewards: 17.04126, mean: 0.06554
[32m[0906 15-42-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18533, current rewards: 22.61615, mean: 0.07296
[32m[0906 15-42-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18529, current rewards: 28.18683, mean: 0.07830
[32m[0906 15-43-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18528, current rewards: 33.75842, mean: 0.08234
[32m[0906 15-43-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18531, current rewards: 27.10988, mean: 0.05893
[32m[0906 15-43-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18524, current rewards: 31.82956, mean: 0.06241
[32m[0906 15-43-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18518, current rewards: 36.55272, mean: 0.06527
[32m[0906 15-43-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18513, current rewards: 41.28062, mean: 0.06767
[32m[0906 15-43-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18510, current rewards: 46.00327, mean: 0.06970
[32m[0906 15-43-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18505, current rewards: 50.72980, mean: 0.07145
[32m[0906 15-44-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18501, current rewards: 55.45494, mean: 0.07297
[32m[0906 15-44-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18503, current rewards: 60.17994, mean: 0.07430
[32m[0906 15-44-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18500, current rewards: 67.80044, mean: 0.07884
[32m[0906 15-44-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18497, current rewards: 72.89260, mean: 0.08010
[32m[0906 15-44-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18494, current rewards: 77.96538, mean: 0.08121
[32m[0906 15-44-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18492, current rewards: 83.03358, mean: 0.08221
[32m[0906 15-45-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18490, current rewards: 88.10671, mean: 0.08312
[32m[0906 15-45-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18486, current rewards: 93.18083, mean: 0.08395
[32m[0906 15-45-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18488, current rewards: 98.25578, mean: 0.08470
[32m[0906 15-45-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18483, current rewards: 103.32761, mean: 0.08539
[32m[0906 15-45-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18484, current rewards: 108.41937, mean: 0.08605
[32m[0906 15-45-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18481, current rewards: 103.37585, mean: 0.07891
[32m[0906 15-45-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18482, current rewards: 108.21095, mean: 0.07957
[32m[0906 15-46-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18478, current rewards: 113.04955, mean: 0.08018
[32m[0906 15-46-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18475, current rewards: 117.88347, mean: 0.08074
[32m[0906 15-46-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18474, current rewards: 122.72038, mean: 0.08127
[32m[0906 15-46-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18458, current rewards: 127.55595, mean: 0.08177
[32m[0906 15-46-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18444, current rewards: 132.39687, mean: 0.08223
[32m[0906 15-46-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18430, current rewards: 137.23390, mean: 0.08267
[32m[0906 15-47-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18419, current rewards: 137.38135, mean: 0.08034
[32m[0906 15-47-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18408, current rewards: 127.44446, mean: 0.07241
[32m[0906 15-47-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18399, current rewards: 132.23595, mean: 0.07306
[32m[0906 15-47-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18392, current rewards: 137.02593, mean: 0.07367
[32m[0906 15-47-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18383, current rewards: 141.81610, mean: 0.07425
[32m[0906 15-47-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18388, current rewards: 136.12909, mean: 0.06945
[32m[0906 15-47-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18389, current rewards: 130.92479, mean: 0.06514
[32m[0906 15-48-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18390, current rewards: 136.16948, mean: 0.06610
[32m[0906 15-48-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18391, current rewards: 140.95733, mean: 0.06680
[32m[0906 15-48-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18382, current rewards: 145.41607, mean: 0.06732
[32m[0906 15-48-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18375, current rewards: 149.87482, mean: 0.06782
[32m[0906 15-48-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18365, current rewards: 154.33356, mean: 0.06829
[32m[0906 15-48-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18350, current rewards: 158.79231, mean: 0.06874
[32m[0906 15-48-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18344, current rewards: 163.25105, mean: 0.06917
[32m[0906 15-49-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18338, current rewards: 167.70980, mean: 0.06959
[32m[0906 15-49-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18335, current rewards: 172.16855, mean: 0.06999
[32m[0906 15-49-25 @Agent.py:117][0m Average action selection time: 0.1834
[32m[0906 15-49-25 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-49-25 @MBExp.py:227][0m Rewards obtained: [156.13039365919897], Lows: [26], Highs: [40], Total time: 7390.675924
[32m[0906 15-50-01 @MBExp.py:144][0m ####################################################################
[32m[0906 15-50-01 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 15-50-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18652, current rewards: 0.61546, mean: 0.06155
[32m[0906 15-50-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18590, current rewards: 6.23827, mean: 0.10397
[32m[0906 15-50-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18545, current rewards: 11.91858, mean: 0.10835
[32m[0906 15-50-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18506, current rewards: 17.60486, mean: 0.11003
[32m[0906 15-50-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18490, current rewards: 23.29027, mean: 0.11091
[32m[0906 15-50-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18480, current rewards: 16.69909, mean: 0.06423
[32m[0906 15-50-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18488, current rewards: 21.80765, mean: 0.07035
[32m[0906 15-51-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18499, current rewards: 26.91645, mean: 0.07477
[32m[0906 15-51-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18497, current rewards: 31.70364, mean: 0.07733
[32m[0906 15-51-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18494, current rewards: 36.60562, mean: 0.07958
[32m[0906 15-51-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18499, current rewards: 41.49258, mean: 0.08136
[32m[0906 15-51-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18504, current rewards: 46.38064, mean: 0.08282
[32m[0906 15-51-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18504, current rewards: 51.26230, mean: 0.08404
[32m[0906 15-52-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18505, current rewards: 56.15242, mean: 0.08508
[32m[0906 15-52-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18497, current rewards: 61.03939, mean: 0.08597
[32m[0906 15-52-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18499, current rewards: 65.92471, mean: 0.08674
[32m[0906 15-52-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18494, current rewards: 49.32824, mean: 0.06090
[32m[0906 15-52-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18493, current rewards: 35.17958, mean: 0.04091
[32m[0906 15-52-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18493, current rewards: 28.44815, mean: 0.03126
[32m[0906 15-52-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18491, current rewards: 23.80493, mean: 0.02480
[32m[0906 15-53-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18492, current rewards: 17.06384, mean: 0.01689
[32m[0906 15-53-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18488, current rewards: 10.34831, mean: 0.00976
[32m[0906 15-53-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18486, current rewards: 5.68295, mean: 0.00512
[32m[0906 15-53-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18484, current rewards: -1.02862, mean: -0.00089
[32m[0906 15-53-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18486, current rewards: -5.68986, mean: -0.00470
[32m[0906 15-53-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18484, current rewards: -12.40608, mean: -0.00985
[32m[0906 15-54-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18481, current rewards: -17.06463, mean: -0.01303
[32m[0906 15-54-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18481, current rewards: -23.79183, mean: -0.01749
[32m[0906 15-54-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18478, current rewards: -28.44678, mean: -0.02018
[32m[0906 15-54-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18477, current rewards: -35.17898, mean: -0.02410
[32m[0906 15-54-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18473, current rewards: -39.81822, mean: -0.02637
[32m[0906 15-54-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18459, current rewards: -46.55812, mean: -0.02984
[32m[0906 15-54-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18445, current rewards: -53.25443, mean: -0.03308
[32m[0906 15-55-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18432, current rewards: -57.62775, mean: -0.03472
[32m[0906 15-55-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18416, current rewards: -64.17386, mean: -0.03753
[32m[0906 15-55-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18401, current rewards: -83.06625, mean: -0.04720
[32m[0906 15-55-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18390, current rewards: -78.52744, mean: -0.04339
[32m[0906 15-55-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18381, current rewards: -73.98488, mean: -0.03978
[32m[0906 15-55-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18375, current rewards: -69.44558, mean: -0.03636
[32m[0906 15-56-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18382, current rewards: -64.90786, mean: -0.03312
[32m[0906 15-56-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18385, current rewards: -60.36628, mean: -0.03003
[32m[0906 15-56-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18387, current rewards: -55.51893, mean: -0.02695
[32m[0906 15-56-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18388, current rewards: -50.83807, mean: -0.02409
[32m[0906 15-56-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18379, current rewards: -46.15688, mean: -0.02137
[32m[0906 15-56-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18370, current rewards: -41.47496, mean: -0.01877
[32m[0906 15-56-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18362, current rewards: -36.79321, mean: -0.01628
[32m[0906 15-57-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18342, current rewards: -39.76507, mean: -0.01721
[32m[0906 15-57-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18334, current rewards: -36.93163, mean: -0.01565
[32m[0906 15-57-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18328, current rewards: -31.75662, mean: -0.01318
[32m[0906 15-57-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18323, current rewards: -24.67771, mean: -0.01003
[32m[0906 15-57-39 @Agent.py:117][0m Average action selection time: 0.1833
[32m[0906 15-57-39 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-57-39 @MBExp.py:227][0m Rewards obtained: [-20.304820549242518], Lows: [102], Highs: [34], Total time: 7849.467659
[32m[0906 15-58-17 @MBExp.py:144][0m ####################################################################
[32m[0906 15-58-17 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 15-58-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18646, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-58-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18547, current rewards: -6.03024, mean: -0.10050
[32m[0906 15-58-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18565, current rewards: -0.99196, mean: -0.00902
[32m[0906 15-58-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18557, current rewards: 4.04871, mean: 0.02530
[32m[0906 15-58-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18550, current rewards: 9.08808, mean: 0.04328
[32m[0906 15-59-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18531, current rewards: 14.12249, mean: 0.05432
[32m[0906 15-59-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18530, current rewards: 19.16264, mean: 0.06181
[32m[0906 15-59-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18524, current rewards: 25.66793, mean: 0.07130
[32m[0906 15-59-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18518, current rewards: 30.67165, mean: 0.07481
[32m[0906 15-59-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18523, current rewards: 35.50622, mean: 0.07719
[32m[0906 15-59-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18523, current rewards: 43.67601, mean: 0.08564
[32m[0906 16-00-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18522, current rewards: 48.51058, mean: 0.08663
[32m[0906 16-00-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18524, current rewards: 53.05337, mean: 0.08697
[32m[0906 16-00-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18527, current rewards: 57.60219, mean: 0.08728
[32m[0906 16-00-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18522, current rewards: 66.57222, mean: 0.09376
[32m[0906 16-00-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18525, current rewards: 71.66893, mean: 0.09430
[32m[0906 16-00-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18519, current rewards: 76.63438, mean: 0.09461
[32m[0906 16-00-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18521, current rewards: 75.47955, mean: 0.08777
[32m[0906 16-01-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18517, current rewards: 66.22582, mean: 0.07278
[32m[0906 16-01-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18516, current rewards: 72.15449, mean: 0.07516
[32m[0906 16-01-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18508, current rewards: 78.08603, mean: 0.07731
[32m[0906 16-01-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18508, current rewards: 84.02367, mean: 0.07927
[32m[0906 16-01-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18505, current rewards: 89.95781, mean: 0.08104
[32m[0906 16-01-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18503, current rewards: 95.88677, mean: 0.08266
[32m[0906 16-02-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18503, current rewards: 100.61429, mean: 0.08315
[32m[0906 16-02-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18503, current rewards: 106.11517, mean: 0.08422
[32m[0906 16-02-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18502, current rewards: 111.61521, mean: 0.08520
[32m[0906 16-02-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18498, current rewards: 95.88383, mean: 0.07050
[32m[0906 16-02-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18497, current rewards: 101.59241, mean: 0.07205
[32m[0906 16-02-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18495, current rewards: 107.29585, mean: 0.07349
[32m[0906 16-02-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18492, current rewards: 113.00057, mean: 0.07483
[32m[0906 16-03-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18477, current rewards: 118.70254, mean: 0.07609
[32m[0906 16-03-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18464, current rewards: 124.50883, mean: 0.07733
[32m[0906 16-03-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18449, current rewards: 130.26092, mean: 0.07847
[32m[0906 16-03-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18428, current rewards: 136.01466, mean: 0.07954
[32m[0906 16-03-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18409, current rewards: 132.84701, mean: 0.07548
[32m[0906 16-03-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18398, current rewards: 136.98870, mean: 0.07568
[32m[0906 16-04-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18389, current rewards: 143.79210, mean: 0.07731
[32m[0906 16-04-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18382, current rewards: 150.59256, mean: 0.07884
[32m[0906 16-04-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18388, current rewards: 157.39532, mean: 0.08030
[32m[0906 16-04-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18391, current rewards: 163.62586, mean: 0.08141
[32m[0906 16-04-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18394, current rewards: 169.72957, mean: 0.08239
[32m[0906 16-04-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18396, current rewards: 164.53593, mean: 0.07798
[32m[0906 16-04-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18387, current rewards: 169.51699, mean: 0.07848
[32m[0906 16-05-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18380, current rewards: 174.56497, mean: 0.07899
[32m[0906 16-05-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18373, current rewards: 179.61199, mean: 0.07947
[32m[0906 16-05-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18353, current rewards: 184.66021, mean: 0.07994
[32m[0906 16-05-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18342, current rewards: 189.70531, mean: 0.08038
[32m[0906 16-05-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18335, current rewards: 195.94842, mean: 0.08131
[32m[0906 16-05-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18331, current rewards: 201.26669, mean: 0.08182
[32m[0906 16-05-56 @Agent.py:117][0m Average action selection time: 0.1833
[32m[0906 16-05-56 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-05-56 @MBExp.py:227][0m Rewards obtained: [205.14457729178667], Lows: [20], Highs: [31], Total time: 8308.373408
[32m[0906 16-06-37 @MBExp.py:144][0m ####################################################################
[32m[0906 16-06-37 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 16-06-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18702, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-06-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18593, current rewards: -5.66344, mean: -0.09439
[32m[0906 16-06-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18537, current rewards: 0.17051, mean: 0.00155
[32m[0906 16-07-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18518, current rewards: 5.99838, mean: 0.03749
[32m[0906 16-07-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18497, current rewards: 11.84077, mean: 0.05638
[32m[0906 16-07-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18484, current rewards: 17.67405, mean: 0.06798
[32m[0906 16-07-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18500, current rewards: 23.51241, mean: 0.07585
[32m[0906 16-07-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18505, current rewards: 29.41380, mean: 0.08170
[32m[0906 16-07-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18506, current rewards: 35.25745, mean: 0.08599
[32m[0906 16-08-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18520, current rewards: 41.10351, mean: 0.08936
[32m[0906 16-08-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18506, current rewards: 46.95124, mean: 0.09206
[32m[0906 16-08-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18519, current rewards: 29.24840, mean: 0.05223
[32m[0906 16-08-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18520, current rewards: 36.67153, mean: 0.06012
[32m[0906 16-08-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18519, current rewards: 44.16849, mean: 0.06692
[32m[0906 16-08-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18513, current rewards: 51.67640, mean: 0.07278
[32m[0906 16-08-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18507, current rewards: 62.62860, mean: 0.08241
[32m[0906 16-09-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18506, current rewards: 70.28279, mean: 0.08677
[32m[0906 16-09-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18500, current rewards: 77.93026, mean: 0.09062
[32m[0906 16-09-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18496, current rewards: 85.57962, mean: 0.09404
[32m[0906 16-09-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18496, current rewards: 93.23148, mean: 0.09712
[32m[0906 16-09-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18494, current rewards: 100.88334, mean: 0.09988
[32m[0906 16-09-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18493, current rewards: 108.53396, mean: 0.10239
[32m[0906 16-10-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18494, current rewards: 102.77207, mean: 0.09259
[32m[0906 16-10-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18492, current rewards: 107.95013, mean: 0.09306
[32m[0906 16-10-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18493, current rewards: 113.40997, mean: 0.09373
[32m[0906 16-10-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18496, current rewards: 118.93340, mean: 0.09439
[32m[0906 16-10-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18494, current rewards: 124.45549, mean: 0.09500
[32m[0906 16-10-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18493, current rewards: 129.97838, mean: 0.09557
[32m[0906 16-10-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18496, current rewards: 135.49581, mean: 0.09610
[32m[0906 16-11-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18495, current rewards: 141.01972, mean: 0.09659
[32m[0906 16-11-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18494, current rewards: 146.54444, mean: 0.09705
[32m[0906 16-11-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18480, current rewards: 152.05734, mean: 0.09747
[32m[0906 16-11-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18465, current rewards: 157.39114, mean: 0.09776
[32m[0906 16-11-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18452, current rewards: 162.83906, mean: 0.09810
[32m[0906 16-11-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18427, current rewards: 147.13114, mean: 0.08604
[32m[0906 16-12-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18403, current rewards: 153.48517, mean: 0.08721
[32m[0906 16-12-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18394, current rewards: 159.85112, mean: 0.08832
[32m[0906 16-12-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18385, current rewards: 166.21480, mean: 0.08936
[32m[0906 16-12-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18376, current rewards: 172.57364, mean: 0.09035
[32m[0906 16-12-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18384, current rewards: 178.93597, mean: 0.09129
[32m[0906 16-12-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18389, current rewards: 185.30334, mean: 0.09219
[32m[0906 16-12-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18393, current rewards: 191.66085, mean: 0.09304
[32m[0906 16-13-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18397, current rewards: 198.02755, mean: 0.09385
[32m[0906 16-13-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18391, current rewards: 204.39162, mean: 0.09463
[32m[0906 16-13-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18383, current rewards: 210.75494, mean: 0.09536
[32m[0906 16-13-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18375, current rewards: 217.11391, mean: 0.09607
[32m[0906 16-13-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18359, current rewards: 223.47576, mean: 0.09674
[32m[0906 16-13-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18344, current rewards: 229.84340, mean: 0.09739
[32m[0906 16-13-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18337, current rewards: 242.68070, mean: 0.10070
[32m[0906 16-14-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18332, current rewards: 249.02333, mean: 0.10123
[32m[0906 16-14-15 @Agent.py:117][0m Average action selection time: 0.1833
[32m[0906 16-14-15 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-14-15 @MBExp.py:227][0m Rewards obtained: [254.10327137128093], Lows: [21], Highs: [22], Total time: 8767.224349
[32m[0906 16-14-58 @MBExp.py:144][0m ####################################################################
[32m[0906 16-14-58 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 16-14-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18523, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-15-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18565, current rewards: -22.79128, mean: -0.37985
[32m[0906 16-15-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18566, current rewards: -28.87768, mean: -0.26252
[32m[0906 16-15-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18546, current rewards: -32.71615, mean: -0.20448
[32m[0906 16-15-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18533, current rewards: -36.79796, mean: -0.17523
[32m[0906 16-15-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18509, current rewards: -42.12039, mean: -0.16200
[32m[0906 16-15-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18501, current rewards: -73.93080, mean: -0.23849
[32m[0906 16-16-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18493, current rewards: -117.50599, mean: -0.32641
[32m[0906 16-16-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18489, current rewards: -157.89900, mean: -0.38512
[32m[0906 16-16-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18480, current rewards: -200.42316, mean: -0.43570
[32m[0906 16-16-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18481, current rewards: -242.94785, mean: -0.47637
[32m[0906 16-16-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18492, current rewards: -282.26770, mean: -0.50405
[32m[0906 16-16-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18501, current rewards: -323.79983, mean: -0.53082
[32m[0906 16-17-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18498, current rewards: -318.35721, mean: -0.48236
[32m[0906 16-17-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18494, current rewards: -312.18308, mean: -0.43969
[32m[0906 16-17-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18487, current rewards: -306.09048, mean: -0.40275
[32m[0906 16-17-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18482, current rewards: -299.99302, mean: -0.37036
[32m[0906 16-17-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18481, current rewards: -315.35349, mean: -0.36669
[32m[0906 16-17-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18481, current rewards: -310.22685, mean: -0.34091
[32m[0906 16-17-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18482, current rewards: -305.10538, mean: -0.31782
[32m[0906 16-18-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18480, current rewards: -299.98367, mean: -0.29701
[32m[0906 16-18-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18481, current rewards: -294.86222, mean: -0.27817
[32m[0906 16-18-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18482, current rewards: -303.07886, mean: -0.27304
[32m[0906 16-18-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18480, current rewards: -297.99410, mean: -0.25689
[32m[0906 16-18-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18479, current rewards: -292.91506, mean: -0.24208
[32m[0906 16-18-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18483, current rewards: -287.84055, mean: -0.22844
[32m[0906 16-19-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18484, current rewards: -303.18563, mean: -0.23144
[32m[0906 16-19-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18481, current rewards: -296.59250, mean: -0.21808
[32m[0906 16-19-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18478, current rewards: -290.00138, mean: -0.20567
[32m[0906 16-19-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18479, current rewards: -283.40079, mean: -0.19411
[32m[0906 16-19-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18476, current rewards: -277.07633, mean: -0.18349
[32m[0906 16-19-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18462, current rewards: -271.56197, mean: -0.17408
[32m[0906 16-19-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18448, current rewards: -265.30505, mean: -0.16479
[32m[0906 16-20-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18435, current rewards: -259.04818, mean: -0.15605
[32m[0906 16-20-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18408, current rewards: -252.79165, mean: -0.14783
[32m[0906 16-20-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18382, current rewards: -246.53822, mean: -0.14008
[32m[0906 16-20-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18372, current rewards: -240.28776, mean: -0.13276
[32m[0906 16-20-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18361, current rewards: -234.03023, mean: -0.12582
[32m[0906 16-20-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18352, current rewards: -227.78112, mean: -0.11926
[32m[0906 16-20-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18360, current rewards: -221.74912, mean: -0.11314
[32m[0906 16-21-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18366, current rewards: -215.48462, mean: -0.10721
[32m[0906 16-21-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18368, current rewards: -209.22534, mean: -0.10157
[32m[0906 16-21-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18370, current rewards: -202.94708, mean: -0.09618
[32m[0906 16-21-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18364, current rewards: -196.68079, mean: -0.09106
[32m[0906 16-21-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18358, current rewards: -190.42097, mean: -0.08616
[32m[0906 16-21-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18351, current rewards: -184.16359, mean: -0.08149
[32m[0906 16-22-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18336, current rewards: -177.89793, mean: -0.07701
[32m[0906 16-22-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18318, current rewards: -184.38285, mean: -0.07813
[32m[0906 16-22-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18311, current rewards: -188.12200, mean: -0.07806
[32m[0906 16-22-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18306, current rewards: -183.16616, mean: -0.07446
[32m[0906 16-22-36 @Agent.py:117][0m Average action selection time: 0.1830
[32m[0906 16-22-36 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-22-36 @MBExp.py:227][0m Rewards obtained: [-179.1631981497525], Lows: [30], Highs: [354], Total time: 9225.437724
[32m[0906 16-23-20 @MBExp.py:144][0m ####################################################################
[32m[0906 16-23-20 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 16-23-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18665, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-23-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18620, current rewards: -5.17493, mean: -0.08625
[32m[0906 16-23-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18582, current rewards: 0.66751, mean: 0.00607
[32m[0906 16-23-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18567, current rewards: 6.51265, mean: 0.04070
[32m[0906 16-23-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18536, current rewards: 12.35914, mean: 0.05885
[32m[0906 16-24-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18529, current rewards: 18.82972, mean: 0.07242
[32m[0906 16-24-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18520, current rewards: 24.75383, mean: 0.07985
[32m[0906 16-24-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18510, current rewards: 30.67796, mean: 0.08522
[32m[0906 16-24-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18507, current rewards: 36.59986, mean: 0.08927
[32m[0906 16-24-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18514, current rewards: 21.22544, mean: 0.04614
[32m[0906 16-24-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18513, current rewards: 27.08747, mean: 0.05311
[32m[0906 16-25-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18513, current rewards: 32.95224, mean: 0.05884
[32m[0906 16-25-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18513, current rewards: 38.81708, mean: 0.06363
[32m[0906 16-25-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18508, current rewards: 43.47040, mean: 0.06586
[32m[0906 16-25-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18507, current rewards: 49.02023, mean: 0.06904
[32m[0906 16-25-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18502, current rewards: 54.56257, mean: 0.07179
[32m[0906 16-25-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18495, current rewards: 60.10999, mean: 0.07421
[32m[0906 16-25-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18492, current rewards: 65.65658, mean: 0.07634
[32m[0906 16-26-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18489, current rewards: 59.01476, mean: 0.06485
[32m[0906 16-26-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18493, current rewards: 63.88025, mean: 0.06654
[32m[0906 16-26-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18486, current rewards: 68.66195, mean: 0.06798
[32m[0906 16-26-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18481, current rewards: 73.70155, mean: 0.06953
[32m[0906 16-26-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18479, current rewards: 79.88885, mean: 0.07197
[32m[0906 16-26-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18474, current rewards: 84.96984, mean: 0.07325
[32m[0906 16-27-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18471, current rewards: 90.04869, mean: 0.07442
[32m[0906 16-27-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18475, current rewards: 74.04477, mean: 0.05877
[32m[0906 16-27-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18475, current rewards: 79.89848, mean: 0.06099
[32m[0906 16-27-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18471, current rewards: 85.74459, mean: 0.06305
[32m[0906 16-27-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18470, current rewards: 91.59398, mean: 0.06496
[32m[0906 16-27-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18469, current rewards: 96.81052, mean: 0.06631
[32m[0906 16-27-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18469, current rewards: 101.86258, mean: 0.06746
[32m[0906 16-28-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18457, current rewards: 107.43713, mean: 0.06887
[32m[0906 16-28-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18444, current rewards: 113.01490, mean: 0.07020
[32m[0906 16-28-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18430, current rewards: 118.59753, mean: 0.07144
[32m[0906 16-28-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18403, current rewards: 124.18267, mean: 0.07262
[32m[0906 16-28-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18380, current rewards: 129.76948, mean: 0.07373
[32m[0906 16-28-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18365, current rewards: 135.34624, mean: 0.07478
[32m[0906 16-29-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18356, current rewards: 140.92730, mean: 0.07577
[32m[0906 16-29-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18348, current rewards: 146.20597, mean: 0.07655
[32m[0906 16-29-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18356, current rewards: 151.79475, mean: 0.07745
[32m[0906 16-29-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18362, current rewards: 135.83752, mean: 0.06758
[32m[0906 16-29-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18367, current rewards: 141.50417, mean: 0.06869
[32m[0906 16-29-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18373, current rewards: 147.20187, mean: 0.06976
[32m[0906 16-29-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18368, current rewards: 152.89230, mean: 0.07078
[32m[0906 16-30-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18362, current rewards: 158.58033, mean: 0.07176
[32m[0906 16-30-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18357, current rewards: 164.27392, mean: 0.07269
[32m[0906 16-30-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18343, current rewards: 170.92782, mean: 0.07399
[32m[0906 16-30-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18326, current rewards: 178.01137, mean: 0.07543
[32m[0906 16-30-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18315, current rewards: 183.83084, mean: 0.07628
[32m[0906 16-30-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18311, current rewards: 187.41018, mean: 0.07618
[32m[0906 16-30-58 @Agent.py:117][0m Average action selection time: 0.1831
[32m[0906 16-30-58 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-30-58 @MBExp.py:227][0m Rewards obtained: [182.84051196004728], Lows: [30], Highs: [32], Total time: 9683.808084
[32m[0906 16-31-45 @MBExp.py:144][0m ####################################################################
[32m[0906 16-31-45 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 16-31-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18582, current rewards: -2.62307, mean: -0.26231
[32m[0906 16-31-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18580, current rewards: 1.96085, mean: 0.03268
[32m[0906 16-32-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18571, current rewards: 6.79282, mean: 0.06175
[32m[0906 16-32-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18532, current rewards: 11.62664, mean: 0.07267
[32m[0906 16-32-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18496, current rewards: 16.45956, mean: 0.07838
[32m[0906 16-32-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18480, current rewards: 23.00463, mean: 0.08848
[32m[0906 16-32-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18470, current rewards: 28.00971, mean: 0.09035
[32m[0906 16-32-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18465, current rewards: 33.01486, mean: 0.09171
[32m[0906 16-33-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18480, current rewards: 25.82604, mean: 0.06299
[32m[0906 16-33-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18483, current rewards: 30.58329, mean: 0.06649
[32m[0906 16-33-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18484, current rewards: 35.33178, mean: 0.06928
[32m[0906 16-33-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18494, current rewards: 40.07585, mean: 0.07156
[32m[0906 16-33-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18495, current rewards: 44.82136, mean: 0.07348
[32m[0906 16-33-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18488, current rewards: 50.21712, mean: 0.07609
[32m[0906 16-33-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18481, current rewards: 34.32177, mean: 0.04834
[32m[0906 16-34-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18478, current rewards: 39.33135, mean: 0.05175
[32m[0906 16-34-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18476, current rewards: 44.34130, mean: 0.05474
[32m[0906 16-34-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18474, current rewards: 49.34999, mean: 0.05738
[32m[0906 16-34-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18472, current rewards: 54.35815, mean: 0.05973
[32m[0906 16-34-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18470, current rewards: 59.36283, mean: 0.06184
[32m[0906 16-34-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18469, current rewards: 64.37240, mean: 0.06374
[32m[0906 16-35-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18463, current rewards: 65.82418, mean: 0.06210
[32m[0906 16-35-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18464, current rewards: 62.14992, mean: 0.05599
[32m[0906 16-35-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18463, current rewards: 66.68061, mean: 0.05748
[32m[0906 16-35-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18463, current rewards: 71.21087, mean: 0.05885
[32m[0906 16-35-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18466, current rewards: 75.74244, mean: 0.06011
[32m[0906 16-35-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18466, current rewards: 80.27016, mean: 0.06127
[32m[0906 16-35-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18466, current rewards: 84.79824, mean: 0.06235
[32m[0906 16-36-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18466, current rewards: 89.32770, mean: 0.06335
[32m[0906 16-36-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18463, current rewards: 93.85714, mean: 0.06429
[32m[0906 16-36-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18463, current rewards: 86.27540, mean: 0.05714
[32m[0906 16-36-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18451, current rewards: 91.06983, mean: 0.05838
[32m[0906 16-36-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18438, current rewards: 95.72758, mean: 0.05946
[32m[0906 16-36-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18419, current rewards: 100.38578, mean: 0.06047
[32m[0906 16-36-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18390, current rewards: 105.03806, mean: 0.06143
[32m[0906 16-37-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18365, current rewards: 109.69470, mean: 0.06233
[32m[0906 16-37-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18347, current rewards: 114.35153, mean: 0.06318
[32m[0906 16-37-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18339, current rewards: 119.01043, mean: 0.06398
[32m[0906 16-37-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18330, current rewards: 123.68344, mean: 0.06476
[32m[0906 16-37-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18339, current rewards: 128.59816, mean: 0.06561
[32m[0906 16-37-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18346, current rewards: 135.97505, mean: 0.06765
[32m[0906 16-38-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18350, current rewards: 140.74070, mean: 0.06832
[32m[0906 16-38-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18354, current rewards: 145.50227, mean: 0.06896
[32m[0906 16-38-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18351, current rewards: 150.27209, mean: 0.06957
[32m[0906 16-38-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18344, current rewards: 155.03782, mean: 0.07015
[32m[0906 16-38-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18339, current rewards: 159.80463, mean: 0.07071
[32m[0906 16-38-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18327, current rewards: 164.57162, mean: 0.07124
[32m[0906 16-38-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18309, current rewards: 169.30113, mean: 0.07174
[32m[0906 16-39-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18295, current rewards: 153.53389, mean: 0.06371
[32m[0906 16-39-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18291, current rewards: 158.51231, mean: 0.06444
[32m[0906 16-39-22 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0906 16-39-22 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-39-22 @MBExp.py:227][0m Rewards obtained: [162.5024843926226], Lows: [21], Highs: [34], Total time: 10141.692964
[32m[0906 16-40-11 @MBExp.py:144][0m ####################################################################
[32m[0906 16-40-11 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 16-40-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18689, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-40-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18604, current rewards: -5.76753, mean: -0.09613
[32m[0906 16-40-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18644, current rewards: -0.43150, mean: -0.00392
[32m[0906 16-40-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18610, current rewards: 4.90511, mean: 0.03066
[32m[0906 16-40-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18607, current rewards: 10.24039, mean: 0.04876
[32m[0906 16-40-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18579, current rewards: 17.40686, mean: 0.06695
[32m[0906 16-41-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18557, current rewards: 22.88081, mean: 0.07381
[32m[0906 16-41-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18556, current rewards: 28.35674, mean: 0.07877
[32m[0906 16-41-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18555, current rewards: 13.42633, mean: 0.03275
[32m[0906 16-41-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18542, current rewards: 19.75715, mean: 0.04295
[32m[0906 16-41-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18530, current rewards: 25.33287, mean: 0.04967
[32m[0906 16-41-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18539, current rewards: 30.90836, mean: 0.05519
[32m[0906 16-42-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18539, current rewards: 36.48568, mean: 0.05981
[32m[0906 16-42-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18534, current rewards: 41.40089, mean: 0.06273
[32m[0906 16-42-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18532, current rewards: 46.87577, mean: 0.06602
[32m[0906 16-42-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18529, current rewards: 52.38657, mean: 0.06893
[32m[0906 16-42-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18520, current rewards: 57.89648, mean: 0.07148
[32m[0906 16-42-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18519, current rewards: 43.04305, mean: 0.05005
[32m[0906 16-42-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18515, current rewards: 49.13728, mean: 0.05400
[32m[0906 16-43-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18515, current rewards: 55.22190, mean: 0.05752
[32m[0906 16-43-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18512, current rewards: 61.30854, mean: 0.06070
[32m[0906 16-43-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18510, current rewards: 67.35431, mean: 0.06354
[32m[0906 16-43-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18508, current rewards: 72.69334, mean: 0.06549
[32m[0906 16-43-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18506, current rewards: 78.50229, mean: 0.06767
[32m[0906 16-43-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18503, current rewards: 73.01454, mean: 0.06034
[32m[0906 16-44-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18506, current rewards: 78.30650, mean: 0.06215
[32m[0906 16-44-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18506, current rewards: 83.59839, mean: 0.06382
[32m[0906 16-44-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18502, current rewards: 88.88840, mean: 0.06536
[32m[0906 16-44-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18499, current rewards: 94.17303, mean: 0.06679
[32m[0906 16-44-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18497, current rewards: 99.46301, mean: 0.06813
[32m[0906 16-44-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18495, current rewards: 108.00769, mean: 0.07153
[32m[0906 16-44-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18484, current rewards: 113.70529, mean: 0.07289
[32m[0906 16-45-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18470, current rewards: 116.07575, mean: 0.07210
[32m[0906 16-45-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18450, current rewards: 113.81663, mean: 0.06856
[32m[0906 16-45-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18422, current rewards: 119.25468, mean: 0.06974
[32m[0906 16-45-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18397, current rewards: 124.69116, mean: 0.07085
[32m[0906 16-45-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18375, current rewards: 130.12309, mean: 0.07189
[32m[0906 16-45-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18367, current rewards: 135.55497, mean: 0.07288
[32m[0906 16-46-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18361, current rewards: 140.82623, mean: 0.07373
[32m[0906 16-46-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18367, current rewards: 146.23983, mean: 0.07461
[32m[0906 16-46-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18373, current rewards: 130.57777, mean: 0.06496
[32m[0906 16-46-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18377, current rewards: 136.18711, mean: 0.06611
[32m[0906 16-46-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18379, current rewards: 141.70587, mean: 0.06716
[32m[0906 16-46-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18375, current rewards: 147.22393, mean: 0.06816
[32m[0906 16-46-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18367, current rewards: 152.74577, mean: 0.06912
[32m[0906 16-47-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18360, current rewards: 158.26292, mean: 0.07003
[32m[0906 16-47-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18349, current rewards: 163.65720, mean: 0.07085
[32m[0906 16-47-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18332, current rewards: 168.17108, mean: 0.07126
[32m[0906 16-47-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18315, current rewards: 173.41584, mean: 0.07196
[32m[0906 16-47-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18309, current rewards: 178.19657, mean: 0.07244
[32m[0906 16-47-49 @Agent.py:117][0m Average action selection time: 0.1831
[32m[0906 16-47-49 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-47-49 @MBExp.py:227][0m Rewards obtained: [182.45690365680952], Lows: [30], Highs: [31], Total time: 10600.005342
[32m[0906 16-48-39 @MBExp.py:144][0m ####################################################################
[32m[0906 16-48-39 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 16-48-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18738, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-48-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18593, current rewards: -5.79551, mean: -0.09659
[32m[0906 16-49-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18586, current rewards: -0.24716, mean: -0.00225
[32m[0906 16-49-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18587, current rewards: 5.30443, mean: 0.03315
[32m[0906 16-49-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18577, current rewards: 10.85569, mean: 0.05169
[32m[0906 16-49-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18564, current rewards: 15.70859, mean: 0.06042
[32m[0906 16-49-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18546, current rewards: 20.92627, mean: 0.06750
[32m[0906 16-49-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18536, current rewards: 26.22368, mean: 0.07284
[32m[0906 16-49-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18523, current rewards: 31.51620, mean: 0.07687
[32m[0906 16-50-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18523, current rewards: 36.81493, mean: 0.08003
[32m[0906 16-50-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18524, current rewards: 42.10820, mean: 0.08257
[32m[0906 16-50-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18527, current rewards: 47.39781, mean: 0.08464
[32m[0906 16-50-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18523, current rewards: 44.26535, mean: 0.07257
[32m[0906 16-50-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18524, current rewards: 36.89970, mean: 0.05591
[32m[0906 16-50-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18522, current rewards: 46.33098, mean: 0.06525
[32m[0906 16-51-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18516, current rewards: 52.30937, mean: 0.06883
[32m[0906 16-51-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18513, current rewards: 58.29541, mean: 0.07197
[32m[0906 16-51-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18505, current rewards: 64.27713, mean: 0.07474
[32m[0906 16-51-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18505, current rewards: 58.83165, mean: 0.06465
[32m[0906 16-51-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18499, current rewards: 63.98802, mean: 0.06665
[32m[0906 16-51-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18494, current rewards: 69.14682, mean: 0.06846
[32m[0906 16-51-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18491, current rewards: 74.31010, mean: 0.07010
[32m[0906 16-52-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18487, current rewards: 79.26126, mean: 0.07141
[32m[0906 16-52-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18485, current rewards: 84.37006, mean: 0.07273
[32m[0906 16-52-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18488, current rewards: 89.47129, mean: 0.07394
[32m[0906 16-52-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18488, current rewards: 94.57013, mean: 0.07506
[32m[0906 16-52-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18486, current rewards: 78.58711, mean: 0.05999
[32m[0906 16-52-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18485, current rewards: 83.73749, mean: 0.06157
[32m[0906 16-53-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18484, current rewards: 88.87981, mean: 0.06304
[32m[0906 16-53-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18481, current rewards: 94.02549, mean: 0.06440
[32m[0906 16-53-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18481, current rewards: 98.93801, mean: 0.06552
[32m[0906 16-53-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18470, current rewards: 103.78652, mean: 0.06653
[32m[0906 16-53-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18457, current rewards: 108.91300, mean: 0.06765
[32m[0906 16-53-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18431, current rewards: 114.03537, mean: 0.06870
[32m[0906 16-53-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18403, current rewards: 119.15593, mean: 0.06968
[32m[0906 16-54-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18377, current rewards: 124.27958, mean: 0.07061
[32m[0906 16-54-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18352, current rewards: 108.30431, mean: 0.05984
[32m[0906 16-54-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18342, current rewards: 113.75471, mean: 0.06116
[32m[0906 16-54-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18336, current rewards: 119.22677, mean: 0.06242
[32m[0906 16-54-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18341, current rewards: 124.51492, mean: 0.06353
[32m[0906 16-54-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18345, current rewards: 130.00680, mean: 0.06468
[32m[0906 16-54-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18349, current rewards: 135.49778, mean: 0.06578
[32m[0906 16-55-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18355, current rewards: 140.98322, mean: 0.06682
[32m[0906 16-55-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18353, current rewards: 134.20051, mean: 0.06213
[32m[0906 16-55-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18345, current rewards: 139.09228, mean: 0.06294
[32m[0906 16-55-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18338, current rewards: 143.98422, mean: 0.06371
[32m[0906 16-55-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18326, current rewards: 148.88153, mean: 0.06445
[32m[0906 16-55-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18309, current rewards: 154.89269, mean: 0.06563
[32m[0906 16-56-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18293, current rewards: 159.90756, mean: 0.06635
[32m[0906 16-56-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18284, current rewards: 144.24525, mean: 0.05864
[32m[0906 16-56-17 @Agent.py:117][0m Average action selection time: 0.1828
[32m[0906 16-56-17 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-56-17 @MBExp.py:227][0m Rewards obtained: [148.6546929320395], Lows: [40], Highs: [32], Total time: 11057.650074000001
[32m[0906 16-57-09 @MBExp.py:144][0m ####################################################################
[32m[0906 16-57-09 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 16-57-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18677, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-57-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18561, current rewards: -16.85992, mean: -0.28100
[32m[0906 16-57-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18590, current rewards: -12.73245, mean: -0.11575
[32m[0906 16-57-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18553, current rewards: -8.60496, mean: -0.05378
[32m[0906 16-57-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18525, current rewards: -4.47742, mean: -0.02132
[32m[0906 16-57-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18530, current rewards: -0.34941, mean: -0.00134
[32m[0906 16-58-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18513, current rewards: 3.77775, mean: 0.01219
[32m[0906 16-58-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18505, current rewards: 7.90832, mean: 0.02197
[32m[0906 16-58-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18493, current rewards: 12.03756, mean: 0.02936
[32m[0906 16-58-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18489, current rewards: 16.16666, mean: 0.03514
[32m[0906 16-58-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18492, current rewards: 20.29496, mean: 0.03979
[32m[0906 16-58-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18492, current rewards: 24.42336, mean: 0.04361
[32m[0906 16-59-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18492, current rewards: 28.54917, mean: 0.04680
[32m[0906 16-59-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18491, current rewards: 33.47809, mean: 0.05072
[32m[0906 16-59-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18495, current rewards: 37.94433, mean: 0.05344
[32m[0906 16-59-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18493, current rewards: 21.28596, mean: 0.02801
[32m[0906 16-59-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18490, current rewards: 14.32084, mean: 0.01768
[32m[0906 16-59-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18485, current rewards: 21.24750, mean: 0.02471
[32m[0906 16-59-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18482, current rewards: 28.17416, mean: 0.03096
[32m[0906 17-00-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18481, current rewards: 35.10081, mean: 0.03656
[32m[0906 17-00-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18479, current rewards: 42.02747, mean: 0.04161
[32m[0906 17-00-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18483, current rewards: 48.95413, mean: 0.04618
[32m[0906 17-00-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18482, current rewards: 26.09992, mean: 0.02351
[32m[0906 17-00-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18488, current rewards: -23.90008, mean: -0.02060
[32m[0906 17-00-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18489, current rewards: -73.90008, mean: -0.06107
[32m[0906 17-01-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18488, current rewards: -123.90008, mean: -0.09833
[32m[0906 17-01-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18488, current rewards: -173.90008, mean: -0.13275
[32m[0906 17-01-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18485, current rewards: -223.90008, mean: -0.16463
[32m[0906 17-01-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18482, current rewards: -273.90008, mean: -0.19426
[32m[0906 17-01-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18480, current rewards: -323.90008, mean: -0.22185
[32m[0906 17-01-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18477, current rewards: -373.90008, mean: -0.24762
[32m[0906 17-01-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18466, current rewards: -423.90008, mean: -0.27173
[32m[0906 17-02-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18452, current rewards: -473.90008, mean: -0.29435
[32m[0906 17-02-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18423, current rewards: -523.90008, mean: -0.31560
[32m[0906 17-02-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18396, current rewards: -573.90008, mean: -0.33561
[32m[0906 17-02-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18370, current rewards: -623.90008, mean: -0.35449
[32m[0906 17-02-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18345, current rewards: -673.90008, mean: -0.37232
[32m[0906 17-02-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18334, current rewards: -723.90008, mean: -0.38919
[32m[0906 17-03-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18327, current rewards: -773.90008, mean: -0.40518
[32m[0906 17-03-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18333, current rewards: -823.90008, mean: -0.42036
[32m[0906 17-03-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18339, current rewards: -873.90008, mean: -0.43478
[32m[0906 17-03-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18344, current rewards: -923.90008, mean: -0.44850
[32m[0906 17-03-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18346, current rewards: -973.90008, mean: -0.46156
[32m[0906 17-03-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18346, current rewards: -1023.90008, mean: -0.47403
[32m[0906 17-03-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18339, current rewards: -1073.90008, mean: -0.48593
[32m[0906 17-04-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18332, current rewards: -1123.90008, mean: -0.49730
[32m[0906 17-04-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18322, current rewards: -1173.90008, mean: -0.50818
[32m[0906 17-04-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18305, current rewards: -1223.90008, mean: -0.51860
[32m[0906 17-04-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18289, current rewards: -1273.90008, mean: -0.52859
[32m[0906 17-04-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18276, current rewards: -1323.90008, mean: -0.53817
[32m[0906 17-04-47 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0906 17-04-47 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-04-47 @MBExp.py:227][0m Rewards obtained: [-1363.900075753986], Lows: [22], Highs: [1426], Total time: 11515.114060000002
[32m[0906 17-05-41 @MBExp.py:144][0m ####################################################################
[32m[0906 17-05-41 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 17-05-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18670, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-05-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18604, current rewards: -3.83261, mean: -0.06388
[32m[0906 17-06-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18518, current rewards: 1.41960, mean: 0.01291
[32m[0906 17-06-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18482, current rewards: 6.67946, mean: 0.04175
[32m[0906 17-06-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18489, current rewards: 11.94241, mean: 0.05687
[32m[0906 17-06-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18483, current rewards: 17.20125, mean: 0.06616
[32m[0906 17-06-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18490, current rewards: 22.07078, mean: 0.07120
[32m[0906 17-06-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18484, current rewards: 27.16254, mean: 0.07545
[32m[0906 17-06-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18492, current rewards: 32.26147, mean: 0.07869
[32m[0906 17-07-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18501, current rewards: 14.17812, mean: 0.03082
[32m[0906 17-07-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18497, current rewards: 20.90371, mean: 0.04099
[32m[0906 17-07-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18492, current rewards: 28.05185, mean: 0.05009
[32m[0906 17-07-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18489, current rewards: 35.19667, mean: 0.05770
[32m[0906 17-07-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18488, current rewards: 42.34335, mean: 0.06416
[32m[0906 17-07-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18495, current rewards: 49.78360, mean: 0.07012
[32m[0906 17-08-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18495, current rewards: 54.56421, mean: 0.07180
[32m[0906 17-08-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18492, current rewards: 59.34483, mean: 0.07327
[32m[0906 17-08-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18488, current rewards: 64.12544, mean: 0.07456
[32m[0906 17-08-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18485, current rewards: 68.90605, mean: 0.07572
[32m[0906 17-08-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18486, current rewards: 73.68666, mean: 0.07676
[32m[0906 17-08-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18484, current rewards: 33.54717, mean: 0.03322
[32m[0906 17-08-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18484, current rewards: -16.45283, mean: -0.01552
[32m[0906 17-09-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18482, current rewards: -66.45283, mean: -0.05987
[32m[0906 17-09-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18485, current rewards: -116.45283, mean: -0.10039
[32m[0906 17-09-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18483, current rewards: -166.45283, mean: -0.13756
[32m[0906 17-09-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18485, current rewards: -216.45283, mean: -0.17179
[32m[0906 17-09-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18481, current rewards: -266.45283, mean: -0.20340
[32m[0906 17-09-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18481, current rewards: -316.45283, mean: -0.23269
[32m[0906 17-10-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18482, current rewards: -366.45283, mean: -0.25990
[32m[0906 17-10-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18483, current rewards: -416.45283, mean: -0.28524
[32m[0906 17-10-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18481, current rewards: -466.45283, mean: -0.30891
[32m[0906 17-10-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18468, current rewards: -516.45283, mean: -0.33106
[32m[0906 17-10-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18454, current rewards: -566.45283, mean: -0.35183
[32m[0906 17-10-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18425, current rewards: -616.45283, mean: -0.37136
[32m[0906 17-10-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18397, current rewards: -666.45283, mean: -0.38974
[32m[0906 17-11-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18372, current rewards: -716.45283, mean: -0.40708
[32m[0906 17-11-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18350, current rewards: -766.45283, mean: -0.42345
[32m[0906 17-11-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18332, current rewards: -816.45283, mean: -0.43895
[32m[0906 17-11-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18325, current rewards: -866.45283, mean: -0.45364
[32m[0906 17-11-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18328, current rewards: -916.45283, mean: -0.46758
[32m[0906 17-11-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18335, current rewards: -966.45283, mean: -0.48082
[32m[0906 17-11-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18338, current rewards: -1016.45283, mean: -0.49342
[32m[0906 17-12-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18342, current rewards: -1066.45283, mean: -0.50543
[32m[0906 17-12-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18344, current rewards: -1116.45283, mean: -0.51688
[32m[0906 17-12-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18337, current rewards: -1166.45283, mean: -0.52781
[32m[0906 17-12-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18329, current rewards: -1216.45283, mean: -0.53825
[32m[0906 17-12-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18321, current rewards: -1266.45283, mean: -0.54825
[32m[0906 17-12-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18304, current rewards: -1316.45283, mean: -0.55782
[32m[0906 17-13-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18287, current rewards: -1366.45283, mean: -0.56699
[32m[0906 17-13-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18270, current rewards: -1416.45283, mean: -0.57579
[32m[0906 17-13-18 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0906 17-13-18 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-13-19 @MBExp.py:227][0m Rewards obtained: [-1456.4528307639068], Lows: [11], Highs: [1541], Total time: 11972.499703000001
[32m[0906 17-14-15 @MBExp.py:144][0m ####################################################################
[32m[0906 17-14-15 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 17-14-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18507, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-14-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18609, current rewards: -4.31885, mean: -0.07198
[32m[0906 17-14-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18509, current rewards: 0.43870, mean: 0.00399
[32m[0906 17-14-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18551, current rewards: 5.19482, mean: 0.03247
[32m[0906 17-14-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18534, current rewards: -0.98839, mean: -0.00471
[32m[0906 17-15-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18537, current rewards: 4.45431, mean: 0.01713
[32m[0906 17-15-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18534, current rewards: 9.89322, mean: 0.03191
[32m[0906 17-15-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18525, current rewards: 15.33408, mean: 0.04259
[32m[0906 17-15-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18523, current rewards: 20.77324, mean: 0.05067
[32m[0906 17-15-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18521, current rewards: 26.21155, mean: 0.05698
[32m[0906 17-15-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18516, current rewards: 31.64835, mean: 0.06206
[32m[0906 17-15-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18513, current rewards: 37.08826, mean: 0.06623
[32m[0906 17-16-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18513, current rewards: 41.42562, mean: 0.06791
[32m[0906 17-16-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18513, current rewards: 46.06505, mean: 0.06980
[32m[0906 17-16-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18507, current rewards: 50.16341, mean: 0.07065
[32m[0906 17-16-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18505, current rewards: 54.70742, mean: 0.07198
[32m[0906 17-16-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18503, current rewards: 59.23224, mean: 0.07313
[32m[0906 17-16-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18495, current rewards: 63.75721, mean: 0.07414
[32m[0906 17-17-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18493, current rewards: 68.27408, mean: 0.07503
[32m[0906 17-17-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18492, current rewards: 72.79307, mean: 0.07583
[32m[0906 17-17-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18491, current rewards: 77.31414, mean: 0.07655
[32m[0906 17-17-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18493, current rewards: 81.83693, mean: 0.07720
[32m[0906 17-17-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18490, current rewards: 65.50909, mean: 0.05902
[32m[0906 17-17-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18489, current rewards: 71.14758, mean: 0.06133
[32m[0906 17-17-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18490, current rewards: 75.89245, mean: 0.06272
[32m[0906 17-18-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18490, current rewards: 80.63513, mean: 0.06400
[32m[0906 17-18-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18484, current rewards: 85.37872, mean: 0.06517
[32m[0906 17-18-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18481, current rewards: 90.12028, mean: 0.06626
[32m[0906 17-18-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18479, current rewards: 94.86201, mean: 0.06728
[32m[0906 17-18-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18479, current rewards: 99.60635, mean: 0.06822
[32m[0906 17-18-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18477, current rewards: 104.34827, mean: 0.06910
[32m[0906 17-19-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18467, current rewards: 87.48990, mean: 0.05608
[32m[0906 17-19-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18447, current rewards: 92.32975, mean: 0.05735
[32m[0906 17-19-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18418, current rewards: 97.14009, mean: 0.05852
[32m[0906 17-19-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18391, current rewards: 101.95325, mean: 0.05962
[32m[0906 17-19-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18368, current rewards: 106.76473, mean: 0.06066
[32m[0906 17-19-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18344, current rewards: 92.71095, mean: 0.05122
[32m[0906 17-19-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18322, current rewards: 95.31150, mean: 0.05124
[32m[0906 17-20-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18316, current rewards: 100.03935, mean: 0.05238
[32m[0906 17-20-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18319, current rewards: 107.16831, mean: 0.05468
[32m[0906 17-20-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18325, current rewards: 115.24260, mean: 0.05733
[32m[0906 17-20-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18328, current rewards: 123.31689, mean: 0.05986
[32m[0906 17-20-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18332, current rewards: 90.73917, mean: 0.04300
[32m[0906 17-20-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18334, current rewards: 40.73917, mean: 0.01886
[32m[0906 17-21-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18325, current rewards: -9.26083, mean: -0.00419
[32m[0906 17-21-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18320, current rewards: -59.26083, mean: -0.02622
[32m[0906 17-21-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18313, current rewards: -109.26083, mean: -0.04730
[32m[0906 17-21-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18295, current rewards: -159.26083, mean: -0.06748
[32m[0906 17-21-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18278, current rewards: -209.26083, mean: -0.08683
[32m[0906 17-21-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18264, current rewards: -259.26083, mean: -0.10539
[32m[0906 17-21-52 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0906 17-21-52 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-21-52 @MBExp.py:227][0m Rewards obtained: [-299.26082837391965], Lows: [30], Highs: [445], Total time: 12429.604033000001
[32m[0906 17-22-50 @MBExp.py:144][0m ####################################################################
[32m[0906 17-22-50 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 17-22-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18628, current rewards: 0.77523, mean: 0.07752
[32m[0906 17-23-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18550, current rewards: 7.16486, mean: 0.11941
[32m[0906 17-23-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18531, current rewards: 13.50586, mean: 0.12278
[32m[0906 17-23-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18528, current rewards: 19.84802, mean: 0.12405
[32m[0906 17-23-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18516, current rewards: 26.18979, mean: 0.12471
[32m[0906 17-23-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18503, current rewards: 32.52813, mean: 0.12511
[32m[0906 17-23-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18516, current rewards: 37.84670, mean: 0.12209
[32m[0906 17-23-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18515, current rewards: 45.74215, mean: 0.12706
[32m[0906 17-24-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18513, current rewards: 40.34294, mean: 0.09840
[32m[0906 17-24-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18507, current rewards: 44.83439, mean: 0.09747
[32m[0906 17-24-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18506, current rewards: 49.32913, mean: 0.09672
[32m[0906 17-24-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18504, current rewards: 53.82334, mean: 0.09611
[32m[0906 17-24-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18498, current rewards: 58.31507, mean: 0.09560
[32m[0906 17-24-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18494, current rewards: 62.80918, mean: 0.09517
[32m[0906 17-25-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18489, current rewards: 67.46264, mean: 0.09502
[32m[0906 17-25-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18488, current rewards: 72.00036, mean: 0.09474
[32m[0906 17-25-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18484, current rewards: 76.54837, mean: 0.09450
[32m[0906 17-25-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18486, current rewards: 81.09808, mean: 0.09430
[32m[0906 17-25-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18486, current rewards: 85.64580, mean: 0.09412
[32m[0906 17-25-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18485, current rewards: 85.56925, mean: 0.08913
[32m[0906 17-25-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18493, current rewards: 90.43449, mean: 0.08954
[32m[0906 17-26-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18495, current rewards: 95.31024, mean: 0.08992
[32m[0906 17-26-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18491, current rewards: 100.52872, mean: 0.09057
[32m[0906 17-26-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18489, current rewards: 105.81067, mean: 0.09122
[32m[0906 17-26-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18490, current rewards: 111.06780, mean: 0.09179
[32m[0906 17-26-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18489, current rewards: 116.32503, mean: 0.09232
[32m[0906 17-26-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18487, current rewards: 121.58057, mean: 0.09281
[32m[0906 17-27-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18486, current rewards: 126.83817, mean: 0.09326
[32m[0906 17-27-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18488, current rewards: 129.99375, mean: 0.09219
[32m[0906 17-27-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18489, current rewards: 116.15614, mean: 0.07956
[32m[0906 17-27-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18487, current rewards: 121.35252, mean: 0.08037
[32m[0906 17-27-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18479, current rewards: 126.64207, mean: 0.08118
[32m[0906 17-27-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18456, current rewards: 131.74713, mean: 0.08183
[32m[0906 17-27-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18427, current rewards: 136.85306, mean: 0.08244
[32m[0906 17-28-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18402, current rewards: 129.13975, mean: 0.07552
[32m[0906 17-28-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18375, current rewards: 133.62891, mean: 0.07593
[32m[0906 17-28-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18349, current rewards: 137.60235, mean: 0.07602
[32m[0906 17-28-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18326, current rewards: 141.57602, mean: 0.07612
[32m[0906 17-28-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18316, current rewards: 145.55343, mean: 0.07621
[32m[0906 17-28-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18319, current rewards: 150.19507, mean: 0.07663
[32m[0906 17-28-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18325, current rewards: 154.44919, mean: 0.07684
[32m[0906 17-29-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18329, current rewards: 158.70504, mean: 0.07704
[32m[0906 17-29-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18331, current rewards: 162.95915, mean: 0.07723
[32m[0906 17-29-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18333, current rewards: 148.01116, mean: 0.06852
[32m[0906 17-29-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18327, current rewards: 154.20241, mean: 0.06977
[32m[0906 17-29-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18320, current rewards: 160.38759, mean: 0.07097
[32m[0906 17-29-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18313, current rewards: 166.57082, mean: 0.07211
[32m[0906 17-30-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18297, current rewards: 173.17296, mean: 0.07338
[32m[0906 17-30-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18281, current rewards: 179.45996, mean: 0.07446
[32m[0906 17-30-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18264, current rewards: 172.66885, mean: 0.07019
[32m[0906 17-30-27 @Agent.py:117][0m Average action selection time: 0.1825
[32m[0906 17-30-27 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-30-27 @MBExp.py:227][0m Rewards obtained: [178.40457484089913], Lows: [22], Highs: [34], Total time: 12886.602495000001
[32m[0906 17-31-27 @MBExp.py:144][0m ####################################################################
[32m[0906 17-31-27 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 17-31-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18485, current rewards: 0.75356, mean: 0.07536
[32m[0906 17-31-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18632, current rewards: 6.35487, mean: 0.10591
[32m[0906 17-31-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18572, current rewards: 13.09029, mean: 0.11900
[32m[0906 17-31-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18565, current rewards: 19.82160, mean: 0.12389
[32m[0906 17-32-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18561, current rewards: 26.56053, mean: 0.12648
[32m[0906 17-32-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18575, current rewards: 33.10339, mean: 0.12732
[32m[0906 17-32-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18566, current rewards: 39.92656, mean: 0.12880
[32m[0906 17-32-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18561, current rewards: 46.74377, mean: 0.12984
[32m[0906 17-32-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18550, current rewards: 53.56226, mean: 0.13064
[32m[0906 17-32-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18543, current rewards: 60.38229, mean: 0.13127
[32m[0906 17-33-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18541, current rewards: 67.20117, mean: 0.13177
[32m[0906 17-33-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18539, current rewards: 74.01234, mean: 0.13216
[32m[0906 17-33-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18526, current rewards: 80.84716, mean: 0.13254
[32m[0906 17-33-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18520, current rewards: 87.55363, mean: 0.13266
[32m[0906 17-33-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18516, current rewards: 72.95593, mean: 0.10275
[32m[0906 17-33-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18515, current rewards: 78.66160, mean: 0.10350
[32m[0906 17-33-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18515, current rewards: 84.38173, mean: 0.10417
[32m[0906 17-34-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18511, current rewards: 90.09189, mean: 0.10476
[32m[0906 17-34-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18509, current rewards: 95.82262, mean: 0.10530
[32m[0906 17-34-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18505, current rewards: 101.54145, mean: 0.10577
[32m[0906 17-34-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18500, current rewards: 107.25484, mean: 0.10619
[32m[0906 17-34-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18494, current rewards: 113.47190, mean: 0.10705
[32m[0906 17-34-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18486, current rewards: 120.94821, mean: 0.10896
[32m[0906 17-35-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18483, current rewards: 126.50851, mean: 0.10906
[32m[0906 17-35-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18481, current rewards: 132.08163, mean: 0.10916
[32m[0906 17-35-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18479, current rewards: 137.64549, mean: 0.10924
[32m[0906 17-35-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18476, current rewards: 122.93280, mean: 0.09384
[32m[0906 17-35-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18473, current rewards: 128.66297, mean: 0.09461
[32m[0906 17-35-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18469, current rewards: 134.39527, mean: 0.09532
[32m[0906 17-35-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18468, current rewards: 140.12962, mean: 0.09598
[32m[0906 17-36-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18467, current rewards: 146.24725, mean: 0.09685
[32m[0906 17-36-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18459, current rewards: 152.00311, mean: 0.09744
[32m[0906 17-36-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18437, current rewards: 157.75463, mean: 0.09798
[32m[0906 17-36-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18409, current rewards: 163.51001, mean: 0.09850
[32m[0906 17-36-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18380, current rewards: 169.26013, mean: 0.09898
[32m[0906 17-36-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18354, current rewards: 163.69177, mean: 0.09301
[32m[0906 17-37-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18330, current rewards: 169.37166, mean: 0.09358
[32m[0906 17-37-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18308, current rewards: 175.05309, mean: 0.09411
[32m[0906 17-37-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18293, current rewards: 179.72727, mean: 0.09410
[32m[0906 17-37-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18295, current rewards: 174.42665, mean: 0.08899
[32m[0906 17-37-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18302, current rewards: 180.28932, mean: 0.08970
[32m[0906 17-37-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18309, current rewards: 186.15563, mean: 0.09037
[32m[0906 17-37-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18314, current rewards: 192.02745, mean: 0.09101
[32m[0906 17-38-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18318, current rewards: 197.89276, mean: 0.09162
[32m[0906 17-38-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18312, current rewards: 203.75519, mean: 0.09220
[32m[0906 17-38-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18306, current rewards: 209.62262, mean: 0.09275
[32m[0906 17-38-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18303, current rewards: 215.48522, mean: 0.09328
[32m[0906 17-38-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18288, current rewards: 221.35182, mean: 0.09379
[32m[0906 17-38-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18271, current rewards: 227.22005, mean: 0.09428
[32m[0906 17-38-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18256, current rewards: 233.09027, mean: 0.09475
[32m[0906 17-39-04 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0906 17-39-04 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-39-04 @MBExp.py:227][0m Rewards obtained: [237.78426880366874], Lows: [15], Highs: [30], Total time: 13343.382914000002
[32m[0906 17-40-06 @MBExp.py:144][0m ####################################################################
[32m[0906 17-40-06 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 17-40-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18805, current rewards: -3.68678, mean: -0.36868
[32m[0906 17-40-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18635, current rewards: 1.97409, mean: 0.03290
[32m[0906 17-40-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18599, current rewards: 7.87795, mean: 0.07162
[32m[0906 17-40-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18586, current rewards: 13.77842, mean: 0.08612
[32m[0906 17-40-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18594, current rewards: 19.68140, mean: 0.09372
[32m[0906 17-40-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18567, current rewards: 25.58597, mean: 0.09841
[32m[0906 17-41-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18550, current rewards: 31.49025, mean: 0.10158
[32m[0906 17-41-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18540, current rewards: 37.39186, mean: 0.10387
[32m[0906 17-41-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18533, current rewards: 43.29877, mean: 0.10561
[32m[0906 17-41-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18526, current rewards: 49.19990, mean: 0.10696
[32m[0906 17-41-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18518, current rewards: 45.22124, mean: 0.08867
[32m[0906 17-41-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18511, current rewards: 51.94909, mean: 0.09277
[32m[0906 17-42-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18505, current rewards: 58.06893, mean: 0.09519
[32m[0906 17-42-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18508, current rewards: 64.08648, mean: 0.09710
[32m[0906 17-42-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18500, current rewards: 70.30245, mean: 0.09902
[32m[0906 17-42-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18495, current rewards: 76.50994, mean: 0.10067
[32m[0906 17-42-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18490, current rewards: 82.71339, mean: 0.10212
[32m[0906 17-42-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18494, current rewards: 88.92449, mean: 0.10340
[32m[0906 17-42-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18488, current rewards: 95.13402, mean: 0.10454
[32m[0906 17-43-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18487, current rewards: 101.34426, mean: 0.10557
[32m[0906 17-43-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18486, current rewards: 94.81100, mean: 0.09387
[32m[0906 17-43-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18485, current rewards: 93.90676, mean: 0.08859
[32m[0906 17-43-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18480, current rewards: 99.90812, mean: 0.09001
[32m[0906 17-43-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18475, current rewards: 105.89651, mean: 0.09129
[32m[0906 17-43-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18474, current rewards: 111.89039, mean: 0.09247
[32m[0906 17-44-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18478, current rewards: 117.88177, mean: 0.09356
[32m[0906 17-44-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18479, current rewards: 123.87469, mean: 0.09456
[32m[0906 17-44-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18481, current rewards: 129.87547, mean: 0.09550
[32m[0906 17-44-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18479, current rewards: 135.87207, mean: 0.09636
[32m[0906 17-44-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18478, current rewards: 141.22734, mean: 0.09673
[32m[0906 17-44-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18482, current rewards: 147.39489, mean: 0.09761
[32m[0906 17-44-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18475, current rewards: 139.29808, mean: 0.08929
[32m[0906 17-45-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18444, current rewards: 144.31780, mean: 0.08964
[32m[0906 17-45-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18415, current rewards: 149.33175, mean: 0.08996
[32m[0906 17-45-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18386, current rewards: 154.35199, mean: 0.09026
[32m[0906 17-45-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18359, current rewards: 159.37468, mean: 0.09055
[32m[0906 17-45-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18334, current rewards: 164.39689, mean: 0.09083
[32m[0906 17-45-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18309, current rewards: 170.35178, mean: 0.09159
[32m[0906 17-45-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18293, current rewards: 176.23514, mean: 0.09227
[32m[0906 17-46-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18295, current rewards: 181.14230, mean: 0.09242
[32m[0906 17-46-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18300, current rewards: 186.04869, mean: 0.09256
[32m[0906 17-46-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18306, current rewards: 190.95294, mean: 0.09270
[32m[0906 17-46-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18312, current rewards: 195.86124, mean: 0.09283
[32m[0906 17-46-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18317, current rewards: 200.76496, mean: 0.09295
[32m[0906 17-46-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18313, current rewards: 186.39310, mean: 0.08434
[32m[0906 17-47-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18309, current rewards: 191.93801, mean: 0.08493
[32m[0906 17-47-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18302, current rewards: 197.47799, mean: 0.08549
[32m[0906 17-47-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18286, current rewards: 203.02581, mean: 0.08603
[32m[0906 17-47-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18270, current rewards: 208.56788, mean: 0.08654
[32m[0906 17-47-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18253, current rewards: 214.10921, mean: 0.08704
[32m[0906 17-47-43 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0906 17-47-43 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-47-43 @MBExp.py:227][0m Rewards obtained: [218.54701916706088], Lows: [21], Highs: [24], Total time: 13800.076312000001
[32m[0906 17-48-47 @MBExp.py:144][0m ####################################################################
[32m[0906 17-48-47 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 17-48-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18645, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-48-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18637, current rewards: -2.94223, mean: -0.04904
[32m[0906 17-49-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18565, current rewards: 2.49863, mean: 0.02271
[32m[0906 17-49-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18520, current rewards: 7.94481, mean: 0.04966
[32m[0906 17-49-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18518, current rewards: 12.97902, mean: 0.06180
[32m[0906 17-49-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18518, current rewards: -2.55797, mean: -0.00984
[32m[0906 17-49-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18526, current rewards: 2.83892, mean: 0.00916
[32m[0906 17-49-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18510, current rewards: 8.23571, mean: 0.02288
[32m[0906 17-50-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18512, current rewards: 13.63094, mean: 0.03325
[32m[0906 17-50-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18503, current rewards: 19.02655, mean: 0.04136
[32m[0906 17-50-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18498, current rewards: 19.99122, mean: 0.03920
[32m[0906 17-50-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18494, current rewards: 17.63988, mean: 0.03150
[32m[0906 17-50-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18496, current rewards: 22.57977, mean: 0.03702
[32m[0906 17-50-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18492, current rewards: 27.02384, mean: 0.04095
[32m[0906 17-50-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18488, current rewards: 31.89093, mean: 0.04492
[32m[0906 17-51-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18494, current rewards: 36.75318, mean: 0.04836
[32m[0906 17-51-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18495, current rewards: 41.61681, mean: 0.05138
[32m[0906 17-51-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18490, current rewards: 46.48256, mean: 0.05405
[32m[0906 17-51-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18490, current rewards: 51.34653, mean: 0.05642
[32m[0906 17-51-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18492, current rewards: 56.21554, mean: 0.05856
[32m[0906 17-51-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18488, current rewards: 61.07859, mean: 0.06047
[32m[0906 17-52-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18490, current rewards: 65.94960, mean: 0.06222
[32m[0906 17-52-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18486, current rewards: 70.81474, mean: 0.06380
[32m[0906 17-52-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18487, current rewards: 75.67738, mean: 0.06524
[32m[0906 17-52-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18482, current rewards: 80.54363, mean: 0.06656
[32m[0906 17-52-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18483, current rewards: 85.41301, mean: 0.06779
[32m[0906 17-52-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18481, current rewards: 67.20831, mean: 0.05130
[32m[0906 17-52-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18483, current rewards: 74.80488, mean: 0.05500
[32m[0906 17-53-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18485, current rewards: 84.22511, mean: 0.05973
[32m[0906 17-53-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18485, current rewards: 92.35497, mean: 0.06326
[32m[0906 17-53-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18487, current rewards: 101.21751, mean: 0.06703
[32m[0906 17-53-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18474, current rewards: 110.09851, mean: 0.07058
[32m[0906 17-53-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18444, current rewards: 118.98138, mean: 0.07390
[32m[0906 17-53-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18415, current rewards: 127.84709, mean: 0.07702
[32m[0906 17-54-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18387, current rewards: 136.71677, mean: 0.07995
[32m[0906 17-54-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18361, current rewards: 145.57873, mean: 0.08272
[32m[0906 17-54-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18336, current rewards: 154.47651, mean: 0.08535
[32m[0906 17-54-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18312, current rewards: 163.34064, mean: 0.08782
[32m[0906 17-54-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18291, current rewards: 172.23554, mean: 0.09018
[32m[0906 17-54-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18295, current rewards: 181.11400, mean: 0.09241
[32m[0906 17-54-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18306, current rewards: 187.39465, mean: 0.09323
[32m[0906 17-55-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18312, current rewards: 192.59106, mean: 0.09349
[32m[0906 17-55-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18320, current rewards: 197.79132, mean: 0.09374
[32m[0906 17-55-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18325, current rewards: 202.98955, mean: 0.09398
[32m[0906 17-55-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18318, current rewards: 208.19405, mean: 0.09421
[32m[0906 17-55-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18312, current rewards: 217.10609, mean: 0.09606
[32m[0906 17-55-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18306, current rewards: 223.10218, mean: 0.09658
[32m[0906 17-55-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18290, current rewards: 228.53838, mean: 0.09684
[32m[0906 17-56-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18275, current rewards: 233.97226, mean: 0.09708
[32m[0906 17-56-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18258, current rewards: 239.41033, mean: 0.09732
[32m[0906 17-56-24 @Agent.py:117][0m Average action selection time: 0.1825
[32m[0906 17-56-24 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-56-24 @MBExp.py:227][0m Rewards obtained: [232.40498254672093], Lows: [21], Highs: [31], Total time: 14256.918978000002
[32m[0906 17-57-30 @MBExp.py:144][0m ####################################################################
[32m[0906 17-57-30 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 17-57-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18528, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-57-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18562, current rewards: -5.60411, mean: -0.09340
[32m[0906 17-57-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18535, current rewards: -0.36226, mean: -0.00329
[32m[0906 17-58-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18541, current rewards: 4.87669, mean: 0.03048
[32m[0906 17-58-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18584, current rewards: 9.44394, mean: 0.04497
[32m[0906 17-58-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18578, current rewards: 14.66286, mean: 0.05640
[32m[0906 17-58-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18563, current rewards: 19.88661, mean: 0.06415
[32m[0906 17-58-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18551, current rewards: 25.10394, mean: 0.06973
[32m[0906 17-58-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18549, current rewards: 30.33004, mean: 0.07398
[32m[0906 17-58-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18550, current rewards: 35.55502, mean: 0.07729
[32m[0906 17-59-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18551, current rewards: 40.77050, mean: 0.07994
[32m[0906 17-59-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18540, current rewards: 45.99450, mean: 0.08213
[32m[0906 17-59-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18541, current rewards: 51.21828, mean: 0.08396
[32m[0906 17-59-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18551, current rewards: 56.44637, mean: 0.08552
[32m[0906 17-59-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18551, current rewards: 61.67287, mean: 0.08686
[32m[0906 17-59-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18551, current rewards: 60.97259, mean: 0.08023
[32m[0906 18-00-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18544, current rewards: 68.12555, mean: 0.08411
[32m[0906 18-00-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18538, current rewards: 75.19353, mean: 0.08743
[32m[0906 18-00-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18536, current rewards: 82.26069, mean: 0.09040
[32m[0906 18-00-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18532, current rewards: 89.32081, mean: 0.09304
[32m[0906 18-00-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18534, current rewards: 97.65839, mean: 0.09669
[32m[0906 18-00-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18532, current rewards: 105.03963, mean: 0.09909
[32m[0906 18-00-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18532, current rewards: 112.38521, mean: 0.10125
[32m[0906 18-01-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18532, current rewards: 119.72795, mean: 0.10321
[32m[0906 18-01-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18532, current rewards: 127.07094, mean: 0.10502
[32m[0906 18-01-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18529, current rewards: 134.40921, mean: 0.10667
[32m[0906 18-01-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18531, current rewards: 141.74485, mean: 0.10820
[32m[0906 18-01-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18534, current rewards: 126.67182, mean: 0.09314
[32m[0906 18-01-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18532, current rewards: 134.76119, mean: 0.09558
[32m[0906 18-02-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18531, current rewards: 140.79460, mean: 0.09643
[32m[0906 18-02-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18531, current rewards: 146.85219, mean: 0.09725
[32m[0906 18-02-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18515, current rewards: 152.91346, mean: 0.09802
[32m[0906 18-02-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18482, current rewards: 158.97049, mean: 0.09874
[32m[0906 18-02-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18454, current rewards: 165.02910, mean: 0.09942
[32m[0906 18-02-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18424, current rewards: 171.08712, mean: 0.10005
[32m[0906 18-02-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18399, current rewards: 177.14384, mean: 0.10065
[32m[0906 18-03-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18375, current rewards: 183.10909, mean: 0.10117
[32m[0906 18-03-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18352, current rewards: 188.10314, mean: 0.10113
[32m[0906 18-03-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18328, current rewards: 172.48886, mean: 0.09031
[32m[0906 18-03-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18327, current rewards: 178.42597, mean: 0.09103
[32m[0906 18-03-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18334, current rewards: 184.29188, mean: 0.09169
[32m[0906 18-03-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18337, current rewards: 190.16042, mean: 0.09231
[32m[0906 18-03-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18340, current rewards: 196.02626, mean: 0.09290
[32m[0906 18-04-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18340, current rewards: 201.89309, mean: 0.09347
[32m[0906 18-04-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18334, current rewards: 207.76009, mean: 0.09401
[32m[0906 18-04-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18328, current rewards: 213.87949, mean: 0.09464
[32m[0906 18-04-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18321, current rewards: 219.63424, mean: 0.09508
[32m[0906 18-04-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18306, current rewards: 225.38423, mean: 0.09550
[32m[0906 18-04-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18289, current rewards: 231.13636, mean: 0.09591
[32m[0906 18-05-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18272, current rewards: 236.88441, mean: 0.09629
[32m[0906 18-05-07 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0906 18-05-07 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-05-08 @MBExp.py:227][0m Rewards obtained: [241.48584967711042], Lows: [20], Highs: [21], Total time: 14714.116183000002
[32m[0906 18-06-16 @MBExp.py:144][0m ####################################################################
[32m[0906 18-06-16 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 18-06-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18524, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-06-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18538, current rewards: -5.09794, mean: -0.08497
[32m[0906 18-06-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18515, current rewards: 0.66813, mean: 0.00607
[32m[0906 18-06-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18474, current rewards: 6.43885, mean: 0.04024
[32m[0906 18-06-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18473, current rewards: 12.20229, mean: 0.05811
[32m[0906 18-07-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18478, current rewards: 17.96476, mean: 0.06910
[32m[0906 18-07-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18478, current rewards: 23.73358, mean: 0.07656
[32m[0906 18-07-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18486, current rewards: 29.50551, mean: 0.08196
[32m[0906 18-07-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18489, current rewards: 35.27681, mean: 0.08604
[32m[0906 18-07-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18482, current rewards: 41.04997, mean: 0.08924
[32m[0906 18-07-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18488, current rewards: 46.81431, mean: 0.09179
[32m[0906 18-08-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18489, current rewards: 54.12654, mean: 0.09665
[32m[0906 18-08-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18484, current rewards: 59.90475, mean: 0.09820
[32m[0906 18-08-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18485, current rewards: 54.60042, mean: 0.08273
[32m[0906 18-08-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18478, current rewards: 59.85962, mean: 0.08431
[32m[0906 18-08-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18474, current rewards: 65.12523, mean: 0.08569
[32m[0906 18-08-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18471, current rewards: 70.38210, mean: 0.08689
[32m[0906 18-08-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18469, current rewards: 75.63981, mean: 0.08795
[32m[0906 18-09-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18469, current rewards: 80.89635, mean: 0.08890
[32m[0906 18-09-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18474, current rewards: 86.38922, mean: 0.08999
[32m[0906 18-09-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18476, current rewards: 91.54860, mean: 0.09064
[32m[0906 18-09-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18477, current rewards: 97.23846, mean: 0.09173
[32m[0906 18-09-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18474, current rewards: 102.92094, mean: 0.09272
[32m[0906 18-09-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18471, current rewards: 108.60898, mean: 0.09363
[32m[0906 18-10-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18473, current rewards: 114.30008, mean: 0.09446
[32m[0906 18-10-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18469, current rewards: 93.89025, mean: 0.07452
[32m[0906 18-10-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18465, current rewards: 99.43510, mean: 0.07590
[32m[0906 18-10-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18465, current rewards: 104.82122, mean: 0.07707
[32m[0906 18-10-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18463, current rewards: 109.35161, mean: 0.07755
[32m[0906 18-10-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18457, current rewards: 114.57254, mean: 0.07847
[32m[0906 18-10-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18456, current rewards: 119.78748, mean: 0.07933
[32m[0906 18-11-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18438, current rewards: 125.00960, mean: 0.08013
[32m[0906 18-11-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18407, current rewards: 109.72660, mean: 0.06815
[32m[0906 18-11-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18379, current rewards: 115.12276, mean: 0.06935
[32m[0906 18-11-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18352, current rewards: 120.52984, mean: 0.07049
[32m[0906 18-11-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18328, current rewards: 125.93576, mean: 0.07155
[32m[0906 18-11-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18303, current rewards: 131.34363, mean: 0.07257
[32m[0906 18-11-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18282, current rewards: 136.74999, mean: 0.07352
[32m[0906 18-12-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18265, current rewards: 142.15921, mean: 0.07443
[32m[0906 18-12-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18264, current rewards: 147.56799, mean: 0.07529
[32m[0906 18-12-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18273, current rewards: 152.97247, mean: 0.07611
[32m[0906 18-12-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18278, current rewards: 158.38458, mean: 0.07689
[32m[0906 18-12-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18285, current rewards: 152.98120, mean: 0.07250
[32m[0906 18-12-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18290, current rewards: 159.67749, mean: 0.07392
[32m[0906 18-13-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18287, current rewards: 167.56181, mean: 0.07582
[32m[0906 18-13-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18282, current rewards: 173.40389, mean: 0.07673
[32m[0906 18-13-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18279, current rewards: 179.25372, mean: 0.07760
[32m[0906 18-13-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18267, current rewards: 185.10623, mean: 0.07843
[32m[0906 18-13-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18250, current rewards: 181.25115, mean: 0.07521
[32m[0906 18-13-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18236, current rewards: 186.88781, mean: 0.07597
[32m[0906 18-13-52 @Agent.py:117][0m Average action selection time: 0.1822
[32m[0906 18-13-52 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-13-52 @MBExp.py:227][0m Rewards obtained: [191.43918607138642], Lows: [23], Highs: [41], Total time: 15170.412653000001
[32m[0906 18-15-02 @MBExp.py:144][0m ####################################################################
[32m[0906 18-15-02 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 18-15-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18674, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-15-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18635, current rewards: -6.47803, mean: -0.10797
[32m[0906 18-15-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18580, current rewards: -1.95609, mean: -0.01778
[32m[0906 18-15-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18534, current rewards: 2.64191, mean: 0.01651
[32m[0906 18-15-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18514, current rewards: 7.13863, mean: 0.03399
[32m[0906 18-15-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18514, current rewards: -7.57799, mean: -0.02915
[32m[0906 18-16-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18509, current rewards: -2.26252, mean: -0.00730
[32m[0906 18-16-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18501, current rewards: 3.05189, mean: 0.00848
[32m[0906 18-16-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18519, current rewards: 8.37199, mean: 0.02042
[32m[0906 18-16-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18519, current rewards: 13.68488, mean: 0.02975
[32m[0906 18-16-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18514, current rewards: 18.99970, mean: 0.03725
[32m[0906 18-16-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18513, current rewards: 23.51677, mean: 0.04199
[32m[0906 18-16-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18515, current rewards: 28.61551, mean: 0.04691
[32m[0906 18-17-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18517, current rewards: 13.43220, mean: 0.02035
[32m[0906 18-17-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18515, current rewards: 18.93183, mean: 0.02666
[32m[0906 18-17-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18511, current rewards: 24.44304, mean: 0.03216
[32m[0906 18-17-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18509, current rewards: 29.95854, mean: 0.03699
[32m[0906 18-17-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18504, current rewards: 35.46933, mean: 0.04124
[32m[0906 18-17-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18504, current rewards: 40.98573, mean: 0.04504
[32m[0906 18-18-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18504, current rewards: 32.30170, mean: 0.03365
[32m[0906 18-18-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18502, current rewards: 35.32165, mean: 0.03497
[32m[0906 18-18-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18504, current rewards: 39.39535, mean: 0.03717
[32m[0906 18-18-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18502, current rewards: 43.46884, mean: 0.03916
[32m[0906 18-18-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18500, current rewards: 47.54635, mean: 0.04099
[32m[0906 18-18-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18501, current rewards: 51.62580, mean: 0.04267
[32m[0906 18-18-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18502, current rewards: 55.70000, mean: 0.04421
[32m[0906 18-19-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18500, current rewards: 59.77216, mean: 0.04563
[32m[0906 18-19-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18497, current rewards: 64.56398, mean: 0.04747
[32m[0906 18-19-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18495, current rewards: 49.39960, mean: 0.03504
[32m[0906 18-19-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18491, current rewards: 54.27002, mean: 0.03717
[32m[0906 18-19-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18489, current rewards: 59.13337, mean: 0.03916
[32m[0906 18-19-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18466, current rewards: 63.99680, mean: 0.04102
[32m[0906 18-20-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18437, current rewards: 68.86029, mean: 0.04277
[32m[0906 18-20-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18408, current rewards: 73.71848, mean: 0.04441
[32m[0906 18-20-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18379, current rewards: 78.57743, mean: 0.04595
[32m[0906 18-20-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18356, current rewards: 83.32706, mean: 0.04734
[32m[0906 18-20-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18331, current rewards: 87.82126, mean: 0.04852
[32m[0906 18-20-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18308, current rewards: 92.73754, mean: 0.04986
[32m[0906 18-20-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18287, current rewards: 97.65607, mean: 0.05113
[32m[0906 18-21-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18281, current rewards: 102.57689, mean: 0.05234
[32m[0906 18-21-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18288, current rewards: 107.49600, mean: 0.05348
[32m[0906 18-21-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18295, current rewards: 112.41421, mean: 0.05457
[32m[0906 18-21-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18301, current rewards: 111.83946, mean: 0.05300
[32m[0906 18-21-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18305, current rewards: 111.27664, mean: 0.05152
[32m[0906 18-21-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18300, current rewards: 116.46277, mean: 0.05270
[32m[0906 18-21-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18296, current rewards: 121.33611, mean: 0.05369
[32m[0906 18-22-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18291, current rewards: 126.20852, mean: 0.05464
[32m[0906 18-22-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18281, current rewards: 131.07899, mean: 0.05554
[32m[0906 18-22-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18263, current rewards: 135.95351, mean: 0.05641
[32m[0906 18-22-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18249, current rewards: 140.82546, mean: 0.05725
[32m[0906 18-22-39 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0906 18-22-39 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-22-39 @MBExp.py:227][0m Rewards obtained: [144.72090629982944], Lows: [31], Highs: [33], Total time: 15627.042956000001
[32m[0906 18-23-51 @MBExp.py:144][0m ####################################################################
[32m[0906 18-23-51 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 18-23-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18525, current rewards: -4.74379, mean: -0.47438
[32m[0906 18-24-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18577, current rewards: 1.74372, mean: 0.02906
[32m[0906 18-24-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18587, current rewards: 7.07397, mean: 0.06431
[32m[0906 18-24-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18563, current rewards: 12.40281, mean: 0.07752
[32m[0906 18-24-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18542, current rewards: 5.46069, mean: 0.02600
[32m[0906 18-24-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18560, current rewards: 10.83898, mean: 0.04169
[32m[0906 18-24-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18549, current rewards: 16.21403, mean: 0.05230
[32m[0906 18-24-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18542, current rewards: 21.59250, mean: 0.05998
[32m[0906 18-25-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18532, current rewards: 26.96537, mean: 0.06577
[32m[0906 18-25-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18515, current rewards: 32.34336, mean: 0.07031
[32m[0906 18-25-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18507, current rewards: 37.35584, mean: 0.07325
[32m[0906 18-25-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18502, current rewards: 42.76397, mean: 0.07636
[32m[0906 18-25-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18502, current rewards: 36.75962, mean: 0.06026
[32m[0906 18-25-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18505, current rewards: 42.31783, mean: 0.06412
[32m[0906 18-26-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18502, current rewards: 47.87952, mean: 0.06744
[32m[0906 18-26-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18502, current rewards: 53.44462, mean: 0.07032
[32m[0906 18-26-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18501, current rewards: 59.01034, mean: 0.07285
[32m[0906 18-26-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18499, current rewards: 64.56902, mean: 0.07508
[32m[0906 18-26-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18502, current rewards: 70.39855, mean: 0.07736
[32m[0906 18-26-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18505, current rewards: 76.53832, mean: 0.07973
[32m[0906 18-26-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18501, current rewards: 81.94751, mean: 0.08114
[32m[0906 18-27-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18499, current rewards: 87.35232, mean: 0.08241
[32m[0906 18-27-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18495, current rewards: 73.77875, mean: 0.06647
[32m[0906 18-27-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18493, current rewards: 77.07069, mean: 0.06644
[32m[0906 18-27-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18490, current rewards: 82.19631, mean: 0.06793
[32m[0906 18-27-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18486, current rewards: 87.32639, mean: 0.06931
[32m[0906 18-27-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18483, current rewards: 92.45216, mean: 0.07057
[32m[0906 18-28-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18481, current rewards: 96.72237, mean: 0.07112
[32m[0906 18-28-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18478, current rewards: 94.12724, mean: 0.06676
[32m[0906 18-28-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18477, current rewards: 96.15028, mean: 0.06586
[32m[0906 18-28-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18474, current rewards: 102.05874, mean: 0.06759
[32m[0906 18-28-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18450, current rewards: 107.93776, mean: 0.06919
[32m[0906 18-28-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18422, current rewards: 113.84374, mean: 0.07071
[32m[0906 18-28-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18394, current rewards: 119.74368, mean: 0.07213
[32m[0906 18-29-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18366, current rewards: 125.63466, mean: 0.07347
[32m[0906 18-29-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18340, current rewards: 131.32682, mean: 0.07462
[32m[0906 18-29-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18316, current rewards: 137.45791, mean: 0.07594
[32m[0906 18-29-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18293, current rewards: 143.57334, mean: 0.07719
[32m[0906 18-29-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18272, current rewards: 128.44955, mean: 0.06725
[32m[0906 18-29-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18262, current rewards: 133.87686, mean: 0.06830
[32m[0906 18-29-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18269, current rewards: 139.53537, mean: 0.06942
[32m[0906 18-30-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18275, current rewards: 145.19586, mean: 0.07048
[32m[0906 18-30-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18282, current rewards: 150.85635, mean: 0.07150
[32m[0906 18-30-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18289, current rewards: 158.56411, mean: 0.07341
[32m[0906 18-30-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18286, current rewards: 166.21139, mean: 0.07521
[32m[0906 18-30-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18280, current rewards: 171.95672, mean: 0.07609
[32m[0906 18-30-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18278, current rewards: 177.70233, mean: 0.07693
[32m[0906 18-31-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18270, current rewards: 183.45152, mean: 0.07773
[32m[0906 18-31-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18254, current rewards: 177.40674, mean: 0.07361
[32m[0906 18-31-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18239, current rewards: 182.77420, mean: 0.07430
[32m[0906 18-31-28 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0906 18-31-28 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-31-28 @MBExp.py:227][0m Rewards obtained: [187.06724331135032], Lows: [20], Highs: [46], Total time: 16083.398790000001
[32m[0906 18-32-42 @MBExp.py:144][0m ####################################################################
[32m[0906 18-32-42 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 18-32-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18556, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-32-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18596, current rewards: -5.69989, mean: -0.09500
[32m[0906 18-33-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18679, current rewards: 2.32034, mean: 0.02109
[32m[0906 18-33-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18579, current rewards: 8.50925, mean: 0.05318
[32m[0906 18-33-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18553, current rewards: 14.64602, mean: 0.06974
[32m[0906 18-33-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18542, current rewards: 20.77969, mean: 0.07992
[32m[0906 18-33-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18534, current rewards: 26.91829, mean: 0.08683
[32m[0906 18-33-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18529, current rewards: 33.05367, mean: 0.09182
[32m[0906 18-33-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18523, current rewards: 39.18386, mean: 0.09557
[32m[0906 18-34-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18521, current rewards: 14.56081, mean: 0.03165
[32m[0906 18-34-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18521, current rewards: 2.95152, mean: 0.00579
[32m[0906 18-34-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18517, current rewards: 9.00159, mean: 0.01607
[32m[0906 18-34-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18517, current rewards: 15.09231, mean: 0.02474
[32m[0906 18-34-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18518, current rewards: 21.17667, mean: 0.03209
[32m[0906 18-34-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18506, current rewards: 27.26298, mean: 0.03840
[32m[0906 18-35-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18507, current rewards: 33.35478, mean: 0.04389
[32m[0906 18-35-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18507, current rewards: 39.44663, mean: 0.04870
[32m[0906 18-35-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18498, current rewards: 34.49541, mean: 0.04011
[32m[0906 18-35-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18492, current rewards: 40.30805, mean: 0.04429
[32m[0906 18-35-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18486, current rewards: 45.78555, mean: 0.04769
[32m[0906 18-35-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18481, current rewards: 51.48968, mean: 0.05098
[32m[0906 18-35-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18479, current rewards: 57.18858, mean: 0.05395
[32m[0906 18-36-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18479, current rewards: 62.88133, mean: 0.05665
[32m[0906 18-36-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18478, current rewards: 68.58290, mean: 0.05912
[32m[0906 18-36-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18473, current rewards: 51.37666, mean: 0.04246
[32m[0906 18-36-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18470, current rewards: 56.42654, mean: 0.04478
[32m[0906 18-36-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18468, current rewards: 61.47642, mean: 0.04693
[32m[0906 18-36-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18465, current rewards: 66.52629, mean: 0.04892
[32m[0906 18-37-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18464, current rewards: 71.57617, mean: 0.05076
[32m[0906 18-37-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18466, current rewards: 76.62605, mean: 0.05248
[32m[0906 18-37-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18461, current rewards: 81.67592, mean: 0.05409
[32m[0906 18-37-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18437, current rewards: 86.72580, mean: 0.05559
[32m[0906 18-37-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18407, current rewards: 91.77568, mean: 0.05700
[32m[0906 18-37-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18379, current rewards: 86.91657, mean: 0.05236
[32m[0906 18-37-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18351, current rewards: 36.91657, mean: 0.02159
[32m[0906 18-38-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18327, current rewards: -13.08343, mean: -0.00743
[32m[0906 18-38-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18302, current rewards: -63.08343, mean: -0.03485
[32m[0906 18-38-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18280, current rewards: -113.08343, mean: -0.06080
[32m[0906 18-38-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18258, current rewards: -163.08343, mean: -0.08538
[32m[0906 18-38-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18247, current rewards: -213.08343, mean: -0.10872
[32m[0906 18-38-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18254, current rewards: -263.08343, mean: -0.13089
[32m[0906 18-38-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18263, current rewards: -313.08343, mean: -0.15198
[32m[0906 18-39-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18269, current rewards: -363.08343, mean: -0.17208
[32m[0906 18-39-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18277, current rewards: -413.08343, mean: -0.19124
[32m[0906 18-39-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18276, current rewards: -463.08343, mean: -0.20954
[32m[0906 18-39-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18271, current rewards: -513.08343, mean: -0.22703
[32m[0906 18-39-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18266, current rewards: -563.08343, mean: -0.24376
[32m[0906 18-39-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18258, current rewards: -613.08343, mean: -0.25978
[32m[0906 18-40-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18241, current rewards: -663.08343, mean: -0.27514
[32m[0906 18-40-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18227, current rewards: -713.08343, mean: -0.28987
[32m[0906 18-40-18 @Agent.py:117][0m Average action selection time: 0.1821
[32m[0906 18-40-18 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-40-18 @MBExp.py:227][0m Rewards obtained: [-753.083425044304], Lows: [39], Highs: [870], Total time: 16539.454318
[32m[0906 18-41-34 @MBExp.py:144][0m ####################################################################
[32m[0906 18-41-34 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 18-41-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18453, current rewards: 1.08632, mean: 0.10863
[32m[0906 18-41-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18552, current rewards: 8.02337, mean: 0.13372
[32m[0906 18-41-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18541, current rewards: -2.14868, mean: -0.01953
[32m[0906 18-42-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18528, current rewards: 6.68154, mean: 0.04176
[32m[0906 18-42-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18525, current rewards: 15.21785, mean: 0.07247
[32m[0906 18-42-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18521, current rewards: 23.74424, mean: 0.09132
[32m[0906 18-42-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18508, current rewards: 32.27025, mean: 0.10410
[32m[0906 18-42-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18519, current rewards: 40.79784, mean: 0.11333
[32m[0906 18-42-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18516, current rewards: 32.49383, mean: 0.07925
[32m[0906 18-42-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18518, current rewards: 37.52703, mean: 0.08158
[32m[0906 18-43-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18512, current rewards: 42.17249, mean: 0.08269
[32m[0906 18-43-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18507, current rewards: 46.23102, mean: 0.08256
[32m[0906 18-43-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18509, current rewards: 51.01350, mean: 0.08363
[32m[0906 18-43-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18509, current rewards: 55.80295, mean: 0.08455
[32m[0906 18-43-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18499, current rewards: 60.58787, mean: 0.08534
[32m[0906 18-43-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18497, current rewards: 65.37124, mean: 0.08601
[32m[0906 18-44-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18493, current rewards: 70.16063, mean: 0.08662
[32m[0906 18-44-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18492, current rewards: 74.94774, mean: 0.08715
[32m[0906 18-44-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18483, current rewards: 79.73485, mean: 0.08762
[32m[0906 18-44-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18484, current rewards: 86.68605, mean: 0.09030
[32m[0906 18-44-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18482, current rewards: 91.66512, mean: 0.09076
[32m[0906 18-44-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18480, current rewards: 76.54494, mean: 0.07221
[32m[0906 18-45-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18480, current rewards: 82.03780, mean: 0.07391
[32m[0906 18-45-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18481, current rewards: 87.50627, mean: 0.07544
[32m[0906 18-45-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18478, current rewards: 92.97508, mean: 0.07684
[32m[0906 18-45-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18477, current rewards: 98.43714, mean: 0.07812
[32m[0906 18-45-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18479, current rewards: 103.90304, mean: 0.07932
[32m[0906 18-45-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18476, current rewards: 109.06886, mean: 0.08020
[32m[0906 18-45-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18475, current rewards: 114.25289, mean: 0.08103
[32m[0906 18-46-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18471, current rewards: 109.73199, mean: 0.07516
[32m[0906 18-46-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18464, current rewards: 113.62204, mean: 0.07525
[32m[0906 18-46-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18440, current rewards: 118.61746, mean: 0.07604
[32m[0906 18-46-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18410, current rewards: 123.60917, mean: 0.07678
[32m[0906 18-46-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18380, current rewards: 128.60077, mean: 0.07747
[32m[0906 18-46-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18354, current rewards: 125.96254, mean: 0.07366
[32m[0906 18-46-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18327, current rewards: 131.34565, mean: 0.07463
[32m[0906 18-47-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18304, current rewards: 138.11494, mean: 0.07631
[32m[0906 18-47-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18282, current rewards: 143.51815, mean: 0.07716
[32m[0906 18-47-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18261, current rewards: 148.92324, mean: 0.07797
[32m[0906 18-47-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18250, current rewards: 154.32180, mean: 0.07874
[32m[0906 18-47-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18255, current rewards: 159.72575, mean: 0.07947
[32m[0906 18-47-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18265, current rewards: 165.12704, mean: 0.08016
[32m[0906 18-48-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18272, current rewards: 176.44999, mean: 0.08363
[32m[0906 18-48-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18278, current rewards: 181.86666, mean: 0.08420
[32m[0906 18-48-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18277, current rewards: 186.24582, mean: 0.08427
[32m[0906 18-48-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18272, current rewards: 191.46140, mean: 0.08472
[32m[0906 18-48-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18267, current rewards: 196.74143, mean: 0.08517
[32m[0906 18-48-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18261, current rewards: 202.02319, mean: 0.08560
[32m[0906 18-48-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18245, current rewards: 186.53343, mean: 0.07740
[32m[0906 18-49-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18230, current rewards: 194.32557, mean: 0.07899
[32m[0906 18-49-10 @Agent.py:117][0m Average action selection time: 0.1822
[32m[0906 18-49-10 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-49-10 @MBExp.py:227][0m Rewards obtained: [200.68708852308643], Lows: [30], Highs: [32], Total time: 16995.617801
[32m[0906 18-50-29 @MBExp.py:144][0m ####################################################################
[32m[0906 18-50-29 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 18-50-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18654, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-50-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18607, current rewards: -17.52783, mean: -0.29213
[32m[0906 18-50-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18558, current rewards: -11.76302, mean: -0.10694
[32m[0906 18-50-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18551, current rewards: -4.39794, mean: -0.02749
[32m[0906 18-51-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18535, current rewards: 1.20620, mean: 0.00574
[32m[0906 18-51-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18539, current rewards: 6.81100, mean: 0.02620
[32m[0906 18-51-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18534, current rewards: 12.41589, mean: 0.04005
[32m[0906 18-51-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18523, current rewards: -2.31661, mean: -0.00644
[32m[0906 18-51-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18511, current rewards: 4.47362, mean: 0.01091
[32m[0906 18-51-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18520, current rewards: 11.26654, mean: 0.02449
[32m[0906 18-52-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18517, current rewards: 18.05995, mean: 0.03541
[32m[0906 18-52-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18518, current rewards: 12.46035, mean: 0.02225
[32m[0906 18-52-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18512, current rewards: 18.12128, mean: 0.02971
[32m[0906 18-52-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18508, current rewards: 23.77946, mean: 0.03603
[32m[0906 18-52-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18510, current rewards: 29.44227, mean: 0.04147
[32m[0906 18-52-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18512, current rewards: 35.09663, mean: 0.04618
[32m[0906 18-52-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18512, current rewards: 40.76525, mean: 0.05033
[32m[0906 18-53-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18509, current rewards: 46.42281, mean: 0.05398
[32m[0906 18-53-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18506, current rewards: 52.08446, mean: 0.05724
[32m[0906 18-53-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18508, current rewards: 57.98562, mean: 0.06040
[32m[0906 18-53-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18509, current rewards: 64.32861, mean: 0.06369
[32m[0906 18-53-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18506, current rewards: 69.94800, mean: 0.06599
[32m[0906 18-53-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18503, current rewards: 75.59265, mean: 0.06810
[32m[0906 18-54-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18505, current rewards: 81.25559, mean: 0.07005
[32m[0906 18-54-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18502, current rewards: 86.91931, mean: 0.07183
[32m[0906 18-54-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18498, current rewards: 92.58230, mean: 0.07348
[32m[0906 18-54-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18495, current rewards: 98.23875, mean: 0.07499
[32m[0906 18-54-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18494, current rewards: 103.89916, mean: 0.07640
[32m[0906 18-54-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18493, current rewards: 109.62374, mean: 0.07775
[32m[0906 18-54-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18493, current rewards: 115.28775, mean: 0.07896
[32m[0906 18-55-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18482, current rewards: 99.99626, mean: 0.06622
[32m[0906 18-55-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18460, current rewards: 107.50778, mean: 0.06892
[32m[0906 18-55-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18428, current rewards: 112.96227, mean: 0.07016
[32m[0906 18-55-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18401, current rewards: 118.41305, mean: 0.07133
[32m[0906 18-55-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18375, current rewards: 123.86258, mean: 0.07243
[32m[0906 18-55-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18349, current rewards: 129.31319, mean: 0.07347
[32m[0906 18-56-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18326, current rewards: 122.37389, mean: 0.06761
[32m[0906 18-56-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18305, current rewards: 127.80211, mean: 0.06871
[32m[0906 18-56-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18283, current rewards: 133.47689, mean: 0.06988
[32m[0906 18-56-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18272, current rewards: 139.15827, mean: 0.07100
[32m[0906 18-56-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18272, current rewards: 144.83564, mean: 0.07206
[32m[0906 18-56-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18280, current rewards: 150.51303, mean: 0.07306
[32m[0906 18-56-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18284, current rewards: 156.19436, mean: 0.07403
[32m[0906 18-57-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18288, current rewards: 161.87352, mean: 0.07494
[32m[0906 18-57-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18290, current rewards: 166.83648, mean: 0.07549
[32m[0906 18-57-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18285, current rewards: 172.54057, mean: 0.07635
[32m[0906 18-57-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18280, current rewards: 178.23662, mean: 0.07716
[32m[0906 18-57-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18276, current rewards: 183.93419, mean: 0.07794
[32m[0906 18-57-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18260, current rewards: 189.63339, mean: 0.07869
[32m[0906 18-57-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18244, current rewards: 195.33294, mean: 0.07940
[32m[0906 18-58-05 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0906 18-58-05 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-58-05 @MBExp.py:227][0m Rewards obtained: [178.66251071972633], Lows: [37], Highs: [31], Total time: 17452.144509
[32m[0906 18-59-26 @MBExp.py:144][0m ####################################################################
[32m[0906 18-59-26 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 18-59-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18514, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-59-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18546, current rewards: -4.49791, mean: -0.07497
[32m[0906 18-59-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18577, current rewards: 2.03488, mean: 0.01850
[32m[0906 18-59-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18551, current rewards: 8.58221, mean: 0.05364
[32m[0906 19-00-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18554, current rewards: 15.12188, mean: 0.07201
[32m[0906 19-00-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18559, current rewards: 21.66325, mean: 0.08332
[32m[0906 19-00-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18556, current rewards: 28.19730, mean: 0.09096
[32m[0906 19-00-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18545, current rewards: 34.72483, mean: 0.09646
[32m[0906 19-00-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18543, current rewards: 39.01122, mean: 0.09515
[32m[0906 19-00-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18538, current rewards: 20.18157, mean: 0.04387
[32m[0906 19-01-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18529, current rewards: 29.74887, mean: 0.05833
[32m[0906 19-01-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18525, current rewards: 36.35433, mean: 0.06492
[32m[0906 19-01-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18520, current rewards: 42.86777, mean: 0.07028
[32m[0906 19-01-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18518, current rewards: 49.37730, mean: 0.07481
[32m[0906 19-01-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18510, current rewards: 55.88311, mean: 0.07871
[32m[0906 19-01-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18509, current rewards: 62.39791, mean: 0.08210
[32m[0906 19-01-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18508, current rewards: 32.37384, mean: 0.03997
[32m[0906 19-02-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18504, current rewards: 38.86851, mean: 0.04520
[32m[0906 19-02-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18503, current rewards: 44.99665, mean: 0.04945
[32m[0906 19-02-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18508, current rewards: 50.67479, mean: 0.05279
[32m[0906 19-02-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18503, current rewards: 56.92093, mean: 0.05636
[32m[0906 19-02-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18495, current rewards: 63.16290, mean: 0.05959
[32m[0906 19-02-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18491, current rewards: 69.41570, mean: 0.06254
[32m[0906 19-03-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18487, current rewards: 69.29055, mean: 0.05973
[32m[0906 19-03-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18488, current rewards: 60.30543, mean: 0.04984
[32m[0906 19-03-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18485, current rewards: 66.31950, mean: 0.05263
[32m[0906 19-03-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18486, current rewards: 72.33329, mean: 0.05522
[32m[0906 19-03-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18482, current rewards: 79.49049, mean: 0.05845
[32m[0906 19-03-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18480, current rewards: 85.42751, mean: 0.06059
[32m[0906 19-03-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18478, current rewards: 91.37023, mean: 0.06258
[32m[0906 19-04-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18464, current rewards: 97.30965, mean: 0.06444
[32m[0906 19-04-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18441, current rewards: 103.24857, mean: 0.06618
[32m[0906 19-04-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18411, current rewards: 109.19163, mean: 0.06782
[32m[0906 19-04-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18384, current rewards: 115.12829, mean: 0.06935
[32m[0906 19-04-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18358, current rewards: 100.81338, mean: 0.05896
[32m[0906 19-04-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18333, current rewards: 107.45514, mean: 0.06105
[32m[0906 19-04-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18310, current rewards: 114.09159, mean: 0.06303
[32m[0906 19-05-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18289, current rewards: 120.71964, mean: 0.06490
[32m[0906 19-05-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18269, current rewards: 127.35248, mean: 0.06668
[32m[0906 19-05-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18259, current rewards: 133.98330, mean: 0.06836
[32m[0906 19-05-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18255, current rewards: 140.62327, mean: 0.06996
[32m[0906 19-05-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18261, current rewards: 147.25467, mean: 0.07148
[32m[0906 19-05-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18268, current rewards: 153.89133, mean: 0.07293
[32m[0906 19-06-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18274, current rewards: 163.47639, mean: 0.07568
[32m[0906 19-06-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18276, current rewards: 138.67705, mean: 0.06275
[32m[0906 19-06-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18271, current rewards: 106.44883, mean: 0.04710
[32m[0906 19-06-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18266, current rewards: 112.53659, mean: 0.04872
[32m[0906 19-06-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18263, current rewards: 118.62737, mean: 0.05027
[32m[0906 19-06-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18246, current rewards: 113.58889, mean: 0.04713
[32m[0906 19-06-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18231, current rewards: 122.02296, mean: 0.04960
[32m[0906 19-07-02 @Agent.py:117][0m Average action selection time: 0.1822
[32m[0906 19-07-02 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-07-02 @MBExp.py:227][0m Rewards obtained: [127.17645618531378], Lows: [46], Highs: [93], Total time: 17908.346847
[32m[0906 19-08-24 @MBExp.py:144][0m ####################################################################
[32m[0906 19-08-24 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 19-08-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18630, current rewards: 0.57186, mean: 0.05719
[32m[0906 19-08-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18671, current rewards: 6.79965, mean: 0.11333
[32m[0906 19-08-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18657, current rewards: -22.85421, mean: -0.20777
[32m[0906 19-08-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18615, current rewards: -72.85421, mean: -0.45534
[32m[0906 19-09-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18584, current rewards: -122.85421, mean: -0.58502
[32m[0906 19-09-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18560, current rewards: -172.85421, mean: -0.66482
[32m[0906 19-09-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18554, current rewards: -222.85421, mean: -0.71888
[32m[0906 19-09-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18543, current rewards: -272.85421, mean: -0.75793
[32m[0906 19-09-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18539, current rewards: -322.85421, mean: -0.78745
[32m[0906 19-09-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18532, current rewards: -372.85421, mean: -0.81055
[32m[0906 19-09-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18537, current rewards: -422.85421, mean: -0.82913
[32m[0906 19-10-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18530, current rewards: -472.85421, mean: -0.84438
[32m[0906 19-10-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18528, current rewards: -522.85421, mean: -0.85714
[32m[0906 19-10-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18529, current rewards: -572.85421, mean: -0.86796
[32m[0906 19-10-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18527, current rewards: -622.85421, mean: -0.87726
[32m[0906 19-10-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18533, current rewards: -672.85421, mean: -0.88533
[32m[0906 19-10-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18534, current rewards: -722.85421, mean: -0.89241
[32m[0906 19-11-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18533, current rewards: -772.85421, mean: -0.89867
[32m[0906 19-11-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18529, current rewards: -822.85421, mean: -0.90424
[32m[0906 19-11-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18523, current rewards: -872.85421, mean: -0.90922
[32m[0906 19-11-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18523, current rewards: -922.85421, mean: -0.91372
[32m[0906 19-11-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18519, current rewards: -972.85421, mean: -0.91779
[32m[0906 19-11-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18515, current rewards: -1022.85421, mean: -0.92149
[32m[0906 19-11-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18512, current rewards: -1072.85421, mean: -0.92487
[32m[0906 19-12-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18512, current rewards: -1122.85421, mean: -0.92798
[32m[0906 19-12-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18509, current rewards: -1172.85421, mean: -0.93084
[32m[0906 19-12-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18505, current rewards: -1222.85421, mean: -0.93348
[32m[0906 19-12-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18498, current rewards: -1272.85421, mean: -0.93592
[32m[0906 19-12-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18497, current rewards: -1322.85421, mean: -0.93819
[32m[0906 19-12-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18494, current rewards: -1372.85421, mean: -0.94031
[32m[0906 19-13-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18480, current rewards: -1422.85421, mean: -0.94229
[32m[0906 19-13-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18459, current rewards: -1472.85421, mean: -0.94414
[32m[0906 19-13-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18430, current rewards: -1522.85421, mean: -0.94587
[32m[0906 19-13-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18401, current rewards: -1572.85421, mean: -0.94750
[32m[0906 19-13-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18375, current rewards: -1622.85421, mean: -0.94904
[32m[0906 19-13-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18349, current rewards: -1672.85421, mean: -0.95049
[32m[0906 19-13-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18325, current rewards: -1722.85421, mean: -0.95185
[32m[0906 19-14-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18303, current rewards: -1772.85421, mean: -0.95315
[32m[0906 19-14-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18281, current rewards: -1822.85421, mean: -0.95437
[32m[0906 19-14-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18272, current rewards: -1872.85421, mean: -0.95554
[32m[0906 19-14-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18268, current rewards: -1922.85421, mean: -0.95664
[32m[0906 19-14-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18276, current rewards: -1972.85421, mean: -0.95770
[32m[0906 19-14-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18284, current rewards: -2022.85421, mean: -0.95870
[32m[0906 19-15-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18293, current rewards: -2072.85421, mean: -0.95965
[32m[0906 19-15-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18297, current rewards: -2122.85421, mean: -0.96057
[32m[0906 19-15-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18292, current rewards: -2172.85421, mean: -0.96144
[32m[0906 19-15-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18288, current rewards: -2222.85421, mean: -0.96227
[32m[0906 19-15-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18282, current rewards: -2272.85421, mean: -0.96307
[32m[0906 19-15-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18267, current rewards: -2322.85421, mean: -0.96384
[32m[0906 19-15-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18252, current rewards: -2372.85421, mean: -0.96457
[32m[0906 19-16-01 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0906 19-16-01 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-16-01 @MBExp.py:227][0m Rewards obtained: [-2412.8542100557497], Lows: [0], Highs: [2421], Total time: 18365.056165
[32m[0906 19-17-25 @MBExp.py:144][0m ####################################################################
[32m[0906 19-17-25 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 19-17-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18449, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-17-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18667, current rewards: -6.92069, mean: -0.11534
[32m[0906 19-17-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18579, current rewards: -2.78469, mean: -0.02532
[32m[0906 19-17-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18563, current rewards: 1.35351, mean: 0.00846
[32m[0906 19-18-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18548, current rewards: 5.49101, mean: 0.02615
[32m[0906 19-18-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18530, current rewards: 9.62822, mean: 0.03703
[32m[0906 19-18-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18515, current rewards: 13.76829, mean: 0.04441
[32m[0906 19-18-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18503, current rewards: 17.90704, mean: 0.04974
[32m[0906 19-18-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18512, current rewards: 22.04437, mean: 0.05377
[32m[0906 19-18-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18509, current rewards: 26.83356, mean: 0.05833
[32m[0906 19-18-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18502, current rewards: 31.42382, mean: 0.06162
[32m[0906 19-19-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18512, current rewards: -2.72795, mean: -0.00487
[32m[0906 19-19-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18512, current rewards: 6.32548, mean: 0.01037
[32m[0906 19-19-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18507, current rewards: 15.37891, mean: 0.02330
[32m[0906 19-19-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18502, current rewards: 24.43234, mean: 0.03441
[32m[0906 19-19-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18498, current rewards: 33.48577, mean: 0.04406
[32m[0906 19-19-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18494, current rewards: 42.53921, mean: 0.05252
[32m[0906 19-20-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18493, current rewards: 51.59264, mean: 0.05999
[32m[0906 19-20-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18488, current rewards: 19.62084, mean: 0.02156
[32m[0906 19-20-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18484, current rewards: -30.37916, mean: -0.03164
[32m[0906 19-20-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18479, current rewards: -80.37916, mean: -0.07958
[32m[0906 19-20-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18481, current rewards: -130.37916, mean: -0.12300
[32m[0906 19-20-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18478, current rewards: -180.37916, mean: -0.16250
[32m[0906 19-21-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18475, current rewards: -230.37916, mean: -0.19860
[32m[0906 19-21-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18477, current rewards: -280.37916, mean: -0.23172
[32m[0906 19-21-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18482, current rewards: -330.37916, mean: -0.26221
[32m[0906 19-21-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18481, current rewards: -380.37916, mean: -0.29037
[32m[0906 19-21-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18476, current rewards: -430.37916, mean: -0.31646
[32m[0906 19-21-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18473, current rewards: -480.37916, mean: -0.34069
[32m[0906 19-21-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18463, current rewards: -530.37916, mean: -0.36327
[32m[0906 19-22-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18449, current rewards: -580.37916, mean: -0.38436
[32m[0906 19-22-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18425, current rewards: -630.37916, mean: -0.40409
[32m[0906 19-22-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18395, current rewards: -680.37916, mean: -0.42260
[32m[0906 19-22-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18366, current rewards: -730.37916, mean: -0.43999
[32m[0906 19-22-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18340, current rewards: -780.37916, mean: -0.45636
[32m[0906 19-22-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18315, current rewards: -830.37916, mean: -0.47181
[32m[0906 19-22-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18292, current rewards: -880.37916, mean: -0.48640
[32m[0906 19-23-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18269, current rewards: -930.37916, mean: -0.50020
[32m[0906 19-23-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18250, current rewards: -980.37916, mean: -0.51329
[32m[0906 19-23-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18242, current rewards: -1030.37916, mean: -0.52570
[32m[0906 19-23-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18237, current rewards: -1080.37916, mean: -0.53750
[32m[0906 19-23-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18241, current rewards: -1130.37916, mean: -0.54873
[32m[0906 19-23-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18248, current rewards: -1180.37916, mean: -0.55942
[32m[0906 19-24-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18256, current rewards: -1230.37916, mean: -0.56962
[32m[0906 19-24-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18260, current rewards: -1280.37916, mean: -0.57936
[32m[0906 19-24-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18255, current rewards: -1330.37916, mean: -0.58866
[32m[0906 19-24-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18250, current rewards: -1380.37916, mean: -0.59757
[32m[0906 19-24-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18245, current rewards: -1430.37916, mean: -0.60609
[32m[0906 19-24-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18231, current rewards: -1480.37916, mean: -0.61427
[32m[0906 19-24-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18215, current rewards: -1530.37916, mean: -0.62211
[32m[0906 19-25-01 @Agent.py:117][0m Average action selection time: 0.1820
[32m[0906 19-25-01 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-25-01 @MBExp.py:227][0m Rewards obtained: [-1570.3791632310617], Lows: [20], Highs: [1635], Total time: 18820.845632
[32m[0906 19-26-27 @MBExp.py:144][0m ####################################################################
[32m[0906 19-26-27 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 19-26-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18502, current rewards: 0.63468, mean: 0.06347
[32m[0906 19-26-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18536, current rewards: 5.55988, mean: 0.09266
[32m[0906 19-26-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18491, current rewards: 10.87129, mean: 0.09883
[32m[0906 19-26-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18494, current rewards: 16.18574, mean: 0.10116
[32m[0906 19-27-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18492, current rewards: 21.49384, mean: 0.10235
[32m[0906 19-27-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18493, current rewards: 26.80576, mean: 0.10310
[32m[0906 19-27-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18492, current rewards: 24.37403, mean: 0.07863
[32m[0906 19-27-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18510, current rewards: 25.83910, mean: 0.07178
[32m[0906 19-27-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18501, current rewards: 30.76502, mean: 0.07504
[32m[0906 19-27-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18493, current rewards: 37.21451, mean: 0.08090
[32m[0906 19-28-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18487, current rewards: 42.09241, mean: 0.08253
[32m[0906 19-28-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18493, current rewards: 46.93528, mean: 0.08381
[32m[0906 19-28-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18488, current rewards: 51.78060, mean: 0.08489
[32m[0906 19-28-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18488, current rewards: 56.62536, mean: 0.08580
[32m[0906 19-28-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18481, current rewards: 61.47002, mean: 0.08658
[32m[0906 19-28-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18478, current rewards: 55.15271, mean: 0.07257
[32m[0906 19-28-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18480, current rewards: 59.28852, mean: 0.07320
[32m[0906 19-29-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18482, current rewards: 63.39136, mean: 0.07371
[32m[0906 19-29-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18480, current rewards: 67.41967, mean: 0.07409
[32m[0906 19-29-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18479, current rewards: 71.52007, mean: 0.07450
[32m[0906 19-29-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18481, current rewards: 75.62529, mean: 0.07488
[32m[0906 19-29-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18483, current rewards: 79.72699, mean: 0.07521
[32m[0906 19-29-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18481, current rewards: 83.83164, mean: 0.07552
[32m[0906 19-30-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18478, current rewards: 87.93462, mean: 0.07581
[32m[0906 19-30-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18476, current rewards: 92.03422, mean: 0.07606
[32m[0906 19-30-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18475, current rewards: 97.79528, mean: 0.07762
[32m[0906 19-30-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18471, current rewards: 102.05391, mean: 0.07790
[32m[0906 19-30-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18472, current rewards: 106.43017, mean: 0.07826
[32m[0906 19-30-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18470, current rewards: 110.80656, mean: 0.07859
[32m[0906 19-30-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18458, current rewards: 115.18612, mean: 0.07889
[32m[0906 19-31-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18442, current rewards: 119.56461, mean: 0.07918
[32m[0906 19-31-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18421, current rewards: 123.94300, mean: 0.07945
[32m[0906 19-31-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18391, current rewards: 128.31715, mean: 0.07970
[32m[0906 19-31-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18363, current rewards: 132.69938, mean: 0.07994
[32m[0906 19-31-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18339, current rewards: 137.07626, mean: 0.08016
[32m[0906 19-31-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18317, current rewards: 141.45252, mean: 0.08037
[32m[0906 19-31-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18294, current rewards: 145.83193, mean: 0.08057
[32m[0906 19-32-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18274, current rewards: 150.21036, mean: 0.08076
[32m[0906 19-32-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18254, current rewards: 135.00202, mean: 0.07068
[32m[0906 19-32-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18244, current rewards: 140.93359, mean: 0.07190
[32m[0906 19-32-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18239, current rewards: 146.85430, mean: 0.07306
[32m[0906 19-32-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18240, current rewards: 152.78453, mean: 0.07417
[32m[0906 19-32-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18247, current rewards: 158.09044, mean: 0.07492
[32m[0906 19-33-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18255, current rewards: 163.63996, mean: 0.07576
[32m[0906 19-33-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18260, current rewards: 169.19576, mean: 0.07656
[32m[0906 19-33-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18257, current rewards: 174.74926, mean: 0.07732
[32m[0906 19-33-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18252, current rewards: 180.30473, mean: 0.07805
[32m[0906 19-33-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18249, current rewards: 185.85649, mean: 0.07875
[32m[0906 19-33-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18237, current rewards: 191.40953, mean: 0.07942
[32m[0906 19-33-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18224, current rewards: 196.96060, mean: 0.08007
[32m[0906 19-34-03 @Agent.py:117][0m Average action selection time: 0.1821
[32m[0906 19-34-03 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-34-03 @MBExp.py:227][0m Rewards obtained: [202.50113236465577], Lows: [10], Highs: [20], Total time: 19276.861028
[32m[0906 19-35-31 @MBExp.py:144][0m ####################################################################
[32m[0906 19-35-31 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 19-35-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18542, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-35-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18488, current rewards: -5.44888, mean: -0.09081
[32m[0906 19-35-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18575, current rewards: -0.61633, mean: -0.00560
[32m[0906 19-36-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18604, current rewards: 4.20952, mean: 0.02631
[32m[0906 19-36-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18582, current rewards: 9.03808, mean: 0.04304
[32m[0906 19-36-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18573, current rewards: 13.87624, mean: 0.05337
[32m[0906 19-36-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18554, current rewards: 18.71148, mean: 0.06036
[32m[0906 19-36-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18544, current rewards: 23.54460, mean: 0.06540
[32m[0906 19-36-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18540, current rewards: 28.00791, mean: 0.06831
[32m[0906 19-36-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18542, current rewards: 11.63779, mean: 0.02530
[32m[0906 19-37-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18543, current rewards: 16.56001, mean: 0.03247
[32m[0906 19-37-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18544, current rewards: 21.46970, mean: 0.03834
[32m[0906 19-37-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18541, current rewards: 26.38236, mean: 0.04325
[32m[0906 19-37-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18537, current rewards: 31.29285, mean: 0.04741
[32m[0906 19-37-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18530, current rewards: 36.20434, mean: 0.05099
[32m[0906 19-37-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18525, current rewards: 41.11368, mean: 0.05410
[32m[0906 19-38-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18528, current rewards: 46.01719, mean: 0.05681
[32m[0906 19-38-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18527, current rewards: 53.29115, mean: 0.06197
[32m[0906 19-38-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18521, current rewards: 58.03227, mean: 0.06377
[32m[0906 19-38-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18521, current rewards: 51.84839, mean: 0.05401
[32m[0906 19-38-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18519, current rewards: 57.59891, mean: 0.05703
[32m[0906 19-38-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18517, current rewards: 63.27347, mean: 0.05969
[32m[0906 19-38-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18512, current rewards: 68.95994, mean: 0.06213
[32m[0906 19-39-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18511, current rewards: 74.64472, mean: 0.06435
[32m[0906 19-39-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18508, current rewards: 80.33151, mean: 0.06639
[32m[0906 19-39-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18509, current rewards: 85.21942, mean: 0.06763
[32m[0906 19-39-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18511, current rewards: 91.08308, mean: 0.06953
[32m[0906 19-39-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18508, current rewards: 96.65689, mean: 0.07107
[32m[0906 19-39-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18502, current rewards: 101.98086, mean: 0.07233
[32m[0906 19-40-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18488, current rewards: 108.20917, mean: 0.07412
[32m[0906 19-40-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18476, current rewards: 113.93413, mean: 0.07545
[32m[0906 19-40-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18451, current rewards: 120.22497, mean: 0.07707
[32m[0906 19-40-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18420, current rewards: 126.02081, mean: 0.07827
[32m[0906 19-40-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18392, current rewards: 132.24045, mean: 0.07966
[32m[0906 19-40-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18365, current rewards: 138.84174, mean: 0.08119
[32m[0906 19-40-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18339, current rewards: 144.19825, mean: 0.08193
[32m[0906 19-41-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18316, current rewards: 149.55451, mean: 0.08263
[32m[0906 19-41-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18293, current rewards: 142.26381, mean: 0.07649
[32m[0906 19-41-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18273, current rewards: 139.25956, mean: 0.07291
[32m[0906 19-41-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18264, current rewards: 144.67870, mean: 0.07382
[32m[0906 19-41-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18259, current rewards: 150.09220, mean: 0.07467
[32m[0906 19-41-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18257, current rewards: 134.87532, mean: 0.06547
[32m[0906 19-41-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18265, current rewards: 138.87196, mean: 0.06582
[32m[0906 19-42-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18273, current rewards: 143.38076, mean: 0.06638
[32m[0906 19-42-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18281, current rewards: 147.86199, mean: 0.06691
[32m[0906 19-42-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18277, current rewards: 152.34512, mean: 0.06741
[32m[0906 19-42-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18272, current rewards: 156.82617, mean: 0.06789
[32m[0906 19-42-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18267, current rewards: 161.31050, mean: 0.06835
[32m[0906 19-42-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18256, current rewards: 165.79289, mean: 0.06879
[32m[0906 19-43-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18240, current rewards: 170.27404, mean: 0.06922
[32m[0906 19-43-08 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0906 19-43-08 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-43-08 @MBExp.py:227][0m Rewards obtained: [173.86065802013903], Lows: [30], Highs: [20], Total time: 19733.274565
[32m[0906 19-44-38 @MBExp.py:144][0m ####################################################################
[32m[0906 19-44-38 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 19-44-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18512, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-44-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18561, current rewards: -6.23973, mean: -0.10400
[32m[0906 19-44-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18582, current rewards: -1.01387, mean: -0.00922
[32m[0906 19-45-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18568, current rewards: 4.21104, mean: 0.02632
[32m[0906 19-45-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18572, current rewards: 9.43507, mean: 0.04493
[32m[0906 19-45-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18559, current rewards: 14.65454, mean: 0.05636
[32m[0906 19-45-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18548, current rewards: 19.87943, mean: 0.06413
[32m[0906 19-45-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18552, current rewards: 25.10608, mean: 0.06974
[32m[0906 19-45-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18549, current rewards: 30.16164, mean: 0.07356
[32m[0906 19-46-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18549, current rewards: 35.35030, mean: 0.07685
[32m[0906 19-46-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18546, current rewards: 40.60562, mean: 0.07962
[32m[0906 19-46-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18552, current rewards: 45.85808, mean: 0.08189
[32m[0906 19-46-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18554, current rewards: 39.89920, mean: 0.06541
[32m[0906 19-46-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18550, current rewards: 45.13405, mean: 0.06838
[32m[0906 19-46-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18544, current rewards: 50.36333, mean: 0.07093
[32m[0906 19-46-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18538, current rewards: 55.59331, mean: 0.07315
[32m[0906 19-47-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18530, current rewards: 60.98159, mean: 0.07529
[32m[0906 19-47-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18523, current rewards: 67.07400, mean: 0.07799
[32m[0906 19-47-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18521, current rewards: 72.20273, mean: 0.07934
[32m[0906 19-47-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18514, current rewards: 77.32479, mean: 0.08055
[32m[0906 19-47-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18513, current rewards: 82.44276, mean: 0.08163
[32m[0906 19-47-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18511, current rewards: 87.56423, mean: 0.08261
[32m[0906 19-48-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18508, current rewards: 72.43727, mean: 0.06526
[32m[0906 19-48-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18506, current rewards: 77.48715, mean: 0.06680
[32m[0906 19-48-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18506, current rewards: 82.53703, mean: 0.06821
[32m[0906 19-48-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18508, current rewards: 86.93638, mean: 0.06900
[32m[0906 19-48-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18506, current rewards: 91.24807, mean: 0.06966
[32m[0906 19-48-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18503, current rewards: 95.55975, mean: 0.07026
[32m[0906 19-48-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18496, current rewards: 99.87143, mean: 0.07083
[32m[0906 19-49-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18480, current rewards: 104.18311, mean: 0.07136
[32m[0906 19-49-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18464, current rewards: 108.49480, mean: 0.07185
[32m[0906 19-49-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18440, current rewards: 103.03038, mean: 0.06605
[32m[0906 19-49-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18412, current rewards: 53.03038, mean: 0.03294
[32m[0906 19-49-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18384, current rewards: 3.03038, mean: 0.00183
[32m[0906 19-49-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18357, current rewards: -46.96962, mean: -0.02747
[32m[0906 19-50-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18334, current rewards: -96.96962, mean: -0.05510
[32m[0906 19-50-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18311, current rewards: -146.96962, mean: -0.08120
[32m[0906 19-50-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18289, current rewards: -196.96962, mean: -0.10590
[32m[0906 19-50-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18270, current rewards: -246.96962, mean: -0.12930
[32m[0906 19-50-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18265, current rewards: -296.96962, mean: -0.15152
[32m[0906 19-50-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18260, current rewards: -346.96962, mean: -0.17262
[32m[0906 19-50-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18255, current rewards: -396.96962, mean: -0.19270
[32m[0906 19-51-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18263, current rewards: -446.96962, mean: -0.21183
[32m[0906 19-51-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18271, current rewards: -496.96962, mean: -0.23008
[32m[0906 19-51-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18278, current rewards: -546.96962, mean: -0.24750
[32m[0906 19-51-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18272, current rewards: -596.96962, mean: -0.26415
[32m[0906 19-51-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18267, current rewards: -646.96962, mean: -0.28007
[32m[0906 19-51-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18261, current rewards: -696.96962, mean: -0.29533
[32m[0906 19-51-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18249, current rewards: -746.96962, mean: -0.30995
[32m[0906 19-52-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18234, current rewards: -796.96962, mean: -0.32397
[32m[0906 19-52-14 @Agent.py:117][0m Average action selection time: 0.1822
[32m[0906 19-52-14 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-52-14 @MBExp.py:227][0m Rewards obtained: [-836.969624453539], Lows: [10], Highs: [970], Total time: 20189.540843
[32m[0906 19-53-46 @MBExp.py:144][0m ####################################################################
[32m[0906 19-53-46 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 19-53-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18585, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-53-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18623, current rewards: -11.76230, mean: -0.19604
[32m[0906 19-54-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18566, current rewards: -6.74005, mean: -0.06127
[32m[0906 19-54-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18552, current rewards: -1.71258, mean: -0.01070
[32m[0906 19-54-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18532, current rewards: 3.31521, mean: 0.01579
[32m[0906 19-54-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18531, current rewards: 8.34241, mean: 0.03209
[32m[0906 19-54-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18540, current rewards: 13.36712, mean: 0.04312
[32m[0906 19-54-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18537, current rewards: 18.38990, mean: 0.05108
[32m[0906 19-55-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18533, current rewards: 25.04445, mean: 0.06108
[32m[0906 19-55-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18531, current rewards: 31.13884, mean: 0.06769
[32m[0906 19-55-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18525, current rewards: 34.29364, mean: 0.06724
[32m[0906 19-55-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18528, current rewards: 22.17886, mean: 0.03961
[32m[0906 19-55-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18526, current rewards: 27.45688, mean: 0.04501
[32m[0906 19-55-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18522, current rewards: 32.73424, mean: 0.04960
[32m[0906 19-55-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18522, current rewards: 38.00922, mean: 0.05353
[32m[0906 19-56-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18518, current rewards: 43.28807, mean: 0.05696
[32m[0906 19-56-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18512, current rewards: 29.07975, mean: 0.03590
[32m[0906 19-56-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18509, current rewards: 33.19333, mean: 0.03860
[32m[0906 19-56-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18507, current rewards: 35.66341, mean: 0.03919
[32m[0906 19-56-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18506, current rewards: 38.13348, mean: 0.03972
[32m[0906 19-56-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18509, current rewards: 40.60356, mean: 0.04020
[32m[0906 19-57-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18510, current rewards: 43.07364, mean: 0.04064
[32m[0906 19-57-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18508, current rewards: 45.54371, mean: 0.04103
[32m[0906 19-57-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18507, current rewards: 48.01379, mean: 0.04139
[32m[0906 19-57-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18505, current rewards: 50.48386, mean: 0.04172
[32m[0906 19-57-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18506, current rewards: 53.42853, mean: 0.04240
[32m[0906 19-57-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18505, current rewards: 57.81268, mean: 0.04413
[32m[0906 19-57-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18508, current rewards: 62.19682, mean: 0.04573
[32m[0906 19-58-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18495, current rewards: 25.24901, mean: 0.01791
[32m[0906 19-58-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18481, current rewards: -24.75099, mean: -0.01695
[32m[0906 19-58-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18467, current rewards: -74.75099, mean: -0.04950
[32m[0906 19-58-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18445, current rewards: -124.75099, mean: -0.07997
[32m[0906 19-58-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18416, current rewards: -174.75099, mean: -0.10854
[32m[0906 19-58-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18389, current rewards: -224.75099, mean: -0.13539
[32m[0906 19-59-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18366, current rewards: -274.75099, mean: -0.16067
[32m[0906 19-59-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18343, current rewards: -324.75099, mean: -0.18452
[32m[0906 19-59-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18319, current rewards: -374.75099, mean: -0.20704
[32m[0906 19-59-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18296, current rewards: -424.75099, mean: -0.22836
[32m[0906 19-59-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18274, current rewards: -474.75099, mean: -0.24856
[32m[0906 19-59-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18268, current rewards: -524.75099, mean: -0.26773
[32m[0906 19-59-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18262, current rewards: -574.75099, mean: -0.28595
[32m[0906 20-00-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18258, current rewards: -624.75099, mean: -0.30328
[32m[0906 20-00-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18264, current rewards: -674.75099, mean: -0.31979
[32m[0906 20-00-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18272, current rewards: -724.75099, mean: -0.33553
[32m[0906 20-00-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18279, current rewards: -774.75099, mean: -0.35057
[32m[0906 20-00-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18275, current rewards: -824.75099, mean: -0.36493
[32m[0906 20-00-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18270, current rewards: -874.75099, mean: -0.37868
[32m[0906 20-00-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18265, current rewards: -924.75099, mean: -0.39184
[32m[0906 20-01-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18259, current rewards: -974.75099, mean: -0.40446
[32m[0906 20-01-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18244, current rewards: -1024.75099, mean: -0.41657
[32m[0906 20-01-23 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0906 20-01-23 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-01-23 @MBExp.py:227][0m Rewards obtained: [-1064.7509873921813], Lows: [20], Highs: [1144], Total time: 20646.040923999997
[32m[0906 20-02-57 @MBExp.py:144][0m ####################################################################
[32m[0906 20-02-57 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 20-02-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18552, current rewards: 0.71615, mean: 0.07161
[32m[0906 20-03-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18713, current rewards: 6.96354, mean: 0.11606
[32m[0906 20-03-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18698, current rewards: 12.99074, mean: 0.11810
[32m[0906 20-03-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18642, current rewards: 19.01526, mean: 0.11885
[32m[0906 20-03-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18584, current rewards: 23.91946, mean: 0.11390
[32m[0906 20-03-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18576, current rewards: 18.26319, mean: 0.07024
[32m[0906 20-03-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18567, current rewards: 23.61440, mean: 0.07618
[32m[0906 20-04-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18561, current rewards: 28.96068, mean: 0.08045
[32m[0906 20-04-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18562, current rewards: 34.31291, mean: 0.08369
[32m[0906 20-04-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18556, current rewards: 39.66014, mean: 0.08622
[32m[0906 20-04-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18551, current rewards: 30.25458, mean: 0.05932
[32m[0906 20-04-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18552, current rewards: 28.73237, mean: 0.05131
[32m[0906 20-04-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18551, current rewards: 33.59192, mean: 0.05507
[32m[0906 20-04-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18551, current rewards: 38.44834, mean: 0.05826
[32m[0906 20-05-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18555, current rewards: 43.30522, mean: 0.06099
[32m[0906 20-05-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18553, current rewards: 37.77258, mean: 0.04970
[32m[0906 20-05-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18555, current rewards: 44.15204, mean: 0.05451
[32m[0906 20-05-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18556, current rewards: 49.98945, mean: 0.05813
[32m[0906 20-05-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18552, current rewards: 56.50232, mean: 0.06209
[32m[0906 20-05-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18552, current rewards: 63.01587, mean: 0.06564
[32m[0906 20-06-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18546, current rewards: 69.52674, mean: 0.06884
[32m[0906 20-06-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18546, current rewards: 76.04260, mean: 0.07174
[32m[0906 20-06-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18546, current rewards: 82.56811, mean: 0.07439
[32m[0906 20-06-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18544, current rewards: 89.08215, mean: 0.07679
[32m[0906 20-06-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18540, current rewards: 95.59707, mean: 0.07901
[32m[0906 20-06-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18540, current rewards: 104.44338, mean: 0.08289
[32m[0906 20-07-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18540, current rewards: 111.12552, mean: 0.08483
[32m[0906 20-07-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18537, current rewards: 117.79839, mean: 0.08662
[32m[0906 20-07-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18524, current rewards: 124.47850, mean: 0.08828
[32m[0906 20-07-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18509, current rewards: 130.54385, mean: 0.08941
[32m[0906 20-07-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18494, current rewards: 137.38876, mean: 0.09099
[32m[0906 20-07-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18467, current rewards: 144.10457, mean: 0.09237
[32m[0906 20-07-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18438, current rewards: 150.83948, mean: 0.09369
[32m[0906 20-08-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18410, current rewards: 156.52755, mean: 0.09429
[32m[0906 20-08-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18384, current rewards: 163.19722, mean: 0.09544
[32m[0906 20-08-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18360, current rewards: 169.80434, mean: 0.09648
[32m[0906 20-08-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18335, current rewards: 176.40871, mean: 0.09746
[32m[0906 20-08-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18313, current rewards: 161.29066, mean: 0.08672
[32m[0906 20-08-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18293, current rewards: 167.91409, mean: 0.08791
[32m[0906 20-08-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18289, current rewards: 174.53665, mean: 0.08905
[32m[0906 20-09-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18284, current rewards: 181.16454, mean: 0.09013
[32m[0906 20-09-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18279, current rewards: 187.79694, mean: 0.09116
[32m[0906 20-09-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18286, current rewards: 194.43266, mean: 0.09215
[32m[0906 20-09-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18293, current rewards: 201.05975, mean: 0.09308
[32m[0906 20-09-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18298, current rewards: 207.69404, mean: 0.09398
[32m[0906 20-09-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18295, current rewards: 214.32639, mean: 0.09483
[32m[0906 20-10-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18288, current rewards: 220.95112, mean: 0.09565
[32m[0906 20-10-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18284, current rewards: 227.57879, mean: 0.09643
[32m[0906 20-10-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18274, current rewards: 234.21041, mean: 0.09718
[32m[0906 20-10-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18259, current rewards: 241.41545, mean: 0.09814
[32m[0906 20-10-34 @Agent.py:117][0m Average action selection time: 0.1825
[32m[0906 20-10-34 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-10-34 @MBExp.py:227][0m Rewards obtained: [251.09328914181637], Lows: [20], Highs: [21], Total time: 21102.920366
[32m[0906 20-12-10 @MBExp.py:144][0m ####################################################################
[32m[0906 20-12-10 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 20-12-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18485, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-12-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18542, current rewards: -4.85880, mean: -0.08098
[32m[0906 20-12-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18577, current rewards: 0.58762, mean: 0.00534
[32m[0906 20-12-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18580, current rewards: 6.04190, mean: 0.03776
[32m[0906 20-12-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18571, current rewards: 11.49084, mean: 0.05472
[32m[0906 20-12-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18564, current rewards: 16.93971, mean: 0.06515
[32m[0906 20-13-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18564, current rewards: 22.02078, mean: 0.07103
[32m[0906 20-13-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18562, current rewards: 28.09412, mean: 0.07804
[32m[0906 20-13-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18557, current rewards: 33.00461, mean: 0.08050
[32m[0906 20-13-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18551, current rewards: 38.73507, mean: 0.08421
[32m[0906 20-13-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18552, current rewards: 44.44974, mean: 0.08716
[32m[0906 20-13-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18545, current rewards: 50.16510, mean: 0.08958
[32m[0906 20-14-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18547, current rewards: 34.60026, mean: 0.05672
[32m[0906 20-14-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18538, current rewards: 40.78082, mean: 0.06179
[32m[0906 20-14-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18532, current rewards: 46.98964, mean: 0.06618
[32m[0906 20-14-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18525, current rewards: 53.19687, mean: 0.07000
[32m[0906 20-14-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18521, current rewards: 58.91554, mean: 0.07274
[32m[0906 20-14-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18522, current rewards: 64.99606, mean: 0.07558
[32m[0906 20-14-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18520, current rewards: 71.14172, mean: 0.07818
[32m[0906 20-15-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18519, current rewards: 77.29435, mean: 0.08051
[32m[0906 20-15-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18518, current rewards: 83.43833, mean: 0.08261
[32m[0906 20-15-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18513, current rewards: 89.58614, mean: 0.08452
[32m[0906 20-15-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18507, current rewards: 95.73181, mean: 0.08624
[32m[0906 20-15-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18510, current rewards: 101.87470, mean: 0.08782
[32m[0906 20-15-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18510, current rewards: 108.05745, mean: 0.08930
[32m[0906 20-16-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18508, current rewards: 112.10657, mean: 0.08897
[32m[0906 20-16-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18505, current rewards: 110.49691, mean: 0.08435
[32m[0906 20-16-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18496, current rewards: 116.10353, mean: 0.08537
[32m[0906 20-16-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18479, current rewards: 121.69938, mean: 0.08631
[32m[0906 20-16-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18464, current rewards: 127.29174, mean: 0.08719
[32m[0906 20-16-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18451, current rewards: 132.89664, mean: 0.08801
[32m[0906 20-16-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18424, current rewards: 138.49786, mean: 0.08878
[32m[0906 20-17-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18395, current rewards: 144.10148, mean: 0.08950
[32m[0906 20-17-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18369, current rewards: 150.78812, mean: 0.09084
[32m[0906 20-17-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18344, current rewards: 156.44529, mean: 0.09149
[32m[0906 20-17-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18321, current rewards: 162.10252, mean: 0.09210
[32m[0906 20-17-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18296, current rewards: 167.75547, mean: 0.09268
[32m[0906 20-17-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18279, current rewards: 173.40854, mean: 0.09323
[32m[0906 20-17-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18261, current rewards: 158.29761, mean: 0.08288
[32m[0906 20-18-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18256, current rewards: 164.58510, mean: 0.08397
[32m[0906 20-18-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18251, current rewards: 170.88741, mean: 0.08502
[32m[0906 20-18-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18246, current rewards: 176.95684, mean: 0.08590
[32m[0906 20-18-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18251, current rewards: 183.23204, mean: 0.08684
[32m[0906 20-18-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18259, current rewards: 189.50819, mean: 0.08774
[32m[0906 20-18-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18267, current rewards: 195.78211, mean: 0.08859
[32m[0906 20-19-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18267, current rewards: 202.05679, mean: 0.08941
[32m[0906 20-19-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18262, current rewards: 208.32920, mean: 0.09019
[32m[0906 20-19-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18259, current rewards: 205.60071, mean: 0.08712
[32m[0906 20-19-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18251, current rewards: 209.25458, mean: 0.08683
[32m[0906 20-19-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18236, current rewards: 216.32340, mean: 0.08794
[32m[0906 20-19-46 @Agent.py:117][0m Average action selection time: 0.1822
[32m[0906 20-19-46 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-19-46 @MBExp.py:227][0m Rewards obtained: [221.20647077025367], Lows: [20], Highs: [30], Total time: 21559.229390999997
[32m[0906 20-21-24 @MBExp.py:144][0m ####################################################################
[32m[0906 20-21-24 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 20-21-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18504, current rewards: -7.90174, mean: -0.79017
[32m[0906 20-21-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18580, current rewards: -2.11164, mean: -0.03519
[32m[0906 20-21-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18596, current rewards: 3.96718, mean: 0.03607
[32m[0906 20-21-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18582, current rewards: 10.04446, mean: 0.06278
[32m[0906 20-22-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18579, current rewards: 16.12216, mean: 0.07677
[32m[0906 20-22-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18564, current rewards: 22.20125, mean: 0.08539
[32m[0906 20-22-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18556, current rewards: 28.28050, mean: 0.09123
[32m[0906 20-22-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18550, current rewards: 35.57916, mean: 0.09883
[32m[0906 20-22-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18538, current rewards: 44.06665, mean: 0.10748
[32m[0906 20-22-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18532, current rewards: 50.14867, mean: 0.10902
[32m[0906 20-22-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18526, current rewards: 56.22951, mean: 0.11025
[32m[0906 20-23-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18533, current rewards: 62.31148, mean: 0.11127
[32m[0906 20-23-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18529, current rewards: 56.86776, mean: 0.09323
[32m[0906 20-23-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18528, current rewards: 62.65677, mean: 0.09493
[32m[0906 20-23-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18520, current rewards: 68.78469, mean: 0.09688
[32m[0906 20-23-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18515, current rewards: 74.91967, mean: 0.09858
[32m[0906 20-23-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18511, current rewards: 80.82552, mean: 0.09978
[32m[0906 20-24-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18510, current rewards: 86.96646, mean: 0.10112
[32m[0906 20-24-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18511, current rewards: 93.11065, mean: 0.10232
[32m[0906 20-24-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18508, current rewards: 99.24800, mean: 0.10338
[32m[0906 20-24-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18509, current rewards: 105.38723, mean: 0.10434
[32m[0906 20-24-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18506, current rewards: 111.52969, mean: 0.10522
[32m[0906 20-24-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18500, current rewards: 117.67403, mean: 0.10601
[32m[0906 20-24-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18499, current rewards: 123.81343, mean: 0.10674
[32m[0906 20-25-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18520, current rewards: 118.12953, mean: 0.09763
[32m[0906 20-25-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18518, current rewards: 124.22065, mean: 0.09859
[32m[0906 20-25-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18516, current rewards: 130.30970, mean: 0.09947
[32m[0906 20-25-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18502, current rewards: 136.41454, mean: 0.10030
[32m[0906 20-25-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18488, current rewards: 142.51660, mean: 0.10108
[32m[0906 20-25-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18474, current rewards: 148.61938, mean: 0.10179
[32m[0906 20-26-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18461, current rewards: 154.72648, mean: 0.10247
[32m[0906 20-26-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18433, current rewards: 160.82939, mean: 0.10310
[32m[0906 20-26-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18405, current rewards: 170.44681, mean: 0.10587
[32m[0906 20-26-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18377, current rewards: 176.63807, mean: 0.10641
[32m[0906 20-26-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18351, current rewards: 182.76974, mean: 0.10688
[32m[0906 20-26-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18325, current rewards: 188.91003, mean: 0.10734
[32m[0906 20-26-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18299, current rewards: 194.62763, mean: 0.10753
[32m[0906 20-27-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18277, current rewards: 195.38829, mean: 0.10505
[32m[0906 20-27-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18259, current rewards: 194.60255, mean: 0.10189
[32m[0906 20-27-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18253, current rewards: 197.77486, mean: 0.10091
[32m[0906 20-27-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18246, current rewards: 175.68791, mean: 0.08741
[32m[0906 20-27-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18242, current rewards: 174.88175, mean: 0.08489
[32m[0906 20-27-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18245, current rewards: 180.52977, mean: 0.08556
[32m[0906 20-27-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18251, current rewards: 186.18169, mean: 0.08620
[32m[0906 20-28-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18260, current rewards: 191.82932, mean: 0.08680
[32m[0906 20-28-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18261, current rewards: 177.06986, mean: 0.07835
[32m[0906 20-28-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18258, current rewards: 182.97151, mean: 0.07921
[32m[0906 20-28-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18254, current rewards: 188.87384, mean: 0.08003
[32m[0906 20-28-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18245, current rewards: 194.43979, mean: 0.08068
[32m[0906 20-28-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18230, current rewards: 200.23642, mean: 0.08140
[32m[0906 20-29-00 @Agent.py:117][0m Average action selection time: 0.1822
[32m[0906 20-29-00 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-29-00 @MBExp.py:227][0m Rewards obtained: [204.93670529431807], Lows: [48], Highs: [28], Total time: 22015.422373999998
[32m[0906 20-30-41 @MBExp.py:144][0m ####################################################################
[32m[0906 20-30-41 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 20-30-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18510, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-30-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18534, current rewards: -30.91240, mean: -0.51521
[32m[0906 20-31-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18508, current rewards: -25.50996, mean: -0.23191
[32m[0906 20-31-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18524, current rewards: -20.10640, mean: -0.12566
[32m[0906 20-31-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18534, current rewards: -14.69716, mean: -0.06999
[32m[0906 20-31-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18535, current rewards: -9.29369, mean: -0.03574
[32m[0906 20-31-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18539, current rewards: -3.89055, mean: -0.01255
[32m[0906 20-31-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18533, current rewards: 3.56338, mean: 0.00990
[32m[0906 20-31-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18535, current rewards: 8.86633, mean: 0.02163
[32m[0906 20-32-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18536, current rewards: 14.16966, mean: 0.03080
[32m[0906 20-32-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18525, current rewards: 19.47748, mean: 0.03819
[32m[0906 20-32-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18524, current rewards: 24.78679, mean: 0.04426
[32m[0906 20-32-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18535, current rewards: 30.18196, mean: 0.04948
[32m[0906 20-32-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18540, current rewards: 35.66241, mean: 0.05403
[32m[0906 20-32-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18537, current rewards: 41.14708, mean: 0.05795
[32m[0906 20-33-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18535, current rewards: 46.34430, mean: 0.06098
[32m[0906 20-33-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18536, current rewards: 51.58390, mean: 0.06368
[32m[0906 20-33-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18529, current rewards: 57.09119, mean: 0.06639
[32m[0906 20-33-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18523, current rewards: 62.60547, mean: 0.06880
[32m[0906 20-33-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18521, current rewards: 68.11804, mean: 0.07096
[32m[0906 20-33-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18520, current rewards: 73.62768, mean: 0.07290
[32m[0906 20-33-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18514, current rewards: 79.13543, mean: 0.07466
[32m[0906 20-34-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18516, current rewards: 84.64505, mean: 0.07626
[32m[0906 20-34-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18512, current rewards: 90.15397, mean: 0.07772
[32m[0906 20-34-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18508, current rewards: 97.85209, mean: 0.08087
[32m[0906 20-34-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18509, current rewards: 92.80262, mean: 0.07365
[32m[0906 20-34-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18510, current rewards: 87.84342, mean: 0.06706
[32m[0906 20-34-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18490, current rewards: 93.19058, mean: 0.06852
[32m[0906 20-35-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18474, current rewards: 98.53774, mean: 0.06988
[32m[0906 20-35-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18460, current rewards: 103.88490, mean: 0.07115
[32m[0906 20-35-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18446, current rewards: 109.23206, mean: 0.07234
[32m[0906 20-35-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18416, current rewards: 87.15648, mean: 0.05587
[32m[0906 20-35-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18388, current rewards: 91.03697, mean: 0.05654
[32m[0906 20-35-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18360, current rewards: 94.95446, mean: 0.05720
[32m[0906 20-35-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18336, current rewards: 98.87047, mean: 0.05782
[32m[0906 20-36-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18312, current rewards: 102.78661, mean: 0.05840
[32m[0906 20-36-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18290, current rewards: 106.70362, mean: 0.05895
[32m[0906 20-36-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18269, current rewards: 110.61875, mean: 0.05947
[32m[0906 20-36-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18253, current rewards: 114.53600, mean: 0.05997
[32m[0906 20-36-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18250, current rewards: 118.45413, mean: 0.06044
[32m[0906 20-36-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18245, current rewards: 122.50094, mean: 0.06095
[32m[0906 20-36-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18240, current rewards: 127.07281, mean: 0.06169
[32m[0906 20-37-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18241, current rewards: 131.15304, mean: 0.06216
[32m[0906 20-37-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18251, current rewards: 135.23163, mean: 0.06261
[32m[0906 20-37-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18268, current rewards: 128.55847, mean: 0.05817
[32m[0906 20-37-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18269, current rewards: 66.54724, mean: 0.02945
[32m[0906 20-37-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18265, current rewards: 4.23004, mean: 0.00183
[32m[0906 20-37-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18261, current rewards: -55.16615, mean: -0.02338
[32m[0906 20-38-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18253, current rewards: -107.01170, mean: -0.04440
[32m[0906 20-38-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18238, current rewards: -160.71299, mean: -0.06533
[32m[0906 20-38-17 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0906 20-38-17 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-38-17 @MBExp.py:227][0m Rewards obtained: [-198.74606033601], Lows: [193], Highs: [46], Total time: 22471.795904
[32m[0906 20-39-59 @MBExp.py:144][0m ####################################################################
[32m[0906 20-39-59 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 20-40-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18663, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-40-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18571, current rewards: -5.58455, mean: -0.09308
[32m[0906 20-40-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18542, current rewards: 0.15391, mean: 0.00140
[32m[0906 20-40-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18531, current rewards: 5.88349, mean: 0.03677
[32m[0906 20-40-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18531, current rewards: 11.62150, mean: 0.05534
[32m[0906 20-40-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18539, current rewards: 17.36212, mean: 0.06678
[32m[0906 20-40-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18555, current rewards: 23.09815, mean: 0.07451
[32m[0906 20-41-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18556, current rewards: 28.21188, mean: 0.07837
[32m[0906 20-41-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18545, current rewards: 33.66265, mean: 0.08210
[32m[0906 20-41-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18548, current rewards: 13.50068, mean: 0.02935
[32m[0906 20-41-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18537, current rewards: 19.15129, mean: 0.03755
[32m[0906 20-41-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18529, current rewards: 24.79928, mean: 0.04428
[32m[0906 20-41-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18514, current rewards: 30.44621, mean: 0.04991
[32m[0906 20-42-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18511, current rewards: 36.09442, mean: 0.05469
[32m[0906 20-42-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18723, current rewards: 41.74215, mean: 0.05879
[32m[0906 20-42-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18718, current rewards: 47.91520, mean: 0.06305
[32m[0906 20-42-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18710, current rewards: 53.66935, mean: 0.06626
[32m[0906 20-42-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18699, current rewards: 59.42855, mean: 0.06910
[32m[0906 20-42-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18684, current rewards: 65.18738, mean: 0.07163
[32m[0906 20-42-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18670, current rewards: 70.94978, mean: 0.07391
[32m[0906 20-43-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18661, current rewards: 76.71177, mean: 0.07595
[32m[0906 20-43-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18651, current rewards: 71.17380, mean: 0.06715
[32m[0906 20-43-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18644, current rewards: 76.73766, mean: 0.06913
[32m[0906 20-43-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18635, current rewards: 83.37287, mean: 0.07187
[32m[0906 20-43-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18636, current rewards: 88.97011, mean: 0.07353
[32m[0906 20-43-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18627, current rewards: 94.57866, mean: 0.07506
[32m[0906 20-44-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18614, current rewards: 100.18581, mean: 0.07648
[32m[0906 20-44-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18590, current rewards: 105.79037, mean: 0.07779
[32m[0906 20-44-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18570, current rewards: 111.39500, mean: 0.07900
[32m[0906 20-44-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18551, current rewards: 105.64420, mean: 0.07236
[32m[0906 20-44-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18532, current rewards: 110.97502, mean: 0.07349
[32m[0906 20-44-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18496, current rewards: 115.95124, mean: 0.07433
[32m[0906 20-44-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18466, current rewards: 120.91672, mean: 0.07510
[32m[0906 20-45-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18437, current rewards: 126.10348, mean: 0.07597
[32m[0906 20-45-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18409, current rewards: 131.28838, mean: 0.07678
[32m[0906 20-45-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18383, current rewards: 136.47557, mean: 0.07754
[32m[0906 20-45-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18358, current rewards: 141.65835, mean: 0.07826
[32m[0906 20-45-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18333, current rewards: 146.84803, mean: 0.07895
[32m[0906 20-45-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18319, current rewards: 152.03174, mean: 0.07960
[32m[0906 20-45-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18313, current rewards: 156.89469, mean: 0.08005
[32m[0906 20-46-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18306, current rewards: 164.93171, mean: 0.08206
[32m[0906 20-46-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18299, current rewards: 170.90981, mean: 0.08297
[32m[0906 20-46-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18296, current rewards: 176.89589, mean: 0.08384
[32m[0906 20-46-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18300, current rewards: 182.87208, mean: 0.08466
[32m[0906 20-46-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18306, current rewards: 188.85177, mean: 0.08545
[32m[0906 20-46-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18307, current rewards: 194.82122, mean: 0.08620
[32m[0906 20-47-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18302, current rewards: 200.79415, mean: 0.08692
[32m[0906 20-47-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18297, current rewards: 206.77475, mean: 0.08762
[32m[0906 20-47-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18291, current rewards: 185.61900, mean: 0.07702
[32m[0906 20-47-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18274, current rewards: 184.59152, mean: 0.07504
[32m[0906 20-47-36 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0906 20-47-36 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-47-36 @MBExp.py:227][0m Rewards obtained: [188.89011299469942], Lows: [25], Highs: [36], Total time: 22929.003771
[32m[0906 20-49-20 @MBExp.py:144][0m ####################################################################
[32m[0906 20-49-20 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 20-49-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18525, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-49-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18562, current rewards: -2.20835, mean: -0.03681
[32m[0906 20-49-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18549, current rewards: 3.41798, mean: 0.03107
[32m[0906 20-49-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18560, current rewards: 9.04697, mean: 0.05654
[32m[0906 20-49-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18570, current rewards: 14.67742, mean: 0.06989
[32m[0906 20-50-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18564, current rewards: 2.31654, mean: 0.00891
[32m[0906 20-50-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18530, current rewards: 10.61666, mean: 0.03425
[32m[0906 20-50-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18521, current rewards: 14.53668, mean: 0.04038
[32m[0906 20-50-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18517, current rewards: -35.46332, mean: -0.08650
[32m[0906 20-50-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18512, current rewards: -85.46332, mean: -0.18579
[32m[0906 20-50-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18508, current rewards: -135.46332, mean: -0.26561
[32m[0906 20-51-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18506, current rewards: -199.72873, mean: -0.35666
[32m[0906 20-51-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18499, current rewards: -277.21338, mean: -0.45445
[32m[0906 20-51-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18494, current rewards: -347.64163, mean: -0.52673
[32m[0906 20-51-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18492, current rewards: -403.93730, mean: -0.56893
[32m[0906 20-51-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18489, current rewards: -476.22783, mean: -0.62662
[32m[0906 20-51-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18493, current rewards: -563.54497, mean: -0.69573
[32m[0906 20-51-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18489, current rewards: -663.54497, mean: -0.77156
[32m[0906 20-52-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18491, current rewards: -763.54497, mean: -0.83906
[32m[0906 20-52-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18486, current rewards: -863.54497, mean: -0.89953
[32m[0906 20-52-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18489, current rewards: -963.54497, mean: -0.95400
[32m[0906 20-52-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18487, current rewards: -1063.54497, mean: -1.00334
[32m[0906 20-52-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18482, current rewards: -1163.54497, mean: -1.04824
[32m[0906 20-52-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18482, current rewards: -1180.80434, mean: -1.01793
[32m[0906 20-53-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18480, current rewards: -1175.58596, mean: -0.97156
[32m[0906 20-53-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18480, current rewards: -1170.26000, mean: -0.92878
[32m[0906 20-53-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18463, current rewards: -1164.93608, mean: -0.88926
[32m[0906 20-53-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18446, current rewards: -1159.60575, mean: -0.85265
[32m[0906 20-53-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18431, current rewards: -1154.28096, mean: -0.81864
[32m[0906 20-53-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18415, current rewards: -1148.67298, mean: -0.78676
[32m[0906 20-53-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18393, current rewards: -1143.78191, mean: -0.75747
[32m[0906 20-54-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18364, current rewards: -1138.69886, mean: -0.72994
[32m[0906 20-54-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18337, current rewards: -1132.26344, mean: -0.70327
[32m[0906 20-54-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18309, current rewards: -1126.64690, mean: -0.67870
[32m[0906 20-54-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18284, current rewards: -1121.06099, mean: -0.65559
[32m[0906 20-54-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18261, current rewards: -1115.48159, mean: -0.63380
[32m[0906 20-54-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18238, current rewards: -1109.83133, mean: -0.61317
[32m[0906 20-55-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18217, current rewards: -1104.23290, mean: -0.59367
[32m[0906 20-55-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18206, current rewards: -1117.36224, mean: -0.58501
[32m[0906 20-55-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18201, current rewards: -1111.89542, mean: -0.56729
[32m[0906 20-55-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18196, current rewards: -1106.40880, mean: -0.55045
[32m[0906 20-55-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18192, current rewards: -1101.77177, mean: -0.53484
[32m[0906 20-55-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18191, current rewards: -1096.29542, mean: -0.51957
[32m[0906 20-55-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18201, current rewards: -1102.07644, mean: -0.51022
[32m[0906 20-56-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18210, current rewards: -1096.97207, mean: -0.49637
[32m[0906 20-56-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18212, current rewards: -1091.85847, mean: -0.48312
[32m[0906 20-56-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18211, current rewards: -1086.76420, mean: -0.47046
[32m[0906 20-56-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18206, current rewards: -1081.63833, mean: -0.45832
[32m[0906 20-56-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18202, current rewards: -1076.53441, mean: -0.44669
[32m[0906 20-56-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18187, current rewards: -1069.72274, mean: -0.43485
[32m[0906 20-56-55 @Agent.py:117][0m Average action selection time: 0.1818
[32m[0906 20-56-55 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-56-55 @MBExp.py:227][0m Rewards obtained: [-1086.395598135351], Lows: [563], Highs: [182], Total time: 23384.12383
[32m[0906 20-58-41 @MBExp.py:144][0m ####################################################################
[32m[0906 20-58-41 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 20-58-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18523, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-58-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18560, current rewards: -14.37555, mean: -0.23959
[32m[0906 20-59-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18538, current rewards: -9.01979, mean: -0.08200
[32m[0906 20-59-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18518, current rewards: -3.66585, mean: -0.02291
[32m[0906 20-59-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18504, current rewards: 1.68179, mean: 0.00801
[32m[0906 20-59-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18495, current rewards: 7.03285, mean: 0.02705
[32m[0906 20-59-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18494, current rewards: 4.63285, mean: 0.01494
[32m[0906 20-59-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18493, current rewards: -36.79031, mean: -0.10220
[32m[0906 20-59-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18499, current rewards: -76.40801, mean: -0.18636
[32m[0906 21-00-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18494, current rewards: -115.08376, mean: -0.25018
[32m[0906 21-00-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18495, current rewards: -153.67314, mean: -0.30132
[32m[0906 21-00-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18501, current rewards: -192.36848, mean: -0.34352
[32m[0906 21-00-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18506, current rewards: -231.17940, mean: -0.37898
[32m[0906 21-00-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18501, current rewards: -270.02133, mean: -0.40912
[32m[0906 21-00-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18496, current rewards: -308.86585, mean: -0.43502
[32m[0906 21-01-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18489, current rewards: -347.63006, mean: -0.45741
[32m[0906 21-01-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18488, current rewards: -380.36079, mean: -0.46958
[32m[0906 21-01-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18485, current rewards: -424.82188, mean: -0.49398
[32m[0906 21-01-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18485, current rewards: -466.96995, mean: -0.51315
[32m[0906 21-01-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18481, current rewards: -507.05824, mean: -0.52819
[32m[0906 21-01-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18477, current rewards: -547.22646, mean: -0.54181
[32m[0906 21-01-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18477, current rewards: -597.84205, mean: -0.56400
[32m[0906 21-02-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18475, current rewards: -592.99508, mean: -0.53423
[32m[0906 21-02-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18474, current rewards: -587.73069, mean: -0.50666
[32m[0906 21-02-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18473, current rewards: -581.44653, mean: -0.48053
[32m[0906 21-02-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18475, current rewards: -575.26866, mean: -0.45656
[32m[0906 21-02-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18458, current rewards: -569.99461, mean: -0.43511
[32m[0906 21-02-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18439, current rewards: -564.72308, mean: -0.41524
[32m[0906 21-03-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18424, current rewards: -559.45120, mean: -0.39677
[32m[0906 21-03-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18408, current rewards: -554.17405, mean: -0.37957
[32m[0906 21-03-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18387, current rewards: -548.89675, mean: -0.36351
[32m[0906 21-03-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18358, current rewards: -554.14948, mean: -0.35522
[32m[0906 21-03-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18331, current rewards: -559.35790, mean: -0.34743
[32m[0906 21-03-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18305, current rewards: -554.24936, mean: -0.33389
[32m[0906 21-03-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18281, current rewards: -548.88290, mean: -0.32098
[32m[0906 21-04-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18257, current rewards: -543.52168, mean: -0.30882
[32m[0906 21-04-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18235, current rewards: -538.16360, mean: -0.29733
[32m[0906 21-04-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18214, current rewards: -532.80275, mean: -0.28645
[32m[0906 21-04-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18203, current rewards: -527.43810, mean: -0.27615
[32m[0906 21-04-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18200, current rewards: -522.07251, mean: -0.26636
[32m[0906 21-04-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18197, current rewards: -526.67771, mean: -0.26203
[32m[0906 21-04-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18193, current rewards: -522.87124, mean: -0.25382
[32m[0906 21-05-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18190, current rewards: -518.01907, mean: -0.24551
[32m[0906 21-05-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18199, current rewards: -513.16605, mean: -0.23758
[32m[0906 21-05-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18206, current rewards: -508.31344, mean: -0.23001
[32m[0906 21-05-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18210, current rewards: -503.46199, mean: -0.22277
[32m[0906 21-05-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18205, current rewards: -498.60750, mean: -0.21585
[32m[0906 21-05-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18201, current rewards: -493.75330, mean: -0.20922
[32m[0906 21-06-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18196, current rewards: -488.89746, mean: -0.20286
[32m[0906 21-06-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18180, current rewards: -483.49205, mean: -0.19654
[32m[0906 21-06-16 @Agent.py:117][0m Average action selection time: 0.1817
[32m[0906 21-06-16 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-06-16 @MBExp.py:227][0m Rewards obtained: [-481.6926978440971], Lows: [346], Highs: [38], Total time: 23839.053239
[32m[0906 21-08-04 @MBExp.py:144][0m ####################################################################
[32m[0906 21-08-04 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 21-08-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18528, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-08-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18591, current rewards: -4.88468, mean: -0.08141
[32m[0906 21-08-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18585, current rewards: 0.46093, mean: 0.00419
[32m[0906 21-08-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18574, current rewards: 5.80904, mean: 0.03631
[32m[0906 21-08-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18544, current rewards: 11.15740, mean: 0.05313
[32m[0906 21-08-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18565, current rewards: 16.50247, mean: 0.06347
[32m[0906 21-09-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18557, current rewards: 21.84811, mean: 0.07048
[32m[0906 21-09-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18536, current rewards: 26.60162, mean: 0.07389
[32m[0906 21-09-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18529, current rewards: 31.94032, mean: 0.07790
[32m[0906 21-09-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18522, current rewards: 37.25300, mean: 0.08098
[32m[0906 21-09-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18509, current rewards: 42.57020, mean: 0.08347
[32m[0906 21-09-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18505, current rewards: 47.88322, mean: 0.08551
[32m[0906 21-09-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18501, current rewards: 42.67003, mean: 0.06995
[32m[0906 21-10-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18501, current rewards: 37.32884, mean: 0.05656
[32m[0906 21-10-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18500, current rewards: 42.50643, mean: 0.05987
[32m[0906 21-10-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18500, current rewards: 47.61649, mean: 0.06265
[32m[0906 21-10-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18498, current rewards: 52.79985, mean: 0.06519
[32m[0906 21-10-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18496, current rewards: 57.98051, mean: 0.06742
[32m[0906 21-10-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18497, current rewards: 63.16741, mean: 0.06941
[32m[0906 21-11-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18504, current rewards: 68.34984, mean: 0.07120
[32m[0906 21-11-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18499, current rewards: 73.53237, mean: 0.07280
[32m[0906 21-11-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18495, current rewards: 66.01627, mean: 0.06228
[32m[0906 21-11-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18489, current rewards: 71.21931, mean: 0.06416
[32m[0906 21-11-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18488, current rewards: 76.19290, mean: 0.06568
[32m[0906 21-11-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18482, current rewards: 81.24975, mean: 0.06715
[32m[0906 21-11-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18477, current rewards: 86.41705, mean: 0.06858
[32m[0906 21-12-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18458, current rewards: 91.58428, mean: 0.06991
[32m[0906 21-12-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18442, current rewards: 96.75415, mean: 0.07114
[32m[0906 21-12-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18428, current rewards: 101.22357, mean: 0.07179
[32m[0906 21-12-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18415, current rewards: 105.89559, mean: 0.07253
[32m[0906 21-12-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18389, current rewards: 110.58585, mean: 0.07324
[32m[0906 21-12-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18357, current rewards: 115.27832, mean: 0.07390
[32m[0906 21-13-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18329, current rewards: 120.56521, mean: 0.07489
[32m[0906 21-13-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18305, current rewards: 125.31054, mean: 0.07549
[32m[0906 21-13-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18279, current rewards: 130.05670, mean: 0.07606
[32m[0906 21-13-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18256, current rewards: 134.80737, mean: 0.07660
[32m[0906 21-13-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18232, current rewards: 139.54624, mean: 0.07710
[32m[0906 21-13-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18212, current rewards: 144.29074, mean: 0.07758
[32m[0906 21-13-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18200, current rewards: 149.03569, mean: 0.07803
[32m[0906 21-14-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18194, current rewards: 153.78049, mean: 0.07846
[32m[0906 21-14-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18191, current rewards: 159.68217, mean: 0.07944
[32m[0906 21-14-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18188, current rewards: 143.62753, mean: 0.06972
[32m[0906 21-14-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18184, current rewards: 149.85091, mean: 0.07102
[32m[0906 21-14-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18193, current rewards: 155.13861, mean: 0.07182
[32m[0906 21-14-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18199, current rewards: 160.43059, mean: 0.07259
[32m[0906 21-14-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18206, current rewards: 165.72582, mean: 0.07333
[32m[0906 21-15-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18204, current rewards: 159.96128, mean: 0.06925
[32m[0906 21-15-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18203, current rewards: 165.16848, mean: 0.06999
[32m[0906 21-15-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18201, current rewards: 170.08951, mean: 0.07058
[32m[0906 21-15-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18186, current rewards: 175.10513, mean: 0.07118
[32m[0906 21-15-39 @Agent.py:117][0m Average action selection time: 0.1818
[32m[0906 21-15-39 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-15-39 @MBExp.py:227][0m Rewards obtained: [179.12628046647768], Lows: [21], Highs: [30], Total time: 24294.150149
[32m[0906 21-17-29 @MBExp.py:144][0m ####################################################################
[32m[0906 21-17-29 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 21-17-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18569, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-17-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18437, current rewards: -10.86448, mean: -0.18107
[32m[0906 21-17-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18430, current rewards: -5.01544, mean: -0.04559
[32m[0906 21-17-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18439, current rewards: 0.84174, mean: 0.00526
[32m[0906 21-18-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18436, current rewards: 6.69062, mean: 0.03186
[32m[0906 21-18-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18444, current rewards: 12.54737, mean: 0.04826
[32m[0906 21-18-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18468, current rewards: 18.40326, mean: 0.05937
[32m[0906 21-18-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18470, current rewards: 6.32696, mean: 0.01757
[32m[0906 21-18-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18468, current rewards: 12.13821, mean: 0.02961
[32m[0906 21-18-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18477, current rewards: 17.94778, mean: 0.03902
[32m[0906 21-19-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18481, current rewards: 23.75486, mean: 0.04658
[32m[0906 21-19-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18484, current rewards: 29.56479, mean: 0.05279
[32m[0906 21-19-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18495, current rewards: 35.37634, mean: 0.05799
[32m[0906 21-19-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18498, current rewards: 41.18963, mean: 0.06241
[32m[0906 21-19-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18493, current rewards: 47.00130, mean: 0.06620
[32m[0906 21-19-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18494, current rewards: 53.35897, mean: 0.07021
[32m[0906 21-19-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18493, current rewards: 44.39475, mean: 0.05481
[32m[0906 21-20-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18485, current rewards: 42.20905, mean: 0.04908
[32m[0906 21-20-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18481, current rewards: 48.52448, mean: 0.05332
[32m[0906 21-20-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18474, current rewards: 54.83990, mean: 0.05712
[32m[0906 21-20-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18472, current rewards: 61.15533, mean: 0.06055
[32m[0906 21-20-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18475, current rewards: 67.47075, mean: 0.06365
[32m[0906 21-20-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18477, current rewards: 73.78618, mean: 0.06647
[32m[0906 21-21-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18479, current rewards: 79.80779, mean: 0.06880
[32m[0906 21-21-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18478, current rewards: 85.37094, mean: 0.07055
[32m[0906 21-21-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18470, current rewards: 90.93408, mean: 0.07217
[32m[0906 21-21-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18457, current rewards: 57.60303, mean: 0.04397
[32m[0906 21-21-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18440, current rewards: 7.60303, mean: 0.00559
[32m[0906 21-21-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18423, current rewards: -42.39697, mean: -0.03007
[32m[0906 21-21-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18407, current rewards: -92.39697, mean: -0.06329
[32m[0906 21-22-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18379, current rewards: -142.39697, mean: -0.09430
[32m[0906 21-22-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18350, current rewards: -192.39697, mean: -0.12333
[32m[0906 21-22-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18323, current rewards: -242.39697, mean: -0.15056
[32m[0906 21-22-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18296, current rewards: -292.39697, mean: -0.17614
[32m[0906 21-22-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18271, current rewards: -342.39697, mean: -0.20023
[32m[0906 21-22-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18247, current rewards: -392.39697, mean: -0.22295
[32m[0906 21-23-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18226, current rewards: -442.39697, mean: -0.24442
[32m[0906 21-23-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18205, current rewards: -492.39697, mean: -0.26473
[32m[0906 21-23-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18195, current rewards: -542.39697, mean: -0.28398
[32m[0906 21-23-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18190, current rewards: -592.39697, mean: -0.30224
[32m[0906 21-23-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18187, current rewards: -642.39697, mean: -0.31960
[32m[0906 21-23-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18184, current rewards: -692.39697, mean: -0.33612
[32m[0906 21-23-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18179, current rewards: -742.39697, mean: -0.35185
[32m[0906 21-24-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18187, current rewards: -792.39697, mean: -0.36685
[32m[0906 21-24-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18195, current rewards: -842.39697, mean: -0.38118
[32m[0906 21-24-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18202, current rewards: -892.39697, mean: -0.39487
[32m[0906 21-24-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18197, current rewards: -942.39697, mean: -0.40796
[32m[0906 21-24-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18193, current rewards: -992.39697, mean: -0.42051
[32m[0906 21-24-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18188, current rewards: -1042.39697, mean: -0.43253
[32m[0906 21-24-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18174, current rewards: -1092.39697, mean: -0.44406
[32m[0906 21-25-04 @Agent.py:117][0m Average action selection time: 0.1816
[32m[0906 21-25-04 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-25-04 @MBExp.py:227][0m Rewards obtained: [-1132.3969716606225], Lows: [21], Highs: [1241], Total time: 24748.946035
[32m[0906 21-26-56 @MBExp.py:144][0m ####################################################################
[32m[0906 21-26-56 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 21-26-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18661, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-27-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18602, current rewards: -14.22536, mean: -0.23709
[32m[0906 21-27-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18594, current rewards: -9.00309, mean: -0.08185
[32m[0906 21-27-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18559, current rewards: -3.77806, mean: -0.02361
[32m[0906 21-27-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18545, current rewards: 1.44839, mean: 0.00690
[32m[0906 21-27-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18562, current rewards: 6.67409, mean: 0.02567
[32m[0906 21-27-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18553, current rewards: -9.56132, mean: -0.03084
[32m[0906 21-28-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18536, current rewards: -4.46985, mean: -0.01242
[32m[0906 21-28-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18534, current rewards: 0.62746, mean: 0.00153
[32m[0906 21-28-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18534, current rewards: 5.72609, mean: 0.01245
[32m[0906 21-28-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18529, current rewards: 10.82497, mean: 0.02123
[32m[0906 21-28-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18521, current rewards: 15.92025, mean: 0.02843
[32m[0906 21-28-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18513, current rewards: 21.01611, mean: 0.03445
[32m[0906 21-28-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18515, current rewards: 26.11070, mean: 0.03956
[32m[0906 21-29-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18505, current rewards: 31.04879, mean: 0.04373
[32m[0906 21-29-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18504, current rewards: 25.96426, mean: 0.03416
[32m[0906 21-29-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18506, current rewards: 27.60984, mean: 0.03409
[32m[0906 21-29-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18500, current rewards: 32.99134, mean: 0.03836
[32m[0906 21-29-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18502, current rewards: 38.37235, mean: 0.04217
[32m[0906 21-29-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18504, current rewards: 43.74947, mean: 0.04557
[32m[0906 21-30-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18509, current rewards: 49.13477, mean: 0.04865
[32m[0906 21-30-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18504, current rewards: 54.51580, mean: 0.05143
[32m[0906 21-30-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18504, current rewards: 59.89156, mean: 0.05396
[32m[0906 21-30-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18500, current rewards: 68.12971, mean: 0.05873
[32m[0906 21-30-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18496, current rewards: 72.59454, mean: 0.06000
[32m[0906 21-30-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18476, current rewards: 77.44361, mean: 0.06146
[32m[0906 21-30-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18458, current rewards: 82.29809, mean: 0.06282
[32m[0906 21-31-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18441, current rewards: 87.14531, mean: 0.06408
[32m[0906 21-31-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18426, current rewards: 91.99457, mean: 0.06524
[32m[0906 21-31-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18412, current rewards: 96.83884, mean: 0.06633
[32m[0906 21-31-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18380, current rewards: 101.68868, mean: 0.06734
[32m[0906 21-31-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18350, current rewards: 106.11329, mean: 0.06802
[32m[0906 21-31-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18323, current rewards: 89.68549, mean: 0.05571
[32m[0906 21-32-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18300, current rewards: 95.22121, mean: 0.05736
[32m[0906 21-32-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18274, current rewards: 100.26523, mean: 0.05863
[32m[0906 21-32-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18249, current rewards: 105.30278, mean: 0.05983
[32m[0906 21-32-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18227, current rewards: 110.34430, mean: 0.06096
[32m[0906 21-32-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18205, current rewards: 115.38207, mean: 0.06203
[32m[0906 21-32-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18199, current rewards: 120.42178, mean: 0.06305
[32m[0906 21-32-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18194, current rewards: 125.45975, mean: 0.06401
[32m[0906 21-33-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18190, current rewards: 134.15384, mean: 0.06674
[32m[0906 21-33-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18185, current rewards: 137.91344, mean: 0.06695
[32m[0906 21-33-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18181, current rewards: 122.90419, mean: 0.05825
[32m[0906 21-33-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18188, current rewards: 129.85398, mean: 0.06012
[32m[0906 21-33-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18196, current rewards: 138.64264, mean: 0.06273
[32m[0906 21-33-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18200, current rewards: 147.43130, mean: 0.06524
[32m[0906 21-33-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18199, current rewards: 156.21996, mean: 0.06763
[32m[0906 21-34-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18197, current rewards: 165.00863, mean: 0.06992
[32m[0906 21-34-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18193, current rewards: 172.87094, mean: 0.07173
[32m[0906 21-34-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18179, current rewards: 178.54801, mean: 0.07258
[32m[0906 21-34-31 @Agent.py:117][0m Average action selection time: 0.1817
[32m[0906 21-34-31 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-34-31 @MBExp.py:227][0m Rewards obtained: [138.5480089246129], Lows: [36], Highs: [61], Total time: 25203.849355000002
[32m[0906 21-36-24 @MBExp.py:144][0m ####################################################################
[32m[0906 21-36-24 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 21-36-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18592, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-36-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18543, current rewards: -6.80037, mean: -0.11334
[32m[0906 21-36-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18547, current rewards: -1.70628, mean: -0.01551
[32m[0906 21-36-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18533, current rewards: 3.37554, mean: 0.02110
[32m[0906 21-37-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18503, current rewards: 8.46477, mean: 0.04031
[32m[0906 21-37-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18500, current rewards: 13.56152, mean: 0.05216
[32m[0906 21-37-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18482, current rewards: 18.64274, mean: 0.06014
[32m[0906 21-37-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18473, current rewards: 25.58646, mean: 0.07107
[32m[0906 21-37-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18480, current rewards: 30.85982, mean: 0.07527
[32m[0906 21-37-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18473, current rewards: 35.37573, mean: 0.07690
[32m[0906 21-37-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18478, current rewards: 40.06515, mean: 0.07856
[32m[0906 21-38-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18482, current rewards: 44.75857, mean: 0.07993
[32m[0906 21-38-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18492, current rewards: 49.44722, mean: 0.08106
[32m[0906 21-38-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18493, current rewards: 54.13563, mean: 0.08202
[32m[0906 21-38-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18486, current rewards: 58.82538, mean: 0.08285
[32m[0906 21-38-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18488, current rewards: 63.54434, mean: 0.08361
[32m[0906 21-38-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18490, current rewards: 68.42054, mean: 0.08447
[32m[0906 21-39-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18491, current rewards: 75.12002, mean: 0.08735
[32m[0906 21-39-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18492, current rewards: 80.28561, mean: 0.08823
[32m[0906 21-39-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18488, current rewards: 85.46396, mean: 0.08902
[32m[0906 21-39-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18487, current rewards: 90.64068, mean: 0.08974
[32m[0906 21-39-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18483, current rewards: 95.81315, mean: 0.09039
[32m[0906 21-39-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18482, current rewards: 100.98914, mean: 0.09098
[32m[0906 21-39-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18483, current rewards: 106.16411, mean: 0.09152
[32m[0906 21-40-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18475, current rewards: 110.94545, mean: 0.09169
[32m[0906 21-40-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18461, current rewards: 116.12024, mean: 0.09216
[32m[0906 21-40-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18445, current rewards: 121.29388, mean: 0.09259
[32m[0906 21-40-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18427, current rewards: 126.45922, mean: 0.09298
[32m[0906 21-40-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18413, current rewards: 110.61505, mean: 0.07845
[32m[0906 21-40-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18396, current rewards: 116.11578, mean: 0.07953
[32m[0906 21-41-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18365, current rewards: 121.61256, mean: 0.08054
[32m[0906 21-41-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18335, current rewards: 127.11022, mean: 0.08148
[32m[0906 21-41-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18306, current rewards: 111.66144, mean: 0.06935
[32m[0906 21-41-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18280, current rewards: 117.06981, mean: 0.07052
[32m[0906 21-41-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18254, current rewards: 122.35589, mean: 0.07155
[32m[0906 21-41-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18230, current rewards: 127.64012, mean: 0.07252
[32m[0906 21-41-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18208, current rewards: 132.92872, mean: 0.07344
[32m[0906 21-42-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18187, current rewards: 138.21535, mean: 0.07431
[32m[0906 21-42-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18181, current rewards: 143.50021, mean: 0.07513
[32m[0906 21-42-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18179, current rewards: 148.78625, mean: 0.07591
[32m[0906 21-42-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18178, current rewards: 153.41233, mean: 0.07632
[32m[0906 21-42-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18173, current rewards: 137.51986, mean: 0.06676
[32m[0906 21-42-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18168, current rewards: 143.00619, mean: 0.06778
[32m[0906 21-42-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18175, current rewards: 148.48655, mean: 0.06874
[32m[0906 21-43-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18182, current rewards: 153.96591, mean: 0.06967
[32m[0906 21-43-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18188, current rewards: 159.45013, mean: 0.07055
[32m[0906 21-43-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18193, current rewards: 164.93339, mean: 0.07140
[32m[0906 21-43-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18191, current rewards: 170.41392, mean: 0.07221
[32m[0906 21-43-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18186, current rewards: 177.18901, mean: 0.07352
[32m[0906 21-43-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18174, current rewards: 182.73678, mean: 0.07428
[32m[0906 21-43-59 @Agent.py:117][0m Average action selection time: 0.1816
[32m[0906 21-43-59 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-43-59 @MBExp.py:227][0m Rewards obtained: [187.125105898003], Lows: [30], Highs: [11], Total time: 25658.656414
[32m[0906 21-45-55 @MBExp.py:144][0m ####################################################################
[32m[0906 21-45-55 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 21-45-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18640, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-46-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18574, current rewards: -109.00000, mean: -1.81667
[32m[0906 21-46-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18592, current rewards: -209.00000, mean: -1.90000
[32m[0906 21-46-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18569, current rewards: -309.00000, mean: -1.93125
[32m[0906 21-46-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18553, current rewards: -409.00000, mean: -1.94762
[32m[0906 21-46-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18564, current rewards: -509.00000, mean: -1.95769
[32m[0906 21-46-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18553, current rewards: -609.00000, mean: -1.96452
[32m[0906 21-47-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18541, current rewards: -709.00000, mean: -1.96944
[32m[0906 21-47-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18530, current rewards: -809.00000, mean: -1.97317
[32m[0906 21-47-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18518, current rewards: -909.00000, mean: -1.97609
[32m[0906 21-47-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18509, current rewards: -1009.00000, mean: -1.97843
[32m[0906 21-47-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18505, current rewards: -1109.00000, mean: -1.98036
[32m[0906 21-47-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18492, current rewards: -1206.94141, mean: -1.97859
[32m[0906 21-47-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18488, current rewards: -1201.89855, mean: -1.82106
[32m[0906 21-48-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18485, current rewards: -1196.62026, mean: -1.68538
[32m[0906 21-48-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18477, current rewards: -1190.32015, mean: -1.56621
[32m[0906 21-48-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18477, current rewards: -1185.06923, mean: -1.46305
[32m[0906 21-48-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18469, current rewards: -1179.82395, mean: -1.37189
[32m[0906 21-48-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18475, current rewards: -1174.57493, mean: -1.29074
[32m[0906 21-48-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18470, current rewards: -1169.33420, mean: -1.21806
[32m[0906 21-49-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18481, current rewards: -1194.80742, mean: -1.18298
[32m[0906 21-49-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18479, current rewards: -1188.87697, mean: -1.12158
[32m[0906 21-49-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18477, current rewards: -1183.84796, mean: -1.06653
[32m[0906 21-49-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18473, current rewards: -1178.82458, mean: -1.01623
[32m[0906 21-49-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18456, current rewards: -1173.79937, mean: -0.97008
[32m[0906 21-49-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18437, current rewards: -1168.77811, mean: -0.92760
[32m[0906 21-49-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18419, current rewards: -1163.75753, mean: -0.88836
[32m[0906 21-50-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18404, current rewards: -1158.73075, mean: -0.85201
[32m[0906 21-50-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18391, current rewards: -1153.70600, mean: -0.81823
[32m[0906 21-50-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18371, current rewards: -1148.69140, mean: -0.78677
[32m[0906 21-50-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18339, current rewards: -1143.66588, mean: -0.75739
[32m[0906 21-50-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18310, current rewards: -1159.05052, mean: -0.74298
[32m[0906 21-50-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18288, current rewards: -1152.86324, mean: -0.71606
[32m[0906 21-50-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18263, current rewards: -1146.68556, mean: -0.69077
[32m[0906 21-51-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18239, current rewards: -1140.50787, mean: -0.66696
[32m[0906 21-51-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18213, current rewards: -1134.33019, mean: -0.64451
[32m[0906 21-51-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18192, current rewards: -1128.15251, mean: -0.62329
[32m[0906 21-51-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18176, current rewards: -1130.96326, mean: -0.60804
[32m[0906 21-51-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18172, current rewards: -1180.96326, mean: -0.61831
[32m[0906 21-51-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18169, current rewards: -1230.96326, mean: -0.62804
[32m[0906 21-52-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18165, current rewards: -1280.96326, mean: -0.63730
[32m[0906 21-52-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18161, current rewards: -1330.96326, mean: -0.64610
[32m[0906 21-52-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18158, current rewards: -1380.96326, mean: -0.65448
[32m[0906 21-52-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18165, current rewards: -1430.96326, mean: -0.66248
[32m[0906 21-52-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18174, current rewards: -1480.96326, mean: -0.67012
[32m[0906 21-52-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18181, current rewards: -1530.96326, mean: -0.67742
[32m[0906 21-52-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18190, current rewards: -1580.96326, mean: -0.68440
[32m[0906 21-53-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18190, current rewards: -1630.96326, mean: -0.69109
[32m[0906 21-53-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18187, current rewards: -1680.96326, mean: -0.69750
[32m[0906 21-53-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18175, current rewards: -1730.96326, mean: -0.70364
[32m[0906 21-53-29 @Agent.py:117][0m Average action selection time: 0.1816
[32m[0906 21-53-29 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-53-29 @MBExp.py:227][0m Rewards obtained: [-1770.9632602195488], Lows: [619], Highs: [669], Total time: 26113.448148
[32m[0906 21-55-27 @MBExp.py:144][0m ####################################################################
[32m[0906 21-55-27 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 21-55-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18466, current rewards: 0.64334, mean: 0.06433
[32m[0906 21-55-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18508, current rewards: 7.29450, mean: 0.12157
[32m[0906 21-55-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18507, current rewards: 12.56215, mean: 0.11420
[32m[0906 21-55-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18495, current rewards: 17.82909, mean: 0.11143
[32m[0906 21-56-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18476, current rewards: 23.09647, mean: 0.10998
[32m[0906 21-56-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18474, current rewards: 28.36358, mean: 0.10909
[32m[0906 21-56-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18464, current rewards: 33.63064, mean: 0.10849
[32m[0906 21-56-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18461, current rewards: 31.16572, mean: 0.08657
[32m[0906 21-56-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18461, current rewards: -18.83428, mean: -0.04594
[32m[0906 21-56-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18456, current rewards: -68.83428, mean: -0.14964
[32m[0906 21-57-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18468, current rewards: -118.83428, mean: -0.23301
[32m[0906 21-57-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18479, current rewards: -168.83428, mean: -0.30149
[32m[0906 21-57-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18476, current rewards: -218.83428, mean: -0.35874
[32m[0906 21-57-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18472, current rewards: -268.83428, mean: -0.40732
[32m[0906 21-57-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18466, current rewards: -318.83428, mean: -0.44906
[32m[0906 21-57-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18461, current rewards: -368.83428, mean: -0.48531
[32m[0906 21-57-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18455, current rewards: -418.83428, mean: -0.51708
[32m[0906 21-58-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18454, current rewards: -468.83428, mean: -0.54516
[32m[0906 21-58-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18456, current rewards: -518.83428, mean: -0.57015
[32m[0906 21-58-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18453, current rewards: -568.83428, mean: -0.59254
[32m[0906 21-58-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18454, current rewards: -618.83428, mean: -0.61271
[32m[0906 21-58-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18454, current rewards: -668.83428, mean: -0.63098
[32m[0906 21-58-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18451, current rewards: -718.83428, mean: -0.64760
[32m[0906 21-59-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18444, current rewards: -768.83428, mean: -0.66279
[32m[0906 21-59-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18433, current rewards: -818.83428, mean: -0.67672
[32m[0906 21-59-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18416, current rewards: -868.83428, mean: -0.68955
[32m[0906 21-59-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18400, current rewards: -918.83428, mean: -0.70140
[32m[0906 21-59-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18384, current rewards: -968.83428, mean: -0.71238
[32m[0906 21-59-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18372, current rewards: -1018.83428, mean: -0.72258
[32m[0906 21-59-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18350, current rewards: -1068.83428, mean: -0.73208
[32m[0906 22-00-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18321, current rewards: -1118.83428, mean: -0.74095
[32m[0906 22-00-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18294, current rewards: -1168.83428, mean: -0.74925
[32m[0906 22-00-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18268, current rewards: -1218.83428, mean: -0.75704
[32m[0906 22-00-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18243, current rewards: -1268.83428, mean: -0.76436
[32m[0906 22-00-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18220, current rewards: -1318.83428, mean: -0.77125
[32m[0906 22-00-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18197, current rewards: -1368.83428, mean: -0.77775
[32m[0906 22-00-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18177, current rewards: -1418.83428, mean: -0.78389
[32m[0906 22-01-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18164, current rewards: -1468.83428, mean: -0.78970
[32m[0906 22-01-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18163, current rewards: -1518.83428, mean: -0.79520
[32m[0906 22-01-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18161, current rewards: -1568.83428, mean: -0.80043
[32m[0906 22-01-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18158, current rewards: -1618.83428, mean: -0.80539
[32m[0906 22-01-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18155, current rewards: -1668.83428, mean: -0.81011
[32m[0906 22-01-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18151, current rewards: -1718.83428, mean: -0.81461
[32m[0906 22-02-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18159, current rewards: -1768.83428, mean: -0.81890
[32m[0906 22-02-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18167, current rewards: -1818.83428, mean: -0.82300
[32m[0906 22-02-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18174, current rewards: -1868.83428, mean: -0.82692
[32m[0906 22-02-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18182, current rewards: -1918.83428, mean: -0.83066
[32m[0906 22-02-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18183, current rewards: -1968.83428, mean: -0.83425
[32m[0906 22-02-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18179, current rewards: -2018.83428, mean: -0.83769
[32m[0906 22-02-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18168, current rewards: -2068.83428, mean: -0.84099
[32m[0906 22-03-01 @Agent.py:117][0m Average action selection time: 0.1816
[32m[0906 22-03-01 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-03-02 @MBExp.py:227][0m Rewards obtained: [-2108.83427636051], Lows: [0], Highs: [2148], Total time: 26568.121231
[32m[0906 22-05-01 @MBExp.py:144][0m ####################################################################
[32m[0906 22-05-01 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 22-05-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18413, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-05-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18498, current rewards: -12.24027, mean: -0.20400
[32m[0906 22-05-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18501, current rewards: -6.50535, mean: -0.05914
[32m[0906 22-05-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18506, current rewards: -0.76292, mean: -0.00477
[32m[0906 22-05-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18527, current rewards: 4.97178, mean: 0.02368
[32m[0906 22-05-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18506, current rewards: 10.71144, mean: 0.04120
[32m[0906 22-05-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18492, current rewards: 16.44967, mean: 0.05306
[32m[0906 22-06-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18491, current rewards: 21.14464, mean: 0.05874
[32m[0906 22-06-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18477, current rewards: 26.92055, mean: 0.06566
[32m[0906 22-06-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18469, current rewards: 32.29079, mean: 0.07020
[32m[0906 22-06-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18468, current rewards: 37.65795, mean: 0.07384
[32m[0906 22-06-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18469, current rewards: 43.02694, mean: 0.07683
[32m[0906 22-06-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18464, current rewards: 48.39001, mean: 0.07933
[32m[0906 22-07-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18465, current rewards: 53.75486, mean: 0.08145
[32m[0906 22-07-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18463, current rewards: 59.10988, mean: 0.08325
[32m[0906 22-07-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18465, current rewards: 64.47869, mean: 0.08484
[32m[0906 22-07-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18465, current rewards: 69.84193, mean: 0.08622
[32m[0906 22-07-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18466, current rewards: 75.19986, mean: 0.08744
[32m[0906 22-07-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18464, current rewards: 80.56166, mean: 0.08853
[32m[0906 22-07-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18463, current rewards: 85.92565, mean: 0.08951
[32m[0906 22-08-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18466, current rewards: 91.29747, mean: 0.09039
[32m[0906 22-08-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18464, current rewards: 96.66555, mean: 0.09119
[32m[0906 22-08-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18463, current rewards: 102.02326, mean: 0.09191
[32m[0906 22-08-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18446, current rewards: 107.39072, mean: 0.09258
[32m[0906 22-08-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18429, current rewards: 112.81304, mean: 0.09323
[32m[0906 22-08-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18412, current rewards: 118.16925, mean: 0.09379
[32m[0906 22-09-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18398, current rewards: 115.11170, mean: 0.08787
[32m[0906 22-09-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18385, current rewards: 98.66623, mean: 0.07255
[32m[0906 22-09-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18370, current rewards: 92.87440, mean: 0.06587
[32m[0906 22-09-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18344, current rewards: 87.09006, mean: 0.05965
[32m[0906 22-09-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18317, current rewards: 83.37426, mean: 0.05521
[32m[0906 22-09-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18290, current rewards: 77.59310, mean: 0.04974
[32m[0906 22-09-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18263, current rewards: 77.71211, mean: 0.04827
[32m[0906 22-10-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18237, current rewards: 84.81549, mean: 0.05109
[32m[0906 22-10-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18213, current rewards: 91.91204, mean: 0.05375
[32m[0906 22-10-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18191, current rewards: 99.00859, mean: 0.05625
[32m[0906 22-10-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18171, current rewards: 106.10514, mean: 0.05862
[32m[0906 22-10-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18161, current rewards: 113.20169, mean: 0.06086
[32m[0906 22-10-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18158, current rewards: 120.29825, mean: 0.06298
[32m[0906 22-10-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18155, current rewards: 88.56914, mean: 0.04519
[32m[0906 22-11-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18151, current rewards: 38.56914, mean: 0.01919
[32m[0906 22-11-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18148, current rewards: -11.43086, mean: -0.00555
[32m[0906 22-11-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18146, current rewards: -61.43086, mean: -0.02911
[32m[0906 22-11-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18153, current rewards: -111.43086, mean: -0.05159
[32m[0906 22-11-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18162, current rewards: -161.43086, mean: -0.07305
[32m[0906 22-11-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18172, current rewards: -211.43086, mean: -0.09355
[32m[0906 22-12-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18178, current rewards: -261.43086, mean: -0.11317
[32m[0906 22-12-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18182, current rewards: -311.43086, mean: -0.13196
[32m[0906 22-12-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18178, current rewards: -361.43086, mean: -0.14997
[32m[0906 22-12-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18167, current rewards: -411.43086, mean: -0.16725
[32m[0906 22-12-36 @Agent.py:117][0m Average action selection time: 0.1816
[32m[0906 22-12-36 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-12-36 @MBExp.py:227][0m Rewards obtained: [-451.4308584315381], Lows: [45], Highs: [584], Total time: 27022.756211
[32m[0906 22-14-37 @MBExp.py:144][0m ####################################################################
[32m[0906 22-14-37 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 22-14-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18593, current rewards: 0.64737, mean: 0.06474
[32m[0906 22-14-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18546, current rewards: 8.25050, mean: 0.13751
[32m[0906 22-14-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18543, current rewards: 16.82411, mean: 0.15295
[32m[0906 22-15-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18505, current rewards: 25.40279, mean: 0.15877
[32m[0906 22-15-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18504, current rewards: 33.97382, mean: 0.16178
[32m[0906 22-15-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18509, current rewards: 28.63110, mean: 0.11012
[32m[0906 22-15-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18511, current rewards: 34.80355, mean: 0.11227
[32m[0906 22-15-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18502, current rewards: 40.51599, mean: 0.11254
[32m[0906 22-15-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18498, current rewards: 46.74577, mean: 0.11401
[32m[0906 22-16-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18509, current rewards: 52.90387, mean: 0.11501
[32m[0906 22-16-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18501, current rewards: 59.07129, mean: 0.11583
[32m[0906 22-16-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18501, current rewards: 65.22809, mean: 0.11648
[32m[0906 22-16-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18489, current rewards: 71.39347, mean: 0.11704
[32m[0906 22-16-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18485, current rewards: 77.55361, mean: 0.11751
[32m[0906 22-16-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18477, current rewards: 83.72307, mean: 0.11792
[32m[0906 22-16-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18473, current rewards: 90.31868, mean: 0.11884
[32m[0906 22-17-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18469, current rewards: 96.77866, mean: 0.11948
[32m[0906 22-17-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18464, current rewards: 81.13177, mean: 0.09434
[32m[0906 22-17-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18460, current rewards: 86.58465, mean: 0.09515
[32m[0906 22-17-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18462, current rewards: 92.03758, mean: 0.09587
[32m[0906 22-17-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18460, current rewards: 97.49353, mean: 0.09653
[32m[0906 22-17-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18458, current rewards: 102.95144, mean: 0.09712
[32m[0906 22-18-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18461, current rewards: 108.40420, mean: 0.09766
[32m[0906 22-18-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18439, current rewards: 92.81961, mean: 0.08002
[32m[0906 22-18-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18418, current rewards: 99.37266, mean: 0.08213
[32m[0906 22-18-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18400, current rewards: 105.24686, mean: 0.08353
[32m[0906 22-18-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18382, current rewards: 111.12703, mean: 0.08483
[32m[0906 22-18-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18367, current rewards: 117.00461, mean: 0.08603
[32m[0906 22-18-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18353, current rewards: 122.87970, mean: 0.08715
[32m[0906 22-19-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18322, current rewards: 110.94020, mean: 0.07599
[32m[0906 22-19-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18292, current rewards: 95.42672, mean: 0.06320
[32m[0906 22-19-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18263, current rewards: 84.04170, mean: 0.05387
[32m[0906 22-19-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18237, current rewards: 69.07905, mean: 0.04291
[32m[0906 22-19-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18214, current rewards: 57.88546, mean: 0.03487
[32m[0906 22-19-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18189, current rewards: 42.41276, mean: 0.02480
[32m[0906 22-19-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18167, current rewards: 20.17826, mean: 0.01146
[32m[0906 22-20-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18149, current rewards: 26.02262, mean: 0.01438
[32m[0906 22-20-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18143, current rewards: 31.86015, mean: 0.01713
[32m[0906 22-20-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18137, current rewards: 37.69373, mean: 0.01973
[32m[0906 22-20-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18133, current rewards: 43.52432, mean: 0.02221
[32m[0906 22-20-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18128, current rewards: 49.14957, mean: 0.02445
[32m[0906 22-20-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18125, current rewards: 54.97552, mean: 0.02669
[32m[0906 22-21-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18121, current rewards: 60.80701, mean: 0.02882
[32m[0906 22-21-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18126, current rewards: 66.64273, mean: 0.03085
[32m[0906 22-21-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18135, current rewards: 72.47542, mean: 0.03279
[32m[0906 22-21-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18142, current rewards: 76.18934, mean: 0.03371
[32m[0906 22-21-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18150, current rewards: 63.21639, mean: 0.02737
[32m[0906 22-21-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18153, current rewards: 69.12982, mean: 0.02929
[32m[0906 22-21-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18150, current rewards: 75.13765, mean: 0.03118
[32m[0906 22-22-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18137, current rewards: 81.05439, mean: 0.03295
[32m[0906 22-22-11 @Agent.py:117][0m Average action selection time: 0.1813
[32m[0906 22-22-11 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-22-11 @MBExp.py:227][0m Rewards obtained: [85.78641587155408], Lows: [94], Highs: [21], Total time: 27476.654829
[32m[0906 22-24-14 @MBExp.py:144][0m ####################################################################
[32m[0906 22-24-14 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 22-24-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18739, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-24-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18664, current rewards: -6.07154, mean: -0.10119
[32m[0906 22-24-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18569, current rewards: -0.72459, mean: -0.00659
[32m[0906 22-24-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18526, current rewards: 4.61793, mean: 0.02886
[32m[0906 22-24-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18516, current rewards: 9.96153, mean: 0.04744
[32m[0906 22-25-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18499, current rewards: 15.30761, mean: 0.05888
[32m[0906 22-25-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18486, current rewards: 22.08490, mean: 0.07124
[32m[0906 22-25-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18470, current rewards: 27.44495, mean: 0.07624
[32m[0906 22-25-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18466, current rewards: 32.81062, mean: 0.08003
[32m[0906 22-25-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18453, current rewards: 38.17873, mean: 0.08300
[32m[0906 22-25-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18447, current rewards: 43.54392, mean: 0.08538
[32m[0906 22-25-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18536, current rewards: 35.83306, mean: 0.06399
[32m[0906 22-26-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18613, current rewards: 36.94607, mean: 0.06057
[32m[0906 22-26-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18636, current rewards: 32.67781, mean: 0.04951
[32m[0906 22-26-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18698, current rewards: 25.33890, mean: 0.03569
[32m[0906 22-26-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18688, current rewards: 28.78055, mean: 0.03787
[32m[0906 22-26-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18668, current rewards: 34.33800, mean: 0.04239
[32m[0906 22-26-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18651, current rewards: 39.88854, mean: 0.04638
[32m[0906 22-27-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18636, current rewards: 45.44462, mean: 0.04994
[32m[0906 22-27-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18623, current rewards: 58.03444, mean: 0.06045
[32m[0906 22-27-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18613, current rewards: 63.04177, mean: 0.06242
[32m[0906 22-27-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18601, current rewards: 68.04604, mean: 0.06419
[32m[0906 22-27-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18577, current rewards: 72.97901, mean: 0.06575
[32m[0906 22-27-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18551, current rewards: 77.99124, mean: 0.06723
[32m[0906 22-27-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18528, current rewards: 83.00373, mean: 0.06860
[32m[0906 22-28-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18507, current rewards: 88.01554, mean: 0.06985
[32m[0906 22-28-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18486, current rewards: 95.97700, mean: 0.07326
[32m[0906 22-28-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18468, current rewards: 105.96124, mean: 0.07791
[32m[0906 22-28-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18447, current rewards: 111.49208, mean: 0.07907
[32m[0906 22-28-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18412, current rewards: 117.02099, mean: 0.08015
[32m[0906 22-28-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18379, current rewards: 122.60093, mean: 0.08119
[32m[0906 22-29-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18348, current rewards: 128.15875, mean: 0.08215
[32m[0906 22-29-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18320, current rewards: 133.69757, mean: 0.08304
[32m[0906 22-29-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18292, current rewards: 139.24037, mean: 0.08388
[32m[0906 22-29-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18266, current rewards: 144.78022, mean: 0.08467
[32m[0906 22-29-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18242, current rewards: 129.85799, mean: 0.07378
[32m[0906 22-29-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18223, current rewards: 135.32735, mean: 0.07477
[32m[0906 22-29-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18217, current rewards: 140.80172, mean: 0.07570
[32m[0906 22-30-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18210, current rewards: 146.16465, mean: 0.07653
[32m[0906 22-30-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18205, current rewards: 151.04469, mean: 0.07706
[32m[0906 22-30-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18199, current rewards: 137.43893, mean: 0.06838
[32m[0906 22-30-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18194, current rewards: 138.54656, mean: 0.06726
[32m[0906 22-30-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18192, current rewards: 143.94576, mean: 0.06822
[32m[0906 22-30-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18198, current rewards: 149.34214, mean: 0.06914
[32m[0906 22-30-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18205, current rewards: 154.74313, mean: 0.07002
[32m[0906 22-31-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18211, current rewards: 160.13642, mean: 0.07086
[32m[0906 22-31-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18216, current rewards: 165.53135, mean: 0.07166
[32m[0906 22-31-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18222, current rewards: 148.86527, mean: 0.06308
[32m[0906 22-31-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18217, current rewards: 153.86510, mean: 0.06384
[32m[0906 22-31-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18203, current rewards: 158.85983, mean: 0.06458
[32m[0906 22-31-50 @Agent.py:117][0m Average action selection time: 0.1819
[32m[0906 22-31-50 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-31-50 @MBExp.py:227][0m Rewards obtained: [162.8554420477617], Lows: [39], Highs: [49], Total time: 27932.158378
[32m[0906 22-33-55 @MBExp.py:144][0m ####################################################################
[32m[0906 22-33-55 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 22-33-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18447, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-34-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18425, current rewards: -6.53437, mean: -0.10891
[32m[0906 22-34-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18429, current rewards: -3.19668, mean: -0.02906
[32m[0906 22-34-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18417, current rewards: 0.14666, mean: 0.00092
[32m[0906 22-34-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18404, current rewards: 3.49079, mean: 0.01662
[32m[0906 22-34-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18418, current rewards: 6.74802, mean: 0.02595
[32m[0906 22-34-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18434, current rewards: 10.16913, mean: 0.03280
[32m[0906 22-35-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18436, current rewards: 13.54655, mean: 0.03763
[32m[0906 22-35-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18437, current rewards: 16.91994, mean: 0.04127
[32m[0906 22-35-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18425, current rewards: -36.93218, mean: -0.08029
[32m[0906 22-35-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18412, current rewards: -136.93218, mean: -0.26849
[32m[0906 22-35-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18401, current rewards: -236.93218, mean: -0.42309
[32m[0906 22-35-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18400, current rewards: -336.93218, mean: -0.55235
[32m[0906 22-35-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18394, current rewards: -436.93218, mean: -0.66202
[32m[0906 22-36-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18398, current rewards: -536.93218, mean: -0.75624
[32m[0906 22-36-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18401, current rewards: -636.93218, mean: -0.83807
[32m[0906 22-36-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18404, current rewards: -736.93218, mean: -0.90979
[32m[0906 22-36-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18398, current rewards: -836.93218, mean: -0.97318
[32m[0906 22-36-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18398, current rewards: -936.93218, mean: -1.02960
[32m[0906 22-36-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18403, current rewards: -1036.93218, mean: -1.08014
[32m[0906 22-37-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18407, current rewards: -1136.93218, mean: -1.12568
[32m[0906 22-37-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18404, current rewards: -1236.93218, mean: -1.16692
[32m[0906 22-37-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18384, current rewards: -1336.93218, mean: -1.20444
[32m[0906 22-37-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18365, current rewards: -1436.93218, mean: -1.23873
[32m[0906 22-37-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18348, current rewards: -1536.93218, mean: -1.27019
[32m[0906 22-37-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18334, current rewards: -1636.93218, mean: -1.29915
[32m[0906 22-37-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18320, current rewards: -1736.93218, mean: -1.32590
[32m[0906 22-38-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18305, current rewards: -1836.93218, mean: -1.35069
[32m[0906 22-38-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18294, current rewards: -1936.93218, mean: -1.37371
[32m[0906 22-38-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18263, current rewards: -2036.93218, mean: -1.39516
[32m[0906 22-38-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18235, current rewards: -2136.93218, mean: -1.41519
[32m[0906 22-38-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18207, current rewards: -2236.93218, mean: -1.43393
[32m[0906 22-38-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18183, current rewards: -2336.93218, mean: -1.45151
[32m[0906 22-38-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18160, current rewards: -2436.93218, mean: -1.46803
[32m[0906 22-39-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18140, current rewards: -2536.93218, mean: -1.48359
[32m[0906 22-39-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18120, current rewards: -2636.93218, mean: -1.49826
[32m[0906 22-39-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18106, current rewards: -2736.93218, mean: -1.51212
[32m[0906 22-39-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18103, current rewards: -2836.93218, mean: -1.52523
[32m[0906 22-39-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18098, current rewards: -2936.93218, mean: -1.53766
[32m[0906 22-39-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18095, current rewards: -3036.93218, mean: -1.54946
[32m[0906 22-39-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18091, current rewards: -3136.93218, mean: -1.56066
[32m[0906 22-40-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18087, current rewards: -3236.93218, mean: -1.57133
[32m[0906 22-40-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18083, current rewards: -3336.93218, mean: -1.58148
[32m[0906 22-40-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18084, current rewards: -3436.93218, mean: -1.59117
[32m[0906 22-40-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18093, current rewards: -3536.93218, mean: -1.60042
[32m[0906 22-40-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18100, current rewards: -3636.93218, mean: -1.60926
[32m[0906 22-40-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18106, current rewards: -3736.93218, mean: -1.61772
[32m[0906 22-41-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18112, current rewards: -3836.93218, mean: -1.62582
[32m[0906 22-41-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18113, current rewards: -3936.93218, mean: -1.63358
[32m[0906 22-41-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18101, current rewards: -4036.93218, mean: -1.64103
[32m[0906 22-41-28 @Agent.py:117][0m Average action selection time: 0.1809
[32m[0906 22-41-28 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-41-28 @MBExp.py:227][0m Rewards obtained: [-4116.932179250867], Lows: [2062], Highs: [21], Total time: 28385.164252
[32m[0906 22-43-35 @MBExp.py:144][0m ####################################################################
[32m[0906 22-43-35 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 22-43-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19710, current rewards: 0.49971, mean: 0.04997
[32m[0906 22-43-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18748, current rewards: -15.21315, mean: -0.25355
[32m[0906 22-43-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18625, current rewards: -9.18974, mean: -0.08354
[32m[0906 22-44-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18567, current rewards: -3.18124, mean: -0.01988
[32m[0906 22-44-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18539, current rewards: 2.74690, mean: 0.01308
[32m[0906 22-44-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18513, current rewards: 8.75497, mean: 0.03367
[32m[0906 22-44-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18505, current rewards: 3.45262, mean: 0.01114
[32m[0906 22-44-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18492, current rewards: 9.07930, mean: 0.02522
[32m[0906 22-44-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18485, current rewards: 14.96103, mean: 0.03649
[32m[0906 22-45-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18467, current rewards: 20.84948, mean: 0.04532
[32m[0906 22-45-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18463, current rewards: 26.73452, mean: 0.05242
[32m[0906 22-45-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18466, current rewards: 32.61978, mean: 0.05825
[32m[0906 22-45-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18461, current rewards: 39.50559, mean: 0.06476
[32m[0906 22-45-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18457, current rewards: 46.59898, mean: 0.07060
[32m[0906 22-45-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18449, current rewards: 52.46890, mean: 0.07390
[32m[0906 22-45-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18445, current rewards: 58.33894, mean: 0.07676
[32m[0906 22-46-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18443, current rewards: 64.19869, mean: 0.07926
[32m[0906 22-46-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18438, current rewards: 70.06832, mean: 0.08147
[32m[0906 22-46-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18437, current rewards: 64.46243, mean: 0.07084
[32m[0906 22-46-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18432, current rewards: 70.28844, mean: 0.07322
[32m[0906 22-46-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18433, current rewards: 76.11855, mean: 0.07536
[32m[0906 22-46-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18424, current rewards: 80.93087, mean: 0.07635
[32m[0906 22-47-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18403, current rewards: 86.56433, mean: 0.07799
[32m[0906 22-47-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18385, current rewards: 92.18768, mean: 0.07947
[32m[0906 22-47-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18370, current rewards: 97.81384, mean: 0.08084
[32m[0906 22-47-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18361, current rewards: 90.61148, mean: 0.07191
[32m[0906 22-47-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18344, current rewards: 95.88526, mean: 0.07319
[32m[0906 22-47-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18332, current rewards: 101.15585, mean: 0.07438
[32m[0906 22-47-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18315, current rewards: 106.42369, mean: 0.07548
[32m[0906 22-48-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18286, current rewards: 113.70883, mean: 0.07788
[32m[0906 22-48-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18257, current rewards: 119.68005, mean: 0.07926
[32m[0906 22-48-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18228, current rewards: 124.86286, mean: 0.08004
[32m[0906 22-48-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18204, current rewards: 130.05183, mean: 0.08078
[32m[0906 22-48-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18180, current rewards: 135.23245, mean: 0.08147
[32m[0906 22-48-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18157, current rewards: 140.40877, mean: 0.08211
[32m[0906 22-48-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18136, current rewards: 145.58750, mean: 0.08272
[32m[0906 22-49-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18124, current rewards: 129.64980, mean: 0.07163
[32m[0906 22-49-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18120, current rewards: 134.59180, mean: 0.07236
[32m[0906 22-49-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18115, current rewards: 139.24808, mean: 0.07290
[32m[0906 22-49-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18116, current rewards: 144.13904, mean: 0.07354
[32m[0906 22-49-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18113, current rewards: 149.02902, mean: 0.07414
[32m[0906 22-49-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18109, current rewards: 153.91870, mean: 0.07472
[32m[0906 22-49-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18107, current rewards: 158.80171, mean: 0.07526
[32m[0906 22-50-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18108, current rewards: 163.68801, mean: 0.07578
[32m[0906 22-50-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18117, current rewards: 155.90761, mean: 0.07055
[32m[0906 22-50-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18125, current rewards: 156.52095, mean: 0.06926
[32m[0906 22-50-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18134, current rewards: 162.26488, mean: 0.07024
[32m[0906 22-50-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18138, current rewards: 168.85661, mean: 0.07155
[32m[0906 22-50-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18137, current rewards: 175.45108, mean: 0.07280
[32m[0906 22-51-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18127, current rewards: 182.04147, mean: 0.07400
[32m[0906 22-51-09 @Agent.py:117][0m Average action selection time: 0.1812
[32m[0906 22-51-09 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-51-09 @MBExp.py:227][0m Rewards obtained: [187.3176232495442], Lows: [25], Highs: [40], Total time: 28838.804549
[32m[0906 22-53-17 @MBExp.py:144][0m ####################################################################
[32m[0906 22-53-17 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 22-53-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18397, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-53-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18488, current rewards: -13.24227, mean: -0.22070
[32m[0906 22-53-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18536, current rewards: -15.00942, mean: -0.13645
[32m[0906 22-53-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18519, current rewards: -18.88172, mean: -0.11801
[32m[0906 22-53-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18502, current rewards: -19.40125, mean: -0.09239
[32m[0906 22-54-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18503, current rewards: -19.95744, mean: -0.07676
[32m[0906 22-54-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18493, current rewards: -23.07970, mean: -0.07445
[32m[0906 22-54-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18491, current rewards: -24.01108, mean: -0.06670
[32m[0906 22-54-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18492, current rewards: -57.17251, mean: -0.13945
[32m[0906 22-54-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18488, current rewards: -56.58004, mean: -0.12300
[32m[0906 22-54-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18479, current rewards: -50.93299, mean: -0.09987
[32m[0906 22-55-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18485, current rewards: -45.29209, mean: -0.08088
[32m[0906 22-55-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18480, current rewards: -39.64789, mean: -0.06500
[32m[0906 22-55-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18480, current rewards: -34.05931, mean: -0.05161
[32m[0906 22-55-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18479, current rewards: -28.42067, mean: -0.04003
[32m[0906 22-55-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18479, current rewards: -22.77878, mean: -0.02997
[32m[0906 22-55-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18484, current rewards: -17.14103, mean: -0.02116
[32m[0906 22-55-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18482, current rewards: -31.83425, mean: -0.03702
[32m[0906 22-56-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18480, current rewards: -24.17917, mean: -0.02657
[32m[0906 22-56-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18477, current rewards: -16.52409, mean: -0.01721
[32m[0906 22-56-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18476, current rewards: -8.86901, mean: -0.00878
[32m[0906 22-56-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18451, current rewards: -32.92015, mean: -0.03106
[32m[0906 22-56-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18429, current rewards: -82.92015, mean: -0.07470
[32m[0906 22-56-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18408, current rewards: -132.92015, mean: -0.11459
[32m[0906 22-57-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18389, current rewards: -182.92015, mean: -0.15117
[32m[0906 22-57-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18375, current rewards: -232.92015, mean: -0.18486
[32m[0906 22-57-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18360, current rewards: -282.92015, mean: -0.21597
[32m[0906 22-57-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18347, current rewards: -332.92015, mean: -0.24479
[32m[0906 22-57-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18325, current rewards: -382.92015, mean: -0.27157
[32m[0906 22-57-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18294, current rewards: -432.92015, mean: -0.29652
[32m[0906 22-57-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18268, current rewards: -482.92015, mean: -0.31981
[32m[0906 22-58-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18242, current rewards: -532.92015, mean: -0.34162
[32m[0906 22-58-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18217, current rewards: -582.92015, mean: -0.36206
[32m[0906 22-58-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18191, current rewards: -632.92015, mean: -0.38128
[32m[0906 22-58-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18167, current rewards: -682.92015, mean: -0.39937
[32m[0906 22-58-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18146, current rewards: -732.92015, mean: -0.41643
[32m[0906 22-58-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18138, current rewards: -782.92015, mean: -0.43255
[32m[0906 22-58-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18133, current rewards: -832.92015, mean: -0.44781
[32m[0906 22-59-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18131, current rewards: -882.92015, mean: -0.46226
[32m[0906 22-59-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18127, current rewards: -932.92015, mean: -0.47598
[32m[0906 22-59-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18123, current rewards: -982.92015, mean: -0.48901
[32m[0906 22-59-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18121, current rewards: -1032.92015, mean: -0.50142
[32m[0906 22-59-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18118, current rewards: -1082.92015, mean: -0.51323
[32m[0906 22-59-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18118, current rewards: -1132.92015, mean: -0.52450
[32m[0906 22-59-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18130, current rewards: -1182.92015, mean: -0.53526
[32m[0906 23-00-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18139, current rewards: -1232.92015, mean: -0.54554
[32m[0906 23-00-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18145, current rewards: -1282.92015, mean: -0.55538
[32m[0906 23-00-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18150, current rewards: -1332.92015, mean: -0.56480
[32m[0906 23-00-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18147, current rewards: -1382.92015, mean: -0.57383
[32m[0906 23-00-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18138, current rewards: -1432.92015, mean: -0.58249
[32m[0906 23-00-51 @Agent.py:117][0m Average action selection time: 0.1813
[32m[0906 23-00-51 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-00-51 @MBExp.py:227][0m Rewards obtained: [-1472.920146975236], Lows: [67], Highs: [1477], Total time: 29292.731133
[32m[0906 23-03-02 @MBExp.py:144][0m ####################################################################
[32m[0906 23-03-02 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 23-03-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18464, current rewards: 0.51142, mean: 0.05114
[32m[0906 23-03-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18512, current rewards: 6.14101, mean: 0.10235
[32m[0906 23-03-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18505, current rewards: 11.87230, mean: 0.10793
[32m[0906 23-03-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18488, current rewards: 17.59103, mean: 0.10994
[32m[0906 23-03-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18497, current rewards: 24.46739, mean: 0.11651
[32m[0906 23-03-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18485, current rewards: 29.95201, mean: 0.11520
[32m[0906 23-04-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18484, current rewards: 35.42350, mean: 0.11427
[32m[0906 23-04-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18484, current rewards: 40.89878, mean: 0.11361
[32m[0906 23-04-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18479, current rewards: 46.37274, mean: 0.11310
[32m[0906 23-04-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18475, current rewards: 41.12401, mean: 0.08940
[32m[0906 23-04-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18470, current rewards: 49.12444, mean: 0.09632
[32m[0906 23-04-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18459, current rewards: 57.02179, mean: 0.10182
[32m[0906 23-04-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18450, current rewards: 64.59019, mean: 0.10589
[32m[0906 23-05-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18450, current rewards: 72.54674, mean: 0.10992
[32m[0906 23-05-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18446, current rewards: 80.51685, mean: 0.11340
[32m[0906 23-05-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18441, current rewards: 88.48131, mean: 0.11642
[32m[0906 23-05-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18444, current rewards: 96.45475, mean: 0.11908
[32m[0906 23-05-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18446, current rewards: 104.41757, mean: 0.12142
[32m[0906 23-05-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18450, current rewards: 93.39840, mean: 0.10264
[32m[0906 23-06-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18447, current rewards: 98.81506, mean: 0.10293
[32m[0906 23-06-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18434, current rewards: 104.01605, mean: 0.10299
[32m[0906 23-06-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18417, current rewards: 109.00502, mean: 0.10283
[32m[0906 23-06-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18399, current rewards: 114.00523, mean: 0.10271
[32m[0906 23-06-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18377, current rewards: 119.00229, mean: 0.10259
[32m[0906 23-06-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18361, current rewards: 115.11838, mean: 0.09514
[32m[0906 23-06-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18345, current rewards: 100.91273, mean: 0.08009
[32m[0906 23-07-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18331, current rewards: 50.65896, mean: 0.03867
[32m[0906 23-07-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18316, current rewards: 30.05947, mean: 0.02210
[32m[0906 23-07-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18291, current rewards: 25.79442, mean: 0.01829
[32m[0906 23-07-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18261, current rewards: 30.84882, mean: 0.02113
[32m[0906 23-07-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18233, current rewards: 35.81524, mean: 0.02372
[32m[0906 23-07-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18205, current rewards: 40.78621, mean: 0.02615
[32m[0906 23-07-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18178, current rewards: 45.75298, mean: 0.02842
[32m[0906 23-08-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18154, current rewards: 50.72185, mean: 0.03056
[32m[0906 23-08-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18132, current rewards: 55.69101, mean: 0.03257
[32m[0906 23-08-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18113, current rewards: 39.85365, mean: 0.02264
[32m[0906 23-08-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18110, current rewards: 45.85665, mean: 0.02534
[32m[0906 23-08-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18106, current rewards: 51.21636, mean: 0.02754
[32m[0906 23-08-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18101, current rewards: 56.92442, mean: 0.02980
[32m[0906 23-08-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18097, current rewards: 62.63091, mean: 0.03195
[32m[0906 23-09-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18094, current rewards: 68.33319, mean: 0.03400
[32m[0906 23-09-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18091, current rewards: 74.03549, mean: 0.03594
[32m[0906 23-09-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18085, current rewards: 79.73806, mean: 0.03779
[32m[0906 23-09-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18087, current rewards: 85.44262, mean: 0.03956
[32m[0906 23-09-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18095, current rewards: 91.14483, mean: 0.04124
[32m[0906 23-09-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18104, current rewards: 96.05843, mean: 0.04250
[32m[0906 23-10-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18111, current rewards: 101.52115, mean: 0.04395
[32m[0906 23-10-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18118, current rewards: 70.57981, mean: 0.02991
[32m[0906 23-10-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18118, current rewards: 35.57659, mean: 0.01476
[32m[0906 23-10-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18111, current rewards: 40.59822, mean: 0.01650
[32m[0906 23-10-35 @Agent.py:117][0m Average action selection time: 0.1810
[32m[0906 23-10-35 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-10-36 @MBExp.py:227][0m Rewards obtained: [44.52524525467475], Lows: [104], Highs: [47], Total time: 29745.948449
[32m[0906 23-12-48 @MBExp.py:144][0m ####################################################################
[32m[0906 23-12-48 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 23-12-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19095, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-13-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19691, current rewards: -62.56004, mean: -1.04267
[32m[0906 23-13-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19286, current rewards: -118.90660, mean: -1.08097
[32m[0906 23-13-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19320, current rewards: -162.52222, mean: -1.01576
[32m[0906 23-13-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19118, current rewards: -157.23501, mean: -0.74874
[32m[0906 23-13-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18969, current rewards: -151.82281, mean: -0.58393
[32m[0906 23-13-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18866, current rewards: -146.41780, mean: -0.47232
[32m[0906 23-13-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18802, current rewards: -141.00272, mean: -0.39167
[32m[0906 23-14-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18757, current rewards: -135.59173, mean: -0.33071
[32m[0906 23-14-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18727, current rewards: -130.17899, mean: -0.28300
[32m[0906 23-14-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18770, current rewards: -156.53253, mean: -0.30693
[32m[0906 23-14-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18746, current rewards: -150.43341, mean: -0.26863
[32m[0906 23-14-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18725, current rewards: -144.51578, mean: -0.23691
[32m[0906 23-14-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18701, current rewards: -138.50609, mean: -0.20986
[32m[0906 23-15-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18682, current rewards: -132.47783, mean: -0.18659
[32m[0906 23-15-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18661, current rewards: -126.48898, mean: -0.16643
[32m[0906 23-15-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18642, current rewards: -120.45990, mean: -0.14872
[32m[0906 23-15-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18624, current rewards: -114.42923, mean: -0.13306
[32m[0906 23-15-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18608, current rewards: -108.44688, mean: -0.11917
[32m[0906 23-15-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18592, current rewards: -102.42318, mean: -0.10669
[32m[0906 23-15-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18559, current rewards: -93.03624, mean: -0.09212
[32m[0906 23-16-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18531, current rewards: -98.40665, mean: -0.09284
[32m[0906 23-16-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18516, current rewards: -137.69139, mean: -0.12405
[32m[0906 23-16-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18513, current rewards: -183.96831, mean: -0.15859
[32m[0906 23-16-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18491, current rewards: -177.82481, mean: -0.14696
[32m[0906 23-16-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18473, current rewards: -172.57507, mean: -0.13696
[32m[0906 23-16-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18457, current rewards: -167.32619, mean: -0.12773
[32m[0906 23-16-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18439, current rewards: -162.08303, mean: -0.11918
[32m[0906 23-17-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18410, current rewards: -156.97671, mean: -0.11133
[32m[0906 23-17-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18376, current rewards: -151.74017, mean: -0.10393
[32m[0906 23-17-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18345, current rewards: -185.54866, mean: -0.12288
[32m[0906 23-17-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18314, current rewards: -250.51340, mean: -0.16059
[32m[0906 23-17-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18285, current rewards: -299.75946, mean: -0.18619
[32m[0906 23-17-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18260, current rewards: -326.16068, mean: -0.19648
[32m[0906 23-18-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18236, current rewards: -335.50757, mean: -0.19620
[32m[0906 23-18-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18220, current rewards: -349.20739, mean: -0.19841
[32m[0906 23-18-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18221, current rewards: -376.08021, mean: -0.20778
[32m[0906 23-18-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18274, current rewards: -436.66348, mean: -0.23477
[32m[0906 23-18-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18270, current rewards: -492.23345, mean: -0.25771
[32m[0906 23-18-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18293, current rewards: -565.50426, mean: -0.28852
[32m[0906 23-18-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18323, current rewards: -621.26970, mean: -0.30909
[32m[0906 23-19-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18354, current rewards: -679.04019, mean: -0.32963
[32m[0906 23-19-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18369, current rewards: -732.78702, mean: -0.34729
[32m[0906 23-19-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18393, current rewards: -770.61479, mean: -0.35677
[32m[0906 23-19-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18411, current rewards: -818.47265, mean: -0.37035
[32m[0906 23-19-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18422, current rewards: -834.59095, mean: -0.36929
[32m[0906 23-19-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18423, current rewards: -829.46258, mean: -0.35907
[32m[0906 23-20-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18418, current rewards: -855.69555, mean: -0.36258
[32m[0906 23-20-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18406, current rewards: -858.14619, mean: -0.35608
[32m[0906 23-20-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18386, current rewards: -862.79155, mean: -0.35073
[32m[0906 23-20-28 @Agent.py:117][0m Average action selection time: 0.1837
[32m[0906 23-20-28 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-20-28 @MBExp.py:227][0m Rewards obtained: [-866.5138912215066], Lows: [565], Highs: [29], Total time: 30206.01255
[32m[0906 23-22-43 @MBExp.py:144][0m ####################################################################
[32m[0906 23-22-43 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 23-22-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18479, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-22-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18600, current rewards: -53.16536, mean: -0.88609
[32m[0906 23-23-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18606, current rewards: -47.27795, mean: -0.42980
[32m[0906 23-23-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18544, current rewards: -41.08683, mean: -0.25679
[32m[0906 23-23-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18525, current rewards: -35.09710, mean: -0.16713
[32m[0906 23-23-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18504, current rewards: -29.10724, mean: -0.11195
[32m[0906 23-23-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18497, current rewards: -44.34804, mean: -0.14306
[32m[0906 23-23-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18489, current rewards: -38.40153, mean: -0.10667
[32m[0906 23-23-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18477, current rewards: -32.40977, mean: -0.07905
[32m[0906 23-24-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18479, current rewards: -26.41512, mean: -0.05742
[32m[0906 23-24-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18473, current rewards: -20.42248, mean: -0.04004
[32m[0906 23-24-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18475, current rewards: -14.20389, mean: -0.02536
[32m[0906 23-24-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18473, current rewards: -8.09411, mean: -0.01327
[32m[0906 23-24-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18465, current rewards: -6.49977, mean: -0.00985
[32m[0906 23-24-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18464, current rewards: -9.71656, mean: -0.01369
[32m[0906 23-25-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18468, current rewards: -4.55183, mean: -0.00599
[32m[0906 23-25-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18469, current rewards: 0.62935, mean: 0.00078
[32m[0906 23-25-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18464, current rewards: 5.85985, mean: 0.00681
[32m[0906 23-25-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18456, current rewards: 10.97739, mean: 0.01206
[32m[0906 23-25-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18430, current rewards: 11.76777, mean: 0.01226
[32m[0906 23-25-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18405, current rewards: 2.23693, mean: 0.00221
[32m[0906 23-25-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18385, current rewards: 9.66522, mean: 0.00912
[32m[0906 23-26-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18367, current rewards: 17.06693, mean: 0.01538
[32m[0906 23-26-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18350, current rewards: 24.46162, mean: 0.02109
[32m[0906 23-26-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18336, current rewards: 31.85688, mean: 0.02633
[32m[0906 23-26-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18321, current rewards: 39.25037, mean: 0.03115
[32m[0906 23-26-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18308, current rewards: 46.64541, mean: 0.03561
[32m[0906 23-26-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18288, current rewards: 53.75492, mean: 0.03953
[32m[0906 23-27-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18257, current rewards: 60.53400, mean: 0.04293
[32m[0906 23-27-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18230, current rewards: 67.48544, mean: 0.04622
[32m[0906 23-27-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18205, current rewards: 74.43967, mean: 0.04930
[32m[0906 23-27-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18180, current rewards: 81.38732, mean: 0.05217
[32m[0906 23-27-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18154, current rewards: -0.05150, mean: -0.00003
[32m[0906 23-27-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18132, current rewards: -100.05150, mean: -0.06027
[32m[0906 23-27-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18115, current rewards: -200.05150, mean: -0.11699
[32m[0906 23-28-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18112, current rewards: -300.05150, mean: -0.17048
[32m[0906 23-28-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18107, current rewards: -400.05150, mean: -0.22102
[32m[0906 23-28-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18103, current rewards: -500.05150, mean: -0.26884
[32m[0906 23-28-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18099, current rewards: -600.05150, mean: -0.31416
[32m[0906 23-28-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18096, current rewards: -700.05150, mean: -0.35717
[32m[0906 23-28-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18094, current rewards: -800.05150, mean: -0.39804
[32m[0906 23-28-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18092, current rewards: -900.05150, mean: -0.43692
[32m[0906 23-29-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18089, current rewards: -1000.05150, mean: -0.47396
[32m[0906 23-29-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18096, current rewards: -1100.05150, mean: -0.50928
[32m[0906 23-29-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18108, current rewards: -1200.05150, mean: -0.54301
[32m[0906 23-29-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18115, current rewards: -1300.05150, mean: -0.57524
[32m[0906 23-29-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18123, current rewards: -1400.05150, mean: -0.60608
[32m[0906 23-29-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18126, current rewards: -1500.05150, mean: -0.63562
[32m[0906 23-30-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18121, current rewards: -1600.05150, mean: -0.66392
[32m[0906 23-30-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18108, current rewards: -1700.05150, mean: -0.69108
[32m[0906 23-30-16 @Agent.py:117][0m Average action selection time: 0.1810
[32m[0906 23-30-16 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-30-17 @MBExp.py:227][0m Rewards obtained: [-1780.0514953275797], Lows: [970], Highs: [32], Total time: 30659.194803
[32m[0906 23-32-33 @MBExp.py:144][0m ####################################################################
[32m[0906 23-32-33 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 23-32-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19707, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-32-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18766, current rewards: -107.94814, mean: -1.79914
[32m[0906 23-32-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18580, current rewards: -207.94814, mean: -1.89044
[32m[0906 23-33-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18598, current rewards: -307.94814, mean: -1.92468
[32m[0906 23-33-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18562, current rewards: -407.94814, mean: -1.94261
[32m[0906 23-33-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18536, current rewards: -507.94814, mean: -1.95365
[32m[0906 23-33-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18540, current rewards: -607.94814, mean: -1.96112
[32m[0906 23-33-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18512, current rewards: -707.94814, mean: -1.96652
[32m[0906 23-33-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18495, current rewards: -807.94814, mean: -1.97061
[32m[0906 23-33-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18479, current rewards: -907.94814, mean: -1.97380
[32m[0906 23-34-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18471, current rewards: -1007.94814, mean: -1.97637
[32m[0906 23-34-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18465, current rewards: -1107.94814, mean: -1.97848
[32m[0906 23-34-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18456, current rewards: -1207.94814, mean: -1.98024
[32m[0906 23-34-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18443, current rewards: -1307.94814, mean: -1.98174
[32m[0906 23-34-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18437, current rewards: -1407.94814, mean: -1.98303
[32m[0906 23-34-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18432, current rewards: -1507.94814, mean: -1.98414
[32m[0906 23-35-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18427, current rewards: -1607.94814, mean: -1.98512
[32m[0906 23-35-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18430, current rewards: -1707.94814, mean: -1.98599
[32m[0906 23-35-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18413, current rewards: -1807.94814, mean: -1.98676
[32m[0906 23-35-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18390, current rewards: -1907.94814, mean: -1.98745
[32m[0906 23-35-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18375, current rewards: -2007.94814, mean: -1.98807
[32m[0906 23-35-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18356, current rewards: -2107.94814, mean: -1.98863
[32m[0906 23-35-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18340, current rewards: -2207.94814, mean: -1.98914
[32m[0906 23-36-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18324, current rewards: -2307.94814, mean: -1.98961
[32m[0906 23-36-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18307, current rewards: -2407.94814, mean: -1.99004
[32m[0906 23-36-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18292, current rewards: -2507.94814, mean: -1.99044
[32m[0906 23-36-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18276, current rewards: -2607.94814, mean: -1.99080
[32m[0906 23-36-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18250, current rewards: -2707.94814, mean: -1.99114
[32m[0906 23-36-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18218, current rewards: -2807.94814, mean: -1.99145
[32m[0906 23-36-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18189, current rewards: -2907.94814, mean: -1.99175
[32m[0906 23-37-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18163, current rewards: -3007.94814, mean: -1.99202
[32m[0906 23-37-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18141, current rewards: -3107.94814, mean: -1.99227
[32m[0906 23-37-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18118, current rewards: -3207.94814, mean: -1.99251
[32m[0906 23-37-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18096, current rewards: -3307.94814, mean: -1.99274
[32m[0906 23-37-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18089, current rewards: -3407.94814, mean: -1.99295
[32m[0906 23-37-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18087, current rewards: -3507.94814, mean: -1.99315
[32m[0906 23-38-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18085, current rewards: -3607.94814, mean: -1.99334
[32m[0906 23-38-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18081, current rewards: -3707.94814, mean: -1.99352
[32m[0906 23-38-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18078, current rewards: -3807.94814, mean: -1.99369
[32m[0906 23-38-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18073, current rewards: -3907.94814, mean: -1.99385
[32m[0906 23-38-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18070, current rewards: -4007.94814, mean: -1.99400
[32m[0906 23-38-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18066, current rewards: -4107.94814, mean: -1.99415
[32m[0906 23-38-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18063, current rewards: -4207.94814, mean: -1.99429
[32m[0906 23-39-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18069, current rewards: -4307.94814, mean: -1.99442
[32m[0906 23-39-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18078, current rewards: -4407.94814, mean: -1.99455
[32m[0906 23-39-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18087, current rewards: -4507.94814, mean: -1.99467
[32m[0906 23-39-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18094, current rewards: -4607.94814, mean: -1.99478
[32m[0906 23-39-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18097, current rewards: -4707.94814, mean: -1.99489
[32m[0906 23-39-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18097, current rewards: -4807.94814, mean: -1.99500
[32m[0906 23-39-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18083, current rewards: -4907.94814, mean: -1.99510
[32m[0906 23-40-06 @Agent.py:117][0m Average action selection time: 0.1807
[32m[0906 23-40-06 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-40-06 @MBExp.py:227][0m Rewards obtained: [-4987.948137142015], Lows: [2489], Highs: [10], Total time: 31111.806536
[32m[0906 23-42-25 @MBExp.py:144][0m ####################################################################
[32m[0906 23-42-25 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 23-42-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19629, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-42-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19248, current rewards: -73.03146, mean: -1.21719
[32m[0906 23-42-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19139, current rewards: -117.30721, mean: -1.06643
[32m[0906 23-42-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19207, current rewards: -179.35868, mean: -1.12099
[32m[0906 23-43-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19069, current rewards: -229.52628, mean: -1.09298
[32m[0906 23-43-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18979, current rewards: -277.14744, mean: -1.06595
[32m[0906 23-43-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18884, current rewards: -269.80503, mean: -0.87034
[32m[0906 23-43-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18831, current rewards: -262.82352, mean: -0.73007
[32m[0906 23-43-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18778, current rewards: -255.84643, mean: -0.62402
[32m[0906 23-43-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18742, current rewards: -248.87638, mean: -0.54104
[32m[0906 23-44-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18731, current rewards: -241.90582, mean: -0.47433
[32m[0906 23-44-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18703, current rewards: -234.93659, mean: -0.41953
[32m[0906 23-44-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18679, current rewards: -227.95702, mean: -0.37370
[32m[0906 23-44-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18757, current rewards: -254.62152, mean: -0.38579
[32m[0906 23-44-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18767, current rewards: -324.53936, mean: -0.45710
[32m[0906 23-44-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18812, current rewards: -370.72965, mean: -0.48780
[32m[0906 23-44-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18839, current rewards: -419.31114, mean: -0.51767
[32m[0906 23-45-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18825, current rewards: -463.19048, mean: -0.53859
[32m[0906 23-45-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18802, current rewards: -495.01621, mean: -0.54397
[32m[0906 23-45-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18759, current rewards: -490.18443, mean: -0.51061
[32m[0906 23-45-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18721, current rewards: -485.20722, mean: -0.48040
[32m[0906 23-45-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18684, current rewards: -480.23278, mean: -0.45305
[32m[0906 23-45-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18652, current rewards: -475.25895, mean: -0.42816
[32m[0906 23-46-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18625, current rewards: -481.34153, mean: -0.41495
[32m[0906 23-46-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18603, current rewards: -475.34944, mean: -0.39285
[32m[0906 23-46-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18577, current rewards: -469.46657, mean: -0.37259
[32m[0906 23-46-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18548, current rewards: -463.29388, mean: -0.35366
[32m[0906 23-46-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18505, current rewards: -457.16317, mean: -0.33615
[32m[0906 23-46-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18465, current rewards: -451.20822, mean: -0.32001
[32m[0906 23-46-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18427, current rewards: -445.25489, mean: -0.30497
[32m[0906 23-47-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18394, current rewards: -439.30577, mean: -0.29093
[32m[0906 23-47-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18361, current rewards: -433.34631, mean: -0.27779
[32m[0906 23-47-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18332, current rewards: -427.40060, mean: -0.26547
[32m[0906 23-47-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18305, current rewards: -421.44645, mean: -0.25388
[32m[0906 23-47-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18297, current rewards: -426.68625, mean: -0.24952
[32m[0906 23-47-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18288, current rewards: -420.47369, mean: -0.23891
[32m[0906 23-47-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18279, current rewards: -414.19595, mean: -0.22884
[32m[0906 23-48-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18272, current rewards: -407.90713, mean: -0.21930
[32m[0906 23-48-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18267, current rewards: -401.63701, mean: -0.21028
[32m[0906 23-48-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18259, current rewards: -395.35915, mean: -0.20171
[32m[0906 23-48-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18251, current rewards: -389.08436, mean: -0.19357
[32m[0906 23-48-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18244, current rewards: -382.80487, mean: -0.18583
[32m[0906 23-48-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18237, current rewards: -377.71693, mean: -0.17901
[32m[0906 23-48-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18243, current rewards: -372.89455, mean: -0.17264
[32m[0906 23-49-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18247, current rewards: -367.98396, mean: -0.16651
[32m[0906 23-49-18 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18250, current rewards: -363.07128, mean: -0.16065
[32m[0906 23-49-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18253, current rewards: -358.15414, mean: -0.15505
[32m[0906 23-49-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18259, current rewards: -365.82988, mean: -0.15501
[32m[0906 23-49-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18267, current rewards: -440.01484, mean: -0.18258
[32m[0906 23-49-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18256, current rewards: -497.18046, mean: -0.20211
[32m[0906 23-50-02 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0906 23-50-02 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-50-02 @MBExp.py:227][0m Rewards obtained: [-532.6327647959821], Lows: [368], Highs: [57], Total time: 31569.172292
[32m[0906 23-52-23 @MBExp.py:144][0m ####################################################################
[32m[0906 23-52-23 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 23-52-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18469, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-52-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18504, current rewards: -36.64842, mean: -0.61081
[32m[0906 23-52-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18455, current rewards: -37.69050, mean: -0.34264
[32m[0906 23-52-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18463, current rewards: -40.83866, mean: -0.25524
[32m[0906 23-53-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18450, current rewards: -51.38438, mean: -0.24469
[32m[0906 23-53-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18433, current rewards: -45.42114, mean: -0.17470
[32m[0906 23-53-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18430, current rewards: -39.55116, mean: -0.12758
[32m[0906 23-53-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18435, current rewards: -33.68947, mean: -0.09358
[32m[0906 23-53-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18429, current rewards: -27.80537, mean: -0.06782
[32m[0906 23-53-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18434, current rewards: -22.63231, mean: -0.04920
[32m[0906 23-53-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18436, current rewards: -17.39960, mean: -0.03412
[32m[0906 23-54-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18438, current rewards: -11.49605, mean: -0.02053
[32m[0906 23-54-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18428, current rewards: -5.60834, mean: -0.00919
[32m[0906 23-54-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18448, current rewards: -25.42075, mean: -0.03852
[32m[0906 23-54-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18448, current rewards: -20.16812, mean: -0.02841
[32m[0906 23-54-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18448, current rewards: -14.97852, mean: -0.01971
[32m[0906 23-54-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18442, current rewards: -9.78583, mean: -0.01208
[32m[0906 23-55-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18411, current rewards: -4.58866, mean: -0.00534
[32m[0906 23-55-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18387, current rewards: 0.23573, mean: 0.00026
[32m[0906 23-55-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18363, current rewards: 5.39263, mean: 0.00562
[32m[0906 23-55-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18343, current rewards: 10.55215, mean: 0.01045
[32m[0906 23-55-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18323, current rewards: 15.71045, mean: 0.01482
[32m[0906 23-55-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18305, current rewards: 20.87077, mean: 0.01880
[32m[0906 23-55-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18289, current rewards: 26.03232, mean: 0.02244
[32m[0906 23-56-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18277, current rewards: 31.18951, mean: 0.02578
[32m[0906 23-56-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18263, current rewards: 36.35001, mean: 0.02885
[32m[0906 23-56-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18250, current rewards: 43.89174, mean: 0.03351
[32m[0906 23-56-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18220, current rewards: 49.15747, mean: 0.03615
[32m[0906 23-56-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18192, current rewards: 50.00083, mean: 0.03546
[32m[0906 23-56-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18165, current rewards: 48.36150, mean: 0.03312
[32m[0906 23-56-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18139, current rewards: 53.58181, mean: 0.03548
[32m[0906 23-57-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18115, current rewards: 58.80058, mean: 0.03769
[32m[0906 23-57-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18092, current rewards: 64.02010, mean: 0.03976
[32m[0906 23-57-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18079, current rewards: 69.24155, mean: 0.04171
[32m[0906 23-57-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18076, current rewards: 74.67692, mean: 0.04367
[32m[0906 23-57-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18072, current rewards: 79.90706, mean: 0.04540
[32m[0906 23-57-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18067, current rewards: 85.14173, mean: 0.04704
[32m[0906 23-57-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18065, current rewards: 90.37693, mean: 0.04859
[32m[0906 23-58-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18063, current rewards: 94.97004, mean: 0.04972
[32m[0906 23-58-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18060, current rewards: 99.68951, mean: 0.05086
[32m[0906 23-58-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18055, current rewards: 104.39315, mean: 0.05194
[32m[0906 23-58-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18054, current rewards: 109.09844, mean: 0.05296
[32m[0906 23-58-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18054, current rewards: 114.12782, mean: 0.05409
[32m[0906 23-58-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18058, current rewards: 118.89135, mean: 0.05504
[32m[0906 23-59-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18068, current rewards: 123.65216, mean: 0.05595
[32m[0906 23-59-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18077, current rewards: 128.41393, mean: 0.05682
[32m[0906 23-59-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18086, current rewards: 133.17377, mean: 0.05765
[32m[0906 23-59-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18088, current rewards: 137.93566, mean: 0.05845
[32m[0906 23-59-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18080, current rewards: 140.33680, mean: 0.05823
[32m[0906 23-59-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18066, current rewards: 144.53841, mean: 0.05876
[32m[0906 23-59-55 @Agent.py:117][0m Average action selection time: 0.1806
[32m[0906 23-59-55 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-59-55 @MBExp.py:227][0m Rewards obtained: [147.88090780838567], Lows: [44], Highs: [30], Total time: 32021.331094999998
[32m[0907 00-02-18 @MBExp.py:144][0m ####################################################################
[32m[0907 00-02-18 @MBExp.py:145][0m Starting training iteration 71.
[32m[0907 00-02-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18483, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-02-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18489, current rewards: -21.75967, mean: -0.36266
[32m[0907 00-02-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18480, current rewards: -15.67118, mean: -0.14247
[32m[0907 00-02-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18507, current rewards: -9.58249, mean: -0.05989
[32m[0907 00-02-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18513, current rewards: -3.49847, mean: -0.01666
[32m[0907 00-03-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18500, current rewards: 2.58649, mean: 0.00995
[32m[0907 00-03-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18489, current rewards: 8.67089, mean: 0.02797
[32m[0907 00-03-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18471, current rewards: 14.75544, mean: 0.04099
[32m[0907 00-03-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18463, current rewards: 20.84054, mean: 0.05083
[32m[0907 00-03-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18462, current rewards: 26.73047, mean: 0.05811
[32m[0907 00-03-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18454, current rewards: 33.04619, mean: 0.06480
[32m[0907 00-04-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18451, current rewards: 39.24467, mean: 0.07008
[32m[0907 00-04-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18443, current rewards: 45.43711, mean: 0.07449
[32m[0907 00-04-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18437, current rewards: 51.65610, mean: 0.07827
[32m[0907 00-04-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18434, current rewards: 0.08209, mean: 0.00012
[32m[0907 00-04-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18431, current rewards: -37.42595, mean: -0.04924
[32m[0907 00-04-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18416, current rewards: -77.60540, mean: -0.09581
[32m[0907 00-04-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18399, current rewards: -117.59277, mean: -0.13674
[32m[0907 00-05-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18385, current rewards: -154.56288, mean: -0.16985
[32m[0907 00-05-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18365, current rewards: -184.83833, mean: -0.19254
[32m[0907 00-05-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18345, current rewards: -217.63549, mean: -0.21548
[32m[0907 00-05-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18328, current rewards: -271.63833, mean: -0.25626
[32m[0907 00-05-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18313, current rewards: -272.62163, mean: -0.24561
[32m[0907 00-05-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18300, current rewards: -267.55224, mean: -0.23065
[32m[0907 00-06-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18287, current rewards: -262.47790, mean: -0.21692
[32m[0907 00-06-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18276, current rewards: -257.40858, mean: -0.20429
[32m[0907 00-06-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18263, current rewards: -252.49166, mean: -0.19274
[32m[0907 00-06-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18234, current rewards: -245.07032, mean: -0.18020
[32m[0907 00-06-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18204, current rewards: -260.43717, mean: -0.18471
[32m[0907 00-06-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18179, current rewards: -255.35106, mean: -0.17490
[32m[0907 00-06-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18153, current rewards: -250.28086, mean: -0.16575
[32m[0907 00-07-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18132, current rewards: -245.20721, mean: -0.15718
[32m[0907 00-07-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18112, current rewards: -240.13515, mean: -0.14915
[32m[0907 00-07-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18100, current rewards: -235.05445, mean: -0.14160
[32m[0907 00-07-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18096, current rewards: -229.98174, mean: -0.13449
[32m[0907 00-07-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18092, current rewards: -224.87570, mean: -0.12777
[32m[0907 00-07-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18090, current rewards: -219.79315, mean: -0.12143
[32m[0907 00-07-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18087, current rewards: -214.71980, mean: -0.11544
[32m[0907 00-08-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18084, current rewards: -209.64372, mean: -0.10976
[32m[0907 00-08-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18081, current rewards: -204.56112, mean: -0.10437
[32m[0907 00-08-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18078, current rewards: -199.48622, mean: -0.09925
[32m[0907 00-08-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18074, current rewards: -194.40685, mean: -0.09437
[32m[0907 00-08-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18074, current rewards: -184.32298, mean: -0.08736
[32m[0907 00-08-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18074, current rewards: -199.91206, mean: -0.09255
[32m[0907 00-08-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18083, current rewards: -193.47529, mean: -0.08755
[32m[0907 00-09-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18095, current rewards: -187.55742, mean: -0.08299
[32m[0907 00-09-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18105, current rewards: -181.63954, mean: -0.07863
[32m[0907 00-09-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18105, current rewards: -175.72167, mean: -0.07446
[32m[0907 00-09-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18097, current rewards: -169.80379, mean: -0.07046
[32m[0907 00-09-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18084, current rewards: -163.88592, mean: -0.06662
[32m[0907 00-09-51 @Agent.py:117][0m Average action selection time: 0.1807
[32m[0907 00-09-51 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-09-51 @MBExp.py:227][0m Rewards obtained: [-159.15161893921712], Lows: [215], Highs: [21], Total time: 32473.945354
[32m[0907 00-12-15 @MBExp.py:144][0m ####################################################################
[32m[0907 00-12-15 @MBExp.py:145][0m Starting training iteration 72.
[32m[0907 00-12-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18358, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-12-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18501, current rewards: -2.04687, mean: -0.03411
[32m[0907 00-12-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18490, current rewards: 4.01480, mean: 0.03650
[32m[0907 00-12-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18481, current rewards: 10.07689, mean: 0.06298
[32m[0907 00-12-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18507, current rewards: 16.13846, mean: 0.07685
[32m[0907 00-13-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18486, current rewards: 22.20208, mean: 0.08539
[32m[0907 00-13-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18462, current rewards: 28.26015, mean: 0.09116
[32m[0907 00-13-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18470, current rewards: 34.32373, mean: 0.09534
[32m[0907 00-13-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18464, current rewards: 9.20586, mean: 0.02245
[32m[0907 00-13-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18450, current rewards: 17.36740, mean: 0.03776
[32m[0907 00-13-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18439, current rewards: 22.51446, mean: 0.04415
[32m[0907 00-13-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18431, current rewards: 28.01599, mean: 0.05003
[32m[0907 00-14-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18428, current rewards: 33.51803, mean: 0.05495
[32m[0907 00-14-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18418, current rewards: 39.02735, mean: 0.05913
[32m[0907 00-14-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18414, current rewards: 44.53214, mean: 0.06272
[32m[0907 00-14-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18410, current rewards: 50.03041, mean: 0.06583
[32m[0907 00-14-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18409, current rewards: 55.54361, mean: 0.06857
[32m[0907 00-14-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18386, current rewards: 61.04491, mean: 0.07098
[32m[0907 00-15-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18362, current rewards: 66.38561, mean: 0.07295
[32m[0907 00-15-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18339, current rewards: 71.89618, mean: 0.07489
[32m[0907 00-15-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18323, current rewards: 77.40545, mean: 0.07664
[32m[0907 00-15-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18313, current rewards: 82.91128, mean: 0.07822
[32m[0907 00-15-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18298, current rewards: 88.41538, mean: 0.07965
[32m[0907 00-15-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18282, current rewards: 87.59175, mean: 0.07551
[32m[0907 00-15-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18267, current rewards: -12.40825, mean: -0.01025
[32m[0907 00-16-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18255, current rewards: -112.40825, mean: -0.08921
[32m[0907 00-16-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18241, current rewards: -102.43894, mean: -0.07820
[32m[0907 00-16-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18208, current rewards: -96.70121, mean: -0.07110
[32m[0907 00-16-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18178, current rewards: -91.09201, mean: -0.06460
[32m[0907 00-16-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18151, current rewards: -85.48554, mean: -0.05855
[32m[0907 00-16-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18126, current rewards: -79.87762, mean: -0.05290
[32m[0907 00-16-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18102, current rewards: -74.26953, mean: -0.04761
[32m[0907 00-17-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18081, current rewards: -68.66205, mean: -0.04265
[32m[0907 00-17-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18060, current rewards: -63.05944, mean: -0.03799
[32m[0907 00-17-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18057, current rewards: -68.87839, mean: -0.04028
[32m[0907 00-17-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18059, current rewards: -63.28963, mean: -0.03596
[32m[0907 00-17-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18056, current rewards: -56.48332, mean: -0.03121
[32m[0907 00-17-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18053, current rewards: -49.69143, mean: -0.02672
[32m[0907 00-18-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18051, current rewards: -42.90012, mean: -0.02246
[32m[0907 00-18-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18049, current rewards: -36.11605, mean: -0.01843
[32m[0907 00-18-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18046, current rewards: -29.32992, mean: -0.01459
[32m[0907 00-18-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18045, current rewards: -22.53300, mean: -0.01094
[32m[0907 00-18-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18041, current rewards: -15.74726, mean: -0.00746
[32m[0907 00-18-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18040, current rewards: -8.67901, mean: -0.00402
[32m[0907 00-18-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18049, current rewards: -1.90765, mean: -0.00086
[32m[0907 00-19-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18056, current rewards: 3.29878, mean: 0.00146
[32m[0907 00-19-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18068, current rewards: 0.23390, mean: 0.00010
[32m[0907 00-19-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18074, current rewards: -2.42837, mean: -0.00103
[32m[0907 00-19-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18073, current rewards: -11.26919, mean: -0.00468
[32m[0907 00-19-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18065, current rewards: -18.88773, mean: -0.00768
[32m[0907 00-19-47 @Agent.py:117][0m Average action selection time: 0.1805
[32m[0907 00-19-47 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-19-47 @MBExp.py:227][0m Rewards obtained: [-31.264450947721702], Lows: [149], Highs: [30], Total time: 32926.080593
[32m[0907 00-22-13 @MBExp.py:144][0m ####################################################################
[32m[0907 00-22-13 @MBExp.py:145][0m Starting training iteration 73.
[32m[0907 00-22-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18416, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-22-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18467, current rewards: -30.53751, mean: -0.50896
[32m[0907 00-22-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18466, current rewards: -25.32818, mean: -0.23026
[32m[0907 00-22-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18450, current rewards: -20.14494, mean: -0.12591
[32m[0907 00-22-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18436, current rewards: -14.95896, mean: -0.07123
[32m[0907 00-23-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18410, current rewards: -9.77258, mean: -0.03759
[32m[0907 00-23-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18400, current rewards: -4.58548, mean: -0.01479
[32m[0907 00-23-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18397, current rewards: 0.59916, mean: 0.00166
[32m[0907 00-23-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18388, current rewards: 5.78379, mean: 0.01411
[32m[0907 00-23-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18380, current rewards: 10.55107, mean: 0.02294
[32m[0907 00-23-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18387, current rewards: 4.72450, mean: 0.00926
[32m[0907 00-23-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18401, current rewards: 9.72452, mean: 0.01737
[32m[0907 00-24-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18391, current rewards: 14.72991, mean: 0.02415
[32m[0907 00-24-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18389, current rewards: 19.73743, mean: 0.02991
[32m[0907 00-24-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18390, current rewards: 24.74801, mean: 0.03486
[32m[0907 00-24-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18389, current rewards: 29.75812, mean: 0.03916
[32m[0907 00-24-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18387, current rewards: 34.76659, mean: 0.04292
[32m[0907 00-24-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18369, current rewards: 39.80451, mean: 0.04628
[32m[0907 00-25-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18346, current rewards: 44.84497, mean: 0.04928
[32m[0907 00-25-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18328, current rewards: 30.63187, mean: 0.03191
[32m[0907 00-25-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18306, current rewards: 25.75590, mean: 0.02550
[32m[0907 00-25-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18298, current rewards: 23.85120, mean: 0.02250
[32m[0907 00-25-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18279, current rewards: 24.66944, mean: 0.02222
[32m[0907 00-25-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18264, current rewards: 4.20877, mean: 0.00363
[32m[0907 00-25-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18255, current rewards: 0.71279, mean: 0.00059
[32m[0907 00-26-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18245, current rewards: -3.49930, mean: -0.00278
[32m[0907 00-26-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18233, current rewards: -10.82377, mean: -0.00826
[32m[0907 00-26-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18221, current rewards: -4.46315, mean: -0.00328
[32m[0907 00-26-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18198, current rewards: -0.67044, mean: -0.00048
[32m[0907 00-26-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18171, current rewards: 3.67158, mean: 0.00251
[32m[0907 00-26-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18144, current rewards: 7.99764, mean: 0.00530
[32m[0907 00-26-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18122, current rewards: 6.68856, mean: 0.00429
[32m[0907 00-27-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18099, current rewards: 11.88230, mean: 0.00738
[32m[0907 00-27-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18079, current rewards: 17.08057, mean: 0.01029
[32m[0907 00-27-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18064, current rewards: 21.52410, mean: 0.01259
[32m[0907 00-27-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18062, current rewards: 26.41632, mean: 0.01501
[32m[0907 00-27-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18060, current rewards: 31.50287, mean: 0.01740
[32m[0907 00-27-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18057, current rewards: 36.59877, mean: 0.01968
[32m[0907 00-27-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18057, current rewards: 41.68405, mean: 0.02182
[32m[0907 00-28-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18058, current rewards: 46.76697, mean: 0.02386
[32m[0907 00-28-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18055, current rewards: 32.94645, mean: 0.01639
[32m[0907 00-28-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18053, current rewards: 37.72850, mean: 0.01831
[32m[0907 00-28-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18050, current rewards: 44.45090, mean: 0.02107
[32m[0907 00-28-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18047, current rewards: 54.32159, mean: 0.02515
[32m[0907 00-28-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18044, current rewards: 60.97629, mean: 0.02759
[32m[0907 00-29-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18047, current rewards: 67.63239, mean: 0.02993
[32m[0907 00-29-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18055, current rewards: 74.29275, mean: 0.03216
[32m[0907 00-29-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18061, current rewards: 77.55287, mean: 0.03286
[32m[0907 00-29-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18060, current rewards: 15.76523, mean: 0.00654
[32m[0907 00-29-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18048, current rewards: -74.94475, mean: -0.03047
[32m[0907 00-29-45 @Agent.py:117][0m Average action selection time: 0.1804
[32m[0907 00-29-45 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-29-45 @MBExp.py:227][0m Rewards obtained: [-154.94474776357907], Lows: [172], Highs: [74], Total time: 33377.840664999996
[32m[0907 00-32-14 @MBExp.py:144][0m ####################################################################
[32m[0907 00-32-14 @MBExp.py:145][0m Starting training iteration 74.
[32m[0907 00-32-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19876, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-32-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19130, current rewards: -25.71328, mean: -0.42855
[32m[0907 00-32-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18843, current rewards: -15.63201, mean: -0.14211
[32m[0907 00-32-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18703, current rewards: -9.92067, mean: -0.06200
[32m[0907 00-32-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18631, current rewards: -4.20576, mean: -0.02003
[32m[0907 00-33-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18585, current rewards: 1.50926, mean: 0.00580
[32m[0907 00-33-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18551, current rewards: 7.22072, mean: 0.02329
[32m[0907 00-33-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18525, current rewards: 12.93830, mean: 0.03594
[32m[0907 00-33-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18511, current rewards: 18.65072, mean: 0.04549
[32m[0907 00-33-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18497, current rewards: -32.24357, mean: -0.07009
[32m[0907 00-33-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18491, current rewards: -76.20429, mean: -0.14942
[32m[0907 00-33-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18477, current rewards: -72.66023, mean: -0.12975
[32m[0907 00-34-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18468, current rewards: -67.04368, mean: -0.10991
[32m[0907 00-34-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18480, current rewards: -61.43094, mean: -0.09308
[32m[0907 00-34-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18484, current rewards: -55.81575, mean: -0.07861
[32m[0907 00-34-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18478, current rewards: -50.20410, mean: -0.06606
[32m[0907 00-34-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18474, current rewards: -44.59213, mean: -0.05505
[32m[0907 00-34-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18447, current rewards: -38.98082, mean: -0.04533
[32m[0907 00-35-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18419, current rewards: -33.36238, mean: -0.03666
[32m[0907 00-35-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18395, current rewards: -23.34782, mean: -0.02432
[32m[0907 00-35-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18373, current rewards: -17.70114, mean: -0.01753
[32m[0907 00-35-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18356, current rewards: -12.07766, mean: -0.01139
[32m[0907 00-35-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18339, current rewards: -6.44978, mean: -0.00581
[32m[0907 00-35-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18323, current rewards: -97.99978, mean: -0.08448
[32m[0907 00-35-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18312, current rewards: -197.99978, mean: -0.16364
[32m[0907 00-36-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18298, current rewards: -297.99978, mean: -0.23651
[32m[0907 00-36-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18287, current rewards: -397.99978, mean: -0.30382
[32m[0907 00-36-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18278, current rewards: -493.28310, mean: -0.36271
[32m[0907 00-36-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18249, current rewards: -507.05530, mean: -0.35961
[32m[0907 00-36-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18219, current rewards: -529.23950, mean: -0.36249
[32m[0907 00-36-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18193, current rewards: -545.57334, mean: -0.36131
[32m[0907 00-36-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18167, current rewards: -581.90640, mean: -0.37302
[32m[0907 00-37-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18145, current rewards: -573.57573, mean: -0.35626
[32m[0907 00-37-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18123, current rewards: -566.07760, mean: -0.34101
[32m[0907 00-37-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18106, current rewards: -558.57479, mean: -0.32665
[32m[0907 00-37-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18103, current rewards: -551.07450, mean: -0.31311
[32m[0907 00-37-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18099, current rewards: -543.23733, mean: -0.30013
[32m[0907 00-37-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18098, current rewards: -535.77952, mean: -0.28805
[32m[0907 00-38-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18097, current rewards: -528.34664, mean: -0.27662
[32m[0907 00-38-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18096, current rewards: -520.92257, mean: -0.26578
[32m[0907 00-38-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18093, current rewards: -513.46991, mean: -0.25546
[32m[0907 00-38-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18092, current rewards: -506.01718, mean: -0.24564
[32m[0907 00-38-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18091, current rewards: -498.59326, mean: -0.23630
[32m[0907 00-38-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18090, current rewards: -491.16291, mean: -0.22739
[32m[0907 00-38-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18088, current rewards: -515.34591, mean: -0.23319
[32m[0907 00-39-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18092, current rewards: -522.82380, mean: -0.23134
[32m[0907 00-39-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18103, current rewards: -516.07895, mean: -0.22341
[32m[0907 00-39-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18111, current rewards: -509.32665, mean: -0.21582
[32m[0907 00-39-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18111, current rewards: -502.56708, mean: -0.20853
[32m[0907 00-39-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18099, current rewards: -495.81632, mean: -0.20155
[32m[0907 00-39-46 @Agent.py:117][0m Average action selection time: 0.1809
[32m[0907 00-39-46 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-39-47 @MBExp.py:227][0m Rewards obtained: [-490.4169077905236], Lows: [397], Highs: [21], Total time: 33830.816469
[32m[0907 00-42-17 @MBExp.py:144][0m ####################################################################
[32m[0907 00-42-17 @MBExp.py:145][0m Starting training iteration 75.
[32m[0907 00-42-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18537, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-42-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18487, current rewards: -48.90994, mean: -0.81517
[32m[0907 00-42-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18543, current rewards: -88.52621, mean: -0.80478
[32m[0907 00-42-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18552, current rewards: -86.23779, mean: -0.53899
[32m[0907 00-42-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18527, current rewards: -66.07648, mean: -0.31465
[32m[0907 00-43-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18508, current rewards: -62.08929, mean: -0.23880
[32m[0907 00-43-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18487, current rewards: -79.17814, mean: -0.25541
[32m[0907 00-43-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18473, current rewards: -68.37858, mean: -0.18994
[32m[0907 00-43-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18466, current rewards: -43.78849, mean: -0.10680
[32m[0907 00-43-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18465, current rewards: -35.40223, mean: -0.07696
[32m[0907 00-43-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18466, current rewards: -32.61003, mean: -0.06394
[32m[0907 00-44-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18468, current rewards: -60.68374, mean: -0.10836
[32m[0907 00-44-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18464, current rewards: -80.38379, mean: -0.13178
[32m[0907 00-44-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18475, current rewards: -107.12066, mean: -0.16230
[32m[0907 00-44-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18487, current rewards: -138.85474, mean: -0.19557
[32m[0907 00-44-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18489, current rewards: -133.46050, mean: -0.17561
[32m[0907 00-44-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18494, current rewards: -128.06726, mean: -0.15811
[32m[0907 00-44-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18497, current rewards: -137.43927, mean: -0.15981
[32m[0907 00-45-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18494, current rewards: -143.08830, mean: -0.15724
[32m[0907 00-45-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18485, current rewards: -137.76076, mean: -0.14350
[32m[0907 00-45-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18458, current rewards: -132.43672, mean: -0.13113
[32m[0907 00-45-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18434, current rewards: -127.11263, mean: -0.11992
[32m[0907 00-45-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18443, current rewards: -154.69076, mean: -0.13936
[32m[0907 00-45-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18424, current rewards: -149.73059, mean: -0.12908
[32m[0907 00-46-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18404, current rewards: -144.75532, mean: -0.11963
[32m[0907 00-46-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18388, current rewards: -139.77839, mean: -0.11094
[32m[0907 00-46-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18371, current rewards: -134.80148, mean: -0.10290
[32m[0907 00-46-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18358, current rewards: -130.19220, mean: -0.09573
[32m[0907 00-46-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18324, current rewards: -124.66734, mean: -0.08842
[32m[0907 00-46-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18292, current rewards: -119.87893, mean: -0.08211
[32m[0907 00-46-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18264, current rewards: -115.52477, mean: -0.07651
[32m[0907 00-47-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18236, current rewards: -111.06451, mean: -0.07120
[32m[0907 00-47-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18212, current rewards: -106.63601, mean: -0.06623
[32m[0907 00-47-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18186, current rewards: -102.19915, mean: -0.06157
[32m[0907 00-47-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18162, current rewards: -97.76503, mean: -0.05717
[32m[0907 00-47-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18140, current rewards: -93.35070, mean: -0.05304
[32m[0907 00-47-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18119, current rewards: -89.03127, mean: -0.04919
[32m[0907 00-47-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18107, current rewards: -84.58446, mean: -0.04548
[32m[0907 00-48-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18104, current rewards: -80.15407, mean: -0.04197
[32m[0907 00-48-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18100, current rewards: -84.10695, mean: -0.04291
[32m[0907 00-48-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18096, current rewards: -90.83277, mean: -0.04519
[32m[0907 00-48-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18093, current rewards: -85.33882, mean: -0.04143
[32m[0907 00-48-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18090, current rewards: -79.83229, mean: -0.03784
[32m[0907 00-48-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18087, current rewards: -74.32727, mean: -0.03441
[32m[0907 00-48-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18086, current rewards: -65.11149, mean: -0.02946
[32m[0907 00-49-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18086, current rewards: -59.42751, mean: -0.02630
[32m[0907 00-49-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18096, current rewards: -53.73908, mean: -0.02326
[32m[0907 00-49-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18103, current rewards: -48.05125, mean: -0.02036
[32m[0907 00-49-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18106, current rewards: -42.37125, mean: -0.01758
[32m[0907 00-49-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18095, current rewards: -36.68974, mean: -0.01491
[32m[0907 00-49-49 @Agent.py:117][0m Average action selection time: 0.1808
[32m[0907 00-49-49 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-49-49 @MBExp.py:227][0m Rewards obtained: [-32.147227465217355], Lows: [204], Highs: [33], Total time: 34283.697086
[32m[0907 00-52-22 @MBExp.py:144][0m ####################################################################
[32m[0907 00-52-22 @MBExp.py:145][0m Starting training iteration 76.
[32m[0907 00-52-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18380, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-52-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18507, current rewards: -22.36928, mean: -0.37282
[32m[0907 00-52-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18526, current rewards: -17.91617, mean: -0.16287
[32m[0907 00-52-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18484, current rewards: -13.42985, mean: -0.08394
[32m[0907 00-53-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18468, current rewards: -8.94717, mean: -0.04261
[32m[0907 00-53-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18480, current rewards: -4.46681, mean: -0.01718
[32m[0907 00-53-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18470, current rewards: 0.01773, mean: 0.00006
[32m[0907 00-53-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18451, current rewards: 4.49938, mean: 0.01250
[32m[0907 00-53-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18449, current rewards: 8.98304, mean: 0.02191
[32m[0907 00-53-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18440, current rewards: 13.45898, mean: 0.02926
[32m[0907 00-53-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18437, current rewards: 17.73523, mean: 0.03477
[32m[0907 00-54-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18427, current rewards: 22.11236, mean: 0.03949
[32m[0907 00-54-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18448, current rewards: 26.00971, mean: 0.04264
[32m[0907 00-54-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18622, current rewards: 12.04533, mean: 0.01825
[32m[0907 00-54-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18707, current rewards: -12.13557, mean: -0.01709
[32m[0907 00-54-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18810, current rewards: -28.71286, mean: -0.03778
[32m[0907 00-54-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18835, current rewards: -46.47752, mean: -0.05738
[32m[0907 00-55-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18990, current rewards: -59.58064, mean: -0.06928
[32m[0907 00-55-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19034, current rewards: -69.19984, mean: -0.07604
[32m[0907 00-55-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19119, current rewards: -78.28488, mean: -0.08155
[32m[0907 00-55-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19157, current rewards: -73.37308, mean: -0.07265
[32m[0907 00-55-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19257, current rewards: -68.72785, mean: -0.06484
[32m[0907 00-55-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19335, current rewards: -64.13869, mean: -0.05778
[32m[0907 00-56-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19435, current rewards: -69.95526, mean: -0.06031
[32m[0907 00-56-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19512, current rewards: -66.97637, mean: -0.05535
[32m[0907 00-56-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19492, current rewards: -85.09803, mean: -0.06754
[32m[0907 00-56-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.19414, current rewards: -79.75408, mean: -0.06088
[32m[0907 00-56-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.19338, current rewards: -74.72782, mean: -0.05495
[32m[0907 00-56-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.19268, current rewards: -69.33197, mean: -0.04917
[32m[0907 00-57-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.19201, current rewards: -63.93057, mean: -0.04379
[32m[0907 00-57-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.19140, current rewards: -58.52681, mean: -0.03876
[32m[0907 00-57-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.19085, current rewards: -54.00227, mean: -0.03462
[32m[0907 00-57-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.19034, current rewards: -48.66065, mean: -0.03022
[32m[0907 00-57-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18984, current rewards: -43.31783, mean: -0.02610
[32m[0907 00-57-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18936, current rewards: -37.97860, mean: -0.02221
[32m[0907 00-57-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18898, current rewards: -31.80750, mean: -0.01807
[32m[0907 00-58-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18872, current rewards: -26.59057, mean: -0.01469
[32m[0907 00-58-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18846, current rewards: -56.15531, mean: -0.03019
[32m[0907 00-58-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18823, current rewards: -48.10628, mean: -0.02519
[32m[0907 00-58-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18801, current rewards: -40.24672, mean: -0.02053
[32m[0907 00-58-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18779, current rewards: -32.38718, mean: -0.01611
[32m[0907 00-58-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18759, current rewards: -24.52764, mean: -0.01191
[32m[0907 00-58-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18740, current rewards: -16.66810, mean: -0.00790
[32m[0907 00-59-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18721, current rewards: -33.60051, mean: -0.01556
[32m[0907 00-59-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18718, current rewards: -29.11685, mean: -0.01318
[32m[0907 00-59-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18716, current rewards: -23.39213, mean: -0.01035
[32m[0907 00-59-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18712, current rewards: -17.67225, mean: -0.00765
[32m[0907 00-59-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18693, current rewards: -11.95294, mean: -0.00506
[32m[0907 00-59-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18665, current rewards: -6.23005, mean: -0.00259
[32m[0907 01-00-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18640, current rewards: -0.50847, mean: -0.00021
[32m[0907 01-00-08 @Agent.py:117][0m Average action selection time: 0.1862
[32m[0907 01-00-08 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-00-08 @MBExp.py:227][0m Rewards obtained: [4.065590417463131], Lows: [63], Highs: [125], Total time: 34749.995417
[32m[0907 01-02-42 @MBExp.py:144][0m ####################################################################
[32m[0907 01-02-42 @MBExp.py:145][0m Starting training iteration 77.
[32m[0907 01-02-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18499, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-02-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18497, current rewards: -8.15407, mean: -0.13590
[32m[0907 01-03-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18475, current rewards: -2.10102, mean: -0.01910
[32m[0907 01-03-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18487, current rewards: 2.88262, mean: 0.01802
[32m[0907 01-03-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18479, current rewards: 7.86594, mean: 0.03746
[32m[0907 01-03-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18453, current rewards: 12.84707, mean: 0.04941
[32m[0907 01-03-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18476, current rewards: 17.83261, mean: 0.05752
[32m[0907 01-03-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18464, current rewards: 22.81333, mean: 0.06337
[32m[0907 01-03-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18467, current rewards: 27.79424, mean: 0.06779
[32m[0907 01-04-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18452, current rewards: 32.78269, mean: 0.07127
[32m[0907 01-04-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18457, current rewards: 17.21575, mean: 0.03376
[32m[0907 01-04-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18455, current rewards: 22.36379, mean: 0.03994
[32m[0907 01-04-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18457, current rewards: 26.53662, mean: 0.04350
[32m[0907 01-04-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18453, current rewards: 30.70946, mean: 0.04653
[32m[0907 01-04-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18445, current rewards: 34.88229, mean: 0.04913
[32m[0907 01-05-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18439, current rewards: 18.46945, mean: 0.02430
[32m[0907 01-05-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18435, current rewards: -31.53055, mean: -0.03893
[32m[0907 01-05-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18415, current rewards: -81.53055, mean: -0.09480
[32m[0907 01-05-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18387, current rewards: -131.53055, mean: -0.14454
[32m[0907 01-05-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18367, current rewards: -181.53055, mean: -0.18909
[32m[0907 01-05-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18353, current rewards: -231.53055, mean: -0.22924
[32m[0907 01-05-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18335, current rewards: -281.53055, mean: -0.26559
[32m[0907 01-06-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18318, current rewards: -331.53055, mean: -0.29868
[32m[0907 01-06-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18304, current rewards: -381.53055, mean: -0.32891
[32m[0907 01-06-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18289, current rewards: -431.53055, mean: -0.35664
[32m[0907 01-06-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18270, current rewards: -481.53055, mean: -0.38217
[32m[0907 01-06-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18235, current rewards: -531.53055, mean: -0.40575
[32m[0907 01-06-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18204, current rewards: -581.53055, mean: -0.42760
[32m[0907 01-06-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18175, current rewards: -631.53055, mean: -0.44789
[32m[0907 01-07-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18150, current rewards: -681.53055, mean: -0.46680
[32m[0907 01-07-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18124, current rewards: -731.53055, mean: -0.48446
[32m[0907 01-07-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18100, current rewards: -781.53055, mean: -0.50098
[32m[0907 01-07-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18078, current rewards: -831.53055, mean: -0.51648
[32m[0907 01-07-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18056, current rewards: -881.53055, mean: -0.53104
[32m[0907 01-07-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18040, current rewards: -931.53055, mean: -0.54475
[32m[0907 01-08-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18030, current rewards: -981.53055, mean: -0.55769
[32m[0907 01-08-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18028, current rewards: -1031.53055, mean: -0.56991
[32m[0907 01-08-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18027, current rewards: -1081.53055, mean: -0.58147
[32m[0907 01-08-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18024, current rewards: -1131.53055, mean: -0.59242
[32m[0907 01-08-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18023, current rewards: -1181.53055, mean: -0.60282
[32m[0907 01-08-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18022, current rewards: -1231.53055, mean: -0.61270
[32m[0907 01-08-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18020, current rewards: -1281.53055, mean: -0.62210
[32m[0907 01-09-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18019, current rewards: -1331.53055, mean: -0.63106
[32m[0907 01-09-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18018, current rewards: -1381.53055, mean: -0.63960
[32m[0907 01-09-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18030, current rewards: -1431.53055, mean: -0.64775
[32m[0907 01-09-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18039, current rewards: -1481.53055, mean: -0.65554
[32m[0907 01-09-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18048, current rewards: -1531.53055, mean: -0.66300
[32m[0907 01-09-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18048, current rewards: -1581.53055, mean: -0.67014
[32m[0907 01-09-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18049, current rewards: -1631.53055, mean: -0.67698
[32m[0907 01-10-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18038, current rewards: -1681.53055, mean: -0.68355
[32m[0907 01-10-14 @Agent.py:117][0m Average action selection time: 0.1803
[32m[0907 01-10-14 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-10-14 @MBExp.py:227][0m Rewards obtained: [-1721.5305501830103], Lows: [11], Highs: [1771], Total time: 35201.460349
[32m[0907 01-12-50 @MBExp.py:144][0m ####################################################################
[32m[0907 01-12-50 @MBExp.py:145][0m Starting training iteration 78.
[32m[0907 01-12-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19661, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-13-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19061, current rewards: -9.32740, mean: -0.15546
[32m[0907 01-13-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18787, current rewards: -3.71960, mean: -0.03381
[32m[0907 01-13-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18693, current rewards: 1.89723, mean: 0.01186
[32m[0907 01-13-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18634, current rewards: 7.50803, mean: 0.03575
[32m[0907 01-13-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18605, current rewards: 13.12782, mean: 0.05049
[32m[0907 01-13-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18568, current rewards: 18.74311, mean: 0.06046
[32m[0907 01-13-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18542, current rewards: 24.35627, mean: 0.06766
[32m[0907 01-14-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18553, current rewards: 29.97171, mean: 0.07310
[32m[0907 01-14-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18545, current rewards: 31.49260, mean: 0.06846
[32m[0907 01-14-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18555, current rewards: 8.77624, mean: 0.01721
[32m[0907 01-14-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18551, current rewards: -3.51139, mean: -0.00627
[32m[0907 01-14-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18537, current rewards: -9.12932, mean: -0.01497
[32m[0907 01-14-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18540, current rewards: -27.22041, mean: -0.04124
[32m[0907 01-15-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18540, current rewards: -41.16195, mean: -0.05797
[32m[0907 01-15-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18529, current rewards: -41.69251, mean: -0.05486
[32m[0907 01-15-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18519, current rewards: -62.11139, mean: -0.07668
[32m[0907 01-15-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18496, current rewards: -71.94575, mean: -0.08366
[32m[0907 01-15-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18467, current rewards: -89.66466, mean: -0.09853
[32m[0907 01-15-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18442, current rewards: -101.23976, mean: -0.10546
[32m[0907 01-15-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18418, current rewards: -113.95314, mean: -0.11282
[32m[0907 01-16-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18397, current rewards: -125.99904, mean: -0.11887
[32m[0907 01-16-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18381, current rewards: -120.49489, mean: -0.10855
[32m[0907 01-16-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18362, current rewards: -115.07263, mean: -0.09920
[32m[0907 01-16-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18344, current rewards: -109.65493, mean: -0.09062
[32m[0907 01-16-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18316, current rewards: -104.37039, mean: -0.08283
[32m[0907 01-16-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18281, current rewards: -99.34886, mean: -0.07584
[32m[0907 01-16-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18256, current rewards: -117.59415, mean: -0.08647
[32m[0907 01-17-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18232, current rewards: -142.92852, mean: -0.10137
[32m[0907 01-17-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18209, current rewards: -140.17042, mean: -0.09601
[32m[0907 01-17-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18191, current rewards: -135.87858, mean: -0.08999
[32m[0907 01-17-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18176, current rewards: -131.65524, mean: -0.08439
[32m[0907 01-17-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18158, current rewards: -127.38302, mean: -0.07912
[32m[0907 01-17-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18139, current rewards: -123.12058, mean: -0.07417
[32m[0907 01-18-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18127, current rewards: -116.42186, mean: -0.06808
[32m[0907 01-18-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18124, current rewards: -111.08586, mean: -0.06312
[32m[0907 01-18-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18122, current rewards: -105.74495, mean: -0.05842
[32m[0907 01-18-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18167, current rewards: -130.29421, mean: -0.07005
[32m[0907 01-18-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18173, current rewards: -130.60770, mean: -0.06838
[32m[0907 01-18-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18168, current rewards: -124.70204, mean: -0.06362
[32m[0907 01-18-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18162, current rewards: -118.78931, mean: -0.05910
[32m[0907 01-19-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18156, current rewards: -112.86802, mean: -0.05479
[32m[0907 01-19-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18152, current rewards: -107.41506, mean: -0.05091
[32m[0907 01-19-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18153, current rewards: -101.96282, mean: -0.04721
[32m[0907 01-19-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18161, current rewards: -96.54466, mean: -0.04369
[32m[0907 01-19-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18167, current rewards: -91.11640, mean: -0.04032
[32m[0907 01-19-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18174, current rewards: -85.68677, mean: -0.03709
[32m[0907 01-20-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18195, current rewards: -104.07266, mean: -0.04410
[32m[0907 01-20-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18205, current rewards: -99.62233, mean: -0.04134
[32m[0907 01-20-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18200, current rewards: -94.49739, mean: -0.03841
[32m[0907 01-20-26 @Agent.py:117][0m Average action selection time: 0.1819
[32m[0907 01-20-26 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-20-26 @MBExp.py:227][0m Rewards obtained: [-90.39798107917413], Lows: [39], Highs: [248], Total time: 35657.002322
[32m[0907 01-23-04 @MBExp.py:144][0m ####################################################################
[32m[0907 01-23-04 @MBExp.py:145][0m Starting training iteration 79.
[32m[0907 01-23-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18463, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-23-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18495, current rewards: -11.93201, mean: -0.19887
[32m[0907 01-23-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18439, current rewards: -7.35637, mean: -0.06688
[32m[0907 01-23-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18420, current rewards: -2.77357, mean: -0.01733
[32m[0907 01-23-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18416, current rewards: 1.81057, mean: 0.00862
[32m[0907 01-23-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18398, current rewards: 6.38600, mean: 0.02456
[32m[0907 01-24-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18403, current rewards: 10.96090, mean: 0.03536
[32m[0907 01-24-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18407, current rewards: 15.53749, mean: 0.04316
[32m[0907 01-24-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18405, current rewards: 20.11418, mean: 0.04906
[32m[0907 01-24-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18395, current rewards: 18.08064, mean: 0.03931
[32m[0907 01-24-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18423, current rewards: 24.85562, mean: 0.04874
[32m[0907 01-24-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18441, current rewards: 30.49523, mean: 0.05446
[32m[0907 01-24-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18433, current rewards: 34.06072, mean: 0.05584
[32m[0907 01-25-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18452, current rewards: 41.26395, mean: 0.06252
[32m[0907 01-25-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18447, current rewards: 46.13763, mean: 0.06498
[32m[0907 01-25-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18442, current rewards: 47.86042, mean: 0.06297
[32m[0907 01-25-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18437, current rewards: 31.49326, mean: 0.03888
[32m[0907 01-25-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18415, current rewards: 31.79128, mean: 0.03697
[32m[0907 01-25-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18392, current rewards: 37.84721, mean: 0.04159
[32m[0907 01-26-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18369, current rewards: 43.89247, mean: 0.04572
[32m[0907 01-26-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18349, current rewards: 49.93774, mean: 0.04944
[32m[0907 01-26-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18332, current rewards: 55.98300, mean: 0.05281
[32m[0907 01-26-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18314, current rewards: 62.02827, mean: 0.05588
[32m[0907 01-26-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18300, current rewards: 68.07354, mean: 0.05868
[32m[0907 01-26-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18291, current rewards: 74.11880, mean: 0.06126
[32m[0907 01-26-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18255, current rewards: 80.14274, mean: 0.06361
[32m[0907 01-27-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18223, current rewards: 49.40237, mean: 0.03771
[32m[0907 01-27-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18190, current rewards: -0.59763, mean: -0.00044
[32m[0907 01-27-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18162, current rewards: -50.59763, mean: -0.03588
[32m[0907 01-27-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18136, current rewards: -100.59763, mean: -0.06890
[32m[0907 01-27-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18111, current rewards: -150.59763, mean: -0.09973
[32m[0907 01-27-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18089, current rewards: -200.59763, mean: -0.12859
[32m[0907 01-27-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18070, current rewards: -250.59763, mean: -0.15565
[32m[0907 01-28-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18053, current rewards: -300.59763, mean: -0.18108
[32m[0907 01-28-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18036, current rewards: -350.59763, mean: -0.20503
[32m[0907 01-28-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18032, current rewards: -400.59763, mean: -0.22761
[32m[0907 01-28-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18032, current rewards: -450.59763, mean: -0.24895
[32m[0907 01-28-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18032, current rewards: -500.59763, mean: -0.26914
[32m[0907 01-28-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18036, current rewards: -550.59763, mean: -0.28827
[32m[0907 01-28-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18037, current rewards: -600.59763, mean: -0.30643
[32m[0907 01-29-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18040, current rewards: -650.59763, mean: -0.32368
[32m[0907 01-29-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18040, current rewards: -700.59763, mean: -0.34010
[32m[0907 01-29-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18040, current rewards: -750.59763, mean: -0.35573
[32m[0907 01-29-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18045, current rewards: -800.59763, mean: -0.37065
[32m[0907 01-29-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18058, current rewards: -850.59763, mean: -0.38489
[32m[0907 01-29-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18070, current rewards: -900.59763, mean: -0.39849
[32m[0907 01-30-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18081, current rewards: -950.59763, mean: -0.41151
[32m[0907 01-30-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18084, current rewards: -1000.59763, mean: -0.42398
[32m[0907 01-30-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18085, current rewards: -1050.59763, mean: -0.43593
[32m[0907 01-30-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18085, current rewards: -1100.59763, mean: -0.44740
[32m[0907 01-30-37 @Agent.py:117][0m Average action selection time: 0.1808
[32m[0907 01-30-37 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-30-37 @MBExp.py:227][0m Rewards obtained: [-1140.5976325620793], Lows: [31], Highs: [1235], Total time: 36109.936287
[32m[0907 01-33-17 @MBExp.py:144][0m ####################################################################
[32m[0907 01-33-17 @MBExp.py:145][0m Starting training iteration 80.
[32m[0907 01-33-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17779, current rewards: 0.98588, mean: 0.09859
[32m[0907 01-33-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17992, current rewards: -25.58566, mean: -0.42643
[32m[0907 01-33-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18232, current rewards: -75.58566, mean: -0.68714
[32m[0907 01-33-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18296, current rewards: -125.58566, mean: -0.78491
[32m[0907 01-33-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18315, current rewards: -175.58566, mean: -0.83612
[32m[0907 01-34-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18326, current rewards: -225.58566, mean: -0.86764
[32m[0907 01-34-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18354, current rewards: -275.58566, mean: -0.88899
[32m[0907 01-34-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18359, current rewards: -325.58566, mean: -0.90440
[32m[0907 01-34-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18366, current rewards: -375.58566, mean: -0.91606
[32m[0907 01-34-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18377, current rewards: -425.58566, mean: -0.92519
[32m[0907 01-34-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18379, current rewards: -475.58566, mean: -0.93252
[32m[0907 01-35-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18373, current rewards: -525.58566, mean: -0.93855
[32m[0907 01-35-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18382, current rewards: -575.58566, mean: -0.94358
[32m[0907 01-35-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18387, current rewards: -625.58566, mean: -0.94786
[32m[0907 01-35-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18386, current rewards: -675.58566, mean: -0.95153
[32m[0907 01-35-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18387, current rewards: -725.58566, mean: -0.95472
[32m[0907 01-35-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18366, current rewards: -775.58566, mean: -0.95751
[32m[0907 01-35-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18345, current rewards: -825.58566, mean: -0.95998
[32m[0907 01-36-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18324, current rewards: -875.58566, mean: -0.96218
[32m[0907 01-36-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18304, current rewards: -925.58566, mean: -0.96415
[32m[0907 01-36-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18285, current rewards: -975.58566, mean: -0.96593
[32m[0907 01-36-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18269, current rewards: -1025.58566, mean: -0.96753
[32m[0907 01-36-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18256, current rewards: -1075.58566, mean: -0.96900
[32m[0907 01-36-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18242, current rewards: -1125.58566, mean: -0.97033
[32m[0907 01-36-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18223, current rewards: -1175.58566, mean: -0.97156
[32m[0907 01-37-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18189, current rewards: -1225.58566, mean: -0.97269
[32m[0907 01-37-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18161, current rewards: -1275.58566, mean: -0.97373
[32m[0907 01-37-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18133, current rewards: -1325.58566, mean: -0.97470
[32m[0907 01-37-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18106, current rewards: -1375.58566, mean: -0.97559
[32m[0907 01-37-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18079, current rewards: -1425.58566, mean: -0.97643
[32m[0907 01-37-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18056, current rewards: -1475.58566, mean: -0.97721
[32m[0907 01-37-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18033, current rewards: -1525.58566, mean: -0.97794
[32m[0907 01-38-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18013, current rewards: -1575.58566, mean: -0.97862
[32m[0907 01-38-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17993, current rewards: -1625.58566, mean: -0.97927
[32m[0907 01-38-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17974, current rewards: -1675.58566, mean: -0.97987
[32m[0907 01-38-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17970, current rewards: -1725.58566, mean: -0.98045
[32m[0907 01-38-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17968, current rewards: -1775.58566, mean: -0.98099
[32m[0907 01-38-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17967, current rewards: -1825.58566, mean: -0.98150
[32m[0907 01-39-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17965, current rewards: -1875.58566, mean: -0.98198
[32m[0907 01-39-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17965, current rewards: -1925.58566, mean: -0.98244
[32m[0907 01-39-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17967, current rewards: -1975.58566, mean: -0.98288
[32m[0907 01-39-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17967, current rewards: -2025.58566, mean: -0.98329
[32m[0907 01-39-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17965, current rewards: -2075.58566, mean: -0.98369
[32m[0907 01-39-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17971, current rewards: -2125.58566, mean: -0.98407
[32m[0907 01-39-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17981, current rewards: -2175.58566, mean: -0.98443
[32m[0907 01-40-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17992, current rewards: -2225.58566, mean: -0.98477
[32m[0907 01-40-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18000, current rewards: -2275.58566, mean: -0.98510
[32m[0907 01-40-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18002, current rewards: -2325.58566, mean: -0.98542
[32m[0907 01-40-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18002, current rewards: -2375.58566, mean: -0.98572
[32m[0907 01-40-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18000, current rewards: -2425.58566, mean: -0.98601
[32m[0907 01-40-48 @Agent.py:117][0m Average action selection time: 0.1800
[32m[0907 01-40-48 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-40-48 @MBExp.py:227][0m Rewards obtained: [-2465.5856609442053], Lows: [0], Highs: [2468], Total time: 36560.719603
[32m[0907 01-43-30 @MBExp.py:144][0m ####################################################################
[32m[0907 01-43-30 @MBExp.py:145][0m Starting training iteration 81.
[32m[0907 01-43-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18048, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-43-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17951, current rewards: -11.57432, mean: -0.19291
[32m[0907 01-43-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17965, current rewards: -13.01344, mean: -0.11830
[32m[0907 01-43-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17945, current rewards: -16.23232, mean: -0.10145
[32m[0907 01-44-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18006, current rewards: -19.67293, mean: -0.09368
[32m[0907 01-44-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18107, current rewards: -20.71819, mean: -0.07969
[32m[0907 01-44-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18167, current rewards: -24.18875, mean: -0.07803
[32m[0907 01-44-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18192, current rewards: -25.26730, mean: -0.07019
[32m[0907 01-44-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18224, current rewards: -28.76322, mean: -0.07015
[32m[0907 01-44-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18234, current rewards: -30.41979, mean: -0.06613
[32m[0907 01-45-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18259, current rewards: -33.93976, mean: -0.06655
[32m[0907 01-45-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18276, current rewards: -35.35059, mean: -0.06313
[32m[0907 01-45-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18285, current rewards: -38.87580, mean: -0.06373
[32m[0907 01-45-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18301, current rewards: -40.40114, mean: -0.06121
[32m[0907 01-45-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18311, current rewards: -43.87044, mean: -0.06179
[32m[0907 01-45-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18313, current rewards: -47.70932, mean: -0.06278
[32m[0907 01-45-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18317, current rewards: -60.19222, mean: -0.07431
[32m[0907 01-46-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18313, current rewards: -51.71813, mean: -0.06014
[32m[0907 01-46-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18292, current rewards: -46.28187, mean: -0.05086
[32m[0907 01-46-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18274, current rewards: -40.84527, mean: -0.04255
[32m[0907 01-46-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18258, current rewards: -35.41265, mean: -0.03506
[32m[0907 01-46-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18245, current rewards: -29.97692, mean: -0.02828
[32m[0907 01-46-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18233, current rewards: -24.53843, mean: -0.02211
[32m[0907 01-47-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18222, current rewards: -78.96888, mean: -0.06808
[32m[0907 01-47-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18208, current rewards: -128.96888, mean: -0.10659
[32m[0907 01-47-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18176, current rewards: -178.96888, mean: -0.14204
[32m[0907 01-47-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18146, current rewards: -228.96888, mean: -0.17479
[32m[0907 01-47-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18120, current rewards: -278.96888, mean: -0.20512
[32m[0907 01-47-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18095, current rewards: -328.96888, mean: -0.23331
[32m[0907 01-47-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18071, current rewards: -378.96888, mean: -0.25957
[32m[0907 01-48-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18050, current rewards: -428.96888, mean: -0.28409
[32m[0907 01-48-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18029, current rewards: -478.96888, mean: -0.30703
[32m[0907 01-48-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18009, current rewards: -528.96888, mean: -0.32855
[32m[0907 01-48-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17990, current rewards: -566.24328, mean: -0.34111
[32m[0907 01-48-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17971, current rewards: -560.07163, mean: -0.32753
[32m[0907 01-48-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17954, current rewards: -553.61281, mean: -0.31455
[32m[0907 01-48-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17943, current rewards: -562.96245, mean: -0.31103
[32m[0907 01-49-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17943, current rewards: -612.96245, mean: -0.32955
[32m[0907 01-49-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17943, current rewards: -662.96245, mean: -0.34710
[32m[0907 01-49-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17944, current rewards: -712.96245, mean: -0.36376
[32m[0907 01-49-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17942, current rewards: -762.96245, mean: -0.37958
[32m[0907 01-49-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17943, current rewards: -812.96245, mean: -0.39464
[32m[0907 01-49-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17945, current rewards: -862.96245, mean: -0.40899
[32m[0907 01-49-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17949, current rewards: -934.33727, mean: -0.43256
[32m[0907 01-50-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17963, current rewards: -992.69979, mean: -0.44919
[32m[0907 01-50-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17974, current rewards: -987.04347, mean: -0.43674
[32m[0907 01-50-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17983, current rewards: -981.85302, mean: -0.42504
[32m[0907 01-50-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17987, current rewards: -976.67078, mean: -0.41384
[32m[0907 01-50-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17987, current rewards: -971.48061, mean: -0.40310
[32m[0907 01-50-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17987, current rewards: -966.29159, mean: -0.39280
[32m[0907 01-51-00 @Agent.py:117][0m Average action selection time: 0.1799
[32m[0907 01-51-00 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-51-00 @MBExp.py:227][0m Rewards obtained: [-962.2814059437868], Lows: [146], Highs: [866], Total time: 37011.191705
[32m[0907 01-53-45 @MBExp.py:144][0m ####################################################################
[32m[0907 01-53-45 @MBExp.py:145][0m Starting training iteration 82.
[32m[0907 01-53-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17723, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-53-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17983, current rewards: -12.51372, mean: -0.20856
[32m[0907 01-54-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18019, current rewards: -6.04400, mean: -0.05495
[32m[0907 01-54-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18007, current rewards: 0.39221, mean: 0.00245
[32m[0907 01-54-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17996, current rewards: 6.84185, mean: 0.03258
[32m[0907 01-54-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18000, current rewards: 13.27952, mean: 0.05108
[32m[0907 01-54-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18064, current rewards: 19.72229, mean: 0.06362
[32m[0907 01-54-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18125, current rewards: 26.16318, mean: 0.07268
[32m[0907 01-54-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18159, current rewards: 38.88523, mean: 0.09484
[32m[0907 01-55-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18191, current rewards: 45.34735, mean: 0.09858
[32m[0907 01-55-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18215, current rewards: 51.40607, mean: 0.10080
[32m[0907 01-55-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18233, current rewards: 57.46269, mean: 0.10261
[32m[0907 01-55-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18254, current rewards: 63.52297, mean: 0.10414
[32m[0907 01-55-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18269, current rewards: 65.10165, mean: 0.09864
[32m[0907 01-55-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18273, current rewards: 62.80200, mean: 0.08845
[32m[0907 01-56-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18287, current rewards: 69.68876, mean: 0.09170
[32m[0907 01-56-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18293, current rewards: 76.55486, mean: 0.09451
[32m[0907 01-56-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18280, current rewards: 83.18535, mean: 0.09673
[32m[0907 01-56-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18260, current rewards: 90.07001, mean: 0.09898
[32m[0907 01-56-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18244, current rewards: 96.94777, mean: 0.10099
[32m[0907 01-56-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18228, current rewards: 103.82594, mean: 0.10280
[32m[0907 01-56-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18216, current rewards: 110.70810, mean: 0.10444
[32m[0907 01-57-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18202, current rewards: 81.60160, mean: 0.07351
[32m[0907 01-57-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18189, current rewards: 86.57634, mean: 0.07463
[32m[0907 01-57-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18166, current rewards: 91.54907, mean: 0.07566
[32m[0907 01-57-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18136, current rewards: 96.04605, mean: 0.07623
[32m[0907 01-57-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18108, current rewards: 80.05534, mean: 0.06111
[32m[0907 01-57-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18083, current rewards: 85.80162, mean: 0.06309
[32m[0907 01-58-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18057, current rewards: 91.20873, mean: 0.06469
[32m[0907 01-58-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18039, current rewards: 96.61259, mean: 0.06617
[32m[0907 01-58-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18020, current rewards: 102.02030, mean: 0.06756
[32m[0907 01-58-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18001, current rewards: 107.42606, mean: 0.06886
[32m[0907 01-58-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17982, current rewards: 112.82876, mean: 0.07008
[32m[0907 01-58-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17964, current rewards: 118.23925, mean: 0.07123
[32m[0907 01-58-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17947, current rewards: 123.64358, mean: 0.07231
[32m[0907 01-59-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17931, current rewards: 129.04939, mean: 0.07332
[32m[0907 01-59-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17922, current rewards: 134.45587, mean: 0.07429
[32m[0907 01-59-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17924, current rewards: 139.86414, mean: 0.07520
[32m[0907 01-59-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17925, current rewards: 145.26798, mean: 0.07606
[32m[0907 01-59-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17925, current rewards: 130.40741, mean: 0.06653
[32m[0907 01-59-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17926, current rewards: 135.02577, mean: 0.06718
[32m[0907 01-59-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17926, current rewards: 140.33580, mean: 0.06812
[32m[0907 02-00-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17927, current rewards: 144.96144, mean: 0.06870
[32m[0907 02-00-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17933, current rewards: 149.58585, mean: 0.06925
[32m[0907 02-00-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17948, current rewards: 154.20827, mean: 0.06978
[32m[0907 02-00-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17971, current rewards: 146.95013, mean: 0.06502
[32m[0907 02-00-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17981, current rewards: 152.87200, mean: 0.06618
[32m[0907 02-00-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17989, current rewards: 158.78021, mean: 0.06728
[32m[0907 02-00-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17996, current rewards: 164.68171, mean: 0.06833
[32m[0907 02-01-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17994, current rewards: 172.25263, mean: 0.07002
[32m[0907 02-01-15 @Agent.py:117][0m Average action selection time: 0.1799
[32m[0907 02-01-15 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-01-16 @MBExp.py:227][0m Rewards obtained: [177.27388989098262], Lows: [40], Highs: [35], Total time: 37461.826367999995
[32m[0907 02-04-02 @MBExp.py:144][0m ####################################################################
[32m[0907 02-04-02 @MBExp.py:145][0m Starting training iteration 83.
[32m[0907 02-04-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17883, current rewards: 1.08632, mean: 0.10863
[32m[0907 02-04-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17927, current rewards: 5.12204, mean: 0.08537
[32m[0907 02-04-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17958, current rewards: 10.83341, mean: 0.09849
[32m[0907 02-04-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18000, current rewards: 16.55142, mean: 0.10345
[32m[0907 02-04-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17984, current rewards: 22.26537, mean: 0.10603
[32m[0907 02-04-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17973, current rewards: 27.98076, mean: 0.10762
[32m[0907 02-04-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18023, current rewards: 33.69583, mean: 0.10870
[32m[0907 02-05-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18090, current rewards: 39.41208, mean: 0.10948
[32m[0907 02-05-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18135, current rewards: 46.68712, mean: 0.11387
[32m[0907 02-05-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18161, current rewards: 52.37503, mean: 0.11386
[32m[0907 02-05-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18187, current rewards: 58.01923, mean: 0.11376
[32m[0907 02-05-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18205, current rewards: 63.66529, mean: 0.11369
[32m[0907 02-05-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18219, current rewards: 69.30879, mean: 0.11362
[32m[0907 02-06-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18239, current rewards: 74.95317, mean: 0.11357
[32m[0907 02-06-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18250, current rewards: 80.59643, mean: 0.11352
[32m[0907 02-06-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18256, current rewards: 86.24175, mean: 0.11348
[32m[0907 02-06-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18290, current rewards: 84.82607, mean: 0.10472
[32m[0907 02-06-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18275, current rewards: 85.94890, mean: 0.09994
[32m[0907 02-06-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18259, current rewards: 89.63147, mean: 0.09850
[32m[0907 02-06-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18245, current rewards: 93.24279, mean: 0.09713
[32m[0907 02-07-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18232, current rewards: 96.85372, mean: 0.09589
[32m[0907 02-07-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18221, current rewards: 100.46566, mean: 0.09478
[32m[0907 02-07-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18209, current rewards: 98.71515, mean: 0.08893
[32m[0907 02-07-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18200, current rewards: 76.65205, mean: 0.06608
[32m[0907 02-07-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18172, current rewards: 64.96368, mean: 0.05369
[32m[0907 02-07-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18141, current rewards: 45.57398, mean: 0.03617
[32m[0907 02-07-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18110, current rewards: 33.89466, mean: 0.02587
[32m[0907 02-08-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18086, current rewards: 14.81364, mean: 0.01089
[32m[0907 02-08-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18062, current rewards: -11.12556, mean: -0.00789
[32m[0907 02-08-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18040, current rewards: -96.39906, mean: -0.06603
[32m[0907 02-08-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18019, current rewards: -101.17964, mean: -0.06701
[32m[0907 02-08-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18002, current rewards: -106.00611, mean: -0.06795
[32m[0907 02-08-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17982, current rewards: -108.85503, mean: -0.06761
[32m[0907 02-09-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17964, current rewards: -110.56262, mean: -0.06660
[32m[0907 02-09-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17947, current rewards: -105.43103, mean: -0.06166
[32m[0907 02-09-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17931, current rewards: -100.30459, mean: -0.05699
[32m[0907 02-09-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17925, current rewards: -95.17802, mean: -0.05258
[32m[0907 02-09-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17926, current rewards: -119.84316, mean: -0.06443
[32m[0907 02-09-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17926, current rewards: -189.80757, mean: -0.09938
[32m[0907 02-09-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17927, current rewards: -216.77018, mean: -0.11060
[32m[0907 02-10-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17928, current rewards: -230.42681, mean: -0.11464
[32m[0907 02-10-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17928, current rewards: -241.19254, mean: -0.11708
[32m[0907 02-10-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17929, current rewards: -303.23200, mean: -0.14371
[32m[0907 02-10-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17932, current rewards: -365.33184, mean: -0.16914
[32m[0907 02-10-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17946, current rewards: -423.22259, mean: -0.19150
[32m[0907 02-10-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17959, current rewards: -483.51019, mean: -0.21394
[32m[0907 02-10-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17970, current rewards: -543.75417, mean: -0.23539
[32m[0907 02-11-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17978, current rewards: -601.65419, mean: -0.25494
[32m[0907 02-11-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17987, current rewards: -669.25691, mean: -0.27770
[32m[0907 02-11-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17986, current rewards: -755.96477, mean: -0.30730
[32m[0907 02-11-32 @Agent.py:117][0m Average action selection time: 0.1798
[32m[0907 02-11-32 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-11-32 @MBExp.py:227][0m Rewards obtained: [-835.9647738688192], Lows: [538], Highs: [30], Total time: 37912.250785
[32m[0907 02-14-20 @MBExp.py:144][0m ####################################################################
[32m[0907 02-14-20 @MBExp.py:145][0m Starting training iteration 84.
[32m[0907 02-14-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18487, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-14-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18057, current rewards: -25.42798, mean: -0.42380
[32m[0907 02-14-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17990, current rewards: -19.32141, mean: -0.17565
[32m[0907 02-14-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18002, current rewards: -13.21286, mean: -0.08258
[32m[0907 02-14-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18036, current rewards: -7.09417, mean: -0.03378
[32m[0907 02-15-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18013, current rewards: -0.98789, mean: -0.00380
[32m[0907 02-15-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18059, current rewards: 5.12719, mean: 0.01654
[32m[0907 02-15-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18107, current rewards: 11.24520, mean: 0.03124
[32m[0907 02-15-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18152, current rewards: 17.35735, mean: 0.04233
[32m[0907 02-15-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18178, current rewards: 23.46133, mean: 0.05100
[32m[0907 02-15-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18199, current rewards: 29.57402, mean: 0.05799
[32m[0907 02-16-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18228, current rewards: 35.69148, mean: 0.06373
[32m[0907 02-16-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18241, current rewards: 41.81538, mean: 0.06855
[32m[0907 02-16-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18250, current rewards: 47.92176, mean: 0.07261
[32m[0907 02-16-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18264, current rewards: 54.03621, mean: 0.07611
[32m[0907 02-16-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18274, current rewards: -35.35705, mean: -0.04652
[32m[0907 02-16-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18274, current rewards: -118.53337, mean: -0.14634
[32m[0907 02-16-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18257, current rewards: -198.53559, mean: -0.23086
[32m[0907 02-17-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18246, current rewards: -274.06270, mean: -0.30117
[32m[0907 02-17-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18230, current rewards: -356.59972, mean: -0.37146
[32m[0907 02-17-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18216, current rewards: -435.68651, mean: -0.43137
[32m[0907 02-17-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18202, current rewards: -518.94484, mean: -0.48957
[32m[0907 02-17-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18189, current rewards: -598.00813, mean: -0.53875
[32m[0907 02-17-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18180, current rewards: -681.26232, mean: -0.58730
[32m[0907 02-18-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18145, current rewards: -760.35864, mean: -0.62840
[32m[0907 02-18-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18116, current rewards: -841.54700, mean: -0.66789
[32m[0907 02-18-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18088, current rewards: -922.67015, mean: -0.70433
[32m[0907 02-18-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18061, current rewards: -1003.86495, mean: -0.73814
[32m[0907 02-18-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18038, current rewards: -1085.01496, mean: -0.76951
[32m[0907 02-18-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18016, current rewards: -1164.07546, mean: -0.79731
[32m[0907 02-18-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17996, current rewards: -1174.84777, mean: -0.77804
[32m[0907 02-19-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17976, current rewards: -1168.76647, mean: -0.74921
[32m[0907 02-19-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17963, current rewards: -1162.90764, mean: -0.72230
[32m[0907 02-19-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17946, current rewards: -1156.81347, mean: -0.69688
[32m[0907 02-19-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17930, current rewards: -1150.72639, mean: -0.67294
[32m[0907 02-19-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17914, current rewards: -1144.64170, mean: -0.65036
[32m[0907 02-19-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17907, current rewards: -1138.55467, mean: -0.62904
[32m[0907 02-19-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17907, current rewards: -1132.46304, mean: -0.60885
[32m[0907 02-20-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17909, current rewards: -1126.36870, mean: -0.58972
[32m[0907 02-20-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17909, current rewards: -1120.27523, mean: -0.57157
[32m[0907 02-20-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17909, current rewards: -1114.18538, mean: -0.55432
[32m[0907 02-20-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17909, current rewards: -1108.09176, mean: -0.53791
[32m[0907 02-20-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17921, current rewards: -1148.36208, mean: -0.54425
[32m[0907 02-20-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17925, current rewards: -1142.37419, mean: -0.52888
[32m[0907 02-20-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17938, current rewards: -1136.88116, mean: -0.51443
[32m[0907 02-21-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17950, current rewards: -1131.38935, mean: -0.50061
[32m[0907 02-21-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17963, current rewards: -1125.89548, mean: -0.48740
[32m[0907 02-21-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17973, current rewards: -1120.41198, mean: -0.47475
[32m[0907 02-21-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17984, current rewards: -1113.98413, mean: -0.46223
[32m[0907 02-21-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17996, current rewards: -1130.75272, mean: -0.45966
[32m[0907 02-21-51 @Agent.py:117][0m Average action selection time: 0.1799
[32m[0907 02-21-51 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-21-51 @MBExp.py:227][0m Rewards obtained: [-1120.7285654215514], Lows: [658], Highs: [33], Total time: 38362.925106999995
[32m[0907 02-24-41 @MBExp.py:144][0m ####################################################################
[32m[0907 02-24-41 @MBExp.py:145][0m Starting training iteration 85.
[32m[0907 02-24-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17820, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-24-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17929, current rewards: -9.98226, mean: -0.16637
[32m[0907 02-25-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17937, current rewards: -4.99010, mean: -0.04536
[32m[0907 02-25-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17949, current rewards: -0.00122, mean: -0.00001
[32m[0907 02-25-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17953, current rewards: 4.98615, mean: 0.02374
[32m[0907 02-25-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17962, current rewards: 9.97749, mean: 0.03837
[32m[0907 02-25-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18019, current rewards: 14.51392, mean: 0.04682
[32m[0907 02-25-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18078, current rewards: 19.31542, mean: 0.05365
[32m[0907 02-25-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18134, current rewards: 24.13620, mean: 0.05887
[32m[0907 02-26-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18215, current rewards: 28.95792, mean: 0.06295
[32m[0907 02-26-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18275, current rewards: 33.77708, mean: 0.06623
[32m[0907 02-26-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18317, current rewards: 19.11830, mean: 0.03414
[32m[0907 02-26-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18362, current rewards: 24.19665, mean: 0.03967
[32m[0907 02-26-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18395, current rewards: 29.27668, mean: 0.04436
[32m[0907 02-26-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18423, current rewards: 35.33729, mean: 0.04977
[32m[0907 02-27-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18451, current rewards: 40.87923, mean: 0.05379
[32m[0907 02-27-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18472, current rewards: 46.03030, mean: 0.05683
[32m[0907 02-27-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18465, current rewards: 51.17694, mean: 0.05951
[32m[0907 02-27-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18456, current rewards: 56.32341, mean: 0.06189
[32m[0907 02-27-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18453, current rewards: 61.47088, mean: 0.06403
[32m[0907 02-27-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18447, current rewards: 56.06442, mean: 0.05551
[32m[0907 02-27-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18443, current rewards: 61.79646, mean: 0.05830
[32m[0907 02-28-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18439, current rewards: 66.72291, mean: 0.06011
[32m[0907 02-28-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18435, current rewards: 71.77585, mean: 0.06188
[32m[0907 02-28-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18420, current rewards: 76.70521, mean: 0.06339
[32m[0907 02-28-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18395, current rewards: 81.63317, mean: 0.06479
[32m[0907 02-28-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18370, current rewards: 86.56037, mean: 0.06608
[32m[0907 02-28-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18348, current rewards: 91.48743, mean: 0.06727
[32m[0907 02-29-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18327, current rewards: 96.41808, mean: 0.06838
[32m[0907 02-29-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18307, current rewards: 101.34845, mean: 0.06942
[32m[0907 02-29-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18290, current rewards: 95.33161, mean: 0.06313
[32m[0907 02-29-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18275, current rewards: 100.48704, mean: 0.06441
[32m[0907 02-29-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18257, current rewards: 105.78751, mean: 0.06571
[32m[0907 02-29-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18242, current rewards: 111.08641, mean: 0.06692
[32m[0907 02-29-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18228, current rewards: 116.39337, mean: 0.06807
[32m[0907 02-30-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18215, current rewards: 121.69362, mean: 0.06914
[32m[0907 02-30-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18202, current rewards: 126.99780, mean: 0.07016
[32m[0907 02-30-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18204, current rewards: 131.83460, mean: 0.07088
[32m[0907 02-30-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18207, current rewards: 137.18689, mean: 0.07183
[32m[0907 02-30-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18210, current rewards: 141.97031, mean: 0.07243
[32m[0907 02-30-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18212, current rewards: 147.28599, mean: 0.07328
[32m[0907 02-30-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18214, current rewards: 152.59688, mean: 0.07408
[32m[0907 02-31-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18216, current rewards: 157.90582, mean: 0.07484
[32m[0907 02-31-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18219, current rewards: 163.21742, mean: 0.07556
[32m[0907 02-31-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18225, current rewards: 168.52799, mean: 0.07626
[32m[0907 02-31-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18238, current rewards: 173.83377, mean: 0.07692
[32m[0907 02-31-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18251, current rewards: 179.14475, mean: 0.07755
[32m[0907 02-31-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18263, current rewards: 185.52358, mean: 0.07861
[32m[0907 02-32-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18273, current rewards: 190.85821, mean: 0.07919
[32m[0907 02-32-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18286, current rewards: 196.18277, mean: 0.07975
[32m[0907 02-32-19 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0907 02-32-19 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-32-19 @MBExp.py:227][0m Rewards obtained: [200.44558087754612], Lows: [11], Highs: [33], Total time: 38821.00580099999
[32m[0907 02-35-15 @MBExp.py:144][0m ####################################################################
[32m[0907 02-35-15 @MBExp.py:145][0m Starting training iteration 86.
[32m[0907 02-35-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18161, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-35-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18291, current rewards: -5.17015, mean: -0.08617
[32m[0907 02-35-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18336, current rewards: 1.32191, mean: 0.01202
[32m[0907 02-35-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18346, current rewards: 7.81486, mean: 0.04884
[32m[0907 02-35-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18356, current rewards: 14.32032, mean: 0.06819
[32m[0907 02-36-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18354, current rewards: 23.19414, mean: 0.08921
[32m[0907 02-36-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18352, current rewards: 32.00235, mean: 0.10323
[32m[0907 02-36-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18357, current rewards: 38.73700, mean: 0.10760
[32m[0907 02-36-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18375, current rewards: 45.47695, mean: 0.11092
[32m[0907 02-36-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18415, current rewards: 52.20417, mean: 0.11349
[32m[0907 02-36-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18453, current rewards: 58.92996, mean: 0.11555
[32m[0907 02-36-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18488, current rewards: 65.66607, mean: 0.11726
[32m[0907 02-37-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18520, current rewards: 63.31950, mean: 0.10380
[32m[0907 02-37-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18544, current rewards: 65.89119, mean: 0.09984
[32m[0907 02-37-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18569, current rewards: 71.68554, mean: 0.10097
[32m[0907 02-37-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18585, current rewards: 77.71531, mean: 0.10226
[32m[0907 02-37-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18586, current rewards: 61.05219, mean: 0.07537
[32m[0907 02-37-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18569, current rewards: 65.22503, mean: 0.07584
[32m[0907 02-38-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18552, current rewards: 69.39786, mean: 0.07626
[32m[0907 02-38-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18541, current rewards: 73.57070, mean: 0.07664
[32m[0907 02-38-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18528, current rewards: 77.74353, mean: 0.07697
[32m[0907 02-38-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18518, current rewards: 75.41563, mean: 0.07115
[32m[0907 02-38-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18508, current rewards: 25.41563, mean: 0.02290
[32m[0907 02-38-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18499, current rewards: -24.58437, mean: -0.02119
[32m[0907 02-38-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18490, current rewards: -74.58437, mean: -0.06164
[32m[0907 02-39-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18458, current rewards: -124.58437, mean: -0.09888
[32m[0907 02-39-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18430, current rewards: -174.58437, mean: -0.13327
[32m[0907 02-39-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18403, current rewards: -224.58437, mean: -0.16514
[32m[0907 02-39-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18378, current rewards: -274.58437, mean: -0.19474
[32m[0907 02-39-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18357, current rewards: -324.58437, mean: -0.22232
[32m[0907 02-39-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18337, current rewards: -374.58437, mean: -0.24807
[32m[0907 02-40-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18317, current rewards: -424.58437, mean: -0.27217
[32m[0907 02-40-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18297, current rewards: -474.58437, mean: -0.29477
[32m[0907 02-40-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18281, current rewards: -524.58437, mean: -0.31601
[32m[0907 02-40-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18265, current rewards: -574.58437, mean: -0.33601
[32m[0907 02-40-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18250, current rewards: -624.58437, mean: -0.35488
[32m[0907 02-40-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18236, current rewards: -674.58437, mean: -0.37270
[32m[0907 02-40-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18239, current rewards: -724.58437, mean: -0.38956
[32m[0907 02-41-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18242, current rewards: -774.58437, mean: -0.40554
[32m[0907 02-41-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18242, current rewards: -824.58437, mean: -0.42071
[32m[0907 02-41-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18244, current rewards: -874.58437, mean: -0.43512
[32m[0907 02-41-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18245, current rewards: -924.58437, mean: -0.44883
[32m[0907 02-41-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18246, current rewards: -974.58437, mean: -0.46189
[32m[0907 02-41-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18247, current rewards: -1024.58437, mean: -0.47434
[32m[0907 02-41-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18250, current rewards: -1074.58437, mean: -0.48624
[32m[0907 02-42-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18263, current rewards: -1124.58437, mean: -0.49760
[32m[0907 02-42-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18276, current rewards: -1174.58437, mean: -0.50848
[32m[0907 02-42-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18288, current rewards: -1224.58437, mean: -0.51889
[32m[0907 02-42-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18298, current rewards: -1274.58437, mean: -0.52887
[32m[0907 02-42-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18308, current rewards: -1324.58437, mean: -0.53845
[32m[0907 02-42-54 @Agent.py:117][0m Average action selection time: 0.1831
[32m[0907 02-42-54 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-42-54 @MBExp.py:227][0m Rewards obtained: [-1364.5843739079985], Lows: [11], Highs: [1468], Total time: 39279.653140999995
[32m[0907 02-45-51 @MBExp.py:144][0m ####################################################################
[32m[0907 02-45-51 @MBExp.py:145][0m Starting training iteration 87.
[32m[0907 02-45-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18077, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-46-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19096, current rewards: -77.86251, mean: -1.29771
[32m[0907 02-46-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.21332, current rewards: -127.86251, mean: -1.16239
[32m[0907 02-46-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.22151, current rewards: -177.86251, mean: -1.11164
[32m[0907 02-46-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.22438, current rewards: -227.86251, mean: -1.08506
[32m[0907 02-46-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.22703, current rewards: -277.86251, mean: -1.06870
[32m[0907 02-47-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.22916, current rewards: -327.86251, mean: -1.05762
[32m[0907 02-47-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.23085, current rewards: -377.86251, mean: -1.04962
[32m[0907 02-47-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.23277, current rewards: -427.86251, mean: -1.04357
[32m[0907 02-47-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.23416, current rewards: -477.86251, mean: -1.03883
[32m[0907 02-47-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.23606, current rewards: -527.86251, mean: -1.03502
[32m[0907 02-48-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.23732, current rewards: -577.86251, mean: -1.03190
[32m[0907 02-48-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.23779, current rewards: -627.86251, mean: -1.02928
[32m[0907 02-48-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.23802, current rewards: -677.86251, mean: -1.02706
[32m[0907 02-48-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.23817, current rewards: -727.86251, mean: -1.02516
[32m[0907 02-48-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.23857, current rewards: -777.86251, mean: -1.02350
[32m[0907 02-49-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.23660, current rewards: -818.13876, mean: -1.01005
[32m[0907 02-49-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.23349, current rewards: -813.21871, mean: -0.94560
[32m[0907 02-49-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.23073, current rewards: -808.32211, mean: -0.88827
[32m[0907 02-49-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.22825, current rewards: -803.42586, mean: -0.83690
[32m[0907 02-49-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.22596, current rewards: -798.53500, mean: -0.79063
[32m[0907 02-49-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.22366, current rewards: -793.73653, mean: -0.74881
[32m[0907 02-49-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.22156, current rewards: -788.84529, mean: -0.71067
[32m[0907 02-50-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.21966, current rewards: -783.95475, mean: -0.67582
[32m[0907 02-50-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.21792, current rewards: -779.06659, mean: -0.64386
[32m[0907 02-50-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.21632, current rewards: -774.17767, mean: -0.61443
[32m[0907 02-50-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.21484, current rewards: -769.29159, mean: -0.58725
[32m[0907 02-50-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.21348, current rewards: -764.40475, mean: -0.56206
[32m[0907 02-50-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.21218, current rewards: -759.51588, mean: -0.53866
[32m[0907 02-51-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.21099, current rewards: -752.70510, mean: -0.51555
[32m[0907 02-51-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.20988, current rewards: -747.80219, mean: -0.49523
[32m[0907 02-51-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.20884, current rewards: -742.89894, mean: -0.47622
[32m[0907 02-51-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.20802, current rewards: -750.35465, mean: -0.46606
[32m[0907 02-51-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.20727, current rewards: -740.26382, mean: -0.44594
[32m[0907 02-51-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.20657, current rewards: -724.17040, mean: -0.42349
[32m[0907 02-51-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.20592, current rewards: -721.56312, mean: -0.40998
[32m[0907 02-52-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.20530, current rewards: -702.01650, mean: -0.38785
[32m[0907 02-52-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.20470, current rewards: -714.45165, mean: -0.38411
[32m[0907 02-52-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.20414, current rewards: -692.68886, mean: -0.36266
[32m[0907 02-52-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.20360, current rewards: -687.29216, mean: -0.35066
[32m[0907 02-52-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.20310, current rewards: -713.58079, mean: -0.35502
[32m[0907 02-52-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.20273, current rewards: -707.41289, mean: -0.34340
[32m[0907 02-52-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.20237, current rewards: -701.24083, mean: -0.33234
[32m[0907 02-53-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.20204, current rewards: -696.19194, mean: -0.32231
[32m[0907 02-53-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.20171, current rewards: -703.54245, mean: -0.31835
[32m[0907 02-53-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.20141, current rewards: -698.39587, mean: -0.30902
[32m[0907 02-53-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.20103, current rewards: -693.92456, mean: -0.30040
[32m[0907 02-53-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.20065, current rewards: -688.82108, mean: -0.29187
[32m[0907 02-53-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.20030, current rewards: -683.71212, mean: -0.28370
[32m[0907 02-54-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.19996, current rewards: -678.60792, mean: -0.27586
[32m[0907 02-54-11 @Agent.py:117][0m Average action selection time: 0.1997
[32m[0907 02-54-11 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-54-11 @MBExp.py:227][0m Rewards obtained: [-695.1793389373515], Lows: [85], Highs: [783], Total time: 39779.684929999996
[32m[0907 02-57-12 @MBExp.py:144][0m ####################################################################
[32m[0907 02-57-12 @MBExp.py:145][0m Starting training iteration 88.
[32m[0907 02-57-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18361, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-57-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18775, current rewards: -38.44570, mean: -0.64076
[32m[0907 02-57-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18555, current rewards: -55.50008, mean: -0.50455
[32m[0907 02-57-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18471, current rewards: -49.81771, mean: -0.31136
[32m[0907 02-57-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18429, current rewards: -43.10530, mean: -0.20526
[32m[0907 02-57-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18412, current rewards: -36.88747, mean: -0.14187
[32m[0907 02-58-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18456, current rewards: -30.68590, mean: -0.09899
[32m[0907 02-58-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18516, current rewards: -24.48345, mean: -0.06801
[32m[0907 02-58-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18664, current rewards: -66.32364, mean: -0.16176
[32m[0907 02-58-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18833, current rewards: -120.50987, mean: -0.26198
[32m[0907 02-58-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18929, current rewards: -175.32071, mean: -0.34377
[32m[0907 02-58-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18906, current rewards: -226.17649, mean: -0.40389
[32m[0907 02-59-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18928, current rewards: -280.47192, mean: -0.45979
[32m[0907 02-59-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18924, current rewards: -331.92561, mean: -0.50292
[32m[0907 02-59-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18945, current rewards: -399.05548, mean: -0.56205
[32m[0907 02-59-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18941, current rewards: -444.82521, mean: -0.58530
[32m[0907 02-59-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18903, current rewards: -505.34927, mean: -0.62389
[32m[0907 02-59-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18877, current rewards: -566.30170, mean: -0.65849
[32m[0907 03-00-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18859, current rewards: -621.28519, mean: -0.68273
[32m[0907 03-00-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18829, current rewards: -648.12177, mean: -0.67513
[32m[0907 03-00-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18801, current rewards: -691.10988, mean: -0.68427
[32m[0907 03-00-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18839, current rewards: -674.10215, mean: -0.63595
[32m[0907 03-00-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18941, current rewards: -647.15957, mean: -0.58303
[32m[0907 03-00-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18894, current rewards: -660.93244, mean: -0.56977
[32m[0907 03-01-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18844, current rewards: -655.74534, mean: -0.54194
[32m[0907 03-01-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18801, current rewards: -650.44780, mean: -0.51623
[32m[0907 03-01-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18759, current rewards: -644.48741, mean: -0.49198
[32m[0907 03-01-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18720, current rewards: -639.64132, mean: -0.47032
[32m[0907 03-01-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18685, current rewards: -645.10142, mean: -0.45752
[32m[0907 03-01-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18663, current rewards: -682.33698, mean: -0.46735
[32m[0907 03-01-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18644, current rewards: -704.02048, mean: -0.46624
[32m[0907 03-02-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18622, current rewards: -698.90113, mean: -0.44801
[32m[0907 03-02-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18619, current rewards: -692.03174, mean: -0.42983
[32m[0907 03-02-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18610, current rewards: -684.33802, mean: -0.41225
[32m[0907 03-02-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18615, current rewards: -704.52979, mean: -0.41201
[32m[0907 03-02-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18604, current rewards: -745.70628, mean: -0.42370
[32m[0907 03-02-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18602, current rewards: -772.72018, mean: -0.42692
[32m[0907 03-02-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18609, current rewards: -775.64153, mean: -0.41701
[32m[0907 03-03-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18601, current rewards: -763.87803, mean: -0.39994
[32m[0907 03-03-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18601, current rewards: -763.79170, mean: -0.38969
[32m[0907 03-03-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18594, current rewards: -755.27989, mean: -0.37576
[32m[0907 03-03-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18604, current rewards: -757.84092, mean: -0.36788
[32m[0907 03-03-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18616, current rewards: -823.28578, mean: -0.39018
[32m[0907 03-03-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18657, current rewards: -853.15350, mean: -0.39498
[32m[0907 03-04-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18727, current rewards: -853.54149, mean: -0.38622
[32m[0907 03-04-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18762, current rewards: -892.27386, mean: -0.39481
[32m[0907 03-04-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18764, current rewards: -949.32380, mean: -0.41096
[32m[0907 03-04-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18768, current rewards: -1033.08132, mean: -0.43775
[32m[0907 03-04-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18797, current rewards: -1097.76324, mean: -0.45550
[32m[0907 03-04-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18820, current rewards: -1172.43272, mean: -0.47660
[32m[0907 03-05-02 @Agent.py:117][0m Average action selection time: 0.1881
[32m[0907 03-05-02 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-05-03 @MBExp.py:227][0m Rewards obtained: [-1207.8821078067335], Lows: [750], Highs: [52], Total time: 40250.880485999995
[32m[0907 03-08-05 @MBExp.py:144][0m ####################################################################
[32m[0907 03-08-05 @MBExp.py:145][0m Starting training iteration 89.
[32m[0907 03-08-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30336, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-08-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20613, current rewards: -91.27992, mean: -1.52133
[32m[0907 03-08-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19570, current rewards: -191.27992, mean: -1.73891
[32m[0907 03-08-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19158, current rewards: -291.27992, mean: -1.82050
[32m[0907 03-08-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18959, current rewards: -391.27992, mean: -1.86324
[32m[0907 03-08-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18938, current rewards: -491.27992, mean: -1.88954
[32m[0907 03-09-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18911, current rewards: -591.27992, mean: -1.90735
[32m[0907 03-09-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18892, current rewards: -691.27992, mean: -1.92022
[32m[0907 03-09-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18870, current rewards: -791.27992, mean: -1.92995
[32m[0907 03-09-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18863, current rewards: -888.86655, mean: -1.93232
[32m[0907 03-09-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18853, current rewards: -988.86655, mean: -1.93895
[32m[0907 03-09-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18839, current rewards: -1088.86655, mean: -1.94440
[32m[0907 03-10-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18800, current rewards: -1188.86655, mean: -1.94896
[32m[0907 03-10-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18767, current rewards: -1288.86655, mean: -1.95283
[32m[0907 03-10-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18736, current rewards: -1388.86655, mean: -1.95615
[32m[0907 03-10-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18710, current rewards: -1488.86655, mean: -1.95903
[32m[0907 03-10-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18683, current rewards: -1588.86655, mean: -1.96156
[32m[0907 03-10-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18663, current rewards: -1688.86655, mean: -1.96380
[32m[0907 03-10-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18640, current rewards: -1788.86655, mean: -1.96579
[32m[0907 03-11-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18621, current rewards: -1888.86655, mean: -1.96757
[32m[0907 03-11-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18576, current rewards: -1988.86655, mean: -1.96917
[32m[0907 03-11-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18534, current rewards: -2088.86655, mean: -1.97063
[32m[0907 03-11-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18501, current rewards: -2188.86655, mean: -1.97195
[32m[0907 03-11-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18467, current rewards: -2288.86655, mean: -1.97316
[32m[0907 03-11-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18436, current rewards: -2388.86655, mean: -1.97427
[32m[0907 03-11-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18408, current rewards: -2488.86655, mean: -1.97529
[32m[0907 03-12-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18383, current rewards: -2588.86655, mean: -1.97623
[32m[0907 03-12-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18360, current rewards: -2688.86655, mean: -1.97711
[32m[0907 03-12-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18336, current rewards: -2788.86655, mean: -1.97792
[32m[0907 03-12-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18317, current rewards: -2888.86655, mean: -1.97868
[32m[0907 03-12-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18297, current rewards: -2988.86655, mean: -1.97938
[32m[0907 03-12-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18278, current rewards: -3088.86655, mean: -1.98004
[32m[0907 03-12-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18264, current rewards: -3188.86655, mean: -1.98066
[32m[0907 03-13-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18266, current rewards: -3288.86655, mean: -1.98124
[32m[0907 03-13-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18267, current rewards: -3388.86655, mean: -1.98179
[32m[0907 03-13-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18268, current rewards: -3488.86655, mean: -1.98231
[32m[0907 03-13-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18269, current rewards: -3588.86655, mean: -1.98280
[32m[0907 03-13-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18272, current rewards: -3688.86655, mean: -1.98326
[32m[0907 03-13-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18273, current rewards: -3788.86655, mean: -1.98370
[32m[0907 03-14-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18275, current rewards: -3888.86655, mean: -1.98412
[32m[0907 03-14-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18280, current rewards: -3988.86655, mean: -1.98451
[32m[0907 03-14-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18294, current rewards: -4088.86655, mean: -1.98489
[32m[0907 03-14-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18307, current rewards: -4188.86655, mean: -1.98524
[32m[0907 03-14-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18318, current rewards: -4288.86655, mean: -1.98559
[32m[0907 03-14-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18329, current rewards: -4388.86655, mean: -1.98591
[32m[0907 03-15-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18339, current rewards: -4488.86655, mean: -1.98622
[32m[0907 03-15-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18339, current rewards: -4588.86655, mean: -1.98652
[32m[0907 03-15-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18338, current rewards: -4688.86655, mean: -1.98681
[32m[0907 03-15-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18337, current rewards: -4788.86655, mean: -1.98708
[32m[0907 03-15-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18335, current rewards: -4888.86655, mean: -1.98734
[32m[0907 03-15-44 @Agent.py:117][0m Average action selection time: 0.1833
[32m[0907 03-15-44 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-15-44 @MBExp.py:227][0m Rewards obtained: [-4968.866553242537], Lows: [2477], Highs: [16], Total time: 40710.061258999995
[32m[0907 03-18-48 @MBExp.py:144][0m ####################################################################
[32m[0907 03-18-48 @MBExp.py:145][0m Starting training iteration 90.
[32m[0907 03-18-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19308, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-19-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19757, current rewards: -54.08004, mean: -0.90133
[32m[0907 03-19-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.20249, current rewards: -98.75224, mean: -0.89775
[32m[0907 03-19-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.20170, current rewards: -144.48586, mean: -0.90304
[32m[0907 03-19-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.20513, current rewards: -191.64954, mean: -0.91262
[32m[0907 03-19-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.20408, current rewards: -237.89063, mean: -0.91496
[32m[0907 03-19-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.20524, current rewards: -283.42808, mean: -0.91428
[32m[0907 03-20-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.20624, current rewards: -330.17250, mean: -0.91715
[32m[0907 03-20-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.20650, current rewards: -379.04273, mean: -0.92449
[32m[0907 03-20-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.20484, current rewards: -426.59016, mean: -0.92737
[32m[0907 03-20-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.20361, current rewards: -474.29572, mean: -0.92999
[32m[0907 03-20-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.20181, current rewards: -522.16293, mean: -0.93243
[32m[0907 03-20-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.20029, current rewards: -572.16293, mean: -0.93797
[32m[0907 03-20-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19898, current rewards: -622.16293, mean: -0.94267
[32m[0907 03-21-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19788, current rewards: -672.16293, mean: -0.94671
[32m[0907 03-21-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19690, current rewards: -722.16293, mean: -0.95021
[32m[0907 03-21-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19602, current rewards: -772.16293, mean: -0.95329
[32m[0907 03-21-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19526, current rewards: -822.16293, mean: -0.95600
[32m[0907 03-21-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19451, current rewards: -872.16293, mean: -0.95842
[32m[0907 03-21-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19361, current rewards: -922.16293, mean: -0.96059
[32m[0907 03-22-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19281, current rewards: -972.16293, mean: -0.96254
[32m[0907 03-22-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19209, current rewards: -1022.16293, mean: -0.96430
[32m[0907 03-22-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19143, current rewards: -1072.16293, mean: -0.96591
[32m[0907 03-22-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19082, current rewards: -1122.16293, mean: -0.96738
[32m[0907 03-22-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19026, current rewards: -1172.16293, mean: -0.96873
[32m[0907 03-22-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18975, current rewards: -1222.16293, mean: -0.96997
[32m[0907 03-22-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18927, current rewards: -1272.16293, mean: -0.97112
[32m[0907 03-23-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18882, current rewards: -1322.16293, mean: -0.97218
[32m[0907 03-23-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18843, current rewards: -1372.16293, mean: -0.97317
[32m[0907 03-23-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18806, current rewards: -1422.16293, mean: -0.97408
[32m[0907 03-23-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18769, current rewards: -1472.16293, mean: -0.97494
[32m[0907 03-23-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18741, current rewards: -1522.16293, mean: -0.97575
[32m[0907 03-23-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18727, current rewards: -1572.16293, mean: -0.97650
[32m[0907 03-23-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18715, current rewards: -1622.16293, mean: -0.97721
[32m[0907 03-24-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18703, current rewards: -1672.16293, mean: -0.97787
[32m[0907 03-24-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18691, current rewards: -1721.11464, mean: -0.97791
[32m[0907 03-24-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18681, current rewards: -1715.25202, mean: -0.94765
[32m[0907 03-24-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18671, current rewards: -1707.97781, mean: -0.91827
[32m[0907 03-24-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18661, current rewards: -1700.70359, mean: -0.89042
[32m[0907 03-24-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18654, current rewards: -1712.90261, mean: -0.87393
[32m[0907 03-25-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18659, current rewards: -1762.90261, mean: -0.87707
[32m[0907 03-25-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18664, current rewards: -1812.90261, mean: -0.88005
[32m[0907 03-25-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18667, current rewards: -1862.90261, mean: -0.88289
[32m[0907 03-25-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18668, current rewards: -1912.90261, mean: -0.88560
[32m[0907 03-25-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18672, current rewards: -1962.90261, mean: -0.88819
[32m[0907 03-25-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18667, current rewards: -2012.90261, mean: -0.89066
[32m[0907 03-25-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18660, current rewards: -2062.90261, mean: -0.89303
[32m[0907 03-26-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18653, current rewards: -2112.90261, mean: -0.89530
[32m[0907 03-26-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18646, current rewards: -2162.90261, mean: -0.89747
[32m[0907 03-26-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18638, current rewards: -2212.90261, mean: -0.89955
[32m[0907 03-26-34 @Agent.py:117][0m Average action selection time: 0.1863
[32m[0907 03-26-34 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-26-34 @MBExp.py:227][0m Rewards obtained: [-2252.902613822881], Lows: [18], Highs: [2247], Total time: 41176.72160999999
[32m[0907 03-29-41 @MBExp.py:144][0m ####################################################################
[32m[0907 03-29-41 @MBExp.py:145][0m Starting training iteration 91.
[32m[0907 03-29-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18268, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-29-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18391, current rewards: -19.88698, mean: -0.33145
[32m[0907 03-30-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18359, current rewards: -13.90899, mean: -0.12645
[32m[0907 03-30-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18349, current rewards: -8.66194, mean: -0.05414
[32m[0907 03-30-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18324, current rewards: -2.59929, mean: -0.01238
[32m[0907 03-30-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18330, current rewards: 3.46927, mean: 0.01334
[32m[0907 03-30-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18420, current rewards: 9.53830, mean: 0.03077
[32m[0907 03-30-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18473, current rewards: 15.60473, mean: 0.04335
[32m[0907 03-30-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18506, current rewards: 21.67278, mean: 0.05286
[32m[0907 03-31-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18534, current rewards: 27.73865, mean: 0.06030
[32m[0907 03-31-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18511, current rewards: 33.80476, mean: 0.06628
[32m[0907 03-31-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18498, current rewards: 39.18651, mean: 0.06998
[32m[0907 03-31-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18483, current rewards: 45.33727, mean: 0.07432
[32m[0907 03-31-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18473, current rewards: 23.58460, mean: 0.03573
[32m[0907 03-31-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18463, current rewards: 12.77981, mean: 0.01800
[32m[0907 03-32-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18452, current rewards: 2.26540, mean: 0.00298
[32m[0907 03-32-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18451, current rewards: -5.09351, mean: -0.00629
[32m[0907 03-32-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18480, current rewards: -5.25114, mean: -0.00611
[32m[0907 03-32-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18462, current rewards: -30.60708, mean: -0.03363
[32m[0907 03-32-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18445, current rewards: -52.26470, mean: -0.05444
[32m[0907 03-32-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18410, current rewards: -58.92362, mean: -0.05834
[32m[0907 03-32-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18378, current rewards: -62.61926, mean: -0.05907
[32m[0907 03-33-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18349, current rewards: -57.04474, mean: -0.05139
[32m[0907 03-33-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18323, current rewards: -51.46773, mean: -0.04437
[32m[0907 03-33-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18298, current rewards: -45.89094, mean: -0.03793
[32m[0907 03-33-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18276, current rewards: -40.31441, mean: -0.03200
[32m[0907 03-33-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18255, current rewards: -34.73433, mean: -0.02651
[32m[0907 03-33-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18234, current rewards: -29.16099, mean: -0.02144
[32m[0907 03-33-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18216, current rewards: -23.58103, mean: -0.01672
[32m[0907 03-34-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18199, current rewards: -18.00856, mean: -0.01233
[32m[0907 03-34-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18186, current rewards: -22.16273, mean: -0.01468
[32m[0907 03-34-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18205, current rewards: -55.54336, mean: -0.03560
[32m[0907 03-34-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18269, current rewards: -83.92468, mean: -0.05213
[32m[0907 03-34-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18294, current rewards: -120.24624, mean: -0.07244
[32m[0907 03-34-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18315, current rewards: -143.39633, mean: -0.08386
[32m[0907 03-35-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18357, current rewards: -173.23806, mean: -0.09843
[32m[0907 03-35-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18402, current rewards: -220.15546, mean: -0.12163
[32m[0907 03-35-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18433, current rewards: -245.60481, mean: -0.13205
[32m[0907 03-35-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18461, current rewards: -275.91613, mean: -0.14446
[32m[0907 03-35-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18497, current rewards: -335.17219, mean: -0.17101
[32m[0907 03-35-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18506, current rewards: -391.48071, mean: -0.19477
[32m[0907 03-36-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18525, current rewards: -446.95853, mean: -0.21697
[32m[0907 03-36-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18575, current rewards: -504.93269, mean: -0.23930
[32m[0907 03-36-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18597, current rewards: -564.70266, mean: -0.26144
[32m[0907 03-36-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18629, current rewards: -618.77623, mean: -0.27999
[32m[0907 03-36-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18677, current rewards: -669.50531, mean: -0.29624
[32m[0907 03-36-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18686, current rewards: -720.29345, mean: -0.31182
[32m[0907 03-37-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18704, current rewards: -778.34685, mean: -0.32981
[32m[0907 03-37-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18737, current rewards: -843.94254, mean: -0.35018
[32m[0907 03-37-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18774, current rewards: -883.69638, mean: -0.35923
[32m[0907 03-37-31 @Agent.py:117][0m Average action selection time: 0.1879
[32m[0907 03-37-31 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-37-31 @MBExp.py:227][0m Rewards obtained: [-916.9922048374001], Lows: [454], Highs: [247], Total time: 41647.34725199999
[32m[0907 03-40-40 @MBExp.py:144][0m ####################################################################
[32m[0907 03-40-40 @MBExp.py:145][0m Starting training iteration 92.
[32m[0907 03-40-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19474, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-40-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18714, current rewards: -105.56083, mean: -1.75935
[32m[0907 03-41-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18658, current rewards: -187.01578, mean: -1.70014
[32m[0907 03-41-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18579, current rewards: -282.67461, mean: -1.76672
[32m[0907 03-41-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18708, current rewards: -369.28215, mean: -1.75849
[32m[0907 03-41-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18805, current rewards: -459.03002, mean: -1.76550
[32m[0907 03-41-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18848, current rewards: -558.03002, mean: -1.80010
[32m[0907 03-41-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18840, current rewards: -646.34699, mean: -1.79541
[32m[0907 03-41-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18833, current rewards: -733.42831, mean: -1.78885
[32m[0907 03-42-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18793, current rewards: -829.17505, mean: -1.80255
[32m[0907 03-42-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18745, current rewards: -924.85389, mean: -1.81344
[32m[0907 03-42-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18713, current rewards: -1022.06252, mean: -1.82511
[32m[0907 03-42-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18684, current rewards: -1113.52271, mean: -1.82545
[32m[0907 03-42-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18658, current rewards: -1209.25857, mean: -1.83221
[32m[0907 03-42-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18633, current rewards: -1305.07430, mean: -1.83813
[32m[0907 03-43-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18618, current rewards: -1396.40770, mean: -1.83738
[32m[0907 03-43-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18609, current rewards: -1489.42629, mean: -1.83880
[32m[0907 03-43-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18621, current rewards: -1585.17296, mean: -1.84322
[32m[0907 03-43-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18589, current rewards: -1685.17296, mean: -1.85184
[32m[0907 03-43-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18554, current rewards: -1785.17296, mean: -1.85956
[32m[0907 03-43-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18513, current rewards: -1885.17296, mean: -1.86651
[32m[0907 03-43-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18479, current rewards: -1985.17296, mean: -1.87280
[32m[0907 03-44-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18447, current rewards: -2085.17296, mean: -1.87853
[32m[0907 03-44-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18417, current rewards: -2185.17296, mean: -1.88377
[32m[0907 03-44-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18391, current rewards: -2285.17296, mean: -1.88857
[32m[0907 03-44-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18365, current rewards: -2385.17296, mean: -1.89299
[32m[0907 03-44-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18342, current rewards: -2485.17296, mean: -1.89708
[32m[0907 03-44-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18328, current rewards: -2585.17296, mean: -1.90086
[32m[0907 03-44-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18308, current rewards: -2593.85124, mean: -1.83961
[32m[0907 03-45-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18294, current rewards: -2588.50407, mean: -1.77295
[32m[0907 03-45-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18295, current rewards: -2583.15690, mean: -1.71070
[32m[0907 03-45-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18295, current rewards: -2577.80974, mean: -1.65244
[32m[0907 03-45-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18296, current rewards: -2572.46257, mean: -1.59780
[32m[0907 03-45-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18297, current rewards: -2567.11540, mean: -1.54646
[32m[0907 03-45-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18296, current rewards: -2561.76824, mean: -1.49811
[32m[0907 03-46-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18296, current rewards: -2557.18571, mean: -1.45295
[32m[0907 03-46-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18297, current rewards: -2610.27036, mean: -1.44214
[32m[0907 03-46-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18296, current rewards: -2710.27036, mean: -1.45713
[32m[0907 03-46-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18296, current rewards: -2810.27036, mean: -1.47135
[32m[0907 03-46-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18296, current rewards: -2910.27036, mean: -1.48483
[32m[0907 03-46-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18309, current rewards: -3010.27036, mean: -1.49765
[32m[0907 03-46-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18321, current rewards: -3110.27036, mean: -1.50984
[32m[0907 03-47-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18333, current rewards: -3210.27036, mean: -1.52146
[32m[0907 03-47-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18342, current rewards: -3310.27036, mean: -1.53253
[32m[0907 03-47-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18353, current rewards: -3410.27036, mean: -1.54311
[32m[0907 03-47-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18357, current rewards: -3510.27036, mean: -1.55322
[32m[0907 03-47-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18356, current rewards: -3610.27036, mean: -1.56289
[32m[0907 03-47-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18365, current rewards: -3686.98372, mean: -1.56228
[32m[0907 03-48-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18365, current rewards: -3786.98372, mean: -1.57136
[32m[0907 03-48-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18364, current rewards: -3886.98372, mean: -1.58007
[32m[0907 03-48-20 @Agent.py:117][0m Average action selection time: 0.1836
[32m[0907 03-48-20 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-48-20 @MBExp.py:227][0m Rewards obtained: [-3966.983715961015], Lows: [1999], Highs: [26], Total time: 42107.25962799999
[32m[0907 03-51-30 @MBExp.py:144][0m ####################################################################
[32m[0907 03-51-30 @MBExp.py:145][0m Starting training iteration 93.
[32m[0907 03-51-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30311, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-51-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.27539, current rewards: -60.00000, mean: -1.00000
[32m[0907 03-51-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.23347, current rewards: -110.00000, mean: -1.00000
[32m[0907 03-52-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.21808, current rewards: -160.00000, mean: -1.00000
[32m[0907 03-52-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.21091, current rewards: -210.00000, mean: -1.00000
[32m[0907 03-52-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.20648, current rewards: -260.00000, mean: -1.00000
[32m[0907 03-52-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.20347, current rewards: -310.00000, mean: -1.00000
[32m[0907 03-52-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.20056, current rewards: -360.00000, mean: -1.00000
[32m[0907 03-52-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19844, current rewards: -410.00000, mean: -1.00000
[32m[0907 03-53-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19679, current rewards: -460.00000, mean: -1.00000
[32m[0907 03-53-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19547, current rewards: -510.00000, mean: -1.00000
[32m[0907 03-53-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19438, current rewards: -560.00000, mean: -1.00000
[32m[0907 03-53-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19345, current rewards: -610.00000, mean: -1.00000
[32m[0907 03-53-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19269, current rewards: -660.00000, mean: -1.00000
[32m[0907 03-53-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19205, current rewards: -710.00000, mean: -1.00000
[32m[0907 03-53-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19142, current rewards: -760.00000, mean: -1.00000
[32m[0907 03-54-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19089, current rewards: -810.00000, mean: -1.00000
[32m[0907 03-54-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19028, current rewards: -860.00000, mean: -1.00000
[32m[0907 03-54-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18958, current rewards: -910.00000, mean: -1.00000
[32m[0907 03-54-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18896, current rewards: -960.00000, mean: -1.00000
[32m[0907 03-54-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18836, current rewards: -1010.00000, mean: -1.00000
[32m[0907 03-54-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18784, current rewards: -1060.00000, mean: -1.00000
[32m[0907 03-54-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18735, current rewards: -1110.00000, mean: -1.00000
[32m[0907 03-55-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18693, current rewards: -1160.00000, mean: -1.00000
[32m[0907 03-55-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18654, current rewards: -1210.00000, mean: -1.00000
[32m[0907 03-55-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18617, current rewards: -1260.00000, mean: -1.00000
[32m[0907 03-55-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18581, current rewards: -1310.00000, mean: -1.00000
[32m[0907 03-55-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18550, current rewards: -1360.00000, mean: -1.00000
[32m[0907 03-55-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18523, current rewards: -1396.20955, mean: -0.99022
[32m[0907 03-56-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18517, current rewards: -1388.74936, mean: -0.95120
[32m[0907 03-56-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18512, current rewards: -1381.28917, mean: -0.91476
[32m[0907 03-56-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18506, current rewards: -1373.82898, mean: -0.88066
[32m[0907 03-56-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18499, current rewards: -1366.36879, mean: -0.84868
[32m[0907 03-56-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18492, current rewards: -1358.90860, mean: -0.81862
[32m[0907 03-56-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18488, current rewards: -1405.46099, mean: -0.82191
[32m[0907 03-56-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18482, current rewards: -1455.46099, mean: -0.82697
[32m[0907 03-57-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18478, current rewards: -1505.46099, mean: -0.83175
[32m[0907 03-57-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18474, current rewards: -1555.46099, mean: -0.83627
[32m[0907 03-57-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18469, current rewards: -1605.46099, mean: -0.84056
[32m[0907 03-57-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18473, current rewards: -1655.46099, mean: -0.84462
[32m[0907 03-57-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18484, current rewards: -1705.46099, mean: -0.84849
[32m[0907 03-57-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18492, current rewards: -1755.46099, mean: -0.85217
[32m[0907 03-58-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18500, current rewards: -1805.46099, mean: -0.85567
[32m[0907 03-58-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18507, current rewards: -1855.46099, mean: -0.85901
[32m[0907 03-58-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18515, current rewards: -1905.46099, mean: -0.86220
[32m[0907 03-58-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18510, current rewards: -1955.46099, mean: -0.86525
[32m[0907 03-58-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18504, current rewards: -2005.46099, mean: -0.86816
[32m[0907 03-58-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18500, current rewards: -2055.46099, mean: -0.87096
[32m[0907 03-58-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18497, current rewards: -2105.46099, mean: -0.87364
[32m[0907 03-59-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18494, current rewards: -2155.46099, mean: -0.87620
[32m[0907 03-59-13 @Agent.py:117][0m Average action selection time: 0.1849
[32m[0907 03-59-13 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-59-13 @MBExp.py:227][0m Rewards obtained: [-2195.4609897590844], Lows: [0], Highs: [2235], Total time: 42570.37253999999
[32m[0907 04-02-26 @MBExp.py:144][0m ####################################################################
[32m[0907 04-02-26 @MBExp.py:145][0m Starting training iteration 94.
[32m[0907 04-02-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18260, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-02-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19007, current rewards: -73.84548, mean: -1.23076
[32m[0907 04-02-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19198, current rewards: -134.14851, mean: -1.21953
[32m[0907 04-02-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19331, current rewards: -202.73450, mean: -1.26709
[32m[0907 04-03-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19609, current rewards: -269.11297, mean: -1.28149
[32m[0907 04-03-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19633, current rewards: -334.34200, mean: -1.28593
[32m[0907 04-03-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19706, current rewards: -403.20558, mean: -1.30066
[32m[0907 04-03-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19674, current rewards: -468.89705, mean: -1.30249
[32m[0907 04-03-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19770, current rewards: -541.77430, mean: -1.32140
[32m[0907 04-03-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19778, current rewards: -607.31131, mean: -1.32024
[32m[0907 04-04-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19727, current rewards: -680.61591, mean: -1.33454
[32m[0907 04-04-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19693, current rewards: -749.92043, mean: -1.33914
[32m[0907 04-04-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19704, current rewards: -818.12289, mean: -1.34119
[32m[0907 04-04-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19728, current rewards: -894.60312, mean: -1.35546
[32m[0907 04-04-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19755, current rewards: -956.95893, mean: -1.34783
[32m[0907 04-04-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19748, current rewards: -1026.07577, mean: -1.35010
[32m[0907 04-05-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19793, current rewards: -1095.77632, mean: -1.35281
[32m[0907 04-05-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19737, current rewards: -1168.16565, mean: -1.35833
[32m[0907 04-05-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19656, current rewards: -1243.71500, mean: -1.36672
[32m[0907 04-05-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19599, current rewards: -1303.35823, mean: -1.35766
[32m[0907 04-05-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19617, current rewards: -1353.91939, mean: -1.34051
[32m[0907 04-05-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19565, current rewards: -1417.69032, mean: -1.33744
[32m[0907 04-06-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19500, current rewards: -1464.42839, mean: -1.31930
[32m[0907 04-06-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19488, current rewards: -1534.22399, mean: -1.32261
[32m[0907 04-06-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19489, current rewards: -1600.29285, mean: -1.32256
[32m[0907 04-06-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19460, current rewards: -1659.92768, mean: -1.31740
[32m[0907 04-06-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.19412, current rewards: -1739.05690, mean: -1.32752
[32m[0907 04-06-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.19352, current rewards: -1736.48797, mean: -1.27683
[32m[0907 04-06-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.19296, current rewards: -1733.98957, mean: -1.22978
[32m[0907 04-07-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.19243, current rewards: -1731.47856, mean: -1.18594
[32m[0907 04-07-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.19194, current rewards: -1728.96135, mean: -1.14501
[32m[0907 04-07-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.19150, current rewards: -1726.46124, mean: -1.10671
[32m[0907 04-07-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.19106, current rewards: -1723.96502, mean: -1.07079
[32m[0907 04-07-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.19064, current rewards: -1721.44651, mean: -1.03702
[32m[0907 04-07-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.19077, current rewards: -1738.94826, mean: -1.01693
[32m[0907 04-08-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.19153, current rewards: -1833.92266, mean: -1.04200
[32m[0907 04-08-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.19238, current rewards: -1915.84667, mean: -1.05848
[32m[0907 04-08-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.19230, current rewards: -2011.56025, mean: -1.08148
[32m[0907 04-08-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.19221, current rewards: -2111.56025, mean: -1.10553
[32m[0907 04-08-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.19211, current rewards: -2211.56025, mean: -1.12835
[32m[0907 04-08-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.19200, current rewards: -2311.56025, mean: -1.15003
[32m[0907 04-09-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.19192, current rewards: -2411.56025, mean: -1.17066
[32m[0907 04-09-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.19181, current rewards: -2511.56025, mean: -1.19031
[32m[0907 04-09-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.19162, current rewards: -2611.56025, mean: -1.20906
[32m[0907 04-09-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.19142, current rewards: -2711.56025, mean: -1.22695
[32m[0907 04-09-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.19123, current rewards: -2811.56025, mean: -1.24405
[32m[0907 04-09-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.19105, current rewards: -2911.56025, mean: -1.26042
[32m[0907 04-09-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.19088, current rewards: -3011.56025, mean: -1.27608
[32m[0907 04-10-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.19072, current rewards: -3111.56025, mean: -1.29110
[32m[0907 04-10-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.19058, current rewards: -3211.56025, mean: -1.30551
[32m[0907 04-10-23 @Agent.py:117][0m Average action selection time: 0.1905
[32m[0907 04-10-23 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-10-23 @MBExp.py:227][0m Rewards obtained: [-3291.5602502255], Lows: [1520], Highs: [318], Total time: 43047.35715299999
[32m[0907 04-13-37 @MBExp.py:144][0m ####################################################################
[32m[0907 04-13-37 @MBExp.py:145][0m Starting training iteration 95.
[32m[0907 04-13-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29124, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-13-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.23799, current rewards: -100.78761, mean: -1.67979
[32m[0907 04-14-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.21286, current rewards: -200.78761, mean: -1.82534
[32m[0907 04-14-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.20549, current rewards: -300.78761, mean: -1.87992
[32m[0907 04-14-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.20126, current rewards: -400.78761, mean: -1.90851
[32m[0907 04-14-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19859, current rewards: -500.78761, mean: -1.92611
[32m[0907 04-14-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19678, current rewards: -600.78761, mean: -1.93802
[32m[0907 04-14-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19558, current rewards: -700.78761, mean: -1.94663
[32m[0907 04-14-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19471, current rewards: -800.78761, mean: -1.95314
[32m[0907 04-15-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19395, current rewards: -900.78761, mean: -1.95823
[32m[0907 04-15-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19339, current rewards: -1000.78761, mean: -1.96233
[32m[0907 04-15-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19288, current rewards: -1100.78761, mean: -1.96569
[32m[0907 04-15-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19248, current rewards: -1200.78761, mean: -1.96850
[32m[0907 04-15-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19219, current rewards: -1300.78761, mean: -1.97089
[32m[0907 04-15-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19172, current rewards: -1400.78761, mean: -1.97294
[32m[0907 04-16-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19089, current rewards: -1500.78761, mean: -1.97472
[32m[0907 04-16-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19006, current rewards: -1600.78761, mean: -1.97628
[32m[0907 04-16-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18933, current rewards: -1700.78761, mean: -1.97766
[32m[0907 04-16-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18867, current rewards: -1800.78761, mean: -1.97889
[32m[0907 04-16-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18808, current rewards: -1900.78761, mean: -1.97999
[32m[0907 04-16-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18755, current rewards: -2000.78761, mean: -1.98098
[32m[0907 04-16-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18708, current rewards: -2100.78761, mean: -1.98188
[32m[0907 04-17-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18664, current rewards: -2200.78761, mean: -1.98269
[32m[0907 04-17-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18623, current rewards: -2300.78761, mean: -1.98344
[32m[0907 04-17-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18585, current rewards: -2400.78761, mean: -1.98412
[32m[0907 04-17-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18551, current rewards: -2500.78761, mean: -1.98475
[32m[0907 04-17-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18520, current rewards: -2600.78761, mean: -1.98533
[32m[0907 04-17-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18492, current rewards: -2700.78761, mean: -1.98587
[32m[0907 04-17-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18465, current rewards: -2800.78761, mean: -1.98637
[32m[0907 04-18-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18440, current rewards: -2900.78761, mean: -1.98684
[32m[0907 04-18-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18416, current rewards: -3000.78761, mean: -1.98728
[32m[0907 04-18-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18395, current rewards: -3100.78761, mean: -1.98768
[32m[0907 04-18-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18376, current rewards: -3200.78761, mean: -1.98807
[32m[0907 04-18-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18357, current rewards: -3300.78761, mean: -1.98843
[32m[0907 04-18-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18339, current rewards: -3400.78761, mean: -1.98876
[32m[0907 04-19-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18323, current rewards: -3500.78761, mean: -1.98908
[32m[0907 04-19-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18308, current rewards: -3600.78761, mean: -1.98939
[32m[0907 04-19-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18311, current rewards: -3700.78761, mean: -1.98967
[32m[0907 04-19-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18325, current rewards: -3800.78761, mean: -1.98994
[32m[0907 04-19-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18388, current rewards: -3880.19353, mean: -1.97969
[32m[0907 04-19-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18417, current rewards: -3974.86816, mean: -1.97755
[32m[0907 04-19-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18480, current rewards: -4056.24977, mean: -1.96905
[32m[0907 04-20-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18496, current rewards: -4145.30280, mean: -1.96460
[32m[0907 04-20-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18543, current rewards: -4227.44350, mean: -1.95715
[32m[0907 04-20-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18582, current rewards: -4302.31450, mean: -1.94675
[32m[0907 04-20-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18577, current rewards: -4402.31450, mean: -1.94793
[32m[0907 04-20-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18571, current rewards: -4502.31450, mean: -1.94905
[32m[0907 04-20-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18565, current rewards: -4602.31450, mean: -1.95013
[32m[0907 04-21-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18561, current rewards: -4702.31450, mean: -1.95117
[32m[0907 04-21-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18555, current rewards: -4802.31450, mean: -1.95216
[32m[0907 04-21-21 @Agent.py:117][0m Average action selection time: 0.1855
[32m[0907 04-21-21 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-21-22 @MBExp.py:227][0m Rewards obtained: [-4882.314503294689], Lows: [2431], Highs: [31], Total time: 43511.96507799999
[32m[0907 04-24-38 @MBExp.py:144][0m ####################################################################
[32m[0907 04-24-38 @MBExp.py:145][0m Starting training iteration 96.
[32m[0907 04-24-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.21847, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-24-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19785, current rewards: -89.72170, mean: -1.49536
[32m[0907 04-24-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19355, current rewards: -164.44205, mean: -1.49493
[32m[0907 04-25-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19409, current rewards: -234.90479, mean: -1.46815
[32m[0907 04-25-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19481, current rewards: -310.78434, mean: -1.47993
[32m[0907 04-25-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19465, current rewards: -379.43950, mean: -1.45938
[32m[0907 04-25-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19453, current rewards: -465.55626, mean: -1.50179
[32m[0907 04-25-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19354, current rewards: -544.45638, mean: -1.51238
[32m[0907 04-25-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19298, current rewards: -593.33257, mean: -1.44715
[32m[0907 04-26-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19291, current rewards: -653.20654, mean: -1.42001
[32m[0907 04-26-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19336, current rewards: -748.87373, mean: -1.46838
[32m[0907 04-26-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19286, current rewards: -759.34288, mean: -1.35597
[32m[0907 04-26-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19235, current rewards: -755.46530, mean: -1.23847
[32m[0907 04-26-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19199, current rewards: -751.59548, mean: -1.13878
[32m[0907 04-26-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19149, current rewards: -747.71902, mean: -1.05313
[32m[0907 04-27-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19060, current rewards: -743.97649, mean: -0.97892
[32m[0907 04-27-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18981, current rewards: -740.11853, mean: -0.91373
[32m[0907 04-27-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18918, current rewards: -736.13637, mean: -0.85597
[32m[0907 04-27-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18853, current rewards: -738.84283, mean: -0.81192
[32m[0907 04-27-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18792, current rewards: -818.32268, mean: -0.85242
[32m[0907 04-27-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18739, current rewards: -918.32268, mean: -0.90923
[32m[0907 04-27-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18692, current rewards: -1018.32268, mean: -0.96068
[32m[0907 04-28-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18649, current rewards: -1118.32268, mean: -1.00750
[32m[0907 04-28-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18609, current rewards: -1218.32268, mean: -1.05028
[32m[0907 04-28-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18573, current rewards: -1318.32268, mean: -1.08952
[32m[0907 04-28-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18542, current rewards: -1418.32268, mean: -1.12565
[32m[0907 04-28-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18513, current rewards: -1518.32268, mean: -1.15902
[32m[0907 04-28-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18484, current rewards: -1618.32268, mean: -1.18994
[32m[0907 04-28-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18456, current rewards: -1718.32268, mean: -1.21867
[32m[0907 04-29-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18431, current rewards: -1818.32268, mean: -1.24543
[32m[0907 04-29-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18408, current rewards: -1918.32268, mean: -1.27041
[32m[0907 04-29-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18385, current rewards: -2018.32268, mean: -1.29380
[32m[0907 04-29-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18363, current rewards: -2118.32268, mean: -1.31573
[32m[0907 04-29-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18345, current rewards: -2218.32268, mean: -1.33634
[32m[0907 04-29-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18327, current rewards: -2318.32268, mean: -1.35574
[32m[0907 04-30-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18311, current rewards: -2418.32268, mean: -1.37405
[32m[0907 04-30-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18296, current rewards: -2518.32268, mean: -1.39134
[32m[0907 04-30-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18298, current rewards: -2618.32268, mean: -1.40770
[32m[0907 04-30-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18312, current rewards: -2718.32268, mean: -1.42321
[32m[0907 04-30-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18325, current rewards: -2818.32268, mean: -1.43792
[32m[0907 04-30-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18335, current rewards: -2918.32268, mean: -1.45190
[32m[0907 04-30-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18345, current rewards: -3018.32268, mean: -1.46521
[32m[0907 04-31-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18355, current rewards: -3118.32268, mean: -1.47788
[32m[0907 04-31-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18356, current rewards: -3218.32268, mean: -1.48996
[32m[0907 04-31-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18355, current rewards: -3318.32268, mean: -1.50150
[32m[0907 04-31-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18354, current rewards: -3418.32268, mean: -1.51253
[32m[0907 04-31-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18354, current rewards: -3518.32268, mean: -1.52308
[32m[0907 04-31-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18354, current rewards: -3618.32268, mean: -1.53319
[32m[0907 04-32-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18354, current rewards: -3718.32268, mean: -1.54287
[32m[0907 04-32-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18354, current rewards: -3818.32268, mean: -1.55216
[32m[0907 04-32-17 @Agent.py:117][0m Average action selection time: 0.1835
[32m[0907 04-32-17 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-32-18 @MBExp.py:227][0m Rewards obtained: [-3898.3226806302587], Lows: [1939], Highs: [76], Total time: 43971.63065599999
[32m[0907 04-35-37 @MBExp.py:144][0m ####################################################################
[32m[0907 04-35-37 @MBExp.py:145][0m Starting training iteration 97.
[32m[0907 04-35-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18855, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-35-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18473, current rewards: -107.00000, mean: -1.78333
[32m[0907 04-35-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18588, current rewards: -207.00000, mean: -1.88182
[32m[0907 04-36-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18616, current rewards: -307.00000, mean: -1.91875
[32m[0907 04-36-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18652, current rewards: -407.00000, mean: -1.93810
[32m[0907 04-36-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18684, current rewards: -507.00000, mean: -1.95000
[32m[0907 04-36-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18692, current rewards: -607.00000, mean: -1.95806
[32m[0907 04-36-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18697, current rewards: -707.00000, mean: -1.96389
[32m[0907 04-36-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18703, current rewards: -807.00000, mean: -1.96829
[32m[0907 04-37-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18714, current rewards: -907.00000, mean: -1.97174
[32m[0907 04-37-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18723, current rewards: -1007.00000, mean: -1.97451
[32m[0907 04-37-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18726, current rewards: -1107.00000, mean: -1.97679
[32m[0907 04-37-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18728, current rewards: -1207.00000, mean: -1.97869
[32m[0907 04-37-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18734, current rewards: -1307.00000, mean: -1.98030
[32m[0907 04-37-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18703, current rewards: -1407.00000, mean: -1.98169
[32m[0907 04-37-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18642, current rewards: -1507.00000, mean: -1.98289
[32m[0907 04-38-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18586, current rewards: -1607.00000, mean: -1.98395
[32m[0907 04-38-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18537, current rewards: -1707.00000, mean: -1.98488
[32m[0907 04-38-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18493, current rewards: -1807.00000, mean: -1.98571
[32m[0907 04-38-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18456, current rewards: -1907.00000, mean: -1.98646
[32m[0907 04-38-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18424, current rewards: -1990.99939, mean: -1.97129
[32m[0907 04-38-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18393, current rewards: -2090.99939, mean: -1.97264
[32m[0907 04-39-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18364, current rewards: -2190.99939, mean: -1.97387
[32m[0907 04-39-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18338, current rewards: -2290.99939, mean: -1.97500
[32m[0907 04-39-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18314, current rewards: -2390.99939, mean: -1.97603
[32m[0907 04-39-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18294, current rewards: -2490.99939, mean: -1.97698
[32m[0907 04-39-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18275, current rewards: -2590.99939, mean: -1.97786
[32m[0907 04-39-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18255, current rewards: -2690.99939, mean: -1.97868
[32m[0907 04-39-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18238, current rewards: -2790.99939, mean: -1.97943
[32m[0907 04-40-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18223, current rewards: -2890.99939, mean: -1.98014
[32m[0907 04-40-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18208, current rewards: -2990.99939, mean: -1.98079
[32m[0907 04-40-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18192, current rewards: -3090.99939, mean: -1.98141
[32m[0907 04-40-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18178, current rewards: -3190.99939, mean: -1.98199
[32m[0907 04-40-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18165, current rewards: -3290.99939, mean: -1.98253
[32m[0907 04-40-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18153, current rewards: -3390.99939, mean: -1.98304
[32m[0907 04-40-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18142, current rewards: -3490.99939, mean: -1.98352
[32m[0907 04-41-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18132, current rewards: -3590.99939, mean: -1.98398
[32m[0907 04-41-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18138, current rewards: -3690.99939, mean: -1.98441
[32m[0907 04-41-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18156, current rewards: -3790.99939, mean: -1.98482
[32m[0907 04-41-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18172, current rewards: -3890.99939, mean: -1.98520
[32m[0907 04-41-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18186, current rewards: -3990.99939, mean: -1.98557
[32m[0907 04-41-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18203, current rewards: -4090.99939, mean: -1.98592
[32m[0907 04-42-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18216, current rewards: -4190.99939, mean: -1.98626
[32m[0907 04-42-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18229, current rewards: -4290.99939, mean: -1.98657
[32m[0907 04-42-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18242, current rewards: -4390.99939, mean: -1.98688
[32m[0907 04-42-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18244, current rewards: -4490.99939, mean: -1.98717
[32m[0907 04-42-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18246, current rewards: -4590.99939, mean: -1.98745
[32m[0907 04-42-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18248, current rewards: -4690.99939, mean: -1.98771
[32m[0907 04-42-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18249, current rewards: -4790.99939, mean: -1.98797
[32m[0907 04-43-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18250, current rewards: -4890.99939, mean: -1.98821
[32m[0907 04-43-13 @Agent.py:117][0m Average action selection time: 0.1825
[32m[0907 04-43-13 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-43-14 @MBExp.py:227][0m Rewards obtained: [-4970.999394525492], Lows: [2480], Highs: [13], Total time: 44428.75527899999
[32m[0907 04-46-34 @MBExp.py:144][0m ####################################################################
[32m[0907 04-46-34 @MBExp.py:145][0m Starting training iteration 98.
[32m[0907 04-46-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.22568, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-46-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.21691, current rewards: -68.82902, mean: -1.14715
[32m[0907 04-46-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.21284, current rewards: -113.35997, mean: -1.03055
[32m[0907 04-47-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.21003, current rewards: -160.15655, mean: -1.00098
[32m[0907 04-47-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.20893, current rewards: -204.79052, mean: -0.97519
[32m[0907 04-47-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.20781, current rewards: -252.55237, mean: -0.97136
[32m[0907 04-47-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.20838, current rewards: -296.09624, mean: -0.95515
[32m[0907 04-47-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.20580, current rewards: -384.76806, mean: -1.06880
[32m[0907 04-47-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.20362, current rewards: -481.70483, mean: -1.17489
[32m[0907 04-48-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.20191, current rewards: -581.70483, mean: -1.26458
[32m[0907 04-48-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.20057, current rewards: -681.70483, mean: -1.33668
[32m[0907 04-48-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19942, current rewards: -781.70483, mean: -1.39590
[32m[0907 04-48-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19852, current rewards: -881.70483, mean: -1.44542
[32m[0907 04-48-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19739, current rewards: -981.70483, mean: -1.48743
[32m[0907 04-48-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19616, current rewards: -1081.70483, mean: -1.52353
[32m[0907 04-49-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19498, current rewards: -1181.70483, mean: -1.55487
[32m[0907 04-49-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19391, current rewards: -1281.70483, mean: -1.58235
[32m[0907 04-49-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19295, current rewards: -1381.70483, mean: -1.60663
[32m[0907 04-49-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19209, current rewards: -1481.70483, mean: -1.62825
[32m[0907 04-49-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19134, current rewards: -1581.70483, mean: -1.64761
[32m[0907 04-49-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19067, current rewards: -1681.70483, mean: -1.66505
[32m[0907 04-49-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19006, current rewards: -1781.70483, mean: -1.68085
[32m[0907 04-50-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18951, current rewards: -1881.70483, mean: -1.69523
[32m[0907 04-50-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18898, current rewards: -1981.70483, mean: -1.70837
[32m[0907 04-50-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18851, current rewards: -2081.70483, mean: -1.72042
[32m[0907 04-50-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18808, current rewards: -2181.70483, mean: -1.73151
[32m[0907 04-50-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18769, current rewards: -2281.70483, mean: -1.74176
[32m[0907 04-50-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18730, current rewards: -2381.70483, mean: -1.75125
[32m[0907 04-50-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18696, current rewards: -2481.70483, mean: -1.76007
[32m[0907 04-51-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18667, current rewards: -2581.70483, mean: -1.76829
[32m[0907 04-51-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18637, current rewards: -2681.70483, mean: -1.77596
[32m[0907 04-51-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18608, current rewards: -2781.70483, mean: -1.78314
[32m[0907 04-51-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18582, current rewards: -2881.70483, mean: -1.78988
[32m[0907 04-51-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18559, current rewards: -2981.70483, mean: -1.79621
[32m[0907 04-51-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18537, current rewards: -3081.70483, mean: -1.80217
[32m[0907 04-52-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18516, current rewards: -3181.70483, mean: -1.80779
[32m[0907 04-52-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18507, current rewards: -3281.70483, mean: -1.81310
[32m[0907 04-52-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18510, current rewards: -3381.70483, mean: -1.81812
[32m[0907 04-52-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18521, current rewards: -3481.70483, mean: -1.82288
[32m[0907 04-52-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18531, current rewards: -3581.70483, mean: -1.82740
[32m[0907 04-52-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18538, current rewards: -3681.70483, mean: -1.83169
[32m[0907 04-52-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18545, current rewards: -3781.70483, mean: -1.83578
[32m[0907 04-53-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18548, current rewards: -3881.70483, mean: -1.83967
[32m[0907 04-53-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18554, current rewards: -3981.70483, mean: -1.84338
[32m[0907 04-53-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18561, current rewards: -4081.70483, mean: -1.84693
[32m[0907 04-53-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18557, current rewards: -4181.70483, mean: -1.85031
[32m[0907 04-53-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18553, current rewards: -4281.70483, mean: -1.85355
[32m[0907 04-53-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18548, current rewards: -4381.70483, mean: -1.85665
[32m[0907 04-54-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18544, current rewards: -4481.70483, mean: -1.85963
[32m[0907 04-54-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18540, current rewards: -4581.70483, mean: -1.86248
[32m[0907 04-54-18 @Agent.py:117][0m Average action selection time: 0.1854
[32m[0907 04-54-18 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-54-19 @MBExp.py:227][0m Rewards obtained: [-4661.704827643672], Lows: [2193], Highs: [278], Total time: 44893.01237599999
[32m[0907 04-57-42 @MBExp.py:144][0m ####################################################################
[32m[0907 04-57-42 @MBExp.py:145][0m Starting training iteration 99.
[32m[0907 04-57-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18213, current rewards: 0.73980, mean: 0.07398
[32m[0907 04-57-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18433, current rewards: -60.83323, mean: -1.01389
[32m[0907 04-58-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18639, current rewards: -160.83323, mean: -1.46212
[32m[0907 04-58-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18716, current rewards: -256.62405, mean: -1.60390
[32m[0907 04-58-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18751, current rewards: -356.62405, mean: -1.69821
[32m[0907 04-58-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18742, current rewards: -456.62405, mean: -1.75625
[32m[0907 04-58-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18760, current rewards: -556.62405, mean: -1.79556
[32m[0907 04-58-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18757, current rewards: -656.62405, mean: -1.82396
[32m[0907 04-58-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18760, current rewards: -756.62405, mean: -1.84542
[32m[0907 04-59-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18764, current rewards: -856.62405, mean: -1.86223
[32m[0907 04-59-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18766, current rewards: -956.62405, mean: -1.87573
[32m[0907 04-59-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18776, current rewards: -1056.62405, mean: -1.88683
[32m[0907 04-59-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18775, current rewards: -1156.62405, mean: -1.89611
[32m[0907 04-59-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18738, current rewards: -1256.62405, mean: -1.90398
[32m[0907 04-59-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18684, current rewards: -1356.62405, mean: -1.91074
[32m[0907 05-00-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18627, current rewards: -1456.62405, mean: -1.91661
[32m[0907 05-00-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18577, current rewards: -1556.62405, mean: -1.92176
[32m[0907 05-00-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18529, current rewards: -1656.62405, mean: -1.92631
[32m[0907 05-00-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18490, current rewards: -1756.62405, mean: -1.93036
[32m[0907 05-00-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18453, current rewards: -1856.62405, mean: -1.93398
[32m[0907 05-00-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18419, current rewards: -1956.62405, mean: -1.93725
[32m[0907 05-00-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18388, current rewards: -2056.62405, mean: -1.94021
[32m[0907 05-01-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18360, current rewards: -2156.62405, mean: -1.94290
[32m[0907 05-01-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18335, current rewards: -2256.62405, mean: -1.94537
[32m[0907 05-01-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18314, current rewards: -2356.62405, mean: -1.94762
[32m[0907 05-01-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18291, current rewards: -2456.62405, mean: -1.94970
[32m[0907 05-01-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18270, current rewards: -2556.62405, mean: -1.95162
[32m[0907 05-01-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18252, current rewards: -2656.62405, mean: -1.95340
[32m[0907 05-01-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18237, current rewards: -2756.62405, mean: -1.95505
[32m[0907 05-02-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18222, current rewards: -2856.62405, mean: -1.95659
[32m[0907 05-02-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18207, current rewards: -2956.62405, mean: -1.95803
[32m[0907 05-02-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18194, current rewards: -3056.62405, mean: -1.95937
[32m[0907 05-02-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18182, current rewards: -3156.62405, mean: -1.96064
[32m[0907 05-02-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18168, current rewards: -3256.62405, mean: -1.96182
[32m[0907 05-02-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18159, current rewards: -3356.62405, mean: -1.96294
[32m[0907 05-03-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18148, current rewards: -3456.62405, mean: -1.96399
[32m[0907 05-03-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18148, current rewards: -3556.62405, mean: -1.96499
[32m[0907 05-03-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18158, current rewards: -3656.62405, mean: -1.96593
[32m[0907 05-03-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18177, current rewards: -3756.62405, mean: -1.96682
[32m[0907 05-03-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18195, current rewards: -3856.62405, mean: -1.96767
[32m[0907 05-03-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18210, current rewards: -3956.62405, mean: -1.96847
[32m[0907 05-03-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18226, current rewards: -4056.62405, mean: -1.96923
[32m[0907 05-04-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18241, current rewards: -4156.62405, mean: -1.96996
[32m[0907 05-04-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18255, current rewards: -4256.62405, mean: -1.97066
[32m[0907 05-04-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18269, current rewards: -4356.62405, mean: -1.97132
[32m[0907 05-04-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18281, current rewards: -4456.62405, mean: -1.97196
[32m[0907 05-04-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18283, current rewards: -4556.62405, mean: -1.97256
[32m[0907 05-04-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18284, current rewards: -4656.62405, mean: -1.97315
[32m[0907 05-05-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18285, current rewards: -4756.62405, mean: -1.97370
[32m[0907 05-05-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18288, current rewards: -4856.62405, mean: -1.97424
[32m[0907 05-05-20 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0907 05-05-20 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-05-20 @MBExp.py:227][0m Rewards obtained: [-4936.62405327433], Lows: [2470], Highs: [0], Total time: 45351.06111599999
[32m[0907 05-08-45 @MBExp.py:144][0m ####################################################################
[32m[0907 05-08-45 @MBExp.py:145][0m Starting training iteration 100.
[32m[0907 05-08-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20658, current rewards: 0.95612, mean: 0.09561
[32m[0907 05-08-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18712, current rewards: -1.26367, mean: -0.02106
[32m[0907 05-09-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18560, current rewards: 7.38716, mean: 0.06716
[32m[0907 05-09-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18505, current rewards: 16.46632, mean: 0.10291
[32m[0907 05-09-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18458, current rewards: 24.07076, mean: 0.11462
[32m[0907 05-09-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18461, current rewards: 32.34040, mean: 0.12439
[32m[0907 05-09-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18535, current rewards: 41.41325, mean: 0.13359
[32m[0907 05-09-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18578, current rewards: 50.48287, mean: 0.14023
[32m[0907 05-10-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18616, current rewards: 59.55666, mean: 0.14526
[32m[0907 05-10-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18639, current rewards: 68.62718, mean: 0.14919
[32m[0907 05-10-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18663, current rewards: 77.69846, mean: 0.15235
[32m[0907 05-10-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18800, current rewards: 52.22926, mean: 0.09327
[32m[0907 05-10-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18829, current rewards: -38.41682, mean: -0.06298
[32m[0907 05-10-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18794, current rewards: -138.41682, mean: -0.20972
[32m[0907 05-10-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18729, current rewards: -238.41682, mean: -0.33580
[32m[0907 05-11-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18665, current rewards: -338.41682, mean: -0.44529
[32m[0907 05-11-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18609, current rewards: -438.41682, mean: -0.54126
[32m[0907 05-11-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18557, current rewards: -538.41682, mean: -0.62607
[32m[0907 05-11-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18515, current rewards: -638.41682, mean: -0.70156
[32m[0907 05-11-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18477, current rewards: -738.41682, mean: -0.76918
[32m[0907 05-11-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18442, current rewards: -838.41682, mean: -0.83012
[32m[0907 05-12-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18410, current rewards: -938.41682, mean: -0.88530
[32m[0907 05-12-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18381, current rewards: -1038.41682, mean: -0.93551
[32m[0907 05-12-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18355, current rewards: -1138.41682, mean: -0.98139
[32m[0907 05-12-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18331, current rewards: -1238.41682, mean: -1.02348
[32m[0907 05-12-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18312, current rewards: -1338.41682, mean: -1.06224
[32m[0907 05-12-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18292, current rewards: -1438.41682, mean: -1.09803
[32m[0907 05-12-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18271, current rewards: -1538.41682, mean: -1.13119
[32m[0907 05-13-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18254, current rewards: -1638.41682, mean: -1.16200
[32m[0907 05-13-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18238, current rewards: -1738.41682, mean: -1.19070
[32m[0907 05-13-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18222, current rewards: -1838.41682, mean: -1.21749
[32m[0907 05-13-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18207, current rewards: -1938.41682, mean: -1.24257
[32m[0907 05-13-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18194, current rewards: -2038.41682, mean: -1.26610
[32m[0907 05-13-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18180, current rewards: -2138.41682, mean: -1.28820
[32m[0907 05-13-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18169, current rewards: -2238.41682, mean: -1.30902
[32m[0907 05-14-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18160, current rewards: -2338.41682, mean: -1.32865
[32m[0907 05-14-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18157, current rewards: -2438.41682, mean: -1.34719
[32m[0907 05-14-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18167, current rewards: -2538.41682, mean: -1.36474
[32m[0907 05-14-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18186, current rewards: -2638.41682, mean: -1.38137
[32m[0907 05-14-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18203, current rewards: -2738.41682, mean: -1.39715
[32m[0907 05-14-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18221, current rewards: -2838.41682, mean: -1.41215
[32m[0907 05-15-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18235, current rewards: -2938.41682, mean: -1.42642
[32m[0907 05-15-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18250, current rewards: -3038.41682, mean: -1.44001
[32m[0907 05-15-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18262, current rewards: -3138.41682, mean: -1.45297
[32m[0907 05-15-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18276, current rewards: -3238.41682, mean: -1.46535
[32m[0907 05-15-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18287, current rewards: -3338.41682, mean: -1.47718
[32m[0907 05-15-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18298, current rewards: -3438.41682, mean: -1.48849
[32m[0907 05-15-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18300, current rewards: -3538.41682, mean: -1.49933
[32m[0907 05-16-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18301, current rewards: -3638.41682, mean: -1.50972
[32m[0907 05-16-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18302, current rewards: -3738.41682, mean: -1.51968
[32m[0907 05-16-24 @Agent.py:117][0m Average action selection time: 0.1830
[32m[0907 05-16-24 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-16-24 @MBExp.py:227][0m Rewards obtained: [-3818.4168154487948], Lows: [1938], Highs: [32], Total time: 45809.47471399999
[32m[0907 05-19-52 @MBExp.py:144][0m ####################################################################
[32m[0907 05-19-52 @MBExp.py:145][0m Starting training iteration 101.
[32m[0907 05-19-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20648, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-20-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19718, current rewards: -52.97454, mean: -0.88291
[32m[0907 05-20-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19998, current rewards: -106.21235, mean: -0.96557
[32m[0907 05-20-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.20012, current rewards: -155.36398, mean: -0.97102
[32m[0907 05-20-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19724, current rewards: -208.49153, mean: -0.99282
[32m[0907 05-20-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19738, current rewards: -242.56515, mean: -0.93294
[32m[0907 05-20-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19809, current rewards: -295.12884, mean: -0.95203
[32m[0907 05-21-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.20221, current rewards: -336.30256, mean: -0.93417
[32m[0907 05-21-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.20138, current rewards: -373.34755, mean: -0.91060
[32m[0907 05-21-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.20270, current rewards: -435.96483, mean: -0.94775
[32m[0907 05-21-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.20634, current rewards: -483.17823, mean: -0.94741
[32m[0907 05-21-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.20652, current rewards: -526.25489, mean: -0.93974
[32m[0907 05-21-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.20490, current rewards: -519.43641, mean: -0.85154
[32m[0907 05-22-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.20329, current rewards: -512.67237, mean: -0.77678
[32m[0907 05-22-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.20190, current rewards: -505.90833, mean: -0.71255
[32m[0907 05-22-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.20052, current rewards: -499.14429, mean: -0.65677
[32m[0907 05-22-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19916, current rewards: -492.38025, mean: -0.60788
[32m[0907 05-22-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19791, current rewards: -485.61621, mean: -0.56467
[32m[0907 05-22-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19680, current rewards: -478.85218, mean: -0.52621
[32m[0907 05-23-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19582, current rewards: -502.74072, mean: -0.52369
[32m[0907 05-23-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19492, current rewards: -552.74072, mean: -0.54727
[32m[0907 05-23-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19409, current rewards: -602.74072, mean: -0.56862
[32m[0907 05-23-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19335, current rewards: -652.74072, mean: -0.58805
[32m[0907 05-23-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19267, current rewards: -702.74072, mean: -0.60581
[32m[0907 05-23-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19205, current rewards: -752.74072, mean: -0.62210
[32m[0907 05-23-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19150, current rewards: -802.74072, mean: -0.63710
[32m[0907 05-24-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.19097, current rewards: -852.74072, mean: -0.65095
[32m[0907 05-24-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.19048, current rewards: -902.74072, mean: -0.66378
[32m[0907 05-24-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.19003, current rewards: -952.74072, mean: -0.67570
[32m[0907 05-24-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18961, current rewards: -1002.74072, mean: -0.68681
[32m[0907 05-24-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18923, current rewards: -1052.74072, mean: -0.69718
[32m[0907 05-24-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18885, current rewards: -1102.74072, mean: -0.70689
[32m[0907 05-24-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18850, current rewards: -1152.74072, mean: -0.71599
[32m[0907 05-25-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18818, current rewards: -1202.74072, mean: -0.72454
[32m[0907 05-25-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18788, current rewards: -1252.74072, mean: -0.73260
[32m[0907 05-25-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18760, current rewards: -1302.74072, mean: -0.74019
[32m[0907 05-25-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18741, current rewards: -1352.74072, mean: -0.74737
[32m[0907 05-25-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18731, current rewards: -1402.74072, mean: -0.75416
[32m[0907 05-25-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18721, current rewards: -1452.74072, mean: -0.76060
[32m[0907 05-26-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18720, current rewards: -1502.74072, mean: -0.76670
[32m[0907 05-26-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18727, current rewards: -1552.74072, mean: -0.77251
[32m[0907 05-26-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18731, current rewards: -1602.74072, mean: -0.77803
[32m[0907 05-26-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18734, current rewards: -1652.74072, mean: -0.78329
[32m[0907 05-26-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18739, current rewards: -1702.74072, mean: -0.78831
[32m[0907 05-26-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18740, current rewards: -1752.74072, mean: -0.79310
[32m[0907 05-26-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18739, current rewards: -1802.74072, mean: -0.79767
[32m[0907 05-27-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18731, current rewards: -1852.74072, mean: -0.80205
[32m[0907 05-27-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18724, current rewards: -1902.74072, mean: -0.80625
[32m[0907 05-27-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18717, current rewards: -1952.74072, mean: -0.81027
[32m[0907 05-27-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18710, current rewards: -2002.74072, mean: -0.81412
[32m[0907 05-27-40 @Agent.py:117][0m Average action selection time: 0.1871
[32m[0907 05-27-40 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-27-41 @MBExp.py:227][0m Rewards obtained: [-2042.740718380211], Lows: [88], Highs: [1932], Total time: 46277.952309999986
[32m[0907 05-31-11 @MBExp.py:144][0m ####################################################################
[32m[0907 05-31-11 @MBExp.py:145][0m Starting training iteration 102.
[32m[0907 05-31-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18327, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-31-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18339, current rewards: -107.93492, mean: -1.79892
[32m[0907 05-31-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18332, current rewards: -207.93492, mean: -1.89032
[32m[0907 05-31-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18328, current rewards: -307.93492, mean: -1.92459
[32m[0907 05-31-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18342, current rewards: -407.93492, mean: -1.94255
[32m[0907 05-31-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18334, current rewards: -507.93492, mean: -1.95360
[32m[0907 05-32-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18393, current rewards: -607.93492, mean: -1.96108
[32m[0907 05-32-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18579, current rewards: -688.52298, mean: -1.91256
[32m[0907 05-32-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18616, current rewards: -749.04800, mean: -1.82695
[32m[0907 05-32-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18680, current rewards: -832.91054, mean: -1.81068
[32m[0907 05-32-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18786, current rewards: -903.26393, mean: -1.77111
[32m[0907 05-32-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18803, current rewards: -960.94391, mean: -1.71597
[32m[0907 05-33-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18805, current rewards: -1045.14729, mean: -1.71336
[32m[0907 05-33-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18772, current rewards: -1145.14729, mean: -1.73507
[32m[0907 05-33-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18745, current rewards: -1245.14729, mean: -1.75373
[32m[0907 05-33-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18721, current rewards: -1345.14729, mean: -1.76993
[32m[0907 05-33-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18675, current rewards: -1445.14729, mean: -1.78413
[32m[0907 05-33-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18623, current rewards: -1545.14729, mean: -1.79668
[32m[0907 05-34-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18577, current rewards: -1645.14729, mean: -1.80785
[32m[0907 05-34-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18538, current rewards: -1745.14729, mean: -1.81786
[32m[0907 05-34-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18504, current rewards: -1845.14729, mean: -1.82688
[32m[0907 05-34-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18469, current rewards: -1945.14729, mean: -1.83504
[32m[0907 05-34-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18438, current rewards: -2045.14729, mean: -1.84248
[32m[0907 05-34-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18410, current rewards: -2145.14729, mean: -1.84926
[32m[0907 05-34-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18385, current rewards: -2245.14729, mean: -1.85549
[32m[0907 05-35-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18364, current rewards: -2345.14729, mean: -1.86123
[32m[0907 05-35-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18342, current rewards: -2445.14729, mean: -1.86652
[32m[0907 05-35-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18322, current rewards: -2545.14729, mean: -1.87143
[32m[0907 05-35-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18303, current rewards: -2645.14729, mean: -1.87599
[32m[0907 05-35-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18287, current rewards: -2745.14729, mean: -1.88024
[32m[0907 05-35-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18270, current rewards: -2845.14729, mean: -1.88420
[32m[0907 05-35-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18254, current rewards: -2945.14729, mean: -1.88791
[32m[0907 05-36-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18238, current rewards: -3045.14729, mean: -1.89140
[32m[0907 05-36-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18225, current rewards: -3145.14729, mean: -1.89467
[32m[0907 05-36-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18212, current rewards: -3245.14729, mean: -1.89775
[32m[0907 05-36-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18199, current rewards: -3345.14729, mean: -1.90065
[32m[0907 05-36-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18197, current rewards: -3445.14729, mean: -1.90340
[32m[0907 05-36-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18202, current rewards: -3545.14729, mean: -1.90599
[32m[0907 05-37-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18205, current rewards: -3645.14729, mean: -1.90845
[32m[0907 05-37-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18210, current rewards: -3745.14729, mean: -1.91079
[32m[0907 05-37-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18219, current rewards: -3845.14729, mean: -1.91301
[32m[0907 05-37-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18235, current rewards: -3945.14729, mean: -1.91512
[32m[0907 05-37-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18253, current rewards: -4045.14729, mean: -1.91713
[32m[0907 05-37-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18267, current rewards: -4145.14729, mean: -1.91905
[32m[0907 05-37-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18279, current rewards: -4245.14729, mean: -1.92088
[32m[0907 05-38-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18291, current rewards: -4345.14729, mean: -1.92263
[32m[0907 05-38-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18294, current rewards: -4445.14729, mean: -1.92431
[32m[0907 05-38-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18296, current rewards: -4545.14729, mean: -1.92591
[32m[0907 05-38-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18299, current rewards: -4645.14729, mean: -1.92745
[32m[0907 05-38-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18299, current rewards: -4745.14729, mean: -1.92892
[32m[0907 05-38-49 @Agent.py:117][0m Average action selection time: 0.1830
[32m[0907 05-38-49 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-38-50 @MBExp.py:227][0m Rewards obtained: [-4825.147286079651], Lows: [2386], Highs: [63], Total time: 46736.331794999984
[32m[0907 05-42-22 @MBExp.py:144][0m ####################################################################
[32m[0907 05-42-22 @MBExp.py:145][0m Starting training iteration 103.
[32m[0907 05-42-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18305, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-42-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19022, current rewards: -46.71537, mean: -0.77859
[32m[0907 05-42-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18711, current rewards: -40.38360, mean: -0.36712
[32m[0907 05-42-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18593, current rewards: -34.91352, mean: -0.21821
[32m[0907 05-43-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18531, current rewards: -29.43810, mean: -0.14018
[32m[0907 05-43-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18499, current rewards: -23.96373, mean: -0.09217
[32m[0907 05-43-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18524, current rewards: -18.49142, mean: -0.05965
[32m[0907 05-43-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18568, current rewards: -13.01624, mean: -0.03616
[32m[0907 05-43-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18604, current rewards: -7.53787, mean: -0.01839
[32m[0907 05-43-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18631, current rewards: -2.30791, mean: -0.00502
[32m[0907 05-43-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18651, current rewards: 3.19399, mean: 0.00626
[32m[0907 05-44-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18662, current rewards: 8.63950, mean: 0.01543
[32m[0907 05-44-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18641, current rewards: 14.08053, mean: 0.02308
[32m[0907 05-44-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18621, current rewards: 19.52253, mean: 0.02958
[32m[0907 05-44-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18601, current rewards: 24.96001, mean: 0.03515
[32m[0907 05-44-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18589, current rewards: 25.96182, mean: 0.03416
[32m[0907 05-44-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18553, current rewards: -14.81951, mean: -0.01830
[32m[0907 05-45-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18512, current rewards: -47.62469, mean: -0.05538
[32m[0907 05-45-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18475, current rewards: -84.34092, mean: -0.09268
[32m[0907 05-45-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18453, current rewards: -140.92539, mean: -0.14680
[32m[0907 05-45-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18419, current rewards: -182.54765, mean: -0.18074
[32m[0907 05-45-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18400, current rewards: -227.24921, mean: -0.21439
[32m[0907 05-45-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18373, current rewards: -294.99650, mean: -0.26576
[32m[0907 05-45-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18351, current rewards: -346.87015, mean: -0.29903
[32m[0907 05-46-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18328, current rewards: -420.86278, mean: -0.34782
[32m[0907 05-46-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18325, current rewards: -462.65291, mean: -0.36718
[32m[0907 05-46-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18325, current rewards: -518.10329, mean: -0.39550
[32m[0907 05-46-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18336, current rewards: -581.78432, mean: -0.42778
[32m[0907 05-46-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18326, current rewards: -663.19829, mean: -0.47035
[32m[0907 05-46-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18309, current rewards: -733.59732, mean: -0.50246
[32m[0907 05-46-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18323, current rewards: -774.44449, mean: -0.51288
[32m[0907 05-47-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18313, current rewards: -856.21725, mean: -0.54886
[32m[0907 05-47-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18311, current rewards: -941.19686, mean: -0.58459
[32m[0907 05-47-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18319, current rewards: -1019.50455, mean: -0.61416
[32m[0907 05-47-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18323, current rewards: -1098.87677, mean: -0.64262
[32m[0907 05-47-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18347, current rewards: -1188.30702, mean: -0.67517
[32m[0907 05-47-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18389, current rewards: -1273.18984, mean: -0.70342
[32m[0907 05-48-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18426, current rewards: -1363.05098, mean: -0.73282
[32m[0907 05-48-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18426, current rewards: -1463.05098, mean: -0.76600
[32m[0907 05-48-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18423, current rewards: -1563.05098, mean: -0.79747
[32m[0907 05-48-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18432, current rewards: -1663.05098, mean: -0.82739
[32m[0907 05-48-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18442, current rewards: -1763.05098, mean: -0.85585
[32m[0907 05-48-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18451, current rewards: -1863.05098, mean: -0.88296
[32m[0907 05-49-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18459, current rewards: -1963.05098, mean: -0.90882
[32m[0907 05-49-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18468, current rewards: -2063.05098, mean: -0.93351
[32m[0907 05-49-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18475, current rewards: -2163.05098, mean: -0.95710
[32m[0907 05-49-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18472, current rewards: -2263.05098, mean: -0.97968
[32m[0907 05-49-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18470, current rewards: -2363.05098, mean: -1.00129
[32m[0907 05-49-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18469, current rewards: -2463.05098, mean: -1.02201
[32m[0907 05-49-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18467, current rewards: -2563.05098, mean: -1.04189
[32m[0907 05-50-05 @Agent.py:117][0m Average action selection time: 0.1847
[32m[0907 05-50-05 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-50-05 @MBExp.py:227][0m Rewards obtained: [-2643.0509807592343], Lows: [1313], Highs: [152], Total time: 47198.83791199998
[32m[0907 05-53-40 @MBExp.py:144][0m ####################################################################
[32m[0907 05-53-40 @MBExp.py:145][0m Starting training iteration 104.
[32m[0907 05-53-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30515, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-53-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.21225, current rewards: -59.41251, mean: -0.99021
[32m[0907 05-54-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19940, current rewards: -97.63560, mean: -0.88760
[32m[0907 05-54-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19525, current rewards: -131.53050, mean: -0.82207
[32m[0907 05-54-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19264, current rewards: -162.23479, mean: -0.77255
[32m[0907 05-54-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19121, current rewards: -212.23479, mean: -0.81629
[32m[0907 05-54-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19091, current rewards: -245.08169, mean: -0.79059
[32m[0907 05-54-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19062, current rewards: -286.51052, mean: -0.79586
[32m[0907 05-54-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19029, current rewards: -336.51052, mean: -0.82076
[32m[0907 05-55-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19010, current rewards: -386.51052, mean: -0.84024
[32m[0907 05-55-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18975, current rewards: -436.51052, mean: -0.85590
[32m[0907 05-55-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18923, current rewards: -486.51052, mean: -0.86877
[32m[0907 05-55-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18881, current rewards: -536.51052, mean: -0.87953
[32m[0907 05-55-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18844, current rewards: -586.51052, mean: -0.88865
[32m[0907 05-55-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18810, current rewards: -636.51052, mean: -0.89649
[32m[0907 05-56-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18748, current rewards: -686.51052, mean: -0.90330
[32m[0907 05-56-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18691, current rewards: -736.51052, mean: -0.90927
[32m[0907 05-56-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18638, current rewards: -786.51052, mean: -0.91455
[32m[0907 05-56-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18590, current rewards: -836.51052, mean: -0.91924
[32m[0907 05-56-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18547, current rewards: -886.51052, mean: -0.92345
[32m[0907 05-56-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18508, current rewards: -936.51052, mean: -0.92724
[32m[0907 05-56-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18478, current rewards: -986.51052, mean: -0.93067
[32m[0907 05-57-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18446, current rewards: -1036.51052, mean: -0.93379
[32m[0907 05-57-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18417, current rewards: -1086.51052, mean: -0.93665
[32m[0907 05-57-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18391, current rewards: -1136.51052, mean: -0.93926
[32m[0907 05-57-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18366, current rewards: -1186.51052, mean: -0.94168
[32m[0907 05-57-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18346, current rewards: -1236.51052, mean: -0.94390
[32m[0907 05-57-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18325, current rewards: -1286.51052, mean: -0.94596
[32m[0907 05-57-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18306, current rewards: -1336.51052, mean: -0.94788
[32m[0907 05-58-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18289, current rewards: -1386.51052, mean: -0.94966
[32m[0907 05-58-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18271, current rewards: -1436.51052, mean: -0.95133
[32m[0907 05-58-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18256, current rewards: -1486.51052, mean: -0.95289
[32m[0907 05-58-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18242, current rewards: -1536.51052, mean: -0.95435
[32m[0907 05-58-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18229, current rewards: -1586.51052, mean: -0.95573
[32m[0907 05-58-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18214, current rewards: -1609.99149, mean: -0.94152
[32m[0907 05-59-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18209, current rewards: -1659.99149, mean: -0.94318
[32m[0907 05-59-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18215, current rewards: -1709.99149, mean: -0.94475
[32m[0907 05-59-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18221, current rewards: -1759.99149, mean: -0.94623
[32m[0907 05-59-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18227, current rewards: -1809.99149, mean: -0.94764
[32m[0907 05-59-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18232, current rewards: -1859.99149, mean: -0.94898
[32m[0907 05-59-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18248, current rewards: -1909.99149, mean: -0.95024
[32m[0907 05-59-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18264, current rewards: -1959.99149, mean: -0.95145
[32m[0907 06-00-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18278, current rewards: -2009.99149, mean: -0.95260
[32m[0907 06-00-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18292, current rewards: -2059.99149, mean: -0.95370
[32m[0907 06-00-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18305, current rewards: -2109.99149, mean: -0.95475
[32m[0907 06-00-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18314, current rewards: -2159.99149, mean: -0.95575
[32m[0907 06-00-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18315, current rewards: -2209.99149, mean: -0.95671
[32m[0907 06-00-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18318, current rewards: -2259.99149, mean: -0.95762
[32m[0907 06-01-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18320, current rewards: -2309.99149, mean: -0.95850
[32m[0907 06-01-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18320, current rewards: -2359.99149, mean: -0.95935
[32m[0907 06-01-18 @Agent.py:117][0m Average action selection time: 0.1832
[32m[0907 06-01-18 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-01-19 @MBExp.py:227][0m Rewards obtained: [-2399.991492225403], Lows: [17], Highs: [2374], Total time: 47657.72866699998
[32m[0907 06-04-56 @MBExp.py:144][0m ####################################################################
[32m[0907 06-04-56 @MBExp.py:145][0m Starting training iteration 105.
[32m[0907 06-04-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18233, current rewards: 1.26261, mean: 0.12626
[32m[0907 06-05-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18323, current rewards: -31.67974, mean: -0.52800
[32m[0907 06-05-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18330, current rewards: -81.67974, mean: -0.74254
[32m[0907 06-05-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18325, current rewards: -131.67974, mean: -0.82300
[32m[0907 06-05-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18331, current rewards: -181.67974, mean: -0.86514
[32m[0907 06-05-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18333, current rewards: -231.67974, mean: -0.89108
[32m[0907 06-05-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18339, current rewards: -281.67974, mean: -0.90864
[32m[0907 06-06-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18409, current rewards: -331.67974, mean: -0.92133
[32m[0907 06-06-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18473, current rewards: -381.67974, mean: -0.93093
[32m[0907 06-06-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18513, current rewards: -422.17553, mean: -0.91777
[32m[0907 06-06-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18527, current rewards: -417.13785, mean: -0.81792
[32m[0907 06-06-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18515, current rewards: -411.89316, mean: -0.73552
[32m[0907 06-06-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18502, current rewards: -430.95614, mean: -0.70649
[32m[0907 06-06-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18492, current rewards: -480.95614, mean: -0.72872
[32m[0907 06-07-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18474, current rewards: -530.95614, mean: -0.74783
[32m[0907 06-07-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18425, current rewards: -580.95614, mean: -0.76442
[32m[0907 06-07-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18386, current rewards: -630.95614, mean: -0.77896
[32m[0907 06-07-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18348, current rewards: -680.95614, mean: -0.79181
[32m[0907 06-07-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18318, current rewards: -730.95614, mean: -0.80325
[32m[0907 06-07-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18290, current rewards: -780.95614, mean: -0.81350
[32m[0907 06-08-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18263, current rewards: -830.95614, mean: -0.82273
[32m[0907 06-08-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18241, current rewards: -880.95614, mean: -0.83109
[32m[0907 06-08-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18225, current rewards: -930.95614, mean: -0.83870
[32m[0907 06-08-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18207, current rewards: -980.95614, mean: -0.84565
[32m[0907 06-08-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18192, current rewards: -1030.95614, mean: -0.85203
[32m[0907 06-08-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18176, current rewards: -1080.95614, mean: -0.85790
[32m[0907 06-08-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18164, current rewards: -1130.95614, mean: -0.86333
[32m[0907 06-09-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18150, current rewards: -1166.26404, mean: -0.85755
[32m[0907 06-09-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18135, current rewards: -1163.79228, mean: -0.82538
[32m[0907 06-09-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18123, current rewards: -1161.32052, mean: -0.79543
[32m[0907 06-09-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18112, current rewards: -1158.84876, mean: -0.76745
[32m[0907 06-09-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18102, current rewards: -1187.86006, mean: -0.76145
[32m[0907 06-09-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18092, current rewards: -1237.86006, mean: -0.76886
[32m[0907 06-09-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18084, current rewards: -1287.86006, mean: -0.77582
[32m[0907 06-10-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18077, current rewards: -1337.86006, mean: -0.78237
[32m[0907 06-10-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18079, current rewards: -1387.86006, mean: -0.78856
[32m[0907 06-10-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18089, current rewards: -1437.86006, mean: -0.79440
[32m[0907 06-10-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18098, current rewards: -1487.86006, mean: -0.79992
[32m[0907 06-10-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18105, current rewards: -1537.86006, mean: -0.80516
[32m[0907 06-10-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18116, current rewards: -1587.86006, mean: -0.81013
[32m[0907 06-11-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18136, current rewards: -1637.86006, mean: -0.81486
[32m[0907 06-11-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18155, current rewards: -1687.86006, mean: -0.81935
[32m[0907 06-11-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18171, current rewards: -1737.86006, mean: -0.82363
[32m[0907 06-11-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18188, current rewards: -1787.86006, mean: -0.82771
[32m[0907 06-11-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18203, current rewards: -1837.86006, mean: -0.83161
[32m[0907 06-11-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18215, current rewards: -1887.86006, mean: -0.83534
[32m[0907 06-11-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18225, current rewards: -1937.86006, mean: -0.83890
[32m[0907 06-12-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18228, current rewards: -1987.86006, mean: -0.84231
[32m[0907 06-12-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18231, current rewards: -2037.86006, mean: -0.84559
[32m[0907 06-12-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18233, current rewards: -2087.86006, mean: -0.84872
[32m[0907 06-12-32 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0907 06-12-32 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-12-32 @MBExp.py:227][0m Rewards obtained: [-2127.8600572206024], Lows: [0], Highs: [2153], Total time: 48114.46490599998
[32m[0907 06-16-12 @MBExp.py:144][0m ####################################################################
[32m[0907 06-16-12 @MBExp.py:145][0m Starting training iteration 106.
[32m[0907 06-16-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19560, current rewards: -5.79637, mean: -0.57964
[32m[0907 06-16-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18578, current rewards: 2.35680, mean: 0.03928
[32m[0907 06-16-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18481, current rewards: 12.87203, mean: 0.11702
[32m[0907 06-16-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18434, current rewards: 23.36504, mean: 0.14603
[32m[0907 06-16-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18428, current rewards: 33.85737, mean: 0.16123
[32m[0907 06-17-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18421, current rewards: 44.34759, mean: 0.17057
[32m[0907 06-17-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18610, current rewards: 17.31017, mean: 0.05584
[32m[0907 06-17-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18836, current rewards: -20.27820, mean: -0.05633
[32m[0907 06-17-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18986, current rewards: -77.12995, mean: -0.18812
[32m[0907 06-17-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19054, current rewards: -121.24864, mean: -0.26358
[32m[0907 06-17-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19005, current rewards: -176.35122, mean: -0.34579
[32m[0907 06-17-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18988, current rewards: -226.38897, mean: -0.40427
[32m[0907 06-18-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19012, current rewards: -281.55563, mean: -0.46157
[32m[0907 06-18-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19031, current rewards: -331.87295, mean: -0.50284
[32m[0907 06-18-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18956, current rewards: -390.36614, mean: -0.54981
[32m[0907 06-18-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18931, current rewards: -454.04341, mean: -0.59743
[32m[0907 06-18-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18964, current rewards: -509.22650, mean: -0.62867
[32m[0907 06-18-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18999, current rewards: -557.42275, mean: -0.64817
[32m[0907 06-19-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19023, current rewards: -591.61179, mean: -0.65012
[32m[0907 06-19-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19024, current rewards: -629.41253, mean: -0.65564
[32m[0907 06-19-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19001, current rewards: -668.96007, mean: -0.66234
[32m[0907 06-19-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19013, current rewards: -712.96999, mean: -0.67261
[32m[0907 06-19-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18957, current rewards: -702.40591, mean: -0.63280
[32m[0907 06-19-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18906, current rewards: -690.68639, mean: -0.59542
[32m[0907 06-20-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18858, current rewards: -678.95864, mean: -0.56112
[32m[0907 06-20-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18817, current rewards: -667.25625, mean: -0.52957
[32m[0907 06-20-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18856, current rewards: -698.59683, mean: -0.53328
[32m[0907 06-20-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18857, current rewards: -747.97586, mean: -0.54998
[32m[0907 06-20-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18945, current rewards: -789.66063, mean: -0.56004
[32m[0907 06-20-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18956, current rewards: -836.41587, mean: -0.57289
[32m[0907 06-20-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18949, current rewards: -884.90027, mean: -0.58603
[32m[0907 06-21-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18943, current rewards: -940.05895, mean: -0.60260
[32m[0907 06-21-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18974, current rewards: -988.44680, mean: -0.61394
[32m[0907 06-21-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18972, current rewards: -1032.35634, mean: -0.62190
[32m[0907 06-21-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18995, current rewards: -1046.17760, mean: -0.61180
[32m[0907 06-21-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18977, current rewards: -1036.76715, mean: -0.58907
[32m[0907 06-21-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18961, current rewards: -1027.33449, mean: -0.56759
[32m[0907 06-22-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18948, current rewards: -1017.90719, mean: -0.54726
[32m[0907 06-22-14 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18947, current rewards: -1008.48032, mean: -0.52800
[32m[0907 06-22-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18945, current rewards: -999.05366, mean: -0.50972
[32m[0907 06-22-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18943, current rewards: -989.62416, mean: -0.49235
[32m[0907 06-22-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18949, current rewards: -992.08581, mean: -0.48160
[32m[0907 06-22-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.19002, current rewards: -1059.78537, mean: -0.50227
[32m[0907 06-23-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.19057, current rewards: -1117.30600, mean: -0.51727
[32m[0907 06-23-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.19117, current rewards: -1185.88041, mean: -0.53660
[32m[0907 06-23-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.19130, current rewards: -1270.97466, mean: -0.56238
[32m[0907 06-23-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.19143, current rewards: -1361.55704, mean: -0.58942
[32m[0907 06-23-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.19155, current rewards: -1429.23771, mean: -0.60561
[32m[0907 06-23-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.19198, current rewards: -1478.95039, mean: -0.61367
[32m[0907 06-24-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.19211, current rewards: -1514.20463, mean: -0.61553
[32m[0907 06-24-13 @Agent.py:117][0m Average action selection time: 0.1922
[32m[0907 06-24-13 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-24-13 @MBExp.py:227][0m Rewards obtained: [-1550.6754822163953], Lows: [382], Highs: [1001], Total time: 48595.89510399998
[32m[0907 06-27-55 @MBExp.py:144][0m ####################################################################
[32m[0907 06-27-55 @MBExp.py:145][0m Starting training iteration 107.
[32m[0907 06-27-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30528, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-28-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.29321, current rewards: -86.17411, mean: -1.43624
[32m[0907 06-28-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.26123, current rewards: -124.67632, mean: -1.13342
[32m[0907 06-28-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.23795, current rewards: -174.67632, mean: -1.09173
[32m[0907 06-28-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.22622, current rewards: -224.67632, mean: -1.06989
[32m[0907 06-28-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.21897, current rewards: -247.20313, mean: -0.95078
[32m[0907 06-29-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.21360, current rewards: -244.38814, mean: -0.78835
[32m[0907 06-29-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.20953, current rewards: -241.57316, mean: -0.67104
[32m[0907 06-29-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.20643, current rewards: -238.75817, mean: -0.58234
[32m[0907 06-29-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.20396, current rewards: -234.62878, mean: -0.51006
[32m[0907 06-29-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.20176, current rewards: -230.31710, mean: -0.45160
[32m[0907 06-29-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19968, current rewards: -243.38515, mean: -0.43462
[32m[0907 06-29-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19794, current rewards: -293.38515, mean: -0.48096
[32m[0907 06-30-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19644, current rewards: -343.38515, mean: -0.52028
[32m[0907 06-30-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19514, current rewards: -393.38515, mean: -0.55406
[32m[0907 06-30-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19400, current rewards: -443.38515, mean: -0.58340
[32m[0907 06-30-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19302, current rewards: -493.38515, mean: -0.60912
[32m[0907 06-30-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19215, current rewards: -543.38515, mean: -0.63184
[32m[0907 06-30-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19139, current rewards: -593.38515, mean: -0.65207
[32m[0907 06-30-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19070, current rewards: -643.38515, mean: -0.67019
[32m[0907 06-31-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19009, current rewards: -693.38515, mean: -0.68652
[32m[0907 06-31-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18950, current rewards: -743.38515, mean: -0.70131
[32m[0907 06-31-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18896, current rewards: -793.38515, mean: -0.71476
[32m[0907 06-31-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18847, current rewards: -843.38515, mean: -0.72706
[32m[0907 06-31-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18804, current rewards: -893.38515, mean: -0.73833
[32m[0907 06-31-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18765, current rewards: -943.38515, mean: -0.74872
[32m[0907 06-32-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18729, current rewards: -993.38515, mean: -0.75831
[32m[0907 06-32-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18696, current rewards: -1043.38515, mean: -0.76719
[32m[0907 06-32-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18665, current rewards: -1093.38515, mean: -0.77545
[32m[0907 06-32-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18637, current rewards: -1143.38515, mean: -0.78314
[32m[0907 06-32-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18608, current rewards: -1193.38515, mean: -0.79032
[32m[0907 06-32-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18585, current rewards: -1243.38515, mean: -0.79704
[32m[0907 06-32-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18580, current rewards: -1293.38515, mean: -0.80334
[32m[0907 06-33-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18575, current rewards: -1343.38515, mean: -0.80927
[32m[0907 06-33-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18571, current rewards: -1393.38515, mean: -0.81485
[32m[0907 06-33-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18566, current rewards: -1443.38515, mean: -0.82011
[32m[0907 06-33-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18577, current rewards: -1493.38515, mean: -0.82507
[32m[0907 06-33-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18584, current rewards: -1543.38515, mean: -0.82978
[32m[0907 06-33-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18592, current rewards: -1593.38515, mean: -0.83423
[32m[0907 06-34-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18599, current rewards: -1643.38515, mean: -0.83846
[32m[0907 06-34-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18605, current rewards: -1693.38515, mean: -0.84248
[32m[0907 06-34-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18610, current rewards: -1743.38515, mean: -0.84630
[32m[0907 06-34-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18616, current rewards: -1793.38515, mean: -0.84995
[32m[0907 06-34-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18621, current rewards: -1843.38515, mean: -0.85342
[32m[0907 06-34-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18620, current rewards: -1893.38515, mean: -0.85674
[32m[0907 06-34-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18614, current rewards: -1943.38515, mean: -0.85990
[32m[0907 06-35-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18609, current rewards: -1993.38515, mean: -0.86294
[32m[0907 06-35-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18604, current rewards: -2043.38515, mean: -0.86584
[32m[0907 06-35-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18600, current rewards: -2093.38515, mean: -0.86862
[32m[0907 06-35-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18595, current rewards: -2143.38515, mean: -0.87129
[32m[0907 06-35-40 @Agent.py:117][0m Average action selection time: 0.1859
[32m[0907 06-35-40 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-35-41 @MBExp.py:227][0m Rewards obtained: [-2183.385151964757], Lows: [42], Highs: [2124], Total time: 49061.53743899998
[32m[0907 06-39-24 @MBExp.py:144][0m ####################################################################
[32m[0907 06-39-24 @MBExp.py:145][0m Starting training iteration 108.
[32m[0907 06-39-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18398, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-39-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18350, current rewards: -109.00000, mean: -1.81667
[32m[0907 06-39-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18362, current rewards: -209.00000, mean: -1.90000
[32m[0907 06-39-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18449, current rewards: -309.00000, mean: -1.93125
[32m[0907 06-40-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18573, current rewards: -409.00000, mean: -1.94762
[32m[0907 06-40-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18641, current rewards: -509.00000, mean: -1.95769
[32m[0907 06-40-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18639, current rewards: -609.00000, mean: -1.96452
[32m[0907 06-40-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18609, current rewards: -709.00000, mean: -1.96944
[32m[0907 06-40-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18584, current rewards: -809.00000, mean: -1.97317
[32m[0907 06-40-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18565, current rewards: -909.00000, mean: -1.97609
[32m[0907 06-40-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18499, current rewards: -1009.00000, mean: -1.97843
[32m[0907 06-41-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18438, current rewards: -1109.00000, mean: -1.98036
[32m[0907 06-41-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18386, current rewards: -1209.00000, mean: -1.98197
[32m[0907 06-41-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18342, current rewards: -1309.00000, mean: -1.98333
[32m[0907 06-41-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18305, current rewards: -1409.00000, mean: -1.98451
[32m[0907 06-41-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18273, current rewards: -1509.00000, mean: -1.98553
[32m[0907 06-41-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18245, current rewards: -1609.00000, mean: -1.98642
[32m[0907 06-42-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18220, current rewards: -1709.00000, mean: -1.98721
[32m[0907 06-42-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18197, current rewards: -1809.00000, mean: -1.98791
[32m[0907 06-42-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18178, current rewards: -1909.00000, mean: -1.98854
[32m[0907 06-42-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18159, current rewards: -2009.00000, mean: -1.98911
[32m[0907 06-42-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18141, current rewards: -2109.00000, mean: -1.98962
[32m[0907 06-42-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18124, current rewards: -2209.00000, mean: -1.99009
[32m[0907 06-42-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18109, current rewards: -2309.00000, mean: -1.99052
[32m[0907 06-43-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18095, current rewards: -2409.00000, mean: -1.99091
[32m[0907 06-43-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18083, current rewards: -2509.00000, mean: -1.99127
[32m[0907 06-43-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18070, current rewards: -2609.00000, mean: -1.99160
[32m[0907 06-43-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18060, current rewards: -2709.00000, mean: -1.99191
[32m[0907 06-43-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18053, current rewards: -2809.00000, mean: -1.99220
[32m[0907 06-43-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18044, current rewards: -2909.00000, mean: -1.99247
[32m[0907 06-43-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18035, current rewards: -3009.00000, mean: -1.99272
[32m[0907 06-44-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18029, current rewards: -3109.00000, mean: -1.99295
[32m[0907 06-44-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18038, current rewards: -3209.00000, mean: -1.99317
[32m[0907 06-44-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18050, current rewards: -3309.00000, mean: -1.99337
[32m[0907 06-44-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18060, current rewards: -3409.00000, mean: -1.99357
[32m[0907 06-44-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18071, current rewards: -3509.00000, mean: -1.99375
[32m[0907 06-44-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18094, current rewards: -3609.00000, mean: -1.99392
[32m[0907 06-45-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18115, current rewards: -3709.00000, mean: -1.99409
[32m[0907 06-45-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18135, current rewards: -3809.00000, mean: -1.99424
[32m[0907 06-45-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18155, current rewards: -3909.00000, mean: -1.99439
[32m[0907 06-45-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18172, current rewards: -4009.00000, mean: -1.99453
[32m[0907 06-45-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18188, current rewards: -4109.00000, mean: -1.99466
[32m[0907 06-45-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18205, current rewards: -4209.00000, mean: -1.99479
[32m[0907 06-45-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18220, current rewards: -4309.00000, mean: -1.99491
[32m[0907 06-46-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18233, current rewards: -4409.00000, mean: -1.99502
[32m[0907 06-46-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18247, current rewards: -4509.00000, mean: -1.99513
[32m[0907 06-46-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18250, current rewards: -4609.00000, mean: -1.99524
[32m[0907 06-46-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18252, current rewards: -4709.00000, mean: -1.99534
[32m[0907 06-46-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18256, current rewards: -4809.00000, mean: -1.99544
[32m[0907 06-46-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18259, current rewards: -4909.00000, mean: -1.99553
[32m[0907 06-47-01 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0907 06-47-01 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-47-02 @MBExp.py:227][0m Rewards obtained: [-4989], Lows: [2489], Highs: [11], Total time: 49518.93634599998
[32m[0907 06-50-47 @MBExp.py:144][0m ####################################################################
[32m[0907 06-50-47 @MBExp.py:145][0m Starting training iteration 109.
[32m[0907 06-50-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18185, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-50-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19612, current rewards: -62.62125, mean: -1.04369
[32m[0907 06-51-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19396, current rewards: -141.06412, mean: -1.28240
[32m[0907 06-51-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19467, current rewards: -229.68047, mean: -1.43550
[32m[0907 06-51-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19606, current rewards: -320.00249, mean: -1.52382
[32m[0907 06-51-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19707, current rewards: -409.85529, mean: -1.57637
[32m[0907 06-51-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19738, current rewards: -493.05567, mean: -1.59050
[32m[0907 06-51-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19666, current rewards: -581.44729, mean: -1.61513
[32m[0907 06-52-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19556, current rewards: -672.05737, mean: -1.63916
[32m[0907 06-52-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19381, current rewards: -772.05737, mean: -1.67839
[32m[0907 06-52-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19222, current rewards: -872.05737, mean: -1.70992
[32m[0907 06-52-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19094, current rewards: -972.05737, mean: -1.73582
[32m[0907 06-52-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18991, current rewards: -1072.05737, mean: -1.75747
[32m[0907 06-52-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18904, current rewards: -1172.05737, mean: -1.77584
[32m[0907 06-53-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18826, current rewards: -1272.05737, mean: -1.79163
[32m[0907 06-53-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18760, current rewards: -1372.05737, mean: -1.80534
[32m[0907 06-53-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18702, current rewards: -1472.05737, mean: -1.81735
[32m[0907 06-53-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18649, current rewards: -1572.05737, mean: -1.82797
[32m[0907 06-53-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18601, current rewards: -1672.05737, mean: -1.83743
[32m[0907 06-53-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18558, current rewards: -1772.05737, mean: -1.84589
[32m[0907 06-53-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18521, current rewards: -1872.05737, mean: -1.85352
[32m[0907 06-54-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18486, current rewards: -1972.05737, mean: -1.86043
[32m[0907 06-54-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18453, current rewards: -2072.05737, mean: -1.86672
[32m[0907 06-54-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18423, current rewards: -2172.05737, mean: -1.87246
[32m[0907 06-54-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18395, current rewards: -2272.05737, mean: -1.87773
[32m[0907 06-54-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18374, current rewards: -2372.05737, mean: -1.88259
[32m[0907 06-54-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18351, current rewards: -2472.05737, mean: -1.88707
[32m[0907 06-54-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18332, current rewards: -2572.05737, mean: -1.89122
[32m[0907 06-55-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18313, current rewards: -2672.05737, mean: -1.89508
[32m[0907 06-55-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18296, current rewards: -2772.05737, mean: -1.89867
[32m[0907 06-55-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18278, current rewards: -2872.05737, mean: -1.90202
[32m[0907 06-55-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18270, current rewards: -2972.05737, mean: -1.90516
[32m[0907 06-55-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18274, current rewards: -3072.05737, mean: -1.90811
[32m[0907 06-55-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18277, current rewards: -3172.05737, mean: -1.91088
[32m[0907 06-56-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18279, current rewards: -3272.05737, mean: -1.91348
[32m[0907 06-56-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18291, current rewards: -3372.05737, mean: -1.91594
[32m[0907 06-56-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18306, current rewards: -3472.05737, mean: -1.91826
[32m[0907 06-56-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18322, current rewards: -3572.05737, mean: -1.92046
[32m[0907 06-56-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18336, current rewards: -3672.05737, mean: -1.92254
[32m[0907 06-56-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18349, current rewards: -3772.05737, mean: -1.92452
[32m[0907 06-56-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18364, current rewards: -3872.05737, mean: -1.92640
[32m[0907 06-57-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18376, current rewards: -3972.05737, mean: -1.92818
[32m[0907 06-57-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18388, current rewards: -4072.05737, mean: -1.92989
[32m[0907 06-57-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18401, current rewards: -4172.05737, mean: -1.93151
[32m[0907 06-57-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18410, current rewards: -4272.05737, mean: -1.93306
[32m[0907 06-57-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18419, current rewards: -4372.05737, mean: -1.93454
[32m[0907 06-57-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18417, current rewards: -4472.05737, mean: -1.93596
[32m[0907 06-58-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18416, current rewards: -4572.05737, mean: -1.93731
[32m[0907 06-58-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18415, current rewards: -4672.05737, mean: -1.93861
[32m[0907 06-58-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18415, current rewards: -4772.05737, mean: -1.93986
[32m[0907 06-58-28 @Agent.py:117][0m Average action selection time: 0.1841
[32m[0907 06-58-28 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-58-28 @MBExp.py:227][0m Rewards obtained: [-4852.057374927714], Lows: [2398], Highs: [61], Total time: 49980.151538999984
[32m[0907 07-02-16 @MBExp.py:144][0m ####################################################################
[32m[0907 07-02-16 @MBExp.py:145][0m Starting training iteration 110.
[32m[0907 07-02-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18220, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-02-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18395, current rewards: -92.59205, mean: -1.54320
[32m[0907 07-02-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19047, current rewards: -170.56402, mean: -1.55058
[32m[0907 07-02-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19113, current rewards: -252.79767, mean: -1.57999
[32m[0907 07-02-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19190, current rewards: -326.72494, mean: -1.55583
[32m[0907 07-03-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19105, current rewards: -415.82047, mean: -1.59931
[32m[0907 07-03-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19090, current rewards: -471.17207, mean: -1.51991
[32m[0907 07-03-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19093, current rewards: -562.11518, mean: -1.56143
[32m[0907 07-03-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19215, current rewards: -659.82415, mean: -1.60933
[32m[0907 07-03-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19328, current rewards: -716.52419, mean: -1.55766
[32m[0907 07-03-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19291, current rewards: -804.10008, mean: -1.57667
[32m[0907 07-04-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19205, current rewards: -904.10008, mean: -1.61446
[32m[0907 07-04-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19089, current rewards: -1004.10008, mean: -1.64607
[32m[0907 07-04-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18988, current rewards: -1104.10008, mean: -1.67288
[32m[0907 07-04-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18900, current rewards: -1204.10008, mean: -1.69592
[32m[0907 07-04-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18831, current rewards: -1304.10008, mean: -1.71592
[32m[0907 07-04-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18764, current rewards: -1404.10008, mean: -1.73346
[32m[0907 07-04-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18707, current rewards: -1504.10008, mean: -1.74895
[32m[0907 07-05-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18656, current rewards: -1604.10008, mean: -1.76275
[32m[0907 07-05-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18613, current rewards: -1704.10008, mean: -1.77510
[32m[0907 07-05-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18568, current rewards: -1804.10008, mean: -1.78624
[32m[0907 07-05-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18531, current rewards: -1904.10008, mean: -1.79632
[32m[0907 07-05-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18497, current rewards: -2004.10008, mean: -1.80550
[32m[0907 07-05-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18466, current rewards: -2104.10008, mean: -1.81388
[32m[0907 07-05-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18441, current rewards: -2204.10008, mean: -1.82157
[32m[0907 07-06-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18416, current rewards: -2304.10008, mean: -1.82865
[32m[0907 07-06-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18393, current rewards: -2404.10008, mean: -1.83519
[32m[0907 07-06-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18369, current rewards: -2504.10008, mean: -1.84125
[32m[0907 07-06-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18350, current rewards: -2604.10008, mean: -1.84688
[32m[0907 07-06-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18332, current rewards: -2704.10008, mean: -1.85212
[32m[0907 07-06-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18314, current rewards: -2804.10008, mean: -1.85702
[32m[0907 07-07-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18317, current rewards: -2904.10008, mean: -1.86160
[32m[0907 07-07-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18320, current rewards: -3004.10008, mean: -1.86590
[32m[0907 07-07-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18322, current rewards: -3104.10008, mean: -1.86994
[32m[0907 07-07-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18323, current rewards: -3204.10008, mean: -1.87374
[32m[0907 07-07-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18326, current rewards: -3304.10008, mean: -1.87733
[32m[0907 07-07-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18326, current rewards: -3404.10008, mean: -1.88072
[32m[0907 07-07-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18327, current rewards: -3504.10008, mean: -1.88392
[32m[0907 07-08-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18344, current rewards: -3604.10008, mean: -1.88696
[32m[0907 07-08-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18359, current rewards: -3704.10008, mean: -1.88985
[32m[0907 07-08-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18371, current rewards: -3804.10008, mean: -1.89259
[32m[0907 07-08-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18384, current rewards: -3904.10008, mean: -1.89519
[32m[0907 07-08-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18397, current rewards: -4004.10008, mean: -1.89768
[32m[0907 07-08-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18406, current rewards: -4104.10008, mean: -1.90005
[32m[0907 07-09-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18417, current rewards: -4204.10008, mean: -1.90231
[32m[0907 07-09-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18424, current rewards: -4304.10008, mean: -1.90447
[32m[0907 07-09-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18423, current rewards: -4404.10008, mean: -1.90654
[32m[0907 07-09-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18422, current rewards: -4504.10008, mean: -1.90852
[32m[0907 07-09-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18421, current rewards: -4604.10008, mean: -1.91041
[32m[0907 07-09-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18421, current rewards: -4704.10008, mean: -1.91224
[32m[0907 07-09-57 @Agent.py:117][0m Average action selection time: 0.1842
[32m[0907 07-09-57 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-09-57 @MBExp.py:227][0m Rewards obtained: [-4784.100075556764], Lows: [2382], Highs: [41], Total time: 50441.52434399998
[32m[0907 07-13-46 @MBExp.py:144][0m ####################################################################
[32m[0907 07-13-46 @MBExp.py:145][0m Starting training iteration 111.
[32m[0907 07-13-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18212, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-13-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18353, current rewards: -67.77775, mean: -1.12963
[32m[0907 07-14-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18369, current rewards: -164.99015, mean: -1.49991
[32m[0907 07-14-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18706, current rewards: -257.39124, mean: -1.60870
[32m[0907 07-14-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18749, current rewards: -354.55230, mean: -1.68834
[32m[0907 07-14-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18680, current rewards: -454.55230, mean: -1.74828
[32m[0907 07-14-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18631, current rewards: -554.55230, mean: -1.78888
[32m[0907 07-14-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18592, current rewards: -654.55230, mean: -1.81820
[32m[0907 07-15-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18563, current rewards: -754.55230, mean: -1.84037
[32m[0907 07-15-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18576, current rewards: -841.04490, mean: -1.82836
[32m[0907 07-15-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18702, current rewards: -913.89233, mean: -1.79195
[32m[0907 07-15-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18720, current rewards: -993.60671, mean: -1.77430
[32m[0907 07-15-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18706, current rewards: -1080.42797, mean: -1.77119
[32m[0907 07-15-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18721, current rewards: -1158.73254, mean: -1.75566
[32m[0907 07-15-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18714, current rewards: -1236.80082, mean: -1.74197
[32m[0907 07-16-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18674, current rewards: -1331.94711, mean: -1.75256
[32m[0907 07-16-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18687, current rewards: -1425.09422, mean: -1.75938
[32m[0907 07-16-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18697, current rewards: -1514.44003, mean: -1.76098
[32m[0907 07-16-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18651, current rewards: -1600.68647, mean: -1.75900
[32m[0907 07-16-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18694, current rewards: -1694.06900, mean: -1.76466
[32m[0907 07-16-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18668, current rewards: -1771.53766, mean: -1.75400
[32m[0907 07-17-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18692, current rewards: -1844.43864, mean: -1.74004
[32m[0907 07-17-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18661, current rewards: -1926.62120, mean: -1.73569
[32m[0907 07-17-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18638, current rewards: -2008.54114, mean: -1.73150
[32m[0907 07-17-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18619, current rewards: -2095.99819, mean: -1.73223
[32m[0907 07-17-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18587, current rewards: -2187.58703, mean: -1.73618
[32m[0907 07-17-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18557, current rewards: -2277.07100, mean: -1.73822
[32m[0907 07-17-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18530, current rewards: -2368.65883, mean: -1.74166
[32m[0907 07-18-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18505, current rewards: -2458.14206, mean: -1.74336
[32m[0907 07-18-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18481, current rewards: -2549.73089, mean: -1.74639
[32m[0907 07-18-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18480, current rewards: -2647.39262, mean: -1.75324
[32m[0907 07-18-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18478, current rewards: -2747.39262, mean: -1.76115
[32m[0907 07-18-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18477, current rewards: -2847.39262, mean: -1.76857
[32m[0907 07-18-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18475, current rewards: -2947.39262, mean: -1.77554
[32m[0907 07-19-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18474, current rewards: -3047.39262, mean: -1.78210
[32m[0907 07-19-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18471, current rewards: -3147.39262, mean: -1.78829
[32m[0907 07-19-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18470, current rewards: -3247.39262, mean: -1.79414
[32m[0907 07-19-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18480, current rewards: -3347.39262, mean: -1.79967
[32m[0907 07-19-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18490, current rewards: -3447.39262, mean: -1.80492
[32m[0907 07-19-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18499, current rewards: -3547.39262, mean: -1.80989
[32m[0907 07-19-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18510, current rewards: -3647.39262, mean: -1.81462
[32m[0907 07-20-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18518, current rewards: -3747.39262, mean: -1.81912
[32m[0907 07-20-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18525, current rewards: -3847.39262, mean: -1.82341
[32m[0907 07-20-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18533, current rewards: -3947.39262, mean: -1.82750
[32m[0907 07-20-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18540, current rewards: -4047.39262, mean: -1.83140
[32m[0907 07-20-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18542, current rewards: -4147.39262, mean: -1.83513
[32m[0907 07-20-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18541, current rewards: -4237.39262, mean: -1.83437
[32m[0907 07-21-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18538, current rewards: -4337.39262, mean: -1.83788
[32m[0907 07-21-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18536, current rewards: -4437.39262, mean: -1.84124
[32m[0907 07-21-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18532, current rewards: -4537.39262, mean: -1.84447
[32m[0907 07-21-30 @Agent.py:117][0m Average action selection time: 0.1853
[32m[0907 07-21-30 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-21-30 @MBExp.py:227][0m Rewards obtained: [-4617.392616958848], Lows: [2303], Highs: [44], Total time: 50905.64215799998
[32m[0907 07-25-21 @MBExp.py:144][0m ####################################################################
[32m[0907 07-25-21 @MBExp.py:145][0m Starting training iteration 112.
[32m[0907 07-25-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20721, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-25-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20663, current rewards: -41.40990, mean: -0.69016
[32m[0907 07-25-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19847, current rewards: -91.40990, mean: -0.83100
[32m[0907 07-25-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19427, current rewards: -141.40990, mean: -0.88381
[32m[0907 07-26-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19187, current rewards: -191.40990, mean: -0.91148
[32m[0907 07-26-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19032, current rewards: -241.40990, mean: -0.92850
[32m[0907 07-26-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18921, current rewards: -291.40990, mean: -0.94003
[32m[0907 07-26-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18841, current rewards: -341.40990, mean: -0.94836
[32m[0907 07-26-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18781, current rewards: -391.40990, mean: -0.95466
[32m[0907 07-26-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18735, current rewards: -441.40990, mean: -0.95959
[32m[0907 07-26-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18647, current rewards: -491.40990, mean: -0.96355
[32m[0907 07-27-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18573, current rewards: -541.40990, mean: -0.96680
[32m[0907 07-27-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18510, current rewards: -591.40990, mean: -0.96952
[32m[0907 07-27-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18454, current rewards: -641.40990, mean: -0.97183
[32m[0907 07-27-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18409, current rewards: -691.40990, mean: -0.97382
[32m[0907 07-27-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18369, current rewards: -741.40990, mean: -0.97554
[32m[0907 07-27-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18336, current rewards: -791.40990, mean: -0.97705
[32m[0907 07-27-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18303, current rewards: -818.00087, mean: -0.95116
[32m[0907 07-28-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18275, current rewards: -814.79855, mean: -0.89538
[32m[0907 07-28-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18251, current rewards: -811.59622, mean: -0.84541
[32m[0907 07-28-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18230, current rewards: -808.39389, mean: -0.80039
[32m[0907 07-28-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18209, current rewards: -805.19156, mean: -0.75961
[32m[0907 07-28-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18191, current rewards: -801.98924, mean: -0.72251
[32m[0907 07-28-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18176, current rewards: -799.09799, mean: -0.68888
[32m[0907 07-29-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18161, current rewards: -796.62791, mean: -0.65837
[32m[0907 07-29-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18148, current rewards: -798.35544, mean: -0.63362
[32m[0907 07-29-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18136, current rewards: -848.35544, mean: -0.64760
[32m[0907 07-29-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18124, current rewards: -898.35544, mean: -0.66056
[32m[0907 07-29-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18115, current rewards: -948.35544, mean: -0.67259
[32m[0907 07-29-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18108, current rewards: -998.35544, mean: -0.68381
[32m[0907 07-29-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18119, current rewards: -1048.35544, mean: -0.69428
[32m[0907 07-30-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18130, current rewards: -1098.35544, mean: -0.70407
[32m[0907 07-30-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18138, current rewards: -1148.35544, mean: -0.71326
[32m[0907 07-30-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18147, current rewards: -1198.35544, mean: -0.72190
[32m[0907 07-30-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18156, current rewards: -1248.35544, mean: -0.73003
[32m[0907 07-30-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18165, current rewards: -1298.35544, mean: -0.73770
[32m[0907 07-30-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18175, current rewards: -1348.35544, mean: -0.74495
[32m[0907 07-31-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18196, current rewards: -1398.35544, mean: -0.75180
[32m[0907 07-31-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18215, current rewards: -1448.35544, mean: -0.75830
[32m[0907 07-31-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18230, current rewards: -1498.35544, mean: -0.76447
[32m[0907 07-31-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18247, current rewards: -1548.35544, mean: -0.77033
[32m[0907 07-31-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18261, current rewards: -1598.35544, mean: -0.77590
[32m[0907 07-31-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18276, current rewards: -1648.35544, mean: -0.78121
[32m[0907 07-31-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18291, current rewards: -1698.35544, mean: -0.78628
[32m[0907 07-32-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18305, current rewards: -1748.35544, mean: -0.79111
[32m[0907 07-32-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18319, current rewards: -1798.35544, mean: -0.79573
[32m[0907 07-32-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18332, current rewards: -1848.35544, mean: -0.80015
[32m[0907 07-32-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18343, current rewards: -1898.35544, mean: -0.80439
[32m[0907 07-32-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18354, current rewards: -1948.35544, mean: -0.80845
[32m[0907 07-32-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18355, current rewards: -1998.35544, mean: -0.81234
[32m[0907 07-33-01 @Agent.py:117][0m Average action selection time: 0.1836
[32m[0907 07-33-01 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-33-01 @MBExp.py:227][0m Rewards obtained: [-2038.3554391985822], Lows: [5], Highs: [2056], Total time: 51365.46240099998
[32m[0907 07-36-54 @MBExp.py:144][0m ####################################################################
[32m[0907 07-36-54 @MBExp.py:145][0m Starting training iteration 113.
[32m[0907 07-36-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30369, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-37-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.27874, current rewards: -24.69528, mean: -0.41159
[32m[0907 07-37-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.27454, current rewards: -76.58581, mean: -0.69623
[32m[0907 07-37-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.24632, current rewards: -126.58581, mean: -0.79116
[32m[0907 07-37-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.23140, current rewards: -176.58581, mean: -0.84088
[32m[0907 07-37-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.22234, current rewards: -226.58581, mean: -0.87148
[32m[0907 07-38-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.21611, current rewards: -276.58581, mean: -0.89221
[32m[0907 07-38-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.21168, current rewards: -326.58581, mean: -0.90718
[32m[0907 07-38-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.20830, current rewards: -376.58581, mean: -0.91850
[32m[0907 07-38-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.20507, current rewards: -426.58581, mean: -0.92736
[32m[0907 07-38-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.20241, current rewards: -476.58581, mean: -0.93448
[32m[0907 07-38-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.20026, current rewards: -526.58581, mean: -0.94033
[32m[0907 07-38-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19842, current rewards: -576.58581, mean: -0.94522
[32m[0907 07-39-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19688, current rewards: -626.58581, mean: -0.94937
[32m[0907 07-39-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19551, current rewards: -676.58581, mean: -0.95294
[32m[0907 07-39-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19438, current rewards: -726.58581, mean: -0.95603
[32m[0907 07-39-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19339, current rewards: -776.58581, mean: -0.95875
[32m[0907 07-39-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19249, current rewards: -826.58581, mean: -0.96115
[32m[0907 07-39-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19168, current rewards: -876.58581, mean: -0.96328
[32m[0907 07-39-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19094, current rewards: -909.54898, mean: -0.94745
[32m[0907 07-40-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19033, current rewards: -903.09016, mean: -0.89415
[32m[0907 07-40-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18975, current rewards: -896.63134, mean: -0.84588
[32m[0907 07-40-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18925, current rewards: -890.57157, mean: -0.80232
[32m[0907 07-40-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18878, current rewards: -887.51878, mean: -0.76510
[32m[0907 07-40-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18834, current rewards: -884.48135, mean: -0.73098
[32m[0907 07-40-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18792, current rewards: -881.44392, mean: -0.69956
[32m[0907 07-41-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18754, current rewards: -878.40649, mean: -0.67054
[32m[0907 07-41-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18720, current rewards: -875.36906, mean: -0.64365
[32m[0907 07-41-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18694, current rewards: -872.33163, mean: -0.61867
[32m[0907 07-41-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18685, current rewards: -869.29420, mean: -0.59541
[32m[0907 07-41-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18675, current rewards: -866.25678, mean: -0.57368
[32m[0907 07-41-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18668, current rewards: -885.73082, mean: -0.56778
[32m[0907 07-41-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18659, current rewards: -935.73082, mean: -0.58120
[32m[0907 07-42-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18652, current rewards: -985.73082, mean: -0.59381
[32m[0907 07-42-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18645, current rewards: -1035.73082, mean: -0.60569
[32m[0907 07-42-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18639, current rewards: -1085.73082, mean: -0.61689
[32m[0907 07-42-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18647, current rewards: -1135.73082, mean: -0.62748
[32m[0907 07-42-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18652, current rewards: -1185.73082, mean: -0.63749
[32m[0907 07-42-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18657, current rewards: -1235.73082, mean: -0.64698
[32m[0907 07-43-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18663, current rewards: -1285.73082, mean: -0.65599
[32m[0907 07-43-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18668, current rewards: -1335.73082, mean: -0.66454
[32m[0907 07-43-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18672, current rewards: -1385.73082, mean: -0.67268
[32m[0907 07-43-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18676, current rewards: -1435.73082, mean: -0.68044
[32m[0907 07-43-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18681, current rewards: -1485.73082, mean: -0.68784
[32m[0907 07-43-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18684, current rewards: -1535.73082, mean: -0.69490
[32m[0907 07-43-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18687, current rewards: -1585.73082, mean: -0.70165
[32m[0907 07-44-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18691, current rewards: -1635.73082, mean: -0.70811
[32m[0907 07-44-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18694, current rewards: -1685.73082, mean: -0.71429
[32m[0907 07-44-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18689, current rewards: -1735.73082, mean: -0.72022
[32m[0907 07-44-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18684, current rewards: -1785.73082, mean: -0.72591
[32m[0907 07-44-41 @Agent.py:117][0m Average action selection time: 0.1868
[32m[0907 07-44-41 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-44-41 @MBExp.py:227][0m Rewards obtained: [-1825.730820005615], Lows: [29], Highs: [1821], Total time: 51833.31611599998
[32m[0907 07-48-36 @MBExp.py:144][0m ####################################################################
[32m[0907 07-48-36 @MBExp.py:145][0m Starting training iteration 114.
[32m[0907 07-48-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18322, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-48-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18523, current rewards: -110.00000, mean: -1.83333
[32m[0907 07-48-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18481, current rewards: -210.00000, mean: -1.90909
[32m[0907 07-49-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18470, current rewards: -310.00000, mean: -1.93750
[32m[0907 07-49-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18453, current rewards: -410.00000, mean: -1.95238
[32m[0907 07-49-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18443, current rewards: -510.00000, mean: -1.96154
[32m[0907 07-49-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18431, current rewards: -610.00000, mean: -1.96774
[32m[0907 07-49-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18433, current rewards: -710.00000, mean: -1.97222
[32m[0907 07-49-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18386, current rewards: -810.00000, mean: -1.97561
[32m[0907 07-50-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18323, current rewards: -910.00000, mean: -1.97826
[32m[0907 07-50-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18275, current rewards: -1010.00000, mean: -1.98039
[32m[0907 07-50-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18230, current rewards: -1110.00000, mean: -1.98214
[32m[0907 07-50-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18188, current rewards: -1210.00000, mean: -1.98361
[32m[0907 07-50-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18159, current rewards: -1310.00000, mean: -1.98485
[32m[0907 07-50-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18133, current rewards: -1410.00000, mean: -1.98592
[32m[0907 07-50-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18111, current rewards: -1510.00000, mean: -1.98684
[32m[0907 07-51-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18094, current rewards: -1610.00000, mean: -1.98765
[32m[0907 07-51-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18077, current rewards: -1710.00000, mean: -1.98837
[32m[0907 07-51-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18061, current rewards: -1810.00000, mean: -1.98901
[32m[0907 07-51-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18047, current rewards: -1910.00000, mean: -1.98958
[32m[0907 07-51-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18034, current rewards: -2010.00000, mean: -1.99010
[32m[0907 07-51-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18025, current rewards: -2110.00000, mean: -1.99057
[32m[0907 07-51-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18015, current rewards: -2210.00000, mean: -1.99099
[32m[0907 07-52-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18005, current rewards: -2310.00000, mean: -1.99138
[32m[0907 07-52-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17996, current rewards: -2410.00000, mean: -1.99174
[32m[0907 07-52-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17988, current rewards: -2510.00000, mean: -1.99206
[32m[0907 07-52-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17982, current rewards: -2610.00000, mean: -1.99237
[32m[0907 07-52-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17977, current rewards: -2710.00000, mean: -1.99265
[32m[0907 07-52-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17982, current rewards: -2810.00000, mean: -1.99291
[32m[0907 07-52-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17996, current rewards: -2910.00000, mean: -1.99315
[32m[0907 07-53-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18010, current rewards: -3010.00000, mean: -1.99338
[32m[0907 07-53-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18022, current rewards: -3110.00000, mean: -1.99359
[32m[0907 07-53-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18033, current rewards: -3210.00000, mean: -1.99379
[32m[0907 07-53-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18043, current rewards: -3310.00000, mean: -1.99398
[32m[0907 07-53-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18052, current rewards: -3410.00000, mean: -1.99415
[32m[0907 07-53-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18068, current rewards: -3510.00000, mean: -1.99432
[32m[0907 07-54-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18093, current rewards: -3610.00000, mean: -1.99448
[32m[0907 07-54-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18114, current rewards: -3710.00000, mean: -1.99462
[32m[0907 07-54-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18134, current rewards: -3810.00000, mean: -1.99476
[32m[0907 07-54-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18153, current rewards: -3910.00000, mean: -1.99490
[32m[0907 07-54-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18170, current rewards: -4010.00000, mean: -1.99502
[32m[0907 07-54-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18187, current rewards: -4110.00000, mean: -1.99515
[32m[0907 07-55-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18204, current rewards: -4210.00000, mean: -1.99526
[32m[0907 07-55-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18219, current rewards: -4310.00000, mean: -1.99537
[32m[0907 07-55-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18234, current rewards: -4410.00000, mean: -1.99548
[32m[0907 07-55-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18249, current rewards: -4510.00000, mean: -1.99558
[32m[0907 07-55-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18261, current rewards: -4610.00000, mean: -1.99567
[32m[0907 07-55-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18274, current rewards: -4710.00000, mean: -1.99576
[32m[0907 07-55-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18287, current rewards: -4810.00000, mean: -1.99585
[32m[0907 07-56-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18290, current rewards: -4910.00000, mean: -1.99593
[32m[0907 07-56-14 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0907 07-56-14 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-56-15 @MBExp.py:227][0m Rewards obtained: [-4990], Lows: [2490], Highs: [10], Total time: 52291.49296399998
[32m[0907 08-00-11 @MBExp.py:144][0m ####################################################################
[32m[0907 08-00-11 @MBExp.py:145][0m Starting training iteration 115.
[32m[0907 08-00-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18259, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-00-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.26560, current rewards: -56.69776, mean: -0.94496
[32m[0907 08-00-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.28057, current rewards: -107.59474, mean: -0.97813
[32m[0907 08-00-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.27613, current rewards: -147.94067, mean: -0.92463
[32m[0907 08-01-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.27381, current rewards: -199.65644, mean: -0.95074
[32m[0907 08-01-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.25652, current rewards: -249.54250, mean: -0.95978
[32m[0907 08-01-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.24403, current rewards: -299.54250, mean: -0.96627
[32m[0907 08-01-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.23484, current rewards: -349.54250, mean: -0.97095
[32m[0907 08-01-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.22796, current rewards: -399.54250, mean: -0.97449
[32m[0907 08-01-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.22249, current rewards: -449.54250, mean: -0.97727
[32m[0907 08-02-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.21812, current rewards: -499.54250, mean: -0.97950
[32m[0907 08-02-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.21454, current rewards: -549.54250, mean: -0.98133
[32m[0907 08-02-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.21155, current rewards: -599.54250, mean: -0.98286
[32m[0907 08-02-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.20901, current rewards: -649.54250, mean: -0.98416
[32m[0907 08-02-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.21065, current rewards: -695.86840, mean: -0.98010
[32m[0907 08-02-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.20853, current rewards: -783.73487, mean: -1.03123
[32m[0907 08-02-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.20662, current rewards: -877.37453, mean: -1.08318
[32m[0907 08-03-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.20497, current rewards: -972.19820, mean: -1.13046
[32m[0907 08-03-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.20568, current rewards: -1050.30626, mean: -1.15418
[32m[0907 08-03-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.21025, current rewards: -1046.41651, mean: -1.09002
[32m[0907 08-03-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.20895, current rewards: -1080.65753, mean: -1.06996
[32m[0907 08-03-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.20766, current rewards: -1127.51338, mean: -1.06369
[32m[0907 08-04-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.20634, current rewards: -1177.51338, mean: -1.06082
[32m[0907 08-04-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.20512, current rewards: -1227.51338, mean: -1.05820
[32m[0907 08-04-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.20399, current rewards: -1277.51338, mean: -1.05580
[32m[0907 08-04-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.20323, current rewards: -1333.25741, mean: -1.05814
[32m[0907 08-04-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.20266, current rewards: -1413.91853, mean: -1.07933
[32m[0907 08-04-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.20197, current rewards: -1513.91853, mean: -1.11318
[32m[0907 08-04-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.20134, current rewards: -1613.91853, mean: -1.14462
[32m[0907 08-05-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.20074, current rewards: -1713.91853, mean: -1.17392
[32m[0907 08-05-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.20019, current rewards: -1813.91853, mean: -1.20127
[32m[0907 08-05-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.19968, current rewards: -1913.91853, mean: -1.22687
[32m[0907 08-05-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.19932, current rewards: -2013.91853, mean: -1.25088
[32m[0907 08-05-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.19905, current rewards: -2113.91853, mean: -1.27344
[32m[0907 08-05-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.19877, current rewards: -2213.91853, mean: -1.29469
[32m[0907 08-06-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.19851, current rewards: -2313.91853, mean: -1.31473
[32m[0907 08-06-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.19826, current rewards: -2413.91853, mean: -1.33366
[32m[0907 08-06-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.19799, current rewards: -2513.91853, mean: -1.35157
[32m[0907 08-06-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.19773, current rewards: -2613.91853, mean: -1.36854
[32m[0907 08-06-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.19751, current rewards: -2713.91853, mean: -1.38465
[32m[0907 08-06-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.19730, current rewards: -2813.91853, mean: -1.39996
[32m[0907 08-06-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.19709, current rewards: -2913.91853, mean: -1.41452
[32m[0907 08-07-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.19691, current rewards: -3013.91853, mean: -1.42840
[32m[0907 08-07-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.19671, current rewards: -3113.91853, mean: -1.44163
[32m[0907 08-07-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.19652, current rewards: -3213.91853, mean: -1.45426
[32m[0907 08-07-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.19634, current rewards: -3313.91853, mean: -1.46634
[32m[0907 08-07-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.19609, current rewards: -3413.91853, mean: -1.47789
[32m[0907 08-07-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.19583, current rewards: -3513.91853, mean: -1.48895
[32m[0907 08-08-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.19549, current rewards: -3613.91853, mean: -1.49955
[32m[0907 08-08-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.19515, current rewards: -3713.91853, mean: -1.50972
[32m[0907 08-08-19 @Agent.py:117][0m Average action selection time: 0.1949
[32m[0907 08-08-19 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-08-20 @MBExp.py:227][0m Rewards obtained: [-3793.918532538961], Lows: [1448], Highs: [915], Total time: 52779.62661699998
[32m[0907 08-12-19 @MBExp.py:144][0m ####################################################################
[32m[0907 08-12-19 @MBExp.py:145][0m Starting training iteration 116.
[32m[0907 08-12-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30364, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-12-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20622, current rewards: -69.94988, mean: -1.16583
[32m[0907 08-12-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19595, current rewards: -119.94988, mean: -1.09045
[32m[0907 08-12-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19219, current rewards: -169.94988, mean: -1.06219
[32m[0907 08-12-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18986, current rewards: -219.94988, mean: -1.04738
[32m[0907 08-13-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18770, current rewards: -269.94988, mean: -1.03827
[32m[0907 08-13-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18625, current rewards: -319.94988, mean: -1.03210
[32m[0907 08-13-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18517, current rewards: -367.79376, mean: -1.02165
[32m[0907 08-13-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18430, current rewards: -413.39135, mean: -1.00827
[32m[0907 08-13-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18366, current rewards: -458.06062, mean: -0.99578
[32m[0907 08-13-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18311, current rewards: -508.06062, mean: -0.99620
[32m[0907 08-14-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18269, current rewards: -558.06062, mean: -0.99654
[32m[0907 08-14-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18235, current rewards: -608.06062, mean: -0.99682
[32m[0907 08-14-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18204, current rewards: -658.06062, mean: -0.99706
[32m[0907 08-14-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18176, current rewards: -708.06062, mean: -0.99727
[32m[0907 08-14-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18156, current rewards: -758.06062, mean: -0.99745
[32m[0907 08-14-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18135, current rewards: -808.06062, mean: -0.99761
[32m[0907 08-14-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18117, current rewards: -858.06062, mean: -0.99774
[32m[0907 08-15-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18104, current rewards: -908.06062, mean: -0.99787
[32m[0907 08-15-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18089, current rewards: -958.06062, mean: -0.99798
[32m[0907 08-15-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18075, current rewards: -1008.06062, mean: -0.99808
[32m[0907 08-15-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18129, current rewards: -1021.89737, mean: -0.96405
[32m[0907 08-15-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18186, current rewards: -1051.93719, mean: -0.94769
[32m[0907 08-15-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18172, current rewards: -1048.13794, mean: -0.90357
[32m[0907 08-16-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18168, current rewards: -1061.55445, mean: -0.87732
[32m[0907 08-16-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18178, current rewards: -1101.10370, mean: -0.87389
[32m[0907 08-16-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18224, current rewards: -1142.64006, mean: -0.87224
[32m[0907 08-16-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18258, current rewards: -1185.62495, mean: -0.87178
[32m[0907 08-16-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18267, current rewards: -1227.86445, mean: -0.87083
[32m[0907 08-16-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18271, current rewards: -1277.86445, mean: -0.87525
[32m[0907 08-16-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18277, current rewards: -1327.86445, mean: -0.87938
[32m[0907 08-17-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18282, current rewards: -1377.86445, mean: -0.88325
[32m[0907 08-17-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18301, current rewards: -1427.86445, mean: -0.88687
[32m[0907 08-17-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18322, current rewards: -1477.86445, mean: -0.89028
[32m[0907 08-17-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18341, current rewards: -1527.86445, mean: -0.89349
[32m[0907 08-17-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18359, current rewards: -1577.86445, mean: -0.89651
[32m[0907 08-17-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18373, current rewards: -1627.86445, mean: -0.89937
[32m[0907 08-18-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18385, current rewards: -1676.77952, mean: -0.90149
[32m[0907 08-18-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18404, current rewards: -1717.47942, mean: -0.89920
[32m[0907 08-18-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18415, current rewards: -1767.47942, mean: -0.90178
[32m[0907 08-18-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18426, current rewards: -1817.47942, mean: -0.90422
[32m[0907 08-18-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18438, current rewards: -1867.47942, mean: -0.90654
[32m[0907 08-18-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18447, current rewards: -1917.47942, mean: -0.90876
[32m[0907 08-18-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18457, current rewards: -1967.47942, mean: -0.91087
[32m[0907 08-19-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18465, current rewards: -2017.47942, mean: -0.91289
[32m[0907 08-19-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18474, current rewards: -2067.47942, mean: -0.91481
[32m[0907 08-19-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18471, current rewards: -2117.47942, mean: -0.91666
[32m[0907 08-19-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18465, current rewards: -2167.47942, mean: -0.91842
[32m[0907 08-19-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18453, current rewards: -2217.47942, mean: -0.92012
[32m[0907 08-19-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18440, current rewards: -2267.47942, mean: -0.92174
[32m[0907 08-20-01 @Agent.py:117][0m Average action selection time: 0.1843
[32m[0907 08-20-01 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-20-01 @MBExp.py:227][0m Rewards obtained: [-2307.479421706251], Lows: [46], Highs: [2239], Total time: 53241.290120999976
[32m[0907 08-24-02 @MBExp.py:144][0m ####################################################################
[32m[0907 08-24-02 @MBExp.py:145][0m Starting training iteration 117.
[32m[0907 08-24-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18220, current rewards: -8.95171, mean: -0.89517
[32m[0907 08-24-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18360, current rewards: -61.75379, mean: -1.02923
[32m[0907 08-24-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18378, current rewards: -121.53114, mean: -1.10483
[32m[0907 08-24-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18349, current rewards: -161.40348, mean: -1.00877
[32m[0907 08-24-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18218, current rewards: -157.06875, mean: -0.74795
[32m[0907 08-24-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18137, current rewards: -191.10975, mean: -0.73504
[32m[0907 08-24-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18084, current rewards: -241.10975, mean: -0.77777
[32m[0907 08-25-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18043, current rewards: -291.10975, mean: -0.80864
[32m[0907 08-25-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18020, current rewards: -341.10975, mean: -0.83198
[32m[0907 08-25-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17997, current rewards: -391.10975, mean: -0.85024
[32m[0907 08-25-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17986, current rewards: -441.10975, mean: -0.86492
[32m[0907 08-25-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17971, current rewards: -491.10975, mean: -0.87698
[32m[0907 08-25-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17955, current rewards: -541.10975, mean: -0.88707
[32m[0907 08-26-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17941, current rewards: -591.10975, mean: -0.89562
[32m[0907 08-26-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17931, current rewards: -641.10975, mean: -0.90297
[32m[0907 08-26-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17922, current rewards: -691.10975, mean: -0.90935
[32m[0907 08-26-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17912, current rewards: -741.10975, mean: -0.91495
[32m[0907 08-26-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17906, current rewards: -791.10975, mean: -0.91990
[32m[0907 08-26-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17899, current rewards: -841.10975, mean: -0.92430
[32m[0907 08-26-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17895, current rewards: -891.10975, mean: -0.92824
[32m[0907 08-27-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17888, current rewards: -941.10975, mean: -0.93179
[32m[0907 08-27-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17884, current rewards: -991.10975, mean: -0.93501
[32m[0907 08-27-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17881, current rewards: -1041.10975, mean: -0.93794
[32m[0907 08-27-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17875, current rewards: -1091.10975, mean: -0.94061
[32m[0907 08-27-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17872, current rewards: -1141.10975, mean: -0.94307
[32m[0907 08-27-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17876, current rewards: -1191.10975, mean: -0.94533
[32m[0907 08-27-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17898, current rewards: -1241.10975, mean: -0.94741
[32m[0907 08-28-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17916, current rewards: -1291.10975, mean: -0.94935
[32m[0907 08-28-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17932, current rewards: -1341.10975, mean: -0.95114
[32m[0907 08-28-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17947, current rewards: -1391.10975, mean: -0.95281
[32m[0907 08-28-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17960, current rewards: -1441.10975, mean: -0.95438
[32m[0907 08-28-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17979, current rewards: -1491.10975, mean: -0.95584
[32m[0907 08-28-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18008, current rewards: -1541.10975, mean: -0.95721
[32m[0907 08-29-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18032, current rewards: -1591.10975, mean: -0.95850
[32m[0907 08-29-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18055, current rewards: -1641.10975, mean: -0.95971
[32m[0907 08-29-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18076, current rewards: -1691.10975, mean: -0.96086
[32m[0907 08-29-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18098, current rewards: -1741.10975, mean: -0.96194
[32m[0907 08-29-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18117, current rewards: -1791.10975, mean: -0.96296
[32m[0907 08-29-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18135, current rewards: -1841.10975, mean: -0.96393
[32m[0907 08-29-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18155, current rewards: -1891.10975, mean: -0.96485
[32m[0907 08-30-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18172, current rewards: -1941.10975, mean: -0.96573
[32m[0907 08-30-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18188, current rewards: -1991.10975, mean: -0.96656
[32m[0907 08-30-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18204, current rewards: -2041.10975, mean: -0.96735
[32m[0907 08-30-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18218, current rewards: -2091.10975, mean: -0.96811
[32m[0907 08-30-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18230, current rewards: -2141.10975, mean: -0.96883
[32m[0907 08-30-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18242, current rewards: -2191.10975, mean: -0.96952
[32m[0907 08-31-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18250, current rewards: -2241.10975, mean: -0.97018
[32m[0907 08-31-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18248, current rewards: -2291.10975, mean: -0.97081
[32m[0907 08-31-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18239, current rewards: -2341.10975, mean: -0.97141
[32m[0907 08-31-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18230, current rewards: -2391.10975, mean: -0.97200
[32m[0907 08-31-38 @Agent.py:117][0m Average action selection time: 0.1822
[32m[0907 08-31-38 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-31-38 @MBExp.py:227][0m Rewards obtained: [-2431.109754559623], Lows: [82], Highs: [2284], Total time: 53697.74103999998
[32m[0907 08-35-41 @MBExp.py:144][0m ####################################################################
[32m[0907 08-35-41 @MBExp.py:145][0m Starting training iteration 118.
[32m[0907 08-35-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18794, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-35-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18962, current rewards: -72.16415, mean: -1.20274
[32m[0907 08-36-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18690, current rewards: -135.81558, mean: -1.23469
[32m[0907 08-36-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18503, current rewards: -195.64174, mean: -1.22276
[32m[0907 08-36-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18391, current rewards: -245.28490, mean: -1.16802
[32m[0907 08-36-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18287, current rewards: -307.09697, mean: -1.18114
[32m[0907 08-36-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18223, current rewards: -383.33432, mean: -1.23656
[32m[0907 08-36-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18202, current rewards: -442.42873, mean: -1.22897
[32m[0907 08-36-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18158, current rewards: -542.42873, mean: -1.32300
[32m[0907 08-37-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18122, current rewards: -642.42873, mean: -1.39658
[32m[0907 08-37-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18096, current rewards: -742.42873, mean: -1.45574
[32m[0907 08-37-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18072, current rewards: -842.42873, mean: -1.50434
[32m[0907 08-37-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18054, current rewards: -942.42873, mean: -1.54497
[32m[0907 08-37-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18032, current rewards: -1042.42873, mean: -1.57944
[32m[0907 08-37-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18014, current rewards: -1142.42873, mean: -1.60905
[32m[0907 08-37-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18006, current rewards: -1242.42873, mean: -1.63477
[32m[0907 08-38-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17996, current rewards: -1342.42873, mean: -1.65732
[32m[0907 08-38-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17987, current rewards: -1442.42873, mean: -1.67724
[32m[0907 08-38-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17978, current rewards: -1542.42873, mean: -1.69498
[32m[0907 08-38-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17970, current rewards: -1642.42873, mean: -1.71086
[32m[0907 08-38-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17964, current rewards: -1742.42873, mean: -1.72518
[32m[0907 08-38-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17957, current rewards: -1842.42873, mean: -1.73814
[32m[0907 08-39-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17951, current rewards: -1942.42873, mean: -1.74994
[32m[0907 08-39-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17945, current rewards: -2042.42873, mean: -1.76071
[32m[0907 08-39-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17939, current rewards: -2142.42873, mean: -1.77060
[32m[0907 08-39-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17945, current rewards: -2242.42873, mean: -1.77971
[32m[0907 08-39-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17962, current rewards: -2342.42873, mean: -1.78811
[32m[0907 08-39-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17978, current rewards: -2442.42873, mean: -1.79590
[32m[0907 08-39-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17991, current rewards: -2542.42873, mean: -1.80314
[32m[0907 08-40-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18006, current rewards: -2642.42873, mean: -1.80988
[32m[0907 08-40-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18022, current rewards: -2742.42873, mean: -1.81618
[32m[0907 08-40-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18047, current rewards: -2842.42873, mean: -1.82207
[32m[0907 08-40-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18076, current rewards: -2942.42873, mean: -1.82760
[32m[0907 08-40-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18102, current rewards: -3042.42873, mean: -1.83279
[32m[0907 08-40-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18126, current rewards: -3142.42873, mean: -1.83768
[32m[0907 08-41-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18148, current rewards: -3242.42873, mean: -1.84229
[32m[0907 08-41-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18169, current rewards: -3342.42873, mean: -1.84665
[32m[0907 08-41-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18188, current rewards: -3442.42873, mean: -1.85077
[32m[0907 08-41-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18205, current rewards: -3542.42873, mean: -1.85467
[32m[0907 08-41-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18224, current rewards: -3642.42873, mean: -1.85838
[32m[0907 08-41-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18239, current rewards: -3742.42873, mean: -1.86190
[32m[0907 08-41-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18254, current rewards: -3842.42873, mean: -1.86526
[32m[0907 08-42-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18269, current rewards: -3942.42873, mean: -1.86845
[32m[0907 08-42-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18281, current rewards: -4042.42873, mean: -1.87149
[32m[0907 08-42-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18297, current rewards: -4142.42873, mean: -1.87440
[32m[0907 08-42-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18310, current rewards: -4242.42873, mean: -1.87718
[32m[0907 08-42-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18319, current rewards: -4342.42873, mean: -1.87984
[32m[0907 08-42-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18316, current rewards: -4442.42873, mean: -1.88239
[32m[0907 08-43-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18305, current rewards: -4542.42873, mean: -1.88483
[32m[0907 08-43-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18296, current rewards: -4642.42873, mean: -1.88717
[32m[0907 08-43-19 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0907 08-43-19 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-43-19 @MBExp.py:227][0m Rewards obtained: [-4722.428729011103], Lows: [2265], Highs: [197], Total time: 54155.83258299998
[32m[0907 08-47-25 @MBExp.py:144][0m ####################################################################
[32m[0907 08-47-25 @MBExp.py:145][0m Starting training iteration 119.
[32m[0907 08-47-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18404, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-47-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19911, current rewards: -49.08619, mean: -0.81810
[32m[0907 08-47-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19334, current rewards: -90.99227, mean: -0.82720
[32m[0907 08-47-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19249, current rewards: -136.82315, mean: -0.85514
[32m[0907 08-48-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19173, current rewards: -187.18204, mean: -0.89134
[32m[0907 08-48-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18945, current rewards: -229.36551, mean: -0.88218
[32m[0907 08-48-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18844, current rewards: -276.06034, mean: -0.89052
[32m[0907 08-48-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18875, current rewards: -311.53240, mean: -0.86537
[32m[0907 08-48-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18808, current rewards: -351.31970, mean: -0.85688
[32m[0907 08-48-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18768, current rewards: -393.29427, mean: -0.85499
[32m[0907 08-49-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18736, current rewards: -436.12986, mean: -0.85516
[32m[0907 08-49-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18710, current rewards: -478.57207, mean: -0.85459
[32m[0907 08-49-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18697, current rewards: -529.13960, mean: -0.86744
[32m[0907 08-49-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18718, current rewards: -561.42360, mean: -0.85064
[32m[0907 08-49-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18712, current rewards: -594.88149, mean: -0.83786
[32m[0907 08-49-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18700, current rewards: -628.83553, mean: -0.82742
[32m[0907 08-49-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18661, current rewards: -667.75778, mean: -0.82439
[32m[0907 08-50-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18635, current rewards: -711.83309, mean: -0.82771
[32m[0907 08-50-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18588, current rewards: -761.83309, mean: -0.83718
[32m[0907 08-50-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18549, current rewards: -811.83309, mean: -0.84566
[32m[0907 08-50-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18514, current rewards: -861.83309, mean: -0.85330
[32m[0907 08-50-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18480, current rewards: -911.83309, mean: -0.86022
[32m[0907 08-50-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18449, current rewards: -961.83309, mean: -0.86652
[32m[0907 08-50-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18422, current rewards: -1011.83309, mean: -0.87227
[32m[0907 08-51-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18409, current rewards: -1061.83309, mean: -0.87755
[32m[0907 08-51-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18409, current rewards: -1111.83309, mean: -0.88241
[32m[0907 08-51-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18412, current rewards: -1161.83309, mean: -0.88690
[32m[0907 08-51-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18411, current rewards: -1211.83309, mean: -0.89105
[32m[0907 08-51-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18410, current rewards: -1261.83309, mean: -0.89492
[32m[0907 08-51-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18407, current rewards: -1311.83309, mean: -0.89852
[32m[0907 08-52-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18415, current rewards: -1361.83309, mean: -0.90188
[32m[0907 08-52-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18432, current rewards: -1411.83309, mean: -0.90502
[32m[0907 08-52-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18444, current rewards: -1461.83309, mean: -0.90797
[32m[0907 08-52-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18456, current rewards: -1511.83309, mean: -0.91074
[32m[0907 08-52-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18467, current rewards: -1561.83309, mean: -0.91335
[32m[0907 08-52-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18479, current rewards: -1611.83309, mean: -0.91581
[32m[0907 08-53-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18485, current rewards: -1661.83309, mean: -0.91814
[32m[0907 08-53-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18495, current rewards: -1711.83309, mean: -0.92034
[32m[0907 08-53-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18505, current rewards: -1761.83309, mean: -0.92243
[32m[0907 08-53-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18513, current rewards: -1811.83309, mean: -0.92440
[32m[0907 08-53-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18520, current rewards: -1861.83309, mean: -0.92629
[32m[0907 08-53-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18528, current rewards: -1875.04310, mean: -0.91022
[32m[0907 08-53-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18535, current rewards: -1872.48599, mean: -0.88743
[32m[0907 08-54-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18542, current rewards: -1869.92887, mean: -0.86571
[32m[0907 08-54-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18548, current rewards: -1867.37175, mean: -0.84496
[32m[0907 08-54-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18555, current rewards: -1864.69526, mean: -0.82509
[32m[0907 08-54-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18554, current rewards: -1861.94856, mean: -0.80604
[32m[0907 08-54-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18539, current rewards: -1859.20187, mean: -0.78780
[32m[0907 08-54-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18526, current rewards: -1898.65253, mean: -0.78782
[32m[0907 08-55-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18512, current rewards: -1948.65253, mean: -0.79214
[32m[0907 08-55-08 @Agent.py:117][0m Average action selection time: 0.1850
[32m[0907 08-55-08 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-55-08 @MBExp.py:227][0m Rewards obtained: [-1988.6525296256168], Lows: [68], Highs: [1893], Total time: 54619.29632999998
[32m[0907 08-59-14 @MBExp.py:144][0m ####################################################################
[32m[0907 08-59-14 @MBExp.py:145][0m Starting training iteration 120.
[32m[0907 08-59-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.16845, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-59-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17197, current rewards: -101.62794, mean: -1.69380
[32m[0907 08-59-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.16502, current rewards: -201.62794, mean: -1.83298
[32m[0907 08-59-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.15978, current rewards: -301.62794, mean: -1.88517
[32m[0907 08-59-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.15697, current rewards: -401.62794, mean: -1.91251
[32m[0907 08-59-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.15524, current rewards: -501.62794, mean: -1.92934
[32m[0907 09-00-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.15412, current rewards: -601.62794, mean: -1.94074
[32m[0907 09-00-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.15329, current rewards: -701.62794, mean: -1.94897
[32m[0907 09-00-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.15267, current rewards: -801.62794, mean: -1.95519
[32m[0907 09-00-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.15215, current rewards: -901.62794, mean: -1.96006
[32m[0907 09-00-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.15174, current rewards: -1001.62794, mean: -1.96398
[32m[0907 09-00-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.15139, current rewards: -1101.62794, mean: -1.96719
[32m[0907 09-00-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.15113, current rewards: -1201.62794, mean: -1.96988
[32m[0907 09-00-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.15091, current rewards: -1301.62794, mean: -1.97216
[32m[0907 09-01-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.15073, current rewards: -1401.62794, mean: -1.97412
[32m[0907 09-01-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.15058, current rewards: -1501.62794, mean: -1.97583
[32m[0907 09-01-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.15042, current rewards: -1601.62794, mean: -1.97732
[32m[0907 09-01-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.15028, current rewards: -1701.62794, mean: -1.97864
[32m[0907 09-01-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.15016, current rewards: -1801.62794, mean: -1.97981
[32m[0907 09-01-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.15005, current rewards: -1901.62794, mean: -1.98086
[32m[0907 09-01-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.14995, current rewards: -2001.62794, mean: -1.98181
[32m[0907 09-01-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.14986, current rewards: -2101.62794, mean: -1.98267
[32m[0907 09-02-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.14978, current rewards: -2201.62794, mean: -1.98345
[32m[0907 09-02-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.14972, current rewards: -2301.62794, mean: -1.98416
[32m[0907 09-02-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.14965, current rewards: -2401.62794, mean: -1.98482
[32m[0907 09-02-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.14958, current rewards: -2501.62794, mean: -1.98542
[32m[0907 09-02-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.14952, current rewards: -2601.62794, mean: -1.98598
[32m[0907 09-02-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.14946, current rewards: -2701.62794, mean: -1.98649
[32m[0907 09-02-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.14941, current rewards: -2801.62794, mean: -1.98697
[32m[0907 09-02-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.14937, current rewards: -2901.62794, mean: -1.98742
[32m[0907 09-03-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.14931, current rewards: -3001.62794, mean: -1.98783
[32m[0907 09-03-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.14928, current rewards: -3101.62794, mean: -1.98822
[32m[0907 09-03-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.14924, current rewards: -3201.62794, mean: -1.98859
[32m[0907 09-03-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.14922, current rewards: -3301.62794, mean: -1.98893
[32m[0907 09-03-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.14918, current rewards: -3401.62794, mean: -1.98926
[32m[0907 09-03-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.14915, current rewards: -3501.62794, mean: -1.98956
[32m[0907 09-03-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.14911, current rewards: -3601.62794, mean: -1.98985
[32m[0907 09-03-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.14908, current rewards: -3701.62794, mean: -1.99012
[32m[0907 09-03-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.14905, current rewards: -3801.62794, mean: -1.99038
[32m[0907 09-04-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.14903, current rewards: -3901.62794, mean: -1.99063
[32m[0907 09-04-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.14902, current rewards: -4001.62794, mean: -1.99086
[32m[0907 09-04-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.14899, current rewards: -4101.62794, mean: -1.99108
[32m[0907 09-04-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.14896, current rewards: -4201.62794, mean: -1.99129
[32m[0907 09-04-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.14893, current rewards: -4301.62794, mean: -1.99149
[32m[0907 09-04-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.14891, current rewards: -4401.62794, mean: -1.99169
[32m[0907 09-04-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.14889, current rewards: -4501.62794, mean: -1.99187
[32m[0907 09-04-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.14863, current rewards: -4601.62794, mean: -1.99205
[32m[0907 09-05-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.14768, current rewards: -4701.62794, mean: -1.99222
[32m[0907 09-05-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.14674, current rewards: -4801.62794, mean: -1.99238
[32m[0907 09-05-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.14583, current rewards: -4901.62794, mean: -1.99253
[32m[0907 09-05-17 @Agent.py:117][0m Average action selection time: 0.1451
[32m[0907 09-05-17 @Agent.py:118][0m Rollout length: 2510
[32m[0907 09-05-18 @MBExp.py:227][0m Rewards obtained: [-4981.627940613487], Lows: [2485], Highs: [12], Total time: 54982.90030199998
